大家好，这里是最佳拍档，我是大飞
6号凌晨
Meta突然宣布开源了Llama 4系列模型
不仅支持原生多模态
最大的参数规模竟然达到了惊人的2万亿
这期视频大飞就来为大家介绍一下发布的详细内容
Llama 4系列这次发布的模型一共包括三个参数规模
首批发布的是Llama 4 Scout和Llama 4 Maverick
同时还预览了最强大的Llama 4 Behemoth
我们分别来介绍一下
Llama 4 Scout是一款小型且快速的模型
拥有170亿激活参数、16个专家和1090亿的总参数
它的最大亮点是支持1000万token的上下文窗口
相当于能够处理长达20多个小时的视频
也非常适合于多文档摘要、大规模用户活动解析
以及大型代码库推理等应用场景
而且，经过Int 4量化之后
Llama 4 Scout能够在单个H100 GPU上运行
在一众基准测试中
Llama 4 Scout的性能超越了Gemma 3、Gemini 2.0 Flash-Lite和Mistral 3.1等模型
比如在图像推理的MMMU基准测试中
Llama 4 Scout的得分达到69.4
高于Gemini 2.0 Flash-Lite的68.0、Gemma 3的64.9以及Mistral 3.1的62.8；
在MathVista数学测试中
Llama 4 Scout得分为70.7
也优于部分对比模型
Llama 4 Maverick则是一款主打多模态能力的模型
拥有170亿激活参数、128个专家和4000亿的总参数
它在多个主流基准测试中表现出色
击败了GPT-4o和Gemini 2.0 Flash等模型
在推理和编码能力上
Llama 4 Maverick与新发布的DeepSeek v3相当
但是激活参数量不到v3的一半
大幅提升了性价比
它的实验性质的聊天版本在LMArena上的ELO评分达到了1417
排名第二
成为第四个突破1400分的大模型
在困难提示、编程、数学、创意写作等任务中均排名第一
在图像理解的Chart QA测试中
Llama 4 Maverick得分为90.0
高于Gemini 2.0 Flash的88.3和DeepSeek v3.1的85.7
在Coding LiveCodeBench编码测试中
Llama 4 Maverick得分43.4
也优于部分对比模型
Llama 4 Behemoth目前还在训练中
它拥有2880亿激活参数、16个专家和近2万亿的总参数
是Meta迄今为止最强大的模型之一
在多个STEM基准测试中
Llama 4 Behemoth的表现优于GPT-4.5、Claude Sonnet 3.7和Gemini 2.0 Pro
比如在MATH-500推理测试中
Llama 4 Behemoth得分为95.0
高于Claude Sonnet 3.7的82.2和Gemini 2.0 Pro的91.8
在MMLU多语言测试中
Llama 4 Behemoth得分为85.8
也展现出了强大的多语言处理能力
而且这一次Behemoth是作为教师模型
通过蒸馏为Llama 4 Maverick等较小模型提供了知识传递
除了这三款模型以外
Llama4系列这次还带来了多项技术突破
首先是架构方面
Llama 4全系列采用了混合专家MoE架构
在MoE模型中
单个token只会激活总参数的一小部分
与传统的稠密模型相比
在训练和推理时有更高的计算效率
以拥有170亿激活参数和4000亿总参数的Maverick为例
Meta通过交替使用密集层和MoE层
提升了模型的推理效率
其中MoE层中有128个路由专家和1个共享专家
也就是说
每个token会被送到共享专家以及128个路由专家中的一个
如此一来
虽然所有参数都存储在内存中
但是运行时只需要激活部分参数
大大降低了模型的服务成本和延迟
多模态能力也是Llama 4的一大亮点
通过早期融合技术
Llama 4将文本和视觉token
无缝整合到了统一的模型框架中
这个进步使得模型可以利用海量的无标签文本、图片和视频数据
进行联合预训练
同时
Meta还升级了基于MetaCLIP的视觉编码器
并且在训练时与冻结的Llama模型分开进行
让编码器能更好地适配大语言模型
从而让模型在复杂场景下的表现超越了部分竞争对手
无论是视觉处理任务还是语音对话任务
都展现出了强大的能力
在训练数据上，Llama 4也下足了功夫
这次的训练数据来源广泛
不仅包含公开的网络数据
还整合了Meta生态系统内的许可数据
比如Instagram和Facebook的公开帖子
以及用户与Meta AI的交互记录
这些丰富多样的数据
提升了模型在多语言支持和现实场景中的适应性
Llama 4通过在200种语言上预训练
实现了开源的微调支持
其中超过10亿个token的语言就有100多种
多语言token的数量比Llama 3多出了10倍
而预训练的整体数据量超过30万亿个token
是Llama 3预训练的两倍多
上下文窗口长度也是Llama 4这次的一个重大突破
Llama 4 Scout支持高达1000万token的上下文窗口
Llama 4 Maverick的上下文窗口也达到了100万token
相比之下
Llama 3的最大上下文仅为128k token
超大上下文窗口使得Llama 4在处理长文档、复杂对话和多轮推理任务时
有着明显的优势
为了实现这个突破
Meta采用了创新的iRoPE架构
通过交错注意力层结合旋转位置嵌入
去除掉部分的位置编码
以及在推理时对注意力进行温度缩放
从而增强了模型的长度泛化能力
为了让Llama 4的性能更上一层楼
Meta在训练和优化方面也做了大量工作
在预训练阶段
除了采用MoE架构、早期融合多模态数据
以及MetaP技术来设置关键的超参数以外
Meta还进行了新的中期训练方法
利用专门的数据集进行长上下文扩展
进一步提升了模型的核心能力
为Llama 4 Scout解锁了1000万token的输入上下文长度
在后训练阶段
Meta采用了从轻量级监督微调到在线强化学习、再到轻量级直接偏好优化DPO的全新训练流程
在训练Llama 4 Maverick的时候
为了解决多模态输入与推理、对话能力之间的平衡问题
Meta使用了Llama模型作为评判工具
剔除了超过50%被标记为“简单”的数据
只留下了剩余较难的数据集进行监督微调
在在线强化学习阶段
Meta精心挑选了更加具有挑战性的提示
同时采用了持续在线强化学习的策略
交替进行模型训练和数据过滤
只保留了中等到高难度的提示
在计算成本和精度之间取得了良好的平衡
最后
通过DPO来处理模型响应质量的边缘情况
使得Llama 4 Maverick在多项能力上都达到领先水平
对于Llama 4 Behemoth这样的超大型模型
后训练面临着巨大的挑战
Meta不得不精简95%的监督微调数据
来确保模型的质量和效率
在强化学习训练中
Meta通过pass@k分析和采样高难度的提示
设计了逐渐增加提示难度的训练课程
动态过滤掉没有优势的提示
并且混合具有多种能力的提示来构建训练批次
从而提升了模型在数学、推理和编码方面的性能
此外，Meta还优化了MoE并行设计
开发了完全异步的在线强化学习训练框架
使得训练效率相比前几代提升了大约10倍
目前，用户已经可以在llama
com和Hugging Face上
下载Llama 4 Scout和Llama 4 Maverick模型
后续这些模型还将上线更多的云平台和集成服务商
不过，从网友们的实测效果来看
Llama4的实际表现略微有些差强人意
不仅在数草莓单词中有多少个r这种问题上翻车
在Python六边形弹跳小球的测试中
效果也不如其他模型
不过，总的来说
Llama4的发布还是给开源模型领域打了一针强心剂
小扎也预示Meta的推理模型即将到来
另外
有网友发现在Llama4的代码仓库里
发布时间实际上是从美国时间4月7日提前到4月5日的
所以怀疑是因为下周有更加强大的模型要发布
所以Meta才选择提前发布Llama 4
而Sam Altman也继续在X上放出烟雾弹
预热OpenAI接下来也要放大招了
具体是什么东西
还是让我们下周拭目以待吧
好了，感谢大家收看本期视频
我们下期再见
