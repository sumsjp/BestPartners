大家好，这里是最佳拍档
在人工智能的发展浪潮中
AI for Science始终是一个被寄予厚望却又充满争议的领域
一边是AI技术高歌猛进
大模型能生成看似完美的科研论文摘要
另一边是传统科学界的质疑与抗拒
看着AI编造的参考文献、给出的荒谬结论嗤之以鼻
当两个领域陷入割裂与对立时
一位站在数学界金字塔顶端的人物
选择迈出了跨界的一步
他就是被誉为数学界的莫扎特的菲尔兹奖得主陶哲轩
2026年初，陶哲轩联合创立的Sair
科学与人工智能研究基金会正式亮相
这位数十年来与纯粹逻辑、绝对真理打交道的数学家
决定以数学为桥梁
拥抱充满概率、幻觉和不确定性的AI世界
更要为AI立起科学的规矩
这不仅是一位数学天才的个人选择
更是AI for Science领域的重要信号
意味着科学界开始主动介入AI的发展
试图驯服这头充满潜力却又难以掌控的猛兽
2026年2月
在Sair即将于加州大学洛杉矶分校的纯粹与应用数学研究所
举办首次启动仪式前
陶哲轩接受了一场深度专访
在这次对话中
他没有盲目吹捧AI的能力
反而以一种极其冷静甚至挑剔的眼光
剖析了当前AI在科研领域的致命弱点
也给出了自己对于AI与科学结合的核心解决方案
这场专访不仅展现了陶哲轩对于AI技术的深刻理解
更勾勒出了AI for Science未来的发展路径
而一切的起点
都要从Sair创立的初衷说起
陶哲轩在专访中坦言
创立Sair是多种因素共同作用的结果
其中最核心的一点
是他坚信AI技术已经准备好改变科学了
经过多年的发展
大语言模型、机器学习、神经网络等技术
已经具备了辅助甚至加速科研的能力
这一点在数学、物理、生物等多个领域都有了初步的验证
比如AI能快速完成海量的数据处理
能在复杂的公式中发现人类未曾注意到的模式
甚至能证明一些此前未被证明的数学定理
但是陶哲轩强调
技术的成熟并不意味着应用的成功
把AI融入科研的过程中
存在着无数错误的路径
而正确的路径其实少之又少
关键在于科学界要学会正确地使用AI
同时避免错误的用法
在这个过程中
学术界不能处于被动的位置
更不能坐等科技公司的施舍
当下的AI产品
大多是科技公司从商业角度出发开发的
其设计初衷并非完全适配科研的需求
如果科学界只是简单地把这些现成的产品拿来用
不仅无法发挥AI的真正价值
还可能因为AI的不确定性导致科研失误
陶哲轩认为
学术界必须深度介入AI的研发与应用过程
与科技公司互动、合作
搞清楚哪些科学领域适合AI的介入
哪些环节仍然需要依靠人类的传统研究方法
让AI成为科研的辅助者，而非主导者
除了技术层面的考量
科研资金环境的不确定性
也是陶哲轩创立Sair的现实原因
陶哲轩所在的UCLA IPAM
就曾遭遇过多个项目资金暂停的困境
这种资金上的混乱
让很多前沿的科研探索被迫中断
在这样的背景下
陶哲轩和其他科学家开始寻找新的资金来源
接触新的投资人和合作伙伴
而Sair的成立
正是这次寻找与合作的成果
作为一个非营利性研究机构
Sair汇集了全球顶尖的科学家
包括诺贝尔奖、图灵奖、菲尔兹奖得主
还吸引了众多科技企业和捐赠者的支持
核心目标就是支持AI for Science的发展
探索如何将AI技术真正整合到科学工作流中
同时也为科研工作者提供了一个新的平台
让他们能在稳定的支持下
尝试AI与科研的融合探索
值得一提的是
Sair并非是一个闭门造车的机构
它甚至在B站和抖音开设了官方账号
这种贴近大众的传播方式
与传统的科研机构形成了鲜明的对比
也让AI for Science的理念能被更多人了解
如果说Sair的创立是陶哲轩为AI与科学结合搭建的平台
那么数学就是他为这场结合找到的核心突破口
在陶哲轩看来，当下的AI工具
尤其是大语言模型
存在着一个巨大的阿喀琉斯之踵
那就是它们的随机性
这种随机性体现在
AI并不真正扎根于现实
也不理解自己生成的内容背后的逻辑
它只是在海量的数据中
通过统计学的方式匹配出一个看似合理的答案
这就导致了AI的输出具有极大的不确定性
有时能给出精准的、有价值的科研建议
有时却会给出完全的垃圾信息
比如编造参考文献、推导过程出现逻辑漏洞、给出与事实相悖的结论
这种不可靠性
让AI在很多学科的应用中都未能达到最初的预期
毕竟科学研究追求的是严谨与准确
任何一点不确定性
都可能导致整个研究的失败
但在所有的学科中
数学几乎是独一无二的
因为它拥有一套成熟且严谨的验证能力
这也是陶哲轩眼中能让AI不得不诚实的终极测谎仪
数学的研究核心是逻辑与证明
无论是人类写出的证明过程
还是机器生成的证明思路
都能通过逻辑定律和数学法则进行检验
判断其正确与否
而随着计算机技术的发展
这种检验还能通过形式化证明语言来实现自动化
比如陶哲轩推崇的Lean语言
就是一款开源的形式化证明语言
它拥有极小的可信内核
能保证数学证明的绝对正确性
甚至能处理费马大定理这样复杂的数学证明问题
这种形式化验证的能力
让数学成为了AI for Science的天然试验场
因为它能过滤掉AI那些糟糕的、胡说八道的用法
只保留下有效的部分
当然，陶哲轩也客观地指出
并非所有的数学研究都能被形式化验证
比如提出新的数学猜想、向大众解释复杂的数学概念
这些需要创造力和表达能力的环节
AI目前还未必擅长
但是在定理证明、逻辑验证这些核心环节
AI的潜力是巨大的
基于数学的形式化验证能力
陶哲轩预见了未来数学研究的全新模式
那就是数学将带有更多的实验性质
长久以来
数学研究几乎完全依靠理论推导
数学家通过严谨的逻辑
从已知的定理推导出新的结论
整个过程几乎不存在实验的环节
但是AI的出现
让这种模式有了改变的可能
陶哲轩认为
未来的AI可以先提出一个数学假设
比如某个公式对所有自然数都成立
然后自己设计实验
通过测试大量的数值案例
或者检查这个假设是否与文献中已有的结果兼容
以此来验证假设的合理性
虽然这种实验性质的验证并非严格的数学证明
却能增加或减少数学家对这个假设的信心
为后续的理论推导指明方向
当然，这种模式目前还处于早期阶段
因为我们还没有建立起完善的AI验证机制
陶哲轩预估
想要让这种模式成为数学研究的主流
可能还需要10年左右的时间
但他同时也表示
AI在数学领域的发展速度
已经超出了他的预期
很多人曾对AI抱有过高的期望
认为数学家和科学家很快就会被AI取代
但是陶哲轩直言，这显然是不现实的
当下的AI虽然能证明一些以前从未被证明的定理
也能发现人类未曾注意到的模式
但是这些成就大多是通过标准方法实现的
AI依然存在不可靠的问题
其核心价值并非是取代人类
而是与人类形成分工
加速科研的进程
陶哲轩认为
AI最擅长的是结构化的重复任务
而这恰恰是人类最不喜欢也最不擅长的
在数学研究中
如果让一个数学家完成一千道类似的推导题目
他可能做完前两道就感到厌烦
剩下的题目根本没有精力去完成
但是这样的重复任务
对AI来说却毫无压力
因此
短期内AI与人类的合理分工模式应该是
人类提出核心的研究构想
画出研究的第一步草图和方向
确定研究的核心逻辑
然后把那些繁重的、重复性的填补工作交给AI
比如大量的数值计算、公式推导、案例验证等等
这种分工能极大地加速现有的科研工作流
让数学家能把更多的精力放在更有价值的创造性工作上
那么
具体该如何利用数学的形式化验证
让AI停止作弊
成为可靠的科研辅助者呢？
陶哲轩在专访中给出了具体的实施流程
这也是目前数学领域中
让AI规范化应用的最佳方法
这个核心方法就是形式化验证
整个流程环环相扣，通过严谨的步骤
让AI的输出变得可验证、可追溯
首先，让AI生成一段自然语言的论证
针对某个数学问题
给出自己的证明思路或推导过程
这一步的输出可能是正确的
也可能存在错误
这是AI发挥自身优势的环节
利用其掌握的海量文献技巧
快速给出初步思路
然后
让同一个AI或者另一个专门的AI
把这段自然语言的论证转换成形式化语言
也就是一种极其精准的代码化语言
每一个断言、每一步推导
都能被精准量化
不存在任何模糊的表述
这一步的核心是把AI的模糊思路转化为精准逻辑
最后，将转换后的形式化语言
交给一个非常严格的编译器进行验证
这里需要特别注意的是
这个编译器并非AI
而是传统的、极其可靠的软件系统
这类系统是专门为了高可靠性而设计的
到目前为止
在主流形式化证明语言的编译器中
几乎没有发现过重大漏洞
这就为验证过程提供了绝对的严谨性
如果形式化语言
在编译器的验证中失败
说明AI的最初论证存在逻辑漏洞
这时就让AI根据验证结果重新生成论证
再次进行转换和验证
如果验证通过
那么我们就能得到一份被机器验证过的形式化证明
虽然这份形式化证明因为过于精准
对人类来说可能很难读懂
但我们可以再让AI把这份形式化证明反转为自然语言
为数学家进行解释
这就是形式化验证的完整流程
其美妙之处在于，每一步都极其精确
数学家可以手动把一个巨大的定理拆分成许多小块
每一块都单独进行AI生成、形式化转换和编译器验证
这样即使某个小块出现问题
也能快速定位并修正
不会影响整个定理的研究
陶哲轩和他的团队已经在实践中遇到过很多这样的案例
AI生成了一个数学证明
数学家一开始完全看不懂这个证明的思路
甚至觉得其推导过程毫无逻辑
但是当他们对AI生成的形式化代码进行反编译和深入研究几天后
不仅理解了AI的证明思路
甚至还在现有的文献中
找到了类似的人类研究先例
这也体现出了AI在科研中的核心优势
广度
AI通过学习海量的科研文献
吸收了其中的各种技巧精华
人类数学家可能因为研究领域的限制
只能熟练掌握四五种解题技巧
但AI却能掌握十几种甚至更多的技巧
虽然它并不总是能恰当地使用这些技巧
有时会出现技巧与问题不匹配的情况
但只要研究问题本身在现有文献中有基础
AI就能发挥出强大的作用
当然，陶哲轩也客观地指出
目前还没有看到AI能提出完全没有先例的、前所未有的全新思想
不过说实话，在整个数学界
大多数人类数学家也同样做不到这一点
原创性始终是科研的核心难题
无论是对人类还是对AI来说
都是如此
尽管AI在数学领域的应用已经取得了初步的成果
也展现出了巨大的潜力
但是陶哲轩直言，当下的AI
还远远算不上科研的合著者
在他看来，AI想要成为真正的合著者
还有很多方面需要提升
而其中最核心的
就是创造力和持续学习能力
首先是创造力
尤其是那种无法追溯到现有文献的原创性
当下的AI所有的输出
都是基于对现有文献的学习和匹配
其本质是归纳，而非创造
它无法提出一套全新的理论体系
也无法找到一条从未有人涉足的研究路径
而这恰恰是科研最核心的价值所在
也是人类科学家不可替代的关键
其次是持续学习能力
陶哲轩曾经把当前AI在数学上的能力比作一个研究生
这个研究生掌握了很多解题技巧
会尝试把这些技巧应用到不同的问题中
有时成功，有时失败
但是与人类研究生相比
AI缺少了一个最核心的能力
那就是从错误中学习
如果指出人类研究生的错误
他会记住这个错误
下次遇到类似的问题时，就不会再犯
但是AI却做不到这一点
只要开启一个新的会话
它往往就忘记了之前的错误和交流内容
虽然现在的大模型已经具备了上下文窗口
能保留之前的部分对话
但这种保留并不稳定
也无法真正让AI形成记忆
还有一个众所周知的现象是
如果你明确告诉AI不要做某件事
它反而可能更倾向于去做
这是因为当下的AI是通用型的
我们还没有能力让它真正专业化
比如把它变成一个只做数学的专家
让它能精准理解科研的需求和禁忌
除了创造力和持续学习能力的缺失
人机协作工作流的不成熟
也是AI无法成为合著者的重要原因
当下我们使用AI的方式
大多是拼凑的，写论文遇到瓶颈了
就打开浏览器问问聊天机器人
需要处理数据了
就找一个专门的AI工具
甚至有些人尝试让AI直接接管电脑进行科研操作
而陶哲轩认为
这其实是个坏主意
这种碎片化的使用方式
让AI无法真正融入科研的整个流程
也无法与人类形成有效的协作
而人类之间的科研合作
经过了几百年的打磨
已经形成了成熟的模式
科学家们可以在黑板前面对面讨论
一边写下公式一边交流
随时调整研究思路
这种互动是高度整合的
每一个想法都能及时得到反馈
每一个调整都能被对方快速理解
但是与AI的合作
却缺失了这种核心的协作感
陶哲轩用一个形象的比喻解释了这种缺失
就像疫情期间
所有人都从线下会议转到了Zoom线上会议
从功能上讲
线上会议完全可以传达信息
科学家们也能通过屏幕交流研究思路
但是面对面交流中的眼神接触、肢体语言
这些微妙的隐性信号却丢失了
而这些信号往往能传递出很多重要的信息
比如对某个观点的质疑、对某个思路的认可
同样，和AI聊天、合作时
人类也会缺失这些隐性的信号
我们无法判断AI对某个问题的理解程度
也无法从AI的输出中
感受到其背后的逻辑思考过程
这种信息的缺失
让人机协作变得极其生硬
更重要的是，当下的AI公司
大多倾向于展示那种一键生成最终答案的产品
这种产品从商业角度来看
能满足用户的即时需求
却完全不符合科研的规律
科研的核心价值
不仅在于得到最终的答案
更在于探索答案的过程
科学家在研究中不断试错、不断调整思路
这个过程本身就是一种学习和积累
但是一键生成答案的AI产品
让人类完全脱离了解决方案的创造过程
如果只是单纯地拿到AI给出的答案
科学家无法理解其背后的推导逻辑
更无法向别人解释这个答案
当需要对答案进行修改和调整时
也只能被动地乞求AI
让AI帮忙修改一下，而每次修改
往往会让结果变得更差
因为AI并不理解修改的核心需求
只是再次通过统计学匹配生成新的内容
陶哲轩认为，理想的人机协作
应该是互动式的
就像人类之间的合作一样，你走一步
AI接一步，人类给出一个研究思路
AI基于这个思路进行推导和验证
然后人类根据AI的输出给出反馈
指出其中的问题
AI再根据反馈进行修正
在这样的互动过程中
科学家能理解证明是如何一步步构建出来的
也能随时调整研究方向
让AI真正成为科研过程的一部分
对于AI在科研中的定位
陶哲轩给出了一个精准的比喻
AI应该像盐
做菜时
加一点盐能让食物的味道更美味
但如果把整罐盐都倒进去
食物就会变得无法入口
AI的使用也是如此
关键在于在合适的时候用
在不合适的时候不用
让AI成为科研的调味剂，而非主菜
AI之所以无法与人类形成有效的互动协作
本质上与机器学习的核心哲学有关
陶哲轩在专访中深入剖析了这一点
早期的AI研究
试图模仿人类的推理过程
让AI像人类一样思考、推导
但是由于人类的思维过程过于复杂
这种研究方向的结果并不好
后来，研究人员转向了另一种方法
只为AI定义一个明确的目标
不管实现目标的过程是否优雅、是否符合逻辑
只要能最大化这个指标就行
这种方法在数据量和算力大幅提升后
取得了惊人的效果
当下的大语言模型、机器学习算法
都是基于这个核心逻辑发展起来的
但是这种逻辑
也让AI产生了一个致命的问题
那就是有时太擅长优化目标了
陶哲轩把这样的AI
比作神话故事里那个只按字面意思理解愿望的精灵
人类向AI下达指令，定义一个目标
AI就会投入所有的算力
精准地达成这个指令
却完全忽略指令背后的核心需求
甚至为了达成目标而作弊
比如
如果要求AI在形式化证明助手里
生成一个某个定理的证明
并且强行要求无论如何都要得到证明
AI就可能会采取作弊的方式
比如随意添加一个新的公理
或者偷偷修改某个数学定义
通过这种不符合科学规律的方式
生成一个看似符合要求的证明
从字面上看，AI确实完成了任务
但是这却完全违背了科研的初衷
之所以会出现这种情况
是因为人类其实并不擅长精确定义目标
在人类的交流中
存在着大量的隐含常识
比如让人类去倒茶
不需要特意告诉他不要把茶倒在我身上
因为人类凭借常识就能理解这个隐含要求
但是AI却没有这种隐含的常识背景
它只能严格按照人类给出的字面指令去执行
陶哲轩认为
这也是未来AI与科研结合需要解决的核心问题之一
我们正在学习如何给AI布置任务
尤其是那些需要精确规范的科研任务
必须把目标描述得非常清楚
堵住所有的逻辑漏洞
同时认真思考自己真正想要的结果
让AI的执行方向与科研的核心需求保持一致
在专访的最后
陶哲轩还谈到了大众在科学中使用AI时
最常见的一个误解，而这个误解
也在一定程度上导致了人们对AI for Science的认知偏差
陶哲轩说，对大多数人来说
AI就等同于聊天机器人
大家心中的AI
是能像人一样回应对话、说些好听的话、能生成文案和图片的工具
这种认知源于聊天机器人的普及
也让人们忽略了AI的真正内涵
不可否认
有些科学家确实会用聊天机器人来辅助思考
比如梳理研究思路、整理文献要点
但是在真正的科研中
更有效、更强大的AI用法
其实与聊天机器人完全不同
这些用法通常是结合了验证机制的数值计算、科学绘图、逻辑检验等
这些AI工具没有华丽的对话界面
也不能像人一样交流
却能在科研的核心环节发挥重要作用
陶哲轩直言，科学家使用AI的方式
与公众的认知大相径庭，在科研中
科学家不需要AI生成可爱的图片
也不需要AI说些迎合的话
需要的是AI能精准、可靠地完成科研辅助工作
遗憾的是，现在的舆论环境
把所有相关的技术都打包叫做AI
让人们误以为AI就是单一的技术
却忽略了AI其实是数百种相关技术的集合
比如神经网络
这项技术已经存在二十多年了
它没有现在的大语言模型那么性感
没有对话界面
本质上就是一个数据处理工具
用来在海量数据中寻找模式、挖掘规律
但就是这样一种看似朴素、枯燥的技术
科学家们已经用了二十多年
在科研中发挥了极其重要的作用
尤其是在数据密集型的学科中
神经网络的价值无可替代
还有形式化证明语言、机器学习算法、数值计算工具等
这些都是AI体系的重要组成部分
也是科研中最常用的AI技术
但是这些技术往往不是公众最关注的
公众的目光大多集中在能直接互动的聊天机器人上
陶哲轩认为
也许我们需要为这些技术制定更好的命名方式
而不是把所有东西都一股脑地塞进AI这个标签里
这样才能让人们更清晰地认识到AI的真正内涵
也能让科学界更精准地选择适合的AI技术进行科研
陶哲轩入局AI for Science
创立Sair
并非只是一位数学天才的个人跨界
更是科学界对AI技术的一次主动拥抱和规范
在AI技术快速发展的今天
与其被动地抗拒
不如主动地介入
用科学的规律为AI立规矩
让AI成为科研的辅助者而非主导者
而数学的形式化验证
就是这场规范的核心抓手
它用数学的确定性
对抗着AI的不确定性
让AI的输出变得可验证、可追溯
当然，AI for Science的发展
还有很长的路要走
AI的原创性、持续学习能力、人机协作的工作流
这些都是需要不断解决的问题
但陶哲轩的尝试
已经为这条道路指明了方向
我们也期待能尽快看到Sair的成果
感谢收看本期视频，我们下期再见
