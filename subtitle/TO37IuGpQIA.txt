大家好，这里是最佳拍档，我是大飞
谷歌正在试图夺回AI王座
第七代TPU直接叫板英伟达Blackwell B200
4月10日
谷歌在拉斯维加斯举办了一年一度的谷歌云大会
吸引了全球科技爱好者的目光
在这次大会上
谷歌带来了一系列的重磅发布
涵盖了首款推理TPU、多款模型升级、全新的A2A协议
以及代码助手等多个领域
不仅展现了谷歌在AI领域的深厚技术积累
也可能将重塑AI产业的格局
今天大飞就来给大家盘点一下
谷歌云大会上都发布了哪些内容
在本次谷歌云大会上
最引人注目的无疑是谷歌第七代TPU Ironwood的首次亮相
这款芯片直接将目标瞄准了英伟达的Blackwell B200
也是谷歌迄今为止性能最强、可扩展性最高的定制AI加速器
专为推理设计
相较于2018年的第一代TPU
推理性能飙涨了3600倍
效率也提升了29倍
Ironwood芯片搭载了高达192GB的HBM显存
是第六代TPU Trillium的6倍
相较于更早的 TPU v4更是提升了六倍
大显存意味着可以处理更大的模型和数据集
同时减少了频繁数据传输的需求
进而提高了性能
HBM的带宽对于AI计算也至关重要
Ironwood芯片的HBM带宽
提升到了惊人的7.2 Tbps
是Trillium的4.5倍
芯片间互连ICI双向带宽
这次也增加到了1.2 Tbps
是Trillium的1.5倍
对于谷歌Cloud客户
Ironwood提供了两种规格
分别是256个芯片和9216个芯片
每个单独的芯片峰值FP8算力达到4614 TFLOPs
当扩展到每个pod 9216个芯片时
可以在FP8精度下达到42.5 Exaflops
不过这里谷歌玩了一个偷梁换柱的概念
号称这个算力是世界上最大的超级计算机El Capitan的24倍以上
但是实际上是跟El Capitan在FP64精度下的1.74 exaFLOPS相比而言的
如果同样换算成FP8精度
El Capitan的理论峰值性能接近87 exaFLOPS
仍然远超Ironwood
不过即便如此
42.5 Exaflops 的 FP8 算力
对于大规模的推理任务而言
仍然是一个相当可观的数字
不仅如此
Ironwood还配备了增强版的SparseCore
这是专门用于处理高级排序和推荐任务的加速器
也使得Ironwood的应用场景更加广泛
不仅局限于传统的AI领域
还能用于金融和科学领域
另外
由谷歌DeepMind开发的ML运行时Pathways
可以与Ironwood很好的配合
从而多个TPU芯片上实现高效的分布式计算
将数十万个Ironwood芯片组合在一起进行计算
同时
谷歌这次还增添了新一代的GKE推理功能
以及将vLLM引入了TPU
这就让那些已经用vLLM针对GPU优化过的PyTorch代码
能够轻松地转到TPU上运行
在性能提升的同时
Ironwood也非常注重功耗效率
与第六代TPU Trillium相比
它在功耗效率上实现了2倍的提升
对比2018年推出的首款TPU
更是高出了29倍
谷歌通过先进的液冷解决方案和优化的芯片设计
保证了即使在持续、繁重的AI工作负载下
也能可靠地维持标准风冷两倍的性能
这对于大规模的AI计算来说
至关重要
在社交平台上
有OpenAI的研究员将Ironwood与英伟达的GB 200做了性能对比
总体来说
Ironwood与GB200的性能相当
甚至在功耗方面
Ironwood还稍低一些
谷歌副总裁兼Cloud AI总经理阿明·瓦赫达特（Amin Vahdat）在会上表示
Ironwood的目标在支持生成式 AI的下一阶段
以及巨大的计算和通信需求
因为在推理时代
AI Agent将主动检索和生成数据
通过协作的方式来提供洞察和答案
而不仅仅是依靠数据了
除了Ironwood芯片以外
谷歌的Vertex AI平台
现在成为了唯一一个拥有涵盖所有模态
包括视频、图像、语音和音乐的模型平台
这次更是包括了四项重大更新
首先
文本转音乐模型Lyria的出现令人眼前一亮
它可以让客户从文本提示词开始
生成完整的、可用于生产环境的音乐素材
比如
企业可以根据自身品牌独特的调性
为营销活动、产品发布或者是沉浸式的店内体验
快速定制配乐
而对于创作者来说
Lyria更是简化了内容创作流程
创作者可以在几分钟内生成定制音乐曲目
直接契合内容的情绪、节奏和叙事
从而加速制作工作流程并且降低授权成本
打个比方
如果创作者想要创作一首高能的Bebop曲调
只需给出详细的描述
Lyria就能按照要求生成相应的音乐
其次
视频生成模型Veo 2也进行了升级
为视频的创建、编辑和视觉效果
添加了一套强大的功能集
使得它从一个单纯的生成工具
转变为了一个全面的视频创作和编辑平台
在视频修复方面
Veo 2无需手动修饰即可获得干净、专业的编辑效果
用户可以轻松移除视频中不需要的背景图像、徽标或干扰物
使它们在每一帧中都平滑完美地消失
就好像这些东西从未存在过一样
在画面扩展功能上
Veo 2能够扩展现有视频素材的画面
将传统视频转换为针对网页和移动平台优化的格式
比如
它可以轻松将横向视频转换为用于社交媒体短视频的纵向视频
从而适应不同的屏幕尺寸和宽高比
此外
Veo 2还新增了应用复杂电影拍摄技术的功能
无需复杂的提示词或者专业知识
团队就能运用指导镜头构图、摄像机角度和节奏等技术
通过连接两个现有素材来创建一个连贯的视频
也是Veo 2这次升级的一大亮点
借助插值功能
用户可以定义视频序列的开始和结束
Veo 2会无缝生成连接帧
从而确保平滑过渡并且保持视觉的连续性
第三
语音生成模型Chirp 3同样带来了令人惊喜的更新
它的高清语音功能提供了超过35种语言的自然逼真语音
以及8种说话人选项
除此之外
谷歌还新增了两个强大的功能
分别是即时定制语音（Instant Custom Voice）功能和带说话人日志功能的转录（Transcription with Diarization）功能
其中即时定制语音只需要10秒的音频输入
就可生成逼真的定制语音
企业能够借助这个功能来个性化呼叫中心、开发无障碍内容
以及建立独特的品牌声音
而带说话人日志功能的转录功能
它可以精确地分离和识别多人录音中的单个说话人
显著提高转录内容的清晰度和可用性
非常适用于会议纪要、播客分析和多方通话录音等应用场景
第四
Imagen 3作为谷歌最高质量的文本转图像模型
这次也有了显著的改进
它能够生成具有比之前更好细节、更丰富光照和更少干扰性伪影的图像
谷歌还显著改进了Imagen 3的图像修复（inpainting）能力
用于重建图像中缺失或损坏的部分
尤其是在物体移除（object removal）方面
不仅质量更高
而且效果也更加自然
除了模型本身能力的升级以外
如今随着人工智能的发展
Agent在各个领域的应用也越来越广泛
但是Agent如果想要发挥更大的作用
就必须能够跨越孤立的数据系统和应用程序
在一个动态的多Agent生态系统中相互协作
为了实现这一目标
谷歌推出了全新的开放协议
Agent2Agent，简称A2A
并且已经获得了超过50家合作伙伴的支持和贡献
简单来说，A2A是一种开放协议
为Agent提供了一种标准的交互方式
让它们之间能够进行相互协作
而无需考虑底层框架或者供应商
比方说
一家大型电商公司使用了多种企业平台和服务
Atlassian 用于团队项目管理
Box 用于文件存储和共享
Salesforce 用于客户关系管理
Workday 用于人力资源管理
以前这些平台上的Agent是无法自由通信的
而现在通过A2A协议
这些企业平台可以安全、自由地自动化交互数据
在与合作伙伴设计协议时
谷歌遵循了五个关键原则
第一
A2A专注让Agent能够在它们自然的、非结构化的模式下进行协作
即使它们不共享内存、工具和上下文
谷歌想要开启的是一个真正的多Agent场景
而不是限制Agent成为一个工具
第二
协议基于现有的、流行的标准构建
包括HTTP、SSE、JSON-RPC等等
这意味着它可以很容易地与企业现在已经在使用的IT技术栈进行集成
第三
A2A协议可以支持企业级的认证和授权
与OpenAPI的认证方案具有对等性
使用A2A 协议能快速通过身份验证
安全地获取数据
保障数据传输的安全性和合规性
防止数据泄露风险
第四，A2A协议具有很好的灵活性
能够支持从快速任务到可能需要几小时、甚至几天的深入研究等各种场景
在整个过程中
A2A可以向用户提供实时的反馈、通知和状态更新
第五，A2A协议可以支持各种模态
包括音频、图像和视频流等等
我们再来简单介绍一下A2A的工作原理
它是通过促进客户端Agent和远程Agent之间的通信来实现的
客户端Agent负责制定和传达任务
而远程Agent则根据这些任务采取行动
提供正确的信息或执行相应的操作
在这个过程中
A2A协议有以下几个关键能力
首先
Agent可以通过“Agent Card”来宣传它们的能力
这些“Agent Card”是以JSON格式存在的
它们能够让客户端Agent识别出哪个远程Agent最适合执行特定的任务
一旦确定了合适的远程Agent
客户端Agent就可以利用A2A协议与之进行通信
将任务分配给它
然后
任务管理是A2A协议中的一个重要环节
客户端和远程Agent之间的通信都是围绕完成任务展开的
协议定义了一个“任务”对象
这个对象具有自己的生命周期
对于一些简单的任务
可能可以立即完成
而对于一些复杂的、长期的任务
Agent们可以相互沟通
保持对任务完成状态的同步
当任务完成时
输出最终的工件Artifact
此外，A2A还支持Agent之间的协作
Agent们可以相互发送消息
这些消息可以包含上下文信息、回复、工件或者用户指令
通过这种方式
Agent们能够更好地协同工作
共同完成复杂的任务
最后，A2A还具备用户体验协商的功能
每条消息都包含部分parts
这些parts是完整的内容片段
比如生成的图像
每个parts都有指定的内容类型
这使得客户端和远程Agent能够协商所需的正确格式
并且明确包括用户界面能力的协商
比如iframe、视频、网络表单等
这样
A2A就能够根据用户的需求和设备的能力
提供最佳的用户体验
谷歌还在博客中对 MCP 和 A2A 两种协议进行了比较
MCP主要是用于工具和资源管理
通过结构化的输入输出
将Agent连接到工具、API 接口和资源上
而A2A协议主要是用于Agent之间的协作
两个协议可以说是互补的
在这次谷歌云大会上
还有一个值得关注的更新
那就是谷歌的AI编码助手
Gemini Code Assist
它现在也可以部署新的AI Agent
通过执行多个步骤来完成复杂的编程任务
比如
它可以根据Google Docs中的产品Spec来创建应用程序
或者将代码从一种语言转换为另一种语言
大大提高开发效率
而且
Code Assist现在除了在其他编码环境中使用外
还可在Android Studio中使用
进一步扩大了它的应用范围
不过它在实际编程环境中的表现究竟如何
还要等它正式发布之后试用才知道
好了
以上就是这次谷歌云大会发布的主要内容了
从性能超强的Ironwood TPU
到全模态升级的Vertex AI平台
再到全新的A2A协议和Gemini Code Assist
谷歌的这场大会
似乎迫不及待的想要展现自己的实力
另外根据CEO Pichai 介绍
Gemini 2.5 Pro 现在已经在 AI Studio、Vertex AI 和 Gemini 应用程序中
向所有人开放了
根据谷歌在今年 1 月发布的财报显示
其 2024 年第四季度的云业务收入
达到 120 亿美元，同比增长了 30%，
AI Studio 和 Gemini API 的活跃用户
更是在过去一个月就增长了 80%。
随着OpenAI打算开启新一轮的发布周
相信谷歌后续也还会有相关的动作跟进
让我们拭目以待
感谢大家观看本期视频
我们下期再见
