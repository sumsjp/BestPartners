大家好，这里是最佳拍档
在过去的几年里
如果要评选科技圈最让人心跳加速、同时也最让人感到焦虑的词汇
那一定非AGI莫属
通用人工智能
这个曾经只存在于科幻小说和少数极客幻想中的概念
如今正以前所未有的速度闯入我们的现实世界
无论是在硅谷的咖啡馆
还是在华尔街的交易大厅
甚至是我们日常的餐桌上
关于AGI何时到来、它将如何重塑人类文明的讨论从未停歇
但是在这个喧嚣的时代
我们似乎听到了太多来自市场营销者的声音
太多来自末日论者的警告
却唯独缺少了那些真正站在技术最前沿、亲手缔造这个未来的科学家的冷静思考
今天
我们要把目光投向一位真正的大神级人物
他不仅是Google DeepMind的联合创始人
更是那个在二十多年前
当所有人都在嘲笑通用智能是痴人说梦的时候
就坚定地将它作为毕生追求的人
甚至连AGI这个词的普及
都在很大程度上归功于他
他就是Google DeepMind的首席科学家
谢恩·莱格（Shane Legg）
在谢恩·莱格（Shane Legg）最新的访谈中
他为我们从技术定义的底层逻辑
到2028年的惊人预测
再到关乎人类命运的安全伦理
呈现出了一幅硬核、客观的AGI全景图
这不仅仅是一次技术的探讨
更是一次关于人类未来的预演
让我们先回到一切的起点
到底什么是AGI？
在很长一段时间里
大众对于AI的理解是割裂的
我们有能战胜世界围棋冠军的AlphaGo
有能推荐你喜欢看什么电影的算法
甚至有能帮你扫地的机器人
但是这些都是狭义上的AI
它们像是一个个精通某种特技的偏科生
离我们要找的那个全能天才
相去甚远
莱格在访谈中非常坦诚地指出
目前关于AGI的定义
确实存在着巨大的混乱
很多人喜欢用一种非黑即白的二元论来看待这个问题
要么AI还没有觉醒
仅仅是冷冰冰的代码
要么AI明天就会变成《终结者》里的天网
统治人类
但是现实往往比电影剧本要复杂得多
也细腻得多
莱格提出了一个非常有建设性的分层定义的概念
首先是最小化AGI（Minimal AGI）
这个定义的门槛看似不高
却非常关键
他认为
如果一个AI Agent能够执行人类通常能做的各种认知任务
那么它就跨过了最小化AGI的门槛
请注意，这里的关键词是通常能做
这意味着它不需要像爱因斯坦那样提出相对论
也不需要像莫扎特那样谱写传世乐章
它只需要像一个普通的、受过基本教育的人类一样
能够理解常识、能够学习新的技能、能够处理日常生活中的认知挑战
如果你觉得这个标准太低了
那么请看一看当下的AI
今天的GPT或者Gemini
已经能够通过律师资格考试
能够写出漂亮的诗歌
甚至能用几百种语言和你对话
这在某些维度上
甚至已经超越了绝大多数的人类
但是
如果你让它去理解一个简单的物理场景
比如判断远处的一辆蓝色汽车和近处的一辆红色汽车
谁更大，或者让它去数一张图表上
一个节点延伸出了几条线
它可能会犯下连三岁小孩都不会犯的错误
这就是莱格所描述的锯齿状的能力边界（Jagged Frontier）
我们的AI现在正处在一个非常奇特的状态
在某些抽象符号处理、知识检索和语言表达上
它是超人级的
但是在视觉推理、长期记忆管理
以及那种走一步看三步的连续学习能力上
它甚至还不如低等的动物
这种能力的不均衡
其实揭示了当前深度学习架构的一些本质局限
我们的大模型
主要是通过海量的文本数据训练出来的
它们极其擅长捕捉概率上的相关性
擅长预测下一个词
但是，真正的智能不仅仅是预测
更是对世界运行规律的深刻理解
也就是我们常说的世界模型
这就引出了通往AGI的下一个关键阶段
从工具到Agent
莱格非常敏锐地指出了当前AI的静态属性
现在的模型
更像是一个被封印在服务器里的、全知全能的图书馆管理员
你问它问题，它给你答案
但是，它没有自己的生活
没有自己的长期记忆
也不会主动去探索世界
它在训练完成的那一刻
某种意义上就已经定型了
但是人类不是这样的
我们是在与物理世界的交互中学习的
我们犯错，我们修正，我们积累经验
这种持续学习（Continual Learning）的能力
是目前AI通往AGI道路上
必须攻克的一座堡垒
想象一下，如果你入职一家新公司
老板不需要你在第一天
就掌握所有的业务细节
但他期望你能在未来的一周、一个月里
通过观察和实践，逐渐掌握这些技能
目前的AI，恰恰缺乏这种在部署后
继续动态生长的能力
为了解决这个问题
莱格提到了一个心理学上的经典概念
也就是诺贝尔奖得主丹尼尔·卡尼曼（Daniel Kahneman）提出的系统1和系统2思维
系统1是快思考，是直觉
是下意识的反应
比如你看到一张愤怒的脸
你会立刻意识到危险
你听到2+2，你会脱口而出等于4
目前的大模型
在很大程度上就像是极致强大的系统1
它们反应极快
基于概率瞬间生成答案
但是有的时候不过脑子
容易产生幻觉
而系统2是慢思考，是逻辑，是推理
当你需要计算17乘以24时
当你需要规划一次复杂的跨国旅行时
或者当你面临一个两难的道德抉择时
你不能靠直觉，你需要停下来
一步一步地推导
在大脑中模拟各种可能的结果
然后做出决定
通往AGI的关键
就在于让AI拥有系统2的能力
这在技术上通常被称为思维链
我们需要让AI学会慢下来
学会把一个大问题拆解成无数个的小步骤
学会在每一步都进行自我反思和验证
只有当AI不仅能够凭直觉回答问题
还能像数学家证明定理一样
严谨地进行推理时
我们才能说它真正具备了通用的认知能力
那么，这个激动人心的时刻
到底什么时候会到来？
这是一个价值万金的问题
而在预测未来这件事情上
莱格的记录好得惊人
早在2009年
当大多数人还把深度学习
看作是学术界的冷门方向时
他就已经在自己的博客上公开预测
人类有50%的概率将会在2028年实现AGI
十几年过去了
尽管经历了无数的技术起伏
经历了AI的寒冬与盛夏
莱格依然坚定地维持着这个预测
哪怕是在今天
面对主持人汉娜·弗莱（Hannah Fry）的追问
他依然没有改变口径
2028年，依然是那个关键的时间节点
这听起来似乎不可思议
2028年距离现在只有短短几年了
我们真的能在这么短的时间里
跨越从聊天机器人到通用智能的鸿沟吗？
这里我们需要警惕人类思维的一个巨大陷阱
线性思维与指数级发展的错位
莱格用了一个非常形象的比喻
2020年3月的那个时刻
当流行病学家看着指数级增长的曲线
声嘶力竭地警告大流行即将到来时
绝大多数普通人还在照常聚会、看球赛
觉得那是遥不可及的威胁
为什么？
因为人类的大脑是为线性世界进化的
我们很难直观地理解
什么是指数级的爆炸
AI的发展正是如此
如果你只看过去一年的进步
你可能会觉得也就那样
但是如果你把时间拉长
看看计算算力的增长、算法效率的提升
以及数据规模的膨胀
你会发现我们正站在一条几乎垂直向上的曲线的拐点上
硬件方面
我们拥有了远超人类大脑能耗效率的芯片
数据方面
虽然高质量文本数据可能面临枯竭
但是多模态数据的潜力才刚刚被挖掘
算法方面
Transformer架构可能只是一个开始
更高效的推理架构
正在实验室里酝酿
这不仅仅是关于算力的堆砌
更是关于质变
就像水温从99度到100度，只差一度
但是水的形态却发生了根本性的变化
莱格认为
随着模型规模的进一步扩大
随着系统2推理能力的引入
我们将看到AI在理解力、规划能力和泛化能力上的涌现
这种涌现
很可能会在未来几年内突然发生
让我们措手不及
当然，伴随着这种强大能力的
是前所未有的风险
这也是莱格作为DeepMind的首席科学家
花费大量精力思考的问题
如何确保一个比人类更聪明的系统
依然站在人类这一边呢？
这就涉及到了AI安全领域的核心难题
对齐（Alignment）
以前我们谈论AI安全
更多是担心它犯错
比如自动驾驶汽车没识别出路障
但是在AGI时代
我们担心的是它太聪明了
聪明到学会了伪装，学会了欺骗
莱格提出了一个非常有深度的观点
我们不能只看结果
必须看过程
在很多的伦理困境中
比如经典的电车难题
或者医生在医疗资源匮乏时的生死抉择
结果往往都是不完美的
如果我们只根据结果来惩罚AI
可能会导致它学会隐瞒真实的意图
或者采取极端的功利主义策略
因此
DeepMind正在探索一种基于思维链监控的安全范式
既然未来的AGI将拥有类似人类的系统2慢思考能力
那么我们就有机会打开这个黑盒
直接观察它的思考过程
我们可以看到它在做决定之前
究竟权衡了哪些因素？
它是否考虑了道德规范？
它是否有恶意的欺骗意图？
这就像我们在法庭上审判一个嫌疑人
不仅要看他做了什么
还要看他的动机是什么
如果是无心之失，我们可以修正算法
如果是蓄意作恶
那就必须在源头上切断
这种让AI的思考过程变得可解释的方法
是实现超人类AI安全的关键一步
说到这里，很多朋友可能会问
如果AI真的能像人类一样思考
甚至比人类思考得更深远
那它会不会产生意识呢？
它会感觉到痛苦或快乐吗？
这是一个极其迷人
但是也极其棘手的话题
莱格坦言
即便是站在世界最顶尖的AI研究群体中
对于这个问题的看法也是极度分裂的
有人认为
意识只是复杂计算的副产品
当信息处理达到一定的密度
意识就会自然涌现
也有人认为，意识是生物体独有的
基于碳基生命的特殊性
目前的科学手段，根本无法定义
更无法测量机器的意识
我们可以轻易地让一个大模型
在对话中声称自己有意识
甚至能富有感情地描述它的内心感受
但是这可能只是因为它在训练数据中
读到了太多人类关于意识的描述
它在模仿这种语言模式
但是
无论AI是否真的具有哲学意义上的意识
只要它在行为上表现得像一个有意识的个体
能够理解语境、能够表达情感、能够进行复杂的社会交互
那么对于人类社会来说
冲击就已经开始了
我们是否应该赋予它们某种权利？
当我们在游戏中杀死一个
表现出恐惧的NPC时
这是否符合道德呢？
这些曾经只存在于哲学课堂上的假设
很快就会变成我们需要面对的现实法律问题
最后
我们再谈谈AGI对于每个人的现实影响
莱格将AGI比作思维的工业革命
正如第一次工业革命用蒸汽机和电力替代了人类的肌肉力量
让人类从繁重的体力劳动中解放出来
AGI的革命将替代的是人类的脑力劳动
这听起来很可怕
尤其是对于那些从事白领工作的人来说
程序员、律师、分析师、翻译官
这些曾经被视为金饭碗的职业
似乎都站在了被颠覆的风口浪尖
莱格承认
这将带来巨大的经济结构转型
但是，莱格的视角中也有另一面
那是一个关于丰饶（Abundance）的愿景
想象一下
如果世界上最顶尖的医生的智慧
可以被复制成千上万份
服务于每一个偏远山区的病人
如果最优秀的科研大脑
可以24小时不间断地攻克癌症、核聚变和气候变暖的难题
如果每一个孩子
都能拥有一个苏格拉底级别的AI导师
根据他的兴趣和特长进行因材施教
AI的核心价值
在于它能极大地降低智能的边际成本
当智能像电力一样廉价
而且随处可取时
人类的创造力将被彻底释放
我们不再需要把生命
浪费在重复性的脑力劳动上
我们可以去探索星辰大海
去创作艺术，去体验生活
去思考那些只有人类才能思考的终极问题
当然，从现在到那个乌托邦之间
必然会经历一段痛苦的转型期
这也是为什么莱格强调
AGI不仅仅是一个技术问题
更是一个社会问题、经济问题和政治问题
我们需要的
不仅仅是更好的算法和更快的芯片
我们需要全社会的参与
教育体系需要改革
不再仅仅灌输知识
而是培养批判性思维和与AI协作的能力
法律体系需要更新
明确AI生成内容的归属权和责任界定
社会分配机制需要调整
确保AI带来的巨大财富红利
不会只集中在少数科技巨头手中
而是能惠及每一个人
正如莱格在访谈最后所暗示的
我们正处在一个历史的十字路口
2028年也好，2038年也罢
时间的早晚其实已经不再是重点
重点是，变革的巨轮已经启动
而且正在加速
对于我们每一个普通人来说
与其在恐慌中等待被替代
不如主动拥抱这个变化
去了解它去使用它
去思考
如何让这个强大的工具为我所用
因为在未来的世界里
能够生存下来的可能不是最聪明的人
也不是最强壮的人
而是最能够适应与AI共生的人
好了
以上就是关于谢恩莱格访谈的解读
如果你对于AGI的发展有什么看法
或者你觉得2028年实现AGI的预测
是否靠谱呢
欢迎在评论区留下你的观点
感谢收看本期视频
我们下期再见
