大家好，这里是最佳拍档，我是大飞
最近这几年，借助于人类生成的数据
AI实现了惊人的突破，可是
仅仅依靠现有的数据和方法
还能支撑AI的持续进步吗？
AI的下一个阶段又该往哪个方向发展呢？
前几天
谷歌强化学习的副总裁大卫·西尔弗（David Silver）与图灵奖得主、强化学习之父理查德·萨顿（Richard Sutton）
共同撰写了一篇最新论文《欢迎来到经验时代（Welcome to the Era of Experience）》，
也许会像《苦涩的教训（The Bitter Lesson）》一样
为我们指明未来的发展方向
西尔弗和萨顿在论文中指出
人类数据正在见顶
经验才是下一个超级数据源
真正能够推动AI跃升的数据
必须是可以随着模型变强而自动增长的
而唯一的办法只有经验本身
萨顿的主张非常清晰
那就是未来的AI不会是提示词+知识库
而是行动+反馈的循环体
正如论文中所说
经验时代将是AI范式的一个大转折
我们正在从人类数据时代跨入经验时代
这不是模型的升级
也不是强化学习算法的迭代
而是一种更根本的范式转变
AI将从模仿人类到超越人类
从静态数据到动态经验
从监督学习到主动试错
这篇论文仿佛是对整个AI的宣言
经验才是通往真正智能的钥匙
今天大飞就来给大家翻译一下
这篇很可能成为又一里程碑式经典的论文
我们先来回顾一下AI的发展历程
特别是人类数据在其中扮演的角色
近年来
AI通过对海量的人类生成数据进行训练
并且借助专家的人工标注和偏好进行微调
取得了显著的进步
大语言模型就是这种方法的典型代表
已经达到了广泛的通用性
也让我们看到了AI巨大的潜力
但是我们也要清醒地认识到
这种主要依赖人类数据的发展模式
逐渐也暴露出了一些问题
虽然模仿人类能够让AI在一定程度上复现人类的能力
但要想在许多重要领域实现超人类的智能
仅仅依靠这一点是远远不够的
在数学、编程和科学这些关键领域
从人类数据中提取的知识已经快要达到极限了
就好比我们开采矿产资源
优质的矿脉越来越少
开采难度也越来越大
高质量数据来源
要么已经被大量使用
要么很快就会被消耗殆尽
而且
仅靠人类数据的监督学习来推动AI进步的速度
也明显慢了下来
更重要的是，有很多有价值的新见解
比如新的定理、技术或者科学突破
都超出了当前人类的理解范围
现有的人类数据根本无法捕捉到这些信息
这就意味着
如果我们想要让AI取得更大的突破
必须寻找新的数据来源和发展模式
那么新的数据到底应该从哪里来呢？
萨顿认为
这个数据正是Agent与环境互动所产生的数据
只有这样
才能让Agent不断地从自身的经验中学习
来持续的改进数据
在下一个时代
经验将成为AI发展的主要数据来源
并且完全取代如今以人类为主的数据
这种转变可能已经开始了
比如在数学领域中
AlphaProof 在接触了大约十万个由人类数学家多年创建的形式化证明后
它的强化学习算法随后通过与形式化证明系统的持续互动
生成了数亿个新的证明
这种对互动经验的关注
使得AlphaProof能够探索超越形式化证明的数学可能性
从而发现更加新颖的解决方案
萨顿认为
一旦充分发挥经验学习的潜力
不可思议的新能力将会涌现
经验时代的特征
是Agent和环境不仅能从海量的经验数据中学习
还将在以下几个方面突破以人类为中心的AI系统的局限性
分别是
1、Agent将栖息于经验流之中
而不是短暂的互动片段
2、它们的行动和观察将深深扎根于环境之中
而不是仅仅通过人类对话进行互动的
3、它们的奖励将来自于对环境的体验
而不是来自人类先入为主的判断
4、它们将根据经验计划和推理
而不是仅仅用人类的术语进行推理
接下来
论文详细解释了一下经验时代的这几个关键特征
我们先来说说经验流
它指的是一个经验型的Agent
可以在它的一生中持续学习
在人类数据时代
基于语言的AI主要关注的是短期互动片段
比如说，我们向ChatGPT提出一个问题
它回答之后
这次互动就基本上结束了
很少有信息会传递到下一次互动中
Agent也无法根据长期的经验来调整自己的行为
但是人类和其他动物不一样
我们的生活其实是一个持续很多年的行动和观察流
就像我们学习一门外语一样
都是今天学一点
明天学一点，随着时间的推移
我们会不断积累经验
根据之前的学习情况调整学习方法
从而提高学习效果
而强大的Agent也应该拥有类似人类的经验流
这样它们就能在较长时间尺度上
推进自己的学习和行动
从而实现未来的目标
并且适应新的行为模式
比方说
一个连接到用户可穿戴设备的健康和保健Agent
它可以持续监测用户数月的睡眠模式、活动水平和饮食习惯
通过对这些数据的分析
它能够提供个性化的建议
比如根据用户的睡眠质量
建议调整作息时间
又或者根据活动水平来推荐合适的运动计划
而且
它还能根据长期趋势和用户的具体健康目标
不断调整自己的指导
同样，一个个性化的教育Agent
可以跟踪用户学习新语言的进展
发现用户在哪些知识点上存在不足
然后根据用户的学习风格来调整教学方法
在几个月甚至几年的时间里
持续地帮助用户提高语言能力
还有科学Agent
它可以追求一些宏大的目标
比如发现一种新的材料或者减少二氧化碳排放
它能够在较长的时间范围内分析真实世界的观察结果
进行模拟实验
提出并且实施在真实世界的实验或者干预措施
这些Agent在实现目标的过程中
可能单个步骤不会立刻带来明显的好处
甚至在短期内还可能产生一些负面影响
但是从长远来看
这些步骤有助于实现更长期的成功
这和当前那些只是追求即时响应的AI系统
有着很大的区别
其次是行动和观察方面的变化
在人类数据时代
大语言模型主要关注的是人类特殊的行动和观察
它和用户之间的互动
主要通过文本输出和输入来完成的
但是在自然界的智能中
动物是通过运动控制和传感器
与环境进行互动的
比如小狗通过奔跑、闻嗅来探索周围的世界
而不是仅仅通过对话
虽然大语言模型也可以在数字世界中调用行动能力
比如API
但是最初这些能力大多数都是来自于人类使用工具的例子
而不是Agent自身的经验
不过现在情况正在发生变化
有很多Agent开始自己运行代码并且观察结果
它们就像是拥有了自己的“双手”，
可以更加自主地探索数字世界
这些变化预示着Agent将从完全依赖人类的交流
转向更加自主的互动
在经验时代
Agent将能够积极的探索世界
根据环境的变化来调整自己的行为
从而发现一些人类可能从来没有想到过的策略
而且
Agent不仅可以使用“人类友好的”行动和观察方式
还可以采取“机器友好的”行动方式
更好地实现自己的目标
此外，Agent还能够通过数字接口
与真实的世界进行互动
比如监测环境传感器的数据
远程操作望远镜观察天体
或者控制实验室中的机械臂进行自主实验
奖励机制在经验时代也会发生很大的变革
大语言模型通常是根据人类先入为主的判断
来优化奖励的
比如说，专家们会观察Agent的行动
判断这个行动好不好
或者在多个备选方案中选择最佳的行动
但是这种奖励方式存在一些问题
因为它是人类在不考虑行动对环境实际影响的情况下决定的
没有真正地扎根于现实世界
这就好比一个人在评判一幅画的时候
只看颜色好不好看
却不考虑这幅画所表达的内涵和对观看者的影响
这样一来
Agent就很难发现那些人类评估者没有注意到的、更好的策略
从而导致性能达到瓶颈
在经验时代
为了发现更多超越人类现有知识的新想法
Agent的奖励应该来自环境本身
比如
一个健康助手可以根据用户休息时的心率、睡眠时长和活动水平等信号
来设置奖励
以此来给出更合适的健康建议
教育助手可以用学生的考试成绩作为奖励信号
优化自己的教学策略
奖励还可以来自作为Agent环境中一部分的人类
比如
人类用户可以反馈自己吃了某个蛋糕后的感受
运动后的疲劳程度
或者头痛时的疼痛程度
这些反馈可以帮助助手Agent提供更好的食谱、改进健身建议、调整推荐的药物
这种奖励因为衡量了Agent在环境中的实际行动后果
所以往往比人类专家预先判断的效果更好
那么，奖励信号应该从哪里获取呢？
其实
当Agent通过丰富的行动和观察空间与世界连接后
就会有无数的基础信号可以作为奖励
我们的世界充满了各种各样的量化指标
比如成本、错误率、生产力、健康指标、气候指标等等
还有很多信号来自于特定事件的发生
或者从原始观察和行动序列中提取的特征
有人可能会问
只优化一个基础的信号作为奖励
就能够满足通用AI的要求吗？
毕竟通用AI需要能够可靠地朝着任意用户期望的行为发展
虽然追求单一奖励信号表面上看起来不符合要求
但是我们可以根据用户的引导
灵活地调整基于基础信号的奖励
比如，我们可以用一个神经网络
将Agent与用户和环境的互动作为输入
来输出一个标量奖励
这样
奖励就能根据用户的目标进行选择
或者组合来自环境的信号
当用户说想要“改善我的健康状况”，
奖励函数就会返回一个与用户心率、睡眠时长和步数相关的函数；
如果用户的目标是“帮助我学习西班牙语”，
奖励函数则可以返回用户的西班牙语考试成绩
而且
用户在学习过程中还可以提供反馈
比如满意度，来微调奖励函数
让奖励函数可以随着时间不断的优化
这就像是一个双层优化过程
把用户反馈作为顶层目标进行优化
把来自环境的基础信号在底层进行优化
通过这种方式
只需要少量的人类数据
就能够产生大量的自主学习
在计划和推理方面
经验时代也带来了新的变化
最近
大语言模型进行推理或“思考”方面
取得了一些进展，比如通过思维链
让模型在输出响应之前进行一定的推理
从概念上讲
大语言模型就像一个通用计算机
它可以通过将token添加到自己的上下文中
来执行各种算法
但是在人类数据时代
这些推理方法大多是模仿人类的思维过程
比如
让大语言模型发出像人类一样的思维链
模仿人类思维的痕迹
或者加强与人类相匹配的思维步骤
而且
推理过程还会根据人类专家给出的正确答案进行微调
但是大家想一想
人类语言真的是通用计算机的最佳实例吗？
其实不然
肯定存在着更加有效的思维机制
只是这些机制可能使用的不是人类语言
比如符号、分布式、连续或者可微分的计算
原则上
自主学习系统可以通过从经验中学习
发现或改进这些方法
就像AlphaProof在学习证明复杂定理时
采用的方式与人类数学家是截然不同的
另外
通用计算机只是为了解决了Agent的内部计算问题
没有将它与外部世界的现实联系起来
如果一个Agent只是被训练用来模仿人类思想
甚至只是匹配人类专家的答案
它可能就会继承数据中存在的错误思维方法
就像如果一个Agent接受了5000年前人类思想和专家答案的训练
那么它在推理物理问题的时候
可能会采用万物有灵论的方式；
如果是1000年前
可能会采用有神论的方式；
如果是300年前
可能是牛顿力学的方式；
50年前，则可能是量子力学的方式
要想超越这些思维方法
Agent必须与现实世界进行互动
做出假设、进行实验、观察结果
然后根据结果来更新自己的原则
这就像科学家在探索真理的过程中
不断通过实验来验证自己的理论一样
Agent也必须扎根于真实世界的数据
才能够推翻那些错误的思维方法
形成自己的、不受当前主流人类思维模式限制的新原则
否则，无论Agent多么复杂
都只是在重复现有的人类知识
无法取得真正的突破
怎样才能让Agent的思维扎根于外部世界呢？
一种可行的方法是构建一个世界模型
这个模型可以预测Agent的行动对世界的影响
包括预测奖励
比如
一个健康助手在为用户推荐当地健身房或者健康播客的时候
它的世界模型可以预测用户采取这个行动后
心率、睡眠模式可能会发生怎样的变化
以及可能会与用户进行怎样的未来对话
这样，Agent就能根据自己的行动
以及它对世界的因果效应来进行计划
随着Agent在经验流中不断与世界互动
这个动态模型会不断更新
纠正预测中的错误
有了世界模型
Agent还可以用一些可扩展的计划方法
来提高自己的预测性能
而且
计划和推理这两个方法并不是相互排斥的
Agent可以在计划过程中
使用内部的大语言模型来选择行动
或者模拟、评估这些行动的后果
可能有人会问
从经验中学习并不是什么新鲜事
为什么现在才说进入了经验时代呢？
这就不得不回顾一下AI的发展历程了
在此之前
强化学习系统已经在模拟环境中取得了很大的成功
在很多复杂任务上达到甚至超过了人类水平
比如在围棋、国际象棋、扑克
甚至在星际争霸II等电子游戏和机器人导航等方面
强化学习都展现出了强大的能力
但是
从模拟环境到现实世界的跨越一直是个难题
如同一道难以逾越的鸿沟
因为现实世界太复杂了
有无数的变量和不确定性
这使得Agent很难在现实中发挥出在模拟环境中的水平
在人类数据的时代
基于人类数据训练的大语言模型
虽然实现了广泛的能力
能够完成各种各样的任务
但是过于依赖人类的知识和数据
从而减弱了Agent自我发现知识的能力
就像是被圈养在人类知识围栏里的动物
很难突破这个界限去探索新的领域
而经验时代的到来
正是为了调和这两者的优势
当前
自主Agent和强化学习方法的不断发展
也表明向经验时代的过渡即将来临
随着以人为中心的大语言模型兴起
人们的焦点从如何自主学习转移到了如何利用人类知识上
像 RLHF之类的技术，虽然功能强大
但是往往绕过了强化学习的核心概念
比如用人类专家来代替机器计算
从而绕过对价值函数的需求
用来自人类数据的强先验知识
来减少对探索的依赖
以及用以人为中心的推理
来减少对世界模型和时间抽象的需求
经验时代的到来
正好为我们重新审视和改进这些概念
提供了机会
通过对这些经典概念和算法的深入研究和优化
我们可以更好地释放自主学习的潜力
让Agent在经验流中更加高效地学习和成长
西尔弗和萨顿在论文中也指出
经验时代的到来
无疑会带来巨大的影响
既有令人期待的潜力
也伴随着诸多挑战
从潜力方面来看
它有望带来更加个性化的助手
比如在个人生活、健康、教育、科学研究、药物研发等领域
但是，经验时代也带来了一系列挑战
首当其冲的就是工作岗位流失的问题
随着Agent在各个领域的能力不断提升
一些重复性、规律性强的工作可能会被Agent取代
这将对就业市场产生巨大冲击
其次，安全风险也会增加
如果Agent的行为不受控制
或者可能被恶意利用
就会给个人、社会甚至国家带来严重的安全威胁
另外
经验时代的Agent往往是通过复杂的算法和大量的经验数据进行学习和决策的
这个决策的过程和结果的可解释性可能会变得更低
这使得我们很难理解Agent为什么会做出这样的决策
一旦出现问题
也难以进行追溯和纠正
不过，经验学习也并非只有风险
它同样具有一些安全方面的优点
因为Agent在经验流中可以不断适应环境的变化
所以能够及时调整自己的行为策略
而且
奖励函数可以根据用户的需求和环境的变化灵活的调整
避免Agent出现一些不符合预期的行为
此外
Agent在现实世界中的行动由于受到时间的制约
不会像在模拟环境中那样进行无限次的尝试
这在一定程度上也限制了潜在的风险
总的来说
经验时代将是AI发展的下一个关键时期
在这个时代
Agent将不再局限于从人类衍生的数据中学习
而是能够从自身与世界的互动中获取经验
不断地学习和成长
从而超越人类数据的局限
释放出全新的能力
好了
以上就是这篇论文的主要内容了
不知道大家是否认同
经验时代将会是AI的下一个发展方向
欢迎在评论区留言
感谢观看本期视频，我们下期再见
