大家好，这里是最佳拍档，我是大飞
今年2月29日
马斯克突然在旧金山法院对OpenAI及公司CEO奥特曼和总裁布罗克曼提起诉讼
斥责奥特曼违背“初心”，
要求OpenAI恢复开源并给予赔偿
事件在接下来的一个月里持续发酵
当地时间3月6日
马斯克在社交平台X上发文
“将OpenAI改名为ClosedAI
我就取消诉讼
”并附上了一张修图后的照片
画面中奥特曼手握的工牌上显示“ClosedAI”图标
也许这场冲突的背后有着复杂的商业考量
但是马斯克的指责也不是空穴来风
2023年3月
OpenAI发布了AI语言模型GPT-4
并且分享了GPT-4的大量测试结果
以及一些有趣的演示
但是基本上没有提供有关用于训练系统的数据、用于创建该系统的特定硬件或方法的信息
人工智能界的许多人都批评了这一做法
指出这一行为严重违背了公司创立之初定下的开源精神
OpenAI开发者关系负责人洛根（Logan Kilpatrick）
一个坚定的开源主义者
也于3月1日在社交平台上宣布辞职
另一方面，OpenAI在选择闭源之后
依然展现出了强劲的研发能力
从年初的Sora到GPT-4o
似乎开源与否根本无关紧要
AI到底要不要开源？
知名博客主持人安洁妮
米德 Anjney Midha 邀请了Mistral CEO 亚瑟
曼彻 Arthur Mensch
就开源与闭源开发的优缺点和未来将要面对的技术挑战进行了讨论
今天大飞就来给大家分享一下其中的观点
与OpenAI的Sora不同
亚瑟和他的Mistral公司推出的Mixtral是完全开源的项目
亚瑟相信
开源社区对于AI的技术进步有着不可取代的作用
首先
亚瑟强调了开源社区合作和信息自由流动
对于技术发展的重要性
他以chinchilla 论文为例子
展示了社区合作在技术迭代方面的作用
在 2019 年到2020 年
人们非常依赖所谓的大型语言模型缩放定律相关论文
这些论文主张无限地扩展模型规模
同时保持数据量相对固定
换句话说
如果开发者拥有四倍的计算能力
他就应该把模型的规模扩大3.5倍
但是训练数据的规模只需扩大 1.2 倍
根据亚瑟所说
当时的每篇论文都犯了一个错误
但是随着AI社区的发展和开发者彼此之间的交流
论文的问题才被逐渐暴露出来
到了 2021 年底
亚瑟和他的朋友们发现
模型的数据规模才是提升大模型性能的关键
只有将模型规模和数据规模同时增加两倍
才符合他们的理论预期
他们的研究成果，chinchilla 论文
在被发表后迅速颠覆了过去学界中
模型规模至上的观念
促使研究者们开始重视起数据的规模
而作为作者之一的亚瑟本人
则将chinchilla论文的成功
归结为AI社区合作与技术信息交流的结晶
如果没有整个社区一同反复审视并且检测缩放定律的论文
那么大语言模型的开发
还会在盲目扩大模型规模的路上走很多年
有了坚实的社区基础与足够透明的信息交流
亚瑟相信
开源模型的开发方式能够促进更快的创新和改进
并且通过社区的广泛使用和测试
可以有效提高模型的安全性和鲁棒性
这也是为什么Mistral 坚持开源的原因
在2023年的12月
Mistral 推出了被称为Mixtral 8x7B的稀疏专家混合模型
亚瑟强调，正是通过开源社区
他的团队才得以克服新技术开发过程中的种种困难
亚瑟自豪地表示
相比同样使用12亿个参数的稠密模型
Mixtral 8x7B在成本和性能上都具有绝对优势
但是他的团队在开发过程中也遇到着不少技术上的困扰
第一个挑战是如何从数学角度正确的训练模型
另一个挑战是如何在训练模型的过程中高效的利用硬件
此外
新技术在架构上也遇到了意想不到的问题
MoE技术在稠密transformer的基础上
将稠密层再复制了一次
创造了一个“专家层”。
随后
再为序列中的每个 token 设计一个路由机制
决定哪个专家应该处理哪个 token
在训练的过程中
模型会将所有 token 发送给对应的专家
然后由专家处理并获取输出
最后再将它们组合
通过调整专家层的数据处理
来减轻模型的负担
最终，在46亿的庞大数据中
每个 token 其实只执行了 12 亿个参数
换而言之
最终得到的模型相当于一个 12 亿参数的网络
其性能远远高于通过大量压缩数据得到的 12 亿稠密transformer模型
大幅提升了模型的推理效率，但是
因为token 会在不同的专家层之间传递
一些意料之外的通信约束也会出现
除此之外
在部署模型进行高效推理的时候
也会有新的约束
正是通过开源社区中用户的使用、修改和测试
开发团队才得以快速地迭代这个模型
并且最终解决了其中的大部分问题
所以亚瑟将它作为开源社区对技术发展有所贡献的另一个例证
除了技术方面的好处以外
亚瑟也将开源社区视为一种理想上的追求
他认为，预训练模型应该是中立的
中立
意味着任何人都能够自由地使用这些模型
并且添加他们的微调方法
人们理应能够自由地选择
如何把预训练模型变成他们想要的模样
亚瑟和他的团队不希望将自己的偏见灌输到预训练模型中
比起将模型当作商品的商人
亚瑟更希望做一个学者
他很怀念深度学习的早期阶段
当时整个行业都是由不同实验室的研究人员之间
大量的开放合作支撑起来的
他们通常会发布所有的研究成果
并在会议上分享
Transformer 模型的论文就是一个著名的、公开给整个社区去研究的例子
亚瑟回忆起自己在AI行业的从业经历
从2012年他们用AI模拟猫狗
到 2022 年生成看起来像人类写的文本
亚瑟指出
这些研究进展都离不开信息的自由流动
学术实验室和大型行业支持的实验室
一直在交流结果并且在彼此的基础上构建
他认为
这种方式显著提高了架构和训练技术
尽管开发者们身处世界各地
但是作为一个线上社区
大家都在积极地为科技进步贡献着自己的力量
整个行业都显得活力四射
直到GPT-3 的发布改变了这一切
亚瑟回忆道，自从那之后
许多公司意识到了技术垄断有着多么巨大的利润空间
从而开始加强自身的技术保密
在 2022 年
各个AI社区在大公司的垄断下
几乎没有任何交流
亚瑟表示
技术垄断的出现对于他、他的朋友以及将来所有想要加入AI行业的人才而言
都是一件非常遗憾的事情
“故事还没有结束，我们需要集思广益
发明更多的新东西
”亚瑟如此说道
虽然如今的大模型技术相比过去已经有了长足的进步
但是还没有完全达到他们当年的预期
所以亚瑟和他Mistral AI依然坚持开源
他仍然认为应该允许社区使用这些模型并根据需要进行修改
与此同时
亚瑟还希望能够与社区中的开发者进行深入的交流
他表示
允许开发者深度访问优质的模型
是与社区互动的最好方法
而且公司和开发者在这一过程中都可以实现双赢
开发者既学到了最前沿的模型架构
公司建立的平台也得到社区的推广
无论如何
在行业领头羊OpenAI采取闭源开发策略的那一刻
整个产业都不可能再回到过去自由交流的状态了
采取开源策略的公司必须同采取闭源策略的公司相竞争
但是亚瑟并不惧怕竞争
他从不认为闭源会帮助企业在市场竞争中获得优势
他表示
尽管Mistral的性能还只能达到 GPT-3.5的级别
但是他的团队正在开发更强的模型
这个模型的性能将介于 GPT-3.5和GPT-4 之间
基本上是世界第二或第三强的模型
他们和OpenAI的差距正在不断缩小
这多亏了开源社区持续帮助开发团队修改模型
亚瑟举了几个例子
有一些公司知道如何根据自己的需求
开发强大的微调模型
所以他们对 Mistral 7B进行了大量的人工标注
让模型在成本更低
控制精度更高的前提下
能像 GPT-3.5 一样解决他们的任务
还有一些开发者设计出了全新的功能
比如对上下文长度的扩展
这些扩展功能运行得非常好
社区内的各路江湖高手甚至可以直接修改编码器
把Mistral 7B硬生生改造成了一个视觉语言模型
亚瑟还提到
有时其他公司的人也会使用他们的开源模型
Hugging Face 的人就在 Mistral 7B 上进行了对话偏好优化
并且制作了一个比Mistral 最初发布的指令模型更强的模型
总的来说
Mistral 在社区中集思广益
并将社区的需求和建议整合到模型中
得益于公司的开源策略
他们与OpenAI的差距已经缩短到了六个月
安全性则是开源闭源之争中另一个重要的话题
当初OpenAI就以安全性为理由拒绝公开GPT4的数据
很多人的第一反应也都认为开源比封闭模型更不安全
但是亚瑟对此有着不同的观点
他认为
至少对于当前这一代的模型来说
开源与否对模型安全性的影响并不大
亚瑟指出
我们今天使用的模型只不过是对互联网上可用信息的压缩
它的本质是新时代的印刷机
就“让知识的获取更加自由和顺畅”的特点而言
发明大模型与发明印刷机没有什么不同
既然印刷技术没有让世界变得不安全
那么当下的大语言模型也没有理由让世界变得不安全
其次，大语言模型被滥用的风险
在开源模型和封闭模型中都存在
毕竟滥用模型不意味着滥用者需要知道模型的一切信息
就像杀人犯不需要知道枪是如何被制作出来的一样
如今互联网上泛滥的AI假消息就是一个例子
GPT和Sora并没有因为OpenAI的闭源策略而不被滥用
所以闭源并不能从根源上解决滥用的问题
亚瑟认为，比起闭源
将AI产品置于最高级别的审查之下
才是更好地了解它们如何被滥用的一种方式
但是不应该混淆需要被监管的对象
他表示
我们在所谓的模型和应用之间存在很大的混淆
而模型实际上是 AI 应用程序的编程语言
如果你与那些用通用模型做出惊人产品的初创公司交谈
他们只是将大语言模型当做一个函数
亚瑟认为
监管需要针对的是模型衍生出的各种AI产品
比如说
有人拿Java写了一个电脑病毒
那么需要处理的肯定是病毒和编程者
而不是Java语言本身
亚瑟指出
大型语言模型永远不会被单独使用
人们总是以某种方式在应用程序中使用它
因此
需要被监管的是使用模型的应用程序
而不是模型这个纯粹的数学工具
此外
亚瑟也坚信人多力量大的朴素道理
他用GPT4举了一个例子
在用户同时拥有API和微调权限的情况下
GPT-4 可以生产出足以突破伦理道德底线的内容
如果是在闭源公司中
人们只能选择信任大型公司的团队来解决这些问题
如果是一个开源公司
社区凭借自身的规模和号召力
就可以在短时间内拉起一支
比专业公司团队规模大得多的队伍来解决问题
各路民间高手的表现也不一定就比专业人士差
甚至屏幕后面坐着的开发者
也许就是另一家公司的技术大拿或者大学里的教授
事实上
如果回顾整个软件、网络安全和操作系统的发展历史
我们就可以发现
相当多的安全漏洞和病毒都是由民间团体来发现和解决的
所以亚瑟相信
如果我们想让当前的 AI 系统更加安全
然后把开发AI的氛围传递给整个社会乃至于下一代
那么开源就是开发 AI 最安全的方式
它不仅能够帮助当代人解决安全问题
还可以帮助培养下一代的AI安全技术人才
好了，以上就是亚瑟
曼彻在本次访谈中的主要内容
大家是如何看待AI开源和闭源的争论呢？
你更希望将来的技术公司能够倾向于哪一方呢？
欢迎在评论区留言
感谢大家的观看，我们下期再见
