大家好，这里是最佳拍档
最近科技圈有一个产品引发了不小的轰动
谷歌的Project Genie正式向美国的Google Ultra用户开放了
一时间在社交媒体上掀起了一股特别的复古游戏风
很多网友用它生成了不少画质略显粗糙
但是能够实时跑跳、自由交互的3D环境
有人调侃说
这像是任天堂世界的拙劣仿制品
但是在我看来
这款产品背后的技术逻辑和未来潜力
远比表面的画质争议
更值得我们深入探讨
可能有些观众还不太清楚Project Genie到底是什么
简单来说
它是由谷歌DeepMind、Google Labs以及Creative Lab联合打造的一款交互式世界模型Web应用
早在去年八月
谷歌官方就发布了由Genie 3驱动的演示视频
而这一次的正式开放
意味着普通用户终于有机会
来亲身体验这种创造并且进入虚拟世界的全新交互方式了
为了搞懂这款产品的核心技术、发展逻辑以及未来的方向
谷歌DeepMind的洛根·基尔帕特里克
对Project Genie团队核心成员迭戈·里瓦斯
什洛米·弗鲁赫特
和杰克·帕克-霍尔德
进行了一场专访
今天我们就来给大家分享一下
看看谷歌的世界模型是怎么样攻克未来不可知这个核心难题的
又将给AI领域带来了哪些颠覆性的影响
首先，到底什么是世界模型呢？
它和我们之前熟悉的传统视频生成模型
有什么本质区别呢？
这也是很多人最开始接触这个领域时会产生的疑问
什洛米·弗鲁赫特给出了一个非常通俗易懂的解释
传统的视频模型
本质上是根据文本指令生成几秒钟的固定视频
你只能被动观看
无法改变视频的走向
而世界模型则完全不同
你只需要向它描述一个环境
它就会逐帧生成这个世界
并且最关键的是它具备交互式属性
在任何时间点
你都可以决定向左或者向右移动
或者在这个世界里进行特定的操作
比如触碰物体、改变场景元素等等
简单说
世界模型就是视频生成模型的交互升级版
因为它模拟了现实世界的物理运行逻辑
所以才被赋予了世界模型这个名字
从强化学习的角度来看
世界模型的意义也非常深远
杰克·帕克-霍尔德提到
世界模型在强化学习领域有着深厚的渊源
最初它的设计目的
是让AI Agent学习如何在现实中执行任务
但是随着生成式AI技术的飞速发展
团队发现
创造新世界的能力本身就极具吸引力而且充满乐趣
这也成为了Project Genie目前的核心研究重点
想象一下，你可以仅凭文字描述
就构建一个专属的3D世界
并且亲身进入其中进行自由的探索
这种体验确实是以往任何AI应用都无法提供的
了解了世界模型的基本概念
我们再聚焦到Project Genie这款产品本身
它的定位其实很清晰
迭戈·里瓦斯将它类比为Veo对应的Flow
或者Imagen对应的ImageFX
本质上是一个让用户构建专属世界的Web应用
目前它已经正式向美国所有的Google Ultra订阅用户发布
用户的使用流程也非常直观
首先输入想要的场景描述
比如，珊瑚礁和一条金鱼
然后系统会调用Nano Banana Pro模型
创建一张图像画布作为视觉基础
之后就能生成完整的3D交互世界
用户可以直接步入其中进行导航和互动
这里有一个很关键的设计细节
为什么在进入世界之前
要先创建一张图像画布呢？
根据反馈，这个步骤的价值非常大
最惊艳的瞬间
莫过于用户从2D素材直接步入3D素材内部
这种从平面到立体的转换
能够很大程度提升用户的沉浸感和体验感
而且除了文本描述以外
用户还可以上传现实中的照片作为条件引导
让静态物体在3D空间中活过来
并且补全它背后的逻辑细节
比如测试中
团队就将Nano Banana的恐龙吉祥物鲍勃的照片上传
输入照片中的房间和玩具
然后在生成的3D世界里
鲍勃就出现在了基于真实照片构建的图书馆场景中
用户还能够实时的控制这个角色
这种赋予静态图像生命的能力
确实让人印象深刻
接下来，我们深入到技术的层面
聊聊大家最关心的问题
当用户点击生成世界的按钮时
系统后台是如何在极短时间内
完成准备工作的呢？
在生成的世界里
交互细节是不是能够遵循物理逻辑呢？
比如能不能随意的替换角色、增加背景元素呢？
什洛米·弗鲁赫特透露
当用户发出指令后
AI系统会在后台为这个世界准备更详尽的描述
所以生成的速度非常快
目前Project Genie还不能完全算是一款游戏
因为它没有复杂的剧情或者叙事线
但是用户可以在其中自由导航、移动
观察其他的角色
甚至会撞到某些物体并使它发生位移
这些交互都遵循着基本的物理逻辑
比如撞到球时，球会自然滚动
这是因为模型在训练过程中
隐含学习了世界的演化逻辑
至于修改世界元素
比如把金鱼换成鲨鱼、增加沉船的背景
或者改变物体的颜色
操作起来也非常简单
迭戈·里瓦斯演示过
只需要点击Remi按钮
输入将球改为红色
或者替换为鲨鱼并添加沉船的背景
系统就能够快速生成修改后的世界
而且生成世界后
用户点击复用提示词
还能看到后台生成的具体指令
这对于想要学习提示词技巧的用户来说
是一个非常实用的功能
这里不得不提到一个核心的技术难点
那就是生成一个实时演化的世界模型
比生成一段预设好的视频
挑战要大得多
什洛米·弗鲁赫特解释说
两者虽然技术上有相关性
但是世界模型的难度会呈指数级上升
原因很简单，生成视频时
模型可以通盘考虑过去和未来的所有帧
从而保证画面的一致性，自由度更高
而世界模型必须面对未来不可知的问题
AI无法预知用户的下一个动作
所以每一帧都必须与过去的操作
以及当前的即时动作保持高度的一致
实现逻辑自洽
这就要求模型在缺乏未来信息的前提下
精准预测世界的演变
这种实时性和一致性的平衡
是世界模型技术实现的核心瓶颈
还有一个大家可能会注意到的细节
目前Project Genie将生成时长
硬性限制在六十秒
这到底是技术上无法突破
还是出于其他的考虑呢？
团队给出的答案是权衡后的选择
什洛米·弗鲁赫特和杰克·帕克-霍尔德都提到
实际上系统可以生成更长时间的内容
内部也做过相关演示
但是目前设定在六十秒
主要是基于两方面的考量
一方面是边际愉悦感的平衡
让用户在两个不同的世界各体验一分钟
它的交互价值远高于在同一个单调场景中停留过久
另一方面是算力成本的控制
六十秒的时长
既能让用户充分体验虚拟的环境
又能够保证在合理的推理成本下
为足够多的用户提供稳定服务
当然，未来这个时长也可能调整
如果是高山滑雪这类需要持续运动的场景
延长到两分钟会带来更好的体验
但是如果是探索图书馆这类静态场景
两分钟可能就显得乏味了
此外，技术上还有一个挑战
随着生成时长的增加
场景的动态表现可能会逐渐减弱
这也是团队正在优化的方向
在视觉风格上
很多人误以为Genie只能走写实的路线
但是实际上它支持多种风格的转换
什洛米·弗鲁赫特强调
当前的写实风格只是因为输入源是写实照片
用户完全可以根据个人喜好
将它改为漫画、卡通或者其他的任何风格
只需要在提示词中明确说明就可以
这种风格上的灵活性
也让世界模型的应用场景更加广泛
无论是娱乐、教育还是医疗领域
都能够根据需求调整视觉的呈现方式
聊完了产品体验和技术细节
我们再来看看Genie系列模型的技术演进
从Genie 2到Genie 3
团队实现了哪些关键突破呢？
杰克·帕克-霍尔德回忆说
一年多以前
Genie 2只能够生成十秒的内容
分辨率很低，而且不能进行实时交互
场景也缺乏照片级的真实感
而现在的Genie 3
不仅实现了一分钟的稳定生成
分辨率大幅提升
还能够保证实时交互和物理逻辑的一致性
这种进步可以说是跨越式的
但是即便如此
Genie 3依然面临着不少核心约束
杰克·帕克-霍尔德指出
目前最大的挑战有两个
一是在保证实时交互频率的同时
优化延迟的表现
二是显存占用的问题
就像大语言模型中
上下文长度的增加会导致计算成本的激增、速度变慢一样
世界模型的生成时长和复杂度的提升
也会带来显存占用的急剧增加
所以当前团队的工作重点
一方面是协同优化这些相互冲突的目标
另一方面是降低成本
让更多的人能够使用这项技术
什洛米·弗鲁赫特也提到
目前模型的运行速度已经足够快了
当生成速度能够跟上用户的操作消耗时
再追求更快的速度意义不大
而降低成本、提升普及度才是关键
从项目发展来看
Project Genie已经从去年八月的大规模研究项目
逐渐转向了具备大规模服务能力的产品
迭戈·里瓦斯透露
从发布演示视频到正式向大众开放
这中间经历了大量的模型优化和基础设施构建工作
团队不仅要提升模型的性能和稳定性
还要搭建能够支撑大规模用户访问的推理架构
控制算力的成本
而且目前Project Genie也计划提供开发者API
未来还会和Google Labs密切合作
在功能、控制手段以及应用底层架构等方面持续演进
将这项技术拓展到更多的平台
值得一提的是，Project Genie的背后
是谷歌强大的跨团队协作和垂直技术栈优势
迭戈·里瓦斯介绍
参与项目的团队非常广泛
包括制作画廊案例的Google Labs和Creative Lab
以及负责推理服务和基础设施的团队等等
在谷歌和DeepMind
团队可以在开发前沿模型的同时
利用最顶尖的硬件提供底层支持
这种软硬件协同的垂直技术栈
是实现实时交互的关键
比如当前模型对算力和显存的要求很高
但是依托谷歌的硬件资源
能够在一定程度上缓解这些约束
而未来随着效率优化
用户甚至有希望在个人设备上
运行完整的宇宙副本
接下来
团队聊到了这项技术的应用前景
这也是最让人期待的部分
他们指出
世界模型的价值远远不止于娱乐
它在教育、医疗、具身智能等多个领域都有着巨大的潜力
在教育领域
世界模型可以提供高度个性化的学习体验
比如让学生进入AI生成的古罗马战场
亲身感受历史场景
或者为害怕蜘蛛的孩子
创建一个虚拟房间
让他们在安全的环境中逐渐克服恐惧症
这种沉浸式、互动式的学习方式
远比书本和视频更有感染力
在医疗领域
最让人动容的一个应用方向
是为阿尔茨海默症患者重构童年记忆
通过患者提供的老照片或者描述
世界模型可以生成对应的虚拟场景
让患者重新体验童年往事
这种记忆疗愈的价值
是传统医疗手段难以替代的
而在具身智能领域
世界模型将成为AI Agent训练的模拟器
为机器人技术发展开辟新的路径
杰克·帕克-霍尔德强调
未来的机器人控制
绝不可能只依赖于键盘的方向键
我们需要更复杂的控制手段
而世界模型可以为机器人智能体提供无限多样的虚拟训练环境
让它们在模拟中学习如何应对各种复杂的场景
这一点
从SIMA项目和Genie 3的联动中就能够看出端倪
提到SIMA，可能有些观众不太熟悉
杰克·帕克-霍尔德给出了介绍
SIMA是目前最强大的游戏AI Agent之一
由Gemini驱动
能够在3D世界中根据文本指令进行交互、实现各种目标
以往SIMA只能够在少数几款固定的游戏中接受训练
但是现在借助Genie 3
用户只需要通过文字输入
就能够创建一个全新的3D世界
然后将SIMA智能体置于其中
观察它的行为、测试它的能力
这种按需求创建训练环境的模式
不仅大幅拓展了AI Agent的训练场景
也为通往AGI开辟了新的路径
除了这些具体的应用以外
世界模型还可能重塑整个媒体和娱乐行业的互动方式
迭戈·里瓦斯认为
这是一个非常有趣的处女地
过去人们只能够被动消费媒体的内容
而现在有了世界模型
每个人都能够将被动消费
转变为互动体验
这种真正的、定制化的交互叙事
将彻底改变媒体和娱乐行业的形态
比如你可以根据自己的喜好
修改电影剧情
或者进入小说中的世界和角色进行互动
这种体验是以往任何媒体形式都无法提供的
当然，这项技术目前还处于发展初期
还有很多需要完善的地方
什洛米·弗鲁赫特坦言
模型目前还不完美
比如在处理大量并行的动态事件时
有时侯会出现动力随时间减弱的情况
这也是发布研究预览版的原因
希望通过用户的使用发现优缺点
持续优化
但是正是这种不完美
也为用户提供了亲历前沿技术的机会
杰克·帕克·霍尔德就提到
当前模型在提示词工程上还不够稳健
但是这反而是一个优势
现在就开始体验的用户
几年后当这项技术成熟时
就能够自豪的说
自己经历过提示词至关重要的时代
而且这种全新的模型
可能会以意想不到的方式捕捉到用户的意图
做出非常有趣的东西
比如尝试骑龙飞行、用球写出名字等创意
都能够给人带来惊喜
关于未来的发展方向
团队也透露了不少关键信息
首先是多人的交互功能
这已经在团队的路线图中了
但是挑战在于多人同时和同一个模型交互时的延迟问题
需要完善很多技术细节
其次是拓展输入的形式
未来定义一个世界可能不再局限于文本和图像
用户只需要提供一段视频或者喜欢的素材
就能够直接步入那个场景
和里面的人进行交谈，完全沉浸其中
最后是硬件适配，团队希望
未来用户能够在个人设备上直接运行这些AI模型
虽然目前高性能TPU和GPU的获取仍有缺口
但是随着效率优化
这个目标有希望实现
在技术的演进规律上，很多人会关心
世界模型是不是遵循Scaling Law呢？
它的技术进步曲线和图像或者视频生成
有什么不同呢？
什洛米·弗鲁赫特和杰克·帕克-霍尔德的观点是
图像生成是目前最成熟的
视频生成次之，而交互式世界模型
则代表了一个更前沿的领域
虽然最新一代视频模型的画质
高于目前的Genie 3
但是实时交互性是世界模型的核心约束
整体技术演进依然处于非常陡峭的上升阶段
和传统的生成式技术不同
世界模型创造的是一种交互体验
开启了许多以往从来没有考虑过的新路径
它不仅仅是用自动化替代现有的生成流程
更是实现了以前根本无法完成的任务
最后，从长远角度来看
谷歌的世界模型
本质上是在构建一个可以交互、演化的虚拟宇宙
它的价值不仅在于提供了一种全新的娱乐方式
更是在于为AI的发展提供了一个全新的载体
在教育领域
它让个性化学习成为可能
在医疗领域
它为疗愈疾病提供了新的思路
在具身智能领域
它为AI Agent的训练提供了无限可能
而在媒体领域
它将重塑人与内容的互动关系
当然
目前它还受限于硬件的物理极限和技术的成熟度
但是正如团队所说
谷歌的垂直技术栈优势是实现实时交互的关键
随着效率不断优化
未来的潜力不可限量
接下来
我会持续关注Project Genie的后续更新
如果大家有体验过这款产品
也欢迎在评论区分享你的感受和创意
感谢收看本期视频，我们下期再见
