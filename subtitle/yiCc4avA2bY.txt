大家好，这里是最佳拍档，我是大飞
自从两年前的奥特曼罢免风波过后
Ilya Sutskever在公众视野中就像是一位隐士一样
当硅谷的CEO们在推特上为了谁的模型更强、谁的用户更多而吵得不可开交时
他选择了沉默
而最近，他终于打破了这种沉默
在与科技博主德瓦尔克什·帕特尔（Dwarkesh Patel）的一场深度对话中
吐露了他对当前AI技术瓶颈、未来超级智能以及人类命运的最新思考
今天这期视频
我们就来看看这位AI先知
是如何看待我们正在经历的这场技术革命的
相信他的很多观点
会颠覆你对现有AI发展路径的认知
在访谈的一开始
Ilya说了一句非常有意思的话
他说，你知道最疯狂的是什么吗？
是这一切竟然都是真的
我们现在正处在一个非常诡异的时间节点
一方面
新闻里每天都在报道科技巨头们动辄几十亿、上百亿美元的投入
用来建设数据中心，购买GPU
这笔资金的规模甚至已经达到了全球GDP的1%。
如果在十年前
有人告诉你我们会花掉全球1%的财富去造一个数字大脑
你一定会觉得这是科幻小说
但是另一方面
对于绝大多数普通人来说
生活似乎并没有发生那种天翻地覆的变化
我们并没有看到满大街的机器人
也没有看到经济数据因为AI
而呈现出一种奇点式的爆发
这种巨大的投入和平缓的体感之间
存在着一种强烈的撕裂感
Ilya认为
这其实揭示了目前AI模型的一个尴尬现状
不管是GPT-4也好，Claude也好
它们在各种考试评分上都表现得极其出色
甚至可以说是碾压人类
但是，当我们试图把这些模型
真正部署到复杂的经济活动中时
它们的影响力却远没有分数看起来那么大
这里Ilya举了一个非常生动的例子
叫做循环Bug现象
想象一下，你让一个AI去写代码
它写了一段，然后出了一个Bug
你告诉它，嘿，这里有个Bug
AI立刻道歉，哦，天哪
你是对的，我马上修
然后它修改了代码
引入了一个新的Bug
你再指出来，它再道歉，再修改
结果神奇的事情发生了
它把代码改回了最开始那个有Bug的版本
这就好比一个学生
他在考试里能够把所有的公式倒背如流
做选择题全对
但是当你让他去解决一个从未见过的实际问题时
他就陷入了死循环
这说明什么？
说明我们的模型虽然在模仿智能上
可以做得登峰造极
但是在真正的推理和理解层面
可能还缺了点什么
这就引出了Ilya对当前AI技术路线的一个核心反思
预训练（Pre-training）与强化学习（Reinforcement Learning）的本质区别
我们知道
现在的的大模型范式主要是预训练+后训练
预训练之所以强大，是因为它不挑食
互联网上有什么，它就学什么
文字、代码、论文、小说
这种来者不拒的学习方式
让模型获得了一个极其广阔的世界观
就像Ilya说的
预训练的答案是一切数据
但是
当我们想要让模型变得更聪明、更像人的时候
我们引入了强化学习（RL）
现在的强化学习是怎么做的呢？
我们在训练AI做数学题或写代码时
会给它一个问题
让它生成成千上万种解法
然后通过一个奖励机制告诉它哪个是对的
Ilya在这里提出了一个非常尖锐的批评
他认为目前的强化学习其实效率极低
他打了一个比方
假设有两个学生想学习编程竞赛
第一个学生，也就是现在的AI模型
他决定通过题海战术来学习
他把这世界上所有的编程题都做了一遍
甚至把每道题的变种都做了几千遍
通过这种极其暴力的记忆和试错
他确实能解决很多问题
但是他其实是在背诵解题路径
第二个学生
他可能只练习了100个小时
但是他拥有某种天赋或者说正确的思考方式
他通过这100个小时
掌握了举一反三的能力
很显然，在未来的职业生涯中
第二个学生会走得更远
而现在的AI，更像是第一个学生
我们试图通过让AI在强化学习中消耗巨大的算力
来弥补它在智商上的不足
但是这显然并不是长久之计
那么，问题来了，那个天赋
那个让第二个学生能快速学习的秘密武器
到底是什么？
Ilya把目光投向了生物学
投向了我们人类自己
不知道大家有没有想过
人类的学习效率其实高得离谱？
一个青少年学习开车
可能只需要几十个小时的练习就能上路了
如果让现在的自动驾驶AI去学
它需要在模拟器里跑几亿公里
这种巨大的差距
说明人类的大脑里预装了一些非常强大的先验知识
或者说学习算法
Ilya认为
这个秘密可能在于我们的情感和欲望
或者用机器学习的术语来说
就叫做价值函数（Value Function）
我们要如何理解情感是价值函数呢？
想想看，进化论经过了几亿年的筛选
给我们的基因里写入了一些非常底层的指令
比如，当你闻到腐烂食物的臭味时
你会感到恶心；
当你看到蛇的时候，你会感到恐惧；
当你在这个社会中受到他人的尊重时
你会感到快乐
这些感觉并不是随机的
它们是进化赋予我们的一个个极其健壮的指南针
指引我们在复杂的环境中
快速做出有利于生存繁衍的决策
更有趣的是
Ilya提到了大脑皮层的通用性
即使是一个天生失明的人
他的视觉皮层也不会闲着
它会被听觉或触觉信号接管
用来处理其他信息
这说明什么？
这说明我们的大脑硬件本身是高度通用的
并不存在什么专门只做视觉的硬件
真正重要的是那个学习算法和价值导向
所以，Ilya推测
如果我们想要通往真正的超级智能
我们可能不需要像现在这样
试图让AI去穷举世界上所有的棋局或者所有的代码路径
我们需要找到那个正确的价值函数
那个能让AI像人类一样
通过少量样本就能洞察本质的算法
这可能就是他眼中
从当前的人工智障跨越到超级智能的关键一步
这就带出了Ilya对于当前AI发展阶段的一个重要判断
我们正在从扩大规模的时代（Age of Scaling）
回归到探索研究的时代（Age of Discovery/Research）
回顾过去
从2012年Ilya参与设计的AlexNet引爆深度学习
到2020年GPT-3的横空出世
这十几年可以被看作是Scaling Laws的黄金时代
大家发现了一个简单的真理
只要我堆更多的算力
喂更多的数据，模型就会变强
这就像是物理定律一样稳定
所以
你可以看到各大科技公司都在疯狂地买显卡
但是，Ilya敏锐地指出
这种单纯靠堆量的红利
可能正在面临边际效应递减
现在的模型训练动辄需要几万张的H100显卡
成本高达几亿甚至几十亿美元
但是，我们得到的效果提升
似乎并没有像当年从GPT-2到GPT-3那样令人惊艳了
这并不是说Scaling Laws失效了
而是说我们可能需要一种更聪明的Scaling方式
Ilya回忆道，当他们做AlexNet的时候
只用了两张GPU
做Transformer这篇划时代的论文时
也不过用了8到64张GPU
那些真正改变世界的想法
往往并不需要天文数字般的算力来验证
相反，如果你的想法不够好
你才需要用海量的算力去强行力大砖飞
所以，Ilya认为
现在的AI领域
有点像是一个因为大家都太有钱而变得懒惰的富二代
大家都在用钱解决问题
而忘记了用脑子
他创立SSI的初衷
正是为了跳出这个怪圈
说到SSI，很多人可能会问
既然OpenAI已经那么成功了
为什么Ilya还要出来单干？
这里涉及到一个非常深刻的理念分歧
那就是关于老鼠赛跑（Rat Race）与直线射击（Straight Shot）的选择
现在的AI巨头们
无论是OpenAI、Google还是Anthropic
其实都陷入了一种不得不参与的老鼠赛跑
为了维持高估值，为了抢占市场份额
它们必须不断地推出中间产品
哪怕这个产品还不完美
哪怕它只是一个聊天机器人
它们也得先发布出来赚钱
赚了钱再买更多的显卡
再去训练下一个版本
这就导致了一个问题
研究的节奏被产品的发布周期给绑架了
所有的资源、算力和人才
都必须优先服务于那个即将发布的下一个版本
而不是去思考那些更长远、更根本、但是也更具风险的问题
Ilya不想玩这个游戏
他的SSI公司，从名字就能看出来
安全超级智能
他的目标非常明确
就是直接通往超级智能
而且是安全的超级智能
他不想在中间做任何的C端产品
不想去卖API
不想去搞订阅制
他要做的
是在实验室里通过纯粹的研究
憋一个大招
这种商业模式在硅谷是极其罕见的
甚至可以说是反直觉的
毕竟
谁会给一家几年内都不打算赚钱的公司投资几十亿美元呢？
但Ilya做到了
SSI刚成立就融到了巨资
这不仅仅是因为Ilya本人的光环
更是因为有一部分资本也意识到
通往AGI的道路
可能真的需要这种面壁者式的专注
对于SSI来说，他们的产品只有一个
那就是最终的那个超级智能
在这之前
所有的中间成果都是为了验证理论
而不是为了卖钱
这就好像是当年的曼哈顿计划
或者是阿波罗登月计划
目标只有一个，要么成功
要么失败，没有中间态
这里必须重点谈谈Ilya对于安全（Safety）的理解
在很多人眼里
AI安全就是给模型加个护栏
不让它说脏话，不让它教人造炸弹
但是在Ilya看来，这只是皮毛
真正的安全
是当AI的能力远远超过人类
成为一种我们无法理解的超级存在时
它依然能与人类的利益保持一致
这就像我们在养育一个孩子一样
在孩子还小的时候
我们可以通过管教、通过规则来约束他
但是当孩子长大
甚至比父母更强壮、更聪明时
真正维系家庭关系的
不再是规则，而是爱与价值观的共鸣
Ilya认为，未来的超级智能
必须具备一种类似人类良知或者同理心的底层架构
这不仅仅是写几行代码就能解决的
这需要我们在构建智能的最底层
就把这种偏好植入进去
这也是为什么他强调
安全和能力是不可分割的
你不能先造出一个毁灭世界的怪物
然后再想办法给它戴上项圈
你必须在造它的时候
就把不毁灭世界作为它智能的一部分
那么，未来会是什么样的呢？
在访谈的最后
Ilya描绘了一个既令人兴奋又令人深思的图景
他不认为未来会立刻出现一个统治一切的单一超级AI
相反
他认为我们会看到一个多极化的世界
会有多个由不同公司、不同国家构建的强大AI系统共存
这些AI系统会在经济、科研、法律等各个领域展开竞争与合作
就像现在的国家和公司一样
它们会通过专业化分工来提高效率
有的AI可能擅长搞科研
有的擅长搞法律诉讼
有的擅长管理物流
这种多极化的结构
在某种程度上也是一种安全机制
因为它避免了权力的绝对集中
但是同时
这也意味着人类社会将面临前所未有的变革
Ilya说，随着AI能力的增强
人类的行为也会发生改变
我们会看到一些现在无法想象的社会形态和经济模式
也许到时候
所有的物质需求都能被极低成本地满足
人类将不得不重新思考存在的意义
当然，这一切的前提是
我们能够顺利地度过那个最危险的阶段
也就是AI能力超越人类
但是还没有完全对齐的那个窗口期
最后
我想引用Ilya在访谈中反复流露出的那种态度作为结尾
哪怕在掌握了如此巨大的资源和声望之后
他依然保持着一种科学家的纯粹和谦卑
他说，想法是廉价的，执行才是关键
但是在AI这个领域，或许还得加一句
正确的直觉，比黄金更珍贵
Ilya Sutskever选择了一条少有人走的路
他赌上自己的名誉和职业生涯
去追寻那个通过直线到达的未来
无论SSI最终是成功还是失败
这场实验本身
就已经成为了人类科技史上最壮观的一页
我们作为观察者
也许无法直接参与到那些复杂的算法推导中
但是理解这些顶尖头脑的思考路径
也许能让我们在这场即将到来的风暴中
稍微站得稳一些
好了，今天的分享就到这里
感谢收看本期视频，我们下期再见
