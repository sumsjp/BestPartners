大家好，这里是最佳拍档
二零二六年的AI
可能不再是聊天框里的问答机器人了
红杉资本在《二零二六:这是AGI》的文章中给出了一个定义
AGI的核心不是能说会道
而是能把事情搞定的能力
而承载这种能力的关键载体
就是今天我们要聊到长程Agent
二零二三年
AutoGPT的爆火让我们第一次窥见了AI自主做事的可能
但是那时候的技术
还只能够停留在概念验证上
而到了二零二六年，情况彻底不同了
模型能力的跃迁、配套工具链的成熟
让长程Agent开始真正从实验室走向产业落地
作为这场变革的核心推动者
LangChain的创始人哈里森·蔡斯
站在Agent基础设施的最前沿
和红杉资本的索尼娅·黄、帕特·格雷迪
展开了一场深度对话
揭秘了长程Agent爆发的底层逻辑、技术架构
以及未来十年的产业走向
今天，我们就借着这场访谈
聊一聊长程Agent的来龙去脉、核心细节和应用前景
首先我们得先搞懂一个核心问题
长程Agent和我们之前用的AI
有什么本质上的区别呢？
过去的AI
无论是ChatGPT还是各类垂直领域的问答工具
本质上都是一个即时响应者
你输入一个问题
它基于上下文给出一个答案
对话结束，任务也就终止了
它们就像健谈者一样
擅长解释、描述
但是很难独立完成
需要多步骤、长时间推进的复杂任务
而长程Agent则完全不同
它的核心特征是自主规划、长时间运行、目标导向
你不需要一步步的指导它
只需要给出一个明确的目标
它就能在后台自主循环
从思考到规划、到行动
再到观察的整个流程
跨越几个小时、几天甚至更长的时间
逐步推进任务
最终产出一个成型的结果
蔡斯在访谈中明确的表示
长程Agent终于开始真正能工作了
这背后是两大关键因素的共同作用
第一个关键因素是模型能力的质变
二零二三年AutoGPT之所以没能普及
核心问题就是当时的模型还不够聪明
推理能力不足
无法在复杂任务中做出正确决策
也难以处理长程任务中的上下文管理
而经过两年的迭代
无论是OpenAI的GPT-5系列、Anthropic的Claude Opus 4.5
还是Google的Gemini 3系列
都在推理、工具使用和长上下文理解上实现了飞跃
尤其是Claude Code
针对代码编辑、文件处理等场景做了专门优化
让模型具备了自主操作计算机的基础能力
第二个关键因素是配套设施的成熟
这里的核心就是Harness和Scaffolding
也就是软件外壳和辅助框架的完善
蔡斯解释道，早期的Agent开发
我们更多依赖Scaffolding
也就是围绕着模型搭建的辅助代码结构
它能帮我们引导模型的输出、管理简单的流程
但是缺乏复杂的自主规划能力
而现在，我们进入了Harness时代
这种软件环境不仅包裹着模型
还内置了规划工具、文件系统交互能力以及最佳实践
形成了一个开箱即用的强预设系统
简单来说
以前的Scaffolding是给模型搭个架子让它站着
现在的Harness是给模型配了个工具箱
让它干活
这两大因素的叠加
让长程Agent的应用场景快速爆发
而最典型的爆发领域就是编程
蔡斯作为每天都在使用这类工具的开发者
直言编程领域的长程Agent案例最多
也最成熟
现在提交一个开发需求
比如搭建一个用户登录系统
需要包含短信验证和密码加密的功能
长程Agent可以自主规划开发的步骤
先创建项目的结构、编写核心代码、调试依赖包、生成测试用例
最后提交一个完整的代码合并请求
等待人类开发者的审核
这种产出初稿加人类优化的模式
已经成为了很多科技公司的日常
除了编程
还有两个场景同样值得关注
第一个是AI SRE
比如红杉投资的Traversal公司
他们的AI SRE
能够自主处理长时程的系统运维任务
深入挖掘服务器日志、诊断潜在故障、甚至自动修复简单的软件漏洞
把原本需要工程师花费几小时的排查工作
压缩到几十分钟内完成
第二个是科研
长程Agent可以自主检索文献、整理实验数据、分析研究趋势
最终生成一份结构化的科研报告初稿
科研人员只需要在此基础上补充细节、验证结论即可
蔡斯特别强调，长程Agent的核心价值
就是为复杂任务提供高质量的初稿
它不需要达到百分之九十九点九的可靠性
毕竟复杂任务的最终把关还需要人类
但是它能够承担百分之九十以上的重复性、流程性工作
把人类从繁琐的劳动中解放出来
比如金融领域的Klarna
这家先买后付的支付公司
已经落地了人机协作模式
一线AI无法处理的复杂用户咨询
不会直接丢给人工客服
而是由后台运行的长程Agent
先生成一份包含前因后果的总结报告
包括用户诉求、之前的沟通记录、可能的解决方案等等内容
人工客服拿到报告后
能够快速的进行对接
从而大幅提升处理的效率
要理解长程Agent的爆发
我们还必须搞懂它的底层架构
尤其是蔡斯反复强调的
从Framework到Harness的演进
这不仅是LangChain的发展路径
更是整个Agent行业的技术趋势
首先
我们需要明确三个核心概念的区别
这也是很多从业者容易混淆的点
第一个是模型
也就是我们常说的大语言模型
它的本质很简单，输入Token
输出Token
无论是GPT-5.2、Claude Opus 4.5还是Gemini 3 Pro
核心功能都是理解文本加生成文本
这是长程Agent的大脑
但是光有大脑还不够
第二个是Framework
这是LangChain早期的核心定位
围绕模型建立起来的一个抽象层
它的特点是无预设，核心价值是灵活
让开发者可以轻松切换不同的模型、添加工具、对接向量数据库和记忆模块
比如你用LangChain的框架
今天可以对接OpenAI的模型
明天可以换成Anthropic的模型
不需要大幅修改代码
但是框架的问题也很明显
它只提供了零件
你需要自己组装成一个完整的系统
对于复杂任务来说，开发成本很高
第三个是Harness
这是长程Agent时代的核心架构
正如LangChain推出的Deep Agents
就是基于Harness的典型案例
它的特点是强预设
认为这样做事才是正确的
所以内置了规划工具、文件系统的交互能力、子Agent的调度机制等等
是一个开箱即用的完整解决方案
如果说Framework是一堆高质量的乐高零件
那么Harness就是已经拼好的乐高模型
你只需要根据自己的需求微调一下
就能直接使用
蔡斯在访谈中透露
Harness的核心竞争力来自三个关键技术
第一个是压缩
长程Agent的运行时间很长
哪怕是现在最大的模型
上下文窗口也是有限的
当任务推进到一定的阶段
上下文会被占满
这时候就需要取舍
哪些信息要保留在上下文里
哪些信息需要暂时存储起来
比如
可能需要把之前的对话记录、工具调用结果
压缩成摘要保留在上下文里
而原始数据存储到文件系统中
模型需要的时侯再去查阅
这听起来简单
但是怎么判断哪些信息重要
怎么平衡压缩效率和信息的完整性
是Harness设计的核心难点
也是目前前沿研究的一个重点
第二个是文件系统的交互
蔡斯是文件系统优先的坚定支持者
他认为文件系统权限将成为所有Agent的标配
为什么呢？
因为文件系统是管理长程任务数据的最佳载体
模型可以把中间结果、原始数据、规划方案都存储在文件里
避免上下文过载
同时，文件系统的结构化存储方式
也让模型更容易追溯历史操作
复用之前的成果
比如
一个科研Agent可以把检索到的文献
存储为PDF文件，把数据分析代码
存储为Python脚本
以及把报告初稿存储为Markdown文件
这样在后续推进任务时
就可以直接调用这些文件
甚至LangChain还推出了虚拟文件系统的概念
底层由Redis等数据库支持
稳定性更高
避免了真实文件系统的安全风险
第三个是子Agent和技能模块的调度
一个复杂任务往往需要多种能力
比如生成一份行业的研究报告
需要文献检索，数据统计
文本撰写，格式排版等多种技能
Harness的作用就是把这些技能
拆分成不同的子Agent
由主模型统一调度
主模型负责规划整体流程
然后把文献检索的任务
交给检索子Agent
把数据统计的任务
交给数据分析的子Agent
最后汇总所有子Agent的结果
生成最终报告
这里的关键是协同
主模型和子Agent之间要传递完整的信息
避免出现子Agent做了一堆的工作
主模型却只收到一句“见上文”的情况
现在的开源Harness
系统提示词动辄几百行
核心就是为了解决这种协同问题
这三大技术的结合
让Harness具备了支撑长程Agent的能力
而行业实践也证明了Harness的重要性
目前最权威的AI Agent终端能力榜单Terminal-Bench 2.0显示
同一个模型在不同的Harness加持下
性能差异巨大
比如，OpenAI的GPT-5.2
在Factory公司的Droid Agent Harness中
准确率达到了百分之六十四点九
排名第一
而在其他公司的Harness中
准确率可能只有百分之六十左右
更值得注意的是
榜单头部的玩家不仅有模型厂商
比如OpenAI、Anthropic
还有第三方创业公司
比如Factory、JetBrains等等
这说明，只要深刻理解了模型的特性
第三方开发者完全能够在Harness层面
挖掘出巨大的性能提升，在这个领域
模型厂商并不具备天生的优势
Factory公司的Droid Agent就是一个典型的案例
它基于GPT-5.2和Claude Opus 4.5等模型
在Terminal-Bench 2.0的八十九个真实终端任务
包括编译代码、训练模型、搭建服务器、生物信息分析等等
准确率达到了百分之六十四点九
位居榜首
它的成功，核心就在于Harness的设计
充分利用了GPT-5.2在命令行上的训练优势
同时优化了上下文压缩和子Agent的调度机制
让模型能够高效处理长时程、多步骤的终端任务
蔡斯还提到
Harness的演进和模型的进化
是一个共同进化的关系
现在的模型之所以能够很好的适配文件系统、命令行工具
是因为它们在训练数据中包含了大量的代码、命令行操作数据
而Harness的发展
又会产生更多的交互数据
反过来促进模型的优化
两年前，我们不可能预知
基于文件系统的Harness会成为主流
因为当时的模型还没有针对这些场景进行充分训练
而现在，模型和Harness的相互成就
终于让长程Agent实现了规模化落地
在访谈中
帕特·格雷迪抛出了一个很有前瞻性的问题
他问
Coding Agent到底是一个子类别
还是说所有的Agent
本质上都应该是Coding Agent呢？
这个问题的核心
其实是在探讨通用AI的实现路径
如果AI的目标是让计算机干活
而代码是控制计算机最精准、最通用的方式
那么Coding Agent
是不是就是通用AI的终极形态呢？
蔡斯对这个问题的思考显然十分深入
他首先明确了一个前提
那就是构建长程Agent
必须给它文件系统的权限
而编程能力
其实是文件系统权限的延伸
文件系统能存储数据
而代码能操作数据、运行任务、实现复杂的逻辑
比如
一个金融Agent可以用代码编写脚本
自动抓取股票数据、计算均线、生成可视化图表
一个科研Agent可以用代码编写数据分析程序
处理实验数据、拟合模型、输出统计结果
这些操作
用自然语言指令是很难精准实现的
但是用代码可以做到零歧义
但是他也指出
编程Agent和具备文件系统权限的Agent
并不是完全等同的
比如，LangChain的虚拟文件系统
不需要模型写代码
也能实现数据的存储和检索
满足一部分简单场景的需求
但是对于长尾的复杂用例
编程能力是无可替代的
你无法用虚拟文件系统来运行一个机器学习模型
也无法用虚拟文件系统
搭建出一个Web服务器
而这些都需要代码才能实现
更重要的是
编程本身就是一种通用工具
无论你是在金融、科研、医疗还是教育领域
只要涉及到复杂的流程自动化、数据处理、系统搭建等任务
编程都是核心的手段之一
蔡斯甚至提到，即使是非编程的任务
你也可以通过编写代码来实现
所以代码本身就是很好的通用手段
这就引出了一个关键的结论
Coding Agent可能是目前最接近通用AI的形态
因为它不局限于某个垂直领域
而是通过代码这个通用语言
对接所有的计算机系统和工具
实现跨领域的复杂任务
当然，这并不意味着
所有的Agent都必须会写代码
对于一些简单的、标准化的任务
自然语言指令加文件系统已经足够了
但是对于长时程、高复杂度、高精准度的任务
编程能力将成为长程Agent的核心竞争力
目前
行业的发展趋势也在印证这一点
Terminal-Bench 2.0榜单上的头部玩家
几乎都是编程类的Agent
Claude Code、Amp Code等产品的爆火
也说明市场对AI编程能力的需求非常旺盛
更重要的是
Coding Agent的能力边界还在不断的扩展
从单一文件的代码生成
到多文件的项目开发
再到完整SaaS应用的构建
Coding Agent正在逐步具备端到端解决复杂工程问题的能力
当然，蔡斯也承认
这只是目前的阶段性判断
未来是不是会出现比代码更通用、更高效的计算机控制语言
还是一个未知数
但是就目前来看
Coding Agent是长程Agent发展的一个核心方向
也是目前最有可能实现通用AI的路径
很多传统软件的开发者在接触长程Agent的时侯
都会有一个困惑
觉得这不就是自动化脚本的升级版吗？
但是蔡斯明确指出
构建长程Agent和构建传统软件
存在着本质上的区别
这种区别不仅体现在技术层面
更体现在开发理念、迭代模式和核心目标等方面
第一个核心区别，逻辑的来源不同
传统软件的逻辑是完全可见、完全可控的
所有的流程、判断、操作都写在代码里
开发者能够精准预测软件在任何场景下的行为
而长程Agent的逻辑
很大一部分来自于只提供了框架的模型代码
比如Harness的结构、工具的对接方式
而具体的决策、规划、操作步骤
都是模型根据上下文和目标自主生成的
这意味着
你无法只看代码就推断出Agent在特定场景下的行为
必须实际运行它，然后观察它的表现
这种非确定性黑盒系统的特性
给开发带来了巨大的挑战
比如，同一个需求
Agent在不同上下文环境下
可能会生成完全不同的操作步骤
甚至在同一个任务中
前十三步的操作都很顺利
第十四步却因为上下文变化而出现偏差
这也是为什么LangSmith的Tracing功能
如此受欢迎的原因之一
它能够复现Agent内部的每一步操作
模型的思考过程、工具的调用结果、上下文的变化、文件的修改记录
开发者可以通过Tracing功能
精准定位Agent的决策偏差
而不是像传统软件那样
一边看着代码一边查bug
第二个核心区别，Source of Truth
也就是单一事实的来源不同
传统软件的事实来源是代码
软件的行为由代码唯一决定
只要代码不变，行为就不变
而长程Agent的事实来源是代码加Tracing
代码定义了基础的规则
而Tracing记录了Agent的实际行为和上下文变化
这意味着，Agent的开发和测试
不能只依赖离线的单元测试
而必须依赖在线测试
只有让Agent接触真实世界的输入
观察它的行为涌现
才能发现问题、优化模型
更重要的是
Tracing正在成为团队协作的核心支点
在传统软件团队中
遇到问题大家会说
去GitHub看代码吧
而在Agent开发团队中，大家会说
去看看Tracing吧
比如
用户如果反馈某个Agent处理邮件时分类错误
开发者不需要去检查代码
而是应该通过Tracing来查看Agent的思考过程
它提取了哪些邮件的关键词？
基于什么规则做的分类呢？
是不是遗漏了什么关键信息呢？
通过这些信息
能够快速定位问题的根源
比如可能是提示词的引导不够清晰
也可能是模型对某些关键词的理解有偏差
而不是代码本身的问题
第三个核心区别，是迭代的模式不同
传统软件的迭代是目标明确、行为可预测的
开发者先设定好功能目标
然后编写代码实现，测试通过后发布
发布前就能明确知道软件的行为
而长程Agent的迭代是目标模糊、行为涌现的
你可能知道要做一个邮件分类的Agent
但是你无法预知它在面对各种复杂邮件
比如带附件的、多语言的、内容模糊的邮件时的表现
因此
Agent的开发需要更多的迭代反馈
发布后
通过收集用户的反馈、分析Tracing的数据、优化提示词和Harness
再发布测试，循环往复
直到Agent的表现能够达到预期为止
而这一切的核心支撑
就是记忆Memory
蔡斯在访谈中反复强调记忆的重要性
如果系统能够自我学习
就减少了开发者手动修改系统提示词的频率
Agent的记忆
本质上是长周期的上下文工程
它记录了之前的交互历史、任务经验、错误教训等等
让Agent在后续的任务中能够举一反三
比如，一个邮件Agent如果记住了
用户把工作汇报类邮件都归类到重要文件夹
下次遇到类似邮件时就会自动分类
如果记住了用户曾经纠正过会议通知和培训通知的分类错误
下次就会更加精准的判断
蔡斯还分享了一个亲身经历
他之前用LangChain构建了一个邮件Agent
积累了很多记忆
后来他想把这个Agent迁移到LangSmith Agent Builder中
结果因为丢失了旧的记忆
哪怕提示词和工具跟之前完全相同
新Agent的体验也远远不如旧的那个
这个案例充分说明
记忆是Agent的核心护城河
一个经过了长时间磨合、内化了特定任务模式和背景记忆的Agent
它的竞争力
是从零开始构建的Agent所无法比拟的
如果说记忆是Agent的经验库
那么评估体系就是Agent的自我修正机制
传统软件的评估很简单
通过程序化断言
比如输入A
输出是不是B，来判断功能是不是达标
但是长程Agent做的是人做的事
比如生成报告、编写代码、处理运维问题等等
对这些任务的评估
很难用非黑即白的规则来定义
必须引入人类判断
或者类人的判断才行
这就引出了评估体系的两种核心方式
第一种是人类直接参与评估
比如，在LangSmith中
开发者可以通过Annotation Queues
直接给Agent的行为标注反馈
比如，这一步做得好
这里分类错误了
应该优先处理这个任务等等
这些自然语言反馈
会被记录到Tracing中
成为优化Agent的核心依据
对于一些高价值、高风险的场景
比如生成金融报告、处理医疗数据等等
人类评估是不可或缺的
毕竟Agent的初稿需要人类把关
避免出现严重的错误
第二种是让大模型来当裁判
这种方式的核心
是用一个更强大的大模型
来评估Agent的行为是不是达标
比如
用GPT-5.2来评估一个编程Agent生成的代码
是不是正确、高效的
用Claude Opus 4.5来评估一个科研Agent生成的报告
是不是严谨、全面的
但是这里有一个关键的前提是
这个当裁判的模型
必须和人类判断是对齐的
如果大模型的评判标准和人类的不一致
那么评估结果就是毫无意义的
为了解决这个问题
LangSmith推出了对齐评估的功能
先让人类标注一部分的Tracing数据
建立正确行为的样本库
然后用这些样本库来训练裁判模型
让它学习人类的评判标准
比如，人类标注了
代码必须包含错误处理逻辑才能达标
那么裁判模型就会以这个为标准
评估Agent生成的代码是不是符合要求
这种人类标注校准
加大模型自动评估的模式
既保证了评估的准确性
又提高了评估的效率
非常适合大规模的Agent迭代
更重要的是
评估体系不仅是给开发者的反馈
更是Agent自我改进的依据
蔡斯把这称为迭代式的自我改进
通过查看Tracing数据
反思自己之前的行为
然后自动修改提示词、调整规划逻辑、优化工具的调用方式
实现Agent越用越聪明的效果
LangSmith Agent Builder就是一个典型的案例
这个工具允许用户用自然语言来描述需求
比如
帮我创建一个能读取Gmail、自动分类邮件并且草拟回复的助手
它就能够自动生成一个完整的Agent
更酷的是，它具备自我改进的能力
当你和Agent交互时，如果你说
应该把会议通知归类到紧急文件夹
而不是普通文件夹
Agent就会自动修改自己的指令文件
下次就会按照新的规则来分类邮件
LangChain还计划增加休眠期计算的功能
让Agent在每晚自动运行
查看当天的Tracing数据
总结经验和教训，更新自身状态
实现无人干预的自我优化
当然
这种自我改进并不是完全无人工干预的
蔡斯强调
最理想的状态是Agent产出初稿
比如修改了提示词
然后人类进行审核，确保它不跑偏
毕竟
Agent的自我改进可能会出现方向错误
比如，它可能会过度优化某个功能
导致其他功能失效
或者误解了用户的反馈
做出不符合需求的修改
因此
Human in the loop是Agent自我改进的必要保障
也是目前最现实、最安全的模式
聊完了技术架构和自我改进
我们最关心的问题来了
未来的长程Agent
会以什么样的形态出现在我们的工作和生活中呢？
我们会怎么和它们交互呢？
它们的核心竞争力又是什么呢？
蔡斯给出的第一个答案，是记忆
他在访谈中直言说
记忆是真正的护城河
这个观点的核心
在于长时程磨合的价值
一个Agent的价值
不仅在于它的初始能力
更在于它越用越懂你的过程
让Agent逐渐成为你的专属助手
而这种专属感
是新构建的Agent所无法替代的
当然，记忆的价值也是有边界的
比如，ChatGPT虽然也加了记忆功能
但是很多用户并不常用
因为大家用ChatGPT都是做一次性任务
比如问一个代码问题、查一个旅游攻略等等
任务之间没有关联
记忆的作用自然有限
但是对于长时程、高频次、个性化的任务
比如科研、办公、金融分析来说
记忆的价值就会被无限放大
蔡斯的判断是，在垂直场景下
记忆绝对是大势所趋
除此以外，未来的长程Agent
不会是纯同步或者纯异步的
而是同步模式加异步模式的混合形态
为什么需要异步模式呢？
因为长程Agent的运行时间很长
可能需要几个小时才能生成一份科研报告
或者可能需要几天
才能完成一个软件项目的开发
在这个过程中
用户不可能一直在等待
所以默认应该是异步的
你下达任务后，Agent在后台运行
完成后再通知你
你再进行后续的操作
像一些项目管理工具和电子邮件
都是异步管理的很好参考
它们能够让你清晰的看到任务进度、状态
而不需要实时的关注
那为什么还需要同步模式呢？
因为当Agent产出结果后
你需要即时反馈
比如，Agent生成的报告有错误
你需要马上指出
Agent编写的代码有漏洞
你需要实时调试
这时候，同步沟通模式就必不可少了
你可以直接和Agent聊天
指出问题在哪里，Agent实时进行修改
从而形成从反馈到修正的闭环
蔡斯还提到了一个关键的细节
现在的Agent不只是在说话
实际上它们是在修改状态
比如文件系统里的文件
这意味着
未来的交互界面必须能够是可视化状态的
就像程序员离不开用IDE来看代码一样
你需要知道Agent修改了哪些文件、调整了哪些参数、运行了哪些任务
这种状态的可视化
才是交互体验的核心
Anthropic的Cowork已经给出了一个很好的范式
它可以设置一个目录作为共享工作区
Agent和用户都能访问这个工作区
查看、修改文件
这种模式建立了一种清晰的心理模型
那就是我们在一个共享状态上进行协作
无论是本地文件、Google Drive还是Notion
共享状态的可视化都是交互的核心
基于混合交互模式和状态可视化的需求
未来长程Agent的UI
会彻底告别现在的纯对话框形态
转向状态管理界面
这种界面会包含三个核心部分
第一，任务管理模块
参考Jira、Kanban等工具
显示Agent正在处理的任务、进度和优先级
第二，共享状态的可视化模块
显示文件系统、代码仓库、数据表格等等
让你能够直观看到Agent的操作结果
第三，同步沟通模块，内置聊天功能
方便你在需要的时候和Agent进行实时交互
给出反馈
简单说，未来的长程AgentUI
会更像项目管理工具
加IDE，加聊天软件的结合体
它不再只是一个沟通的窗口
更是任务管理和状态监控的平台
只有这种界面设计
才能够完美适配异步管理加同步反馈的混合交互模式
让用户既能高效管理多个长时程任务
又能及时解决Agent遇到的问题
最后，蔡斯明确指出
代码沙箱绝对是一个未来的核心组件
代码沙箱的作用
是为Agent提供一个安全、隔离的运行环境
Agent可以在沙箱里编写代码、运行脚本、测试程序
而不会影响外部系统的安全
他还给出了三个判断
第一
文件系统访问是所有Agent的标配
第二
编程能力是长程Agent的核心竞争力
第三，浏览器访问目前还不够成熟
虽然有一些尝试
比如让Agent通过命令行操作浏览器
但是模型的准确性和稳定性还需要提升
这意味着，未来的长程Agent
都会内置一个代码沙箱
具备文件系统的访问和编程能力
能够在隔离环境中安全的运行复杂任务
而浏览器访问
可能会在模型进一步优化后
成为一个补充能力
红杉资本说
AGI就是把事情搞定的能力
而长程Agent正是实现这种能力的关键一步
二零二六年
也许会是AI行动者纪元的起点
我们有理由相信，在未来几年
长程Agent将会彻底重构我们的工作和生活
让AI真正成为大家身边的最佳拍档
感谢收看本期视频，我们下期再见
