大家好这里是最佳拍档我是大飞
去年的11月
Meta经历了「All in元宇宙」后
最难熬的寒冬
那时的Meta遭遇了苹果调整隐私策略和元宇宙遇冷的双重打击
股价一度跌至近6年来的谷底
比2021年的最高价位缩水了三分之二还多
不足一百美元
但是让人出乎意料的是
Meta恢复的速度比跌倒还要快
2023年Meta做出了大量调整
包括裁员和削减项目收缩成本、押注短视频应用Reels
以及加大AI技术的投资
利用AI来改进广告模型投放等等
其中
AI在Meta「苏醒」的历程中扮演了非常重要的角色
今年以来Meta在AI领域持续发力
不断地开源自家的AI研究成果
从技术层面来看并不弱于OpenAI和Google等明星AI公司
就在今天
Meta发布了开源大模型Llama 2
引爆了整个AI圈
因为Llama 2不仅性能不输GPT-3
而且免费、开源，还可商用！
那么什么是Llama 2呢？
Llama 2是Meta今年3月初发布的Llama模型的后续版本
Llama因为体积小、性能强等优点
在AI社区得到了广泛的好评
被认为是推动AI研究和开发的重要工具
Meta AI今天一同发布了Llama 2及其调优版本Llama 2-Chat
相比Llama 1
新版Llama 2在模型规模、训练数据量、模型结构等多个方面
进行了全面提升
Llama 2家族包含多个模型规模
包括70亿、130亿、暂未发布的340亿和700亿参数量的多个版本
覆盖了不同的应用场景需求
这次Meta首先开源发布了70亿和130亿参数的Llama 2
以及对应的聊天机器人调优版本Llama 2-Chat
与Llama 1相比
Llama 2在三个方面进行了重要的改进
首先，训练数据量增加了40%，
从Llama 1的1.4万亿个token
增至2万亿个token
训练数据中的文本来源更加多样化
包括书籍、论文、新闻报道、网页内容等在线公开来源
其次
Llama 2还将单条文本的最大长度
从2048个token提升至4096个token
更长的文本输入意味着可以包含更多上下文信息
提升了模型的理解能力
第三
Llama 2在更大模型的版本中采用了「分组Attention」机制
可以显著降低计算和内存需求
提升推理速度
除了规模和结构的改进
Llama 2在多个自然语言处理基准测试上的结果
也优于Llama 1和其他开源大模型
显示出在知识表达、推理、对话等能力上的提升
除了纯预训练模型
调优对话型模型对结果的质量也很重要
Meta研究人员开发了全新的调优方案
通过监督微调和强化学习相结合的方式
不断提升 Llama 2-Chat的性能
举个例子
Llama 2-Chat的理解能力和表达能力都上了一个台阶
现在可以只用Emoji和你聊天
那这是怎么做到的呢？
Meta的研究人员先利用人工标注数据进行监督微调
使模型初步符合人类偏好
兼顾有用性和安全性
为后续的强化学习奠定了良好基础
然后
利用强化学习中的「拒绝采样」策略
进行迭代调优
该策略为每个输入文本生成多个响应
利用训练好的「奖励模型」选择最佳的响应
再利用选择后的响应样本微调模型
研究人员收集了超过100万条人类偏好比较数据来训练奖励模型
在此过程中，安全性和有用性
作为两个独立的奖励模型进行训练和评估
安全性奖励模型可以识别风险更高的输入
并给出更低的分数
有助于降低模型生成有害内容的风险
简单来说
Llama 2的性能和安全性在开源大模型里面都是首屈一指的存在
更详细的技术细节可以参考Meta公布的技术论文
我们后续也会专门再做一期节目来详细解读一下
目前Meta已在GitHub上开源了Llama 2预训练模型的代码和参数
允许研究人员进行探索
Meta还开放了Llama 2的商业使用许可
相信很快将会有一批基于Llama 2的大模型产品涌现出来
除此之外
在今天的微软Inspire合作伙伴大会上
微软CEO萨蒂亚·纳德拉（Satya Nadella）
还宣布了Meta与微软合作的消息
这项合作让Llama 2可以运行在微软的云服务Azure上
Meta则表示
微软是Llama 2的首选合作伙伴
未来两者会通过深度合作
来增加对基础人工智能技术的普及
从而让全球的企业受益
而除微软以外
Meta同时还和亚马逊AWS、Hugging Face
两家云服务供应商达成合作
在他们的平台上托管Llama 2的运行
值得注意的是
Llama 2虽然允许了商业使用
但是它在社区许可协议中还添加了一条附加商业条款
大意就是
如果你的公司或者关联公司
提供的产品或服务的每月活跃用户数
在上个月超过了7亿
那么必须向Meta申请许可
等Meta明确授权后方可继续使用
这意味着一些大厂
譬如亚马逊、Google这样的巨头想要使用Llama 2
还存在一定的限制
当然他们也大概率会使用自己的模型
不会使用拉马2
在微软的官方博客中
微软表示 Llama 2已经针对Windows进行了优化
可以在Windows本地运行
这有可能会让Windows一举成为
开发者打造个性化AI体验需求的最佳平台
也就是说
Meta推出的Llama 2大语言模型
可能会成为OpenAI的主要竞争者
相信大家都知道
微软持有OpenAI 49%的股份
OpenAI也依赖Azure来提供大量算力
来支撑其人工智能模型的运营
甚至ChatGPT 目前联网搜索的插件
也接入的是必应的搜索引擎
而此前让不温不火的必应
访问量暴增的New Bing也是依靠GPT-4来开发的
可以说，微软在人工智能领域
与OpenAI已经有着水乳交融般的合作
但是我觉得这并不影响微软两边同时押注
闭源领域依靠OpenAI实现2C业务
进行商业化
开源领域与Meta合作
建立生态的同时
还能威胁到其他的闭源大语言模型
不得不说
微软同时押注Meta和OpenAI
才是真的精
也再次印证了商业里没有一直的朋友与敌人
此外，Llama 2也探讨了在移动终端
特别是智能手机领域
本地运营的可能性
高通表示
正在和Meta一起合作优化Llama 2直接在终端侧的执行
计划从2024年起
在搭载骁龙平台的旗舰智能手机和PC上
支持基于Llama 2的AI部署
未来Llama 2也可能将搭载在
VR头显、汽车座舱、物联网终端等领域
搞不好到明年这个时候
你正在用着的骁龙芯片手机
也能够运行Llama 2模型了
不过，对于Llama 2
Meta 公司也承认它并非绝对的完美
比方说
Llama 2 70B在推理任务上虽然接近GPT-3.5
但是在编码基准上存在显著的差距
同时
它在性能上还无法与OpenAI的GPT-4、PaLM-2-L相媲美
在计算机编程方面Llama 2明显落后于GPT-4
Meta还承认
Llama 2与所有生成式AI模型一样
在某些层面存在偏差
例如，由于训练数据的不平衡
以及训练数据中存在“有毒”文本
它可能会制造“幻觉”、生成“有毒性”的内容
针对这一点
Meta 选择和微软合作的一部分
也包括使用Azure AI Content Safety服务
帮助检测AI生成的图像和文本中的“不当”内容
从而减少Azure上有毒的Llama 2输出
最后
如果说OpenAI引领了大模型赛道
那么Meta则打开了开源大模型的新大门
Llama 2的开源也为未来带来了更多的可能性
同时
为了避免Llama 2开源存在的潜在争议
Meta还同时发布了一封主题为
《支持Meta对当今人工智能的开放方法》的声明
其中写道
我们支持对人工智能采取开放式创新方法
负责任和开放式创新
为我们所有人提供了参与人工智能开发过程
为这些技术带来可见性、审查和信任
今天开放的Llama模型
将使每个人都从这项技术中受益
截至到目前
已有近百位AI专家在声明上签名
当然，不容忽视的是
无论是开源还是闭源大模型
其都面临着复杂的法律问题
因为他们需要判别
用于训练的数据池中是否存在受版权保护的资源
如何有效避免这些问题
也将成为这些大模型开发公司
下一阶段需要解决的事情
大家如果对Llama 2感兴趣
可以在Meta网站上填写表格
来申请下载Llama 2
我会把相关链接放到视频简介里
想要尝鲜的小伙伴不妨一试
好了，今天的内容就介绍到这里
感谢大家的观看，我们下期再见
