大家好，这里是最佳拍档，我是大飞
在这个人工智能浪潮汹涌的时代
算力就如同战场上的军火
是各大科技巨头竞相争夺的战略资源
今天，我们就来根据公开数据
探讨一下全球五大巨头的GPU总量情况
看看这场算力军备竞赛究竟有多激烈
而谁又可能在这场角逐中脱颖而出
首先，在这场AI巨头的芯片之争中
英伟达可以说是稳坐GPU霸主的宝座
数据中心收入在近年来实现了爆发式增长
2024年仅数据中心的收入预计就将达到1100亿美元
比2023年的420亿美元增长了一倍多
2025年更是有望突破1730亿美元
而这背后的收入主力
就是其强大的GPU产品
根据估计
2025年英伟达的销量为650万到700万块GPU
几乎全是最新的Hopper和Blackwell系列
根据生产比例和产量预期
其中大约包括200万块Hopper
500万块Blackwell
这些先进的GPU产品
将为全球各大科技公司提供强大的计算支持
也进一步巩固了英伟达在GPU市场的主导地位
不过，2024年英伟达的实际产量数据
相对较少而且存在着一些不确定性
有估算称
2024年第四季度将生产大约150万块Hopper GPU
但是其中包括一些性能较低的H20芯片
因此是一个上限值
根据季度间数据中心的收入比例推测
全年生产总量可能上限为400万块到500万块
虽然这个数据
与年初估计的150万到200万块H100的生产量存在差异
但是英伟达在GPU生产方面的强大实力
毋庸置疑
我们再来说说英伟达的客户结构和销售模式
英伟达的客户分为「直接客户」和「间接客户」两种
其中，46%的收入来自于直接客户
包括像SMC、HPE、戴尔这样的系统集成商
这些系统集成商采购完GPU之后
会组装成服务器
再提供给间接客户来使用
间接客户覆盖范围更加广泛
包括公有云服务提供商、互联网消费类公司、企业用户、公共部门机构和创业公司等等
像微软、Meta、谷歌、亚马逊、xAI这些巨头
都属于「间接客户」。
英伟达2024年的财年报告中披露了
大约19%的总收入
来自于通过系统集成商和分销商采购产品的间接客户
接下来
我们来看一下巨头们的算力布局
在这场算力大战中
微软无疑是一个强劲的竞争者
它不仅拥有全球最大的公有云服务平台之一Azure
为微软提供了强大的计算资源基础
同时
微软还是OpenAI的主要算力供应商
与OpenAI的紧密合作
让它在人工智能领域的布局更加深远
值得注意的是
微软并没有像谷歌和亚马逊那样
大规模地部署自己的定制芯片
而是选择与英伟达进行深度合作
事实上
微软与英伟达建立了一种特殊的合作关系
也是首个获得Blackwell GPU的公司
早在今年10月
微软Azure就已经开始测试32个GB200服务器的机架
这表明了微软在追求先进算力方面的积极态度
根据一些估算和分析
微软在英伟达销售中的份额
虽然在2024年较2023年有所降低
但是仍然占据着重要的地位
2024年微软的收入占比数据显示
其上半年在英伟达的收入占比为13％
第三季度则超过10％
综合各种因素，预计到2024年底
微软将拥有75万到90万块等效的H100算力
而到2025年
这个数字有望扩展到250万到310万块
可以说算力增长势头是相当强劲
说完微软，我们再看谷歌
谷歌在人工智能领域一直处于领先的地位
算力布局也毫不逊色
谷歌已经拥有大量自研的定制TPU
这也是公司内部工作负载的主要计算芯片
去年12月
谷歌推出了下一代迄今为止最强大的TPU v5p
进一步巩固了在自研芯片领域的优势
Semianalysis曾经在2023年底的一篇报道中指出
谷歌是唯一一家拥有出色的自研芯片的公司
在低成本、高性能且可靠的大规模AI部署方面的能力
几乎无人能及
堪称全球算力最丰富的企业之一
从谷歌的投入来看
它对基础设施的重视程度也在不断的提高
2024年第三季度财报估计
谷歌的AI支出为130亿美元
其中“大部分”用于搭建技术基础设施
而在这其中
大约60%是服务器，包括GPU和TPU
假设按照TPU对GPU支出2:1的估算
并且保守假设TPU的每美元性能
与微软的GPU支出相当
预计到2024年底谷歌将拥有相当于100万到150万块等效的H100算力
到2025年
谷歌的算力预计将进一步扩展到350万到420万块等效H100
继续保持它在算力领域的领先地位
作为社交媒体领域的巨头
Meta在人工智能领域也在不断的发力
Meta曾经发文宣称，到2024年底
将拥有相当于60万块H100的算力
其中包括35万块H100
剩余部分很可能是H200
以及少量将在最后一个季度交付的Blackwell芯片
如果按照这个数字
并且结合它在英伟达收入中的占比进行推算
Meta的算力规模比微软略低
预计2024年
Meta将拥有55万到65万块等效的H100算力
到2025年
这个数字将有望增长到190万到250万块
从Meta在人工智能基础设施方面的持续投入
也可以看出它在AI领域不断发展的决心
相比起其他家来说
亚马逊在这场算力竞赛中的策略则略有不同
一方面
亚马逊持有相当数量的英伟达芯片
主要是为了满足通过AWS云平台提供的外部GPU需求
尤其是为Anthropic等公司提供算力支持
另一方面
亚马逊也在积极发展自己的自研芯片
比如Trainium和Inferentia芯片
不过，相比谷歌的TPU
亚马逊在自研芯片方面的起步较晚
这些芯片在市场接的受度方面
起初并不理想
甚至亚马逊还提供高达1.1亿美元的免费额度
来吸引用户的尝试
但是在2024年，情况似乎出现了转机
在第三季度财报电话会议上
亚马逊CEO 安迪·贾西Andy Jassy表示
Trainium2芯片获得了巨大的市场兴趣
公司已经多次与制造合作伙伴协商
大幅提高原定的生产计划
虽然目前关于亚马逊的Trainium/Trainium2芯片
换算成等效H100的具体数量还难以获得
但是可以确定的是
亚马逊在人工智能算力方面的布局正在逐步加强
预计到2024年底
亚马逊将拥有25万到40万块等效H100算力
2025年这个数字有望达到130万到160万块
而作为新的入局者
xAI在2024年可谓是一鸣惊人
xAI标志性的事件，就是在122天里
建成了由10万块H100组成的世界最大超算Colossus
马斯克还预告了未来将扩展到20万块由H100/H200组成的超算
展示了xAI在算力建设方面的雄心壮志
不过
xAI在发展过程中也面临着一些挑战
尤其是在供电方面
尽管如此
xAI的发展速度依然令人瞩目
根据报道
xAI使用了2万块H100训练了Grok 2
然后计划用10万块H100来训练Grok 3
考虑到H100的高性能
Grok 2和Grok 3的训练计算量应该处于行业的前沿水平
此外
xAI并非完全依赖于自有的芯片资源
部分资源还来源于租赁，根据估算
他们从Oracle云平台租用了1.6万块H100
预计到2024年底
xAI将拥有约10万块等效H100算力
到2025年
这个数字可能会增长到55万到100万块
了解了各大巨头的算力储备后
我们在来看一下
OpenAI、谷歌、Anthropic、Meta和xAI等公司
在模型训练算力使用情况的分析
首先，OpenAI在2024年的训练成本
预计高达30亿美元
推理成本为40亿美元
对算力的需求巨大
据称
微软向OpenAI提供了40万块GB200 GPU
用来支持GPT模型的训练
这使得OpenAI的训练能力远超Anthropic
OpenAI也凭借着强大的算力支持
不断推动模型的发展
在人工智能领域保持领先地位
Anthropic在2024年预计亏损大约20亿美元
而收入仅为几亿美元
考虑到它们的收入主要来自API服务
而且推理成本相对较低
这意味着20亿美元中大部分都用在了模型训练上
保守估计其训练成本为15亿美元
大约为OpenAI的一半
不过Anthropic凭借着自身独特的技术和策略
在前沿模型领域保持了竞争力
这种差异也反映了两家公司在算力获取和利用上的不同策略
Anthropic的主要云提供商AWS的资源相对有限
可能也限制了它们的算力规模
进而影响了模型训练的规模和能力
谷歌的Gemini Ultra 1.0模型
使用了大约为GPT - 4的2.5倍的计算资源
发布时间却晚了9个月
而且所用得计算资源
比Meta的最新Llama模型要高25%。
尽管谷歌拥有强大的计算能力
但是作为云服务巨头
它还需要支持大量其他的内部工作负载
这在一定程度上也分散了用来训练前沿模型的算力资源
Meta的Llama 3模型所用的计算资源比Gemini少
而且发布时间晚8个月
这表明Meta分配给前沿模型的资源
相较于OpenAI和谷歌更少
Meta同样需要在支持其庞大的社交媒体业务
和发展人工智能模型之间
去平衡算力资源
这也使得它在模型训练的算力投入上相对较为谨慎
xAI虽然是新入局者
但是在算力利用上却展现出了高效的特点
根据报道
xAI使用了2万块H100训练Grok 2
并且计划用10万块H100训练Grok 3
考虑到H100的高性能
Grok 2的训练计算量大约为GPT - 4的两倍
而Grok 3则预计达到5倍
单就计算资源利用水平来说处于前沿
尽管xAI的部分算力资源来源于租赁
但是这并不影响它们在模型训练上的高效表现
这种发展模式
也为其他新兴人工智能公司提供了新的思路和借鉴
随着人工智能技术的不断发展
以及模型规模和复杂性的持续增长
对算力的需求也将水涨船高
这场算力军备竞赛不仅是一场资源的争夺
更是一场技术和创新的较量
各大巨头在不断扩充算力的同时
也在探索如何更高效地利用这些算力
来推动人工智能技术的发展
未来
我们可能会看到更强大的模型诞生
为医疗、交通、金融等众多领域带来前所未有的变革
同时，随着技术的发展
GPU/TPU的性能也将不断提升
成本也可能会进一步降低
这将使得人工智能技术更加普及
惠及更多的人群和行业
在这场激烈的竞争中
谁将成为最后的赢家
目前尚不可知，但是可以确定的是
这场算力军备竞赛将推动整个人工智能行业以更快的速度向前发展
为我们带来更多的突破和可能
好了，今天的分享就到这里
希望能够对大家了解全球AI算力领域的竞争态势
有所帮助
感谢大家的观看，我们下期再见！
