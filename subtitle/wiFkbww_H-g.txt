大家好，这里是最佳拍档，我是大飞
在OpenAI发布了GPT-4o之后
内部却迎来了新一波的动荡
联合创始人兼首席科学家Ilya Sutskever宣布离职
随后又有不少人宣布离开OpenAI
包括超级对齐团队的联合负责人Jan Leike
昨天他更是在X平台上连发13条推文
直接公开透露自己与OpenAI高层
在公司的核心优先事项上
存在着“无法调和”的长期分歧
尤其是团队在推动项目和争取计算资源时遭遇重大的阻碍
严重影响研究的进度和质量
最后更是“语重心长”地告诫所有OpenAI员工
要学会感受AGI
要对你们手中正在构建的事物
态度庄重一些
而且根据《连线》杂志证实
OpenAI的超级对齐团队已经解散
余下成员要么辞职
要么将被纳入OpenAI的其他研究工作中
而为什么目前少有内部人站出来说
是因为OpenAI会让员工在离职时
签署包含非贬损公司条款的离职协议
如果拒绝签署
员工就相当于放弃了自己在公司的股权
意味着可能会损失数百万美元
其实我们频道之前做过好几期与超级对齐有关的节目
想在回过头来看看
真是唏嘘不已
显然，OpenAI已经放弃了AI安全
一路在商业化方向狂奔
前段时间甚至还有传闻
要开放生成色情内容的能力
不知道有没有想过
这会对青少年产生怎样的危害
不过
我们这期节目并不是想吐槽OpenAI
而是我看到前几天有评论说
不知道Ilya是谁
我觉得有必要再普及一下
或者说做多少期节目去介绍他都不过分
通过了解Ilya的过往经历
以及他在联合创立OpenAI之前、期间以及发布ChatGPT之后的整个经历和思考
或许可以告诉我们他为何离开OpenAI的答案
对于已经熟知他的观众
也可以当做是再温故知新一下
Ilya Sutskever出生于上个世纪80年代中期的俄罗斯
当时还是苏联
5岁的时候，他的家人移民到以色列
这在当时是许多欧洲犹太家庭的选择
当他读到八年级的时候
他开始在以色列的开放大学
攻读计算机科学学士学位
因为以色列开放大学接受任何人入学
不论你是否有高中学历
所以即使他才8年级也可以入学
另外
那里的主要学习方式是远程教育
在一次接受以色列开放大学的采访时
他是这样描述这段经历的
我没有把自己逼得太紧
我通常只选2到3门课
从不选更多的课程
在初中和高中时
我不太在意自己的成绩
他认为，远程学习非常适合他
因为他可以按照自己的节奏来学习
之后，Ilya去了加拿大学习数学
在2005年他获得了学士学位以及硕士学位
最后在多伦多大学师从Geoffrey Hinton
获得了博士学位
他的博士论文正是如何训练循环神经网络
在此期间
Ilya和亚历克斯·克里热夫斯基Alex K
以及Geoffrey Hinton
一起完成了题为《使用深度卷积神经网络进行ImageNet分类》这篇著名的AlexNet论文
这篇论文的特别之处在于
尽管Yann LeCun和Yoshua Bengio在1995年发表的题为《用于图像、语音和时间序列的卷积网络》的论文中
为深度学习提供了基础理论
但是这是第一次使用深度学习来解决有监督的计算机视觉问题
2012年12月
Ilya参与成立了一家名为DNNresearch的公司
其实本质上就是Hinton在多伦多大学所从事研究工作的一个衍生项目
仅仅四个月后
这家公司就被Google收购了
随后的3年时间，他一直在Google工作
用他自己的话说
我是Google的一名研究员
当时我正在研究深度学习
我非常开心
然后在2014年的一天
他收到了一封陌生邮件
邀请他与Sam Altman、Greg Brockman以及Elon Musk共进晚餐
讨论的主题是
如何能创办一个能与Google和Deepmind竞争的人工智能实验室呢？
马斯克当时是这么说的
因为Google是闭源的
以盈利性为目的的
所以Google的对立面应该是一个开源的、非盈利的组织
不过
从头创办一个新的人工智能实验室的想法
对Ilya还是非常有吸引力的
即使在2014年的时候
Ilya就已经是深度学习的忠实信徒
但是他对AI有着更大、更深的野心
他曾经说过
研究人员在某种程度上被训练成要从小处着手
由于工作的性质
这种小思维会得到奖励
但是在OpenAI
我们有幸能够着眼于更大的宏伟蓝图
这个AI实验室的最终目标
是认真对待通用人工智能
也就是AGI的理念
因此在2015年
这群人在另一群人的投资下
成立了名为OpenAI的非营利人工智能实验室
而Ilya的加入非常重要
马斯克在最近的一次采访中是这么说的：
我在招募关键科学家和工程师方面发挥了重要作用
尤其是Ilya
事实上，Ilya来来回回犹豫了好几次
他曾经说他要加入OpenAI
然后现在DeepMind的CEO Demis Hassabis又说服他不要加入
这种情况来回发生了好几次
最终他决定加入 OpenAI
Ilya的加入是OpenAI最终能够取得成功的关键原因
在加入OpenAI之后
作为OpenAI的首席科学家
Ilya贡献了多项突破性的研究成果
但是最重要的应该是两个
一个是2017年的情感神经元论文（Sentiment Neuron Paper）
一个就是2022年的ChatGPT了
首先我们来看情感神经元论文
这个想法是训练一个AI模型
去成功完成一项特定的任务
然后尝试了解模型是如何擅长完成这个任务的
你可以想象一只经过训练的猴子
喜欢吃某些水果
但是不喜欢其他的水果
那么我们能否对它的大脑做一些神经科学研究
单纯地通过观察猴子的大脑活动
来弄清楚并且解释这个决策是如何做出的呢？
Ilya和团队发现
如果我们试图解决这样的问题
可能会在猴子的大脑中
发现一个单一的神经元
由它来决定猴子是否喜欢芒果
你可以想象一下
猴子大脑中的一个神经元
当猴子食用甜食或者含糖的水果的时候
这个特定的神经元会被激活
按照完全相同的方式
Ilya和他的团队训练了一个神经网络模型
用来生成亚马逊网站上的评论
并且发现有一个单一的神经元
可以“恢复情感的概念”。
这篇题为《学习生成评论并发现情绪
Learning to Generate Reviews and Discovering Sentiment（2017）》的论文
首先训练了一个递归神经网络语言模型LSTM
为各种在线网站
比方说亚马逊购物网站、IMDB电影网站等等
来生成用户评论
一旦他们在这个模型上取得了良好的性能
就会观察单个神经元的激活
并且发现了一些令人着迷的东西
其中
有一个神经元学会了对每次向前传递的情绪分析任务
进行分类
这种神经元在情绪分析任务的表现
优于大多数最先进的模型
Ilya在论文中写道
为什么我们的模型可以以如此精确、可解释和可操纵的方式
恢复情感概念呢
这是一个悬而未决的问题
在此基础上，更是形成了一个假设
那就是如果我们训练一个AI模型
来执行任务A，为了解决任务 A
这个模型就应该有能力学习解决更简单的任务B
这表示模型应该具有学习泛化的潜在能力
那个时候
虽然Ilya已经对监督式深度学习有了坚定的信念
但是这让他对无监督式深度学习更加充满希望
于是，Ilya和他的团队
在OpenAI开始用更大的模型和更复杂的任务
来测试这个假设
其次是ChatGPT
ChatGPT是OpenAI在2018年开始的一项工作的成果
目的将工作从情感神经元论文扩展到更复杂的任务
不过这一次
他们没有像上次那样去生成评论
而是专注在更加通用的任务上
比方说问答、语义相似性评估、文档分类等等
这次迭代的第3版和第4版
最终形成了我们现在所知道的ChatGPT
其中，GPT的论文最早发表于2018年
标题为《通过生成预训练提高语言理解
Improving Language Understanding by Generative Pre-Training》，
这篇论文建立在Google一年前推出的自注意力机制之上
并且将模型预训练作为学习文本信息的手段
GPT-2于2019年发布
这是OpenAI最后一个完全以开源方式发布的模型
同时也公开了模型权重
GPT-3于2020年6月发布
这次面向大众只发布了一个论文
由于潜在的危险
他们已经开始规范对人工智能的访问
2022年11月
GPT-3.5终于以ChatGPT的名义向公众发布
这是一个建立在GPT-3之上的混合模型
带有基于人类反馈的强化学习RLHF
主要针对聊天格式的回答进行了微调
GPT-4于2023年3月14日发布
这次连模型的技术规范都没有公布
从中可以看出一个明显的规律是
OpenAI越来越倾向于规范模型的发布
甚至都没有提到GPT-4参数总数
那么
这一切与Ilya的思考过程有什么关系呢？
这里主要有两点
首先是模型的性能
大型语言模型具有解决任务的能力
这是由于在模型架构内的一个迷你世界模型
这个模型用来生成输出
正如Ilya自己所说的那样
足够好地预测下一个Token意味着什么？
意味着你了解导致生成这个Token的潜在现实
其次是Ilya开始公开表示对AI的担忧
OpenAI内部的团队非常公开地承认了人工智能的潜在危险
特别是像ChatGPT这样的消费型人工智能
并且很乐意去监管那些可能会产生潜在危险的的信息
我们现在都已经知道
在ChatGPT发布之后
它成为了历史上用户增长速度最快的消费型软件工具
新闻文章、公开采访、炉边谈话、参议院听证会
突然之间
好像每个人都对人工智能有了看法
甚至很多人联名写了一封公开信
要求暂停大型AI实验6个月
那么在这种情况下
Ilya决定要怎么做呢？
2023年8月14日
Ilya在西蒙斯计算理论研究所发表了一场演讲
他以OpenAI典型的缄默语调
暗示了相关内容
他的原话是
我们在OpenAI所做的很多技术工作
我都不能说
现在，甚至从不久前已经开始
我把所有的研究重点都转到了人工智能对齐上
好了
如果我们对Ilya的行动信以为真
那么对于OpenAI的内部来说
对危险的人工智能会出错的担忧程度
似乎已经足够严重
以至于需要他们的首席科学家
专注在对齐方面取得进展
在2023年旧金山对齐研讨会的开幕致辞中
Ilya曾经说道
解决对齐问题并不是一件小事
同年7月5日
OpenAI在题为《介绍超级对齐》的博客中指出
将在未来四年内
将20%的计算资源用于解决超级智能对齐的问题
可惜，如今还没一年
超级对齐团队已经土崩瓦解
物是人非
OpenAI内部也已经没有人再能够去阻挡Sam Altman前进的步伐
Ilya接下来的工作方向
也无时无刻不牵动着大家的注意
不过，Ilya也曾经说过一句
只有变化是唯一的不变
最后大飞我希望
无论人工智能和OpenAI这些公司如何发展
无论AGI是否到来
这个频道能一直陪伴着大家
和大家一起见证这些历史的瞬间
可能也是这个频道的一种价值吧
感谢大家观看本期视频
我们下期再见
