大家好，这里是最佳拍档，我是大飞
今天是一期论文解读
有的观众可能知道，最近
大语言模型在处理表格数据方面取得了一些进展
这主要得益于程序辅助机制的引入
这些机制能够操纵和分析表格数据
不过
这些方法往往需要将整个表格作为输入
于是会带来位置偏差和上下文长度限制而导致的可扩展性问题
而且如果表格太大了
输入起来也会很麻烦
容易出错，那能不能再简单一点呢？
当然可以，为此谷歌推出了Table RAG
一个专门为表格理解而设计的检索增强生成框架
它可以通过查询与单元格检索的结合
在提供信息给大语言模型之前
精准定位到关键数据
从而实现更高效的数据编码和精确检索
大幅缩短提示长度
并且减少信息丢失
在谷歌的实验数据中显示
Table RAG的检索设计
在大规模表格理解任务中表现卓越
已经可以达到业界领先的水平
在开始介绍Table RAG以前
我们先来了解一下
传统的大语言模型是如何处理表格的
传统上
我们在使用大语言模型进行表格理解任务的时候
往往会选择将整个表格喂给模型
然后让它自己进行理解
但是这种方法存在着不小的局限性
首先
这个方法受限于模型本身的上下文长度限制
比如说
一个包含100列和200行的表格
单元格数量会超过40,000个
这就已经超出了LLaMA和GPT等模型的处理能力
此外，哪怕你的表格没那么大
只是稍微有一点点大
那也会因为上下文过长
导致推理能力惨遭削弱
最后，哪怕是你的表格满足了要求
不会降低推理能力了
但是随着表格尺寸的增加
计算成本和延迟也会显著上升
最终的结论就是，大的算不了
小的没太大必要，还有点小贵
因此，有人针对大型表格的理解任务
提出了一些新的方案，比如截断表格
或者仅读取表格的Schema
但是这种方法往往会丢失关键的信息
除此之外
还有人试图通过检索关键行和列
来构建一个包含回答查询所需要的基本信息的子表
再将整行和整列内容编码成稀疏或密集的嵌入
从而减少模型的token成本
但是这种方法也有两个问题
首先是对于包含数百万单元格的大型表格来说
这种做法并不现实
其次是将较长的行和列
压缩成固定大小的嵌入
可能会丢失语义信息
尤其是当表格包含多样化或者语义上不太丰富的内容的时候
因此，基于这些问题
Google DeepMind等团队联合提出了Table RAG方法
Table RAG融合了模式检索与单元格检索
可以从表格中提取出核心信息
使得模型Agent能够根据这些信息来回答查询
同时
Table RAG也提高了编码和推理上的效率
在Arcade QA数据集上的检索结果显示
Table RAG在列和单元格检索方面
都优于其他方法
并且进一步增强了后续的表格推理过程
我们再来说说Table RAG的核心工作流程
首先，问题通过大语言模型
被扩展为多个模式和单元格查询
这些查询依次用来检索Schema和单元格配对
随后，每个查询的前K个候选项
会汇总成提示词
提供给大语言模型生成对应答案
而高效处理表格的关键
就在于如何精确地识别出查询所需要的列名和单元格的值
与传统的表格理解任务不同的是
Table RAG会单独针对Schema和单元格
分别生成独立的查询
比方说
对于问题“钱包的平均价格是多少？
”，通过大语言模型会生成针对列名
比如“产品”和“价格”的潜在查询
以及针对相关单元格的值
比如“钱包”的查询
这些查询都会用来从表格中检索出相关的模式和单元格值
而在生成查询之后
Schema检索会通过预先训练的编码器fenc
获取相关的列名
fenc会对查询进行编码
并且与编码的列名进行匹配
从而确定二者的相关性
检索到的Schema数据包括列名、数据类型和示例值
检索到之后
Table RAG会再汇总每个查询的前K个检索结果
并且根据接近查询的相似度进行排序
在Schema检索之后
Table RAG会提取回答问题所需要的、特定的单元格的值
单元格检索的作用在于两方面
一是进行单元格识别
让模型能够精确地检测到
表格中特定关键词的存在
比如，区分“tv”和“television”，
从而确保搜索和操作会涉及到的精确的数据条目
二是将特定的单元格与相关的列名关联起来
这对于处理特定属性的问题至关重要
比如将“钱包”与“描述”列关联
从而实现行索引
单元格检索在通过单元格的值进行索引的时候
会特别有用
比方说，要回答“平均价格是多少？
”这类问题
只需要识别与价格相关的列名即可
因为平均值的实际计算可以由程序来处理
不过有的时候
操作者可能会比较懒惰
或者因为懒得改变之前的习惯
所以会将整个表格都喂给模型
这样的话
不同值的数量与单元格的总数是相匹配的
为了在这种情况下保持Table RAG的可行性
开发人员们引入了一个单元格编码预算B
如果不同值的数量超过B
就会将编码限制在出现频率最高的B对
这样一来
Table RAG即使在面对大型表格的时候
也能保持可控的成本，优化计算资源
缩短大规模表格理解任务的响应时间
可是，省了时间省了成本
效果到底怎么样呢
根据论文的结论来看
Table RAG的表现并没有一开始想的那么糟糕
反而有些出乎作者的预料
首先在检索性能方面
Table RAG展现出了不错的成绩
在列检索方面，由于列数较少
所有方法都实现了较高的召回率
但是Table RAG在两个数据集上展现了更高的精确度
这表明它在快速识别最相关的列上
非常有效
在单元格检索方面
Table RAG在所有指标上都持续超越了其他方法
而且在单元格检索的高召回率上
也比其他表格提示方法有了显著提升
这说明它能够检索到后续推理所需要的大多数单元格
总的来说
称得上是目前最优秀的表格检索
而在回答准确性方面
研究人员也对Table RAG进行了多轮测试
在Arcade QA和Bird QA上
Table RAG超过了所有其他的语言模型
达到了最高的准确率
具有明显的优势
而同样采用Table RAG框架的三种语言模型中
GPT 3.5 Turbo无论采用哪种表格提示方法
都能够稳定的提供最佳性能
说到这里
可能有敏锐的观众会注意到
我们之前讲到的
把整个表格全都喂给大语言模型的传统方法
劣势只是在表格比较大的时候
那么现在的Table RAG
在小表格方面还有优势么？
对此
研究人员也是做了相关的研究测试
为了探究在相似条件下
不同表格大小对Table RAG的性能影响
研究人员基于TabFact创建了一系列的合成数据
表格尺寸从50×50到1000×1000不等
而正如预料的一样
全表阅读的方法在一开始确实表现出众
甚至略微超过了Table RAG
但是随着表格尺寸的增加
它的准确性急速下滑
在表格尺寸达到100的时候
就已经彻底不行了
这就是因为目前大语言模型上下文长度的限制
而TableRAG展现出了更为稳定和可伸缩的性能
即使在表格尺寸增加到1000行和列的时候
性能也只是适度的下降
从83.1%降到了68.4%，
证明了它在处理大型表格方面的有效性
只不过表格增大所带来的失误风险
也是必然存在的
因此随着表格越来越大
正确率也会逐渐的下滑
大家在实际使用中还是要注意
那作为一个新出现的表格处理框架
Table RAG跟其他的表格处理框架相比
是否也具有足够的优越性呢？
既然我们要引入辅助框架
那自然是应该选择最好的
于是研究人员们将Table RAG与世界上的其他先进技术进行了比较
包括TaBERT 、Text-to-SQL 、Binder 和Dater
结果是，Table RAG以微弱的优势
超过Binder 56.74的得分
取得了第一的得分，57.03
除了性能上的表现以外
Table RAG在输出的时候
也提供了不少的可选项的
首先就是更换检索结果数量
也就是K值
这张图，是改变Top检索结果K的数量
对性能和后续语言模型推理的token成本的影响
可以看到，在增加k值之后
性能并没有跟着一起增加
而且较大的K值虽然允许模型访问更多的信息
但是也导致了更长的上下文
可能会加剧中间损失
甚至影响输出的质量
不过Table RAG可以通过减少K值
降低所需要的上下文token数量
来减少后续推理的成本
其次是对检索方法进行更换
也就是说
同样是在Table RAG的框架之下
但是采用了不同的检索方法
比如著名的BM25方法
这是一种著名的基于统计的检索方法
效率上表现出色
能够处理所有的单元格
不过由于它缺乏语义理解能力
最终成绩上仍然是逊色于混合方法和嵌入式的检索方法
但是嵌入检索因为编码的限制
无法处理整个表格
而在编码预算方面
与刚才的检索方法情况类似
虽然更高的预算
理论上允许检索更多信息
但是结果表明
这并不总是会导致更好的性能
研究人员通过对比
研究了Table RAG和Row Col Retrieval
在不同编码预算下的性能
发现在高编码预算的情况下
Row Col Retrieval的性能反而有所下降
整体数据呈现了一个突起的弧线形状
论文作者推测
可能是因为检索到了更多的行
使得选择正确的行变得更加复杂
并且产生了来自于更长列的噪声嵌入
而Table RAG在不同编码预算下
基本保持了一致的性能
说明它通过单元格频率来构建语料库的方法
即使在有限的编码预算下
也能够有效地捕获基本信息
好了，以上就是对Table RAG的介绍了
作为一种新形态的表格处理框架
Table RAG本质上仍然是大语言模型的一种辅助机制
让大语言模型可以更好地处理一些、原本不属于“自然语言”的部分
它的出现
也说明大语言模型在生态上的逐渐完善
以及在解决现实问题上的进步
AI正在逐渐渗透到更加垂直的特定领域问题上
相信以后我们会看到更多类似辅助框架的出现
感谢大家的观看，我们下期再见
