大家好，这里是最佳拍档，我是大飞
今天来给大家介绍一篇跟视频生成模型有关的论文
不知道大家还记不记得
当Sora横空出世的时候
OpenAI 在宣传页面上曾经写过这么一句话
提升视频生成模型的参数与数据量
为构建物理世界通用模拟器
提供了一条可行之路
这句话当时给大家带来了很大的希望
但是与此同时
业内的质疑声音也一直没有断过
很多人都不相信基于 DiT 架构的视频生成模型
能够真正的理解物理规律，于是
AI行业里就掀起了一场“视频生成模型到底懂不懂物理规律”的争论
图灵奖得主杨立昆（Yann LeCun）明确地表示
即使是基于文本提示生成了逼真视频
也并不代表模型就真正理解了物理世界
他更是直言
像Sora这样通过生成像素来建模世界的方式
注定要失败
但是Keras 之父弗朗索瓦·肖莱（François Chollet）则认为
Sora 这样的视频生成模型
确实嵌入了“物理模型”，但是问题是
这个物理模型是否足够准确呢？
它能否能泛化到新的情况
也就是那些训练数据插值以外的情形呢？
这些问题的答案非常关键
决定了视频生成模型的应用范围
到底是只能用于媒体制作
还是可以用来模拟现实世界呢？
关于这个问题的争论
业界一直没有个统一的说法
直到最近
字节的豆包大模型团队出于好奇
历经 8 个月的时间
完成了一项针对这个问题的系统性研究
总算是给这个争论画上了一个不等号
实验结果明确表示
视频生成模型目前虽然可以生成一些、看似符合常识的视频
但是还没有办法理解真实的物理规律
研究团队通过大规模的实验
发现就算按照Scaling Law去扩大模型的参数和训练数据量
模型还是没办法抽象出一般的物理规则
甚至就连大家中学物理就学过的牛顿第一定律、抛物线运动这些都搞不明白
这就好比一个学生
只会照着答案“抄作业”，
一旦遇到没学过的问题
就完全“抓瞎”了
这项研究结果在 X 平台上发布之后
杨立昆不仅点赞转发
还评价说这个结果一点也不意外
同时
谢赛宁和加里·马库斯（Gary Marcus）等人也都关注了这个事情
接下来，我们就来聊聊这篇
题目为《视频生成距离世界模型还有多远：
站在物理定律的视角》的研究论文
首先得说
这次研究中有个很大的挑战
那就是怎么去定量分析
视频生成模型对物理规律的理解程度呢？
为此
研究团队专门开发了一个物理引擎
用这个引擎合成了一些经典物理场景的运动视频
比如匀速直线运动、小球碰撞、抛物线运动等等
然后再用这些视频去训练基于主流 DiT 架构的视频生成模型
最后通过检查模型生成的视频
在运动和碰撞方面是不是符合力学定律
来判断模型到底有没有真正理解物理规律
以及有没有成为“世界模型”的潜力
针对视频生成模型在学习物理定律时的泛化能力
团队又探讨了三种场景的表现
第一种是分布内泛化
In Distribution，简称ID
指的是训练数据和测试数据来自同一分布
第二种是分布外泛化
Out of Distribution
简称OOD
指的是当模型面对从来没有见过的新场景时
能不能把学过的物理定律用上去
这也是衡量模型是否学到物理规律的重要标准
第三种是组合泛化
这种情况介于 ID 和 OOD 之间
在训练数据里包含了所有的“概念”或者物体
但是这些东西没有以所有可能的组合、或者更复杂的形式出现
在基于视频的观察中
每一帧就代表一个时间点
物理定律的预测
就是根据过去和现在的帧来生成未来的帧
所以研究团队在每个实验里
都训练了一个基于帧条件的视频生成模型
再用它来模拟和预测物理现象的变化
这样一来
通过测量生成视频每个帧里物体位置的变化
就能够判断物体的运动状态
再和真实模拟的视频数据比一比
就能知道生成的内容
是不是符合经典物理学的方程了
我们先说分布内泛化和分布外泛化的实验
在设计方面
团队重点关注了由基本运动学方程支配的确定性任务
这些任务能够清楚地定义分布内和分布外泛化
而且能够很直观地评估误差
团队选择了三种物理场景来评估
每种运动都是由它的初始帧决定的
先说匀速直线运动
比如一个球在水平方向移动
速度一直保持不变
这就能体现出惯性定律
再看完美弹性碰撞
两个大小和速度不一样的球
在水平方向相向运动然后碰撞
这体现的是能量与动量守恒定律
还有抛物线运动
一个带着初始水平速度的球因为重力作用下落
这符合牛顿第二定律
从实验结果来看
在分布内泛化的测试中
团队发现随着模型规模的增大
例如从 DiT - S 到 DiT - L
或者随着训练数据量的增加
比如从 30K 到 3M
模型在三种物理任务里的速度误差都降低了
这说明模型规模和数据量的增加
对分布内泛化很重要
就像你要盖高楼，地基打得越大越稳
楼就能盖得越高越安全
但是，分布外泛化的结果却相当明显
首先是在所有设置里
OOD 的速度误差比 ID 高出了一个数量级
其次是扩展数据和模型规模
对降低 OOD 的误差几乎没什么作用
其实这种情况也可以理解
毕竟从数据中提炼出精确的物理规律
对人类来说也是非常困难的
只不过人类可以通过组合过往的经验
来预测将要发生的事情
接下来，针对组合泛化的场景
团队用 Phyre 模拟器来评估模型的组合泛化能力
Phyre 是一个二维模拟系统
里面有球、罐子、杆子、墙壁这些东西
它们有的是固定的，有的是动态的
还能互相碰撞、有抛物线轨迹、旋转这些复杂的物理交互
不过系统里的底层物理规律是确定的
在视频数据构造方面
每个视频考虑了八种物体
包括两个动态的灰色球、一组固定的黑色球、一个固定的黑色条形、一个动态的条形、一组动态的立式条形、一个动态的罐子和一个动态的立式棍子
每个任务里包含一个红色球
以及从这八种类型里随机选的四个物体
这样总共能形成70种独特的模板
对于每个训练模板
团队保留了一小部分视频
用来创建模板内的测试集
再保留了10 个没用过的模板
用来做模板外测试集
这样就能评估模型对训练时、没见过的新组合的泛化能力了
从数据上看
当模板数量从 6 个增加到 60 个的时候
所有度量指标
包括FVD、SSIM、PSNR、LPIPS在模版外的测试集上
都有显著的提升
特别是异常率
也就是生成视频违背物理定律的比例
从 67%大幅下降到 10%。
这说明当训练集覆盖了更多组合场景的时候
模型有更强的泛化能力
不过，在模板内测试集里
模型在 6 个模板的训练集上的 SSIM、PSNR 和 LPIPS 这些指标表现最好
因为每个训练示例都被反复展示了
这些结果表明
模型容量和组合空间的覆盖范围
对组合泛化非常关键
这也意味着视频生成的 Scaling Law
应该更加注重增加组合的多样性
而不只是扩大数据量
总得来说，研究团队的实验发现
就算按照“Scaling Law”来增加模型参数规模和数据量
模型还是没办法真正“理解”物理规律
就拿最简单的匀速直线运动来说
模型在学习了不同速度下
小球做匀速直线运动的训练数据后
给它初始的几帧
让它生成小球在训练集速度区间内匀速直线运动的视频
随着模型参数和训练数据量的增加
生成的视频会越来越符合物理规律
但是
如果要让它生成没见过的速度区间的运动视频
也就是超出训练数据范围的视频
模型就突然不遵守物理规律了
而且不管怎么增加模型参数或者训练数据
结果都没什么明显改进
这就说明
视频生成模型根本没有真正的理解物理规律
也没办法把这些规律用到全新的场景里
不过
如果模型对训练视频里所有的概念和物体都已经熟悉了
这时候加大训练视频的复杂度
比如增加物体间的物理交互
或者增加训练数据
模型对物理规律的遵循就会越来越好
那么为什么会这样呢？
研究团队也探究了背后的机理
他们首先用匀速运动的视频来训练
速度范围在2.5到 4.0之间
用前 3 帧作为输入条件
用两个数据集进行训练
其中Set - 1 只包含从左到右移动的球
Set - 2 则包含从左到右和从右到左移动的球
实验发现，当给定低速正向
也就是从左到右运动的帧条件时
Set - 1 模型生成的视频只有正速度
而且偏向高速范围
相比之下
Set - 2 模型偶尔会生成负速度的视频
研究团队认为
这可能是因为模型觉得
和低速球更接近的是训练数据里反向运动的小球
导致模型受到了训练数据里“误导性”示例的影响
也就是说
模型更多是靠记忆和案例的模仿
而不是抽象出普遍的物理规则
来实现分布外泛化的
那么模型是靠什么属性来寻找模仿对象的呢？
通过对比颜色、形状、大小和速度四个属性后
研究团队发现
基于扩散技术的视频生成模型
天生更偏向于形状以外的其他属性
这也能解释
为什么现在在开放数据集上训练的视频生成模型
在形状的保持上经常有困难
比如这里第一行是真实视频
第二行是视频模型生成的内容
可以看到颜色很好的保持了一致
但是形状则难以保持一致
其次，经过两两对比
团队发现视频生成模型更习惯通过“颜色”来寻找相似参考
从而生成物体的运动状态
其次是大小
然后是速度，最后才是形状
而对于复杂的组合泛化，团队提出
视频模型有三种基本的组合模式
分别是属性组合、空间组合和时间组合
实验结果发现
对于速度与大小或者颜色与大小这些属性对
模型有一定的组合泛化能力
而且模型能够对训练数据的局部片段
在时间和空间维度进行再组合
但是要注意的是
不是所有情况都能通过组合泛化
来生成符合物理规律的视频
模型对案例匹配的依赖会限制效果
在不了解底层规则的情况下
让模型检索并组合片段
可能会生成不符合现实的结果
除此以外
研究团队还探索了模型在视频表征方面的局限性
结果发现
视觉模糊性会导致模型在细粒度物理建模方面
出现明显的误差
比如说物体的尺寸差异只有像素级别的时候
光靠视觉来判断一个球能不能通过间隙
就很困难
可能会导致看起来合理、但是实际上错误的结果
这些发现都表明，单纯依赖视频表示
是不足以进行精确的物理建模的
好了，以上就是对论文内容的介绍了
最后介绍一下这个论文的核心作者
一共有两位
其中一位是95 后研究员康秉义（Bingyi Kang）
他之前负责的研究项目“Depth Anything”被收入了苹果的 CoreML 库
另一位作者乐（抱歉口误，应该发音Yue）杨是00 后
目前是清华自动化系的博士生
曾经获得过全国大学生数学竞赛一等奖
以及多次国家奖学金
二人之前都曾经在新加坡Sea AI实验室工作
那大家对这篇论文有什么看法呢？
欢迎在评论区留言，感谢大家的观看
我们下期再见
