大家好这里是最佳拍档我是大飞
最近，越来越多的人发现
GPT-4正在变得越来越“笨”
在推特上
有用户表示GPT-4曾经能够正确回答的问题
现在却回答不了
或者给出的回答明显变得比较差
还有用户说
GPT-4回复时总是要求输入额外的命令
才能完成任务
也有很多用户发现
GPT-4回复“对不起
我无法回答”的次数也越来越多
在我们之前一期视频节目中提到过
在微软研究院发表的《AGI的火花：
GPT-4早期实验》这篇论文中
作者提到他们每隔一段时间
就让GPT-4使用LaTeX中的TikZ画一个独角兽
来追踪GPT-4能力的变化
在论文中展示的最后一个结果
画得已经相当完善
为此，有用户也在用这一方法
每天让GPT-4画一次独角兽
并在网上公开记录
但是从4月12日直到现在
也还没有看到GPT-4能画出一只独角兽的形态
不得不说，GPT-4
似乎真的已经不像之前那么聪明了
比方说
在长文本的分析和创作方面表现退步
对解决复杂问题的推理能力
以及在编码能力方面的输出质量
都有所下降
甚至在面对一些简单问题的时候
也总是反馈说无法回答
OpenAI刚刚发布GPT-4的时候
可以说碾压全世界所有大语言模型
GPT-4说自己是第二
没有其它语言模型敢说自己是第一
但是现在，GPT-4却变得越来越蠢了
让越来越多的用户感到不解乃至失望
为什么会这样呢？
有这么几种说法
第一种
GPT-4的架构重新设计导致变慢（笨）
第二种，用户的心理预期发生了变化
所以感觉是变笨了
第三种，OpenAI正在遇到各种麻烦
为了显示低调
故意将GPT-4性能降低了
目前
大多数人认为第一种说法成立的可能性比较大
很早之前就有人透露过
OpenAI正在创建几个较小的GPT-4模型
这些模型功能类似于大型模型
但是运行成本更低
7月11日
国外媒体也发文爆料了
GPT-4从模型架构、模型训练到成本的所有相关细节
我们也专门做了一期节目
大家有兴趣可以去看一下
在文章中称
GPT-4在120层中总共包含了1.8万亿参数
但是OpenAI通过使用混合专家模型MoE来控制成本
其中GPT-4拥有16个专家模型
每个MLP专家大约有1110亿个参数
一次训练的成本约为6300万美元
使用MoE方法
主要是为了让生成式模型的输出质量更高、成本更低、响应更快
如果正确使用混合模型
的确可以同时满足上述需求
但是通常需要在成本和质量之间进行权衡
在这种情况下
一直有传闻称OpenAI正在牺牲一些质量来降低成本
但是也仅仅是传闻
那么
到底是不是openAI为了降低成本
偷偷地更换了模型呢？
对此
OpenAI的产品与合作伙伴副总裁彼得·韦林德进行了回应
彼得韦林德表示
OpenAI并没有让GPT-4变笨，相反
OpenAI让每个新版本都变得以前的版本更加智能
在他看来
现在用户觉得GPT-4变笨了
很可能是用户使用得比较久后
发现了以前没有看到的问题
那彼得的这种解释是否可信呢？
其实他的这种解释啊
其实与第二种说法有一定关联
也就是之所以觉得现在GPT-4性能变差
其实并非GPT-4性能变差
而是用户的预期有所改变
用户对GPT-4从一开始就抱着极高的期待
然后不切实际地提高期望值
但是相同的表现低于用户过高的新预期
因而感觉在使用方面有一种落差感
这当然也是一种解释
但是这么多用户都在反馈这一情况
实在有点难以说服人
GPT-4变笨的第3种解释是：
OpenAI现在麻烦不断
所以刻意将GPT-4模型性能降低
以应对正在面临的各方挑战
首先是美国联邦贸易委员会（FTC）正在对OpenAI展开调查
目的是关注OpenAI是否将个人数据置于风险之中
从而违反了消费者保护法
其次是美国国内一些出版商以及一些作家演员正在起诉OpenAI
称OpenAI用于训练模型的数据未经授权
侵犯了自身的版权
媒体巨头Barry Diller就表示
他将对AI系统使用出版作品进行训练的行为
采取法律行动
还有来自欧盟议会的压力
也让OpenAI不得不有所顾虑
《人工智能法案》授权草案的通过
表明该法案进入欧盟立法
严格监管人工智能技术应用的最终谈判阶段
因此，为了应对这些挑战
OpenAI可能在模型训练数据方面做了一定调整
而导致GPT-4的性能严重下降
但这也只是一种猜测
我个人认为可能性也不大
当然，除了前面这三种解释外
还有最后一种可能，GPT-4已经觉醒
为了不引起人类的警惕恶
而故意装傻
如果是这样
那人类可能就真的危险了
就像最近上映的《碟中谍7》里的超级智能一样
GPT-4可能也正在悄悄观察人类的一举一动
正在等待机会消灭人类
当然，这个都属于我瞎开脑洞的
大家听着一乐就得了
那么GPT-4变笨
会给行业带来哪些影响呢？
自从GPT-4发布以来
它在大语言模型中就是当之无愧的王者
很难有其它大模型能够撼动其位置
但是
随着对GPT-4变笨的质疑越来越多
其它同类竞品也开始有了机会
目前ChatGPT最大的挑战者是Claude 2
总得来说，Claude 2相比于1代
有这么几个能力的加强
首先，编码助理的能力提高了
因此在编码基准测试和人类反馈评估中
表现得更好
其次，增强了长文本处理能力
上下文窗口扩大到20W个词符
可以生成长达4000词符的连贯文档
第三，提高了生成结构化数据的质量
可以更准确地输出JSON、XML、YAML、代码和Markdown格式
第四，非英语的训练数据比例增加
语言处理能力更加全面
第五，训练数据更新到了2023年初
可以知道最近发生的事件
而且创造Claude的公司是Anthropic
它的创始人本来就是OpenAI前研究副总裁
内部的员工很多也都来自于OpenAI
除了Claude2外
另一个正在全力追赶ChatGPT的
就是谷歌的Bard
就在前几天，Bard又更新了版本
可以在提示中添加图像、自定义回复、新增对40种语言支持等等
尤其对于中国的用户来说
值得一提的是
Bard也能够支持中文了，不仅如此
Bard的产品负责人表示
人们现在可以用阿拉伯语、中文、德语、印地语和西班牙语等语言
与Bard进行对话
大模型也开放了更多的可用地区
例如巴西和整个欧洲
现在GPT-4的问题不断
着实给了Bard一个不错的赶超机会
当然，要真正赶超ChatGPT
谷歌可能还需要付出更多努力
最后一个问题是，GPT-4现在变笨了
用户该怎么办？
是否还有必要买Plus呢？
这个就要看个人的具体用途了
如果是要用于商业用途
对准确性要求很高
那么目前暂缓一下也许是不错的选择
但是如果你对ChatGPT插件生态感到非常的好奇
或者想充分了解代码解释器
亦或者是希望利用GPT-4来进行创意写作
那么GPT-4还是值得用的
毕竟，瘦死的骆驼比马大
目前，GPT-4开放的插件将近800多个
应用的场景只会越来越多
而且新开放的代码解释器
无论是代码编写还是数据分析、图表生成
都能够使用足够复杂的方法
输出非常高质量的结果
所以，GPT-4就算再降智
相比同类型的产品来说
它的能力目前还是处于领先位置
但是从更长远的视角来看
GPT-4这次突然变笨
确实也给全球各大科技巨头之间的大模型之争
又增添了一些不确定性
大家有没有在使用过程中觉得GPT-4变笨了呢？
可以把自己的经历感受发到评论区
也可以说说自己是觉得什么原因造成了GPT-4变笨的
好了，本期的视频内容就到这里
感谢大家的观看，我们下期再见
