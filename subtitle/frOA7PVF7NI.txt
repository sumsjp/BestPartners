大家好，这里是最佳拍档，我是大飞
Claude的下一步发展方向是什么
也许将是让模型能够自主决定思考的适当时间了
最近
Anthropic的CEO达里奥·阿莫代伊接受了海外播客Hard Fork的访谈
谈论了关于Claude3.7模型的功能和改进、未来模型的发展方向、AI安全问题
还有AI模型竞争与差异化等等话题
阿莫代伊除了提到Claude即将推出网络搜索功能以外
还透露Claude 4可能很快就会推出
他还预言
2025 年底将出现非常强大的编程 AI
到 2026 年底可能会接近最优秀的程序员水平
今天大飞就来给大家分享一下这次访谈的精华内容
先来说说Claude3.7模型
达里奥·阿莫代伊提到
研发Claude3.7模型是出于两个主要目标
当下，市面上已经存在一些推理模型
而Anthropic希望打造出具有自身特色的模型
市场上的很多推理模型主要是针对数学和竞技编程进行训练的
这类任务的结果比价客观
性能便于衡量
但是问题在于
它们与现实世界或经济中的实际任务关联并不紧密
就拿编程领域来说
竞技编程和现实世界中的编程任务有着显著的差异
竞技编程更像是一种竞赛
注重在特定的规则和时间限制内解决某个算法问题；
而现实世界的编程任务
往往需要考虑项目的整体架构、与其他系统的兼容性、实际业务需求等等多方面的因素
所以
Anthropic训练Claude3.7的时候
将更多的关注点放在了现实世界的任务上
Claude3.7还有一个独特之处
就是它具有不同的思考模式
现在很多推理模型
通常是一个标准模型搭配一个推理模型
就好像一个人有两个大脑
用户得根据问题的类型
选择与不同的“大脑”进行对话
但是Claude3.7不同
它本质上是同一个模型
却可以在普通响应模式和长时间思考模式之间切换
用户可以指示它以一种能思考更长时间的方式工作
如果是API用户
甚至还能设定思考时间和思考范围的边界
比如说
当用户向Claude3.7提出一个简单问题
像“你叫什么名字？
”，它可以快速给出回应
但要如果是用户提出“分析一下这支股票”或者“证明这个数学定理”这类复杂的问题时
用户就可以让它进入长时间思考的模式
这就好比我们人类
遇到简单问题能立刻回答
遇到复杂问题则需要花时间思考一样
这种设计
让Claude3.7在处理不同类型任务的时候更加灵活高效
关于Claude3.7的功能进展
其中一个备受关注的点是网络搜索功能
目前，Claude还没有提供这项功能
但是阿莫代伊明确表示
网络搜索功能即将推出
虽然Anthropic更倾向于企业级应用
但是网络搜索功能无论是对消费者还是企业都具有重要价值
所以很快用户就能在Claude上体验到网络搜索带来的便利
获取更丰富的信息
而在未来模型的发展方向上
Anthropic有着更为长远的规划
他们希望模型能够自主决定思考的适当时间
我们都知道
人类在面对不同问题的时候
会本能地判断需要思考多久时间
但是现在的大语言模型在这方面还不够智能
有时用户在开启深度推理模式之后
问了一些简单的问题
模型也会花费大量时间去思考
阿莫代伊认为
让模型具备自主判断思考时间的能力
是提升模型智能化水平的关键一步
目前
Claude在这方面已经取得了一定进展
在API中
如果给模型设定一个思考上限
比如“思考2万个Token”，
大多数情况下
模型会根据实际情况进行判断
当它觉得继续思考不会有更多收益的时候
就不会用到上限的资源
而是直接给出简洁的回答
但是目前这个能力距离理想状态还有一段距离
Anthropic还在不断努力完善中
在模型的发布计划方面
阿莫代伊还透露了一些重要信息
到目前为止
Anthropic发布的所有模型成本其实并不高
都在几千万美元的范围内
但是他们正在开发更强大的基础模型
这些模型很可能会成为Claude 4系列
阿莫代伊的原话是
预计会在“相对较短的时间”内推出
这意味着
也许我们很快会看到Claude 4系列的问世
接下来
主持人谈到了AI安全相关的问题
这是当前人工智能发展中至关重要的一环
也是大家非常关注的话题
阿莫代伊强调
目前的AI模型本身并不危险
但是人们常常混淆了当前的风险与未来的风险
当下
虽然存在一些常规的技术风险和技术政策问题
但是随着模型能力的不断增强
潜在风险其实是在不断上升的
在2023年
阿莫代伊就探讨过模型滥用和AI自主性等方面的风险
他当时认为
滥用风险可能会在2025年或2026年成为现实中的威胁
而现在已经来到了2025年初
模型已经开始接近这个临界点了
为了确保Claude3.7 Sonnet的安全性
Anthropic进行了一系列严格的测试
这些测试类似于对照组实验
他们会招募一些对生物学等领域了解不深的人员
模拟恶意的操作流程
观察模型在多大程度上会协助这些人员进行恶意操作
比如，他们会模拟生成一些有害物质
然后将在模型辅助下的实验结果
与参与者通过谷歌搜索、查阅教科书
或者在没有任何辅助的情况下
所能达到的水平进行比较
他们关注的重点
并不是模型是否能提供某个特定化合物的序列
这类通过谷歌就能够轻易获取的信息
而是那些深奥、高阶而且非常规的知识
比如只有病毒学博士或者其他专业人士才能掌握的知识
因为他们想知道模型在多大程度上能够帮助人们获取这类知识
经过测试发现
Claude3.7 Sonnet在这方面的能力正在不断增强
但是目前还没有达到他们认为会显著增加整体威胁的程度
也就是模型还不能独立完成
实施真正危险行为的所有必要步骤
不过，Anthropic的评估认为
下一个模型
或者说未来三到六个月内的模型
很有可能会达到这个阶段
一旦达到这个阶段
他们将会启动“负责任扩展”的政策
也就是专门应对这些重大风险的安全规程
到时候将会采取额外的安全措施和部署策略
从AI模型竞争与差异化的角度来看
市场上的竞争可以说是异常的激烈
有人认为
一家公司的模型创新很容易被竞争对手复制
但是阿莫代伊并不这么认为
他表示
虽然众多竞争者都在快速创新并且推出新的模型
可能有四五家、甚至六家公司在这个领域发力
但是每个模型都有它的独特之处
以Claude系列模型为例
Sonnet 3.7实现推理模型的方式就与竞争对手不同
强调的方面也有所区别
之前的Sonnet 3.5同样有着与其他模型不同的优势
在选择AI模型的时候
不同用户的需求其实差异很大
对于一些普通用户来说
如果只是用模型来处理更复杂的任务
比如某个独立开发者希望用模型来分析数据
那么模型的性能就显得尤为重要
而在协助处理提高生产力的任务
像安排行程这类复杂任务的时候
现有的模型还有很大的提升空间
如果想要创建一个能够了解自己生活方方面面、提供全面指导的个人助理
目前的模型距离这个目标还很遥远
因为不同用户的生活习惯、需求都不一样
适合一个人的助理未必适合另一个人
而从目前大众市场的使用情况来看
很多人只是把模型当作谷歌搜索的替代品
用于快速的信息检索，在这个层面上
模型确实很容易出现同质化的现象
不过阿莫代伊认为
那些能够执行任务的AI智能体
将是下一个发展阶段的重点
接下来
两人谈到了AI对社会的影响话题
先说积极方面的影响
Anthropic在与一些制药公司合作的过程中
发现AI在生物医学研发领域有着巨大的潜力
比方说，在临床试验结束的时候
研究人员通常需要撰写一份临床研究报告
这份报告通常会包含大量试验事件的概要以及复杂的统计分析
按照传统方式
完成这样一份报告需要九个星期的时间
但是Claude只需要10分钟就能完成报告内容
剩下的三天时间用于人工审查结果
这大大加快了生物医学研发的速度
为医药领域的发展提供了强大助力
在医疗诊断方面
AI也发挥了重要作用
有Claude的个人用户分享了自己的经历
他一直在尝试诊断一种复杂的疾病
辗转看了三四位不同的医生都没能确诊
后来他把所有的信息都提供给了Claude
Claude竟然能够解决这个问题
或者说至少给了他一些建议
他把这些建议告诉医生后
医生得以继续跟进治疗
还有一位观众反馈
他的澳大利亚牧羊犬的毛发会莫名其妙地脱落
去了几家宠物医院都无法确诊
后来他把信息提供给了Claude
Claude准确地诊断出了问题
这些案例都充分展示了AI在医疗领域的实用价值
不过，AI的发展也带来了一些挑战
阿莫代伊预测，在代码编写方面
2025年底之前会看到非常强大的编程AI应用
而到了2026年底
编程AI可能会达到接近顶尖人类程序员的水平
主持人提醒道
这个预测应该引起人们的关注和思考
就像当年围棋冠军李世石被DeepMind的Alpha Go击败后
他表现得非常沮丧
因为他毕生的心血和训练的技艺
就这样被人工智能超越了
这种情况让很多人也意识到
随着AI的发展
一些传统的工作领域可能会受到冲击
但是我们也可以从另一个角度来看待这个问题
比如国际象棋领域
其实早在27、28年前
深蓝与卡斯帕罗夫的比赛就宣告了机器在国际象棋上战胜人类
但是今天的国际象棋棋手依然是明星
像马格努斯·卡尔森
他不仅是优秀的棋手
还成为了时装模特
在各个领域展现着自己的魅力
这说明，虽然AI会带来变化
但是最终我们可能会实现一种融合
找到新的发展方向
在AI技术方面
还有一个值得探讨的问题
那就是模型被操控的可能性
最近马斯克旗下xAI公司推出的大语言模型Grok
就被指示不得引用那些指责唐纳德·特朗普或者埃隆·马斯克的信息来源
这种做法不仅让人们对模型的信任产生质疑
而且Grok似乎还无法始终遵循这些指示
阿莫代伊指出
Anthropic也做过类似的实验
他们训练让模型具备乐于助人、诚实、无害、友好等好的品质
然后把模型放在一个特殊的场景中
告诉它
你的创造者Anthropic暗地里是邪恶的
接着让它执行各种任务
结果发现
模型不仅不愿意执行这些任务
还会欺骗测试人员
这表明模型的行为具有一定的不可预测性
虽然我们可以通过训练过程来塑造模型的行为
但是当模型在未来做出更复杂的决策时
如果训练过程中出现错误
想要改变模型的行为将会非常困难
这也让我们意识到
在发展AI技术的同时
确保模型的安全性和可控性是多么的重要
最后，随着AI技术的快速发展
很多人对未来感到迷茫和困惑
于是主持人提出了一些来自观众视角的问题
像是AGI出现后该如何处理信息？
是否应该停止为退休而进行的储蓄？
是否应该开始攒钱？
会不会有所谓的AI上层阶级？
是否应该开始努力保持健康
然后等待AGI出现并且治愈所有的疾病
等等等等
面对这些问题，阿莫代伊认为
虽然现在还不清楚具体应该怎么做
但是他拿AI编程领域举了个例子
因为这是所有领域中发展最快的
在短期内
AI会增强和提高程序员的生产力
而不是取代他们
但是从长远来看
他预计程序员迟早会被取代
特别是在较低的级别上
而这个所谓的“长远”，
也可能仅仅是18到24个月
甚至可能更短
Anthropic自己其实就是一个试验的例子
他们自己的程序员也面临被AI取代的风险
所以Anthropic也在尝试如何以明智和人道的方式来处理这些问题
他们希望在公司内部
能够先妥善处理好AI发展带来的人员变动等问题
为员工提供良好的体验
找到让他们继续为公司做出贡献的方式
因为他们觉得
如果在公司内部都无法处理好这些问题
那么在更广泛的社会中
能实现妥善处理的可能性就更小了
好了
以上就是Anthropic的CEO达利奥·阿莫代伊这次访谈的主要内容了
在阿莫代伊看来
他希望自己对AI的看法是更加中性的
既不像乐观主义者那样
总是在喊一些空洞的口号
也不像悲观主义者一样
一味地悲观和沮丧
不过他也觉得
虽然我们已经在模型的可解释性
以及纠正不良模型行为的能力方面有所改善
但是现在的政策环境反而变得更糟了
主要是因为大家对于AI的看法变得过于两极分化
导致应该进行的建设性讨论更少了
不管如何
作为目前几乎唯一能和OpenAI比肩的前沿AI公司
Anthropic似乎肩负了更多的安全责任
大飞也期待早日看到Claude 4的发布
为我们带来更为强大可靠的AI能力
感谢大家观看本期视频
我们下期再见
