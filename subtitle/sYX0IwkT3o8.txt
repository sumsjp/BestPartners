大家好，这里是最佳拍档，我是大飞
Google DeepMind最新发布了一系列的机器人视频
在视频中
一个没有配备任何触觉传感器的类人机器人
仅仅凭借着视觉
就能精准抓起一根香蕉
而从来没有接受过篮球训练的机械臂
在第一次见到迷你篮筐时
就完成了标准的灌篮动作
这些看似简单的操作背后
实际上正暗藏着机器人技术发展的一个重大转向
那就是当业界还在比拼机器人的硬件性能时
DeepMind已经将核心竞争力转向了"机器人的心智进化"。
今天
我们将通过DeepMind的机器人研究负责人卡罗琳娜·帕拉达（Carolina Parada）
在DeepMind播客中的深度分享
来了解一下这场正在发生的技术革命
在我们大多数人的认知里
机器人可能就等同于那些在工厂里重复单调动作的机械臂
或者是科幻电影中具有人类外形的仿生机器
但是卡罗琳娜·帕拉达带领的团队
正在重新定义"机器人"的本质
她说道
我们不是在制造更灵活的机械臂
而是在构建能够理解、推理和自主行动的智能主体
这种认知转变始于对传统机器人技术瓶颈的深刻洞察
那就是即使是最先进的工业机器人
也只能在预设的环境中执行固定的任务
而在面对陌生场景的时候
往往是一筹莫展
随后卡罗琳娜稍微回顾了一下机器人的技术发展史
2010年代的主流方法
是通过强化学习来训练机器人完成特定动作
在DeepMind的早期实验中
研究人员会通过设置"叠积木越高
那么奖励就越高"的简单规则
让机器人在百万次试错中掌握平衡的技巧
但是这种方法存在着一个致命的缺陷
那就是当更换积木的形状
或者调整积木的摆放位置后
机器人就需要重新再学习几个月
但是2022年成为了一个关键的转折点
团队首次将大语言模型引入到了机器人系统中
当卡罗琳娜对机器人说出"我渴了"这句话的时候
这个曾经只能够执行预设程序的机械装置
第一次自主完成了"识别饮水机
到取杯子
到接水、递水"的一连贯动作
这标志着机器人正在开始从"由传感器驱动的执行者"，
进化为"能够理解语言的思考者"。
而如今DeepMind的Gemini机器人技术
本质上是将Google的多模态大模型
转化为物理世界的行动能力
在抓香蕉的经典实验中
机器人没有配备任何的触觉或者力传感器
仅凭双目视觉摄像头和Gemini模型来完成操作
它首先会通过视觉语言模型VLM来识别香蕉的颜色、形状和空间位置
然后再调用预训练的"物体抓取知识库"，
这个知识库并非针对香蕉做了专门的训练
而是基于千万级得物体抓取数据所提炼的通用策略
比如对于长条形的物体
抓取中部偏下的位置可以保持平衡
而对于柔软的物体
施加2-3牛顿的握力可以避免物体的损坏
更令人惊叹的是灌篮实验
当创意团队带着机器从来没见过的迷你篮筐和小球进入实验室的时候
研究人员并没有对机器人进行过任何专门的训练
但是搭载了Gemini的机器人
仅用了200毫秒就完成了从视觉识别到动作规划的全过程
它首先通过多模态模型
理解"篮球"是一个"需要投入到圆形框体的球体"，
然后基于三维空间定位
计算出抛射角度和力度
最终以92%的成功率完成了灌篮
卡罗琳娜在播客中强调
这并不是简单的模式匹配
而是真正的概念迁移，也就是说
机器人从互联网级的文本和图像数据中
提炼出了'从投掷到目标'的抽象关系
并且应用在了全新的场景中
对于人类来说
我们天生就具备的"具身认知"的能力
从而让我们无需刻意学习
就能够理解物体的物理属性
比如知道鸡蛋需要轻拿轻放
纸张折叠需要按照顺序来进行
而DeepMind提出的"具身思维"（Embodied Thinking）
正是要让机器人获得类似于人类的物理世界理解能力
比如在整理办公桌的任务中
机器人就需要完成一个复杂的认知链条
首先是边界框的识别
机器人需要通过多摄像头融合
比如顶部的广角镜头加上手腕处的特写镜头
来构建物体的三维边界框
从而精确地识别出咖啡杯的把手位置、笔记本的开合状态等等细节
其次是语义关联
机器人需要将视觉信息与语言指令关联起来
比如将"整理"理解为"将文具放入抽屉
将杯子放回杯架"这样的具体任务；
第三是运动规划
机器人需要考虑物体的物理属性
比如马克杯的重心位置、A4纸的易损性等等
来生成无碰撞的抓取路径
这种能力在折纸任务中达到了新的高度
机器人需要理解"对折""压痕""翻转"等抽象的指令
并且实时调整动作来应对纸张的形变
研究人员发现
当模型具备了"边界框识别"的能力后
折纸任务的成功率可以从47%提升到89%，
这是因为机器人能够准确判断纸张的边缘位置和折叠顺序
而无需依赖预设的几何模型
受到丹尼尔·卡尼曼（Daniel Kahneman）"系统一与系统二"理论的启发
DeepMind还设计了独特的机器人控制系统
首先是云端的慢系统，对应着系统二
它负责运行完整的Gemini多模态模型
以及复杂推理和长期规划
比如在规划午餐打包任务的时候
需要分析食材的保存条件
比如香蕉不能挤压、三明治需要密封
以及容器空间布局等多重因素
从而生成最优的操作序列
其次是本体的快系统
对应着System 1
它负责部署轻量化的模型
实时处理传感器数据并且调整动作
比如当抓取香蕉的时候
快系统会以200Hz的频率接收视觉反馈
一旦检测到物体滑动了
就会立即微调手指的握力
这种架构在动态环境中展现出了卓越的性能
在模拟人类干扰的实验中
当机器人搬运咖啡杯的时候
实验人员突然移动了杯架的位置
快系统能在40毫秒内检测到位置变化并且调整运动轨迹
而传统单模型系统的延迟则超过200毫秒
导致任务的失败率高达65%。
卡罗琳娜透露
团队曾经尝试过纯云端的控制方案
但是在处理快速移动的物体时
网络延迟会导致抓取成功率从85%骤降到32%，
这也促使他们最终采用了双系统的架构
传统的机器人在训练时通常都要依赖海量的试错数据
比如学会叠衣服需要经历20万次的失败
而DeepMind通过三大技术创新
将数据效率提升了两个数量级
首先就是对人类示范数据的高效利用
在系鞋带的任务中
研究人员采用了"远程具身示范"的技术
让人类操作员先佩戴着VR手套和摄像头
在虚拟环境中完成1000次的系鞋带动作
然后再将这些数据通过扩散模型
生成5万种的变体
包括不同的鞋带长度、打结方式等等
再输入到机器人进行强化学习
这种方法使得真实环境中的训练次数
从20万次降到500次
而成功率则达到了78%。
其次是仿真与现实的双向迁移
DeepMind开发的DemoStart系统
它的核心突破在于"小样本迁移学习"，
仅需要5个真实的示范
比如将钥匙插入锁孔
机器人就能够在仿真环境中生成10万种训练场景
包括不同的光照、角度、锁孔类型等等
从而通过对抗训练来提升泛化能力
实测数据显示
这个系统在真实环境中的首次操作成功率可以达到63%，
远超传统方法的22%。
第三就是多模态预训练的涌现能力
Gemini模型在包含了30亿张图像文本对的互联网级语料中
进行预训练后
具备了强大的零样本学习能力
在从未见过的"制作字谜"任务中
机器人能够通过解析"将字母块拼成单词"的语言指令
结合视觉识别的字母形状
自主完成拼图
关键是
这种能力并没有在专项训练中出现过
而是多模态学习的涌现结果
除此以外
随着机器人正在从实验室走向家庭
DeepMind也构建了一个多层次的安全体系
在物理层面上
DeepMind的机器人沿用了工业级的力控传感器
当抓手压力超过20N
相当于人类握手力度的1/3时
会自动触发紧急停止
在早期测试中
机器人曾经因为误判香蕉的硬度
而导致捏烂香蕉
随后研究团队通过在训练数据中
增加了2万张不同硬度物体的视觉和力度对应样本
将这个问题的发生率从15%降到了2%。
在语义层面上
研究团队基于阿西莫夫三定律
开发了一个Asimov数据集
包含了20万组"危险场景"的训练对
比如"将金属物品放进微波炉"，
或者是"在楼梯的边缘放置一个水杯"。
特别值得关注的是
团队还采集了美国消费品安全委员会CPSC报告里的1800例家庭机器人伤害案例
将它们转化为可训练的视觉-语言风险模型
从而使机器人识别潜在危险的准确率达到了89%。
在系统层面
针对网络中断等极端场景
DeepMind开发了一个"气隙模式"，
简单来说
就是当检测到云端连接中断的时候
机器人会自动切换到本地的运行模式
依靠轻量化模型来执行预设的安全任务
比如原地待命、紧急制动等等
在2024年日本台风的模拟测试中
这个模式让机器人在断网环境下的安全响应率保持在了91%，
而传统的联网机器人仅为37%。
当被问到"什么时候我们能拥有像《星际迷航》里那样的全息机器人助手"时
卡罗琳娜保持了审慎的乐观态度
她说
我们的机器人目前还相当于2-3岁的幼儿
虽然能够理解简单的指令
完成基础的操作
但是仍然缺乏复杂情境下的持续推理能力
不过她也同时指出
技术融合正在加速突破这方面的进展
比如在社交智能方面
最新的模型已经能够开始识别人类的手势和表情
在实验中
当实验人员做出"停止"的手势时
机器人能在0.3秒内中止动作
准确率可以达到92%。
而在持续学习方面
通过云端模型的更新
机器人可在夜间自动学习用户白天产生的新数据
比如识别家中新购买的扫地机器人的品牌
从而让系统的适应周期从72小时缩短到6个小时
在环境建模方面
团队还部署了一个三维语义地图系统
让机器人能够在进入陌生房间的45秒内
构建包含物体属性
比如材质、用途、重量在内的数字孪生模型
从而为复杂任务的规划提供底层的支持
在播客的结尾
卡罗琳娜再次强调了技术发展的本质
她说，我们不是在制造更先进的机器
而是在拓展智能的边界
当机器人能够理解'为什么要整理房间'，
而并不是仅仅知道'如何移动手臂'的时候
我们才算是真正创造了物理世界的智能主体
这种从"执行指令"到"理解意图"的跨越
或许才正是机器人技术最激动人心的未来
好了
以上就是DeepMind机器人负责人卡罗琳娜这次访谈的主要内容了
希望能帮助大家了解更多机器人方面的发展现状
感谢大家收看本期视频
我们下期再见
