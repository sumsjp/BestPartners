大家好
这里是最佳拍档
我是大飞
在我之前介绍TaskMatrixAI的节目里呢
当时我就说过
要找时间介绍一下Toolformer这个模型
今天呢就班班弄斧的来试一试
希望大家呢轻点拍
那我们已经知道呢
大语言模型lLLM有很多的优势
但是呢
他们在其他方面也有很多的局限性
比如说他无法访问最新的信息对吧
存在幻觉
以及对低资源的语言理解很困难
甚至还缺乏一些精准计算的数学技能
以及也不了解时间的进展等等
那么如何用大模型来解决更多的问题呢
微软之前就提出了一个
TaskMatrixAI的解决方案
就是将Toolformer和ChatGPT结合起来
通过把基础模型与数百万个API
连接起来来完成任务
那什么是Toolformer呢
今天我们就来讲一讲
简单来说呢
Toolformer是一个可以自己学习
如何使用工具的语言模型
这里的工具呢
指的就是API 应用编程接口
如果你还不知道API是什么意思
你大概可以把它理解成
就是两个程序之间
协商好的一种沟通方式
比如说我去你家要找你对吧
那我先敲三下门
然后你再回我一个猫叫
然后我就知道你在你也给我开门
大概呢就是这么个意思
这个呢我们今天不过多的讲
因为不是今天的重点
那Toolformer呢
是一个Meta开源的新的模型
可以自己学会如何使用像计算器
维基百科搜索 字典查找等等的API
在这个过程中呢
Toolformer的模型需要解决几个问题
首先呢
他必须意识到自己要使用一个API
然后能够确定使用哪个API
以及如何使用这个API
虽然在论文中呢
Toolformer使用的API种类并不多
但是如果按照TaskMatrixAI的想法
我们会有上百万个API
那么应用的场景应该说呢
是无穷无尽的
从提供对问题的即时搜索
到提供场景化的信息
比如说城里哪个餐馆是最好吃的
这些呢都可以做到
那Toolformer呢
是基于一个预先训练的GPT-J
的一个模型
这个模型呢包含了67亿个参数
然后使用了
自监督学习的方法来进行训练
其中呢包括采样和过滤API的调用
那对于如何自学使用工具这件事呢
研究人员给Toolformer提了两个要求
一个是工具的使用
应该通过自监督的方式来学习
这样呢就不需要大量的人工标注
第二个呢模型不应该丧失一般性
应该能够自行的决定
何时以及如何使用哪种工具API
那么我们先展示一个Toolformer
在数据样本中嵌入API调用
进行预测的一个示例
在这个示例中呢
由其他颜色突出显示的
就是调用API的部分
分别是问答 计算器
机器学习翻译
以及维基百科搜索的API
那通过调用这些API
计算或者是获取相关的信息
就可以把原来的文字补充完整
或者让它变得更加丰富
接下来呢
我们讲一讲Toolformer的架构和实现方法
这部分呢我刨掉了数学相关的部分
相信应该就算是小白
也大概能够听得懂
首先呢我们先介绍一下
在ChatGPT中有一个核心的特性
就是基于上下文的学习
英文呢叫做In-Ccntext Learning
它指的是一种机器学习的方法
就是模型呢
可以从特定的上下文或者环境中
所呈现出来的示例来学习
上下文学习的目的呢
是为了提高模型在指定的上下文
或者情况下
理解和生成语言的能力
而在自然语言处理NLP的任务中呢
它可以用来训练语言模型
从而生成对于特定的提示
或者特定问题的响应
那么Toolformer
是如何来利用上下文学习的呢
首先呢Toolformer作为一个大语言模型
它能够通过API
来调用和使用不同的工具
每个API调用的输入和输出
都需要被格式化
为一个文本对话的序列
这样呢才好在会话中自然的流动
那我们从这张图上可以看到
Toolformer是如何利用模型的
上下文的学习能力
来对大量潜在的API
进行采样和调用的
首先呢Toolformer先对样本文本进行采样
把匹兹堡也称为钢铁城
这句话分成两个部分
同时呢对可选的API也进行采样
分别选择了
匹兹堡的另一个名称是什么
以及匹兹堡属于哪个国家这两个API
然后呢
调用这两个API获取到相应的结果
一个呢是钢铁城
一个是美国
然后呢判断这两个结果哪个更好
计算他们的损失函数
损失更小呢就是更好
那明显呢因为钢铁城这个答案更好
所以就把它再放回到原文中
变成了一个新的样本
加入到新的数据集中
然后呢再对这个新的数据集
不断的重复这个过程
从而呢完成自监督的训练
这样的好处是呢
一个是需要更少的人工标注
第二个呢
是可以调用外部的API
来丰富数据样本
那经过训练之后呢
Toolformer呢就可以学会预测
到底哪个任务应该调用哪个API
我们再详细讲一下
这个过程中的几个点啊
首先是API的采样
从图中呢可以看到
Toolformer会使用一个<API></API>的标识符
用这个标识符呢
来生成具体的API调用
以及对文本进行标注
那实际上
Toolformer会为文本序列的每个token
去分配一个概率
通过计算每个位置调用API的概率
对多个候选位置进行采样
对于概率大于给定阈值的位置呢
就使用对应的<API>标识来表示API调用
然后呢再用</API>来结尾
这样呢
每个位置就可以获得多个API调用
接下来呢
API调用的执行
完全取决于执行调用的客户端
这个客户端呢
可以是不同类型的应用程序
从神经网络 Python脚本到搜索引擎
都可以作为客户端
需要注意的是
当客户端调用API的时候
API会返回一个单一的文本序列的响应
这个响应里呢
包含了有关调用的详细信息
包括调用的成功或者是失败的状态
执行时间等等
因此呢为了获得准确的结果
客户端应该确保提供正确的输入参数
如果输入的参数不正确
那么API可能会返回错误的结果
这对于用户来说呢可能是不可接受的
另外呢
客户端还应该确保
与API的连接是稳定的
从而避免在调用期间发生连接中断
或者是其他的网络问题
那调用了多个API之后
我们怎么来过滤API调用的结果呢
实际上Toolformer
会通过API调用后的token
来计算加权交叉熵损失
然后呢比较这两种不同的损失计算
一种呢是API调用了
并且调用的结果被作为输入
给到了Toolformer
另一种呢是没有调用API
或者API调用了但是没有返回结果
如果前者的损失明显比后者小
并且后者减前者的差大于某个阈值
那就说明呢这个API调用是有用的
就会让Toolformer呢
更容易的预测未来的token
那么这个API就会被保留下来
那我们可以看到呢
表中的最后一列的值是比较大的时候
就说明这个API是有用的
就会被保留下来
而负值呢就会被过滤掉
如果你不太清楚这些名词
比如说什么损失函数啊之类的
你大概可以这么去理解
就是我们通过一个比较的方式
去决定哪个API对我有用
我就留下哪个
最后呢Toolformer将保留下来的API调用
与原始的输入语料进行一个合并
并且创造一个新的
包含了API调用的增强数据集
换句话说呢
新的增强数据集
包含了与原始数据集相同的文本
只不过呢插入了新的API调用
然后呢
我们就可以使用增强的数据集
对Toolformer进行微调了
这样呢模型就能够理解
何时以及如何根据自己的反馈
来使用哪个API调用
接下来呢就是模型的推理过程
当这个语言模型产生了
—>这个token的时候
就表示他接下来期望呢
是一个API调用的响应结果
也就是说表示这块要调用API了
于是解码的过程呢就会被暂时的中断
等待调用API并且返回响应
然后在原文中插入这个响应
和</API>这个标识符之后
再继续解码
这里呢需要注意的是
我们需要确保获取的响应
与上一个token所期望的响应相匹配
如果不匹配呢
我们就需要调整API的调用
来获得一个正确的响应
在继续解码之前呢
我们还需要执行一些数据处理的工作
来准备下一步的推理过程
这些数据处理工作呢
包括对响应的分析
对上下文的理解
以及对推理路径的选择
因此呢在推理过程中
不仅需要调用API来获取响应
还需要进行一系列的数据处理和分析
从而确保推理过程的正确性和连贯性
那以上呢
就是整个Toolformer的训练方法了
接下来呢
我们讲一下论文中提到的API工具
在Toolformer中呢
每个可以使用的API工具
都要满足两个条件
第一个呢
是API的输入输出
都要能够被表示为一个文本序列
第二个呢
是对如何使用这个API工具
要有一个演示性的说明
那在Toolformer的初始实现中呢
支持了5个API工具
分别是第一个问题回答
实际上呢这是另一个语言模型
可以回答简单的一些事实问题
第二个计算器
目前呢只支持了四个基本的算数运算
并且四舍五入到了小数点后两位
第三个维基搜索
这是一个搜索引擎
可以返回维基百科中的一段文本
第四个机器翻译
这也是一个语言模型
可以将任何语言的短语翻译成英文
第五个日历
这个API调用会返回当前的日期
而且它不接受任何的输入
那讲到这里
Toolformer都能够应用在哪些场景
而且应用的情况如何呢？
在论文中Toolformer在LAMA数学数据集
问题解答
和时间数据集等任务中的性能呢
都优于基准的模型以及GPT3
但是在多语言回答中呢
表现不如其他的模型
这块我们大概介绍一下
首先是LAMA的任务
这个任务呢是要用一个缺少的事实
比如说一个时间或者地点
来补全一句陈述的语句
在这个测试结果中呢
Toolformer的性能要优于基准的模型
甚至是一些更大的模型
例如GPT-3
接下来的是数学数据集任务
目的呢是评估Toolformer的数学推理能力
可能是因为Toolformer经过了微调
所以这项测试中
他的性能也优于其他的模型
包括OBT和GPT-3等更大的模型
在这项测试中呢
几乎所有的情况下
模型都决定向计算器工具寻求帮助
也就是说
所有的计算都会去调用计算器API
第三个任务呢是问题解答
就是回答一些问题
Toolformer可以利用维基百科的搜索工具
来完成大多数的示例
并且性能也是要优于同样大小的基准模型
但是呢低于175B的GPT-3
在第四个任务多语言回答中
使用了一个多语言问答的基准测试MLQA
其中呢包含了英语阿拉伯语
德语西班牙语印地语
越南语以及简体中文的各种问题
Toolformer在这里表现并不是最好的
主要是由于CCNet
在所有语言上都缺乏调优
第五个呢是时间数据集任务
主要是回答跟时间
日期相关的各种问题
比如说罗纳尔多
从哪年到哪年期间是在踢球
那在这个测试中呢
Toolformer能够超越基准模型
但是他几乎很少的去调用日历的API
相反呢他会调用维基百科的搜索API
和问答的API
那这个呢
论文中也说可能跟他用的数据集
TempLAMA有关
因为这个数据集的语料呢
都是从维基百科中弄下来的
而且呢因为作者限制了
只能调用一个API
所以很多场景下呢
应该先使用日历API查询日期
再使用问答API的情况
也就没法做到了
那讲完了Toolformer的优点之后呢
我们再说说Toolformer的局限性
比方说呢
由于每个工具的API
调用都是独立生成的
因此Toolformer现在还无法在一个流程中
使用多个AP工具API
其次
对于可能会返回数百个不同结果的API
比如说搜索引擎
Toolformer还不能处理这种结果
以交互式的方式来使用
再次
使用Toolformer进行训练的模型呢
对输入措辞的准确性非常敏感
这可能对于某些API来说效率比较低
需要大量的文本
才能够生成少量有用的API调用
最后呢
是目前的模型在调用API的时候
并没有考虑到API的成本
那这样
就可有可能会导致较高的计算成本
那到这里呢
我们就基本上讲完了
Toolformer论文的整个内容
做个总结吧
Toolformer是一个大语言模型
通过使用上下文学习
来提高模型在指定的上下文
或者是情况下
理解和生成语言的能力
可以调用外部工具的API
并进行自监督的学习
然后呢通过对模型进行微调
来保留有用的API调用
这样Toolformer就可以学会预测
哪个任务应该使用哪个工具API
其实大飞我觉得啊
在现在AutoGPT HuggingGPT出来之后呢
这种基于大语言模型和API调用的方式
会变得越来越主流
这样呢也才能解决
实际中较为复杂的大多数问题
Toolformer至少提出了一个很好的思路
就是让模型自己来学会
如何调用外部的API
为整个大语言模型生态的进化
打下了一个很好的基础
这也是一个让大语言模型
跟现在很多已有的系统相结合的最佳方案
大家如果想在自己的工作产品中
引入大语言模型
不妨也试试能不能把Toolformer用起来
跟已有的API结合起来
让解决的问题 更加实际更加广泛
也让产品的形态呢变得更加丰富
功能更强大
好了今天的分享呢就到这里
感兴趣的小伙伴们
欢迎订阅我们的频道
我们下期再见
