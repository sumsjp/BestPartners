大家好，这里是最佳拍档，我是大飞
Ilya Sutskever在官宣从OpenAI离职后
第一时间点赞了一篇AI论文
引起了大家的广泛关注
这篇论文的标题翻译过来是柏拉图表征假说《The Platonic Representation Hypothesis》，
由MIT团队在上周发表
周末我花了一点时间
仔细读完了这篇论文，不得不说
Ilya精选的论文果然不同凡响
我个人觉得
这篇论文对未来AI发展路径和方向有着指导意义
无论你是AI从业者、科技投资人、还是对AI感兴趣的朋友
都值得一读
今天我们就来解读一下这篇论文的精华内容
相信看完这篇文章
大家对于深度学习模型的未来
会有一个全新的哲学认知
一切还得从柏拉图的洞穴寓言说起
洞穴寓言是柏拉图在他的著作《理想国》中提出的一个思想模型
探讨了什么是“现实”。
寓言是这样说的，有一群囚犯
他们一生都被锁链锁在一个洞穴中
对于洞穴外的世界一无所知
他们一直面对着一面墙壁
只能看到身后各种事物在墙壁上映射出的影子
长此以往
这些影子就成为了囚犯眼中的“现实”，
但是这其实并不是真实的世界
在洞穴寓言中
“影子”代表了我们通过各种感官感知到的现实片段
即通过六根，眼耳鼻舌身意
感受到的六尘，色声香味触法
都不过只是“现实”的种种投影罢了
柏拉图的老师苏格拉底曾经说过
哲学家就像是从洞穴中获释的囚犯
他们走出洞穴来到阳光下
逐渐明白墙上的影子只不过是“现实”的投影
并不是真正的“现实”。
哲学家的目标
就是通过逻辑、数学、自然科学等手段
去理解和感知更高层次的“现实”，
只不过现在
这个宏伟的目标从哲学家传递到了AI科学家的手中
理解了柏拉图洞穴寓言后
今天我们要说的柏拉图表征假说
应该就比较容易理解了
柏拉图表征假说的原文定义是
神经网络在不同的数据和模态上
以不同目标进行训练
正趋向于在它的表征空间中
收敛成一个共享的现实世界统计模型
简单一点来说，就是不同的AI模型
正在趋向于一个统一的现实表征
用再通俗一点话来说
就是不管是什么样的大模型
只要规模足够，训练得当
它们解释和预测这个世界的方法
都会趋同
这就好比
不管是什么文化环境下成长的人
只要看了足够多的书，足够好的书
见了足够多的世面
经历了足够多的事
他们对世界的理解，都会趋同
如果这么说大家还是觉得抽象
那么接下来我就再具体解释一下论文
假设我们把现实Z具象成一个圆锥加一个圆球
那么X是现实Z的图片模态的投影
而Y是现实Z的文本模态的投影
这时我们训练两个AI模型
一个是CV模型fimg
一个是文本模型ftext
它们各自学到了对于X和Y的表征方式
但是随着模型参数规模、训练数据的扩大
这两个模型最终会学到X、Y这两个投影背后
现实Z的表征方式
你可以理解为
当一个AI模型变得足够聪明的时候
它就不再是那个被铁链拴住的囚犯
而是成为了一名走出洞穴的哲学家
它看到的不再是墙壁上的投影
而是逐渐理解了事物的本来面貌
感知到了更高维度的现实
这就是柏拉图表征假说的含义
柏拉图表征假说还有一个非常重要的推论
就是不同模态、不同算法架构的AI模型
都会汇聚到同一个终点目标
那就是形成对于高维现实的准确表征
通俗一点的来说，就是各个大模型
它们对世界的认知，最终是趋同的
具体而言
这种对现实的表征可以理解为一个概率模型
它是现实事件的联合分布
这些离散事件采样自未知的分布
而且能够通过多种方式被观察和感知
无论是一张图片、一段声音、一段文字
还是质量、力、力矩等等
那么既然这是一个假说
我们自然得寻找方法来验证它的有效性
这就要用到数学工具了
论文作者将“表征对齐”，
Representation Alignment
定义为两个表征的核函数上的相似性度量
在这个基础上
我们需要用到一项叫做模型拼接
Model Stitching的技术
来评估两种表征之间的相似度
模型拼接的原理其实比较直观
就是将两个模型的中间表示层
通过一个拼接层Stitching Layer连接起来
形成一个新的“缝合”模型
如果这个“缝合”模型的性能良好
那么表明两个原始模型在该层的表征是兼容的
即使它们之前可能是基于完全不同的数据集进行训练的
通过“模型拼接”技术
以及“表征对齐”的评估手段
我们就可以来验证柏拉图假说是否真的存在
作者选取了78个CV模型
对他们进行了表征相似度分析
前提是这些模型在训练数据集、任务目标、算法架构上都各不相同
实验结果非常有趣
我来给大家解读一下
首先看左边的柱状图
横轴是所有模型通过VTAB任务的比例
这个比例越高，说明模型的性能越强
这里作者将78个CV模型
按照性能强弱分为了5个组
越往右越强
纵轴是每个组中所有模型间的表征相似度
柱子越高说明表征相似度越高
不难看出，模型的性能越强
它们之间的表征相似度就越高
反之，模型的性能越差
它们之间的表征相似度就越低
而右边的散点图把这个结论更加明确的呈现了出来
每个点都代表一个CV模型
颜色越红说明模型越弱
颜色越蓝说明模型越强
可以看到，强大的模型
也就是蓝色的点聚集在了一块儿
说明它们之间有着较高的表征相似度
而弱小的模型
也就是红色的点却比较分散
说明它们之间表征相似度较低
正如列夫·托尔斯泰在《安娜·卡列尼娜》中曾经写道的
幸福的人都是相似的
不幸的人各有各的不幸
论文作者也模仿托尔斯泰的口吻说道
强大的模型往往都是相似的
弱小的模型各有各的弱法
通过实验结果
我们发现柏拉图表征假说确实存在
那么AI模型为什么会呈现出如此明显的表征收敛性质呢？
作者认为主要有三大原因
第一个原因，任务通用性
当一个AI模型只需要完成一种特定任务
比如图像分类的时候
实现的方法就会有很多种
但是如果需要这个AI模型
同时胜任一系列不同的任务
那么实现的方式就会少得多
因为每个任务目标都会对模型施加额外的约束
当我们需要一个模型同时能够进行翻译、问答、写代码、解数学题的时候
它的表征空间会收敛到一个很小的范围
或者我们再举一个例子，有四个人
一个物理学家，一个生物学家
一个文学家
一个画家
这4个人的大脑形态和思维方式大不相同
他们之间想聊到一起就会比较困难
但是如果有两个人
他们都既是物理学家
又是生物学家，既是文学家
又是画家
那么这两个人的思维方式就会非常接近
很可能会一见如故
事实上
大语言模型可以看做是一个多任务目标训练的过程
根据上下文预测下一个token看似简单
实际上却是一个包罗万象的任务集合
多任务目标的训练向模型施加了更多的约束
从而导向更加紧致、更高质量的解决方案空间
这也是大语言模型为什么能够涌现出智能的一种有力解释
第二个原因，模型容量
模型越大
就越容易逼近全局的最优表征
从而推动表征收敛
比方说
黄色区域和绿色区域是两个AI模型的表征空间
一层一层的同心圆可以看做是模型的loss等高线
位于圆心处是loss最低的全局最优解
在左侧
由于两个模型的参数规模都比较小
沿着降低loss的方向进行梯度下降
只能求解出两个局部最优解
用空心星号表示
随着模型参数规模的增加
黄色和绿色的色块范围在不断扩大
意味着两个AI模型的表征空间也在变大
右侧的两个模型能够找到一个共享的全局最优解
用实心星号表示
从而实现表征收敛
这里所谓的共享表征
就是说表征具有跨模态的通用性和适应性
其中暗含的意思是
更大的模型才有可能更聪明
聪明到解决一切问题
而且研究还发现
在相同的训练目标下
即使是不同的架构，只要模型够大
也会倾向于收敛到同一个最优解
这不禁会让我们想到OpenAI工程师、著名文生图模型DALL-E的第一作者
詹姆斯·贝特克James Betker说过的一段话
他曾经看到
在同一数据集上训练足够长的时间后
几乎所有拥有足够权重和训练时间的模型
最终都会收敛到同一点
规模足够大的扩散卷积神经网络生成的图像
跟ViT生成器输出的图像别无二致
AR采样生成的图像与扩散模型生成的图像如出一辙
第三个原因，简单性偏见
论文指出
更大的模型拥有更多的参数和计算能力
能够探索更多可能的方式来拟合相同的数据集
但是它们总是倾向于简单的解决方案
并且这种倾向会随着模型变大而更加显著
这里所谓的解决方案
是指模型在训练过程中找到的一组特定的参数和配置
使得模型能够有效地对数据进行拟合并做出准确的预测
而所谓的“简单”，则包括三点
第一点，模型中很多参数值接近零
这意味着
模型实际上倾向于使用较少的参数数量
第二点，在大量的输入特征中
模型会关注关键的特征
而忽略贡献较小的特征
第三点
模型不会完美地拟合训练数据中的所有细节
尤其是那些噪声或异常点，这意味着
模型的算法会倾向于更加平滑、更加通用
不得不说
深度神经网络天然遵循着奥卡姆剃刀原则
所以有简单性偏见
倾向于选择所有可行解中的最简单的解决方案
也许正是这种独特的性质
让深度神经网络模型从一堆模型架构中脱颖而出
成为现代AI的奠基算法
那么柏拉图表征假说还能带给我们什么启发呢？
首先
随着模型参数、任务多样性、算力FLOPS的增加
模型的表征会逐渐收敛趋同
那么这是不是意味着只要Scaling up就可以实现AGI呢？
答案应该说是也不是
虽然Scaling up能够实现表征的收敛
但是不同方法的收敛效率
可能会是天差地别
举个例子
AlphaFold 3能够有效预测包括蛋白质在内的生物大分子结构
而FSD能够通过图像识别实现无人驾驶
这两种任务显然是相对独立的
如果用一个统一的AI模型
来同时实现AlphaFold 3和FSD的能力
训练过程可能会非常低效
性价比较低
因此，对于某些独立任务而言
可以单独训练一个shortcut模型
而不一定要依靠对于现实的统一表征
这说明在某些场景中
相比费尽力气取得全局最优解而言
高效地取得局部最优解
会更具备经济价值
其次，我们可以从一个新的视角
来审视多模态数据之间的关系
假设你手上有M张图片和N段文字
为了训练出最强的CV模型
你不应该只训练全部的M张图片
还应该把N段文字也纳入到训练集中
这其实已经成为AI行业的常规操作了
有不少优秀的CV模型
都是从预训练的大语言模型上微调而来的
这个道理反之亦然
如果你想要训练出最强的文本模型
你不应该只训练全部的N段文字
还应该把M张图片也纳入训练集
这是因为不同模态的数据背后
隐含着某种与模态无关的通用现实表征
这意味着即使训练集中不存在跨模态的配对数据
比如文本和图片的配对数据
纯粹的文本语料也会对CV模型训练
有直接的帮助
而跨模态配对数据的主要价值
则在于提升表征收敛的效率
好了
以上就是《柏拉图表征假说》这篇论文的主要内容
两千年前，柏拉图提出洞穴寓言
哲学家们开始运用逻辑工具、几何工具
懵懵懂懂地探索现实的本质
两千年后
人类的工具箱中多了一件超级武器
那就是AI
这一次，人类究竟能否借助AI的力量
寻找到表征世界的全局最优解
走出洞穴
探寻并且理解高维度的真正现实呢？
欢迎大家在评论区发表自己的看法
感谢大家观看本期视频
我们下期再见
