大家好，这里是最佳拍档，我是大飞
说起来大家可能不相信，科技越发展
不仅越耗钱
耗芯片，还更耗水
前两天，谷歌发布了2023年环境报告
里面的一项离谱的数据
立马引发的大伙们的关注
那就是谷歌去年一年花掉了56亿加仑水
这水量
大概能装满一个半西湖
而且不单单是谷歌
包括微软、亚马逊等等科技巨头
也一个个都是耗水大户
那他们整这么多水干什么呢？
肯定不是想做大自然的搬运工了
实际上
这些水
大都被用去给数据中心散热了
因为这件事实在是太耗水了
其实在早些年
不少数据中心散热靠的并不是水
而直接用电，给服务器吹空调
就拿中国自己为例，像是2021年
全国数据中心总耗电量就高达2166亿度
约占全国总耗电量的2.6%。
这么大一笔的电力支出
要是全用在数据处理和存储上
大家可能还会该省省该花花
但问题就是
有不少电用来做 “无用功”了
而最大头的 “无用功” 就是散热
因为数据中心全年无休，发热量巨大
为了让仪器能够在合适的环境下正常工作
就得大空调、大电扇嘎嘎上
自然就费电了
据统计
数据中心6成的成本都花在电费上
而电费里的4成多又得靠散热
为了多省点电费
最好的方法就是尽可能地白嫖散热
于是我们就看到
各个企业绞尽脑汁地白嫖散热
首先
大家想的第一个方法就是 “哪儿凉快哪儿呆着” 。
2014年
腾讯就在贵州凿出了47万平米的“七星洞”，
用来当数据中心
2017年
华为在贵安新区造了个云上屯
用来当华为云数据中心
2018年
苹果的iCloud数据也摇身一变
成了 “云上贵州” 。
大家集体跑去贵州
一方面是贵州地价便宜、水电资源丰富
电费便宜，像华为建完云上屯后
每年光电费就能省下6个亿
另一方面就是贵州四季如春的环境
足够凉快和稳定
很适合养数据中心
不过，比起国内这些公司往贵州跑
国外的大厂们更狠
Facebook早在2013年就在北极圈外的小镇吕勒奥
建立了自己的数据中心
除了往更凉快的地方去
数据中心本身也在进化
而在进化的过程中
数据中心的散热也从很耗电
转变成了更耗水
前面说的
空调冷却系统因为需要大量的电给冷凝剂降温
所以这几年因为太费电逐渐被淘汰了
于是另一种蒸发冷却系统就流传了开来
相较传统空调来说
蒸发冷却机只靠外界水来降温
不需要用电来降温冷凝剂
所以可以大幅度减少耗电量
但这也会让用水量猛增
不过相对电来说
水总是更便宜的那个
所以大家普遍都开始选蒸发冷却机
除了蒸发冷却机，为了提高散热效率
还有公司直接给数据中心用上了液冷散热
但是在数据中心里
水冷散热还要更夸张
像阿里在千岛湖的数据中心
设备虽然都泡在特制的冷却液里用于快速散热
但是这些液体最终还是需要靠大量湖水来进行冷却
也难怪不少网友调侃自己买的农夫山泉
是阿里云服务器的洗脚水
最绝的当属微软
他们在2018年的时候
就把 “北方群岛” 服务器扔到了大西洋海底
利用海水潮汐进行水冷散热
这种散热法子
对于水资源本来就充分的地区来说
其实并还算是物尽其用
对一些缺水地区
妥妥是经不起这类折腾的
像国内的内蒙古等地区
之前就指名道姓发文
要求辖区内大数据企业
一律禁止使用地下水冷却降温
但是在国外
特别是美国的缺水地区
服务器的耗水就整出了不少问题来
大家都知道
最近这几年美国一直闹旱灾
然后几个大厂又在疯狂新建数据中心
其中不少就建在很缺水的亚利桑那州等地方
这些城市缺水所以沙漠多
沙漠多所以风电光电很发达
风电光电发达所以电费便宜
再加上沙漠地区地皮也便宜
在这建数据中心能省不少钱
而且这些地区的政府
为了让这些数据中心来安家
还会签协议优先保证水量供应
几个因素一叠加，事情就麻烦了
比如谷歌在梅萨建立数据中心时
就和当地政府签了一份协议
梅萨镇要 “优先” 保证谷歌每天能有足够的水进行散热
这对于水资源本来就不富裕梅萨镇来说
已经影响到当地生态系统
甚至人类的生活用水了
类似的还有亚利桑那州政府
因为供水给数据中心
被迫停了城市基建
还被美国联邦政府教训
要求“少用点河水” 。
而在达尔斯城
谷歌3座数据中心的年耗水量
已经将近达到了达尔斯市年总用水量的三分之一
被当地媒体一路追着咬
这些问题越来越多的时候
各个大厂也不得不开始优化自家散热设备
给公众画大饼
像谷歌承诺到 2030 年时
无论是东水西调
还是投资海水净化设施
反正要补充自家公司用水量120%的水
微软则是承诺到2024年
将全球数据中心蒸发冷却系统的用水量减少95% ，
到2030年将实现“水中和”。
只不过，承诺归承诺，执行归执行
更要命的是
一些学者发现AI大模型的爆火
让水耗得更多了
按照加州大学副教授Shaolei Ren的说法
谷歌用水量比去年足足多了20%，
巧的是，谷歌这一年算力也长了20%。
所以他们大胆推断
就是因为在AI军备竞赛
会让数据中心耗水更多
也不光是谷歌家 AI 费水
根据美国加州大学河滨分校的一项研究发现
ChatGPT为代表的语言大模型的用水量就是很多
据他们测算
OpenAI光是训练个GPT-3就用掉了70万升水
更不要说数据量更大的GPT-4
而且除了训练阶段
后续的使用也特别费水
和GPT们随便聊个三五十句
就得消耗一瓶农夫山泉的水
眼下AI热潮仍在继续
大家的AI竞争只会越来越激烈
数据中心的作用只会越来越大
散热的法子
多半又得来一波大升级了
否则在AI抢走人类工作之前
一些地区的水
可能就先被AI给抢走了
大家对这方面有什么好的想法呢
欢迎在评论区留言
感谢大家观看本期视频
我们下期再见
