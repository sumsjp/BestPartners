大家好，这里是最佳拍档，我是大飞
在AI图像生成领域一直有一个老大难
那就是角色的一致性问题
直到谷歌Nano Banana模型的出现
11月11日
红杉资本的斯蒂芬妮·詹（Stephanie Zhan）和帕特·格雷迪（Pat Grady）
对Nano Banana核心团队进行了一次专访
受访的两位分别是谷歌Nano Banana产品负责人妮可·布里托娃（Nicole Brichtova）和工程负责人汉萨·斯里尼瓦桑（Hansa Srinivasan）
这次专访
不仅拆解了Nano Banana实现角色一致性的技术密码
更让我们看到了AI视觉工具从好玩到实用的转变
未来
也许AI会真正的让人人都成为故事家
今天我们就来给大家分享一下
首先，我们得先搞懂
Nano Banana到底解决了什么核心问题？
在它之前，AI图像模型的角色一致性
究竟又难在哪里呢？
妮可·布里托娃（Nicole Brichtova）在专访里提到
过去谷歌发布的图像模型
一直有个明显的短板
用户编辑图像的时候
很难保留不变的部分
比如广告商想把自家产品
放进AI生成的生活场景里
以前的模型要么改完场景产品就变形
要么需要上传上百张产品图做微调
还得等20多分钟才能出结果
而Nano Banana的核心目标
就是要做到
用户只需要上传1张参考图
再用文本描述想要的场景
就能生成高度一致的图像
而且支持多轮对话式编辑
也就是说
你可以跟模型不断地提修改需求
而且修改后的人物或产品的特征依然不变
速度还很快
能够支撑流畅的对话式创作
而角色一致性
尤其是大家最关心的面部一致性
到底又是靠什么技术实现的呢？
汉萨·斯里尼瓦桑（Hansa Srinivasan）在专访里把这项技术支撑
拆分成了四个关键的部分
第一个是高质量数据
很多人以为AI模型只要数据量够大就行
但是斯里尼瓦桑（Hansa Srinivasan）强调
高质量比数量多更重要
这些数据的核心作用
是教会模型如何泛化
比如模型看了大量的人脸数据后
不是只会生成标准脸
而是能记住某一张特定人脸的眼角弧度、颧骨高度、嘴角特征
哪怕把这个人放进红毯、校园、太空等不同的场景
这些核心特征依然能保留
如果数据质量不高，模型就容易学偏
所以呢
高质量数据是角色一致性的基础
没有这个，后面的技术再强也没用
第二个支撑是谷歌的Gemini基础模型
斯里尼瓦桑（Hansa Srinivasan）说
Nano Banana不是一个孤立的模型
而是建立在Gemini这个多模态的基础模型之上的
Gemini给它带来了两个关键能力
一个是多模态的理解能力
也就是说模型既能懂文本
又能懂图像
还能把两者精准结合
另一个是长上下文窗口
这意味着模型能够记住你之前的操作
这两个能力加起来
才让多轮对话式编辑成为可能
而不是每次修改都要重新从零开始
第三个支撑
可能会超出很多人的预期
它不是多么复杂的算法
而是人工评估
布里托娃在专访里分享了一个细节
团队在内部测试的时候
她上传了自己的照片
生成了红毯上的自己
当时她特别激动
因为这张图真的很像自己
但是同事们一开始的反应却很平淡
说就是你在红毯上啊，没什么特别的
直到后来
她让同事们都用自己的照片测试
大家才慢慢体会到那种
哇，这真的是我的震撼
因为对于面部一致性
旁观者很难判断好坏
比如我看你的AI生成图
可能觉得还行
但是你自己一眼就能看出眼角的痣没了、嘴角的弧度不对
这就导致
量化指标根本没办法捕捉这种细微的主观感受
所以谷歌专门组建了团队
设计了完善的人工评估流程
让测试者用自己的照片生成图像
然后打分判断
像不像自己、画面美不美
再根据这些反馈来调整模型
斯里尼瓦桑（Hansa Srinivasan）说
这是他们在图像生成领域最大的收获之一
人类评估是一切的基础
尤其是在面部、美学这些主观维度
机器指标永远替代不了人的眼睛
第四个支撑
布里托娃（Nicole Brichtova）把它叫做AI开发中的匠心
也就是团队对细节的极致打磨
比如模型的文本渲染功能
一开始效果并不好
但是团队里有个成员对这个问题特别痴迷
死磕了很久，反复调整算法
最后让文本渲染的清晰度和一致性
都提升了一个档次；
再比如模型的推理速度
为了支撑对话式编辑
团队在基础设施上做了大量优化
确保每次生成不超过10秒
要知道
很多AI图像模型生成一张图要等1-2分钟
根本没法对话
这些看似微小的设计决策
比如文本渲染的字体边缘要不要抗锯齿
推理时优先保证速度还是分辨率
其实都是团队反复权衡的结果
而正是这些细节
最终让Nano Banana的体验远超同类产品
除了这四个技术支撑
还有一个很重要的点
就是谷歌的模型协同逻辑
Nano Banana不是孤军奋战
而是和Imagine、Veo等模型相互配合的
布里托娃说
谷歌的核心愿景
是构建一个能够输入任意模态、输出任意模态的通用模型
也就是Gemini
但是在实现这个目标的过程中
会先做一些专用的模型
比如专注于图像生成的Imagine
专注于视频生成的Veo
这些专用模型的作用
就是探索各种模态的前沿技术
而且，图像领域的技术突破
通常会比视频领域早一年左右
因为图像只需要处理单帧
训练和推理成本都更低
等图像技术成熟了
再把思路用到视频上
这种把专用模型当试验场
用核心模型来做整合的逻辑
既保证了各模态的技术领先
又能让Gemini不断吸收各领域的成果
变得越来越强
讲完了技术，我们再来聊聊产品
Nano Banana这个名字为什么这么奇怪？
它的产品定位和以前的AI图像工具
到底有什么不一样？
先来说说名字的由来
斯里尼瓦桑在专访里爆料
这纯属是凌晨两点的巧合
Nano Banana最初是在谷歌的LM Arena上发布的
按照流程
每个测试模型都需要一个代号
当时大概是凌晨两点
团队里的一位产品经理已经极度疲惫
有人发消息问给模型起个什么代号？
这位经理随口说了Nano Banana
大家觉得好玩、易记
还有专属的表情符号
于是就这么定了
没想到后来模型火了
用户都喊Nano Banana
甚至有用户抱怨在Gemini应用里找不到这个香蕉模型
谷歌干脆就在Gemini里加了香蕉图标
让它更加醒目
布里托娃说
这个名字的好处在于没有距离感
很多用户因为好奇Nano Banana是什么而尝试使用
最后被功能所吸引
这也印证了一个道理，好的产品
有时候有趣也是一种竞争力
再来说说产品定位
Nano Banana从一开始就没打算做成一个全能的工具
而是聚焦在消费端对话式图像编辑器上
布里托娃解释道
这个定位的核心就是速度快和易上手
速度快，才能支撑对话式编辑
比如你改完背景想再调光线
不用等很久；
易上手
是因为它用的是聊天机器人的交互方式
你不用学复杂的参数
直接说把光线调亮一点就行
这种定位
把Nano Banana和像Photoshop这样的专业图像工具
区分开来
不过，有意思的是
Nano Banana的用户场景
远远超出了团队最初的预期
它不仅是一个好玩的工具
还成了实用的助手
妮可·布里托娃分享了一个让她印象深刻的案例
有个用户用Nano Banana给化学主题做速写笔记
用来理解他父亲的工作
他的父亲是大学化学家
讲的内容很专业，儿子听不懂
于是就把父亲的讲座内容输入Gemini
用Nano Banana生成图文结合的速写笔记
比如用图展示分子结构
用文字标注反应原理
最后
父子俩第一次能就父亲的工作聊起来
这个场景完全不在团队的设计目标里
因为Nano Banana的文本渲染能力其实不是最强的
但是用户通过精心设计的提示词
把它变成了学习辅助工具
还有一个场景是情感需求
斯里尼瓦桑说
有用户用Nano Banana修复了一张童年损坏的家庭合影
照片里的孩子把自己的脸画花了
用户上传照片后
让模型还原画花的面部
保持其他部分不变
最后成功修复了这张照片
还说这弥补了童年的遗憾
另外
还有家长用它生成以家人为原型的故事书角色
比如把孩子、父母、宠物都变成童话里的角色
然后编一个孩子解决校园矛盾的故事
读给孩子听
这些意外场景
其实印证了布里托娃的一个观点
趣味性是通往实用性的入口
很多用户一开始是因为好玩才用Nano Banana的
但是用着用着
就发现了它的实用价值
比如学习、修复照片、家庭互动
而且，这种从好玩到实用的转变
还降低了技术的门槛
斯里尼瓦桑举了自己父母的例子
他的父母不是技术爱好者
但是因为Nano Banana好玩
就试着用它生成自己的照片
后来发现还能移除照片里的路人
生成家庭聚会的邀请函图片
慢慢就用得越来越多
这种先吸引，再留存的路径
其实是很多消费级AI产品成功的关键
接下来，我们再来聊聊未来
在Nano Banana之后
AI视觉领域会往哪个方向走呢？
布里托娃和斯里尼瓦桑在专访里
把未来分成了短期和长期两个阶段
先看短期1-2年
核心是完善体验和探索交互
在消费端，最大的问题是提示词工程
现在很多用户为了得到满意的效果
会写几百字的提示词
这对普通用户来说太麻烦了
所以，团队的目标是摆脱提示词工程
比如你上传照片后
模型会主动问你想要什么场景
什么风格，你不用写长提示词
回答几个问题就行；
或者模型能根据你的参考图
自动推荐合适的场景
在专业端
短期目标是解决稳定性和提升控制的精度
专业用户需要的是100%可靠
比如生成10张产品图
产品的logo位置、颜色必须完全一致
不能有一张变形
但是现在的Nano Banana还做不到这一点
偶尔会出现细节偏差
所以团队要优化模型的稳定性
确保每次输出都符合预期
另外，专业用户还需要像素级的控制
这就需要模型能更精准地识别要修改的区域和要保留的区域
未来可能还会加入手势控制
让操作更直观
短期还有一个重要方向是交互创新
现在的Nano Banana还是文本+参考图的交互
但是视觉创作其实更适合视觉交互
布里托娃提到，谷歌有个实验室团队
正在探索视觉创作画布
比如你可以在画布上画一个简单的草图
模型会自动把它变成精细的图像
或者你可以直接在生成的图像上涂画修改
模型会理解你的意图并调整
但这里的挑战是如何平衡复杂性和易用性
画布不能太复杂，也不能太简单
这就需要团队不断测试和调整
再看长期3-10年
AI视觉领域的目标会更加宏大
核心是多模态融合和主动代理
布里托娃说
未来的模型不应该只输出单一模态
比如你让它解释光合作用的原理
它不应该只给你一段文字
而是会自动判断用什么形式呈现最好
比如用短视频来展示从阳光到叶子
再到氧气的过程
用图表对比有光和无光时的反应差异
用文字来总结核心步骤
这种多模态的自动适配
才是真正的智能
因为它符合我们人类接收信息的习惯
主动代理是另一个长期方向
简单说就是模型能主动帮你做事
而不是你说一步，它做一步
比如你要做一个项目进展的演示文稿
不用自己找图、排版
只要告诉模型会议记录、项目要点、之前用的演示文稿是什么样的
它就能自动整理内容
生成合适的幻灯片
这就像雇了一个专业的助理
你不用管细节
只要告诉它目标就行
还有一个长期方向是个性化学习
布里托娃对此特别期待
她认为，现在的学习方式太一刀切了
所有人都在学同一本教材
用同一种方法
但是每个人的学习风格和兴趣都不一样
未来，AI模型可以成为个性化的导师
它能识别你的学习风格
比如你喜欢篮球
那就用篮球的例子讲物理；
你喜欢画画，就用画图的方式讲数学
而且
它还能根据你的知识起点调整难度
比如你没学过微积分
那就从基础函数开始教
不会一上来就讲复杂公式
当然，这里有个前提是
模型不能说谎，必须基于真实的知识
所以团队会在事实准确性上做大量的验证
避免模型生成错误的内容
聊完了技术和未来
我们还得关注一个很重要的话题
AI图像模型这么强，怎么防止滥用？
布里托娃和斯里尼瓦桑在里
专门谈了谷歌的应对措施
核心是技术防护和持续权衡
首先是技术防护方面
谷歌用了两种水印
一种是可见水印
所有用Nano Banana生成的图像、视频
都会在角落标注由Gemini生成
让观众一眼就知道这是AI内容；
另一种是不可见水印
也就是谷歌的SynthID技术
它会在内容里嵌入一串普通人看不到的代码
通过专门的工具可以检测出来
哪怕内容被裁剪、压缩
这个代码也不会消失
这两种水印结合
既能让普通用户识别AI内容
又能让平台追溯内容的来源
其次是持续权衡，布里托娃承认
在创作自由和防止滥用之间找平衡
是永远的难题
比如
用户希望能生成任何自己想要的图像
但是平台必须防止生成违法、暴力、造谣的内容
谷歌的做法是先做限制
再根据反馈调整
比如模型不会生成模仿真人的虚假新闻图片
不会生成暴力场景；
同时，团队会和外部专家合作
测试模型可能的滥用场景
然后更新防护措施
举个例子
当发现有人用模型生成假的身份证照片时
团队就会在模型里加入禁止生成身份证类图像的规则
斯里尼瓦桑说，这不是一劳永逸的事
模型在进化，滥用方式也在变
所以我们的防护措施也要跟着变
最后，对于初创公司来说
在Nano Banana这样的大公司产品之外
还有哪些机会呢？
布里托娃和汉萨·斯里尼瓦桑都认为
机会主要在垂直领域和交互创新上
第一个机会是垂直工作流的自动化
大公司的产品追求的是通用
能满足大多数用户的需求
但是特定行业的细分需求往往照顾不到
比如咨询行业
咨询师需要经常做演示文稿
要把数据变成图表、把案例变成图像
现在的工具需要在数据软件、图像模型和PPT之间来回切换
很麻烦
初创公司可以做一个咨询师专用工具
整合数据导入、AI图像生成、PPT排版功能
咨询师只要上传数据和案例
工具就能自动生成演示文稿
不用再切换软件
类似的
还有教育行业、电商行业等等
这些垂直领域的需求很明确
用户愿意付费
大公司又不会花太多精力去做
正好是初创公司的机会
第二个机会是创意工具的集成
现在的创意工作流太碎片化了
比如你想做一个短视频
需要先用语言模型写脚本
再用图像模型生成关键帧
然后用视频模型合成视频
最后用音频模型配背景音乐
整个过程要在4-5个工具之间切换
初创公司可以做一个一体化的创意平台
把这些工具整合起来
最好能在写好脚本后
平台会自动生成关键帧、合成视频、配音乐
还能实时修改
这种整合能极大提升效率
尤其是对中小创作者来说
他们没有团队帮忙
需要一站式解决所有问题
第三个机会是用户界面的创新
现在的AI图像工具
要么是文本框+参考图上传
要么是专业的参数面板
但是还有很多用户群体的需求没被满足
比如老年人，他们不习惯用文本描述
更习惯用语音+手势的操作
还有儿童
他们喜欢用画画的方式告诉模型自己想要什么
初创公司可以针对这些群体做一些专属的UI
比如给老年人做一个语音控制工具
说生成一张我和孙子在公园的图就行
给儿童做一个画画控制工具
孩子画一个简单的太阳
模型就会生成有太阳的公园场景
这种细分人群的UI创新
大公司很少做
因为用户量可能不大
但是初创公司可以靠这个做精做透
形成差异化
好了
以上就是这次访谈的主要内容了
我们从中可以看到
Nano Banana的成功不是偶然
它靠的是高质量数据+Gemini基础模型+人工评估+细节匠心的技术组合
靠的是消费端聚焦+趣味性入口的产品定位
更靠的是对用户真实需求的关注
而它背后的趋势
是AI视觉工具从能生成图像
到能帮人解决问题的转变
未来呢
当AI能真正理解我们的需求
主动帮我们做事的时候
人人都是故事家就不再是一句口号了
而是每个人都能实现的日常
感谢大家观看本期视频，我们下期再见
