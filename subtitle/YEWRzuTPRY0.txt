大家好这里是最佳拍档我是小郭
今天给大家分享一下如何安装 Doctor GPT
Doctor GPT 是一个利用人工智能
来帮助患者的程序
根据其症状和医疗历史
提供个性化建议
以便为其特定的医疗情况
找到合适的专科医生
它的目标是让人们更轻松高效的获取
医疗建议
而无需长时间排队
或进行大量的在线搜索
它的优点是
1. 完全免费：不必花钱买 Pro 等功能
2. 本地部署：不用担心隐私泄露的问题
3. 准确率高：号称已经通过了美国医学执照考试
4. 跨平台：支持苹果安卓 PC 甚至是 Web
要完成本视频的安装步骤
需要以下几点
第一已安装好显卡驱动的带图行界面的操作系统
第二能访问谷歌等墙外的网站
第三安装需要一些软件比如 Git LFS NodeJS
Python 或其他 HTTP 的服务器
Doctor GPT 只提供了模型文件
如果要使用这个模型文件
就需要借助 MLC-LLM
根据它 GitHub 页面的介绍
他支持将各种语言模型进行本地部署
支持手机PC甚至是浏览器环境
虽然介绍的支持手机
但我在手机上并没有运行成功
大家可以尝试一下
在手机上安装倒也简单
大家可以看一下 Doctor GPT Github 页面上的介绍
在页面偏下的位置
如果你是苹果手机
去 Apple Store 搜索并安装 MLC Chat
但好像需要国外的 Apple ID
国内的不提供这个软件
如果你是安卓手机
从左侧找到 Android App 然后点击
在页面上部就可以看到 apk 的下载地址
直接将 apk 文件下载到手机上进行安装即可
安装后打开应用
点击 Add model variant
然后输入模型的地址
不要直接填这里给的地址
需要打开它
然后点击这里的 files and versions
可以看到上面(地址栏)的地址最后是 tree/main
把 tree 改成 resolve
并在 main 后增加一个斜杠
然后点击 Add 等待下载完成就可以了
但我点完 Add 之后
提示 Download 目录没有权限
但实际已经给了应用存储权限
不确定具体原因是什么
网上还有人说
添加模型以后程序会直接崩溃
印象中在手机上运行的话
至少需要 4GB 的内存
注意是运行内存不是存储空间
大家可以试一下运气
既然手机上运行这条路行不通
咱们就退而求其次选择 Web 的方式
虽然 Doctor GPT 官方这里介绍的 Web 方式还是 TODO 的状态
但实际上 MLC LLM 有一个子项目叫 web-llm
它可以独立在浏览器中处理模型文件
并且还支持硬件加速
咱们可以通过它
来在浏览器中运行 Doctor GPT
咱们要用到项目里的 simple chat 这个示例
先把 web-llm 项目下载下来
可以直接下载 zip 文件
或者用 git clone 到本地
然后用 vs code 打开 examples/simple-chat 这个目录
然后再打开终端运行 npm install
后面加上国内的镜像
注意不要用 pnpm 安装
否则会有依赖版本冲突的问题
如果你的梯子比较稳定
并且网络速度也够快的话
安装起来会很容易
只需要修改 src 下的 gh-config.js 文件
在 model_list 的最后增加 DoctorGPT 的模型文件地址即可
先将最后的这个记录复制一下
注意要带上前面的逗号
然后把模型地址改成刚才填写的地址
local_id 改成 DoctorGPT_mini
修改好以后运行 npm run start
等命令成功以后在浏览器中打开
http://localhost:8888 即可
但这种方式对网络的要求比较高
如果你的网络不是那么稳定
或者不想经常从 hugging face 上下载将近 1.5G 的文件的话
可以试一下下面这个方法
思路是将每次都需要下载的文件提前下载到本地
然后让 web-llm 从本地去下载
一共需要下载两个东西
一个是 Web Assembly 的 wasm 文件
另外一个就是模型文件
wasm 文件的下载地址
可以从刚才提到的 gh-config.js 中找到
就是 model_lib_map 中最后的这个
直接在浏览器中下载即可
模型文件就是刚才在 hugging face上看到的那些文件
如果你有 git lfs
可以用 git lfs clone
如果没有的话也可以从页面上
点击这个下载图标下载
一共有 50 多个文件一会就下载完了
手动下载的话别忘了点击最下面的 Load more files
否则会漏掉这几个文件
再回到 vs code 找到 src/mlc_local_config.js
和刚才修改的办法类似
也是把 model_list 中最后一段复制一下
然后修改 model_url 和 local_id
只是模型地址
不再填写 hugging face 的地址了
而是填写本地的地址
然后把 model_lib_map 中最后一行的 URL 改成本地的地址
至次配置文件就改好了
只需要修改这两个地方
然后咱们再来改一下打包脚本
打开 package.json 文件
找到第8行
将 build 后的 cp 命令要复制的文件
换成刚才修改的那个 mlc_local_config.js
修改完之后运行 npm run build 来编译
程序会将编辑好的文件
放到 lib 目录下
如果你嫌编译 web_llm 示例麻烦的话
也可以下载我预先编译好的文件
这样就只需要按开始提到的下载 wasm 文件
和模型文件就可以了
大家可以在视频的说明中找到下载地址
web-llm 的运行需要 web 环境
不能直接用浏览器打开 llm_chat.html 进行访问
最简单的方式就是用 Python 的 HTTP Server 模块
在终端中切换到 lib 目录下
然后运行 python -m http.server
后面跟上端口号
它会启动一个 HTTP 服务监听你指定的端口号
并将当前目录作为HTTP服务的根目录
这个端口号要和上面修改的配置文件中的一致
我预先编译的是 18080
在浏览器中打开 http://localhost:18080/llm_chat.html
在上面的模型列表中选择 DoctorGPT_mini
这时会发现窗口提示了异常信息
这是因为程序无法加载到 wasm 文件导致的
咱们需要将之前下载的模型文件和
wasm 文件都链接到 lib 目录下
如果你觉得创建链接麻烦的话
也可以直接复制过来
处理好以后再次刷新页面
会发现异常信息变了
大概意思是当前浏览器不支持
需要使用 Google Canary
并且在启动时还需要加上一个参数
咱们到它的官网去下载一个安装上
然后去终端运行这个命令启动
然后再来访问切换模型
可以看到他在加载模型文件了
当显示 Finish loading on WebGPU 之后
就说明已经加载完成了
可以开始聊天了
可能是模型训练素材的问题
Doctor GPT 对中文的支持很差
而我的英文又不是很好
所以就不在这里给大家演示了
如果大家想训练自己的模型文件
或者想了解一下 Doctor GPT 的模型是如何训练出来的
可以看一下官方的 Jupiter Notebook 文件
据说在付费的 Google collab 上
用 A100 GPU 需要运行大概 24 小时
至于训练出来的模型效果如何
这不得而知
估计会比这个 MINI 要强
希望有朋友训练后在下面评论一下
好了以上就是今天视频的全部内容了
感谢大家的观看下次见
