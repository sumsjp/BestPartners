大家好，这里是最佳拍档，我是大飞
9月5日
Hyperwrite AI的联合创始人兼CEO 马特·舒默
在X上扔出了他们家最新的大模型Reflection70B
这款大模型由马特·舒默和萨希尔·乔杜里两人合作开发
一出世便被冠以「世界顶级开源」模型的称号
纸面性能强到令人发指
在MMLU、MATH、IFEval、GSM8K上横扫其他模型
甚至击败了GPT-4o，以及Llama 3.1
结果没多久
Reflection 70B就被打假了
公司公布的基准测试结果和用户的独立测试之间
存在着显著的差异
无论是AI研究者，还是第三方评估者
都无法复现马特所声称的结果
根据Artificial Analysis的数据
Reflection 70B在基准测试中的表现
竟然还不如原始版的Llama 3.1 70B
随后，开发者们逐渐发现
Reflection可能就是个「套壳」模型
而且还是连套三家
Claude，GPT和Llama纷纷惨遭毒手
很多人表示
在API上使用Reflection模型的时候
会出现一些奇怪的行为，比如
生成与Claude相同的随机数
模型声称它是由Anthropic制作的
当被要求写出「Claude」这个词的时候
模型会在应该出现「Claude」的地方回复空引号
这些现象
加上一些与分词器相关的测试
让大家高度怀疑团队只是接了Claude的服务
并通过后处理
过滤掉了像「Claude」这样的词
这就立刻在Reddit和X等平台上
掀起了质疑的声浪
十月七号，调查结果终于水落石出
Reflection 70B果然没有达到最初报告的基准
而Glaive的创始人萨希尔·乔杜里
也在博客上发布了关于「Reflection 70B造假事件」的事后分析报告
今天大飞就带大家读一读这份报告
看看这个Reflection70B到底做了什么
才忽悠了一大票的基准测试
一上来
乔杜里先是针对外界的质疑一一进行了回应
他否认了对团队造假的指控
并且解释道自己没有验证模型是否正确
就匆忙进行了发布
如果单看这句话
大家可能会觉得乔杜里的道歉毫无诚意
要知道，在被打假之前
Reflection 70B可是靠着强劲的测试表现
风光了好一阵子
根据Hyperwrite AI公布的数据
Reflection 70B在与各种顶级闭源模型的比较中
都表现相当出色
不仅在MMLU、MATH、IFEval、GSM8K等测试基准上
都击败了GPT-4o
而且Reflection 仅凭70B的参数
就彻底击败了405B的Llama 3.1
当时大伙都觉得
是不是大模型又取得了一个重大突破
结果发现模型的数据复现不出来
这不是造假是什么呢？
而根据乔杜里自己的说法
这都是bug惹的祸
之前的Reflection 70B的几个测试结果
之所以出现了几个百分点的偏差
是因为原始代码中有一个bug
由于系统处理外部API响应的方式出现了错误
导致MATH和GSM8K的分数显示异常
比如在MATH基准上
模型实际的得分为69%-70%，
而不是报告的79%；
GSM8K基准的得分，实际为94%-96%，
而非报告的99.2%。
乔杜里在报告中也放出了他们修好bug之后的分数
可以看到，模型在MMLU和GPQA上
分别提升了1.04%和0.3%，
但是在HumanEval、MATH、GSM8K
以及IFEVAL上，都有着明显的下降
分别是1.98%、8.9%、3.98%、2.5%。
好家伙，搞了半天
原来之前的数据都是API响应错误造成的
以防万一，乔杜里还做了多项检查
首先
他使用LMSYS的「LLM Decontaminator」检查了数据集是否存在污染
结果并没有发现数据集与基准测试有明显的重叠
不过，这还不能完全证明
模型没有在基准测试上进行过训练
因为无法确定这就是用来训练特定版本模型的数据集
所以，他又进行了另一个测试
那就是对基准测试集中的每个问题
将问题字符串分成两半
然后在温度为0且不附加任何EOS token的情况下
生成输出
然后检查生成的问题是否与评估问题相同
结果显示
模型能够生成6%的MMLU测试集中的问题
最后，为了赢回大家的信任
让所有人能够更好地进行评测
乔杜里还发布了用来训练模型的训练脚本和超参数
作为补充
他还跑了一遍MixEval的基准测试
来查看模型是否过度拟合基准测试
或者是否在某种程度上具有泛化能力
总而言之
之前Reflection70B的超高得分完全就是个乌龙事件
其实只要他们自己多测几次
就可以轻易地找出这种简单的bug
那Hyperwrite AI到底是怎么犯下这样的低级错误的呢？
在报告中
乔杜里也复盘了整个开发流程
在模型的开发上
乔杜里和马特二人只用了3到4周
就生成了Reflection的数据集
并且在各种模型规模上进行了多次迭代
他们的想法是
如果让模型对思维链（COT）进行「反思」，
模型或许能够识别并且修正错误
为此，他们生成了一个数据集
其中响应被分为〈thinking〉和〈output〉标签
而〈reflection〉标签在〈thinking〉标签内使用
马特先是训练了一个8B版本的模型
在较小的规模上进行了几次迭代之后
他们想扩展到70B模型
但是马特没有算力进行完整的微调
所以乔杜里对70B版本的模型进行了训练
在对数据混合进行了几次迭代后
最终达到了基准测试分数非常好的程度
乔杜里与马特分享了这些基准测试的分数和数据集
在看到那个带着bug的结果之后
二人可以说是欣喜若狂
都想尽快地发布模型
并且秀出基准测试的跑分
然而
除了乔杜里进行的一次基准测试
以及马特在乔杜里提供的API上
进行的一些基本测试以外
模型其实并没有经过任何实际的验证
在发布前的一小时
乔杜里开始上传权重
同时使用Hugging Face的「Repo Duplicator」功能
将文件转移到马特的仓库中
同样，他们并没有验证文件是否正确
或者是否能用Transformers库
克隆和运行这个模型
乔杜里表示
自己曾经想过要测试一下模型能否按照预期工作
但是由于马特还有电话会议
于是模型就这样匆匆上线了
同时发布的还有一个演示平台
它最初是由Glaive的API和马特在Replit上的代理提供支持
后来被乔杜里的另一个代理所替代
这就是后来被OpenRouter等平台使用的同一个API
也是Artificial Analysis用来测试基准的API
这个API其实是一个从来没有打算进入生产环境的API
它只是一个带有代理的vllm服务器
所以
实际上两个开发者连一个正确维护的模型都没有
与此同时
因为两人也没有构建过通用模型
所以没有经常运行MMLU这类基准测试的需求
乔杜里是基于OpenAI的「Simple Evals」，
在一个GPU节点上临时编写了评估代码
直到几天前
它甚至都还没有进入版本控制
简直可以用草台班子来形容
可以说
两位开发者完全就是被最开始的数据冲昏了头脑
一直到模型发布，他们都没有想过
要再跑一遍分数来验证一下数据对不对
甚至连debug都没有做
果然，模型发布后不久
就被网友们揪出了种种问题
比如
当模型以fp32格式上传、分割成2GB大小的文件时
整个模型就崩了，很难下载和运行
与此同时
模型的嵌入大小（embedding size）没有添加特殊的token
因此模型无法按照预期运行
看到网友们的反馈后
乔杜里才如梦初醒，急忙开始debug
然后重新上传了新的版本
这一次
网友们倒是可以用Transformer来跑模型了
但是他们很快发现，config
json文件中提到的是Llama 3
而不是Llama 3.1
在网友们再次纷纷报错后
乔杜里才注意到了这一点
他表示
有人猜测模型是不是在基准测试上
进行了Llama 3 的LoRA训练
但是事实并非如此
乔杜里承认
来自社区的批评让他在压力下感到恐慌
然而由于他的粗心大意
没有添加特殊token
导致重新训练的模型依然表现不佳
对于这一系列的「迷之操作」，
乔杜里也报告中反思道
他们不应该在没有测试的情况下发布模型
还声称它是最好的开源模型
最终，乔杜里表示向大家诚挚地道歉
因为深知自己和马特闹出的这起事件
对开源生态系统产生了极为负面的影响
不过，他们的道歉声明
并没有被开源社区的网友们所接受
AI研究员亚历山大·莫伊尼就表示
为什么他们花了一个月的时间
才将模型权重新上传到Hugging Face上？
Hyperwrite AI到底有没有一个带有「真实权重」的API？
Hyperbolic Labs的联合创始人兼CTO Yuchen Jin 也表示了怀疑
此前
Jin曾经努力尝试托管Reflection 70B
但是他很快就发现了问题
而现在对于乔杜里的澄清说明
他依然觉得不对劲
比如乔杜里声称已经复现了两个分数之外的所有基准测试分数
但是跟实际提供的数据并不相符
数据显示
至少有4个基准测试的分数发生了变化
网友卡登·比耶（Kaden Bilyeu）也提出了同样的质疑
并且嘲讽道，你们是怎么做到
在看到99%这个跑分之后还不进行检查的？
而在Reddit的Local LLaMA子版块中
一位名叫「FuckSides」的用户
甚至做了这样的大胆猜测
乔杜里说不定是在一个月的时间里
微调出了一个新的模型来支持自己的声明
这个模型实际上就是Anthropic的Claude 3.5
这样就能解释用户之前遇到的奇怪输出了
Reflection API实际上就是带有提示符的Sonnet 3.5套壳程序
通过过滤掉「Claude」的字符串来进行伪装
还有一位Reddit用户「DangerousBenefit」，
分析了乔杜里最近发布的训练数据
发现其中频繁出现「作为一个AI语言模型」的说法
他认为
这表明数据可能主要来自于ChatGPT
而且没有经过适当的清洗
目前
马特和乔杜里还没有做出进一步的解释
好了
以上就是这次Reflection 70B乌龙事件的全部内容了
好笑的是
有人表示马特还是做出了一点贡献的
那就是Reflection 70B的发布
让OpenAI心安理得地拿出了还没做完的o1-preview
抛开这些玩笑话
这次事件也确实给所有人上了一课
以后的大模型已经不能再盲目地信奉基准测试了
英伟达高级研究主管Jim Fan也表示
基准测试其实是可以轻松操控的
比如
开发者可以根据测试集的示例来训练模型
然后通过提示工程快速提升模型
增加推理时间和更强的计算能力等等
总之
2024年9月的MMLU或HumanEval基准
已经被严重破坏了
随便一个本科生就能随意操纵他们
在Jim Fan看来
识别优秀模型的唯一可靠方法
就是使用LMSy的Arena聊天机器人
或者来自第三方提供商的私人基准测试
那大家是如何看待这次Reflection70B 的乌龙事件呢？
欢迎在评论区留言，感谢大家的观看
我们下期再见
