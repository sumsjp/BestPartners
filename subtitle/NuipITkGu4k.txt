大家好，这里是最佳拍档，我是大飞
在科幻电影里，我们常常会看到
AI机器人能够精准地预判人类的动作
做出恰到好处的回应，可是在现实中
AI要想做到这点却难如登天
生活里人与人的互动本来就是复杂多变的
一个抬手动作
可能是握手、挥手，甚至挠痒痒
意图捉摸不定
AI想要准确地判断出来
并且进行合理的反应，又谈何容易呢？
最近
国内人大高瓴团队带来了一篇论文
他们发布的Think-Then-React
简称TTR的框架，有望改变这个局面
让AI能够像人一样
一眼看穿他人的动作意图
然后做出合适的反应
这篇论文已经被ICLR 2025接收了
今天，我们就来聊一聊这个TTR框架
看看它究竟是如何赋予AI预判能力的
在介绍TTR框架之前
我们得先了解一下它要解决的问题
在日常的社交活动里
人与人的互动是相当频繁的
比如在街头遇到朋友，对方抬手
瞬间你的脑海里会闪过许多种可能
是要热情握手、轻松挥手
还是有其他的意图呢？
我们凭借着生活经验、对方的表情
以及过往的互动等等信息
可以快速做出判断并且回应
但是对于AI来说
解读人类的动作并没有这么简单
以往AI在处理这类问题的时候
在理解动作的意图和生成合适的反应上
其实是困难重重的
这是因为人类的动作千变万化
在不同场景、人物关系下
同一个动作的含义可能会天差地别
在一些复杂的社交环境中
AI更是难以精准捕捉动作的关键信息
更别说是做出恰当的反应了
这严重限制了AI在社交交互领域的应用
像智能陪伴机器人、虚拟社交助手等等
都因为这个难题而无法达到理想的效果
面对这些挑战
人大高瓴团队提出了一个TTR框架
通过采用预训练大语言模型加运动编码器的策略
让AI先思考，后反应
大模型大家估计都比较熟悉了
所以我们先来看看统一运动编码器
以往我们在处理人类动作数据的时候
会经常把动作的起始姿态
在空间上规范到坐标轴原点
这样虽然能够提升编码器的效率
却忽略了人类交互场景里的相对位置关系
打个比方，两个人在跳舞
舞者间的距离、方位是时刻变化的
如果其中一个人只关注自身的姿态
不管彼此的位置
就没法完整地呈现舞蹈互动
因此
研究团队提出了解耦空间-位姿编码
把人类动作的全局信息
像是在空间中的位置和身体朝向
与局部信息，也就是运动位姿
分别编码再组合使用
这就好比给AI装上了一个透视眼
既能看清每个人的动作细节
又能把握他们在空间中的相对位置
不仅可以全面获取动作信息
还能保证了编码系统的高效运行
我们再来聊聊运动-文本的联合预训练
为了让大语言模型更好地理解运动数据和语言
研究团队设计了一系列相关的预训练任务
你可以把AI想象成是一个刚刚接触人类世界的“小机灵鬼”，
他会把运动数据和文本数据关联起来学习
就像把看到的动作和对应的文字描述一一进行对应
然后逐渐明白两者之间的联系
比如看到“拥抱”的动作
同时学习到相关的文本描述
进而知道这代表着友好、亲密
在这些预训练任务中
AI可以学习到不同动作的语义、可能的反应
以及动作和文本的对应关系
从而为后续的反应生成
打下坚实的基础
总的来说
TTR框架的核心就是从思考到反应生成
所以模型会分为两个阶段工作
在思考阶段
模型会像人类一样琢磨输入动作的含义
判断合适的反应
比如看到对方抬手
就会通过分析这个动作的速度、幅度、方向
结合之前学习到的知识和经验
来思考对方的意图
而在反应阶段
模型会根据思考的结果来生成相关的反应动作
整个过程不仅是在模仿人类的决策和行动流程
也是在模拟人类对外界刺激的反应机制
从而让AI反应更加自然、合理
不过，理论再好
还得看实际的效果
因此研究团队对TTR进行了多方面的实验评估
先看反应动作生成质量测评
在不同的任务指标上
比如R-Precision、分类准确率、FID、多模态距离等等方面
TTR的表现都非常优异
在FID指标上，TTR仅为1.942
远低于次优方法ReGenNet的3.888
FID可以用来衡量生成图像或动作
与真实样本的差异
数值越低，生成的动作越接近真实
这表明TTR生成的反应动作
在视觉效果和语义上都更为贴合实际
在R-Precision和分类准确率方面
TTR也得分更高
意味着它生成的反应动作
更为符合输入动作的语义
在用户研究中，对比TTR和ReGenNet
在较长的时间序列场景里
TTR以76.2%的胜率胜出
也说明用户明显更加青睐它生成的动作
为了进一步验证TTR有效性
团队还做了多项消融实验
在去除思考阶段之后
FID从1.942飙升到了3.828
这清楚地表明思考阶段对反应的生成极为关键
没了思考，AI就像没头苍蝇一样
无法理解动作的意图
反应也自然变差
而去除掉所有的预训练后
模型的性能也会大幅下降
说明预训练在让模型适应运动-语言模态中不可或缺
预训练就像给AI积累了知识和经验
没了它，AI就变得脑袋空空
难以处理复杂的任务
同时
在去除不同预训练任务的时候研究人员发现
动作-动作、空间-位姿、动作-文本这三种预训练任务
都有正向的贡献，相互补充
这就好比是在盖一座房子
不同的任务是不同的建筑材料
缺了谁都不行
而去除单人数据之后
模型仅靠依赖多人数据
说明单人数据对模型的提升效果不明显
通过t-SNE可视化工具可以发现
单人运动和两人运动的序列特征几乎不重叠
比如按摩、被拉拽等交互动作
在单人运动里很少见；
而T字姿势这类单人运动
在多人交互中也不多
两者只有少量重叠
比如说像静止站立
除了上述实验以外
团队还对TTR框架进行了系统分析
在重新思考的时间间隔方面
TTR的重新思考机制
能够动态的调整反应描述
减少累积误差，而且计算成本很低
实验显示
重新思考频率过高或者过低
都会降低模型的性能
但是在合适的频率下
TTR能在单张Tesla V100上实现实时推理
延迟低于50毫秒
这意味着它能够做到快速响应
满足实际的应用需求
在动作描述质量评估中
在运动描述任务里
TTR在所有指标上都表现最佳
即使只提供四分之一的输入动作
TTR仍然能够准确预测动作和反应描述
展现出强大的泛化能力
在探究思考过程的必要性实验中
输入真实的提示
预测反应质量有显著的提升
而采用增强版的思考模型
FID可以从1.94降到1.88；
而如果完全去除思考过程
反应的生成质量则会暴跌
这充分证明了思考和重新思考过程
在指导反应生成、减少误差方面的关键作用
在Inter-X数据集上
TTR框架优势明显
在多个指标上远超传统方法
与InterFormer、MotionGPT、InterGen、ReGenNet等模型对比
TTR在Top-1、R-Precision、Top-2、Top-3、Acc
等指标上都更为出色
FID和MMDist指标也更低
说明生成的动作质量更高
而且
TTR还能够模拟人类思考决策的过程
保证生成的反应动作更为自然合理
这是传统方法难以企及的
可以预见到的是
TTR将在智能陪伴机器人、虚拟社交助手、人机交互游戏等领域
有巨大的应用潜力
比如智能陪伴机器人能够更好地理解用户的动作意图
从而提供更为贴心服务；
虚拟社交助手能与用户进行自然的互动
提升社交体验；
而在人机交互游戏里
玩家可以获得更为真实、有趣的游戏感受
不过，研究团队也指出
TTR也有一定的局限性
虽然它在现有数据集上表现优异
但是实际场景还是要复杂得多
在不同文化背景、地域差异的情况下
人类动作的含义和反应方式也不尽相同
TTR可能无法完美地适应
比如在某些文化中
特定手势有着特殊的含义
TTR目前可能无法准确的理解
在未来
团队还计划探索更加高效地利用跨类别数据集
包括单人与多人动作数据
来提升模型的泛化能力
让TTR在复杂多变的真实世界中也能够游刃有余
好了
以上就是对TTR这篇论文的简单解读了
感兴趣的观众可以自行去阅读一下原论文
感谢大家的观看，我们下期再见
