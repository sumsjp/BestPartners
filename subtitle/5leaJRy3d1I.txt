大家好，这里是最佳拍档，我是大飞
几天前
《人类简史》的作者尤瓦尔·赫拉利
在油管的官方频道上
更新了在东京庆应义塾大学所做的一场讲座
主持人是庆应义塾大学的校长伊藤公平（Kohei Itoh）
尤瓦尔·赫拉利应该不需要我过多介绍了
他是一位以色列历史学家
也是畅销书简史三部曲的作者
在六年前出版的《今日简史》中
他指出了三大全球性的威胁
分别是核战、不受控制的生物技术发展
以及信息技术网络与人工智能的失控
而在这场讲座中
他认为当年的三大威胁
核威胁和生物威胁
现在看来风险没有那么大
但是AI风险的优先级要高得多
如今在整个行业里
明显谈AI机遇的人更多
谈AI风险的人更少
之前我们听到最多的
应该就是辛顿和本吉奥了
所以大飞我今天再给大家分享一下尤瓦尔的最新观点
伊藤公平在开场提出的问题是
为什么尤瓦尔在新书《智人之上》中
将主要火力集中在了信息网络与AI之上
相较于生物技术和核战争威胁
这种优先级的调整是基于什么样的考量？
尤瓦尔的回答非常清晰
他首先比较了AI与生物技术
虽然两者都能给世界带来巨大的改变
但是AI的发展速度现在远超生物技术
生物技术的变革周期漫长
因为“生物学本身就慢得多” 。
他举例说明，对人类基因组进行修改
然后再观察它影响
再根据结果来进行更大的改变
这个过程可能需要持续二三十年
甚至四十年
才能够评估新的遗传物质对人类行为、智力、心理的具体作用
因此，生物技术领域
尤其是在涉及到人类的时候
它的代际周期大概会是20到30年
相比之下
AI的迭代速度就快得惊人了
可能只需仅仅几天
他指出
数字进化比有机进化要快数百万倍
这就决定了
尽管生物技术的潜在危险不容小觑
但是AI因为其迅猛的发展态势
而显得更为紧迫
接着
尤瓦尔将AI与核威胁进行了对比
他认为，之所以更聚焦于AI
主要有两个原因
其一，核战没有任何积极的意义可言
因此也没有支持者
自从1945年以来
国际体系中最大的禁忌
就是强国不能仅仅因为自身的强大就入侵、试图征服并且摧毁弱国
如今，虽然这个禁忌已经被打破
但是至少所有人都明白它的危险性
正所谓核战争中没有赢家
而AI则是一个更为复杂的挑战
因为它拥有巨大的积极潜力
这使得人们很难充分理解它的潜在威胁
尤瓦尔还提到
自广岛和长崎原子弹爆炸以来
核技术的危险性对人类而言是清晰可见的
无需过多解释
但是AI的危险则是难以把握的
因为它是一种异类的威胁
他强调
AI的核心问题不在于它是邪恶的
而在于它的“异类性” 。
这是一种在许多方面可能超越人类的智能
但是它并非人类智能
也并非有机智能
很多人问尤瓦尔
AI什么时候能达到人类水平的智能
他的回答是“永远不会”，
因为它与我们完全不同
他巧妙地比喻道
这就像是问飞机什么时候能够达到鸟类的飞行水平
答案是永远不会
飞机和鸟类完全不同
它们以不同的方式飞行
因此，AI一定会超越人类智能
但是它的本质上是异类的
这就使得预测它发展轨迹和后果
变得极为困难
更进一步
尤瓦尔抛出了一个关于AI最核心、也最需要被大众理解的观点
那就是它不只是一个工具
它是一个具有能动性的Agent
这是人类有史以来创造的
第一项有能动性而非单纯工具的技术
无论是原子弹还是用来发电的核反应堆
它们都是人类手中的工具
由人类来决定如何使用它们
比如是用来发电，还是用来摧毁城市
决定权都在人类的手中
反应堆本身是无法做出任何决定的
更不要说让它去发明下一代的反应堆或者炸弹
直到现在
只有人类能够做出决策和创造新的思想
但是AI
是第一种可以在没有人类帮助和干预的情况下
做到这些的技术
AI可以自行决策
AI武器不需要人类指令
就能够自行决定轰炸目标
甚至可以发明新的武器和军事策略
它既拥有巨大的积极潜力
也拥有巨大的消极潜力
正因为如此
尤瓦尔选择在他的新书中
专注于信息技术的历史
因为他认为在当前时刻
这才是我们面临的最大挑战
甚至在很多方面是“人类历史上所面临的最大挑战” 。
数千年来，人类统治着地球
地球上没有任何事物能够在智能和创新能力上与我们竞争
但是现在
地球上出现了一种可能在几年内
就会在智能上超越我们、能够决定我们生活、能够发明从药物到武器等一切新事物的存在
这，便是最大的挑战所在
随即，伊藤注意到
尤瓦尔早在2015年出版《未来简史》的时候
就已经对信息技术和信息网络发出了警告
并且给予了重点关注
他好奇地追问
与十年前撰写《未来简史》时的思考相比
尤瓦尔现在的想法有什么改变么？
这十年间
从一位历史学家、中世纪军事专家
转而聚焦于信息网络与AI
他个人的思想发展轨迹又是怎样的呢？
尤瓦尔坦言
十年前撰写《未来简史》的时候
谈论AI的人还非常少
当然
计算机科学领域、谷歌和微软等顶尖公司的内部人士
已经预见到了一些趋势
也有像尼克·博斯特罗姆（Nick Bostrom）这样的少数哲学家在进行探讨
但是在当时，撰写关于AI的内容
感觉更像是在讨论可能数百年后才会发生的事情
对我们生活的直接实际影响微乎其微
然而，时至今日
AI已经无处不在
它的发展速度简直令人震惊
尤瓦尔回忆起来
当时已经有像雷·库兹韦尔（Ray Kurzweil）这样的人物预测
到大约2029年的时候
将会出现通用人工智能AGI
能够在所有领域超越人类
当尤瓦尔本人在读到库兹韦尔的预测时
也曾经认为他太夸张了
不可能是2029年
但是现在
库兹韦尔仍然坚持2029年的预测
而他已经被认为是较为保守的思想家之一了
听听那些中美两国大型AI企业AI的人们是怎么说的
他们谈论的是在一年、五年内实现AGI
所以说，AI的发展进程显著加速了
另一个显著的变化是
所有关于监管AI、与AI达成某种协议的希望
现在看起来都是极其天真的
尤瓦尔认为
尤其是在最近一次美国大选之后
达成一项关于如何管理AI发展风险的全球协议的希望
基本上已经破灭了
这就引出了AI革命的一个巨大悖论
也就是信任的悖论
尤瓦尔在与领导AI革命的那些人
比如OpenAI、微软、腾讯、百度等公司的负责人
以及主要的政治家交流时
总是会问他们两个问题
第一个问题是
“你们为什么发展得这么快？
” 尤瓦尔表示理解AI巨大的积极潜力
但是也清楚它存在着风险
因此他建议，让我们稍微放慢一点
给人类社会一些时间
人类是适应性极强的生物
我们可以适应AI时代
但是我们需要时间
请给我们多一点时间
”
而这些领导者的回答几乎如出一辙
那就是，我们理解存在巨大的风险
甚至可能导致人类灭绝
我们理解这一点
我们也愿意放慢速度，但是我们不能
因为如果我们放慢了
而其他公司、其他国家的竞争对手不放慢
他们就会赢得这场竞赛
然后那些最冷酷无情的人将主宰世界
因为他们将拥有AI这项奇妙的技术
于是，结论就变成
因为我们无法信任其他的人类
所以我们必须更快地发展
然后，尤瓦尔会问第二个问题
“你们认为自己能够信任正在开发的超级智能AI吗？
” 他们的回答都是，是的
尤瓦尔对此感到不可思议
那些一分钟前还告诉我
他们无法信任其他人类的人
突然之间变得非常容易信任AI
他直言，这简直在“濒临疯狂的边缘” 。
因为对于人类来说
他能理解为何我们难以相互信任
但是毕竟我们与其他人类打交道已经有数千年的经验了
了解我们自己的心理和动机
我们深知人类对权力的渴望
但是也明白制约权力的机制
数千年来
人类也发展出了学习互相信任的方法
从一万年生活在几十人小部落、无法信任部落外任何人的状态
发展到如今拥有几亿公民能够互相信任的国家
全球贸易网络也连接着地球上所有的80亿人
我们吃的食物、穿的衣服、保护我们的药物
往往是由地球另一端的陌生人生产的
所以
尽管信任他人仍然是一个巨大的问题
但是我们在这方面拥有经验
然而，对于超级智能AI
我们反而是“毫无经验” 的
我们不知道它们可能会发展出什么样的目标和伎俩
更不知道当数百万个超级智能AI相互作用
并且与数百万人类互动的时候会发生什么
AI并非某个地方的一台大型计算机
更应将它视为“一场席卷全球的移民浪潮” 。
他认为
AI就好像是一波数百万异类移民的浪潮
它们将夺走人们的工作
拥有截然不同的如何来管理社会的想法
甚至可能会接管国家
这才应该更让人们感到恐惧
因此，这个巨大的悖论的核心在于
在我们开发出超级智能AI之前
如何在人类之间建立信任？
谈到信任，伊藤进一步引申到
不仅是人与AI Agent之间的信任问题
所谓“精英”与“普通民众”之间的信任鸿沟也在不断地扩大
他关心的是
尤瓦尔的著作可能会更多地被所谓的“精英阶层”阅读
那么这些深刻的思考在多大程度上能够影响普通大众？
毕竟
弥合这两个分裂群体之间的鸿沟至关重要
尤瓦尔回应道
如同我们头脑中发明的许多分歧一样
“精英”与“人民”之间的这种划分
也是一种“错误的二分法” 。
他以世界上最富有的人，比如马斯克
以及其他一些亿万富翁举例
这些人本身就是亿万富翁
却声称他们反对精英
尤瓦尔反问道，如果你不是精英
那么什么是精英？
难道世界上最富有的人不是精英吗？
所有这些现在执掌美国政府的亿万富翁
他们不是精英
为什么？
他认为
“精英”这个词已经变成了一个负面标签
人们只是用它来攻击对手
事实是，每个人群都有它的精英
尤瓦尔强调，管理任何人群
哪怕是一个足球俱乐部
都离不开精英
社会中总会有一些人在某些方面更有才华
或者拥有更多权力与影响力
这是人类社会的本质
问题不在于精英的存在与否
关键在于，这是一个服务型的精英
还是一个自私自利型的精英？
他进一步解释道，在一个群体中
无论是小到朋友圈
还是大到整个国家乃至全球
如果那些最具影响力的人
仅仅是为了自身利益而使用权力
那将是非常糟糕的局面
理想的情况是
那些在特定领域更有才华、更具影响力或权力的人
能将它们用在社会的福祉上
那种认为可以建立一个没有任何精英的社会的幻想
从来都行不通
它往往是一些人借以争夺权力的伎俩
尤瓦尔认为
尤其是对于庆应这样的高等学府以及所有大学而言
目的应该不是摧毁精英
也不是打破群体间的壁垒
而是培养服务型的精英
这才是大学应该追求的目标
随后
对话自然而然地延伸到了教育在应对AI时代挑战中的作用
伊藤提到尤瓦尔在书中谈到的
生活在网络空间与物理空间的人群之间的分化
以及越来越多的人沉浸在网络空间
习惯于接收碎片化信息的现象
他忧虑地问道
像庆应这样的高等教育机构
以及中小学等基础教育阶段
应该如何应对这一挑战
确保年轻一代仍然有能力阅读引人深思、激发讨论的长篇内容？
在这个信息获取越来越便捷
但是深度思考能力面临考验的时代
教育在维持人类智力水平方面
究竟应该扮演着什么样的角色？
尤瓦尔指出，在以往的时代
教育机构的核心任务是向人们提供信息
因为信息是稀缺的
他描绘了一个这样的场景
那就是生活在偏远小镇的人们
镇上可能只有一个几百本藏书的图书馆
想要获取一本新书都非常困难
而现在，情况恰恰相反
人们不再缺乏信息
而是被海量的信息所淹没
最关键的一点是需要理解
信息并不是真相
尤瓦尔强调道
真相是信息中一个非常罕见的子集
如果审视世界上所有的信息
真相所占的比例微乎其微
大部分的信息都是垃圾信息、虚构、幻想、谎言和宣传等等
背后的原因也不难理解
首先，真相是昂贵的
而虚构是廉价的
撰写一篇真实的记述，需要进行研究
花费时间分析和核查事实
这需要时间、精力和金钱
而虚构则是非常廉价的
只需要将头脑中闪现的任何想法写下来即可
其次，真相往往是复杂的
因为现实是复杂的
比方说
要撰写一篇关于量子物理学的论述
这个过程本身就很复杂
而人们通常不喜欢复杂的叙事
他们更偏爱简单的故事
而虚构则可以根据需要
被编造得尽可能简单
最后，真相常常是痛苦的
虽然并非总是如此
但是现实的某些部分确实令人不适
从个人层面看
这就是人们需要心理治疗的原因
如果关于自身的一切都是愉悦有趣的
就不需要治疗师来帮助我们承认那些痛苦的记忆
或者内在的痛苦了
这一点其实也适用于整个国家
国家也常常不愿承认历史或社会中某些痛苦的部分
因此，真相有时是痛苦的
而虚构则可以被随心所欲的塑造成美好动听的故事
在这场昂贵、复杂且痛苦的真相
与廉价、简单且诱人的虚构之间的竞争中
虚构往往会胜出
所以会导致世界充斥着海量的虚构内容
因此，像大学、报社这样的机构
它们的任务已经不再仅仅是向人们提供更多信息了
而是应该为人们提供一种方法
在信息的海洋中找到那些罕见的真理宝石
并且知道如何区分两者
作为一名历史学家
尤瓦尔在历史课上教给学生的主要内容
并不是关于过去的具体史实
比如某位国王在哪一年战胜了另一位国王
这些信息学生们通过网络搜索
轻易就能获得
他们真正需要在历史课上学到的
是如何区分可靠的历史来源和不可靠的历史来源
比如一个来源可能是我们今天在互联网上看到的东西
像是TikTok上看到的视频
你是否该相信它呢？
另一个来源可能是来自中世纪的一份文件
你又该如何判断是否应该相信它呢？
因为一千年前的人们也会撒谎
而不仅仅是今天的人们
这才是核心的问题
当然，在每个科学学科中
这个问题会略有不同
但是关键都不在于如何获取更多的信息
而在于我们如何区分可靠的信息和不可靠的信息
物理学或化学实验也是同理
比如如何知道是否应该采信某个实验的结果呢？
随后，伊藤提到
阅读尤瓦尔的新书《智人之上》，
虽然给他带来了复杂的情感体验
甚至有些痛苦
但是也同时给予了他希望
因为事情还没有到无法挽回的地步
人类拥有自我纠错和合作的能力
只要我们有足够的时间
在AI发展到某个临界点之前
或许能够找到应对之道
正是基于这种考量
庆应大学成立了“跨尊严中心”（Cross Dignity Center）
希望召集人文社科学者共同应对这一挑战
他随即向尤瓦尔抛出了一个问题
那就是如果尤瓦尔是这个中心的研究员
最想要研究的课题会是什么
尤瓦尔毫不犹豫地回答道
他认为目前“最为紧迫的”课题
就是如何在人类之间建立信任
因为当前世界正目睹着人类信任的瓦解
而这恰恰发生在我们最需要信任的时刻
他强调
当今世界最大的危险其实并不是AI
而是人类之间的不信任
如果人类之间能够互相信任并且合作
我们仍然可以设计出安全发展AI的方法
正是人类间的不信任
使得AI革命变得如此危险
因此，他会聚焦在这个课题上
并且相信
现在建立足够的人类互信来控制AI
还为时不晚
那么，具体应如何着手应对呢？
尤瓦尔认为，这需要多学科的投入
因为没有任何单一学科能够独立解决这个问题
我们需要生物学和心理学的视角
我们仍然是动物
需要理解自身的动物性传承
当然也需要经济学、计算机科学的参与
因为当今所有的社会系统都建立在新的信息技术之上
许多在过去十年、二十年间非常成功的人类信任建立方法
如今可能都已经过时了
因为现在人类通过计算机进行交流
关于过去一二十年间人类信任崩溃的原因
本身也存在着巨大的讨论
而且又是一个悖论
因为从很多的硬数据来看
比如儿童死亡率、疾病、饥荒等
人类社会正处于有史以来最好的状态
但是人们却如此愤怒、沮丧
无法相互沟通
尤瓦尔认为
原因在于一种新的技术介入了人类之间
现在，大多数人类的交流
都要通过一个非人类的中介
这在世界上造成了混乱
但是要重建信任，我们不能简单地说
扔掉所有的智能手机和电脑
而是需要重新学习如何在信息技术的调解下
在广大民众之间建立信任
鉴于尤瓦尔的新书《Nexus》的日文版刚刚推出
伊藤也顺势询问了尤瓦尔对自美国领导换届以来
全球局势发展的看法
尤瓦尔表示自己充满忧虑
他指出
由于社会内部以及社会之间信任的加速侵蚀
我们看到二战后建立的国际秩序正在瓦解
这个国际秩序最重要的禁忌和规则是
强国不能随意地入侵和征服弱国
这与此前数千年的人类历史形成了鲜明对比
21世纪初
人类享受了历史上最和平与繁荣的时代
很大程度上是因为这个禁忌得到了维持
这一点从政府预算中最能清晰地反映出来
纵观历史长河
绝大多数国王、幕府将军和皇帝的预算中
超过50%都是用于军事方面的
而在21世纪初
全球政府军事支出的平均水平降到了大约6%或7%，
而大约10%的预算用于医疗保健
这是人类历史上第一次
全球各国政府在医疗上的投入超过军事
然而，如今这个趋势正在逆转
现在，如果弱者拒绝服从强者
那么由此引发的冲突，责任在于弱者
这种逻辑随处可见
比如美国曾经扬言要“征服”格陵兰岛
尤瓦尔警告说
这种世界观和逻辑将把全人类带回持续战争的状态
在这种情况下
不仅医疗和教育预算会下降
任何监管AI的机会也将不复存在
因为每个国家都会说
我们必须赢得AI竞赛
我们不会做任何可能让我们放慢脚步的事情
以免对方获胜，然后他们成为强者
我们就必须服从他们
在问答环节
有两个问题我觉得很有意思
特意挑了出来
一个是社交媒体上的虚假新闻和信息操纵问题
有观众询问如何在保障言论自由的同时
规范信息传播
特别是在算法主导信息分发的背景下
如何确保信息的质量与可信度
尤瓦尔对此进行了精确的区分
我们需要区分讲话的自由（freedom of speech）和信息的自由（freedom of information）
他强调
讲话是赋予人类的一项非常重要的权利
应该受到保护
然而，信息自由则完全不同
这是一项新的权利，它并非赋予人类
而是赋予了AI、算法和机器人
许多社交媒体巨头有意混淆这两项权利
社交媒体的问题不在于人类编造谎言
因为人类数千年来一直在编造谎言
除非极端情况，他们不应因此受罚
真正的问题在于，平台有一个算法
它决定故意传播谎言、仇恨等等
这应该被制止，并且应该受到惩罚
尤瓦尔再次明确
如果一个YouTube用户制作了一个虚假新闻视频
他不应该因此受到惩罚
但是，如果我是这家公司
我故意向数百万人推荐和播放这个充满仇恨的阴谋论视频
因为我能从中赚钱
这就应该受到惩罚
这种行为不受言论自由的保护
因为这是由算法完成的
而算法没有人权
它们没有传播谎言的权利
所以，社交媒体公司有责任
就像报纸和电视台一样
在传播任何内容之前
确保其真实性，而非充满仇恨的谎言
另一个问题是关于AI对战争形态的影响
尤瓦尔指出
信息技术的发展并不会废除物理世界
而是在其之上构建了新的层面
数千年来人类创造的各种信息
无论是法律宪法、宗教还是金钱
都没有取代或者废除物理和生物现实
人们仍然拥有身体
需要食物和清洁的水
但是这些额外的信息层
使得人类能够创造贸易网络等事物
从而改变了获取食物的方式
AI对战争的影响也与此类似
战争的本质仍然是杀伤
但是实现方式正在改变
目前看来，杀戮仍然是由人类执行的
但是，AI已经真正改变的是
谁在选择目标
谁在做决策，谁决定轰炸这座建筑
谁决定轰炸这个人
尤瓦尔指出，答案越来越多地指向AI
并且在过去两三年间表现得尤为明显
以前
识别目标的工作是由人类情报官员来完成的
他们收集信息、阅读报告
可能需要几天才能确定一个目标
但是现在
AI可以在几秒钟内完成这项工作
AI能够处理的海量信息
远超任何人类的分析能力
它能发现人类无法察觉的模式
并且在几秒钟内指出
这是敌方的总部，轰炸它
当然
最大的问题还是在于我们能否相信AI的判断？
它是否可能犯错
指示我们轰炸一个民用而非军事建筑？
尤瓦尔从不同的人那里听到了不同的说法
一些人说，在AI指出目标后
会有人类分析师复核所有得信息
以确保没有错误
而另一些人则表示
人类分析师可能只会花半分钟的时间
根本无法真正核查AI的判断
因为AI处理的数据点太多
人类的复核基本上只是走个形式
真正做决策的是AI
虽然目前这两种情况可能都有
但是展望未来五到十年
趋势是非常清晰的
那就是AI将在战争中越来越多地做出关键决策
这无疑是一个非常危险的发展
在活动的尾声
尤瓦尔对当天的讨论和问答进行了总结
他坦承
我们讨论的许多议题听起来令人忧虑
这是因为那些开发AI的公司
往往只强调了AI的积极潜力
因此需要哲学家、历史学家和批评家来指出潜在的危险
寻求平衡
问题的关键不在于如何阻止AI的发展
而是我们希望能够以安全的方式来发展它
而实现这个目标的关键
再次回到了如何“在人类之间建立信任”的问题上来
谈到这个核心主题
尤瓦尔分享了一个自己的思考
信任确实是生命的基础
如果你不信任他人，不信任外界
你连一分钟都活不下去
即便是我们赖以生存的呼吸
这个维持生命的最简单动作
它的本质也是对我们身外之物的信任
正是这种信任的吸入与呼出维持着我们的生命
所以说
即使这个世界上存在巨大的问题
但是归根结底，生命的基石是信任
好了
以上就是尤瓦尔赫拉利这次讲座的主要内容了
希望能给大家带来一些启发和思考
感谢大家的观看，我们下期再见
