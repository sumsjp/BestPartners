大家好，这里是最佳拍档，我是大飞
就在今天凌晨
OpenAI铺垫已久的草莓模型终于发布了
只不过
这款新模型的正式名称既不叫草莓
也不叫GPT，而是OpenAI o1
那为什么不继续沿用GPT的命名呢
OpenAI官方的说法是
“对于复杂的推理任务来说
这是一个重要的进展
代表了人工智能能力的新水平
考虑到这个原因
我们将模型发展的进度重置为了1
并且将这个系列的模型命名为 OpenAI o1
”可见，OpenAI敢放出如此的豪言壮语
对o1系列的信心可谓十足
各路科技媒体们的反应也没有让OpenAI失望
模型的各种测试数据一经放出
立刻引发了新一轮的互联网狂欢
大家争相高呼
o1系列已经开启了大模型的新纪元
然而，在网友们实际上手测试之后
不少人却发现
目前已经发布的o1-preiview
以及o1 mini
并没有宣传中的那么好用
甚至感受不出来和GPT4o有多么明显的差距
今天
大飞就来结合官方报告和实际的测评结果
努力给大家呈现一个真实的OpenAI o1
按照频道的老规矩
我们先来看看o1模型在各类测试中的表现
在性能评测结果上
O1确实可以称得上一句傲视群雄
根据OpenAI的官方测试
o1完全不用专门的训练
就能直接拿下数学奥赛金牌
甚至能够在博士级别的科学问答环节上
击败人类专家
为了突出相比GPT-4o 在推理性能上的改进
OpenAI在一系列不同的人类考试和机器学习基准测试中
测试了o1模型
实验结果表明
在绝大多数的推理任务中
o1的表现都明显优于GPT-4o
在许多推理密集型的基准测试中
o1 的成绩也都很好
不过
由于最近的很多其他前沿模型也在MATH和GSM8K上表现得非常好
甚至还搞出了Reflection 70B这个大乌龙
以至于这些基准测试在区分模型性能方面
让人感觉不是很靠谱
因此
OpenAI选择在AIME上来评估模型的数学能力
所谓的AIME
其实是美国的一个高水平的高中生奥数竞赛
在2024年的AIME考试中
GPT-4o的一次通过准确率只有12%，
64个样本的平均准确率为13.4%。
不过这次OpenAI发布的o1
仅预览版的一次通过准确率就达到了43%，
64个样本的平均准确率达到了56.7%，
而o1正式版的一次通过的准确率更是高达74%，
64个样本的平进准确率高达83%，
而在使用学习过的评分函数对 1000个样本重新排序后
准确率更是达到了惊人的为93% ，
相当于15分中得到了13.9分
在实际中
AIME的13.9分已经可以跻身全美前500名
并且高于美国数学奥林匹克竞赛的分数线
此外
OpenAI还在GPQA Diamond基准上评估了o1模型
这是一个相当有难度的智力基准测试
一般用来测试化学、物理和生物学方面的专业知识
为了将模型与人类进行比较
OpenAI还特地聘请了拥有博士学位的专家
同时来回答GPQA Diamond基准中的问题
而在这项测试中
o1竟然取得了超越了人类专家的成绩
成为第一个能够在这个基准测试中做到这一点的模型
值得注意的是，连OpenAI自己也说
这个成绩并不意味着
o1已经达到了可以取代人类博士的水平
而是说这个模型在解决一些需要博士解决的问题方面
会更加熟练
一些自媒体揪着这个数据大吹特吹
说o1已经可以取代人类的博士了
这显然就是一种博眼球的手段
还希望大家理性看待
我们再来看看代码方面
o1的纸面数据也是取得了新的突破
在基于o1进行了初始化
并且进一步训练了编程技能以后
OpenAI推出了一个非常强大的编程模型
称为o1-ioi
这个模型在2024年的国际信息学奥林匹克竞赛
简称IOI的赛题上，得到了213分
达到了排名前49%的水平
并且这个模型评测的条件
于参与2024 IOI竞赛的人类参赛者是一样的
也就是需要在10个小时内
解答出6个高难度的算法问题
并且每个问题只能提交50次答案
最后
OpenAI还模拟了Codeforces 主办的竞争性编程竞赛
以此来展示o1-ini模型的编码技能
这次采用的评估规则与竞赛也非常接近
只允许提交10份代码
最后，GPT-4o的Elo评分为 808
超过11%的人类竞争对手
而o1预览版得分为1258分
超过64%的人类竞争对手
o1正式版得分为1673分
超过89%的人类竞争对手
而微调后的编程模型o1-ioi
则达到了1807分
超过了93%的人类竞争对手
从以上种种成绩来看
o1的纸面数据可以说是相当漂亮
然而
当用户在官网上花大价钱体验了o1-preiview和o1-mini后
却完全没有像初次使用GPT-4那样
能感受到一种划时代的力量
相反，根据各路网友的反馈
如今官网上公布出的预览版问题很多
无论是代码能力还是逻辑推理
都比GPT-4o强的有限
但是价格却贵了不少
现在ChatGPT Plus和Team版的用户
已经可以在ChatGPT中手动选择o1-preview和o1-mini模型
暂时每周的消息限制分别为30条和50条
API访问权限将首先给到Tier 5的用户
也就是已经在OpenAI API上花费了超过1000美元的人
不少人冲着o1
也特意破费来体验了一把API
结果网友的反馈
却并不是单方面的好评
不少人用下来的第一感觉
就是模型的上下文长度与宣传的不符
按照OpenAI官方文档
o1的上下文输出可以达到64k
但是根据网友们的实测
模型输出的内容远远小于这个数字
以这张图为例
这里的提示词是“写一部黑神话悟空的同人小说
不少于2万字”，
但是模型返回的内容只有1000多字
那大家买的token都上哪去了呢？
经过各路大神的进一步测试
问题很可能出在了思维链上
这次的o1系列模型采用了全新的推理范式
Self-play Reinforcement Learning
全称是自我对弈强化学习
听起来好像很复杂
但其实我们可以用一个简单的比喻来理解
假设有一个孩子正在学习下围棋
那么一般大模型的学习方式
就是看棋谱，记住开局的布置
再背诵一些固定的战术
孩子学习了大量的数据
知道很多可能的解法
但是他们可能并不真正理解
为什么要这样下棋
而自我对弈强化学习则另辟蹊径
让这个孩子不停地和自己下棋
刚开始可能下得很快
但是通过不断尝试不同的走法
观察每步棋的结果，慢慢地
他就会发现哪些策略会更有效
哪些走法会输掉整盘棋
在这个过程中
孩子不仅仅是在记住棋谱
更是在真正理解棋局的变化
理解每一步棋为什么要这样走
自我对弈强化学习就是让AI不断地和自己"对弈"，
可能是下棋，也可能是解决数学问题
甚至是进行对话
在这个过程中
AI不只是在重复它看到过的内容
而是在主动探索、尝试和学习
显然，这个新范式的好处很多
通过这种方式
o1学会了如何磨炼自身的思维链、完善自己的策略
进而学会识别和纠正自己的错误
但是
这个策略也会让模型的思维链变得非常庞大
疯狂地吞噬掉了用户的token
而且，在API调用的过程中
OpenAI会隐藏掉模型在思维链中间的思考
比如对于同一个问题
“安徽牛肉板面，为什么是石家庄特产？
”，API的返回结果是这样的
可以看到，光是这个思维链
就一口气吃掉了用户896个token
我们再换个例子
当提示词是很简短的“你好”时
返回结果是这样的
可见模型输出了471个token
而其中448个token是用于推理
只有23个token是真实的输出
要知道，每一个token都是要算钱的
所以这样算下来，o1模型的价格
竟然是 GPT-4o-0806的6倍
再加上对推理的消耗
以及o1模型本身token的计算就要比GPT-4o要多
那么你的API开支可能会彻底爆炸
大飞来给各位简单算一笔账
以“你好”这个提示为例
4o-0806 模型的费用也就是0.00011美元
而在o1模型中，费用则为0.02841美元
在这个案例中，完成相同的任务
o1比GPT-4o贵了足足258倍
对于非极端问题
而且提示词较短的情况下
比如“安徽牛肉板面
为什么是石家庄特产？
”，
4o-0806 模型的开销为0.0021925美金
而o1模型的开销为0.086835美金
在这个案例中，完成相同的任务
o1模型比GPT-4o贵了40倍
这种开销上的暴涨属实让人觉得有点坑爹
那既然价格贵了40倍
模型的能力有没有强上四十倍呢？
至少在o1预览版上
大飞我并没有感觉到
从训练数据，以及训练时间来看
o1-preview，o1-mini
GPT-4o，4o-mini 的训练数据
都是截至到2023年10月的
在抛去思维链的行为之后
我们可以发现
o1-mini 和GPT-4o的行为和语言风格
都是极为高度相似的
当网友询问“我的猫为什么不会汪汪叫”的时候
还会出现GPT-4o中非常经典的“意图识别”。
这就让不少人产生了一个很不好的预感
这个o1-mini
不会是个拿GPT-4o进行一些微调后的agent吧？
当然了，目前这只是一个猜测
大家姑且一听
网友们之所以会有这个猜测
主要还是因为o1系列的体验
没有能和GPT4o拉开差距
当用户要求o1-mini“完整输出一篇千字文”的时候
无论是从语言识别、意图识别还是指令遵循上
都非常的不尽如人意
即便是换用所谓更强的o1-preview
结果也不太行
不仅选中的文字全是错的
而且输出也不全
就算o1-preview只是一个阉割后的先行版本
不支持联网、没有画图功能
这些还都可以理解
但是在最基础的文字生成方面
表现依然如此的平庸
这就让大伙很不满意了
一想到自己花了那么多钱
更是心在滴血
与此同时
虽然o1两个版本的代码能力目前还说得过去
但是在o1的API中
还不支持system、tool等字段
以及json mode和结构化输出等方法
还不清楚这是否是特意被阉割掉的功能
好了
以上就是有关OpenAI最新发布的o1系列模型的介绍了
这次的新模型
甚至让OpenAI不惜推倒了过去GPT系列的命名体系
重新起了一个o系列
看得出来，整个公司都对它寄予厚望
但是先行发布的版本并没有达到预期的测试效果
现在也只能是让子弹再飞一会
看看正式版的o1效果如何吧
那大家是如何看待o1模型的呢？
OpenAI能靠这款模型保持AI行业的领先地位么？
欢迎在评论区留言，感谢大家的观看
我们下期再见
