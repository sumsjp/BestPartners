大家好，这里是最佳拍档，我是大飞
在OpenAI刚刚发布了GPT-5之后
CEO Sam Altman做客了Huge Conversations的访谈
接受了YouTube知名主播克莱奥·阿布拉姆（Cleo Abram）的独家专访
在这场一个小时的对话中
Altman不仅揭秘了GPT-5研发背后的艰辛
还回答了对超级智能的看法
今天
大飞就来给大家总结一下这场访谈中的重要信息
一起来看看GPT-5究竟会带来哪些变革
以及AI未来的发展走向
首先，主持人提到
很多人可能会好奇
GPT-4已经能在SAT、LSAT、GRE等考试中超越90%的人类
还能通过编程考试、侍酒师考试和医疗执照考试
那么GPT-5又能做到哪些GPT-4做不到的事情呢？
Sam Altman提到
其实像GPT-4这样在各类考试中表现出色的AI系统
依然无法复制人类擅长的许多能力
这也反映了SAT等测试存在一定的局限性
就像在GPT-4发布的时候
人们也预测了很多积极的影响
但是也并没有完全实现
因为这些模型擅长的领域
并不能够完全涵盖我们需要人类去做、或者重视人类去做的事情
GPT-5也是如此
它在很多方面会让人震惊
但是也存在着局限性
不过，让Sam Altman感到兴奋的是
GPT-5是他头一次觉得
能够向它提出任何复杂的科学或者技术问题
还能得到相当不错答案的模型了
他举了一个很有意思的例子
初中九年级的时候
他有了台TI-83图形计算器
花了好久才编出了一个“贪吃蛇”的游戏
在学校里很受欢迎
但是给TI-83编程特别费劲
不仅耗时长
调试还难
后来他突然灵光一闪
为什么不用GPT-5的试试呢
看看它能不能做出TI-83风格的贪吃蛇游戏
结果GPT-5只用了7秒时间就完美搞定了
那一刻，Altman说他有三秒钟的恍惚
他在想，那个11岁的自己
看到这一幕是会觉得兴奋
还是会因为失去那种挣扎探索的乐趣
而感到失落呢？
他还尝试让GPT-5添加新的功能、修改外观
GPT-5都能立刻实现，这说明
GPT-5不光能够回答复杂的问题
还能几乎即时创建定制化的软件
这是GPT-5时代的标志性特征
也是GPT-4所没有的
除了编程方面
GPT-5在融入日常生活方面也有了很大进步
以前用GPT-4
人们总是会感觉互动是孤立的
而GPT-5会更自然地融入到生活中
和日历、Gmail这些工具连接起来
还会变得更主动
比如早上醒来的时候
它可能会告诉你
昨晚有些新的情况
我注意到你调整了日历
并且关于昨天你问的那个问题
我又有了些新想法
未来
OpenAI可能还会推出消费级设备
它可能会在你进行采访的时候
安静地陪在一旁，结束后对你说
刚才聊得不错
但是下次或许可以问我这个问题
因为上次那个问题我其实没答好
随后
Sam Altman回顾了一下GPT的进化史
在做GPT-1的时候
他们提出了一个当时被专家嘲笑的想法
那就是训练模型玩“游戏”，
比如给它一串词，让它预测下一个词
他们并不会直接告诉模型“这是猫”“那是狗”，
而是通过词序列来让它自己推断下一个可能的词
这在当时听起来很荒诞
但是结果证明
这种方式能让模型在没有经过显式教学的情况下
学会物理学、数学、编程等复杂概念
就和人类婴儿学习语言的过程很类似
后来他们发现
模型的效果与规模密切相关
而且需要跨多个数量级的提升
才会有显著改善
GPT-1的表现确实不佳
当时不少专家也曾断言这条路不会成功
但是他们找到了所谓的“Scaling Laws”，
也就是随着算力、内存和数据量的提升
模型的效果会按照可预测的趋势持续增强
于是他们坚定地沿着这个方向去扩展模型
最终取得了出乎意料的好结果
他们还引入了强化学习
通过让模型知道哪些答案好、哪些不好
来提升推理能力
这个方法在最初也被认为过于简单
不可能带来质的突破
但是事实证明它促成了O1、O3以及GPT-5的跃升
现在他们正探索新的视频模型
利用新的数据和交互环境来进一步扩展能力
并且他预计未来几年
算法设计的进步会保持稳定而强劲的势头
不过，这条路并非是一帆风顺
Sam Altman也分享了GPT-5发布前遇到的一些问题
比如之前发布的GPT-4.5
它的规模很大，功能也很酷
但是使用的体验并不理想
这让他们意识到
研究不仅要追求“大”，
还要探索不同“形状”的模型架构
他们原本一直认为
只要模型的参数更大
效果就会线性提升
但是后来发现，在推理能力上
还有另一条更为陡峭的“规模曲线”，
沿着它前进会获得更高的回报
在数据集方面，他们也遇到过问题
模型需要海量而且高质量的数据来学习
但是有时会受制于数据质量或者覆盖范围的瓶颈
不过，虽然每天都伴随着曲折
但是整体的趋势依然是稳步向前
对于GPT-5之后的发展
Sam Altman给出了自己的预测
他觉得一年后
AI可能还不能完全发现新的科学
但是会非常接近了
如果万一实现了
它可能会治愈更多的疾病
也可能会带来生物安全等方面的威胁
世界变化的速度可能会让人头晕目眩
经济也可能快速增长
但是人类的适应能力很强，不用太久
人们就会把这些巨变视作生活的新常态
在访谈中
主持人提到了一个很有意思的观点
就是“认知受力时间”，就像在健身中
用30秒完成一个深蹲
要比用3秒完成能带来更多肌肉增长一样
许多创造性的工作
都离不开大量的“认知受力时间”，
需要长时间的专注和思考
但是有些人可能会觉得
这些AI工具会不会成为我们逃避思考的捷径呢？
Sam Altman认为
这确实和计算器不一样
有些人用ChatGPT是为了避免思考
有些人却借助它思考得更为深入
社会本身就是个竞争场，理论上
新工具或许能让人们减少工作量；
但是在实际当中
人们会更努力地工作
对自己的期望也会更高
就像其他技术一样
有人用ChatGPT做出了更多成果
也有人做得更少
但是如果去看ChatGPT上最活跃的前5%用户
会发现他们的学习效率、做事能力和产出量都非常惊人
他自己也才刚用了GPT-5几个小时
还在摸索怎么和它互动
还调侃道，自己刚学会用GPT-4
现在又要学用GPT-5
主持人随后问了Altman几个其他大佬提出的问题
首先是Stripe的CEO帕特里克·克里森（Patrick Collison）
他问AI什么时候能取得重大的科学发现
Altman表示
大多数人可能会认为这将在未来两年内发生
但是“重大”如何定义并不清晰
不过他打赌
到了2027年末
大多数人都会同意AI已经取得了重大的新发现
目前缺少的是模型的认知能力
他还引用了一位研究员的例子
一年前
他们的模型能处理高中数学竞赛问题
但是最近
他们的模型已经获得了国际数学奥林匹克（IMO）的金牌
IMO有六道题，需要九小时完成
平均每题一小时半
这意味着现在他们能够处理从几秒到几分钟、再到一小时半的任务了
而证明一个重大的、新的数学定理
可能需要顶尖人才们一千个小时的时间
所以模型还需要继续提升
但是路已经摆在眼前了
那就是继续Scaling模型
英伟达CEO黄仁勋提的问题是
事实是客观的，而真理则是主观的
它取决于视角、文化、价值观、信仰和背景
AI可以学习并且理解事实
但是怎样才能让AI理解不同国家、不同背景的人所认同的“真理”呢？
Sam Altman坦言自己并不完全认同这种定义
不过让他惊讶的是
AI在适应不同文化背景和个体方面
表现得非常流畅
他尤其喜欢ChatGPT的增强记忆功能
因为它让他感觉这个AI真正“了解”他的兴趣、生活经历和背景
他举了个例子
有个朋友是ChatGPT的重度用户
在对话中输入了很多的生活细节
虽然他从来没直接告诉ChatGPT自己的性格
但是最近让ChatGPT以自己的身份做性格测试
结果与现实中的测试分数几乎一致
同样
他的ChatGPT在与他长期对话的过程中
也逐渐理解了他的文化、价值观和生活方式
这说明
虽然全球用户使用的是同一个基础模型
但是它可以根据个人或社区的不同需求
加入特定的上下文
让自己的行为更贴近每个人的背景与理解
这种个性化能力
也是在事实与真理之间建立联系的方式
关于未来如何分辨AI生成内容的真假
Altman考虑从技术角度来说
可以通过加密签名来验证内容的来源
但是他觉得未来的情况会更复杂
也更融合
现在，用iPhone拍的照片
虽然大多数都是真实的
但是其中都经过了AI处理
只是未必清楚具体过程
未来
公众对“真实”的判断标准也会不断的变化
问题更多会出在教育
比如媒体内容一直都是部分真实、部分虚构的
我们看科幻电影的时候
也知道那是假的
哪怕Instagram上的度假照片
都会刻意避开了背景里的拥挤人群
所以
未来会有越来越多让人感觉“不完全真实”的内容
这是一个必然的长期趋势
只不过我们最终会逐渐适应
并且接受这种状态
当被问到AI变革可能带来的影响
以及谁最会受到伤害的时候
Altman表示
不确定人们会有怎样的感受
因为我们正踏入一个未知的领域
但是他相信人类的适应力和无限的创造力
总能找到新的事情去做
但是如果变化真如预测的那样快
社会的适应速度可能会出现滞后
其中一些工作会消失
许多工作会发生显著的改变
当然也会出现新的职业
虽然社会对变化有一定的韧性
但是没有人知道这次变化会波及有多广、有多快
所以
我们需要以不同寻常的谦逊和开放态度
去思考那些不久前还无法想象的新方案
Altman还认为
社会契约可能需要根本性的改变
或许资本主义会继续正常运作
供需平衡能解决一切的问题
我们也能找到新的工作模式和价值转移方式
但是他觉得
我们可能需要思考如何分享未来最重要的资源
比如AI算力资源等等
最好的办法是让AI算力变得极其丰富、廉价
甚至超出当前的需求
让我们能够尽情发挥所有好点子
如果做不到这一点
那可能就会引发真正的冲突
所以说，如何探索新的算力分配方式
这是一个虽然听起来很疯狂、但是却非常重要的方向
当被问到对其他人的期望以及共同的责任时
Sam Altman举了一个他自己最喜欢的例子
那就是晶体管
这是一项了不起的科学发现
具有极强的扩展性
迅速融入了电脑、手机、相机等无数的设备中
曾经有一段时间
人们会关注晶体管公司
但是现在大多数人已经不会再特意想起它们
晶体管早已经融入了社会
就连“硅谷”名字的由来都快被人们所遗忘了
他相信AI也会如此
今天出生的孩子不会知道没有AI的世界
也不会特别关注AI公司
而是会关注在AI基础上构建的企业、政府的决策以及用户的行为
社会本身就是一种“超级智能”，
单个人无法达成集体努力的结果
所以说
不断有人在已有社会的基础上添加新的一层
这正是社会的美妙之处
他希望每个人都能在AI的基础上创造些什么
正如前人铺就了进步的道路
那么我们可以沿着它走下去
再为后来者添一块砖
在面对如今自己创造出来的这些东西时
Sam Altman坦言自己有很多充满敬畏的时刻
但是并不全是负面的
也有一些骄傲在其中
比如第一次与GPT-4对话的时候
那种感觉是团队长期努力换来的惊人成就
最近与一些研究员们的对话也让他深受震撼
他们的系统一天输出的文字量
可能会超过全人类的总和
现在每天有数十亿条的消息发到ChatGPT
人们依赖这些回复工作、生活
所以，研究员们的一个小调整
就可能影响到模型与所有人的交互
由于这项技术拥有巨大的力量
而且发展速度太快
所以他们必须思考在这种规模下
改变模型“性格”的意义究竟何在
对于市面上很多的AI威胁论
Sam Altman表示很难理解那些说AI会毁灭我们
却还每周工作100小时来开发AI的人
如果他真的相信它会带来毁灭
那应该去农场生活
或者倡导停止开发
又或者专注于安全研究
他假设他们是真诚的
但是或许存在一些他也无法理解的心理因素
不过，他能理解的另一种情况是
有人认为AI有99%的可能带来好处
1%的可能引发灾难
因此想把那99%的概率提升到99.5%，
这种态度他能接受
最后 当主持人征询Altman对下一个被采访者的提问时
Altman表示
他自己总是会好奇这几个问题
比如你为什么会选择这个方向？
它是怎么开始的？
在其他人看到这些机会之前
你又先看到了什么？
他觉得，在做一件有趣事情的人
往往能比共识更早的察觉到机会
正如他自己从小就是一个AI迷
大学学的是AI
还在AI实验室工作过
以前看科幻电视剧的时候
就觉得能造出AI的人很酷
不过，他从没想过自己会参与其中
在大学的时候
AI对他来说还遥不可及
直到2012年AlexNet论文发布
他和Ilya Sutskever合作的时候
才第一次觉得可能有可行的方法
也没想到真的开始走向成功了
好了
以上就是Altman在GPT5发布后的最新访谈内容了
目前网上对GPT5的评价
虽然在编程和科学方面有亮点
但是总体来说都不是很高，接下来
还要看GPT5更多的一些应用案例
以及对社会的渗透程度了
我们也会保持关注
为大家更新AI行业的最新变化
感谢大家观看本期视频
我们下期再见
