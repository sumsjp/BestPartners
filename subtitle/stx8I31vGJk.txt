大家好，这里是最佳拍档
最近
OpenAI的创始元老、PPO算法之父、RLHF架构的灵魂人物约翰·舒尔曼
在一场深度访谈中
详细拆解了OpenAI的崛起之路
并且分享了他对AI研究本质、强化学习趋势、AGI时间线的犀利看法
甚至还透露了自己新公司Thinking Machines的重磅产品
这场谈话
可以说是来自AI核心战场亲历者的第一手观察
是褪去行业神话外衣之后
关于技术、团队和趋势的最真实的思考
今天我们就来给大家分享一下
现在的AI行业似乎已经形成了一种共识
大模型的成功
离不开海量的算力堆砌
从GPT 3的一千七百五十亿参数
到如今动辄万亿级别的模型规模
算力仿佛成了衡量AI实力的唯一标准
也成了很多创业者望而却步的门槛
但是约翰·舒尔曼却在访谈中抛出了一个颠覆性的观点
他说，算力从来不是唯一的瓶颈
如果带着现在的后见之明
回到二零一八年
只需要两三个人，用几台V100显卡
一年内就能搓出接近GPT 3.5水平的模型
这个说法初听之下确实令人震惊
毕竟OpenAI当年推出ChatGPT的时侯
背后是微软百亿级别的算力支持
是数百人的团队协作
但是舒尔曼作为RLHF架构的核心设计者
他的观点显然不是信口开河
他提到了一个关键的案例
nanochat项目
这个项目由一个人独立开发
只用了半年时间编写代码
就能在单台H100显卡上运行
虽然H100是比V100更先进的显卡
但是舒尔曼认为
即便在二零一八年只有V100的情况下
通过将几台GPU设备联网
结合现在成熟的后训练和微调技术
一个小团队完全有能力实现接近GPT 3.5的效果
舒尔曼解释道
很多人误以为只有GPT 3这种级别的超大模型
才能够打造出优秀的少样本提示聊天模型
但是实际上，通过优化后训练的流程
就能够大幅度提升计算资源的利用效率
如果还愿意投入大量的精力进行微调
并且巧妙的构建微调数据集
即便模型规模小得多
也能达到相当不错的效果
换句话说，技术方法的巧思
能够在很大程度上弥补算力的不足
而OpenAI当年之所以没有更早推出ChatGPT
并不是因为算力不够
而是因为当时还没有掌握这些成熟的后训练和微调技巧
只能够通过堆算力这种更粗暴的方式来推进
舒尔曼还补充道
这一切的前提是知道最终的技术路径和目标方向
如果当时的团队能够预见到ChatGPT的巨大回报
其实可以更快的扩大规模
而且
这也得益于其他人已经完成的预训练数据集和网络爬取的成果
不需要从零开始构建数据基础
他甚至大胆的预测
未来可能会出现更极致的情况
如果是演示级别的ChatGPT
只需要一个文件就能够完成整个训练的流程
自动爬取网络的数据
一天内就能完成训练
这无疑给那些担心算力门槛的创业者和研究者们带来了新的希望
这也证明，AI的进步
从来不是算力的独角戏
技术创新和方法优化同样非常的重要
提到如今的OpenAI
人们想到的是市值千亿、引领AI革命的科技巨头
但是很少有人知道
早期的OpenAI其实是一个相当非正式的、临时拼凑的小团队
舒尔曼在访谈中坦然的承认
二零一六年的OpenAI
更像是一个松散的学术研究小组
团队里的人都是基于个人兴趣的驱动而开展的工作
压力并不大
当时的工作模式大多是一到三人的小团队
研究成果往往只是一篇论文或者一篇博客文章
并没有明确的商业化目标或者产品导向
但是即便是这样的一个草台班子
也有着远大的野心
他们当时就认为，和学术界相比
通过开展专业的工程实践、组建更大规模的项目团队
能够取得更大的突破
而这个想法
很大的程度上受到了DeepMind的影响
DeepMind在AlphaGo等项目中
率先采用了研究人员加工程师协同推进的、大型项目的工作模式
这给了OpenAI团队深刻的印象
因此，早期的OpenAI呈现出了一种
小型研究项目和大型项目并存的状态
核心思路是整合研究人员和工程师的力量
探索AI的前沿领域
不过
探索的道路从来都不是一帆风顺的
大多数研究项目最终都没有成为公司发展的主流方向
一些大型项目也以失败告终
舒尔曼分享了一个非常典型的例子
Universe项目
这个项目的核心思路
是创建大量不同的强化学习环境
构建一个完整的数据集
将这些环境整合起来
希望模型在所有这些环境训练之后
能够具备良好的泛化能力
从而打造出一个性能卓越的AGI智能体
为了实现这个目标
团队收集了大量不同的电子游戏和网页导航任务
想要将它们整合到一起
但是这个看似正确的想法
却因为生不逢时而失败了
舒尔曼认为
Universe项目的本质思路是完全正确的
但是实施得太早了
可能早了整整十年
当时很多必要的前提条件都还不具备
一方面，整个系统非常难以操作
并不适合开展强化学习实验
另一方面
由于模型是从零开始训练的
泛化能力其实并不是很好
虽然团队最终搭建了这个系统
并且开始进行实验
但是并没有取得预期的成功
不过，失败并不是毫无价值的
舒尔曼后来带领团队从事强化学习研究时
就借鉴了Universe项目的经验教训
他们没有像之前那样
试图收集所有能在电脑上完成的任务
而是专注于模拟电子游戏
事实证明，这种简化后的做法
更利于开展研究
也取得了更好的效果
除了Universe项目
早期的OpenAI还有一些其他的死胡同项目
比如机器人的相关研究
这些项目虽然没有直接带来商业成功
但是从长远来看
却为OpenAI积累了宝贵的财富
通过这些项目
团队学会了如何开展大型工程和研究项目
也培养了一批具备相关工作经验的人才
为后来ChatGPT等产品的成功奠定了基础
而在早期的大型项目中
Dota项目可以说是第一个真正成功的案例
这个项目投入了大量的计算资源
不仅涉及到了机器学习系统的开发
还需要搭建大型的代码库和相关系统
同时开展了大量特定场景下的强化学习研究
舒尔曼回忆道
Dota项目的工程工作主要分为两个方面
一方面是环境基础设施的搭建
比如如何接入Dota游戏、构建训练环境
另一方面是训练系统的开发
这个系统需要支持大规模的部署、并行训练
还涉及到异步强化学习等复杂技术
理想的情况下
训练系统应该和环境基础设施分离
但是在实际操作中
两者往往无法完全的割裂
需要紧密的配合才能确保项目的推进
随着AI领域的快速发展
越来越多的大型科学研究正在展开
团队规模也越来越大
这就对研究管理者提出了更高的要求
毕竟
被管理的团队成员往往都是性格各异、能力突出的专业人才
如何协调他们的力量
激发创新的潜力
成为了一个关键问题
作为在OpenAI、Anthropic、Thinking Machines等多家顶尖AI机构任职过的资深研究者
舒尔曼对这个问题有着深刻的见解
在舒尔曼看来
理想的研究管理者并没有统一的模板
他见过很多人采用截然不同的管理方式
却都取得了成功
而且，这个领域一直在变化
七、八年前有效的管理方式
现在可能已经不再适用
他将常见的成功管理模式分为两种
一种是亲力亲为型
管理者自己会编写大量的代码
审阅团队成员的所有代码
并且提供了非常详细的技术反馈
另一种是放手型
管理者更多的扮演了智囊团的角色
为团队成员提供职业发展的建议
而不是具体的技术指导
主要负责保持团队成员的积极性和满意度
让大家能够自主的开展工作
这两种模式之所以都能够成功
核心在于它们适用于不同的场景
舒尔曼解释道
如果开展的是探索性研究
而且团队成员都是经验丰富的独立贡献者
那么采用放手的管理模式是合理的
因为在这种情况下
给予研究者足够的自主权
让他们按照自己的思路去探索
往往能够发现一些有趣的而且有价值的成果
但是如果项目更注重目标导向
或者团队成员的经验不足
又或者需要执行具体明确的任务
那么管理者就需要亲力亲为、提供更多技术监督的模式可能更合适
毕竟，在这种场景下
需要有人把控方向，解决技术难题
确保项目能够按时按质量的完成
谈到OpenAI的管理模式的灵感来源
很多人可能会以为它借鉴了贝尔实验室、施乐帕洛阿尔托研究中心等历史上成功的工业研究实验室
但是舒尔曼却透露，事实并不是这样
至少对于他而言
OpenAI并没有从这些实验室寻求灵感
团队更多是借鉴了成员之前工作过的地方的经验
比如
大多数人都有研究生阶段的经历
或者曾经在Google Brain、DeepMind等机构工作过
因此，谷歌和DeepMind的工作方式
在很大程度上影响了OpenAI的运作
不过，团队也确实讨论过
一些类似于曼哈顿计划这样的大型项目案例
但是并没有刻意的去分析和借鉴历史上最成功的研究机构
更多的还是在实践中不断的摸索
作为对比
舒尔曼也分享了早期的OpenAI
和他现在创办的Thinking Machines之间的差异
他发现两者之间有很多相似的地方
比如都有许多个不同的项目同时在推进
公司的愿景也在不断成型的过程中
愿景往往是随着这些不同项目的推进而逐渐清晰的
但是两者所处的行业发展阶段却截然不同
在OpenAI早期
虽然已经有了DeepMind
但是行业内并没有形成一致的竞争方向
也没有明确的发展路径
当时大家可能都有扩大强化学习、提升它的性能、探索更优模型架构等想法
但是并没有一个所有人都在全力推进的核心方向
所以在某种程度上
OpenAI的早期更像是一个和平时期
这也促成了更多的探索性工作的开展
而现在，行业发展的速度非常的快
还有其他公司也在迅速的崛起
所以Thinking Machines等新兴公司在一段时间内
会面临着追赶模式的压力
需要先复制当前的最先进技术
再开展自己想做的新事情
舒尔曼非常清楚这一点
所以他一直努力确保Thinking Machines不仅处于追赶的模式
同时也在积累探索性研究的能力
探索那些并不是行业主流方向的新想法
因为他知道
如果一直处于追赶的模式
之后再想培养探索性研究的能力
就会变得十分困难
而且，构建合适的创新文化
也并不是一件简单的事
作为PPO算法之父、RLHF架构的灵魂人物
舒尔曼在强化学习领域有着举足轻重的地位
而他对于强化学习未来趋势的判断
也备受行业的关注
在访谈中
他围绕着价值函数的命运、持续学习的解决方案、泛化能力的瓶颈
以及协同训练的前景等关键问题
分享了自己的独到见解
首先是价值函数的争议
如今，在很多强化学习研究中
价值函数已经不再流行
这让很多人疑惑
价值函数是否已经过时了呢？
舒尔曼给出的答案是否定的
他认为
在当前人们开展强化学习研究的场景中
价值函数的帮助并不大
但是这并不意味着价值函数失去了价值
它的主要作用是减少方差
而且在这方面确实是效果显著
在当前的这类任务中
价值函数带来的方差减少效果并不明显
而在其他一些强化学习的研究任务中
它却能显著的降低方差
至于背后的具体原因
舒尔曼表示目前还很难说
但是他预计
价值函数在未来的某个时候会重新流行起来
接下来是持续学习的难题
持续学习是AI走向实用化的关键之一
它要求模型能够像人类一样
不断的学习新知识、新技能
而不会遗忘之前所学的
舒尔曼认为
持续学习可能有多种含义
用心理学的类比来说
学习包括情景记忆、新知识学习、程序性记忆等不同的类型
因此
不同类型的学习可能需要不同的方法来支持
他预计，上下文相关的方法
或者上下文管理技术会持续发展
长上下文的处理能力也会变得越来越重要
而对于大家关注的Lora技术
舒尔曼认为它会作为补充
或者说参数微调会在这个基础上发挥作用
并且对于某些类型的记忆会更加有效
尤其是那些需要大量容量、吸收大量知识的记忆类型
不过，舒尔曼也指出
持续学习的解决方案可能并不是单一的
如果我们继续扩大模型的规模、提升模型的性能
那么我们设定的所有指标都将得到持续的改善
甚至有观点认为
即使不改变现有的方法论
甚至不进行参数的微调
最终可能也可以解决所有这些问题
但是舒尔曼更倾向于认为
一些新的思路会更快的解决这些问题
并且可能会带来不同的缩放定律
要么是通过固定乘数提高有效的计算效率
要么是采用不同的方法
缩放定律的斜率会发生变化
因此
其他方法可能会带来更好的缩放效果
或者更快、更有效的持续学习能力
在具体的应用场景上，舒尔曼认为
上下文学习在短时间的跨度场景中会非常有效
而且在这个范围内很难被超越
但是从更长的时间跨度来看
权重更新可能会更加具有优势
而参数微调则可能在某个中间场景中发挥作用
比如当有更多需要记忆的内容时
泛化能力的脆弱性问题
也是很多人担心的一个关键点
我们的模型可能在预训练阶段做得很好
但是在运用强化学习的时候
它只能在特定领域和数据分布中发挥作用
而在跨领域迁移方面表现不佳
这是不是会成为通用人工智能在多个知识工作领域有效发挥作用的障碍呢？
舒尔曼坦言
关于模型的泛化能力有多强
以及它们的样本效率与人类相比是怎样的
目前还很难给出明确的结论
比如，在上下文的学习中
模型的样本效率可能和人类相当
甚至比人类更高
但是在某些类型的训练中
模型需要的数据量
会远远超过人类学习相同内容所需要的数据量
所以
模型在某些方面确实比人类要脆弱得多
但是很难清晰的界定
这些方面具体是什么
他认为
人类在更长的时间跨度上表现的更好
是因为进化已经让我们适应了长达八十年的时间跨度
而且人类拥有了很多自我纠正机制
虽然人们并不完美
但是在纠错方面确实相当的出色
如果给人们设定一个目标并且激发他们的动力
他们会变得非常的足智多谋
会尝试各种不同的方法
而模型在某些情况下虽然也可能非常执着
甚至比人类更加执着
但是在处理大量的工作时
它们往往更容易陷入困境
如果验证过程中包含了模型的推理和指令遵循能力
并且利用好这些能力
为生成模型提供学习信号
那么随着模型在推理和指令遵循方面的能力得到提升
它也会成为更好的验证器
从而形成一个良性的循环
因此，这个思路非常有意义
舒尔曼个人也很喜欢多智能体训练或者博弈相关的理念
比如设计零和博弈，或者多人博弈
使得博弈的均衡点具有非常有价值的特性
博弈带来了很多良好的属性
比如自动的课程学习
当你在博弈中和自己的复制品对抗时
对手会随着你的进步而同步变强
此外，从理论计算机科学的角度来看
设计这类博弈也有它的合理性
比如，有一些不同的复杂度
是基于双人零和博弈所定义的
其中包含一个多项式时间裁判和两名玩家
而这个博弈的均衡点可以解决一个非常困难的问题
因此，通过一个计算成本较低的过程
你可以创建一种激励机制
使得均衡点的达成需要解决这个难题
在对齐的相关文献中也有一些关于这个理念的讨论
特别是辩论博弈的想法
舒尔曼认为非常的有说服力
虽然现在已经有了一些相关的研究
但是他预计这类理念会变得越来越重要
如今，技术发展迅速
很多人都在预测AI进步的速度
尤其是对AGI什么时侯会实现的预计
已经成为行业内的一个常见对话题
大多数人谈论AGI时
指的是计算机上的所有知识工作
都能由AI而不用人类完成
但是在这种乐观的预测背后
是不是存在被低估的难度呢？
访谈中
主持人提到了一个非常有趣的观察
工程师和研究人员在估计一个非常小的项目
什么时候能够完成的时候
表现都会非常的糟糕
因为他们存在一种系统性的偏见
总是假设自己能比实际更早的完成任务
主持人通常会在他们的预测基础上乘以三倍
这样得到的结果
更加接近实际完成的时间
那么
这个对大多数人AGI时间线的批评合理吗？
研究人员是不是普遍低估了实现AGI所需的时间呢？
舒尔曼对此表示完全认同
他认为
确实存在着持续低估时间线的偏见
在理想情况下
可能需要乘以两到三倍
所以，使用这种启发式的方法
有理由预测AGI的实现时间
会比人们给出的明确预测要稍微晚一些
最类似的例子可能是自动驾驶汽车
我们已经看到
实现完全的自动驾驶和RoboTaxi等目标所花费的时间
比人们预期的要长得多
因此，舒尔曼认为这个假设是合理的
但是他也指出了问题的另一面
AI会加速自身的发展
这可能也会超出人们的直觉
所以，那些考虑到这个效应的人
会给出相当短的时间线
这个推理也有一定的说服力
因此，舒尔曼表示
他对于AI的发展能带来多大的提升
存在着很多的不确定性
也不确定是否存在人类理解能力等方面的瓶颈
所以，无论哪种预测
他都不会过于自信
离开OpenAI后
舒尔曼并没有停下脚步
而是创办了新公司Thinking Machines
并且推出了一款名为Tinker的产品
这款产品被舒尔曼定位为底层微调的API
它的出现
可能会彻底改变AI模型微调的游戏规则
在访谈中
舒尔曼详细介绍了Tinker的核心定位和功能
他表示
Tinker提供了一组小型的底层原语
用来执行训练和采样任务
借助它
用户几乎可以实现所有想要的后训练算法
而且无需担心GPU或者加速器的相关问题
也不需要处理大量分布式系统相关的复杂事项
它试图找到一个值得抽象的良好层级
并将它构建成为一项服务
通常情况下
人们不会使用服务来进行机器学习的训练
现有的相关服务也多是更高层级的
因此，Tinker的新颖之处在于
它是围绕这些底层原语构建的服务
最接近的类比其实是OpenAI、Anthropic等公司提供的采样API
你无需自己启动GPU设备来进行采样
只需要通过Python、JavaScript等语言调用API即可
而借助Tinker
用户基本上可以通过编写一些Python脚本
就能够完成大量的训练代码
这些脚本可以直接运行
无需担心安装大量GPU相关的依赖项
谈到Tinker的目标用户，舒尔曼表示
目前来说
Tinker附带了大量的开源代码
所以用户不需要自己编写所有的训练算法
因此
Tinker最适合那些想要了解细节并且深入研究的用户
但是随着时间的推移
团队会让它变得越来越容易使用
在Tinker之上构建更加多的工具和高层级的组件
使它成为一个全栈解决方案
不需要专家级知识就能使用
届时
用户只需明确自己想要解决的业务问题
或者想要构建的模型规格
Tinker提供的软件就能帮他们实现
舒尔曼的最终愿景
是让很多初创公司不需要开发自己的基础设施
只需要在Tinker之上
构建非常复杂的定制模型
并且实现规模化就可以
这无疑会大幅度降低AI创业的门槛
让更多的创业者能够专注于模型创新和应用落地
而不是被底层的算力和分布式系统问题所困扰
对于Thinking Machines的未来规划
舒尔曼表示，在明年的某个时候
公司会推出自己的一些模型
同时，团队也会持续改进Tinker
添加更多的模型功能
比如多模态训练、各种多模态的输入输出
以及大幅度提升Tinker所能处理的任务规模
这意味着
未来的Tinker不仅能够支持文本模型的微调
还能涵盖图像、音频、视频等多种模态
处理更加复杂、更加大规模的训练任务
从Tinker的设计理念中
我们不难看出舒尔曼的初心
他希望通过技术的创新
让AI研究和开发变得更加高效、更加普惠
正如他之前所说
算力不是唯一的瓶颈
技术方法的优化同样重要
而Tinker的出现
正是通过优化模型微调的流程和工具
让更多的人能够参与到AI的创新中来
这或许会成为AI行业发展的一个新的增长点
作为AI领域的顶尖研究者
舒尔曼的个人研究习惯和工作方式
也给很多从业者带来了启发
在访谈中
他分享了自己怎样使用AI的工具辅助研究
以及自己一天的工作日常
舒尔曼表示，他经常用AI来编程
比如频繁使用Cursor、Claude Code以及其他的一些工具
他每天都会打开多个不同模型的聊天窗口
一天会向它们提问很多次
这些问题不仅包括一些需要查找答案的内容
更重要的是
他会用AI来辅助自己的研究过程
比如，现在如果他有一个模糊的想法
会写一两段文字
然后让模型帮他进一步的充实内容
他觉得这非常的有帮助
尤其是文献检索功能
以前查找相关文献需要花费很长的时间
现在借助AI工具，效率大幅度的提升
这还包括查找开源库
现在也变得容易多了
除了辅助研究
舒尔曼还会用AI来辅助写作
比如获取写作的反馈
不过他也强调
通常大部分思考工作还是由他自己完成
但是之后会把聊天模型当作第一轮反馈的来源
帮助自己优化内容
而谈到自己的工作日常，舒尔曼表示
他经常去咖啡馆
他喜欢在咖啡馆思考
周围有一些活动的氛围
他可以拿着咖啡、带着笔记本
随手记下一些想法，远离干扰
尤其是在项目的想法形成阶段
在思考应该做什么的时候
他会经常这样做
而当项目进入执行阶段的时候
如果是需要自己亲自参与
他就会开始编程
或者花很多时间阅读其他人写的文档、消息
查看他们的图表和代码
现在
他也要花很多时间来做研究指导的工作
主要是审阅其他人的研究成果
随着AI领域的快速发展
特别是二零二零年缩放定律出现以来
越来越多的研究人员进入了机器学习领域
既有学术界的，也有工业界的
但是一个有趣的现象是
尽管领域内的研究人员数量增长了十倍甚至一百倍
重大突破性想法的产生速度却似乎保持着稳定
这个现象背后的原因是什么呢？
而进入这个领域的人员特质
又发生了怎样的变化呢？
舒尔曼认为
这类关于量化科学进步速度的问题
总是有些棘手
而且很难准确的衡量近期的进步速度
毕竟还不知道
哪些想法最终会被证明是重要的
所以，他不太愿意轻易的下结论
即便研究人员的数量大幅度的增加
进步速度也没有真正的加快
不过，舒尔曼也给出了自己的观察
他说
如果你回顾七十年代、八十年代、九十年代的论文
会发现当时的实验严谨性比较低
如今
在实验严谨性方面的标准已经有所提高
比如尝试基准方法、在不同任务上开展大量的实验等等
在过去
一篇强化学习的论文可能提出了一系列复杂的想法
但是只在一个玩具任务上做了一次可疑的实验
却能成为开创性的论文
而且当时很多数学理念也并不复杂
因此
舒尔曼并不惊讶于随着更多人进入到这个领域
想法的产生速度
实际上已经大幅度得到提升
同时在某些方面的标准和质量也有所提高
总体而言
我们很难直接比较两个时期的人才分布
但是考虑到现在的人数规模
舒尔曼认为准入门槛已经提高了
因为太多人想要进入这个领域
争夺这些职位
同时，他也指出
现在工程技能的重要性比以前更高了
而研究品味的重要性则相对下降
因为如今规模化带来了许多的进步
很多简单的想法
通过规模化和高效执行就能够收获显著的成果
让这个领域已经变得更加成熟
你不再需要在Jupyter Notebook中从零开始编写大量的代码
而是在他人的代码库基础上进行开发
同时还有很多优质的基础设施可以利用
由于需要大量整合他人的代码和工具
所以拥有软件工程背景的人
现在会更加具有优势
纵观整场访谈，舒尔曼的一系列观点
其实都指向了一个核心问题
AI的未来，到底是算力的胜利
还是技术方法和研究品味的回归呢？
从他的分享中，我们可以清晰地看到
舒尔曼更倾向于后者
他用ChatGPT本可以早三年诞生的假设
告诉我们算力并不是唯一的瓶颈
成熟的后训练技术、巧妙的微调数据构建
同样能够实现惊人的效果
他用OpenAI早期的失败项目
告诉我们AI的进步从来不是一帆风顺的
那些看似超前的想法
需要合适的时机和前提条件才能开花结果
他还用强化学习的趋势判断
告诉我们那些被遗忘的经典理念终将回归
因为它们背后有着坚实的理论基础
以及用Tinker的产品愿景
告诉我们技术创新的核心
在于降低门槛、提升效率
让更多的人能够参与到AI的创新中来
感谢收看本期视频，下期再见
