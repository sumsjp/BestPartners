大家好，这里是最佳拍档，我是大飞
8月8日
吴恩达接受了The Moonshot播客的专访
围绕吴恩达的学术生涯起点、Google Brain项目的创立与发展、以及AI的未来趋势
回顾了Google Brain赖以成功的两大颠覆性基石
也就是规模至上与单一学习算法
这两个假说的提出与论证
以及在当时学术界主流范式下
这些观点所遭遇的巨大阻力与争议
此外
吴恩达还谈到了Google Brain团队的关键合作、硬件选择的曲折之路、早期应用场景的开拓、以及他对AI未来、教育和工作的看法
今天我们就来回顾一下这场访谈的核心内容
了解一下那段对吴恩达来说
充满挑战与突破的岁月
故事要从吴恩达的博士时期说起
当时，强化学习领域还相当冷门
但是他却用一个小型神经网络
成功控制了一架无人直升机保持悬停
这在当时可以说是一项重大的突破
正是这个实验
让他对神经网络有了更深刻的认识
也为他后来的理论奠定了基础
提出了“规模决定性能”和“单一学习算法”的观点
不过在当时
这些观点可没少受到质疑
在2010年左右
当吴恩达在学术会议上和人们谈论扩展深度学习算法的必要性时
一些非常资深的学者给他的建议是
嘿，吴恩达
你为什么要去构建更大的神经网络呢？
你应该去发明新的算法
就连他很尊敬的前辈
约书亚·本吉奥（Yoshua Bengio）也曾经告诫他
吴恩达
这样做对你的职业生涯没有好处
但是吴恩达并没有被这些声音所动摇
因为他手里握着一件“秘密武器”，
那就是数据
他的学生亚当·科茨（Adam Coates）和洪拉克·李（Honglak Lee）绘制了一张图表
横轴是模型的规模
纵轴是模型的性能
他们测试了大量不同的模型
结果发现，研究的每一种模型
它的性能曲线都坚定地一路向右上角攀升
基于这些数据，吴恩达确信
构建的模型越大，它的性能就会越好
他知道，作为一名科学家来说
不能光靠民意调查来做研究
虽然听取他人意见固然重要
但是最终必须有自己坚信不疑的假设
而他的假设
正是由这些数据所塑造的
除了“规模决定性能”的假设以外
“单一学习算法”的提出也很有启发性
吴恩达当时深受神经重塑实验的启发
这些实验表明
如果大脑的某个区域受损
其他的区域可以重新学习
接管受损区域的功能
比如用处理听觉的大脑区域去学习处理视觉
这让他开始思考
我们真的需要为视觉、听觉等不同的任务
开发完全不同的算法吗？
还是说
可能存在一种通用的学习算法
给它什么样的数据
无论是文本、图像还是音频
它都能够学会处理呢？
现在看来
“单一学习算法”这个提法可能过于简单了
甚至在某种程度上是错误的
吴恩达也认为
当时过分强调了从神经科学中寻找直接灵感的必要性
来自神经科学的具体细节在大多数情况下其实并没有太大帮助
尽管如此，那个更高层面的想法
也就是人类大脑可以依赖一种通用算法来处理多种任务
依然极具启发性
它引导着吴恩达去思考
与其让一万名研究者去发明一千种不同的算法
不如集中一小部分人
去发明一种足够强大的算法
然后用各种数据去训练它
事实证明，这条路走对了
不过，在当时
这个想法简直就是异端邪说
吴恩达记得有一次在国家科学基金会的研讨会上
他讨论了“单一学习算法”的假说
当时他还很年轻
在演讲中调侃了计算机视觉领域传统的手工工程方法
一位非常资深的计算机视觉研究者当场站起来对他大声斥责
作为一个年轻教授
那次经历确实有点打击人
但是多年以后
他可以笑着回顾这一切
因为结果证明他的方向是正确的
带着这些想法
吴恩达开始寻找能够将它付诸实践的地方
而当时谷歌旗下的创新实验室X
成为了那个关键的平台
这背后
德国计算机科学家、前Udacity的CEO塞巴斯蒂安·特龙（Sebastian Thrun）起到了重要的作用
当时在斯坦福
吴恩达和塞巴斯蒂安的办公室就隔着一堵墙
吴恩达在这边敲墙
塞巴斯蒂安在另一边就能听到
当时
吴恩达在斯坦福的学生已经通过实验证明
构建的神经网络越大
学习系统的性能就越好
他感觉自己手里握着一份“秘密”数据
其实说它秘密也不尽然
因为他到处宣讲
但是人们就是不相信他
这或许反而是件好事
塞巴斯蒂安听了吴恩达的想法之后对他说
谷歌有的是计算机
你为什么不直接去向谷歌推介这个想法
让他们把谷歌海量的计算资源给你用
去构建一个前所未有的大型神经网络呢？
于是
塞巴斯蒂安为吴恩达安排了一次向拉里·佩奇（Larry Page）推介的机会
吴恩达记得自己用笔记本电脑精心准备了幻灯片
带齐了所有的材料
但是他们是在一家日式餐厅见的面
那种环境下实在不方便拿出笔记本电脑
所以最后，他只是和塞巴斯蒂安一起
跟拉里·佩奇口头聊了聊他的想法
幸运的是
拉里·佩奇当场就接受了他的观点
并且授权了他与塞巴斯蒂安以及X实验室的合作
推进这个后来成为谷歌Brain的项目
那顿晚餐，吴恩达至今记忆犹新
对他而言，那是一次决定成败的谈话
他至今仍然非常感谢拉里·佩奇愿意相信
他那个在当时听起来非常疯狂的愿景
进入X之后，谷歌Brain项目正式启动
而杰夫·迪恩（Jeff Dean）的加入
被吴恩达视为天大的幸运
在拉里·佩奇的指导下
当吴恩达和塞巴斯蒂安准备启动这个项目的时候
拉里·佩奇让吴恩达去和谷歌内部的许多人交流
吴恩达和杰夫·迪恩、格雷格·科拉多（Greg Corrado）、汤姆·迪恩（Tom Dean）、杰伊·亚格尼克（Jay Yagnik）等许多人都聊过
他向杰夫·迪恩展示了自己的想法
如果能用上更大规模的神经网络
一切都会变得更好
这个想法让杰夫·迪恩兴奋不已
随着项目的推进，所有参与者都明白
如果能让杰夫·迪恩更深入地参与进来
他将发挥不可估量的价值
幸运的是
杰夫·迪恩对他们的工作抱有极大的热情
随着时间的推移
尤其是在他深度参与之后
他们自然而然地形成了分工
杰夫·迪恩成为了系统专家
他构建了谷歌大部分的基础设施
并且对规模化有着深刻的理解
而吴恩达则专注于机器学习的算法
这种伙伴关系被证明是无价的
吴恩达在机器学习方面的专业知识
加上杰夫·迪恩对计算机系统的了解
让他们能够有效地利用谷歌的基础设施
扩展机器学习算法
最终交付了一个真实而且有影响力的成果
杰夫·迪恩为谷歌乃至世界带来的一项重要贡献
就是解决了一个极其困难的问题
如何在全世界所有潜在的搜索信息中
找到用户想要的东西
并且在毫秒内返回结果
这意味着必须将问题分解
而这种“分解问题再重组结果”的模式
与他们在训练日益庞大的神经网络时所做的工作非常相似
杰夫·迪恩发明了后来大名鼎鼎的MapReduce技术
它的核心就是将工作分解
分配到许多计算机上进行并行执行
然后再将结果汇总
这是他们早期训练模型的第一个版本
后来随着不断迭代
最终才催生了TensorFlow等等技术
不过，在谷歌内部
拥抱GPU的过程却花了更长的时间
吴恩达回忆
如果说谷歌Brain有什么遗憾
那就是他希望能够更早地拥抱GPU
或者说更早地启动TPU的决策
其实他们很早就看到了GPU的潜力
比如当时就有一两台GPU服务器
但是吴恩达至今仍然能够想起
它被放在某人的办公桌下
周围缠绕着一堆电线的场景
通过那台计算机
他们意识到了GPU的巨大作用
但是从谷歌整体基础设施的角度来看
存在一个当时看来也很合理的顾虑
那就是
当时谷歌的计算基础设施非常统一
任何人写的代码
几乎都可以在任何地方无缝运行
然而，GPU是一种截然不同的硬件
这意味着程序员需要做额外的工作来适配它
他们当时还在考虑
购买大量的GPU是否对其他任务
比如YouTube的视频转码也有利
以及它们除了训练AI模型以外
是否还有其他的用途
由于这些顾虑
他们在谷歌内部推进GPU的步伐有所放缓
没有像吴恩达当时可能希望的那样积极
最终，吴恩达在斯坦福大学的团队
率先用GPU进行了演示性工作
后来随着谷歌Brain团队更多地转向GPU
并且开始构建TPU
效果之好，可以说是有目共睹
在谷歌Brain早期的时候
面对像翻译、语音转文本或者图像识别等众多的领域
他们又是如何挑选重点方向的呢？
吴恩达刚加入X时，最早做的事情之一
就是在谷歌内部开设了一门关于神经网络的课程
他记得当时和汤姆·迪恩以及格雷格·科拉多密切合作
这门课非常成功
有近百人参加
他们每周开会
分享吴恩达关于神经网络和规模化的“非主流”想法
并且讨论在谷歌大脑的工作
幸运的是
这帮助他们在谷歌内部结识了许多朋友
找到了许多盟友
他们最早合作的团队之一是语音团队
原因有二
首先
他们认为规模化在改进语音识别方面有巨大的潜力
当时，语音搜索还不像现在这么成熟
但是与手机应用对话
用声音在谷歌上搜索这个想法
确实非常激动人心
所以他们想要提高语音转录的准确性
另外
当时的语音团队已经开始研究神经网络了
他们觉得通过帮助语音团队实现规模化
可以显著提升谷歌的语音识别能力
所以，这在一定程度上是顺势而为
关键在于谁愿意与他们合作
以及他们认为可以和谁一起
共同推动“规模化”的这个愿景
除了语音识别以外
吴恩达还参与过谷歌的街景项目
当时
他们利用计算机视觉分析街景图像
读取门牌号码
以便更精确地在谷歌地图上定位房屋
事实证明，那个项目在当时的影响力
甚至超过了语音识别
他还记得讨论过如何帮助广告业务
早期人们对于赋能网络搜索业务是持怀疑态度的
他当时费了九牛二虎之力
才说服了网络搜索团队
幸运的是，广告团队对此要开放得多
此外
当时马里奥·凯罗斯（Mario Queiroz）的团队在YouTube上也加入了人工智能
在基于内容为视频打标签
以及内容审核方面
做了许多非常出色的工作
由于吴恩达开设的那门有近百名谷歌员工参与的课程
许多不同的应用团队都表现出了浓厚的兴趣
有时也会有人想要加入他们
但是他们无法提供全职的岗位
他们就会说，那我们先合作吧
也正是这种方式促成了大量的合作
从吴恩达开始在X工作
到谷歌Brain从X毕业
并且迁入谷歌的核心部门
大概不到两年的时间
对于这次“毕业”，
吴恩达的感觉是复杂的
对他来说，X实验室过去是
现在依然是一个非常特别的地方
他记得在X的办公楼里工作
感觉妙不可言
比如，离他十英尺远的
就是当时的自动驾驶团队
也就是现在的Waymo；
旁边是研究热气球的团队；
还有研究语言的团队
所有这些团队都在离他办公桌几步之遥的地方
做着各种大胆、前沿、激动人心的探索
所以，尽管从X“毕业”，
被视为一次成长和迈向新阶段的标志
但是他认为，最终迁入谷歌核心部门
更贴近业务并且获得更多资源
绝非坏事，他也没有任何的遗憾
当然
离开X那幢充满疯狂创意、每天都有新奇事物涌现的办公楼
确实有些伤感
搬到谷歌后，情况发生了一些变化
他们变得更加专注于神经网络和规模化
减少了与形形色色的人闲聊的时间
也错过了体验更多早期原型的机会
可以说他们变得更加“企业化”了
但是这里绝非贬义
因为对于谷歌Brain团队而言
与更多的谷歌业务部门紧密联系显然是有很多好处的
你只需要步行一分钟
就能与那些正在构建重要应用的团队交流
并且寻求合作
后来
吴恩达逐渐将重心从谷歌Brain转移到了Coursera的日常运营上
最初
他和联合创始人达芙妮（Daphne）在斯坦福大学教授一门机器学习课程
由于谷歌Brain进展顺利
而且他相信可以将团队领导权
交给出色的搭档杰夫·迪恩
他觉得自己已经准备好迎接新的挑战了
相比之下
Coursera当时仍然处于非常早期的阶段
更需要他的日常领导
他和杰夫·迪恩谈过之后
花了近一年的时间
逐步将领导权移交给了他
幸运的是
这次交接也非常的顺利
在离开x之后
Transformer架构才被正式发明和发表
吴恩达认为
Transformer论文的绝妙之处在于
它的作者们是在谷歌Brain强调“规模化”的传统中
成长起来的
因此
Transformer网络架构的许多决策
都是为了设计一个能够在GPU上高效扩展的神经网络
比如
注意力机制（Attention Mechanism）
它是一种非常巧妙的方式
让神经网络能够决定要关注句子中的哪些部分
在Transformer论文发表之前
像循环神经网络RNN这些主流的算法
它们在处理翻译任务的时候
比如将一句英文翻译成法文
会先读完整个英文句子
试图将其中的全部信息记在脑中
然后再生成法文翻译
这种方式效果虽然还可以
但是难度很大
毕竟记住一个长句子是相当困难的
而Transformer论文提出了一种创新的架构
它会保留完整的英文句子
然后在生成法语句子的时候
根据当前生成单词的位置
将“注意力”动态地聚焦到英文句子中最相关的部分
事实证明
这种能够同时审视整个英文输入和整个法文输出
并且在处理过程中动态决定关注点的机制
需要巨大的计算量
但是正因为它在GPU和TPU这样的并行硬件上
具有极佳的扩展性，所以效果斐然
后来也成为了现代基础模型的基石
我们不再只是从英文翻译到法文
而是将用户的提示词“翻译”成他们所提出的问题的答案
而Transformer论文之所以如此出色并且获得巨大成功
很大程度上是因为作者们非常巧妙地设计了神经网络架构
确保每一步都是高度的并行化
能够在GPU上高效的运行
这为模型在海量数据上进行训练
奠定了坚实的计算基础
也让它在性能上取得了卓越的突破
谷歌Brain项目还有一个里程碑时刻
被人们津津乐道
那就是“猫咪视频”的突破
他们构建了一个当时可能是世界上最大的神经网络
让它观看海量的无标签的YouTube视频
从中自主学习
吴恩达记得他的博士生（Quoc Le）
有一天把他叫过去说
嘿
吴恩达，快来看看我的电脑
吴恩达走过去
看到了一张模糊的、黑白且略带幽灵感的猫脸图片
这是算法在观看了无数YouTube视频后自主“发现”的
因为YouTube上恰好有很多的猫咪视频
一个算法
在没有任何人告知它“猫”为何物的情况下
仅仅通过观察海量的数据
就自主识别出了猫脸的概念
那真是一个了不起的突破时刻
震撼地展示了AI从原始数据中自主学习的巨大潜力
回顾在X的经历
吴恩达认为还有很多宝贵的经验
比如在塞巴斯蒂安领导的早期X团队中
有一种非常宝贵且罕见的特质
那就是思想的交叉传播
他记得有一次
Waymo团队的成员来找他
说道，吴恩达
想不想坐坐我们的无人驾驶汽车？
他欣然前往
在山景城市中心体验了一辆早期的Waymo原型车
这种开放性、思想的自由交流
以及勇于尝试新奇事物的意愿
是极其罕见和珍贵的
他非常喜欢当时团队里那种“我们正在做有意义的工作”的氛围
大家来这里不是为了做些无聊的事
他记得拉里·佩奇过去常常问大家
如果你正在做的事
取得了超乎想象的成功
会有人在乎吗？
言下之意是
去做那些能让你给出肯定回答的事情
这种感觉非常好，在X的任何角落
人们都抱着一个信念
永远不要做那些即使成功了也无足轻重的事情
还有一个吴恩达个人非常看重的东西
那就是速度
创新之初
几乎可以肯定自己并不清楚方向
因此，快速执行、快速试错的能力
是成功的关键
他发现
面试时几乎所有候选人都会说自己行动迅速
但是实际执行速度的差异是巨大的
能够达到10倍，甚至100倍
他见过有的领导者能在15分钟的谈话中做出决定
也见过另一些领导者面对同样情况会说
很好，我们先花三个月研究一下
到时再碰头
这种执行速度的差异令人震惊
创新的悖论在于
像谷歌这样的大公司
绝对不能让一个工程师
随意尝试可能导致主搜索瘫痪的操作
但是在X，他们创造了一个安全的环境
可以在谷歌Brain上随心所欲地探索
即使没有权限
也绝对不会有意外搞垮谷歌搜索的风险
这种环境让他们能够快速行动、大胆尝试
执行速度与“沙盒式”安全防护的结合
确保没人能够危及“母舰”的安全
这是一种极难实现的平衡
而吴恩达相信X做到了
主持人也认为
缩短学习的周期至关重要
我们不应该在乎花了多久才取得伟大的成就
或者发现自己走错了路
应该关心的是
从提出假设到获得可评估结果之间的时间
如果这个周期是一个小时
而不是一个月
那么这两种情况简直是天壤之别
聊完了谷歌大脑的发展历程
我们再来看看吴恩达现在的工作
以及他对AI未来的看法
如今
他将大量时间投入在经营AI Fund上
这是一个风险投资工作室
他们平均每月孵化一家新的创业公司
其中也包含了当年从X的运作模式中学到的一些早期经验
同时，他通过deeplearning
ai和Coursera
继续从事大量的人工智能教育工作
他认为人工智能的前景极其广阔
像谷歌这样的公司
在训练基础模型方面做得非常出色
最新版的Gemini就充分展示了团队的卓越工作
他对未来将建立在这些基础模型之上的应用数量
感到无比的兴奋
他渴望投身到这样一个环境
每天都有无数绝佳的应用场景
有着明确的市场需求
能够改善人们的生活
却从来没有人去着手构建
这让他备受鼓舞
在AI Fund
从一个想法到成立一家公司
大约需要六个月的时候
其中一半的时间都会花在招聘CEO上
一旦CEO就位
他们会和AI Fund一起工作三个月
这三个月后，成功率大约是75%，
另外25%的情况是他们或者CEO决定不再继续
基本上，只要CEO和他们共事满三个月
他们就会启动公司
吴恩达认为
人工智能领域的一大变化是
原型验证的成本已经急剧下降
如果你有一个想法
现在构建原型、吸引用户来验证或者推翻它的成本极低
即使想法被证伪，那也很好
可能只损失了几天时间和几千美元
这种转变正在真正的加速创新
尤其是在应用层面
这与基础模型层形成了鲜明对比
后者仍然需要动辄数十亿美元的预算
和庞大的数据中心基础设施才能实现
在主持人看来
这就像电力与晶体管的区别
它们是20世纪末计算机行业和互联网基础设施的基石
都具有深远的赋能作用
但是必须在它们之上构建成千上万的东西
才能真正实现它们的价值
同样
基础模型、机器学习以及如今向全世界开放的大模型
就像电力、晶体管一样
它带来了难以置信的可能性
但是必须用它来做点什么
吴恩达也认同这一点
他说，如果回顾美国的电气化进程
就会发现建造发电厂是一项宏伟而伟大的事业
许多人投身其中并且取得了巨大的成功
但是如果你再看看消费电子行业
或是是利用电力制造出的产品
那个产业的规模要比发电行业大得多
他认为人工智能也将如此
构建人工智能模型本身将是一个巨大的产业
但是它的规模
远不及我们利用AI构建海量应用所共同创造的价值
除了对AI产业的展望
吴恩达对教育也同样充满热情
这源于他从小父母的教诲
重要的不是个人
而是如何帮助他人成功
后来在斯坦福大学
他记得教机器学习课程的时候
年复一年地走进同一间教室
讲授同样的课程
甚至说着同样的笑话
过了一段时间，他开始反思
就帮助学生成功而言
这真的是对他的时间最高效的利用吗？
于是，在几年的时间里
他尝试录制视频并且免费发布到网上
任何人都可以观看
他还尝试了自动评分测验之类的工具
并且从可汗学院的经验中学到
应该制作更短的视频
事实上，在Coursera一炮而红之前
其实有过五个可能不为人知的版本
其中一些可能只有20个用户
但是正是这些尝试
让他学到了如何构建可扩展的在线教育平台的宝贵经验
当这项工作取得成功后
他觉得自己有机会将教育的触角
延伸到极为庞大的受众
于是邀请了联合创始人
一同开启了Coursera的征程
对于未来十年人工智能和机器学习领域可能会发生的变化
吴恩达也有着自己的见解
他热切期盼的一件事
就是让每个人都能学会编程，或者说
掌握这种由人工智能辅助的新型的编程方式
因为他不仅在自己的职业生涯中
写了大量的代码，也在个人生活中
为孩子们编写应用程序
就在一周前
他还为女儿写了一个打印乘法口的小应用
他只花了不到一天的时间
就构建出了一个新原型
可以在手机上调用并且进行互动
这个过去需要几周甚至几个月才能构建的原型
如今却在几小时内就能完成
而且在AI的辅助下
几乎不需要写太多代码
他还认为
社会对软件工程的需求是巨大的
许多人都希望能够编写更多的程序
但是传统方式的成本太高了
目前，美国50个州里有4个州
要求高中毕业生必须接受一定的计算机教育
他希望有朝一日
全美50个州都能将其纳入到毕业要求里
如果能让每个人都学会利用计算机去创造
而不仅仅是消费
他相信这将极大地赋能每一个人
所以，在他的眼中
未来最重要的技能之一
就是驾驭计算机、让它为我们所用的能力
因为计算机将变得空前的强大
归根结底
在一个我们需要用全新的方式来教导孩子编程的世界里
下一代将比我们这一代拥有更强大的力量
而对于美国之外
甚至是一些发展中的经济体
吴恩达希望人工智能能够带来巨大的普惠效应
因为当今世界
最昂贵的商品之一就是智慧
请一位经验丰富的专科医生诊疗
费用高昂；
请一位资深的导师一对一辅导孩子
同样代价不菲
虽然他看不到让人类智慧变得廉价的途径
因为培养一个人才本来就需要巨大的投入
但是
让AI变得廉价却存在一条清晰的路径
这意味着
如今只有相对富裕的人才能雇佣某些专业人士为他们服务
但是在未来
每个人都可能拥有一个庞大、博学、智能的团队
来帮助他处理各种事务
这将极大地提升无数人的生活水准
最后，关于人工智能对劳动力的影响
吴恩达引用了一句名言
那就是AI不会取代人类
但是使用AI的人将取代不使用AI的人
这句话最初是他的朋友库尔特·兰洛茨（Kurt Langlotts）针对放射科医生所提出的
这就像在如今的知识经济中
如果一位求职者不懂得使用谷歌搜索
大家会觉得不可思议
他相信在未来
对于大多数的岗位来说
同样不会雇佣那些不懂得高效使用AI的人
不过话说回来
薪酬最终会与生产力挂钩
既然AI能大幅提升人们的生产力
他认为许多人的经济状况反而会因此改善
他们通过使用AI变得更加高效
从而能够赚取更多收入
好了
以上就是吴恩达对他在谷歌Brain历程的回顾
以及他对人工智能一些方面的看法了
不仅让我们看到了机器学习当年的路线之争
以及谷歌早期那令人激动的创新文化
也让我们看到了吴恩达投身于教育的热情和执着
相信对AI领域的很多人
也许不一定同意吴恩达的观点
但是或多或少都听过他的公开课
大飞也希望能通过这个视频
让大家更多的了解吴恩达
了解人工智能的发展历程
感谢大家收看本期视频
我们下期再见
