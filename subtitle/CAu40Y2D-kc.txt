大家好，这里是最佳拍档，我是大飞
今天的节目
还要从我们两个月前做的一期节目讲起
两个月前
我们做了一期介绍美国加州SB 1047 法案的视频
简单地说
就是加州政府试图给AI系统戴上紧箍咒
通过种种规定和约束
提前预防AI可能引发的各种灾害
这个法案在八月份通过了加州的州参议院
现在正在等待加州州长加文·纽森的批准或者否决
这个法案在美国AI圈里引发了一场小地震
辛顿、李飞飞等多位大佬纷纷下场
围绕着人工智能的监管展开了一场论战
而作为1047 法案的直接约束对象之一
同时也是Anthropic 的创始人达里奥·阿莫代伊Dario Amodei
也自然加入了这场大讨论中
最近
他做客知名播客主持人诺亚·史密斯Noah Smith的节目
在与知名科技投资人艾里克·托伦伯格Erik Torenberg 展开了一场深度对谈
在节目中
达里奥聊到了自己对于加州监管法案的看法
认为政府应该谨慎处理过度监管的风险
除了监管以外
二人还谈到了AI 安全性、全球竞争等更加复杂的话题
今天大飞就来给大家分享一下这期访谈的主要内容
有熟悉诺亚·史密斯Noah Smith节目的观众
可能会感到有些困惑
他搞的Econ 102不是一个经济学节目吗
怎么突然跑到AI赛道上来了呢
这其实是艾里克的点子
在另一期节目中
诺亚和艾里克聊到了一个有趣的问题
AI公司到底有没有所谓的产业护城河？
艾里克这里把这个问题抛给了达利奥
在艾里克看来
AI产业就像之前火热的太阳能产业一样
太阳能当然是一个非常庞大的产业
但是艾里克指出
很难说出哪家太阳能公司赚到了大笔利润
钱几乎都集中到了产业链的其他环节
比如光伏
AI现在就面临着类似的情况
尽管大模型公司每周甚至每天都能搞很多创新
但是最赚钱的却是买铲子的英伟达
而作为产品的大模型，时至今日
依然没有形成品牌效应、网络效应
锁定机制等常见的企业护城河
那么
如何保证AI产业的钱是被AI公司赚走
而不是产业链上的其他环节呢？
达里奥觉得
其实AI这个城是没法保护的
因为它涉及到的产业太多了
AI以及基于AI的产品
最终将会成为人类经济一个非常大的组成部分
而收益会流向社会的所有角落
如果这种时候你再想搞什么产业护城河
吃独食
小心和谷歌一样遭到联邦政府的反垄断调查
那既然不能搞护城河
AI公司又靠什么长期地赚钱呢？
达里奥表示
与其抱着自己那一片蛋糕不放
不如与其他人一起
把整个蛋糕做得更大
蛋糕大了
每一个参与者能分到的利益就更多
自然也就不需要什么护城河来保证利润了
但是在AI产业链的内部
公司与公司之间还是天然会存在一堵高墙
那就是模型的开发成本
作为Scalling law的忠实拥趸
达里奥觉得模型规模在未来还是会继续地膨胀下去
哪怕算力会变得更加便宜
越来越大的模型规模
以及喂养这个巨无霸所需要的数据
依然会带来一个天文数字般的开销
到时候
真的还会有人花十亿或者一百亿美元搞开源模型吗？
就算搞出来了
中小企业能负担得起这些巨无霸的运行成本吗？
如果我们真的到了需要十亿或者一百亿美元来构建一个模型的地步
那么整个行业中就只会剩下超级巨头
以及背靠国家的官方资本
到那时
也就根本没有设立护城河的必要了
达里奥觉得
拿过去互联网时代的思维来看待AI的护城河问题
其实是不太对的
因为AI领域最终会发展为类似于重工业的寡头垄断
而不是互联网时代的企业垄断
达里奥的观点非常有意思
他看到的可不仅是一个巨头林立的赛博朋克世界
还指出了AI企业国有化的可能
假如AI产业最后真的向着重工业的模式发展
那么无论是出于国家安全的考虑
还是单纯眼馋基础设施能够带来的巨大利益
各国政府对AI企业实施国有化
其实是在所难免的
达里奥指出
我们可以分开讨论两种可能的未来
一种是 Scaling Law 成立的世界
另一种是 Scaling Law 不成立、甚至发展停滞的世界
先说后者，如果Scaling Law发展停滞
那么AI就只是一种像互联网或者太阳能这样的技术
虽然规模更大一些
但是并不是一种史无前例的基础建设系统
这样AI产业并不会被国有化
但是，如果 Scaling Law 是正确的
我们正在构建类似于诺贝尔奖得主水平的模型
那么国家竞争的问题、模型误用的问题
以及模型的自主性
就将成为世界的焦点
政府可能会在第二种未来里扮演重要角色
到那个时候
尖端模型可能会成为美国及其盟国
最有价值的国家防御资产之一
出于国家安全的原因
政府参与行业的模式其实有很多种
比如 SpaceX 的公共合同模式、公共私营合作模式、类似国家实验室的模式
或者是实际的国有化模式
这些已经存在的合作形式很可能会被推广开来
成为未来行业内的一种标准
不过呢
AI取代人类已有的基础设施建设
将会是一个十分漫长的过程，急不得
以电力的发展历史为例
当电力开始普及的时候
制造商们试图将蒸汽机拆掉
换上发电机
然而，这样做反而增加了损耗
因为他们保留了蒸汽机工厂的原有布局
并没有进行合理的电路规划
所以用上电的工厂效率反而降低了
后来有人意识到
可以把电力并行地分配给多个工作站
这才改变了制造业的工作方式
从一条流水线变成了各自独立的工作站
从而带来了巨大的、持续了几十年的生产力提升
达里奥认为
AI产业大概也会是同样的发展路线
最初，大家在没有合理安排的情况下
无脑使用AI来替换人工
最后反而发现公司效率下降了
又会去斥责AI是一个骗局
我们可能需要兜兜转转几十年
才能找到一个合理使用AI的方式
人类才能学会如何和AI一起工作
达里奥还以Anthropic的经验补充道
Anthropic既给用户提供了可以直接对话的Claude
也通过 API 将模型出售给一大批的用户
但是人们自己似乎搞不清楚到底应该买哪个
达里奥自己也曾经迷茫过
究竟是不是应该把AI变成一个聊天机器人
更何况
企业在盲目用AI替换人工的过程中
可能会放大模型的可靠性问题
比如说，我有一个模型
假设它是用来提供财务信息或者分析法律合同的
可以在95% 的时间里给出正确答案
也许这个准确率比人类更高，但是
万一有一个倒霉的公司遇上这5%呢？
到时候公司因为做假账被起诉的话
老板是打算送大模型去坐牢吗？
所以达里奥也认为
人类还在摸索如何以最好的方式
来使用这些模型
不过
他并不认为人类会和AI达成某种平衡
随着模型变得越来越智能
它们解决问题的能力也会变得越来越强
人们会更倾向于将它们转变为 Agent
它们也会更善于执行端到端的任务
而在这个过程中
人类的参与度必然会逐渐减少
结合之前提到的国有化
未来的AI很可能会成为一套全自动化的社会基础设施
人类只需要用路边的一个按钮
或者用一个麦克风给AI下达指令
大模型就会搞定所有的事情
到那个时候
作为AI主人的人类就可以尽情摆烂了
不过，全自动化的AI社会也意味着
AI一旦出事带来的损失将会大得惊人
AI的安全风险也会被无限地放大
攻击其他国家的AI基础设施
甚至会成为一种军事手段
或者说，已经成为一种军事手段了
无论是作为实体兵器的AI无人机
还是围绕着芯片展开的各种金融大战
我们都已经亲眼见证了
AI军备竞赛正在以中美为核心的两大阵营中不断升温
达里奥对此也表达了深深的无可奈何
一个由 AGI 推动的专制政权
听起来真的非常可怕
所以他觉得
目前美国在芯片和半导体设备上采取的政策是非常合理的
他们需要减少大模型被滥用、误用的可能
不过，作为一个技术出身的人
达里奥还是不想过多参与到政治中
在他看来，努力用AI造福全人类
才是眼下最要紧的事情
随即
他又把话题带回了刚刚提到的AI和人类之间的社会关系
假如AI改造社会的趋势是无可避免的
那么它最终会把我们的社会塑造成什么样子呢？
是否会出现一个赛博朋克式的未来呢？
在那个世界中，AI 是如此强大
以至于可以为我们提供惊人的生物技术、惊人的制造技术
以及惊人的一切
一切都会变得比现在好10 倍、100 倍
但是人类却会这个极度丰富的世界中
变得贫困不堪
达里奥表示，这本质上不是AI的问题
而是社会分配的问题
AI当然有能力让我们的生活变好100倍
这在生物科学中已经得到验证
比如AI可以让基因组测序的速度提高10倍甚至是100倍
到那个时候
人类的生产力自然会极大地提高
寿命也会得到延长
这是我们都希望看到的
但是问题在于
AI带来的这些收益能不能顺利地分配给全社会？
达里奥能想到的是
AI带来的巨大财富
会主要集中在开发这些技术的公司、这些公司的员工
以及配套资产的生产者身上
而普通人却无法分享到这些财富
尤其是在发展中国家
所以
一个全球规模的赛博朋克社会是有可能的
AI确实是有风险的
但是美国现在又不能停下来
因为人类本身的不可控性
最终也将反映到他们所使用的AI工具上
中国会拿AI做什么？
俄罗斯会拿AI做什么？
这些潜在的安全风险是美国人不得不面对的
“加速AI发展来击败潜在敌人”和“AI需要加强自身的安全性”之间
存在着一种诡异的矛盾
而这个矛盾最好的体现
就是围绕SB 1047号草案的论战了
一方面
人们希望能有一个机构来约束AI产业中的重重风险
但是另一方面
过度监管又有可能影响科技开发的速度
针对这个问题
Anthropic 曾经写了两封信
第一封信是写给最初的草案
达里奥表示
草案最初的版本太过严厉
当时提出的机制与Anthropic 、OpenAI、Google等公司
共同开发的负责任扩展计划RSPS非常相似
这个计划是一种自愿机制
要求在开发更强大的模型时
要进行一系列的测试
包括对自主行为、生物武器滥用、网络攻击
以及核信息的测试
如果要将这些测试都变成法律
有两种方式可以实现
一种是政府部门来制定这些规定
规定你必须进行哪些测试
采取哪些安全措施
如果模型足够智能到通过这些测试
那么就由行政机构来编写相关规则
而AI公司担心的是
这些测试目前还非常新
而且几乎所有的灾难性事件都还没有发生
因此
这些预防性测试可能完全就是无效的
纯属外行指导内行，或者更糟糕的是
被某些政客所利用，成为政治工具
于是，达里奥更加提倡另一种机制
这也是Anthropic 在第二封信里写的内容
他称之为威慑机制
在这种机制下
每家公司都必须制定他们的安全和保障计划
他们可以自己决定如何进行测试
但是如果发生了坏事
比如AI接管了世界
或者一次更普通的网络攻击
法院会检查你的计划
并且评估计划是否合理
是否采取了所有可以采取的措施
来防止灾难的发生
达里奥希望，通过这种机制
公司之间可以出现一种积极的竞争
这种竞争的目标不是比烂
而是更好的预防灾难
不要让自己成为灾难发生后被追责的对象
好了
以上就是达里奥·阿莫代伊这次访谈的主要内容了
SB 1047号法案目前还在加州州长加文·纽森的办公桌上
没人知道他是否会在法案上签字
达里奥提出的思考
显然是AI发展不得不面临的重要问题
但又需要各方妥善的协调和解决
一方面政府必然会参与监管
另一方面又不得不面临如何监管
那大家对达利奥的观点有什么意见呢？
AI是否会被国有化
震慑机制会有用么
1047号法案又是否应该被通过呢？
欢迎在评论区留言，感谢大家的观看
我们下期再见
