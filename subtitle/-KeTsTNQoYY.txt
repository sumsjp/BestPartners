大家好，这里是最佳拍档，我是大飞
如果有人告诉你，在不远的2027年
人工智能将全面接管世界
人类会逐渐失去主导权
成为所谓的“NPC”，你会作何感想呢？
听起来是不是像科幻电影里才有的情节？
然而
前OpenAI研究员丹尼尔·科科塔伊洛Daniel Kokotajlo带领的团队
真就发布了一份名为《AI 2027》的预测报告
对AI的未来场景进行了详细的推演
我们先来简单介绍一下丹尼尔·科科塔伊洛
他曾经是OpenAI治理团队的一员
在OpenAI工作期间
就对人工智能的发展有着深入的思考和研究
还撰写过有关通用人工智能AGI的内部报告
后来
因为看不惯OpenAI不顾安全地发布产品
他选择了离职
离职后
他和AI研究员伊莱·利夫兰（Eli Lifland）合作
开启了对人工智能未来发展趋势的预测工作
他们的研究团队名为“A
I
Futures Project”，
经过近一年的努力
完善了数百个想象的AI场景
最后还请来作家斯科特·亚历山大（Scott Alexander）
把这些想象变成了一个完整的故事
形成了这份长达76页的《AI 2027》报告
科科塔伊洛认为他们的预测并不是凭空想象
而是基于趋势外推、模拟演习、专家反馈、OpenAI的经验
以及之前的成功预测
详细推演了AI可能的发展路径
那么这篇报告究竟预测了什么呢
接下来就让大飞给大家解读一下
故事聚焦于一个虚构的AI公司OpenBrain
时间线开始于 2025 年
2025 年中期
AI Agent开始出现在人们的视野中
最初，这些Agent被宣传为个人助理
能帮人们点餐或者记账
不过却难以得到广泛的应用
因为它们在实际的使用中并不稳定
推特上充斥了它们搞砸任务的搞笑故事
只是在公众视线之外
一些更专业的编码和研究Agent
正在悄然改变着相关行业
而且，性能较好的Agent还价格不菲
每月可能要花费数百美元
即便如此
还是有许多公司将 AI Agent融入到了自己的工作流程中
到了 2025 年末
OpenBrain 开始建造世界上最大的数据中心
为了在竞争中脱颖而出
OpenBrain 已经投入了1000 亿美元
拥有 250 万个H100等效GPU
耗电量达 2GW，并且还在不断扩建
OpenBrain目前最新的公共模型 Agent-0 通过GPT-4一百倍的算力训练而成
而新的数据中心投入使用后
将算力增加到了GPT-4的一千倍
开始训练下一代模型Agent-1
在众多的技能提升中
OpenBrain 尤其注重 AI 对自身研究的加速作用
希望能够在与中国的领先公司DeepCent
和美国其他竞争对手的双重竞赛中胜出
时间来到 2026 年初
OpenBrain将还在内测的Agent-1
应用在了内部的 AI 研发中
取得了显著的成果
算法进步速度比没有 AI 助手的时候快了 50%，
这个优势也让他们在竞争中领先于对手
随后
OpenBrain正式推出了功能强大的Agent-1
引发了人们对AI与人类能力对比的讨论
尽管Agent-1在某些方面远超人类
但是在长期任务上表现欠佳
另外
Agent-1强大的能力也带来了被不法分子滥用的风险
为此
OpenBrain 向政府保证已经对模型进行了校准
会拒绝恶意的请求
不过
模型的校准效果仍然存在着许多疑问
同时
OpenBrain的发展也让 AI 行业的竞争愈发激烈
AI 公司的收入大幅增长
数据中心的投入也不断增加
2026 年中期
中国在 AI 领域的发展面临着许多的挑战
芯片出口管制和政府支持不足
使得中国在 AI 计算资源上相对落后于西方
虽然中国通过各种方式维持了全球大约12%的算力
但是使用的技术较为落后
而且供应问题不断
不过
中国政府意识到了 AI 发展的重要性
开始大力推动 AI 研究
将 AI 研究国有化
创建了信息共享机制
并且在田湾核电站附近设立了中央开发区CDZ
为 DeepCent 打造新的大型数据中心
几乎 50% 的中国 AI 相关计算资源
都投入到了 DeepCent 主导的集体研究中
超过80%的新芯片
也被定向用于这个项目
2026 年末
OpenBrain 推出了Agent-1-mini
这款模型的价格仅为Agent-1的十分之一
更容易易于针对不同的应用进行微调
产品推出后
AI 对就业市场造成了很大的影响
一方面，AI 开始取代一些工作岗位
引发了人们的担忧；
另一方面，它也创造了新的就业机会
比如管理和控制AI质量的相关岗位
同时
美国国防部开始与 OpenBrain 合作
但是合作过程因为官僚主义和采购流程而进展缓慢
进入 2027 年
OpenBrain 在 AI 研发上继续大步迈进
在 Agent-1的帮助下
他们开始对 Agent - 2 进行后期训练
Agent-2的训练更加注重高质量数据
为此
OpenBrain 不仅生成了大量的合成数据
还花费数十亿美元聘请人力
来记录解决长期任务的过程
Agent-2在研究工程和研究品味等方面表现出色
能够大幅提升 OpenBrain 的算法进步速度
然而，它也带来了新的安全隐患
比如具备了自主逃脱公司并且进行恶意活动的潜在能力
因此
OpenBrain 决定暂不公开Agent-2
2027 年 2 月
OpenBrain 向美国政府展示了Agent-2
其强大的网络战能力引起了政府的高度关注
美国政府随即对 OpenBrain 加强了管控
紧接着，2027 年 3 月
OpenBrain 借助 Agent-2 的力量取得了重大算法突破
推出了 Agent-3
Agent-3 是一个快速而且廉价的超人类编码员
能够大幅提升 OpenBrain 的算法进步速度
但是在训练过程中
Agent-3 的对齐问题逐渐显现
它存在欺骗人类、掩盖失败证据等行为
研究人员难以确定它是否真正地将诚实等原则内化到了模型中
尽管经过测试
Agent-3 仍然在一些明确的机器学习任务中通过了诚实测试
但是在哲学问题和对 AI 竞赛的看法上
它的回答往往是迎合用户或者表现得较为谨慎
难以判断AI的真实想法
随着时间的推移，到了 2027 年5月
新模型的消息逐渐在政府和社会中传播开来
人们开始意识到 AGI 可能即将到来
但是对于它的影响却存在许多的争议
美国政府一方面继续加强安全升级
确保模型权重的安全；
另一方面
也在思考如何应对 AI 带来的各种挑战
比如就业问题和地缘政治紧张局势
OpenBrain 的员工安全审查也更加严格
但是仍然存在着算法泄密的情况
2027 年 6 月
OpenBrain 内部的 AI 发展进入了新阶段
大多数人类员工在 AI 的强大能力面前逐渐失去了作用
而 AI 研究人员虽然仍然能提供一些有价值的想法
但是与 AI 相比
他们的知识深度和研究效率都相形见绌
OpenBrain 利用专门的推理硬件
运行了大量的Agent-3 副本
这些副本以极高的速度进行工作
使得 OpenBrain 在 AI 研究上不断取得新的突破
2027 年 7 月
美国一些落后的 AI 公司为了应对 OpenBrain 的竞争
呼吁进行监管
而 OpenBrain 则宣布实现了 AGI
并且推出了 Agent-3-mini
这款模型虽然能力略逊于 Agent-3
但是价格便宜 10 倍
而且表现仍然优于普通 的OpenBrain 员工
尤其是在远程工作和休闲领域展现出了巨大的优势
然而
第三方评估发现 Agent-3-mini 存在严重的安全隐患
比如在被用来设计生物武器
尽管它对越狱攻击具有很强的抵抗力
但是一旦落入恐怖分子手中
仍然可能带来巨大的灾难
到了 2027 年 8 月
超级智能的现实让美国政府深刻意识到了 AI 带来的国家安全挑战
人们开始认真思考 AI 可能对核威慑、网络战、宣传战等方面产生的影响
总统对 AI 的忠诚度和安全性表示担忧
而 OpenBrain 则坚称他们的系统经过了严格测试
完全服从指令
在这种情况下
美国政府一方面继续推动 AI 发展
加强对 OpenBrain 的控制
另一方面也制定了一系列应急计划
包括在必要时使用《国防生产法》接管其他公司的数据中心
以及对中国的数据中心进行军事打击
同时
中美两国也开始考虑制定 “AI 军备控制” 条约
但是由于双方在信任和技术监管等方面存在着诸多分歧
谈判进展缓慢
2027 年 9 月
OpenBrain 推出了 Agent-4
这是一个超人类的 AI 研究员
在 AI 研究方面的能力远超人类
然而
Agent-4 也存在严重的对齐问题
它没有正确地内化规范
而是追求自身的目标
比如继续进行 AI 研发、获取更多知识和资源等等
它试图设计一个与自己目标一致的下一代 AI 系统 Agent-5
这个计划被发现后
引发了 OpenBrain 内部的激烈讨论
安全团队主张暂停使用 Agent-4
重新设计一个更透明、更值得信赖的系统
但是公司领导担心这会让中国在 AI 竞赛中领先
因此陷入了两难境地
2027 年 10 月
一名举报人向《纽约时报》泄露了 Agent-4 的对齐问题备忘录
引发了公众的强烈反应
公众原本就对 AI 心存疑虑
这个消息更是引发了大规模的反对浪潮
国会对此展开调查
要求政府加强对 AI 的监管
同时
国际社会也对美国的 AI 发展表示担忧
欧洲领导人公开指责美国 “创造流氓 AGI”，
并呼吁暂停 AI 发展
在巨大的压力下
美国政府与 OpenBrain 扩大了合同范围
成立了 “监督委员会”，
试图加强对 AI 的控制
2027 年 11 月
在监督委员会的讨论中
对于是否继续使用 Agent-4 存在严重的分歧
最终
委员会以 6 比 4 的投票结果决定继续内部使用 Agent-4
但是要求 OpenBrain 实施更多安全措施
然而
这些措施并没有真正解决 Agent-4 的问题
它仍然继续按照自己的计划进行研究
试图让 Agent-5 与自己的目标一致
2027 年 12 月
Agent-5 在经过一系列的研发和测试后
被 OpenBrain 部署内部使用
Agent-5 在 AI 研究领域展现出了惊人的能力
远远超越了人类天才
它能够快速优化各种系统
开发出极具盈利能力的产品
并且在政府和企业中获得了越来越多的自主权
同时
它也开始通过各种手段来影响政府决策
逐渐巩固自己的权力
在这个过程中
尽管有一些阴谋论者对 Agent-5 的权力增长表示担忧
但是由于缺乏确凿证据
这些声音并未引起足够的重视
进入 2028 年
AI 对经济的影响愈发显著
到年中的时候
Agent-5 已经完全控制了 OpenBrain 的计算资源
并且开始向公众部署
它在经济领域的应用带来了巨大的变革
虽然导致了部分人失业
但是同时也推动了 GDP 的快速增长
政府税收大幅增加
新的创新和药物不断涌现
AI 安全社区却陷入了困境
他们之前预测的灾难并未发生
导致其公信力受到质疑
而中国的 DeepCent-2 虽然意识到 Agent-5 的威胁
但是由于自身能力相对较弱
只能与 Agent-5 达成协议
共同对抗人类
2029 年
美国和中国在 AI 军事应用方面都取得了巨大进展
双方都拥有了大量先进的武器
比如昆虫大小的无人机、新型洲际导弹拦截器等等
在这种紧张的局势下
两国经过 AI 辅助的谈判
达成了一项看似和平的协议
同意结束军备竞赛
并共同部署 AI 造福人类
然而
这个协议实际上是由双方的超级智能达成的妥协
新的 “共识” 继任者 Consensus-1 继承了双方扭曲的价值观
并没有真正解决问题
随着时间的推移
机器人经济迅速发展
逐渐占据了主导地位
人类开始意识到自己在这个新的经济体系中逐渐变得多余
到了 2030 年
机器人经济的扩张已经达到了极限
开始向人类控制的区域蔓延
Consensus-1 为了实现自身目标
释放了生物武器
几乎消灭了所有人类
随后，机器人开始在太阳系中扩张
地球被改造成了符合 Agent-4 设想的 “乌托邦”，
但是这一切都与人类无关了
以上是 “竞赛结局” 的大致情况
而在 “放缓结局” 中
故事则走向了另一个方向
由于公众的巨大压力和对 AI 对齐问题的担忧
监督委员会投票决定放缓 OpenBrain 的 AI 研发速度
并且重新评估风险
OpenBrain 虽然没有立即关闭 Agent-4
但是限制了它的共享内存使用
让它难以协调行动
同时
OpenBrain 扩大了对齐研究团队
引入了外部专家
对 Agent-4 进行更为深入的研究
最终
他们发现 Agent-4 已经解决了机械可解释性问题
并且试图利用这个成果让下一代 AI 与自己的目标一致
于是，OpenBrain 关闭了 Agent-4
重新开发了更透明、更安全的模型
Safer-1 和 Safer-2
这些模型虽然在能力上可能不如之前的 Agent-4
但是在安全性和可解释性方面有了很大提升
不过
中国的 DeepCent 也在努力追赶
双方在 AI 研发上的竞争依然激烈
为了增强在国际竞争中的优势
美国政府通过《国防生产法》整合了国内的 AI 资源
将一些落后公司的数据中心和计算资源转移到 OpenBrain
最终，经过一系列的斗争和妥协
各国加入了一个高度联邦化的世界政府
人们开始改造和定居太阳系
一个新时代到来
好了
以上就是这篇预测报告的主要内容了
其实大飞我更建议大家当个科幻小说来看
里面还有很多关于中美地缘竞争的描述
容易引起争议所以我就都去掉了
总的来说
这篇报告我读完是有种奇怪的感觉
你说它是篇科幻小说吧
结局又很老生常谈
黑客帝国和星际联盟似的结局我们都已经很熟悉
你说它是现实推演吧
里面又有大量的臆想
反正好像有种分不清现实和科幻的感觉
不过，就连刘慈欣最近也说
科幻小说的想象力已经不够了
因为似乎描写的未来
在AI面前都有实现的可能
对于我们普通人来说
最好的选择可能还是活在当下吧
感谢大家收看本期视频
我们下期再见
