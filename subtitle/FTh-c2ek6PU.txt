大家好，这里是最佳拍档，我是大飞
总有人说老黄的芯片供不应求
大家有时候恨不得自己去手搓一个GPU
但是谁都知道
GPU是一个相对复杂的研究领域
想想就难
实践起来就更别提有多难了
不过没想到，现在真的有人这么干了
最近
美国一家web3开发公司thirdweb的创始工程师之一
亚当·马吉穆达尔Adam Majmudar
分享了他自己「手搓GPU」成功的经历
引发了网友们的一片点赞
令人惊讶的是
他仅仅用了两周左右的时间
零经验从头开始完成了这一脑力壮举
他自己还调侃这可比想象的要难多了
在X平台的主题帖子中
马吉穆达尔进行了直播
一步步带我们回顾了整个过程
并且把制作GPU过程中的代码等产出物
也公开到了GitHub上
现在这个项目已有接近6000的Star数量了
按照马吉穆达尔之前规划的
设计GPU所需完成的任务流程
这个项目目前的节点是在Verilog中的芯片布局
最终通过OpenLane EDA软件进行了验证
在这之后
GPU还将通过Tiny Tapeout 7提交流片
因此注定会在未来几个月内成为物理形态的芯片
那么，手搓GPU究竟要分几步呢？
对于马吉穆达尔来说
实际上的操作其实比他计划的步骤还要多
因为他真的没啥技术基础
只能从学习GPU架构的基础知识开始
他首先开始尝试通过学习英伟达的CUDA框架
来理解GPU的软件模式
然后进一步理解用来编写GPU内核的(SIMD) 编程模式
有了这些背景知识以后
马吉穆达尔开始深入学习GPU的核心元素
包括从全局内存、计算核心、分层缓存、内存控制器到程序调度
其中
全局内存是存储数据和访问程序的外部内存
也是GPU编程的最大的瓶颈和限制
而计算核心是在不同线程中
并行执行内核代码的主要计算单元
分层缓存是指用来最小化全局内存访问的缓存
内存控制器用来处理对全局内存的限制请求
而调度程序是GPU的主控制单元
将线程分配到可用资源上以供执行
然后在每个计算核心中
还要了解其中的主要单元
包括寄存器、本地/共享内存、加载存储单元 (LSU) 、计算单元、调度程序、获取器和解码器
其中寄存器是用来存储每个线程数据的专用空间
本地/共享内存是指
线程之间用来相互传递数据的共享内存
加载存储单元 (LSU)用来存储或者加载全局内存中的数据
计算单元则是指ALU、SFU、专用图形硬件等等
用来对寄存器的值执行计算
调度程序负责管理每个核心中的资源
并且计划什么时候执行来自不同线程的指令
GPU设计的大部分复杂性都在这里
此外
获取器用来从程序内存中检索指令
而解码器用来将指令解码为控制信号
好了
现在你已经是一个了解了现代GPU架构的人了
下面就让我们来手搓一块GPU吧
这时候马吉穆达尔表示
由于设计GPU的复杂性如此之高
我们必须将GPU简化到新手能够设计的水平
否则整个项目的工期就该要爆炸了
接下来就是创建一个自己的GPU架构
马吉穆达尔的目标是创造一个最小的GPU
来突出GPU的核心概念
并且消除不必要的复杂性
以便其他人可以更轻松地了解GPU
马吉穆达尔表示
设计自己的GPU架构是一项令人难以置信的实践
他一边学习一边操作
随后决定在设计中重点关注以下几个方面
分别是，1、并行化
如何在硬件中实现SIMD模式；
2、内存访问
如何应对从缓慢而且带宽有限的内存
访问大量数据的挑战；
3、资源管理
如何最大限度地提高资源利用率和效率
通过对上面这个架构的多次迭代
马吉穆达尔决定专注在通用并行计算 (GPGPU) 的功能上
这样可以面向机器学习提供更广泛的用例
不得不说
这个设计真的称得上是紧跟时代
第三步
就是为这块GPU编写自定义的汇编语言了
马吉穆达尔表示
其中一个最关键的因素
是他的GPU要实际上可以执行用SIMD编程模式编写的内核
为了实现这一点
就必须为GPU设计自己的指令集架构（ISA）
以便用来编写内核
于是，受到LC4 ISA的启发
他自己制作了11条小型指令ISA
包括每条指令的确切结构
比如NOP指令
这是一条经典的空行指令
仅用于增加PC计数器
BRnzp指令
使用NZP寄存器来启用条件语句和循环的分支指令
CMP比较指令，用来设置NZP寄存器
供BRnzp指令稍后使用
ADD、SUB、DIV、MUL这些都是基本的算术指令
用来实现简单的张量计算
STR/LDR指令
用来在全局数据存储器中存储、或者加载数据
从而访问初始数据并存储结果
CONST指令，为了方便起见
用来将常量值加载到寄存器中
以及RET指令，表示线程已经完成执行
之后
他又编写一些简单的矩阵数学内核作为概念证明
其中，矩阵加法内核使用8个线程
添加两个1x8的矩阵
并演示了SIMD模式、一些基本算术指令和加载/存储功能的使用
而矩阵乘法内核使用了4个线程
将两个2x2矩阵相乘
另外还演示了分支和循环
这些矩阵加法和乘法内核
将会被用来演示GPU的关键功能
同时作为提供在图形和机器学习任务中
应用有效的证据
不过
接下来马吉穆达尔用Verilog构建GPU的时候
遇到了许多问题
这是整个过程中最困难的部分
他也学会了很多知识
但是也多次重写了代码
值得一提的是
马吉穆达尔得到了美国知名黑客乔治·霍兹George Hotz的建议与帮助
后者曾经因为开发iOS越狱程序
以及对PlayStation 3进行逆向工程而名声大噪
最初的时候
马吉穆达尔将全局内存实现为同步SRAM
而霍兹给出的反馈是说这违背了构建GPU的整个目的
GPU的最大设计挑战是管理访问有限带宽的异步内存
也就是DRAM的延迟
因此
马吉穆达尔最终使用外部异步内存
重新进行了设计
并且最终意识到还需要添加内存控制器
其次
马吉穆达尔一开始使用warp-scheduler来实现GPU
但是这是一个很大的错误
因为对于这个项目来说
warp-scheduler过于复杂而且没有必要
还好霍兹及时提出了反馈
不过，当一开始收到霍兹反馈的时候
马吉穆达尔甚至没有足够的背景知识来完全理解它
所以花了很多时间
尝试去构建一个Warp调度程序
这才醒悟过来
这还没有完，在一开始的设计中
马吉穆达尔没有在每个计算核心内
正确的实现调度，因此不得不回过头
重新分阶段地设计计算核心执行过程
才获得正确的控制流
在这个过程中
他对GPU要解决的挑战有了更深刻的感受
比方说，当他遇到内存问题的时候
才真的感受到了
为什么管理瓶颈内存的访问是GPU的最大限制之一
而当他的设计无法工作的时候
又从第一性原理发现了对内存控制器的需要
因为多个LSU试图同时访问内存
于是他意识到需要一个请求队列系统
还有当他在简单实现调度程序和计划程序的时候
看到了更先进的调度和资源管理策略
比如流水线，是如何优化性能的
最终
马吉穆达尔对代码进行了三次重写之后
才实现了目标
并且修复了计算核心的执行调度
经过大量的重新设计后
我们终于可以看到GPU运行矩阵加法和乘法内核时的景象了
当看到一切正常工作
GPU输出了正确的结果
这确实让人有点感觉到不可思议
在视频中
我们可以看到GPU运行的执行轨迹
也可以看到执行跟踪中每个周期的每个线程或者核心的单独指令、PC、ALU处理器、寄存器值等等
最重要的是，我们可以看到正确的值
被加载到数据存储器中的结果矩阵中
接下来
马吉穆达尔还需要将设计通过EDA流程
转换为完整的芯片布局
完整的Verilog设计是通过OpenLane EDA实现的
采用Skywater 130nm工艺节点
马吉穆达尔还特别解释道
有一些设计规则检查DRC没有通过
需要返工
所以又经过两周的努力
马吉穆达尔终于得到了一个强化版的GPU布局
其中包含提交所需的GDS文件
并且可以通过3D可视化来展示他设计的GPU了
好了，到这里
马吉穆达尔已经从了解芯片架构的基础知识
到掌握芯片制造的细节
再到使用EDA工具完成了他的第一个完整芯片布局
最终实现了手搓GPU
马吉穆达尔将这个手搓过程
总结为了6个步骤
分别是，1、学习芯片架构的基础知识；
2、学习芯片制造的基础知识
包括材料、晶圆制备、图案化和封装等；
3、通过逐层制作CMOS晶体管
开始电子设计自动化；
4、用Verilog创建第一个完整电路；
5、为电路实施仿真和形式验证；
6、设计完整芯片布局
并使用开源EDA工具OpenLane进行设计和优化
好了，看完马吉穆达尔的狠活之后
不知道是不是已经有人手痒了呢
欢迎大家亲自动手实践
感谢大家观看本期视频
我们下期再见
