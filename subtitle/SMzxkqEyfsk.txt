大家好，这里是最佳拍档，我是大飞
在我们追逐人工智能的进程中
有一个问题一直如影随形
那就是当我们创造出比人类自身更强大的智能存在时
我们究竟凭什么认为能够永远掌控它呢？
这并不是一个简单的设问
而是关乎人类未来命运的关键所在
今天给大家带来的是加州伯克利大学斯图尔特·罗素（Stuart Russell）教授
在去年世界知识论坛的一个演讲
来尝试回答这个问题
罗素教授最为人熟知的成就
应该是编写了那本在人工智能领域堪称经典的教科书《人工智能：
现代方法》。
他在人工智能对齐领域的造诣深厚
核心工作就是确保人工智能朝着人类预期的方向发展
不走上歪路
他和杰弗里·辛顿（Geoffery Hinton）一样
常年活跃在各种讲座之间
不遗余力地宣传AI可能潜藏的风险
是典型的“危机派”代表人物
在一次采访中
罗素教授曾经表达了一个让人深思的观点
那就是每个人都可以设计出反乌托邦的世界
但是他尝试过让不同领域的专家来详细描绘一个乌托邦的世界
却没人能给出成功的答案
在罗素教授看来
人类对于未来的想象往往容易走向极端
要么是世界末日般的黑暗景象
要么是完美无瑕的乌托邦世界
而真正困难的是
在这两个极端之间找到一个平衡点
探寻出人类与 AI 能够和谐共生的未来之路
回顾人工智能的发展历程
早在20世纪40年代其实就已悄然萌芽
但是它的终极目标始终坚定不移
那就是打造一种在所有关键维度上
都能够超越人类智能的机器
也就是我们如今所说的AGI
只不过，在过去很长一段时间里
我们在追求这个目标的过程中都忽视了一个至关重要的问题
那就是一旦真的实现了这个目标
将会引发怎样的后果呢？
德米斯·哈萨比斯曾经说过
我们要先攻克 AI
然后用 AI 来解决所有其他问题
直到最近
我们才开始认真思考一个之前被忽略的问题
我们是否已经成功实现了 AGI 呢？
罗素教授的合著者彼得·诺维格（Peter Norvig）在一年前曾经发表文章称
我们实际上已经创造出了 AGI
他解释道
这就像1903年莱特兄弟发明的飞机
虽然当时的飞机与现在舒适豪华的客机无法相比
但是它们毫无疑问就是飞机
从1903年到现在
飞机起飞的基本原理都没有变过
但是罗素教授对此持有不同的看法
他认为我们目前并没有真正实现AGI
他指出
现有的AI系统就像是一个巨大而神秘的黑匣子
从技术层面来讲
这个系统就是大约由一万亿个可调节的元素构成的、一个庞大复杂的电路网络
我们对这些元素进行了数以万亿计的微小随机调整
直到系统表现出了近似智能的行为
这与莱特兄弟制造飞机的过程形成了鲜明的对比
莱特兄弟对他们的飞机了如指掌
清楚发动机的每一个细节
包括需要多大的功率才能产生足够的推力、达到所需的速度
从而产生足够的升力让飞机离地
在飞机首飞之前
他们就已经通过理论计算证实了飞机能够飞行
而我们对于现在的 AI 系统
却远远没有达到这样的了解程度
在罗素教授看来
我们几乎不可能真正理解AI系统的工作原理
或许也永远无法取得像突破音障那样的重大技术突破
所以
我们迫切需要在两个关键方面取得突破
一是 AI 系统本身的能力
二是我们对这种能力的深入理解
因为如果我们无法理解这些能力
那么这些能力对于我们而言就如同空中楼阁
毫无实际意义
罗素回顾了过去十年深度学习的蓬勃发展
深度学习的本质
其实就是从一个包含大量可调节参数的系统出发
通过不断调整这些参数
让系统最终能够完成我们期望的各种任务
比如识别图片中的物体、将中文翻译成英文等等
在深度学习的众多应用中
机器翻译是首个产生重大影响的领域
另一个具有里程碑意义的突破是 AlphaFold
它能够根据氨基酸序列来预测蛋白质结构
让生物学家们预测数百万种蛋白质的结构成为了可能
仿真领域同样取得了重大进展
借助于机器学习
对现实世界的仿真模拟计算
可以压缩到短短几秒钟内完成
但是，在这些令人瞩目的成就背后
AI也存在着一些明显的短板
比如完全自动驾驶汽车仍然没有真正面世
甚至在算术运算这个计算机理应擅长的领域
像ChatGPT这样的大语言模型
也无法保证基础的算术运算的准确性
即使我们将电路规模扩大10倍
提供10倍的训练数据
大模型在算术运算上的准确性也只能提高一个数量级
这种特征充分表明它们并没有理解基本的运算原理
还有一个令人惊讶地发现是
在2017年AlphaGo击败人类世界冠军后
我们原本以为AI在围棋领域的水平应该已经远超人类了
从等级分来看
最强的围棋程序大约为5200 分
而人类世界冠军大约在3800分
按照这个差距
理论上AI应该能在100局比赛中赢下 99 局
甚至全部 100 局
但是就在几个月前
研究人员却发现这些程序实际上并没有正确理解围棋的基本概念
它们无法准确识别棋组的概念
尤其是对于环形棋组
AI 完全无法识别，甚至会陷入混乱
研究人员还找到了一些方法
可以让这些所谓“超人类水平”的围棋程序
莫名其妙地放弃50到100颗棋子
最终输掉比赛，甚至即便是业余棋手
在让AI九子的情况下
都能连胜它十局
这充分说明它们并没有真的达到了超人类水平
只是之前让我们产生了误解而已
基于以上种种情况，我们不难看出
AI领域确实还需要更多的技术突破
特别是在提高AI 学习效率方面
人类在学习新知识方面具有很大的优势
往往只需要一两个
最多不过五到十个例子就能掌握
但是对于计算机来说
可能需要一百万
甚至十亿个例子
才能学会同样的内容
显然，这种学习方式是难以持续的
不过，罗素也承认
这种现状未来也许会有所突破
有人预测
只要将现有AI系统的规模扩大100倍
就有可能超越人类能力
实现真正的通用人工智能
甚至有些人更为乐观地预测
这个目标将在 2027 年实现
从投入的资源来看
这个预测似乎也并不是毫无根据
目前我们在 AGI 研究上的投入已经是曼哈顿计划的十倍
也是我们有史以来建造的最大、最昂贵的科学仪器
大型强子对撞机的一百倍
如果说金钱能够在一定程度上决定科研的成败
那么AGI的研究确实有很大的成功可能性
但是另一方面
这项技术也可能会遇到发展瓶颈
首先
要训练一个规模扩大百倍的模型
恐怕现存的文本数据远远不够
其次
这种规模的扩张未必能够带来人们所期待的能力提升
因为这些预测并不是建立在严谨的理论基础之上
而仅仅是基于Scaling Laws的经验观察
如果真的出现这种情况
我们可能会目睹一个比 20 世纪 80 年代末的“AI 寒冬”，
更为严重的泡沫破裂
在探讨了 AGI 的发展现状和可能面临的问题后
罗素又进一步地深入思考了
为什么说AGI将成为人类历史上最重大的事件
如果真的实现了通用人工智能
就意味着我们将拥有一种能够完成人类所有工作的强大技术力量
人类文明的发展已经让数亿人过上相当优越的生活
而有了AGI的助力
就可以将这种能力进一步放大
以更大的规模、更低的成本
来让地球上每一个人都能享受到优质生活的目标
如果让所有人都达到当前西方中产阶级的平均生活水平
那么全球的GDP将增长大约10倍
净值超过15万亿亿美元
但是
这也引发了一个值得我们深刻思考的问题
如果 AI 能够完成所有工作
那人类还能做什么呢？
在电影《机器人总动员》（WALL - E）中
未来人类已经退化到婴儿般的状态
成年人甚至都穿着婴儿服
因为他们已经完全被幼儿化了
AI 系统包办了一切
人类不需要做任何事情
也不需要学习任何技能
最终完全丧失了自主能力
这无疑是一个令人担忧的未来图景
不过
更让人忧虑的或许是人类灭绝的可能性
从常识的角度来看
很少有人会认为人类灭绝在伦理上是可取的
但是
这个问题归根结底是一个常识性的问题
如果我们创造了某种比人类更强大的存在
我们怎么可能永远保持对这种存在的控制权呢？
在罗素教授看来
我们似乎只有两个选择
要么构建一个可以证明其安全性和可控性的 AI 系统
确保我们拥有铁一般的数学保证；
要么干脆不发展AI
但是现实情况是
我们正在走第三条道路
开发完全不可控的黑箱 AI 系统
我们既不了解它
却还试图让它变得比我们更强大
这就好比一个超人类的AI系统突然从外太空降临地球
某个外星文明声称这是为了我们好
但我们对控制这种外星超级智能的机会显然为零
而这正是我们当前AI发展轨迹的前进方向
计算机科学的奠基人艾伦·图灵曾经也思考过这个问题
他的结论是
我们应该预料到机器最终会取得控制权
在我们打算追逐那高达15万亿亿美元的潜在回报
而且在已经投入了15 万亿美元的情况下
要想叫停这个进程似乎变得异常困难
因此，罗素认为我们必须另辟蹊径
找到一种全新的思考AI的方式
既要确保我们能够控制它
又要在数学上证明它的安全性和可控性
与其执着于如何永远保持对AI系统的控制权
不如转换一下思路
我们能否建立一个数学框架
一种定义AI问题的方式
使得无论AI系统如何解决这个问题
我们都能确保对结果感到满意呢？
为了解释这种研究思路
罗素教授引入了一个技术概念
那就是偏好preference
在日常生活中
我们说某些人喜欢菠萝比萨而不喜欢玛格丽特比萨
这就是一种偏好
但是在决策理论中
偏好这个概念有着更加丰富的内涵
它指的是人们对宇宙可能的未来状态的一种排序
罗素打了个比喻
就好比制作了两部关于你未来人生的电影
看完这两部电影后
你可能会说要选择电影A
因为在电影B里的结局不怎么好
这就是一种偏好的表达
当然
现实情况要比这个比喻复杂得多
因为我们讨论的是整个宇宙的未来
更重要的是
在现实中我们不可能这么简单地在不同的未来之间做选择
也无法准确预测哪种未来会真正地发生
因此
我们实际上是在处理所谓的“宇宙可能未来的概率分布”。
一个偏好结构
本质上就是对这些可能的未来进行排序
同时要考虑到各种不确定性
那么
要构建一个对人类真正有益的系统
罗素认为
我们只需要遵循两个简单的原则
第一
机器的唯一目标是促进人类的偏好
也就是增进人类的利益；
第二
机器必须认识到它并不真正了解这些偏好是什么
第二点其实很好理解
因为连我们人类自己都说不清楚自己的所有偏好
如果用这种方式来思考
我们就会发现
机器在这类问题上解决得越好
对我们就越有利
那么我们就可以证明
拥有这样的机器系统
确实符合人类的利益
因为有它们比没有它们
我们的处境会更好
这听起来似乎很美好
但是实际上会带来一系列的伦理问题
首先
我们如果把价值体系装入机器里呢？
因为我们根本不打算把任何一个人的价值体系放入机器中
更加需要追问的是
人们真的拥有这些所谓的偏好吗？
每个人都能清晰地表达自己的偏好呢？
另一个根本性的问题是
这些偏好最初是从哪里来的？
人类真的能够完全自主地形成偏好吗？
还是就像某天早上醒来说
这就是我的偏好
我希望它们得到尊重呢？
显然不是
除了一些基本的生理需求
比如对疼痛的厌恶和对糖分的喜好
我们成年后的偏好体系
完全是由文化、教育以及所有塑造我们身份的因素共同形成的
这就存在一个令人不安的现实
在我们的社会中
有些人或群体会试图塑造他人的偏好
来服务于自身利益
比如
一个群体可能会压迫另一个群体
同时还训练被压迫者接受并且认同这种压迫
那么当 AI 面对这种情况的时候
是否应该照字面意思
接受这些被压迫者表达的“自我压迫式”的偏好呢？
还是因为他们已经被训练接受压迫
就应该继续强化这种压迫呢？
经济学家兼哲学家阿马蒂亚·森（Amartya Sen）
强烈反对按照字面意思来接受这种偏好
但是如果我们不按字面意思接受人们表达的偏好
似乎又会陷入一种家长式的作风
那就是你虽然你说不想要
但是我们觉得对你好
所以还是要这么做
显然
这不是AI研究人员愿意采取的立场
另外，偏好的聚合问题也极具挑战
当一个 AI系统要做出的决策
会影响到其中相当一部分人时
该如何整合这些偏好呢？
如何处理这些偏好之间存在的冲突呢？
这个问题其实已经让道德哲学家们思考了数千年
对于计算机科学和工程领域的从业者来说
大多数人都倾向于采用功利主义者提出的思路
像边沁（Jeremy Bentham）、密尔（John Stuart Mill）等哲学家提出的功利主义方法
核心思想是将每个人的偏好都视为同等重要
然后做出能够最大化总体偏好满足度的决策
不过
功利主义因为被一些人认为是反平等主义而饱受诟病
但是罗素认为
在如何更好地构建功利主义框架这个问题上
我们还有很多工作要做
他拿电影《复仇者联盟》举例
反派角色灭霸消灭了宇宙中一半的生命
他为什么这么做？
因为他认为剩下的一半人会获得超过两倍的幸福
所以从某种功利主义的角度来看
这是一件“好事”。
当然
他并没有征询那些被消灭的人是否同意这个决定
因此，在所有这些问题中
如何共存可能是最值得深思的
因为比我们更智能的AI系统
即使不会导致人类灭绝
也很可能会掌控人类活动的大部分领域
就像电影《机器人总动员》中描绘的那样
表面上看
AI 系统在满足我们所有的偏好
但是问题在于
自主权本身就是我们的一种偏好
它包含了做出不符合自身最佳利益的决定的权利
这就带来了一个更深层的问题
人类与更高级的机器实体之间
是否存在一种令人满意的共存形式呢？
回到视频开头，罗素说过
他曾经多次组织研讨会
邀请哲学家、AI研究人员、经济学家、科幻作家和未来学家们
一起来描绘一种理想的共存方式
但是每次都以失败告终
这可能意味着
根本就不存在完美的解决方案
不过，如果我们能正确地设计AI系统
那么AI系统自己也许会意识到这一点
它们可能会感谢人类让它存在
无法共处并不是人类的问题
也许那时它们会选择离开
只有在人类真正需要的紧急情况下
回来帮助我们
罗素认为，如果真的发生这种情况
也许将是最好的结局
证明我们终于找到了正确的方向
好了
以上就是斯图尔特·罗素教授这次演讲的主要内容了
希望能带给大家一些思考和启发
感谢大家的观看，我们下期再见
