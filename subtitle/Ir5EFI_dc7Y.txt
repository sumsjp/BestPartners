大家好，这里是最佳拍档，我是大飞
在AI行业有这么一家公司
从一成立就被打上了欧洲OpenAI的标签
它曾经凭借6人团队和7页PPT
在成立后短短四周内就斩获了8亿人民币的融资
它就是Mistral
上周，在Figma举办的一场活动中
硅谷知名个人创业者埃拉德·吉尔Elad Gil与Mistral创始人亚瑟·门施Arthur Mensch进行了一场访谈
从讲述Mistral的成立及产品的快速研发谈起
重点涉及大模型自我学习能力、大模型推理能力、大模型效率及规模、对AI监管的看法以及开源模型与商业模型的平衡等
今天大飞就来跟大家分享一下这次访谈的精彩内容
亚瑟先回顾了一下成立Mistral的过程
他和合伙人蒂莫西Timothy在DeepMind和Meta工作的时候
就一直在等待时机
ChatGPT发布之后
他们觉得时机成熟了
并且只用了四个月的时间
就发布了7B模型
当时
他们意识到小型模型实际上对人们来说非常有吸引力
但Llama 7B还不够好
所以他们准备打造一个更好的7B模型
在四个月内
他们几乎从零开始构建整个训练堆栈
从一块GPU都没有
到最终在大约500个GPU上进行了训练
团队在这四个月里几乎没有休息过
很快
他们也将推出一些新的开源模型
包括通用模型和针对特定行业的模型
Mistral计划从服务金融行业开始
因为那里的成熟度最高
市场策略有两种
首先是通过与云服务提供商的合作
因为它们在市场中占据了主导地位
比方说
通过与Microsoft Azure云服务的合作
Mistral就立刻获得了大约1000个客户
然后通过Mistral自己的平台
直接与开发者对话
在谈及大模型的发展趋势时
亚瑟认为
Mistral首先关注的是效率
要比目前的方法更高效地训练模型
等提高效率后才会开始扩大规模
虽然Mistral也在增加计算资源
模型规模也会提升
但是保持模型的高效推理和压缩至关重要
并且Mistral会继续开源这类模型
另一个在扩大模型之前的限制
就是对知识的压缩
在特定任务上可以让7B模型非常强大
但是如果想将世界上所有的知识都压缩到7GB中
这实际上是相当有野心的
所以在这种规模上
多语言模型可能并不是一个好主意
需要专注于想要压缩的人类知识的特定部分
此外
AI领域在过去几年间发生了一个重要转变
就是两年前，强化学习非常重要
今天它实际上变得不那么重要了
因为模型已经变得更好
有时甚至足够好，可以自我监督
这意味着通过人工标注的成本实际上在减少
同时也降低了进入门槛
在被问及随着AI模型规模的增加
是否会自然地获得更好的推理能力
亚瑟强调
目前唯一被验证过的提升模型推理能力的方法
是通过在更大的数据集上训练模型
并增加它们的规模
通过构建外部循环、添加新功能、为模型添加数据等方法
模型可以更好地推理
目前Mistral并没有专门的“秘方”来显著提高模型的推理能力
但是他们通过重点关注数据质量
特别是数学数据
成功开发出了具有良好推理能力的模型
阻碍大模型推理的原因是模型的高延迟
如果你想大量采样
就需要让模型变得更小
这与效率密切相关
随着效率的提高，模型容量也在增加
这样就能更广泛地探索和采样
这是通过自动循环发展来提高推理能力的有效方法
谈到大语言模型的记忆
以及以不同方式跨行动维持更长时间状态的能力
亚瑟说道
Mistral试图通过函数调用来实现这一点
这是创建存储状态的代理的好方法
当我们谈论记忆的时候
实际上是通过在中间件路径上引入一些粗略的函数
来实现对话记忆的
所以函数调用是一个多用途的工具
可以用来创建复杂的设置和复杂的代理
让它工作是很难的，评估它们也很难
所以亚瑟认为这将是Mistral在产品方面需要解决的最大挑战之一
Gil随后又问道有关上下文窗口的问题
在生物学模型中
如果增加上下文窗口
最终会得到更好的蛋白质折叠等结果
上下文真的很重要
但是它会取代RAG或者微调么？
亚瑟回答，上下文窗口不会取代微调
因为微调的目的是根据你的偏好来塑造任务
另一方面，上下文窗口简化了rag方法
因为可以将更多的知识融入上下文
用户的反馈通常是
一旦开始使用具有大上下文的模型
就不想回去了
不过这正是Mistral想要改进和扩展的东西
因为对于基础设施而言
这实际上是一个挑战
当上下文窗口变得越来越大时
我们需要重新思考分片和通信的技术
来处理非常大的注意力矩阵
不过这会付出代价
因为模型会因为质量成本而变得更慢
接下来，两人谈到一些商业化的事情
Mistral最早是一个以开发者为中心的产品
现在开始转为企业服务
这两者之间是否有什么共性
亚瑟认为，企业采用AI大模型
首先考虑的是开发者生产力
他们通常因为现有的方式
不适合他们的开发方式而苦恼
其实是内部的知识管理
最后是通过更多地自动化手段
来提高客户服务
现在对于企业来说
内部采用AI的最大障碍
是他们仍然在努力评估和弄清楚
如何验证模型是否可以投入生产
企业缺少一系列的工具
用于持续集成
以及自动改进大模型应用场景的工具
因此
对于要让企业内部的用户使用AI
我们仍然离创建能够很好地遵循指令、可以轻松定制的助手
还有很长的路要走
在AI监管方面，亚瑟认为
当前关于AI和大模型风险的议题都缺乏实际证据
包括AI是否存在风险与是否有关国家安全的讨论
所以与其关注这些相当抽象的问题
AI行业有更迫切、更实际的问题值得研究
比如如何安全部署AI模型、控制内容输出、处理模型偏见、微调模型的编辑倾向等等
目前Mistral也不打算进入文字以外的多模态领域
他认为生成非文本的东西实际上是一个陷阱
模仿声音和深度面孔是非常令人担忧的
生成文本虽然会有错误信息
但是通常错误信息是由扩散而不是由创建所限制的
所以Mistral目前还只是会专注于文本生成
在谈到大语言模型的本地化问题时
亚瑟认为这是Mistral的一个独特竞争点
整个欧洲目前拥有一个非常稳固的初创企业生态圈
如果着眼于目前全球AI领域
初创企业基本上不是在硅谷
就是在巴黎-伦敦的这条走廊
首先
伦敦一直以来都有DeepMind这样的公司
它吸引了全世界的顶尖人才
2018年
巴黎迎来了DeepMind和Google的研究办公室
这进一步加强了当地的研究氛围
法国以及其他几个欧盟国家有着出色的教育体系
因此
那里的初级机器学习工程师和科学家素质很高
正因为如此
欧洲在基础技术层面以及应用层面都有着强大的公司生态
依托于欧洲的优势
Mistral选择的是一种全球性分销策略
实际上
他们本来可以选择另一条道路
那就是集中精力于欧洲市场
并且假设这样做有某种防御性优势
但是Mistral认为
技术本质上是流动的
能够轻易跨越国界
同时他们正在开发的技术与语言紧密关联
而语言是多种多样的
英语只是其中的一种
事实证明
大语言模型处理英语的能力远超过其他语言
因此，通过专注于多种不同语言
与美国的模型相比
Mistral成功地开发出了特别适合处理欧洲语言的模型
这就形成了一个庞大的市场
同样，在亚洲
也有大量对能够理解亚洲语言的模型的需求
虽然为了满足这些市场
有许多科学问题需要解决
但是这些市场巨大
而且还没有成为美国公司的关注重点
这就为Mistral这家欧洲公司提供了机会
从而能够更加聚焦于全球市场
最后，在观众问答环节
亚瑟聊了聊Mistral的开源计划
虽然现在Mistral已经推出了商业模型
并且没有开源所有东西
但是他们并没有放弃开源模型的开发和维护
也有计划推出新的开源模型
Mistral的目标是发布最好的开源模型
然后向企业提供可以收费的高级功能
从而支持其开源项目和研究活动
不过目前的策略随着时间的推移也可能会发生变化
比如既拥有非常强大的开源模型
但也有更封闭的模型API
Mistral关注的一件事是
即使是对于商业模型
也要使这些模型的部署非常便携和灵活
所以Mistral会向他们的客户发送权重
允许他们修改模型
从而进行客户端的微调
就像他们对待开源模型一样
从这个意义上看
Mistral在商业和开源之间有一些重叠
好了
以上就是Mistral CEO亚瑟·门施Arthur Mensch的这次访谈内容
可以看出
他对大语言模型的发展和公司的发展
有着自己比较清晰、独立的认识
尤其在商业化领域想的很明白
既能推出像8x7B这样的开源模型
也能够准确的定位金融客户进行商业服务
而且拥有全球化的视角也相当不易
大飞我期待Mistral有更好的发展
也能开源出更好的模型
大家对这次访谈有什么看法
欢迎在评论区留言
感谢大家的观看，我们下期再见
