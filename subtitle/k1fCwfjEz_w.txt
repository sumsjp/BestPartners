大家好，这里是最佳拍档
这个圣诞节
英伟达和AI芯片初创公司Groq
达成了一笔重磅交易
涉及金额高达 200 亿美元
折合人民币 1405 亿元
这也是英伟达历史上最大的一笔收购
根据 Groq 的官方声明
这次交易的核心内容
是英伟达获得了 Groq 推理技术的授权
Groq的创始人兼 CEO Jonathan Ross、总裁 Sunny Madra
以及其他高管将加入英伟达
协助推动授权技术的落地
与此同时
Groq 还将继续作为独立公司运营
新的CEO 由现任 CFO Simon Edwards 担任
这听起来似乎只是一场普通的技术合作
但是Groq 的投资方、Disruptive 公司的 CEO Alex Davis 却表示
英伟达将获得 Groq 几乎所有的资产
只有初具规模的云计算业务 GroqCloud
不在这次的交易范围内
很显然，这是一笔典型的 Acqui-hire
人才收购
也就是不买公司外壳
但是拿走技术、专利和最关键的人才
那么，英伟达为什么要花200亿美元
重金收购 Groq 呢？
这还要从 Groq 的来头说起
Groq 成立于 2016 年
创始人 Jonathan Ross 的履历相当传奇
他高中辍学，大学也没读完
却在谷歌设计出了第一代 TPU 芯片的核心架构
而TPU是谷歌为 AI 计算自研的芯片
被市场视为英伟达 GPU
在 AI 领域最重要的竞争对手之一
2016 年
Ross 带着 TPU 团队10 位核心成员中的 7 位集体出走
创立了 Groq
这家公司从一开始
就做了一个极其明确、甚至有些反主流的选择
那就是不和英伟达拼训练算力
只做 AI 推理
Groq 的名字来源于
Grain of Quantum
量子之粒，既在暗指
要搞定量子级别的海量数据
也在宣告
在芯片领域里，小体量也能有大杀器
Groq的核心杀手锏
是专门为 AI 推理设计的 ASIC 芯片
LPU
和英伟达的 GPU 相比
LPU 在处理大语言模型的推理时
能做到更低的延迟、更高的吞吐量
这对英伟达、AMD 和英特尔等传统 GPU 制造商
构成了巨大的挑战
为了实现规模化的推理
Groq 还设计了可扩展的分布式系统
能够将数千个 LPU 芯片互联
让计算流持续在芯片间流动
从而避免了传统架构里
因为频繁访问外部内存
带来的能耗与延迟
得益于架构方面的优化
LPU 的单位 token 能耗
可以降低到普通GPU的三分之一左右
2024年，Ross曾经公开表示
AI推理的成本高昂
Groq 因此专门为大模型提供了超快、更便宜的芯片选择
当时他宣称，到今年年底
Groq很可能会成为
大多数初创公司使用的基础设施
而且价格非常友好
而这也正是英伟达的结构性短板
根据投资方透露
在被英伟达接洽的时候
Groq其实并没有出售的打算
今年 9 月
Groq 刚完成 了7.5 亿美元的融资
估值达到 69 亿美元
投资方包括贝莱德、三星、思科等等
Groq 今年的营收目标是 5 亿美元
正处于高速的增长期
根据 CNBC 报道
黄仁勋在英伟达的内部邮件中
点名了这次交易的战略意图
那就是计划将Groq的低延迟处理器
整合到英伟达的AI工厂架构中
从而服务更广泛的AI推理和实时工作负载
翻译成大白话就是，Groq 的核心技术
将成为英伟达生态的一部分
至于 Groq 这家公司本身
只留下了云业务继续运营
这既不影响英伟达的战略
也避免了直接并购
可能引发的反垄断风险
而对于英伟达来说
这次交易不光是拿下了一项关键技术
也是把潜在的挑战者
变成了自己体系里的一个模块
截至到2025年 10 月底
英伟达手中持有的现金以及短期投资
规模已经达到了 606 亿美元
相比2023年初的133亿美元
翻了近5倍
这也为英伟达的大手笔投资
提供了充足的弹药
巧合的是，2025年9月底
科技播客20VC的主持人Harry Stebbings
与Groq的创始人Jonathan Ross
进行了一场将近90分钟的对话
Ross在对话中反复强调
我们不会做模型
也坦承可能会被客户吞并
他详细解释了
为什么自建芯片几乎注定失败
为什么英伟达的护城河，不在CUDA
而在HBM供应链
以及为什么Groq能做到6个月的交付周期
这才是真正的差异化
如今三个月后的收购
让这期对话有了一些特殊的意义
所以今天我们也顺带回顾一下这场对话的主要内容
也许能够一窥
这次收购背后的逻辑脉络
Ross在对话开场，就抛出了一个判断
他认为，当前AI公司最大的瓶颈
不是模型，而是算力
如今，OpenAI和Anthropic最大的瓶颈
其实是速率限制
导致用户拿不到足够的token
如果这些公司有更多算力
就能产出更多token
就能收更多的钱，甚至翻倍
主持人追问道，能解释一下吗？
怎么会翻倍呢？
Ross的回答是
算力决定了你能服务多少用户
以及服务到什么质量
OpenAI的聊天服务，如果跑得慢一点
用户的参与度就会下降
这也就是OpenAI宣布推出
限量高价产品的原因
因为他们想看看
当投入更多的算力时
产品会变成什么样，能好多少
他认为，AI和SaaS的逻辑完全不同
SaaS产品的质量，是由工程师决定的
而AI不一样，你可以跑两个实例
然后选择更好的答案
甚至可以给高价值的客户更多算力
让结果更好
也就是说，用户能直接用钱
买到更好的产品质量
很多人可能会觉得
AI的响应速度够用就行了
等几秒钟也无所谓
但是Ross说，这个判断是完全错误的
他用消费品行业来做类比
如果我们把消费品按利润率排序
那么最高的应该是烟草，其次是嚼烟
再次是软饮料，往下是水和其他产品
所以
决定利润率的核心变量是什么呢？
答案是，成分作用于人体的速度
多巴胺循环的越快
品牌的黏性就越强
他引用了一个数据，每100毫秒的加速
会带来大约8%的转化率提升
这是Google和Facebook早年就验证过的规律
也是Google一直在强调速度的原因
Ross说
Groq刚开始做速度优化的时候
有人看了演示视频问
为什么需要比你的阅读速度还快呢？
他反问道，为什么网页加载
需要比你的阅读速度还快呢？
所以他指出，人们很不擅长判断
究竟是什么在真正影响参与度和结果
但是Groq从早期互联网公司的建设中
学到了这一点
主持人又问他
现在的AI是不是泡沫呢？
Ross说，如果一个问题你反复问
却得不到答案，也许应该换个问题
所以，与其问有没有泡沫
不如问问，聪明钱都在做什么
比如，Google在做什么？
微软在做什么？
亚马逊在做什么？
一些国家在做什么？
他们都在加倍的投入AI
每次宣布投资额之后
下一次都会更高
他讲了一个例子，微软有一个季度
部署了大量的GPU
然后宣布不会把它们放到Azure上出租
因为自己用，比租出去能赚更多的钱
这就是Ross相信的
市场里有真金白银
他在阿布扎比参加高盛峰会的时候
台下坐的
都是管理100亿美元以上资产的基金经理
他问了在场所有人一个问题
你们有谁100%的确信
10年后的AI做不了你们的工作吗？
没有人举手
所以Ross说
这就是超大规模厂商们的感受
他们当然要像醉酒水手一样花钱
因为另一个选择是被完全踢出局
这已经不是一个纯经济的框架了
而是自己还能不能保住领导地位的问题
他还补充说
要想留在七巨头的位置上
你就必须持续投入
而这些公司的股价能一直维持在高位
部分原因就是因为它们在这前七名里
所以说
这其实是一个自我强化的循环
主持人接着问
OpenAI会不会自建芯片
做垂直整合呢？
英伟达难道不担心吗？
Ross的回答，充满了工程师的冷静
他说，如果我今天再创业
肯定不会做芯片了
因为时机已经不在了
从芯片的设计到投产
即使是执行完美的情况下
最快也得要三年
英伟达通常也需要3年到4年
只是多条产品线并行而已
更残酷的是
首次流片的成功率只有14%。
也就是说，86%的概率
你需要重新来过
他回忆道，自己当时做V2芯片的时候
已经预约好了重新流片的时间
结果第一次就成功了
连他们自己都被震惊了
但是，这种几率太小了
Ross说
大家都以为造芯片最难的是硬件
其实你做过才会知道，软件更难
再做下去又会发现
跟上市场的演进方向
才是最难的
如果你是一名在位者
提前两年规划是没问题的
因为大家都在为你的硬件来设计模型
但是，如果你是一名新进入者
没人会为你还没出来的芯片设计模型
所以你必须有更快的迭代循环
而现实情况是
Groq做到了一年一代芯片
V2之后一年是V3，再一年是V4
他还提到了Sarah Hooker的论文《硬件彩票》，
这篇论文的核心观点是
人们只为现有的硬件设计模型，因此
即使可能存在比attention更好的架构
但是attention在GPU上跑得好
所以它就成了标准
Ross还讲了一个Google的故事
当时AMD还在市场上挣扎
Google却建了10000台AMD的服务器
他去参观实验室的时候
看到工程师们把服务器从机架上拉出来
把AMD的芯片拔下来，扔进垃圾桶
他说，大家都知道那一代的Intel会赢
那Google为什么还要建10000台AMD的服务器呢？
因为他们想在Intel那里拿到更好的折扣
所以，自建芯片的动机
不一定是真的要用那个芯片
很多人会以为
CUDA是英伟达的护城河
但是Ross说，这只是对训练成立
对推理不成立
他认为，真正的护城河应该在供应链
具体来说，就是HBM
Ross解释了一个概念，买方垄断
monopsony
Monopoly是卖方垄断
monopsony是反过来的
指的是，你是唯一的大买家
所以你能够控制供给
英伟达的GPU本身
用的工艺其实和手机芯片是一样的
如果他们想
一年其实可以造出来5000万颗GPU die
但是今年大概只造了550万颗
为什么呢？
因为HBM的产能有限
导致中介层的产能也有限
他举了个例子
当一家超大规模云服务商对英伟达说
给我100万颗GPU
英伟达会说，抱歉，还有其他客户
服务商说，没关系，我自己造
然后英伟达神奇地就找到了货
给这家服务商
他想表达的是，自建芯片
真正给你的不是芯片本身
而是掌控自己命运的能力
因为英伟达没法告诉你配额是多少
虽然自建芯片可能会更贵
也不会像英伟达那么好
但是Ross解释了
为什么这点差距在系统总成本里
可能微不足道
他说，如果芯片只占系统总成本的20%，
那么芯片的性能提升20%，
整个系统的价值就会提升20%，
但是芯片成本只增加了20%的20%，
也就是4%，这就是为什么
小的性能优势能够带来巨大的价值差异
也是为什么
英伟达即使只比AMD好一点点
也能主导市场的原因
当然，HBM供应商也有着自己的算计
由于HBM的利润率极高
所以他们不愿意增加产能
因为供给增加，利润率就会下降
同时产能的建设
需要提前至少两年下单付款
即使有英伟达的现金流
也很难押注那么远的需求曲线
接下来的部分
这可能是整期访谈中最关键的
关于差异化的解释
Ross说
他跟一家超大规模云服务商的基础设施负责人开会
讲了速度、成本等等各种优势
对方都没太在意
但是当他提到
自己能做到6个月的供应链时
对方直接暂停了对话
只想深挖这一点
显然，这是他唯一关心的事
为什么会有这个差异呢？
原因在于
Groq的LPU架构不依赖于HBM
使用的是片上SRAM
静态随机存取存储器
这也是大家最常会问到的问题
SRAM不是比DRAM贵吗？
Ross解释说
SRAM每比特大约比DRAM贵3到4倍
因为SRAM需要6到8个晶体管
而DRAM只需要1个晶体管加1个电容
而且SRAM部署在更先进的制程上
每单位的面积成本更高
综合下来可能会贵10倍
但是，这只是从芯片的视角来看
如果用系统的视角来看，就会发现
当Groq跑一个像Kimi这样的模型时
需要用4000颗芯片
而GPU跑同样的模型
可能只需要用到8颗
但是这意味着
GPU那边有500份模型拷贝
用了500倍的内存容量
所以，即使SRAM每比特贵了10倍
但是他们用了500倍的内存量
因此系统总成本算下来
Groq反而会更便宜
Ross说
他们现在是在从全球视角看问题
Groq有13个数据中心
分布在美国、加拿大、欧洲、中东
他们会根据不同地区的需求
在不同数据中心
部署不同模型的不同编译优化版本
因此，他们是在世界级别做负载均衡
而不只是数据中心级别
他还讲了一个两周前的真实案例
有客户来找他们
要5倍于全部产能的算力
他们从任何一家云服务商都拿不到
从任何人那里都拿不到
Groq也给不了，没有人能给
也就是说
市场不是有没有需求的问题
而是产能根本不够的问题
在访谈中
Ross还谈到了中美AI发展路径的差异
其中有一个判断值得我们注意
当DeepSeek等国产模型发布的时候
业界关注的焦点
都是在训练成本的突破
但是Ross认为
这背后其实是不同的优化方向选择
他的判断是，中国模型的运行成本
大约是美国模型的10倍
因为中国模型优化的是训练成本
而美国模型优化的是推理成本
那为什么API价格反而会更低呢？
Ross认为，这其实是定价策略的差异
不能把价格和成本混为一谈
当你是某个特定模型的唯一提供者时
你在封闭市场里
其实是可以灵活定价的
需要注意的是，训练是一次性的投入
要摊销到每次推理上
如果推理量巨大、算力充裕
降低单次推理成本的收益就会更高
如果算力受限
那就需要先把训练效率做到极致、让模型跑起来更加务实
所以，他的思路是
由于芯片的获取受限
中国团队在有限的算力下
把训练效率做到了极致
这是约束条件下的理性选择
Ross还提到
中国正在建设大量的核电站
从能源侧为AI算力做长期的准备
当能源不再是瓶颈的时候
算力约束的逻辑
就会发生变化
比起中国
Ross对欧洲的诊断则非常直接
他说
问题不是资源，是恐惧
他还说了一个让主持人惊讶的判断
那就是美国比欧洲更厌恶风险
但是他马上解释道，风险有两种
一种是犯错的风险，做了某事
结果是错的
另一种是错过的风险，没做某事
结果错过了机会
而美国害怕的，是错过的风险
在高增长经济体里
错过比犯错代价更大
而欧洲害怕的是犯错的风险
他说，欧洲试图通过立法来进行竞争
比如要求数据的本地化、隐私保护等等
但是，这解决的是别人控制我的风险
解决不了我没有足够算力的问题
所以，如果欧洲想竞争AI
其实可以直接在挪威部署大量的风力发电
因为挪威的风力利用率是80%，
配合水电，光这一个国家
就能提供相当于整个美国的电力
他还说
欧洲还有大量的潜在能源没有开发
更何况
沙特阿拉伯也在建设数据中心
有吉瓦级别的电力
欧洲为什么不和沙特合作
利用他们的数据大使馆的概念
在主权监管下使用对方的能源呢？
关于核能
Ross说他在欧洲基本不提这个
因为大家会本能的抗拒
但是日本正在重启核电站
他还提到一个数据，在美国建核电站
许可证费用是电站本身的3倍
而欧洲可能会更糟
其实，法国知道怎么建核电站
韩国也知道
Ross建议
还不如来一个能源领域的曼哈顿计划
主持人问，如果欧洲不行动会怎样呢？
Ross回答
那么欧洲经济就会变成旅游经济
人们只是来看看古老建筑，仅此而已
如果你没有新经济所依赖的资源
那么就没有办法在新的经济中竞争
而新的经济就是AI
它建立在算力之上
简单来说，控制算力，就能控制AI
没有能源，就没有算力
聊到对AI经济影响的判断
Ross的观点也与主流叙事完全相反
主流媒体都在担心AI会导致大规模的失业
但是Ross说
他认为AI会导致大规模的劳动力短缺
也就是说，没有足够的人
来填补将要创造的工作岗位
他预测AI会带来三重效应
第一层，大规模的通缩压力
咖啡会更加便宜，住房会更加便宜
一切都会更加便宜
主持人不解的问
咖啡怎么会更便宜呢？
Ross回答
因为机器人农业会更加高效
供应链管理会优化
甚至可以通过基因工程
改造咖啡豆让每瓦阳光产出更多
整个产业链的成本都会下降
第二层，人们会退出劳动力市场
因为工作时间减少了
每周工作的天数也会减少
退休也会更早
因为维持生活水平需要的工作量下降了
第三层，新工作和新产业的涌现
100年前，美国98%的劳动力在农业
现在只有2%。
那这98%的人去做什么了呢？
答案就是做100年前根本无法想象的工作
比如软件工程师、网红
所以Ross认为，100年后
软件工程师这个职业也会消失
但是会以不同的方式消失
因为那时人人都会vibe coding了
Ross还解释了AI经济学与工业革命的本质区别
他认为
工业革命时期
能源不够用，还需要机器来转化
如果想让更多的汽车上路
光挖更多的石油还不够
还得造汽车
而AI不一样
如果把算力翻倍
那么用户数就会翻倍
产品质量还会得到提升
所以直接加算力就行，没有中间环节
在经济中，最有价值的无疑是劳动力
而现在我们可以通过生产更多的算力和更好的AI
向经济中增加更多的劳动力
这在历史上是从未发生过的
为了具体说明这一点
Ross讲了一个公司内部的案例
有一次客户来访，提了一个功能需求
Ross做了一个非常high level的规范说明
四个小时后
这个功能就上线生产环境了
没有一行人类写的代码
也没有人类做调试
全是提示工程
他们甚至通过Slack来做代码提交
他说，再想象一下
也许6个月后
这件事在和客户的会议结束前就能完成了
这就不只是省钱的问题了
而是质的不同
当你能做到那么快的时候
你能赢得竞争对手赢不了的单子
主持人问
Vibe Coding会是一个持久的市场吗？
还是只是一个过渡期的现象呢？
Ross用读写的类比进行了回答
他说，读写曾经是一项专业技能
如果你是抄写员
你是少数会读写的人
人们雇佣你就是为了记录东西
你会比普通人过得好
因为这是稀缺技能
但是现在，人人都会读写了
这已经不是一项特殊技能了
而是每份工作的基本要求
编程也正在经历同样的转变
以后做市场的要会编程
做客服的也要会编程
Ross说
他们有些实习生特别擅长vibe coding
他还提到一个开连锁咖啡店的朋友
从来没有写过代码
但是自己用vibe coding
做了一个供应链的库存管理工具
更有意思的是
他发现了软件工程师都会发现的问题
比如员工反馈说，这个功能不正常
那个极端情况没处理
然后他就用vibe coding一个个的修复
关于利润率，也就是margin
主持人问Ross怎么看
Ross说了一个反直觉的观点
他希望Groq的利润率尽可能的低
只要业务保持稳定就行
他解释了利润率的两个功能
第一，稳定性
如果你的利润率很薄
市场一波动你可能就撑不住了
第二，竞争壁垒
但是反过来说
对手的利润率就是自己的机会
因为高利润率会吸引更多的竞争者
Ross说他面试过一个CFO的候选人
对方建议定价应该让供给匹配需求
也就是提价到需求下降为止
这从经济学角度来说很合理
但是从逻辑上说
为什么不把你的品牌价值变现呢？
为什么不利用客户的信任
卖给他们不那么好的东西？
Ross认为
品牌和客户信任是有价值的
而信任会生出利息
但是，当你收取高利润率的时候
你和客户是对立的
所以，他给Groq定的策略是
利润率尽可能的低
同时通过增加销量
来获得充足的现金流
对于未来5年后，芯片市场的发展前景
Ross预测
英伟达仍然将占到50%以上的收入
但是可能只占10%的芯片销量
他说，品牌是有巨大价值的
你可以收更多的钱
但是这会让你感到不那么饥渴
于是你开始收更高的利润率
有些人会愿意为品牌付费
因为买英伟达没人会被开除
所以这个生意会继续非常值钱
但是他又说
当你有像现在这样的客户集中度
比如35或36个客户
占了99%的token消费
那么这些大客户一定会基于
什么对自己的业务有利
来做决定，而不只是基于品牌
所以会有更多其他的芯片被使用
主持人又问，5年后
英伟达能值10万亿美元吗？
Ross回答说，如果不值，我会很惊讶
然后主持人又问，Groq 5年后
能值10万亿吗？
Ross回答，可能吧
Groq没有供应链的约束
能够生产比任何人都多的算力
现在市场上最稀缺的资源就是算力
而Groq能生产几乎无限量的算力
而就在他说完这句话的三个月之后
英伟达用200亿美元给出了答案
无论是从英伟达的收购
还是从Ross的对话中
我们都可以看到，全球的AI产业
正处在从模型的训练阶段
迈入规模化推理落地的关键期
低延迟、高能效的推理算力
已经成为AI模型的核心刚需
那大家是如何看待
英伟达这次收购Groq呢？
你们觉得200亿美元值吗？
感谢收看本期视频，我们下期再见
