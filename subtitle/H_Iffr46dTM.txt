大家好，这里是最佳拍档，我是大飞
在AI领域，如何通过更好的提示工程
来提升模型的推理能力
一直是研究人员和工程师们聚焦的重中之重
从最初的少样本学习（few-shot learning）到思维链CoT（Chain of Thought）
再到思维树ToT（Tree of Thoughts）以及思维图GoT（Graph of Thoughts）
提示技术始终在不断地进化之中
而最新的一项研究成果显示
有一个令人意想不到的方向
或许会给提示工程带来突破性的进展
那就是在提示中融入叙事（Narrative）元素
来自波恩大学等机构的研究者们
提出了一种别出心裁的 prompt 框架
名为思维故事（Story of Thought）
简称SoT
总的来说
这个方法可以借助于构建叙事性的信息组织形式
来强化大语言模型的推理能力
这项研究不但在理论层面颇具趣味
更为关键的是在实践应用中
也展现出了卓越的成效
比如在复杂的科学推理任务 GPQA 和 JEEBench 上
SoT 的表现超越了包括 CoT 在内的许多现有方法
在介绍这篇论文之前
我们先来探讨一下为什么要在提示中引入叙事元素
这个理念呢
其实来源于一项认知科学的发现
那就是相较于简单地罗列事实
人类往往更容易通过故事化的方式
去理解和记忆复杂的概念
在科学传播、教育以及医疗沟通等许多的领域
叙事方法也已经被证实
能够有效地帮助人们理解复杂的信息
因此
研究者们提出了一个很有趣的假设
那就是既然叙事有助于人类更好地理解与推理
那么它是否也能够帮助大语言模型
更出色地处理复杂的问题呢？
这个假设主要基于两点考量
第一点就是
叙事结构有助于识别与阐释抽象的概念
第二点
叙事框架能够更为连贯地组织信息流
好了
接下来让我们深入来了解一下 SoT 框架
SoT 框架的核心在于
将复杂问题的解决流程拆解为三个关键的步骤
第一步是问题阐明（Question Clarification）
在这个阶段
模型要扮演一个“探索者”的角色
对问题展开细致入微的剖析
并且识别与问题相关的专业领域知识
这个步骤的目的
并不是要去解答问题
而是要分解问题的核心构成部分、识别相关的子主题
以及确定所需要的知识领域
比方说
我们可以给出这样的示例提示
“你是一名探索者
目的是识别并且收集不同相关专业的学科领域信息来阐明问题
你的目标是要缩小问题的范围
并且提供你所拥有的、有助于阐明以下问题的相关知识和经验
你不应该回答这个问题
”
第二步是叙事生成（Narrative Generation）
这也是 SoT 框架最具有创新性的一个环节
在这个阶段中
模型需要根据第一步的分析结果
构建一个结构化的叙事
以此来帮助对问题的理解
在这个过程中
会运用到五种关键的叙事技巧
第一种为渐进式披露（Progressive Disclosure）
也就是逐步地展示信息
按照循序渐进的方式来引导思维过程
第二种是分支叙述（Branching）
也就是探索问题的不同视角
提供多种解决思路
第三种是类比（Analogy）
也就是将抽象概念与熟悉的情景联系起来
从而简化复杂的问题结构
第四种是类比推理（Analogical Reasoning）
也就是通过相似的情况进行推理
从而建立问题之间的关联
第五种是隐喻（Metaphor）
也就是使用比喻来简化复杂的概念
增强理解的直观性
论文中给出的对应提示示例是这样的
“你是一位擅长基于叙事进行科学传播解释的专家
你的目标是通过下面提供的相互关联的信息
以叙事的方式来阐明以下问题
以便非专业人士能够以更连贯
而且更具上下文丰富性的方式
来理解这个问题
你不应回答这个问题
在通过相互关联的信息阐明问题的时候
务必使用所有这些叙事技巧
包括渐进式披露、分支叙述、类比、类比推理和隐喻
”
最后一步就是问题求解（Problem Solving）
在这个阶段
要基于生成的叙事框架来解决原始的问题
而关键在于充分利用叙事中构建的结构化理解
论文中给出的示例提示为
“你是一位分析基于叙事的解释来解决任务的专家
请根据以下基于叙事的阐释
来回答以下问题：”
那在了解了 SoT 框架之后
我们再来看看实验的结果
以及这种叙事框架的效果究竟怎么样
为了证明SoT表现
研究团队在两个极具挑战性的数据集 GPQA 和JEEBench上
开展了详细的实验
先看 GPQA 数据集的测试结果
GPQA（Graduate - level Problem - solving QA）是一个涵盖了高质量研究生水平问题的数据集
实验结果表明
使用 Llama 3 70B 模型搭配 SoT 方法
准确率高达 51.01%，
在所有测试方法中拔得头筹
而GPT - 4 模型在应用了 SoT 之后
准确率从基准的 34.7%，
跃升到了 48.98%，
相对提升幅度达 41%。
从结果来看，几乎所有的大模型
在运用 SoT 框架后
都实现了性能上的提升
我们再看 JEEBench 数据集的测试结果
JEEBench 是一个包含了 515 个具有挑战性的、与工程数学、物理和化学问题有关的数据集
实验结果显示
Llama 3 70B 结合 SoT 方法之后
在所有科目和问题类型上都达到了最佳表现
总体准确率达到 0.453
超越了之前的SOTA
也就是 GPT-4 + CoT + Self - Consistency
特别值得关注的是不同学科领域的表现
其中生物学问题上的提升最为显著
以及物理和化学问题也都有明显改善
那么
为什么这种叙事框架会如此有效呢？
研究者们随即对 SoT 的效果展开了深入的剖析
发现了几个关键的成功因素
首先一点就是叙事技巧的协同效应
实验结果显示
单独运用某一种叙事技巧的效果
不如综合运用所有技巧的组合
如果只使用渐进式披露或者分支叙述
模型的准确率会下降 6 - 9 个百分点
而只使用类比或者类比推理的时候
准确率会下降 3 - 5 个百分点
只有综合使用所有技巧的时候
才能获得最佳的效果
第二点是模型的规模与叙事能力的关系
研究发现
模型规模与叙事生成的能力
存在着显著的关联
规模更大的模型
比如说Llama 3 70B和GPT - 4
能够生成质量更高的叙事
而小模型生成的叙事
可能反而会降低推理效果
不过使用大模型生成的叙事
也能够帮助小模型提升性能
第三点是叙事的质量分析
研究者们借助 Llama 3 70B
对不同模型生成的叙事进行了质量评估
并且统计了各种叙事技巧的使用频率
结果显示
OpenAI 的模型在叙事技巧的使用频率上最高
其中渐近式披露和类比是最为常用的技巧
而分支叙述的使用频率则相对较低
那么对于提示工程师而言
如何将 SoT 框架应用到实际工作中呢？
论文中也给出了一些具体的建议
首先是要选择合适的场景
SoT 框架尤其适用于以下这些场景
比如需要复杂推理的科学问题、涉及多个知识领域的问题
以及需要结构化思维的决策问题
其次是要优化提示词设计
在设计提示的时候需要留意
要明确指定清楚每个步骤的角色定位
确保涵盖所有必要的叙事技巧
并且要根据具体的任务
来灵活调整叙事的策略
尽管从研究结果来看
SoT展现出了良好的效果
但是研究者们也指出了它存在的一些局限性
首先在技术层面
叙事生成的质量依赖于模型的能力
对不同类型问题的适应性还有待进一步的验证
生成的叙事可能会存在不确定性
在应用层面
采用SoT可能会需要更多的计算资源
响应时间或许会增加
实现成本相对较高
好了
以上就是对SoT框架内容地介绍了
应该说，SoT 的提出与验证
为提升大语言模型的推理能力
又开辟了一条新的路径
这种将认知科学中的叙事概念与提示工程相结合的方法
不仅在学术研究领域有一定价值
也为实际应用带来了一些新的机会
对于提示工程师而言
SoT框架也可能会成为一个强大的工具
帮助他们更为出色地处理复杂的推理任务
如果能够再将传统的思维链与结构化的叙事融合起来
或许能够推动大语言模型在复杂推理任务上
实现更大的突破
感谢大家观看本期视频
我们下期再见
