大家好，这里是最佳拍档
过去一年
我们已经感受到了AI行业的疯狂迭代
从刷新我们认知的模型发布
到技术路线的激烈博弈
再到全球范围内的竞争与合作
AI正在以超出想象的速度重塑我们的世界
2月1日
知名科技播客博主莱克斯·弗里德曼
邀请到了两位AI领域的重量级嘉宾
展开了一场长达数小时的硬核对话
一位是知名机器学习研究员与教育家塞巴斯蒂安·拉施卡
另一位是艾伦人工智能研究所的后训练负责人、RLHF领域的权威专家内森·兰伯特
他们一位深耕技术原理与教育普及
一位专注后训练技术与行业实践
恰好代表了当前AI领域的两大核心关切
这场访谈信息密度极高
不仅复盘了2025年的关键技术突破
更是对2026年的行业走向做出了深刻预判
今天
我们就来给大家拆解一下这场访谈的核心内容
一起看清AI行业的现状与未来
谈到全球AI竞争
2025年最关键的转折点
无疑是DeepSeek时刻
2025年1月
中国公司DeepSeek发布了开放权重的模型DeepSeek R1
这款模型以更低的算力成本达到了接近Sota的性能
瞬间震惊了业界
也被视为中美AI竞争的分水岭
内森·兰伯特在访谈中提到
中国公司在开源权重模型领域的表现堪称强势
除了DeepSeek
阿里巴巴的通义千问、MiniMax、Kimi等公司
都发布了大量高性能开源模型
凭借出色的性能和友好的许可协议
赢得了全球开源社区的广泛青睐
与之形成鲜明对比的是美国曾经的开源标杆
Meta的Llama系列
拉施卡分析指出
Meta在2025年陷入了刷榜陷阱
试图通过构建巨大的Llama 4模型在基准测试中击败ChatGPT
却忽略了AI领域真正的需求
也就是轻量级、可用的模型
这种战略失误导致Llama留下的生态空白
正被中国的开源模型迅速填补
兰伯特则补充道
中国的开源模型不仅数量多
规模也更大
大多采用混合专家模型架构
峰值性能更高，而许多西方开源模型
比如Gemma、Nemotron则以较小规模为主
不过这种局面在2026年可能会发生改变
Mistral Large 3、英伟达的Nemotron等模型也开始向大参数量的混合专家架构靠拢
不过
中国公司坚持开源权重模型的策略
背后其实有着务实方面的考量
兰伯特解释道，由于安全担忧
许多美国的顶尖科技公司不会购买中国公司的API订阅服务
因此开放权重模型成为了中国企业参与全球AI市场的重要途径
通过让全球用户本地部署模型
打入美国巨大且不断增长的AI支出市场
此外
中国开源模型的许可协议往往更加友好
大多采用无限制的开源许可
比如Apache 二点零
而Llama、Gemma等模型
则附带用户数量上限等条件
这也成为中国开源模型受欢迎的重要原因
不过，这场竞争并非零和博弈
拉施卡认为
中国顶级开源模型的广泛使用
反而会鼓励美国公司发布更好的开源模型
从而形成一种积极的循环
而兰伯特也提到
他正在推动一项名为亚当计划的美国版DeepSeek项目
旨在构建和托管高质量的美国开源AI模型及基础设施
与中国开源生态竞争
这也意味着2026年的全球开源竞争将会更加激烈
在闭源模型领域
当前的市场格局同样精彩
访谈中
两位嘉宾对主流AI实验室和模型的表现进行了细致点评
Anthropic无疑是当前的热门玩家
它们推出的Claude Opus 4.5被视为顶流模型
尤其在编程领域表现出色
深受开发者的喜爱
兰伯特提到
Claude Opus 4.5发布后热度一路攀升
甚至盖过了Google Gemini 3的风头
而Anthropic最突出的优势在于组织有序
是所有主流实验室中最不混乱的
这种稳定的组织架构为技术迭代提供了有力保障
Google的表现则展现出了低调的强大
Gemini 3发布时的营销声量不如对手
但是性能极其强劲
Google的核心优势在于全栈垂直整合能力
从TPU芯片、云计算
到模型研发和应用落地
形成了完整的技术栈
这让它不依赖英伟达的高价GPU芯片
利润率极高
弗里德曼也提到
Gemini在大海捞针任务中表现突出
处理长上下文并且寻找特定信息的能力堪称顶尖
OpenAI则呈现出了混乱中的强大
尽管内部运营常被传混乱
但是OpenAI的交付能力依然极强
GPT-5系列模型通过推理时计算优化
节省了大量成本
并且定义了新的技术范式
拉施卡和兰伯特都提到
ChatGPT凭借先发优势和飞轮效应
积累了庞大的用户群体
它们的记忆功能、多场景适配能力
也让用户形成了使用习惯
短期内难以被超越
相比之下
Meta的Llama系列则面临困境
兰伯特透露
Llama系列存在内部政治和激励机制的问题
研究人员想要构建实用的模型
但是管理层更倾向于追求基准测试排名
导致技术决策出现偏差
对于未来是否会有开源的Llama 5
嘉宾们普遍持怀疑态度
认为Meta的开源策略正在动摇
其开源生态的领先地位已经不复存在
除此之外，其他模型也各有特色
xAI的Grok-4 Super Heavy在硬核调试任务中表现出色
被弗里德曼用来解决其他模型无法处理的编程问题
OpenAI推出的首个开源模型GPT-OSS
则在工具调用方面实现了突破
成为首个在训练时就充分考虑工具调用的公开权重模型
对于2026年的竞争格局，兰伯特预测
Gemini将继续追赶ChatGPT
而Anthropic会在软件和企业端延续成功
Google Cloud凭借丰富的产品线和TPU芯片优势
将保持良好发展势头
而OpenAI虽然面临竞争
但是凭借着它在全新研究理念落地方面的核心能力
依然难以被超越
如果说过去几年AI的进步
主要依赖于预训练的规模扩张
那么2025年的最大技术突破
则标志着AI行业正式进入后训练时代
兰伯特明确指出
预训练已经变得极其昂贵
而且边际效益递减
现在模型能力的提升重点
已经从预训练转向了后训练阶段的创新
传统的预训练是计算密集型任务
核心依赖算力堆叠
通过扩大模型参数和数据集规模来提升性能
但是随着模型参数量达到万亿级别
预训练的成本已经高到令大多数机构望而却步
DeepSeek的预训练费用大约为500万美元
而如果包含工程调试、实验和集群闲置在内
训练一个模型的实际成本可能更高
更重要的是
预训练的唾手可得的果实已经被大量采摘
继续扩大规模带来的性能提升越来越有限
与之相对，后训练阶段的核心技术
带有可验证奖励的强化学习
RLVR，彻底改变了模型的训练方式
兰伯特解释道
传统的基于人类反馈的强化学习
RLHF，更多是调整模型的语气和风格
属于微调偏好，容易触及性能天花板
而RLVR则是让模型在数学、代码等有客观答案的领域
进行大规模试错
通过从生成到评分的迭代循环
让模型像人类学生一样在数万次练习中自我修正
从而解锁预训练中已有的知识
拉施卡用一个生动的例子展示了RLVR的强大
他在Math 五百数据集上训练通义千问3基座模型
仅用了50个步数
几分钟内准确率就从15%飙升到了50%。
这并非是模型在短时间内学会了数学
而是RLVR解锁了预训练中已经存储的知识
RLVR的美妙之处在于
它能让模型展示完整的推理步骤
甚至出现顿悟时刻
让模型意识到自己的错误并自我修正
这不仅提高了准确性
也增强了用户对模型的信任
值得注意的是
预训练和后训练的硬件需求截然不同
预训练是算力受限
核心指标是每秒浮点运算次数
Flops
而后训练阶段的RLVR则更像是内存密集型任务
更看重GPU的运行时间
而非单纯的算力堆叠
兰伯特提到
现在强化学习的运行天数正在接近预训练的天数
虽然没有同时使用那么多GPU
但从GPU小时数或者实际时长来看
强化学习的规模正在快速追赶
除了RLVR以外
后训练阶段还包括中期训练和人类反馈强化学习
中期训练介于预训练和后训练之间
本质上是专业化的预训练
比如专门训练模型的长上下文能力
以弥补预训练阶段在特定领域的数据不足
而RLHF则依然是必不可少的点睛之笔
主要用来调整模型的语气、风格和格式
使其更符合人类的交互习惯
用兰伯特的来话说
中期训练赋予模型技能
RLVR通过试错深化能力
RLHF负责最后的润色与交互体验
三者共同构成了后训练的完整体系
除了训练范式的变革
AI对编程领域的重塑
可能也远超许多人的预期
访谈中
三位嘉宾都分享了自己使用AI编程工具的体验
而这些体验背后
是软件工程领域的深刻变革
兰伯特提到了Vibe Coding的概念
开发者不再纠结于具体的代码细节
而是通过自然语言描述需求
让AI快速生成并且修改代码差异
在这种模式下
人类的角色从代码的编写者
转变为了系统设计师和审查者
他提到
自己用Claude Code构建数据分析工具时
原本需要几天时间的工作
AI几小时就完成了
而且生成的代码趋势合理
只需进行简单的核查即可
拉施卡则更倾向于使用VSCode的Codex插件
他认为这款工具达到了恰到好处的平衡点
既能提供代码帮助
又没有完全取代人类的工作
符合他对代码的控制欲
弗里德曼则是Cursor和Claude Code的重度用户
他提到
使用Claude写代码的一个意外收获是培养了用英语编程的能力
这种体验让他不再微观管理代码生成的细节
而是更关注代码的逻辑和结构
三位嘉宾都认同
AI正在让软件开发变得高度工业化
虽然完全自动化的超级智能编程
因为数据分布的参差不齐
难以在短期内完美实现
但是工具的门槛正在急剧降低
兰伯特预测
未来一个不懂底层代码的人
只要拥有清晰的系统设计思维
利用Claude Code或Cursor等工具
就能构建出复杂的软件系统
而弗里德曼分享的一项调查数据
也印证了这一点
在拥有10年以上经验的专业开发者中
超过50%代码由AI生成的案例中
高级开发者占比更高
而且大约80%的开发者表示
AI让他们的工作更有趣
不过，AI编程也带来了一些新的挑战
拉施卡提到
自己维护的开源仓库最近收到了大量由大模型生成的Pull Request
作为维护者
他需要花费大量时间审核这些代码
这让他有些应接不暇
此外
AI生成的代码可能存在隐藏的漏洞
而初学者如果过度依赖AI
可能会失去亲手构建代码的机会
难以建立深刻的思维框架
因此，嘉宾们普遍认为
AI是编程的强大助手，但不是替代品
人类开发者需要保留核心的系统设计能力、调试能力和逻辑思维能力
在AI的辅助下提升效率
而非完全依赖AI
针对AI发展是否遇到瓶颈的质疑
两位嘉宾给出了明确的否定答案
那就是Scaling Laws并没有失效
只是扩展的维度变得更加丰富了
传统的Scaling Laws主要关注两个核心维度
分别是模型参数规模和数据集规模
过去几年
AI行业的发展确实遵循着这个规律
模型参数量从数十亿
一路飙升到万亿级别
数据集规模也达到了万亿Token级别
模型性能随之持续提升
但是正如我们之前提到的
单纯的预训练规模扩展已经面临成本高、边际效益递减的问题
因此行业开始探索多维度的扩展策略
兰伯特将当前的规模扩展分为了三个维度
第一个维度是传统的Scaling Laws
即继续堆叠模型参数和数据集
这依然是技术发展的基石
尤其是对于大模型而言
更多的参数和更高质量的数据
依然能带来性能提升
第二个维度是强化学习规模
也就是模型可以进行多长时间的试错学习
这正是RLVR技术的核心
通过延长强化学习的训练时间
让模型在更多任务上进行试错
从而深化能力
第三个维度是推理侧算力扩展
即让模型在回答前思考的更久
生成更多的思维链Token
OpenAI的o1模型就是这个维度的典型代表
它通过在推理时生成大量隐藏的思维链
显著提升了复杂任务的解决能力
这种多维度的扩展策略
使得科技巨头们在2026年
依然敢于投入数百亿美元建设吉瓦级规模的算力集群
拉施卡用一个形象的比喻解释了这种策略
在一个拥有无限算力的理想世界里
你会把这三个维度的旋钮全部拉满
但是在现实中
这变成了一场关于性价比的权衡游戏
大公司需要考虑
是花1亿美元训练更大的模型
还是花200万美元做推理侧扩展
才能获得同等的性能提升
OpenAI选择了后者
兰伯特提到
GPT-5系列通过高端线路功能的路由机制
让大多数用户不再消耗昂贵的GPU资源
节省了大量成本
而对于需要巅峰性能的特定任务
比如奥数竞赛、复杂编程
则可以通过调用更多的算力、生成更长的思维链来实现
这种通用场景省成本
高端场景提性能的策略
已经成为了当前平衡性价比和用户体验的最优解
嘉宾们普遍认为
Scaling Laws的多维度扩展
将在未来几年持续主导AI行业的发展
随着吉瓦级算力集群的落地
实验室将拥有更多算力用于训练和推理
而如何在三个维度之间找到最佳平衡点
将成为各大AI公司的核心竞争力
谈到通用人工智能AGI的未来
嘉宾们打破了单一全能模型统治世界的幻想
兰伯特明确表示
单一通用模型的梦想已经破灭
未来的AI生态将是分工明确的系统
属于多Agent与专业化模型
为什么单一通用模型难以实现呢？
首先，不同任务的需求差异巨大
法律、医疗、编程、数学等领域
都有其独特的知识体系和任务特点
一个模型很难在所有领域都达到顶尖水平
其次
数据分布的参差不齐也限制了通用模型的能力
某些领域的训练数据非常匮乏
模型难以通过预训练和后训练掌握相关技能
最后，从性价比角度来看
专业化模型更具优势
针对特定任务优化的模型
能够以更低的成本提供更高的性能
而通用模型为了覆盖所有任务
往往需要付出巨大的算力和数据成本
因此
未来的AI生态将呈现术业有专攻的格局
不会再依赖一个单一的ChatGPT去处理所有事务
而是会有专门负责法律的垂直模型、专门处理医疗诊断的模型、专注于编程的模型等
人们将根据不同的任务
调用不同的Agent
而未来的数据中心里
将是许多专门的AGI在相互交流、管理和执行任务
弗里德曼则提到
在AI 二零二七报告中
曾预测二零二七年将出现超越人类水平的编程者
进而实现AI研究自动化
但是嘉宾们认为这个时间线可能需要推迟
兰伯特认为，AI的能力是锯齿状的
在某些方面表现卓越
而在另一些方面表现糟糕
即使在编程领域
AI也可能在传统机器学习系统和前端开发中表现出色
但在分布式机器学习等领域存在短板
因此，人机协作的模式将长期存在
最顶尖的AI研究人员和开发者
将是那些能够充分发挥AI优势、弥补AI短板的人
不过
嘉宾们对AI的长期发展依然乐观
拉施卡认为
大语言模型最终会像计算器解决计算问题一样
解决编程问题，成为一种通用的工具
而兰伯特则预测，到2026年底
被自动化的软件数量将会非常高
软件开发将更多地转向系统设计以及对结果目标的追求
任何人都能凭指尖灵感创造软件
对于想要从零开始进入AI开发与研究领域的人
两位嘉宾结合自己的经验
给出了一些非常实用的建议
拉施卡的核心建议是
从头开始构建一个简单的模型
他认为
这么做的目的不是为了用自己构建的模型
来取代ChatGPT或其他开源模型
而是为了确切了解大模型的输入输出、预训练的运作机制
以及注意力机制、Transformer块等核心组件的工作原理
通过在自己的电脑上从零构建一个模型
能让学习者深入理解预训练、监督微调等关键流程
而这种底层理解是使用现有工具无法获得的
他特别提醒
不要一开始就去阅读Hugging Face的Transformers库源码
为了兼容成百上千种模型和生产环境
这些代码极其复杂而且交织在一起
阅读体验不是线性的
不适合初学者学习原理
相反，他建议采用逆向工程的方法
先查看模型仓库中的配置文件
了解模型的层数、注意力机制类型等参数
然后从基础模型开始
逐步添加这些组件，加载预训练权重
验证自己的架构是否正确
他举例说
自己曾花了一天时间处理Llama 3的位置嵌入扩展
正是在这种挣扎的过程中
才真正理解了相关技术
兰伯特则建议，在掌握基础后
应该深入研究一个细分领域
AI领域发展太快
顶尖人才往往会转向解决更大的难题
这就为初学者留下了许多细分领域的机会
他以自己关注的性格训练为例
通过调整数据让模型变得幽默、讽刺或严肃
就是一个有趣且有价值的细分方向
他提到
一位牛津大学的博士生正是在这个方向深入研究
最终发布了相关论文
对于没有充足算力的初学者
兰伯特建议专注于评估工作
通过使用闭源模型或开放权重模型的补全结果
研究模型的失败模式和能力边界
如果你能发现一些顶尖模型难以处理的问题
同样能在行业中获得认可
两位嘉宾都强调了挣扎的价值
拉施卡认为
学习过程中没有感到挣扎
说明没有遵循正确的学习流程
兰伯特则提到
他在推导DPO论文的数学步骤时非常痛苦
但这种挣扎让他对技术有了更深刻的理解
对于使用AI辅助学习
嘉宾们的建议是分阶段进行
先进行一轮离线、专注模式的学习
努力克制立即查阅资料的冲动
让问题沉淀一段时间
之后再使用AI作为复习工具
补充背景知识、解决遗留问题
而不是一开始就依赖AI获取答案
除了技术本身
访谈还探讨了AI行业的职场文化、商业整合等热门话题
在AI行业
九九六文化正在变得越来越普遍
拉施卡解释道
九九六指早上9点工作到晚上9点
每周六天
总共七十二小时的工作模式
这种拼命工作的心态在硅谷AI公司中尤为突出
兰伯特则提到
前沿实验室的员工几乎是一直工作
这种高强度工作的背后
是激烈的行业竞争和互相超越的技术氛围
因为模型更新迭代的速度极快
一旦落后就可能被市场淘汰
不过
这种高强度工作也带来了高昂的人力资本代价
许多员工会感到职业倦怠
尽管工作强度大
但是AI行业的薪酬待遇非常诱人
兰伯特透露，OpenAI员工的平均薪酬
仅股票部分每年就超过100万美元
对于普通人来说
只要能进入这类顶尖AI实验室
人生都会发生翻天覆地的变化
这也导致了一种现象
许多顶尖大学的博士生会选择放弃学位
加入OpenAI、Anthropic等公司
不过，嘉宾们也指出
学术界和工业界各有优势
学术界能提供更自由的研究环境和个人认可
而工业界则能提供更充足的资源和更高的薪酬
选择哪种路径
取决于个人的职业规划和价值追求
在商业层面
2026年AI行业将迎来整合浪潮
兰伯特提到
目前AI初创公司的溢价非常高
成立仅一年左右的初创公司估值可能达到100亿美元
而成立八个月的Manus
就以20亿美元的价格被收购
未来
大型科技公司可能会收购更多有技术优势的AI初创公司
比如有传言称Apple可能收购Perplexity
此外
授权交易也会成为重要的整合方式
比如Grok与英伟达之间的200亿美元非排他性授权协议
不过这种方式可能无法让普通员工受益
与完整收购存在本质区别
对于Anthropic、OpenAI等顶尖AI公司是否会IPO
嘉宾们普遍认为短期内可能性不大
只要融资容易
这些公司就不会选择IPO
因为公开市场会带来业绩压力
而在中国
MiniMax和零一万物等公司已经提交了IPO申请
这也反映了中美AI公司不同的资本路径
访谈的最后
嘉宾们探讨了AI领域的新技术方向、硬件发展趋势
以及人类文明与AI的长远关系
在技术前沿方面
文本扩散模型成为备受关注的新方向
拉施卡解释道
文本扩散模型源于图像生成领域的扩散模型
其核心思路是从一段随机文本开始
通过多次迭代不断填补和完善缺失部分
实现文本生成
与传统的自回归Transformer一次生成一个Token不同
文本扩散模型可以同时处理多个Token
实现并行化生成，效率更高
不过，文本扩散模型也存在权衡
要想达到与自回归模型相同的质量
需要增加去噪步数
最终消耗的算力可能相差无几
而且在推理、工具调用等非并行任务中表现不佳
嘉宾们认为
文本扩散模型不会取代自回归大语言模型
但是可能用于快速、廉价且大规模的文本生成任务
工具调用是另一个重要的发展方向
目前
工具调用主要集中在闭源大模型上
但未来会有更多开源工具涌现
工具调用的核心价值在于
将某些依赖记忆的任务外包给工具
比如让模型调用计算器解决数学问题、调用搜索引擎获取实时信息
这能有效减少模型的幻觉问题
不过
工具调用也面临信任和安全挑战
赋予大模型访问邮件、硬盘的权限可能带来风险
如何在保障安全的前提下实现工具调用的广泛应用
是行业需要解决的问题
在硬件方面
英伟达依然占据主导地位
但是面临着Google、Amazon、微软等公司的挑战
这些公司都在制造自己的芯片
嘉宾们认为
英伟达的核心护城河不仅是GPU硬件
更是演进了二十年的Cuda生态系统
这种长期积累的软件生态很难被复制
未来
训练和推理算力可能会发生分离
英伟达也推出了针对特定场景的新芯片
比如专为推理预填充阶段设计的低内存芯片
而黄仁勋作为英伟达的核心领导者
他对公司的高度掌控和对AI趋势的敏锐判断
将继续推动英伟达在AI硬件领域的领先地位
谈到人类文明与AI的长远关系
嘉宾们都保持了乐观的态度
认为，100年后
AI可能会被统称为计算机
其核心依然是计算能力的提升
而深度学习作为一个术语会被铭记
兰伯特则预测
未来人类会随身携带某种物理计算设备
用于保障隐私和实现与互联网的接口
而AI带来的最大价值
将是提升人类的自主性和社区感
让人们有更多时间与亲近的人相处
赋予生活更多意义
嘉宾们也提醒
AI的发展需要平衡创新与伦理
AI生成的垃圾内容可能会泛滥
需要建立有效的内容验证机制；
AI带来的就业岗位流失可能会引发社会问题
需要建立完善的社会支持系统；
而AI的安全问题则是重中之重
尤其是在机器人、自动驾驶等具身智能领域
必须确保AI系统的可靠性
避免造成人身伤害
总的来说
这场长达数小时的硬核访谈
为我们清晰地勾勒出了2026年AI行业的全景图
从中美开源竞争的格局反转
到主流AI实验室的各有优劣；
从后训练与RLVR的技术革命
到AI编程带来的行业变革；
从多维度扩展的规模定律
到多智能体主导的AGI终局
我们看到了一个充满活力、快速迭代的AI行业
AI的发展不是一蹴而就的
它需要技术的持续创新、资本的理性投入、人才的不断涌现
更需要行业对伦理和安全的坚守
作为普通人，我们不应畏惧AI的发展
而是应该主动拥抱这个变革
无论是学习AI知识，还是使用AI工具
都能让我们在这个快速变化的时代中占据主动
感谢收看本期视频，我们下期再见
