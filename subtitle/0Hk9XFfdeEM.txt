大家好，这里是最佳拍档，我是大飞
前一段时间
大家都在猜测OpenAI是不是已经开始在训练GPT-5
但是后来CEO 萨姆奥特曼出来辟谣
说没有计划训练GPT-5
当时也有网友表示
OpenAI可能是给它起了换了个新名字
所以他们才说没有训练GPT-5
这就像当时推出代码解释器一样
许多人感觉它的能力早已经不是GPT-4模型
而应该是GPT-4.5
不过既然CEO都这么说
大家最后也就都不了了之了
不过，在9月1日
国外博客80000 Hours
主持人罗布·维布林（Rob Wiblin）在采访DeepMind联合创始人、现在Inflection AI的CEO穆斯塔法·苏莱曼（Mustafa Suleyman）的时候
苏莱曼在采访时投出了重磅炸弹
他怀疑OpenAI正在秘密训练GPT-5
并且原话是，Come On
我认为我们都直截了当地说会更好
意思就是大家都别装了
都开诚布公点不好么
你看我们都这么公开透明了
你们也别老在怀里藏着掖着了
另外，采访中，苏莱曼还公布
在未来18个月内
Inflection AI训练的模型比当前的前沿模型大100倍
未来3年内
Inflection的模型比现在大1000倍
并且爆出了很多自己在DeepMind和Inflection AI工作时的内部信息
包括了谷歌当时收购DeepMind和之后的内幕
某种程度上解释了为什么DeepMind相比于OpenAI起了个大早
却赶了个晚集
他还认为
开源模型可能会增加AI带给人类的不稳定和危害
而AI安全性最大的威胁来源并不是大语言模型
而是未来可能出现的自主智能体
那我们就来看看苏莱曼这次访谈的主要内容都有哪些
首先
我们先来简单介绍一下穆斯塔法·苏莱曼
他年轻时就读于牛津大学
但是为了帮助创办穆斯林青年热线而退学
并与伦敦市长一起研究人权政策
2010年
他与儿时好友黛米斯·哈萨比斯（Demis Hassabis ）一起帮助创建了世界顶级的人工智能实验室之一DeepMind
2014年，DeepMind被谷歌收购
他成为DeepMind应用人工智能负责人
2019年，他离开DeepMind
在谷歌母公司担任政策职务
2022年，他离开谷歌
与LinkedIn创始人里德·霍夫曼（Reid Hoffman）一起创立了Inflection AI
目前已经获得超过10亿美元的投资
正在致力于建造世界上最大的超级计算机之一
并且推出了个人化AI聊天机器人Pi
维布林开场先向苏莱曼提出了一个问题
就是未来AI是否有可能会成为一个有自主进化能力的智能体
苏莱曼认为，在短期之内
不太可能出现这种智能体
一种能够自主运行
能够制定自己的目标
能够识别环境中的新信息、新的奖励信号
并且学会用它作为自我监督
并且随着时间的推移更新自己权重的人工智能体
但是这种自主进化能力的AI
是所有人都不应该忽视的东西
因为如果某种AI技术真的展现出这种能力的
它可能会有非常大的潜在风险
至少在他知道的范围之内
Inflection AI和DeepMind都没有在往这个方向上走
他认为Inflection AI不是一家AGI公司
他们想做的事就是希望能够做出一个非常好用的个人助理
这个助理在能够充分访问用户个人信息的前提下
为用户提供高度定制化的AI服务
接下来
维布林问了苏莱曼关于把最新的模型开源出去的看法
作为一直在闭源科技公司工作的苏莱曼
对于开源模型的价值和可能的风险
有非常与众不同的观点
首先，他认为
在未来5年这个时间维度之内
开源模型始终会落后于最前沿的闭源模型
3-5年的时间
而且
开源模型会增加AI带来的社会风险
如果所有人都能无限制地访问最新的模型
将会出现一个现象
也就是所谓的力量的快速扩散
举个例子
就像新媒体平台让每个人都可以成为一个自媒体
像一份完整的报纸一样发挥作用
拥有数百万粉丝，甚至能影响全世界
那么对于最前沿大模型的无限制访问
也将会扩大这种力量
因为在未来3年内
人类能够训练出比现有模型规模大上1000倍的模型
即便是Inflection AI
也能在未来18个月内
获得比现在最前沿的大模型大100倍的计算能力
而开源的大模型会将这种力量交到每个人的手中
相当于给了每个人一个潜在的大规模不稳定破坏性的工具
而到时候
如果再想办法避免这些工具可能产生的破坏性后果
有人做了一个很巧妙的比喻
那就是试图通过用手接住雨水
来让雨停下来
他曾经向监管部门解释过
AI技术未来会降低很多潜在危险化合物或者武器的开发门槛
AI能在实际制作这些东西的时候
提供大量的帮助
比如在实验室中遇到技术挑战的时候
告知他们从哪里获取工具等等
不过他也承认
从预训练中删除这些内容
对模型进行对齐等等办法
可以有效地降低这样的风险
总之
对于用大模型能力来做坏事的人来说
需要尽量让他们在做这些事的时候变得困难
但是如果不管不顾的开源一切模型
那么未来面对能力越来越强的模型
将会暴露更多的类似风险
所以虽然开源模型对于很多人来说确实是一件好事
能够让所有人都获得模型
并且进行各种各样的尝试
带来技术上的创新和改进
但是也一定要看到开源的风险
因为并不是每个人都是善意和友好的
苏莱曼还强调
并不是为了攻击开源社区才说出这番言论的
虽然他知道说这样的话
可能会被很多人理解为他在做的事和开源社区存在利益冲突
因此很多人可能会很生气
但是他还是要坚持表达他的观点
接下来二人又聊了聊在谷歌和DeepMind期间的事情
在DeepMind度过的10年里
苏莱曼花了大量时间试图将更多的外部监督融入到构建AI技术的过程中
这是一个相当痛苦的过程
虽然他认为谷歌的出发点是好的
但是公司运作的方式仍然像传统的官僚机构一样
一开始当他们设立谷歌的伦理委员会时
计划是有九名独立成员的
作为开发敏感技术过程中进行外部监督的一项重要措施
但是因为他们任命了一个保守派人士
而这个人过去曾经发表过一些有争议的言论
很多网友就在推特等场合抵制她
同时也抵制其他支持她的几个成员
要求他们退出委员会
最后这变成了一场彻底的悲剧
结果非常令人沮丧
他们花了两年时间来建立这个委员会
但是在一周内
九名成员中的三名辞职了
最终那个保守派人士也辞职了
然后这个委员会就失去了半数成员
然后公司转过来说
我们为什么要招人来限制自己？
这纯粹是浪费时间
其实，当DeepMind被收购时
苏莱曼他们就提出了一个收购的条件
就是要有一个伦理和安全委员会
原本的计划是要将DeepMind打造成一个全球利益公司
一个所有利益相关者在做决策时都能发声的公司
因此它是一个按担保有限责任公司设立的公司
然后，他们计划制定一个宪章
为AGI的开发制定相关的伦理安全目标
这样就可以将收入的大部分用于科学和社会使命
这是一个非常有创意和实验性的结构
但是当Alphabet看到伦理委员会设立的时候
他们变得胆怯了
他们不希望同样的事情也会发生在那个全球利益公司的身上
最终，DeepMind被合并进了谷歌
从某种程度上说
DeepMind从未独立过
当然现在当然也完全从属于谷歌
在AI训练成本方面，苏莱曼认为
未来AI训练的规模不可能达到
训练某个模型需要100亿美元的成本
除非真的有人会花3年时间去训练一个模型
因为堆叠越多算力去训练一个越大的模型
需要的时间也会更长
虽然花的成本越高
但是这不是一个没有上限的数学问题
需要考虑很多实际情况的限制
不过
因为算力成本随着芯片算力的迭代
在不断下降，所以未来可能会出现
训练某个模型的成本相当于在2022年花费了100亿美元来训练
但是又因为芯片算力会以2-3倍的效率增长
所以到时候训练一个这样规模的成本
应该会远远小于现在看起来的成本
比如说
现在开源社区中的Llama2或者Falcon等模型
只有15亿参数或20亿参数
就获得了接近有1750亿参数的GPT-3的参数的能力
最后
两人聊到有关于AI模型的军备竞赛
苏莱曼介绍到，他的公司
也就是Inflection AI
正在建造世界上最大的超级计算机之一
并且他认为在接下来的18个月内
他们可能会运行一次比GPT-4训练大10倍或者100倍的训练
不过这种训练仍然会产生一个聊天机器人
大家可以把它理解为一个更好的GPT-4
但是因为它依然缺乏自主性
不能进行改造物理世界等等行为
所以模型本身并不具有危险性
但是如果模型能够实现自我迭代
自我制定目标这些能力
可能就会真的变得很危险了
不过那大约是五年、十年、甚至二十年之后的事了
因为主持人提到了Authropic的态度
他们不愿意第一个公开自己在研究的东西
苏莱曼不愿意置评
结果就聊到了OpenAI
他觉得萨姆奥特曼最近说他们没有训练GPT-5
可能没有说实话
他觉得所有拥有大规模算力的公司
都应该能尽可能的保持公开透明
所以他也披露了自己拥有的计算总量
目前
他们有6000台H100正在训练模型
到12月
将会有22000个H100全面投入运营
因此从现在开始
每个月都会增加1000到2000台H100
同时
他认为谷歌DeepMind也应该做同样的事情
应该披露Gemini接受了多少FLOPS训练
关于Gemini我们前两天也做过一起节目
现在谷歌应该说把宝都压到了Gemini上
有传言说
该模型将至少有上万亿参数
使用数以万计的TPU芯片训练
而且与OpenAI类似
Gemini同样是一个混合专家模型（MoE）
由多个具有特定能力的人工智能专家模型组成
这次除了生成图像和文本外
Gemini还可以生成简单的视频
类似于Runway的Gen-2
而且在编码能力方面也有了提升
至少有20多位谷歌高管参与了Gemini的研发
包括DeepMind的创始人黛米斯·哈萨比斯（Demis Hassabis）领导
谷歌创始人谢尔盖·布林（Sergey Brin）
以及前谷歌大脑主管杰夫·迪恩（Jeff Dean）等等
那以上就是这次访谈的一些关键信息
其实这次访谈也是为了宣传一下刚刚出版的
苏莱曼和迈克尔·巴斯卡合著的新书
《即将到来的浪潮：
技术、权力和21世纪最大的困境》，
苏莱曼在书中认为人类将会面临几个挑战
以及提出了一个由10个部分组成的方案
来限制新兴技术的负面和不可预见的后果
包括对人工智能模型进行能力审核
让批评者参与直接设计人工智能模型
以及极大提高政府对人工智能的理解及合理监管的能力等等
总体来说
应该是一本偏向于人工智能的中立派、或者说冷静派
主要在思考人工智能所带来的社会变化和风险
以及应对措施的书
当然，他自己也说
提的很多观点可能略微有些超前
可能是十年、二十年后才会发生
大家有兴趣可以去看一下
那关于GPT-5是否真的在秘密训练中
苏莱曼其实并没有给出非常清晰的说法
只是他觉得有可能有所隐瞒
不过这也非常符合萨姆奥特曼的风格
关于这个方面
大飞我也会持续的关注
毕竟大家对GPT-5的期待度还是相当高的
如果它的出现
让大模型AI的能力能够再次上一个台阶
那么很多人对于这次AI浪潮是否能持续的怀疑可能就会被打消
到底是算力为王，还是昙花一现
到时候应该就有个较为明确的答案了
好了，本期视频内容就到这里
感谢大家的观看，我们下期再见
