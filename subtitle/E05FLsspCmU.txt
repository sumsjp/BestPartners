大家好，这里是最佳拍档，我是大飞
不知道大家如今在使用编程AI工具的时候
有没有想过
AI是如何写出这些代码的呢？
这可能不仅仅是一个技术问题
更是对如何让机器真正理解人类意图的一种思考
在AI IDE这个领域中
Cursor显然处于领先的地位
虽然我们知道Cursor有在训练自己的小模型
但是它究竟是怎样设计出来的
背后又有着怎样的思考
其实一直是一个谜
而就在前不久
Cursor放出了一个接近1小时的内部团队讨论视频
深度分析了他们用到的技术和思考
让我们也有机会
深入了解Cursor 团队内部对于训练超人类编程模型的看法
这些来自一线研究者和工程师的见解
也揭示了当前 AI 编程领域最前沿的挑战和突破方向
他们正在解决的问题远比表面看起来的要复杂得多
涉及从强化学习的稀疏奖励到长上下文处理
从多步骤工具调用到实时用户反馈的方方面面
从他们的对话中可以感觉到
AI 编程能力正在经历一个临近质变的关键节点
传统的训练方法已经遇到瓶颈
而新的解决方案需要在计算效率、训练稳定性和实际效果之间找到平衡
更重要的是
这些技术突破将会直接影响我们每一个开发者的日常工作体验
为了让大家能够深入了解
这些技术专家正在如何塑造编程的未来
大飞我整理了一下视频的核心内容
分享给大家
首先，我们必须意识到
训练编程 AI所面临的挑战
远比我们想象的要复杂
Cursor团队指出
编程领域的强化学习与数学或写作等其他领域
有着根本性的差异
在数学推理中，答案通常很短
推理过程可以帮助模型逐步到达正确的答案
但是在编程中
推理本身就嵌入在答案里
代码既是思考的过程
也是最终的结果
更复杂的是
编程任务往往需要多个步骤的工具调用过程
编程任务不像简单的生成任务那样
生成推理token
然后生成答案
最终获得奖励，它的流程更像是
生成一些token
调用工具，获取工具响应
然后可能需要迭代多次
这种多步骤的特点
使得强化学习的形态发生了根本上的变化
因为现在需要优化整个多步骤的工具调用过程
而不是单一的输出
有趣的是
Cursor 团队特别重视那些无法通过传统方式验证的场景
虽然数学问题有标准答案
编程问题也可以通过测试来验证
但是在实际应用场景中
很多时候用户并不会明确告诉系统
某个解决方案是否是有效的
这就需要在没有明确反馈信号的情况下进行强化学习
这是一个前所未有的挑战
对于写作等其他领域
团队认为当前的后训练方法
往往会让模型写出僵硬死板的内容
但是这并不是模型固有的局限性
而是训练方式所导致的结果
他们提出了一个有趣的想法
为什么一定要训练模型来预测下一个词
而不是整个章节呢？
如果让模型根据当前的章节来预测整个下一章节的内容
然后使用某种相似性度量
来评估预测章节与真实章节的相似度
那么就能将困难的下一个词的预测问题
转化为更长序列的预测
并且允许使用语义奖励来进行优化
不过
编程和写作之间存在的一个关键差异在于
代码的好坏有相对客观的标准
主要是功能性是否正确
而写作的质量很大程度上取决于个人的品味
即使是经验丰富的专家
对同一篇文章的好坏也可能有完全不同的观点
虽然在编程中也存在类似的主观性问题
比如对代码质量的评判
但是一旦代码通过了测试
要想进一步提升代码的质量就变得相当困难
因为通过测试这个标准
并不能够捕捉到模型为了通过测试而采取的具体方法
在深入介绍了训练方法后
Cursor团队对于将测试作为奖励信号
表示出了既认可又谨慎的态度
测试的优势很明显
它提供了接近于真实情况的信号
如果测试覆盖的比较充分
就能够给出代码是否有效的可靠反馈
可以基于这个信号进行长期的强化学习
并且学习到一些有趣的行为模式
但是测试无法捕捉到所有重要的方面
这就需要放宽条件
寻找其他获得奖励的方式
其中一个创新的想法是使用真实变更的对比数据
比如某个功能变更的真实 diff
虽然这不是一种完美的信号
但是可以作为验证信号的有用信息
团队还提到了一个有趣的观察
那就是模型实际上看到的不是原始奖励
而是优势值，也就是相对奖励
通常情况下，如果任务太困难
模型只能在一千次尝试中成功一次
那么稀疏奖励就会成为真正的问题
如果成功率能达到百分之一或者稍高一些
那么这个信号就是可以使用的
而对于大任务的分解
比如完整的 Pull Request
除非投入大量的计算资源
否则会非常困难而且稀疏
因为以目前模型的能力水平
很少能够通过完整PR的所有测试
但是如果能够将完整的 PR 分解为更小的部分
并且对每个部分进行测试
可能就会减少奖励稀疏
从而给模型带来显著的性能改进
在谈到如何选择工具的时候
Cursor团队提到
不同的实验室会选择不同的工具集
来训练强化学习模型
比如 OpenAI 的 o3 模型
专门针对终端进行了高度的优化
它是一个相当奇特的模型
只倾向于使用 grep 和 sed 命令
而且除了终端之外
不愿意使用任何的其他工具
而 Claude 模型则倾向于围绕搜索和编辑进行设计
这种差异反映了不同团队
对如何权衡工具复杂性与效果之间的不同理解
Cursor团队认为
终端工具受到青睐的主要原因是因为它的简单性
你不需要构建复杂的测试框架来运行 agent
只需要给它一个 shell 的访问权限
它就可以在那里完成所有的工作
不过他们也指出
其实可以在核心工具集的基础上做得更好
比如代码检查工具Linter就是一个很好的例子
虽然Linter 能够提供大量的信号
但是想要获取这些信号
就需要运行语言服务器
而让语言服务器在任意代码上运行
实际上是相当困难的
不过Cursor 的优势在于
自带了预安装的语言服务器扩展
用户通过设置就可以获得像 Linter 这样的工具信号
他们还提到了语义搜索工具
虽然语义搜索在静态代码文件上
可能无法提供比多跳搜索更多的信息
但是它能查的更快，成本更低
使用的上下文窗口也更少
速度也更快
团队还提到了一个有意思的观点
就是我们可以使用工具来管理模型本身的行为
比如
很多推理模型喜欢进行大量的推理
甚至在不需要推理的情况下也会过度思考
而缓解这个问题的一种方法
就是给模型添加一个思考工具
当模型意识到当任务需要一些推理的时候
才调用这个工具来启用推理过程
现在的推理模型
往往会在提交用户消息后、甚至还没有看到任何内容之前就开始思考
然后调用所有这些工具
所以Cursor团队的成员建议
对于某些步骤来说
其实可以考虑在工具调用之后再进行思考
在讨论代码和长上下文的交互时
Cursor 团队的观点也让人眼前一亮
他们指出，在某种程度上
长上下文确实非常重要
因为如果将所有的内容都限制在 8K token 以内
那么现在所有的模型基本上是等效的
可能需要至少 50-60k token 的上下文长度
才能看出不同模型之间的区别
上下文的趋势肯定是会一直越来越长
但是成本也会越来越高
对于究竟需要多长的上下文窗口这个问题
团队认为更长肯定更好
但是也会存在递减效应
长期来看
即时查询检索相关的 token
肯定不是唯一的方法
最有意义的可能还是使用混合机制
比如DeepSeek的NSA机制
它将注意力分为了三个部分
一个进行滑动窗口注意力
关注短期发生的事情
另外两个部分进行块状注意力
每隔一定数量的 token
就将它们存储为键和值
然后查询会关注这些块
从中获得最相关的前 k 个块
然后对这些块进行完全注意力
而对于长上下文的评估来说
真正的困难在于如何判断基线效果
因为各种机制多多少少都是有效的
比如稀疏注意力
或者让一些头关注局部
另一些头关注全局
这些都会带来性能和速度方面的差异
所以评估必须要非常严谨
在讨论更复杂的状态工具时
Cursor 团队提出了一个非常有趣的概念
就是记忆工具
这种工具允许模型存储信息片段
并且稍后能够进行检索
但是问题在于
如何鼓励模型实际存储的是对以后有用的好记忆呢？
这个问题比看起来要复杂得多
因为它涉及到了跨时间序列的信用分配问题
记忆工具里实际上包含了两个不同的工具
一个工具是"我想把这次的交互存储成记忆"，
而另一个则是"我要检索那次的记忆"。
检索记忆相对简单
如果检索到的记忆有帮助
就可以给予奖励
但是存储记忆则复杂得多
因为奖励要看后面一系列动作的表现
而不是当前这一步
所以在训练的时候
需要做很多完全不同情境下的采样
才能给到信号
也就是说
在训练时既要让模型学会写入记忆
又要做后续的采样
去读取记忆并且根据效果回传奖励
这种跨轨迹的信用分配问题
使得记忆的存储机制很难直接反向传播
最好的办法还是做个基准测试
然后用不同的规则、启发式方法或者提示词实验
看看什么时候存储记忆、什么时候忘记
最后再来直接比较效果
在讨论硬件对长上下文处理的影响时
Cursor 团队展现出了对底层技术的深刻理解
他们提到
新一代 GPU 确实让长上下文处理变得更加容易
GB200 和 NVL72 架构通过两种方式支持了超长上下文
首先
由于拥有 72 个通过 NVLink 网格互连的 GPU
可以进行大规模的张量并行
还能把注意力头分布在不同设备上
更容易搞定KV 存储
其次，Grace CPU 还能做统一内存
也就能够存储更多的 KV
另外，KV 不一定要都放在 GPU 上
只要把运算和加载交错
每次用到注意力的时候
再加载到 GPU 就行
Cursor 团队还提到了一个他们特别喜欢概念
也就是文档级注意力
他们称之为章鱼注意力squid attention
因为他们把它想象成了一个章鱼
每个文档就像一个不同的触手
这个概念简单来说
其实就是让每个文档都能独立 “关注自己”，
最后再一起全局关注
好处就是可以把多个文档的 key 和 value 各自缓存起来
推理的时候可以随时替换
不需要重新预填充
这对于产品的快速创建内容、语义检索和读取文件等功能
都会非常有用
当谈到如何优化真实世界的使用
而非仅仅是测试用例的时候
Cursor 团队谈到了当前强化学习方法的一个重要局限
他们指出
目前大多数强化学习都是为了完成一堆的测试用例
但是训练人员真正关心的
并不是模型在测试用例上的表现
而是希望它能够更好地处理人类实际的需求
比如在文件中添加 console log
或者其他以人为中心的工作
而想要获得这些以人为本的奖励信号
就需要从真实环境中的真实人类那里
获得真实的信号
比如用户是否喜欢 agent 所做的更改
或者用户是否接受了这次编辑
为此，团队提出了一个想法
那就是观察用户实际做出的真实更改
然后根据这个来判断模型做得像不像
比如让后台对某个问题进行三到四次的尝试
尝试一堆不同的模型、参数设置和温度
然后选择所有选项中最有效的那个
把它作为训练奖励模型的信号
如果确实有奖励信号
但是用户总是在三个选项中选择其中一个
那么如何以不同的方式来进行强化学习呢？
团队认为可以只针对这个信号来训练奖励模型
这样的好处是
奖励模型在看到真实情况后
会比原始模型知道得更多
从而会饱和得更晚
最后，在聊到编程 agent 的未来时
Cursor 团队认为
未来的模型将会使用更多的 token
特别是在输出上下文方面
如果看 o3 这样的模型
它会一直生成内容
直到建立起正确的上下文
才知道该如何解决问题
所以他们预计
未来的模型会在做决定前
连续调用工具很长时间
但是这样做似乎会很浪费
因为很多内容在下次又得重新算一遍
不过团队也认为
大多数情况其实没必要每次都推理那么多
可以复用之前的推理过程
从而摊销其中的一些成本
比如让 agent 查看轨迹
或者查看在代码库中之前做过的事情
学到有用的知识
再将它存储在某个地方
总的来说
长上下文或者代码库专用模型会变得很重要
只要能复用之前积累的知识、理解代码结构
不用每次都重新理解
模型就会高效很多
另外一点是，输出 token 的扩展
也会让训练的采样变得更加高效
通常在 SFT 中
模型只是从输出 token 获得信号
这也让它变得相当低效
而如果是一个超长输出
那么要进行信用分配也很困难
对此Cursor的团队发现
对于大语言模型的训练来说
高质量的数据比算力更加稀缺
但是最好的数据都是很有限的
那么怎么有效的烧算力
可能又是未来的一个优化方向了
好了
以上就是Cursor团队这次谈话的主要内容了
从他们的讨论中
我们可以看到一个编程AI更加清晰的未来图景
那就是它们将变得更加智能
不仅能够理解当前的任务需求
还能够从历史的经验中学习
从而建立对代码库的深入理解
并且能够高效地重用这些知识
我们也不得不承认
现在正站在编程范式转换的一个临界点上
我们即将从手动编写每一行代码
逐步调试，反复测试的方式
到逐渐被 AI 辅助的协作式编程所取代
在这种新的模式下
开发者将更多地专注在高层次的设计和创意方面
而将具体的实现细节
交给能够理解上下文、学习代码偏好、并且能够持续改进的 AI agent
那大家对于编程AI的未来是如何看的呢？
欢迎在评论区留言
感谢大家收看本期视频
我们下期再见
