大家好，这里是最佳拍档，我是大飞
在前两天我们介绍谷歌云2025大会的视频
提到了谷歌发布了最新的Agent协议Agent2Agent
简称A2A
虽然当时简单介绍了一些A2A和Anthropic的MCP有什么区别
但是我觉得还是有必要再出一期视频
更详细的讲一下
尤其是再算上OpenAI之前的Function Calling
到底这三个标准之间有什么区别
如何互相补充
背靠三家AI巨头的它们
在今后AI的发展中又将会有什么样的地位
今天我们就来聊一聊这个话题
咱们先来说说OpenAI主推的Function Calling
简单来讲，Function Calling的出现
主要是为了解决大语言模型早期存在的一个痛点
我们都知道，大语言模型虽然很强大
能够回答各种各样的问题
但是它也有一个明显的缺陷
就是在训练完成之后
知识更新就停滞了
比如说，你问它今天的温度是多少
或者今天的大盘收盘点数是多少
这些实时性的信息
大模型很难准确的回答
而Function Calling就像是给大模型装了一个“外挂”，
允许大语言模型和外部工具连接起来
把我们输入的自然语言
巧妙地转化为各种API调用
这样就能借助外部工具来获取最新的信息
从而解决大模型知识更新不及时的问题
那Function Calling具体是怎么工作的呢？
我们以天气查询为例来详细讲解一下
想象一下
你问大模型“北京今天的天气怎么样”，
这个时候
Function Calling就开始发挥作用了
首先是函数定义阶段
开发者会提前定义好了一个专门用来获取天气信息的函数
比如“get_current_weather”，
同时还规定了描述、参数和参数的类型
像这里的参数就可能包括城市“location”和温度单位“unit”。
接下来是模型的推理环节
大模型接收到你的问题后
会对问题进行分析
判断这个问题是不是需要调用函数来解决
当它发现这是一个关于实时天气的问题时
就确定需要调用天气相关的函数了
然后进入参数的生成阶段
大模型会根据问题的内容
生成函数所需要的参数
并且以JSON格式输出
比如针对“北京今天的天气怎么样”这个问题
生成的参数可能就是{"location":
"北京",
"unit": "celsius"}。
再然后是函数的执行阶段
开发者会根据模型输出的这些参数
去执行实际的函数
在这里
就是使用这些参数去调用实际的天气API
来获取北京的实时天气数据
最后是结果整合阶段
把函数执行得到的结果返回给大模型
大模型再根据这些数据来生成最终的回答
比如“根据最新数据
北京今天的天气晴朗
当前温度23°C
湿度45%，微风
今天的最高温度预计为26°C
最低温度为18°C”。
对于开发者来说
使用大模型的Function Calling有一个很大的优势
那就是起步相对容易
他们只需要按照API的要求
定义好函数的规格
通常就是用JSON格式来定义
然后把这些信息随着请求一起发送给模型
模型就有可能按照需求去调用这些函数
整个逻辑是比较直观的
所以
在一些只需要单一模型、少量功能的简单应用场景中
Function Calling的实现非常直接
几乎可以只需要一键操作
就能够轻松地把模型输出和代码逻辑对接起来
不过
Function Calling也存在着一些局限性
其中最明显的缺点
就是缺乏跨模型的一致性
由于每个大模型供应商的接口格式都略微有些差异
这就给开发者带来了麻烦
如果开发者想要支持多个模型
就不得不为不同的API做适配工作
或者使用额外的框架来处理这些差异
这无疑增加了一定的开发难度和成本
说完了Function Calling
咱们再来看看MCP
MCP，全称为Model Context Protocol
是由Anthropic提出的一种协议
它的目标很明确
就是要解决不同大模型和不同外部工具集成时的标准化问题
目前
像Anthropic的Claude系列、OpenAI的GPT系列、Meta的Llama系列
还有deepseek、阿里的通义系列等各种主流模型
都已经接入了MCP生态
MCP采用的是客户端-服务器架构
这个架构包含了几个核心组件
首先是MCP主机Hosts
像Claude Desktop、各种IDE或者AI工具都属于MCP主机
它们是MCP生态系统的入口点
主要负责向用户提供各种AI功能
接着是MCP客户端Clients
这些客户端的作用是维持与MCP服务器的一对一连接
它们会处理通信过程中的各种细节问题
确保主机和服务器之间的数据能够顺畅传输
然后是MCP服务器Servers
这是MCP的核心部分
都是一些轻量级程序
每个服务器都可以通过标准化的Model Context Protocol
来暴露特定的功能
起到连接AI模型和实际数据源的关键作用
最后就是数据源
它包括本地数据源和远程服务
本地数据源就是你计算机上的文件、数据库和服务等等
MCP服务器可以安全地访问这些资源；
远程服务则是通过互联网可以调用的外部系统
比如各种API、云服务等
MCP服务器也能连接到这些远程服务
这几个组件的相互协作
形成了一个完整的生态系统
数据的流向是从MCP主机出发
经过MCP客户端到达MCP服务器
然后MCP服务器再去访问数据源或者远程服务获取数据；
获取到数据之后，再按照相反的路径
把数据返回给AI模型
通过这样的架构
MCP让AI模型能够安全、高效地访问各种数据和工具
大大提高了模型与外部资源整合的效率
接下来
我们再来了解一下谷歌最新推出的A2A开放协议
它主要是为了解决不同Agent之间的通信和协同问题
在深入了解A2A的工作流程之前
我们得先掌握几个关键概念
第一个概念是Agent Card
它就像是Agent的“电子名片”一样
是一个公共的元数据文件
里面详细描述了Agent的能力、技能、端点URL和认证需求等信息
通过这个Agent Card
其他的Agent就能快速了解某个Agent的基本情况
第二个是A2A Server
它负责接收请求并且管理任务的执行
当有任务到来的时候
A2A Server就会按照相应的规则和流程去处理任务
第三个是A2A Client
它是消费A2A服务的应用程序或者Agent
主要负责向A2A Server发送请求
还有任务Task
它是A2A协议中的工作中心单元
客户端通过发送消息来启动任务
每个任务会有不同的状态
可以跟踪任务的进度
比如已提交、处理中、需要输入等等
最后是消息Message
它表示客户端和Agent之间的通信轮次
包含多种形式的部分
就好比人类对话中的语句
通过这消息
Agent之间就能进行信息的交流
A2A协议的工作流程也可以分为几个阶段
首先是初始化阶段
A2A Client向A2A Server发送请求
启动一个新的任务
同时发送初始消息
然后进入交互阶段
如果任务在执行过程中
需要更多的输入才能继续
就会在这个阶段进行交互
客户端和服务器之间会不断地传递信息
接着是发现阶段
客户端会从服务器获取Agent Card
这样就能了解其他Agent的能力
为后续的协作做准备
再然后是处理阶段
A2A Server负责处理任务
并且在处理过程中会根据需要提供更新信息
最后是完成阶段，任务完成后
服务器会提供最终的结果
举个略微有些复杂的例子
在一个项目中
有一个Agent负责收集市场数据
另一个Agent负责分析市场数据
并且生成报告
负责收集数据的Agent就可以作为A2A Client
向A2A Server发送收集市场数据的任务请求
A2A Server接收到请求后
会根据任务的要求
找到具有相应数据收集能力的其他Agent
然后在处理阶段协调这些Agent进行数据的收集工作
在这个过程中
如果需要调整收集数据的范围或者方式
就会进入到交互阶段进行沟通
当数据收集完成以后
A2A Server会把收集到的数据交给负责分析数据的Agent
由它来生成报告
最后把报告作为最终结果
返回给最初的A2A Client
现在
我们已经分别了解了Function Calling、MCP和A2A这三种技术
接下来对它们进行一番对比
看看它们之间到底有哪些不同之处
先说说MCP和Function Calling
它们虽然都致力于实现外部工具与大模型的交互
但是在设计理念和应用场景上存在着明显的差异
其中最突出的就是可扩展性方面
Function Calling由于缺乏统一的标准
不同的大语言模型需要定义不同的函数格式
假设现在有M个不同的大模型应用
同时有N个不同的工具或服务
从理论上来说
开发者可能需要进行M×N次重复的对接工作
这无疑是一个巨大的工作量
而且
Function Calling本身并不直接支持函数的链式调用
模型一次只能调用一个函数
当模型获取到一个函数的结果后
如果还需要调用下一个函数
就需要由应用逻辑
把前一个函数的结果输入到模型的下一轮对话中
然后再触发下一个函数调用
虽然从原理上来说
这样可以实现函数输出作为输入形成链条
但是这整个过程需要开发者在应用层精心的编排
模型自身缺乏对这种跨调用流程的全局把控能力
而MCP则通过统一的接口标准
很好地解决了这个问题
它把复杂的M×N问题转化成了M + N的问题
对于工具创建者来说
他们只需要为每个工具或系统
实现一次MCP Server即可
对于应用开发者而言
也只需要为每个应用实现一次MCP Client
大家都遵循通用的协议
就能够协同工作
这样一来
扩展新功能的边际成本就大幅降低了
也大大提高了开发的效率和灵活性
我们再对比一下MCP和A2A
在之前的视频
包括谷歌官方的博客中也说到
这两者之间更多的是一种能力互补的关系
MCP的主要作用是让Agent能够使用各种工具
解决“做什么”的问题；
而A2A则专注于实现Agent之间的协作
解决“与谁合作”的问题
这就好比在一个汽车生产工厂里
有的同事擅长研发汽车的发动机
有的同事擅长组装汽车
如果让一个同事既负责研发发动机
又负责组装和销售汽车
那效率肯定高不起来
但要是通过一条流水线
把擅长不同环节的同事串联起来
共同完成一个项目
效率就会大大提升
在AI领域也是一样
MCP让Agent具备了使用工具的能力
A2A则让Agent之间能够相互协作
共同完成更复杂的任务
从长远来看
我们很有可能会看到这三大通信机制逐渐融合的趋势
不过
目前OpenAI和Anthropic这两家公司还没有支持A2A
而且在科技领域
大家在宣传新技术的时候都有自己的理念
但是最终如何选择技术路线
往往要考虑到背后商业利益
但是不管怎么说
从技术发展的大趋势来看
融合是必然的
随着AI技术的不断发展
各个技术之间相互借鉴、相互融合
才能推动整个AI生态系统不断向前发展
为我们带来更多的便利和创新
感谢大家观看本期视频
我们下期再见
