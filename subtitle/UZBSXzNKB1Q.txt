大家好，这里是最佳拍档，我是大飞
前几天发了一个稚晖君的视频
是他的新公司智元机器人的发布会
我看大家关注度还蛮高的
不过也有不少人对他还不熟悉
甚至认错了
我简单介绍一下，稚晖君本名彭志辉
1993年出生于江西吉安
毕业于电子科技大学
毕业后就职于OPPO研究院AI实验室
担任算法工程师
2020年，加入“华为天才少年计划”，
从事昇腾AI芯片和AI算法的相关研究工作
2022年12月27日
他在微博发文称已经从华为离职
2023年2月，创立智元机器人公司
英文名为AGIBot
现在是智元机器人的CTO兼首席架构师
稚晖君之所以出名
跟他在B站发布了很多科技产品的视频有很大关系
尤其是自动驾驶自行车、自制机械臂给葡萄缝针
相当硬核
因此还获得了哔哩哔哩“2021年度百大UP主”称号
在Youtube他也有一个频道
大家可以去订阅下
在那个视频下面
有人怀疑六个月能不能从零到一做个机器人出来
我觉得如果大家看过他以前的视频
应该就会打消这个疑虑了
好了，我们言归正传
在智元远征A1机器人发布以后
稚晖君又专门写了一篇关于具身智能的文章
介绍了自己关于这个领域的一些理解
这里也跟大家分享一下
在ChatGPT之后
又一个大模型概念火了
那就是具身智能
英文名为Embodied AI
在学术界
图灵奖得主、上海期智研究院院长姚期智认为
人工智能领域的下一个挑战将是实现“具身通用人工智能”。
在产业界
微软、谷歌、英伟达等大厂均开展了相关的研究
比如谷歌的RT-2、英伟达的VIMA等
英伟达创始人兼CEO黄仁勋在ITF World 2023 半导体大会上也表示
AI的下一个浪潮将是“具身智能”。
具身智能作为人工智能发展的一个重要分支
正在迅速崭露头角
成为科技界和大众关注的热门话题
同时在各个领域中展现出巨大的潜力和吸引力
那么究竟什么是具身智能呢？
简单来说
具身智能是通过在物理世界和数字世界的学习和进化
达到理解世界、互动交互并完成任务的目标
具身智能是一个由“本体”和“智能体”两部分耦合而成
能够在复杂环境中执行任务的智能系统
一般认为
具身智能需要具有如下的几个核心要素
第一是本体，作为实际的执行者
是在物理或者虚拟世界进行感知和任务执行的机构
本体通常是具有物理实体的机器人
可以有多种形态
本体的能力边界会限制智能体的能力发挥
所以
具有广泛适应性的机器人本体是非常必要的
随着机器人技术的进步
本体会越来越呈现多样化和灵活性
比如
四足机器人可以具有良好的运动能力和通过性
复合机器人则把运动和操作机构整合
具有较好的任务能力；
而人形机器人作为适应性更加广泛
通用能力更强的本体形态
得到了长足的进步
已经到了可以商业化的前夕
因此
本体具备环境感知能力、运动能力和操作执行能力
是连接数字世界和物理世界的载体
具身智能的第二个要素是智能体
Embodied Agents
是具身在本体之上的智能核心
负责感知、理解、决策、控制等核心工作
智能体可以感知复杂的环境
理解环境所包含的语义信息
能够和环境进行交互
还可以理解具体的任务
并且根据环境的变化和目标状态做出决策
进而控制本体完成任务
随着深度学习的发展
现代智能体通常由深度网络模型驱动
尤其是随着大语言模型的发展
结合视觉等多种传感器的复杂多模态模型
已经开始成为新一代智能体的趋势
同时
智能体也可以分化为多种任务形态
处理不同层次和模态的任务
智能体要能够从复杂的数据中
学习决策和控制的范式
并且能够持续的自我演进
进而适应更复杂的任务和环境
智能体设计是具身智能的核心
具有通用能力的大语言模型和视觉大模型
赋予了通用本体强大的泛化能力
使得机器人从程序执行导向转向任务目标导向
向通用机器人迈出了坚实的步伐
具身智能的第三个要素是数据
数据是泛化的关键
但是涉及机器人的数据不仅稀缺
而且昂贵
为了适应复杂环境和任务的泛化性
智能体规模变的越来越大
而大规模的模型对于海量数据更为渴求
现在的大语言模型通常需要web-scale级别的数据
来驱动基础的预训练过程
而针对具身智能的场景则更为复杂多样
以及围绕着复杂任务链的规划决策控制数据
尤其是针对行业场景的高质量数据
将是未来具身智能成功应用落地的关键支撑
具身智能的第四个要素是学习和进化架构
智能体通过和虚拟或者真实的物理世界的交互
来适应新的环境、学习新的知识
并强化出新的解决问题方法
采用虚拟仿真环境进行部分学习是一种合理的设计
比如英伟达的元宇宙开发平台Omniverse
就是构建了物理仿真的虚拟世界
来加速智能体的演进
但是真实环境的复杂度通常会超过仿真环境
如何耦合仿真和真实世界
进行高效率的迁移
也是架构设计的关键
那介绍完具身智能的概念
现在具身智能的科研和技术进展到底到了什么阶段呢？
应该说
在基于Transformer的大语言模型浪潮带领下
微软、谷歌、英伟达等大厂
以及斯坦福、卡耐基梅隆等高等学府
都开展了具身智能的相关研究
微软基于ChatGPT的强大自然语言理解和推理能力
能够生成控制机器人的相关代码；
英伟达的VIMA基于T5模型
将文本和多模态输入交错融合
可以结合历史信息预测机器人的下一步行动动作；
斯坦福大学利用大语言模型的理解、推理和代码能力
与VLM交互并生成3D value map
来规划机械臂的运行轨迹；
而谷歌的具身智能路线就比较多了
包括从PaLM衍生来的PaLM-E
从Gato迭代来的RoboCat
以及最新基于RT-1和PaLM-E升级得到的RT-2
与其他大厂相比
谷歌在具身智能的研究上更具有广泛性和延续性
谷歌依托旗下两大AI科研机构
Google Brain和DeepMind
在具身智能上研究了更多的技术路线
并且各路线之间有很好的技术延续性
其中基于RT-1的研究成果
谷歌融合了VLM和RT-1中收集的大量机器人真实动作数据
提出了基于视觉语言动作模型VLA的RT-2
在直接预测机器人动作的同时
受益于互联网级别的训练数据
实现了更好的泛化性和涌现性
从RT-2的实验结果看，一方面
面对训练数据中没见过的物体、背景、环境
RT-2系列模型仍然能够实现较高的成功率
远超基线对比模型
证明了模型有较强的泛化能力
另一方面
对于符号理解、推理和人类识别
这三类不存在于机器人训练数据中的涌现任务
RT-2系列模型也能以较高的正确率完成
表明语义知识已经从视觉语言数据中
转移到RT-2 中
证明了模型的涌现性能
同时
思维链推理能够让RT-2完成更复杂的任务
任何的训练都需要数据的支撑
目前来看
机器人数据来源通常是真实数据和合成数据
真实数据效果更好
但是需要耗费大量的人力和物力
不是一般的企业或机构能够负担的
谷歌凭借自己的资金和科研实力
耗费17个月时间收集了13台机器人的13万条真实数据
为RT-1和RT-2的良好性能打下根基
谷歌的另一项研究RoboCat
在面对新的任务和场景时
会先收集100-1000个真实的人类专家示例
再合成更多数据，用于后续训练
这也是一种经济性和性能的权衡
除了数据来源问题
还有一个问题就是
具身智能体的预测如何映射到机器人的动作
这主要取决于预测结果的层级
以谷歌PaLM-E和微软ChatGPT for Robotics为例
PaLM-E的预测结果处于高级别的设计层级
实现了对具身任务的决策方案预测
但是不涉及机器人动作的实际控制
需要依赖低级别的现成策略或者规划器
来将决策方案“翻译”为机器人动作
而微软默认提供了控制机器人的低层级API
ChatGPT输出是更高层级的代码
只需调用到机器人低层级的库或者API
从而实现对机器人动作的映射和控制
还有一种情况就是预测结果已经到了低级别动作层级
例如，RT-2输出的一系列字符串
是可以直接对应到机器人的坐标、旋转角度等信息
而VoxPoser规划的结果
直接就是机器人运行轨迹
VIMA也可以借助现有方法
将预测的动作token映射到离散的机器人手臂姿势
这样就不需要再经过复杂的翻译
将高层级设计映射到低层级动作
那么发展到现在
具身智能还存在哪些难点呢？
虽然具身智能作为迈向通用人工智能（AGI）的重要一步
是学术界和产业界的热点
而却随着大模型的泛化能力进一步提升
各种具身方法和智能体不断涌现
但是要实现好的具身智能
仍然面临着算法、工程技术、数据、场景和复杂软硬件等诸多挑战
首先，要有强大的通用本体平台
如何解决硬件的关键零部件技术突破
形成具有优秀运动能力和操作能力的平台级通用机器人产品
将具身本体的可靠性、成本和通用能力做到平衡
是一个巨大的挑战
从基础的电机、减速器、控制器到灵巧手等各个部分
都需要持续进行技术突破
才能够满足大规模商用的落地需求
同时，考虑到通用能力
人形机器人被认为是具身智能的终极形态
这方面的研发
也将持续成为热点和核心挑战
其次，需要设计强大的智能体系统
作为具身智能的核心
具备复杂环境感知认知能力的智能体
将需要解决诸多挑战
包括物理3D环境精确感知、任务编排与执行、强大的通识能力、多级语义推理能力、人机口语多轮交互能力、long-term记忆能力、个性化情感关怀能力、强大的任务泛化与自学迁移能力等
同时
具身智能要求实时得感知和决策能力
才能适应复杂和变化的环境
这就要求高速的数据采集、传输和处理
以及实时的决策反应
尤其是大语言模型所消耗的算力规模巨大
对于资源有限的机器人处理系统
将形成巨大的数据量、AI计算能力和低延迟的挑战
再者
高质量的行业数据也将成为巨大的挑战
现实场景的复杂多变
使得现阶段缺乏足够的场景数据
来训练一个完全通用的大模型
进而让智能体自我进化
而且，耦合的本体
需要实际部署到真实环境中
才能够采集数据
这也是和非具身智能的明显不同
比如，在工厂作业中
由于机器人本体并未参与到实际业务
所以很多实际运行数据就无法采集
而大量的人类操作数据虽然可以弥补部分不足
但是仍然需要实际业务的数据
当然
通过大模型的涌现能力和思维链能力
部分任务可以零样本学习到
但是对于关键业务
要求较高的成功率
则仍然需要高质量的垂直领域数据
同时，通过层次化的智能体设计
将不同任务限定到特定领域
也是一个解决泛化和成功率的有效尝试
最后，通过虚拟和真实的交互
持续学习和进化的能力
也是具身智能演进的重要技术途径
亿万年的生物演化过程
造就了形态丰富的生命形式
而学习新任务来适应环境的变化
则是持续改进的动力
形态适配环境合适的智能体
则可以快速的学习到解决问题能力
进而更好的适应变化
但是，由于形态的变化空间无穷巨大
搜索所有可能的选择
在有限的计算资源情况下变的几乎不可能
本体的自由度设计
也会物理上约束智能体的任务执行能力
进而限制了控制器的学习效果
在复杂环境、形态演化和任务的可学习性之间
存在着未可知的隐式关系
如何快速学习到合理的规划和决策能力
则成为具身智能的重要一环
以上就是稚晖君对具身智能相关内容的介绍
那么在这个领域
稚晖君所带领的智元机器人
是如何实践的呢？
这部分，我简单说一下
建议大家去看发布会原视频
首先
远征A1提出了一种具身智脑的概念
具身智脑Embodied Intelligence Brain
是把机器人的具身智能思维系统
分为云端的超脑、端侧的大脑、小脑
以及脑干这样四层
分别对应于机器人任务级、技能级、指令级以及伺服级的能力
⼤脑⽤于完成前⾯提到的语义级多段推理任务
结合上下文进行任务理解
⽽且如果模型的通识能⼒不满⾜任务需求
还可以借⽤更强的云端超脑的互联⽹能⼒
小脑则负责结合各种传感器的信息进行运动指令⽣成
就跟⼈类⼀样
⼤家⾛路的时候并不会想着怎么精确地控制每块肌⾁收缩
而是由⼤脑发出⼀个宏观指令后
由⼩脑完成身体的平衡和各种运动学动⼒学的控制
运控算法都跑在这一层
最后呢在硬件底层
由脑干来进行精确的伺服闭环控制
每个电机高效精准的执行
在EI-Brain的设计上
上层大模型
聚焦于具体的感知决策和计划生成
不用依赖于具体的机器人载体硬件
而下层的视控模型和运控算法
聚焦于底层的具体场景的特定动作执行
不用决策整个任务是如何完成的
超脑大脑与小脑脑干能够相互的解耦
不用相互依赖
实现了具身智能系统的层次划分
远征A1设计时候呢
考虑了两个非常重要的指标
分别是任务泛化率和任务执行成功率
任务泛化率呢
指的是对没有见过的任务的泛化能力
是否能够按照之前生成的指令计划
进行精准的执行
这个指标主要是针对于上层的云端超脑和大脑来说的
大模型是否能够对用户各种新的任务和新的3D环境
进行精准的感知决策和指令计划生成
任务执行成功率呢
指的是机器人载体在实际的物理环境当中
执行具体任务的成功率
这个指标呢主要是针对于下层的小脑和脑干来说的
视控模型和运控算法是否能够按照上述生成的指令计划
进行精准的执行
在技能级模型层面
智元机器人定义了一系列的元操作库
也叫做Meta-Skill
在元操作库范围限定的这些有限泛化的场景内
机器人能够自主推理决策出
端到端完成任务所需要的动作编排
而且随着元操作库列表的不断扩充
机器人能够胜任的任务空间
也将呈指数级的增长
在交互中学习进化
最终实现全场景的覆盖
远征A1的本体形态与人类相似
身高一米75
重量55公斤
最高步速呢可以达到每小时7公里
全身49个自由度
整机承重80公斤
单臂最大负载5公斤
全身搭载了包括谐波⼀体关节
⾏星伺服
直线驱动器
空心杯电机等等在内的49个各种类型的执行器
也就是说它拥有49个自由度
在硬件层面
智元自研了关节电机Powerflow
灵巧手SkillHand
反屈膝设计等等关键的零部件
在软件层面智源自研了AgiROS
这是一套机器人运行时的中间件系统
能够实现自主的任务编排
常识推理以及规划执行等等
说实话
大飞我对稚晖君还是挺看好的
综合能力全面
动手能力超强
而且半年时间内呢
能做出来一个机器人的实体
确实速度很快
但是这一次并不是说像之前在B站做个视频
大家热闹一下就行了的
稚晖君呢还需要向大家证明的是
商业方向技术突破
量产能力应用落地等等多方面的结果
对他来说呢应该还是有不小的挑战
尤其是双足机械人这个领域呢
其实非常垂直也非常前沿
并没有太多的开源方案能够借鉴
每家的设计理念呢会直接决定
后续的技术方案和量产能力
可行和可用这两个词之间呢
可能会是天差地别
尤其是各个零部件的精度和配合
还非常考验设计者和背后整个工业供应链的能力
因此呢在这个层面上
真正的源源不断的创新才是关键
所以我也希望能够继续看到他们的创新和突破
我们也会关注最新的进展
第一时间跟大家报道
好了本期的视频内容就到这里
感谢大家的观看
我们下期再见
