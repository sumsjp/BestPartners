大家好，这里是最佳拍档，我是大飞
我们都知道，在视觉CV领域
李飞飞等人创建的ImageNet被奉为检验模型视觉能力的试金石
那么在大模型时代
我们又该如何来评估大语言模型的性能呢？
现在
我们比较熟悉的有像 MMLU、GSM8K等一些评估基准
也不断有模型在它们上面刷新得分
但是这些评估基准真的完美吗？
OpenAI科学家、同时也是思维链的提出者
Jason Wei
在他最新的一篇博客中进行了深入的研究
在博客中
Jason Wei首先列举了几种成功的评估基准
然后总结了评估基准不成功的常见原因
一共七条
包括样本数量少、评估基准太复杂等等
他把这些形容是评估基准的七宗罪
进一步
Jason Wei认为有些评估工具命名方式并不完美
比如HumanEval，虽然叫做人类评估
实际上并没有用到人类进行评估
只是因为问题是由人类创建的
除此之外
文中还提到了一些针对特定领域的小众评估工具
只不过在它们的领域之外
这些评估可能不会引起大家的任何关注
而对于大家关心的测试集污染问题
Jason Wei也给出了一些解决方案
接下来
就让我们看看Jason Wei到底都说了什么内容
首先
Jason Wei对于如何评估基准的成功
给出了一个自己的定义
那就是如果一个评估基准被用在某篇突破性的论文中
并在得到了社区的信任
那么应该说，它就是成功的
按照这个标准，在过去五年中
有这样一些评估基准可以说是成功的
首先比方说，GLUE/SuperGLUE
这两个基准测试主要是用来评估模型在理解自然语言的能力
包含了多种任务
比如文本分类、推理、问答和情感分析
GLUE是在2018年推出
SuperGLUE是在2019年推出，难度更高
包括多句理解和阅读理解等任务
它们在大语言模型出现之前
基本上所有的NLP论文
包括像BERT、T5等等
都在使用这两个评估基准
其次是MMLU，大规模多任务语言理解
通过零样本和少样本设置来评估模型
涵盖了初等数学、美国历史、计算机科学、法律等57个学科
难度从高中水平到专家水平
既考验世界知识
也考验解决问题的能力
这个评估基准几乎目前所有的大语言模型论文都会使用
而且也是DeepMind和Google最喜欢的评估基准之一
第三是GSM8K，小学数学8K
这是一个包含了8.5K高质量英文小学数学的数据集
其中7.5K是训练数据，1K是测试数据
主要是测试模型对于需要多步骤推理的基本数学问题的解答能力
几乎每一篇与思维链（chain-of-thought）有关的论文都会引用它
第四个是MATH
这是一个由数学竞赛问题组成的评估基准
由ACM 10、ACM 12和AIME等组成
包括了7.5K训练数据和5K的测试数据
也是大多数大语言模型的论文都会用到
第五个是HumanEval
这个是由OpenAI发布的164个手写的编程问题
包括模型语言理解、推理、算法和简单数学等任务
也是大语言模型编程方面的经典评估基准
当然，除了这几个之外
还有一些好的评估基准
比如HellaSwing，SQuAD等等
对这些评估基准是否成功的判断标准
往往是会有一篇大论文
声称在评估基准上取得了一些突破
比如，GLUE是由BERT推广的
MMLU是由Gopher、Chinchilla和Flan-PaLM推广的
而思维链提示（chain-of-thought prompting）声称在GSM8K上取得了突破
Minerva的超凡能力在MATH上得到体现
Codex等模型使用了HumanEval
更深入一点地说
想要在评估基准上得到好的分数
必须意味着实现一些重要、而且易于理解的事情
比方说超越了人类的表现、解决了小学水平的数学问题等等
不过
搞砸一次评估比做好一次评估更加容易
而大多数不成功的评估基准
都至少犯了以下七个错误之一
第一点，如果评估没有足够的样本
那么对于研究人员来说
它将会产生很多的噪音
而且用户界面会很糟糕
比方说
有人可能会在模型训练过程中运行评估
并切发现它在各个检查点之间波动很大
这对于研究人员来说非常痛苦
因此他们就不会喜欢用这个评估基准来评估模型
一个好的评估基准
最好应该有至少1000个样本来供评估使用
如果是多项选择评估
那么可能需要的会更多
举个例子来说
尽管GPQA是一个很好的评估基准
但是由于它会根据提示语而产生波动
所以导致它难以使用
第二点、评估基准应该是高质量的
如果评估基准中有很多错误
人们就不会愿意选择相信它
比如Jason Wei曾经长期使用过的Natural Questions（NQ）基准
在GPT-4出来之后
如果GPT-4都在测试样本上失败
那更有可能是因为基准提供的基本事实答案是错误的
所以他后来就停止使用NQ了
第三点，如果评估基准过于复杂
人们就会很难理解它
并且也会很少去使用它
比方说
HELM基准的第一个版本是一项巨大的努力
但是它提供了太多的指标和子集
导致很难理解和使用
所以说
拥有单一的数字指标是至关重要的
更何况任何一个伟大的评估基准
都是有单一数字指标的
第四点
如果评估基准需要太多的工作才能运行
即使这个基准的其他一切都很好
它也不会有很大的吸引力
比方说
BIG-Bench是Jason Wei最喜欢的评估基准之一
但是运行起来非常痛苦
它既有对数概率评估，也有生成评估
这就需要不同的基础设施
而且它的子集太多
甚至有些子集的样本也太多
所以运行一次评估要花很长的时间
Jason Wei相信
这就是为什么BIG-Bench虽然提供了很多的优势
但是依然没有获得太多关注的原因
第五点
如果评估不是针对于某项有意义的任务
那么人工智能的研究员就不会很密切地关注到它
比方说
在BIG-Bench Hard这个评估基准中
有一些推荐电影或者正确关闭括号的任务
虽然这些任务很有挑战性
并且模型越大
评估效果越好
但是在这些任务上做得好
并不能对模型的智能程度
给出实质性的结论
通常会去衡量对于智能来说至关重要的事物
比如语言理解、考试问题或者数学等等
第六点
评估基准给出的评分应该非常正确
如果有人认为评估基准对模型给出的评分不正确
或者不认可该评分
那么他们可以立即取消使用这个评估基准
我们应当花时间来尽量减少由于解析而导致的错误
或者尽可能去获得最好的自动评分器提示
第七点
为了让评估基准能够经得起时间的考验
它的性能还不能太快出现饱和
例如
GLUE/SuperGLUE就是因为饱和的太快
所以很难显示出巨大的增益效果
于是渐渐地人们就不再使用它们
而且
大语言模型在总结和翻译等任务上的表现
也比我们为它们开发出一个良好的评估基准的速度更快
所以就没必要再去测试这些基准中的任务了
以上就是Jason Wei指出的
很多模型评估基准中存在的问题
除此之外
他还提出了很多其他的观点
首先
有很多看起来很优秀的评估工具
却都取了些糟糕的名字
比方说，GSM8K其实并不需要加上8K
而HumanEval虽然叫做人类评估
但是实际上并没有用到人类进行评估
而之所以叫这个名字
是因为这些问题是由人类创建的
所以有明显的误导性
而MATH这个名字叫的太普通了
所以人们开始称之为亨德里克斯数学「Hendrycks-math」，
用创建者的名字来命名
这显然是一个更加聪明的命名方式
那如果你自己创建了一个评估基准
想要把它推广开来
有什么办法呢？
Jason Wei也给了几个建议
首先要做的是帮助人们来使用这个基准
比方说
帮助他人在模型上运行这个评估基准
如果模型在这个评估上表现良好
那么人们通常会喜欢它并且进一步的推广它
像HELM基准就非常擅长为其他人来评估模型
并且公布结果
其次，如果你能为人们使用评估基准
创造一些激励机制，也会很有帮助
对于员工来说
最好的激励之一就是他们领导所重视的东西
因此
获得实验室或者公司内部领导的支持
对于评估基准的推广可能会有所帮助
他们会要求手下的员工都来运行它
Jason Wei举了自己在谷歌创建MGSM的例子
当时他选择与Google Deepmind 的研究主管迪潘詹·达斯Dipanjan Das合作来完成
由于迪潘詹很喜欢这个工具
所以在他的团队中获得了一些人的支持和使用
在文章的结尾部分
Jason Wei还列举了一些评估基准发展所面临的挑战
比如说，大语言模型的出现
对评估工具提出了更高的要求
目前还没有一个单独的评估基准能够充分的评估大语言模型
都还是在使用一些非常简单的评分方式
比如多项选择、数字检查
或者执行单元测试
而且即便这些方法也存在问题
另外就是有些人在尝试对模型进行成对评估
比如LMSYS
但是这种评估方式是一把双刃剑
它们之所以强大
是因为你可以通过一组简单的提示
得到一个单一的数字指标来衡量一个大语言模型的好坏
并且可以通过大量的样本
来平均掉样本级别的噪声
不过
成对评估的危险之处在于你并不完全确定在测量什么
比如相对于正确性
感觉和风格等因素的权重影响有多大
还有就是评估基准的主题会很大程度影响到人们对它的关注
有一些基准是非常高质量的特定领域评估
比方说法律、医疗等，这种情况下
最重要的是根据该领域的专家所重视的内容来定制评估
比如Jason Wei曾经制作过一个组织病理学的图像基准
不出所料
它在医学图像分析领域之外
几乎没有引起任何关注
只获得了40次引用
评估基准要面临的另外一个挑战就是测试集污染
一个好的评估基准被创建之后
评估样本往往会传播到互联网的各个地方
比如arxiv、ChatGPT或者reddit
常见的解决办法是对测试集进行「隐藏」，
但是这种方法也会引起很多分歧
斯坦福大学教授Chris Manning提出了一个很好的建议
就是对公开测试集、私有测试集都进行评估
并且监控模型在这两个测试集上是否有大的偏差
这种方法可以平衡公开测试集上测试的低摩擦性
以及私有测试集的高可信度
最后
Jason Wei倡导AI社区应该更多地投资评估基准
尽管这可能不会像开发模型那样
得到很多的回报，但是归根结底
好的评估基准才是AI研究人员对于模型的客观评价指标
并且是对AI领域产生重大影响的一种方式
好了
以上就是Jason Wei这篇文章的主要内容
对大模型评估基准的现状和发展
都给出了很多自己的思考和看法
在AI领域
这块也是经常容易被人忽视的一部分
大家天天都在说自己的模型怎么怎么好
但是其实如何客观的评价才是最重要的
否则就都变成王婆卖瓜自卖自夸了
欢迎大家在评论区发表自己的看法
感谢观看本期视频
我们下期再见
