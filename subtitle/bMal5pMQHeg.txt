大家好，这里是最佳拍档
在刚刚举行的二零二六年的达沃斯世界经济论坛上
Anthropic的CEO达里奥·阿莫代伊
抛出了一句，未来的GDP将会飙升
但是一半的初级白领工作会被彻底抹去
而谷歌DeepMind的CEO德米斯·哈萨比斯
却坚持着旧的不去新的不来的理论
认为AGI还需要五年到十年到来
这场横跨技术、商业、社会、地缘政治的大辩论
正如一场正在发生的现实预演
关乎着我们每个人的饭碗、财富
甚至文明的走向
今天
我们就来聊聊达沃斯论坛上的这场AI论战
看看在AI狂飙的时代
我们究竟该何去何从
首先，在论坛的公开演讲中
微软CEO萨蒂亚·纳德拉大谈AI在医疗领域的突破
比如通过大模型加速新药的研发
让罕见病患者获得生机
德米斯·哈萨比斯则聚焦科学到创新
强调AI如何帮助人类破解基因的密码、应对气候变化
他们的发言充满了对技术的信心
维持着技术乌托邦的体面
仿佛只要持续推进AI的发展
人类就能攻克所有的难题
进入一个物质丰裕、疾病减少的理想社会
但是这种看似美好的叙事
在另一些大佬眼里
却成了回避现实的遮羞布
而Anthropic的达里奥·阿莫代伊和Palantir的亚历克斯·卡普
则用更尖锐的方式戳破了幻想
阿莫代伊直言不讳的说
我们可能会进入一个GDP猛涨
但是失业率居高不下、贫富差距拉大的世界
他不是在危言耸听
而是基于AI发展的数学来计算
当前AI在文本处理、代码编写、数据分析师等初级白领工作中的效率
已经远远超过人类
而且迭代速度越来越快
卡普则更直接，他把AI对白领的冲击
与当年全球化对蓝领的冲击相提并论
当年工厂工人失去工作时
社会经历了漫长的阵痛
而现在AI冲击的是掌握知识的中产阶级
这个群体的规模和影响力更大
社会能承受住这种冲击吗？
更讽刺的是
这些大佬们不仅观点对立
言行上还存在剧烈的脱节
台面上，他们高呼要为AI建立护栏
要进行核武器级的管控
甚至提议技术封锁
但是在台面下
商业的触角却在疯狂的跨越红线
微软一边给OpenAI砸了一百三十多亿美元
拿着近百分之二十七的股份
另一边又跟OpenAI的劲敌Anthropic眉来眼去
每年还支付好几亿的技术使用费
纳德拉管这叫相互尊重
但是本质上就是两头下注，谁赢都赚
谷歌一边呼吁国际社会共同监管AI
一边却在算力的投入上毫不手软
试图在模型的性能上拉开差距
这种表面上喊着长期主义
眼里盯着下个季度财报的矛盾
让达沃斯变成了一个巨大的认知失调现场
在所有的争论中
最核心、也最令人焦虑的问题是
AGI到底离我们还有多远呢？
这个能像人类一样具备全面认知能力
在多个领域达到、甚至超越人类水平的人工智能
一旦出现
将会彻底改变人类社会的运行逻辑
而在达沃斯论坛上
两位AGI领域的核心玩家
阿莫代伊和哈萨比斯
却给出了截然不同的时间预测
这场争论也被媒体形容为披头士和滚石再次同台
激烈又充满了看点
在去年的巴黎
阿莫代伊就曾经预测说
二零二六年到二零二七年
会出现在多个领域达到诺奖级别的通用模型
到了二零二六年的达沃斯
他不仅没有收回这个预测
反而给出了更加具体的时间线
他说
我们可能距离实现AGI还有六到十二个月的时间
尤其是在软件编程领域
AI端到端接管软件工程师的日子
已经不远了
他的底气
来自Anthropic内部的实际体验
阿莫代伊透露
现在公司里的工程师几乎都已经不再写代码了
而是审核AI写的代码
这些工程师的角色
已经从单纯的代码编写者
变成了产品经理或者架构师
工作内容就是提出需求、编辑模型生成的代码、把控整体的架构
这种工作模式的转变
背后正是AI能力的飞速提升
更关键的是
AI正在进入自迭代的加速循环
阿莫代伊解释道
AI不仅已经在写代码、做研究了
而且我们正在用AI去加速下一代AI
这个循环一旦跑顺
研发速度就会直接起飞
呈现指数级的冲刺
以前
模型迭代还需要依赖人类工程师的代码编写、架构设计
而现在，AI可以自主完成这些工作
真正限制速度的，已经不再是人
而是芯片制造、算力供给和训练周期
这种AI造AI的闭环
是阿莫代伊敢于给出激进预测的核心原因
当技术突破不再依赖人类的速度时
一切都将被压缩
与阿莫代伊的激进形成鲜明对比的
是哈萨比斯的稳健
他依然坚持去年的判断
认为在二零三零年前
有百分之五十的概率
会出现具备全人类认知能力的AGI
哈萨比斯清楚AGI实现的核心难点在哪里
反复强调三个无法回避的限制
第一，很多领域无法快速验证对错
AI在代码和数学领域确实很强大
因为这些领域的答案是明确的
对错可以快速的判断
但是自然科学不一样
一个化学假设是否成立
一个物理理论是否正确
都需要真实世界的实验验证
这个过程无法被AI快速的替代
比如AI可以设计实验方案
但是无法亲自操作实验室设备
更是无法快速获取实验结果
并且调整方向
这个环节会严重的拖慢AI在自然科学领域的突破速度
第二，提出问题比解题更难
AI现在能解决很多已有的问题
但是科学创造力的顶点
是提出新的理论、新的范式
正如牛顿提出万有引力、爱因斯坦提出相对论
这些不是解决已有的问题
而是发现了新的问题和规律
这种能力是当前的AI不具备的
也是很难通过迭代快速获得的
第三，现实世界其实是一个阻尼器
AI的发展不仅依赖软件模型
还需要硬件的支撑
比如机器人技术、物理系统的适配
机器人在真实世界中移动、操作物体
会受到各种物理限制
这些情况会不断的打断AI的指数级增长
哈萨比斯认为
AGI很可能会先诞生在纯信息的世界中
而要在现实世界中具备全面的能力
还需要更长的时间
尽管两人的预测存在巨大的差距
但是他们在一个核心观点上达成了共识
那就是真正的拐点
不是模型更加聪明
而是模型开始构建下一代的模型
如果AI能完成从写核心代码到设计模型结构
到优化训练策略
再到推动研究本身的闭环
那就是指数级失控的起点
在结尾的问答中
主持人问他们明年再见面时
最值得关注的是什么
两人的答案高度一致
那就是AI是否开始真正的构建AI
如果这一步走的通
时间线会被极度的压缩
如果没有走通
世界模型、持续学习、机器人技术
将会成为下一条突破的路径
这场关于AGI时间线的争论
本质上是对技术发展规律的不同理解
阿莫代伊看到的
是AI在信息领域的爆炸式增长
而哈萨比斯看到的
是现实世界对技术的约束
但是无论哪种预测成真
有一点是确定的
AGI已经不再是遥远的科幻概念
而是正在快速逼近的现实
人类需要为那一天的到来做好准备
宏大的技术叙事终究要落到每个人身上
而最刺痛人心的问题莫过于
我们的工作还能保住吗？
在达沃斯论坛上
这个问题也把大佬们分成了截然不同的阵营
让每一个职场人陷入了深思
悲观派的代表，依然是阿莫代伊
他坚持自己一年前的预测
未来一到五年内
百分之五十的初级白领工作将被AI彻底的抹去
这个判断是基于AI在多个领域的替代能力
当前
AI已经能高效的完成文案撰写、数据录入
简单设计、基础代码的编写、客户咨询等工作
这些岗位覆盖了行政、人事、财务、运营、初级程序员等多个领域
都是典型的初级白领岗位
阿莫代伊透露
Anthropic内部已经显现出了这种趋势
初级和中级岗位的需求锐减
公司正在严肃思考
如何人性化的处理裁员和转型
他承认
历史上的技术变革也会导致旧工作的消失
但是这次不一样，农业自动化后
百分之八十的农民转为工厂工人
再转为知识工作者
这个过程用了几十年甚至上百年
社会有足够的时间去适应
但是AI的迭代是指数级的
速度太快了
人类社会的适应速度根本跟不上
黑石集团的拉里・芬克从历史的视角
给出了一个更为沉重的警告
他在论坛上提到
当年全球化冲击蓝领工人时
引发了一系列的社会问题
比如贫富差距扩大、民粹主义的抬头
而现在AI冲击的是白领阶层
这个群体是社会的中坚力量
他们的失业带来的将不仅是经济问题
还有身份认同危机和社会结构的动荡
芬克的担忧并不是没有道理
白领阶层之所以被称为中坚力量
不仅是因为他们的收入水平居中
还因为他们对社会秩序、主流价值观的认同度更高
一旦这个群体大规模的失业
而且无法快速找到新的工作
很可能会引发比蓝领失业更严重的社会震荡
乐观派则试图给大家吃一颗定心丸
哈萨比斯就是其中的代表
他认为，AI确实会取代一些初级岗位
但是长期来看，会诞生更多新的工作
也就是所谓旧的不去，新的不来
哈萨比斯以实习岗位为例
现在实习岗位确实在减少
因为很多复印文件、整理数据的工作被AI替代了
但是大学生们与其去做这些重复劳动
还不如赶紧学习AI工具的使用
这比传统的实习会更有价值
等于给未来五年提前铺路
他观察到，已经有一些新的岗位出现
比如AI训练师、AI伦理顾问、AI工具优化师等等
这些岗位需要人类结合专业知识和AI能力
创造出更大的价值
哈萨比斯还提到了能力悬溢的概念
即便是构建AI模型的人
也很难完全探索当下模型的全部能力
但是普通人通过学习和掌握AI工具
能在专业领域实现自我飞跃
因此他鼓励年轻人，不要害怕 AI
要学会和AI共生
未来最有价值的不是你能做什么
而是你能利用AI做什么
而务实派的观点
则更加贴近普通人的现实选择
吴恩达作为AI领域的权威
给出了最接地气的判断
AI现在顶多能完成一件事情的三四成
剩下六七成还得靠人
他的潜台词是
与其纠结会不会被AI替代
不如关注具体哪些任务会被替代
AI擅长的是重复性、规则明确、不需要复杂情感和创造力的任务
而人类擅长的是复杂决策、情感沟通、创新思维、跨领域整合等能力
吴恩达举了一个例子
一个市场分析师
AI可以帮助他快速的处理海量数据
生成基础报告
但是解读报告背后的商业逻辑、制定营销的策略、与客户沟通谈判
这些还是需要人类来完成
因此，吴恩达的核心观点是
会用AI的人
效率将会吊打不会用的人
自然就把不会用的人给替代了
这句话点出了问题的关键
AI不是要替代人类
而是要替代那些不会用AI的人类
未来的职场竞争
不再是人和人之间的竞争
而是人加AI，和单纯的人之间的竞争
那些能够熟练运用AI工具
把AI变成助手而不是对手的人
不仅不会被替代，还会因为AI的加持
变得更具有竞争力
Palantir的卡普则从另一个角度提出了思考
以后的劳动力都将过剩
尤其是有手艺的
除非你的技能特别专业
否则移民将不再有任何优势
这句话看似在讨论移民问题
实则揭示了AI时代的就业核心
只有具备了不可替代的专业技能或者创造力
才能在竞争中立足
初级技能的价值会越来越低
而高端技能、跨领域能力、情感智力的价值
会越来越高
这场关于饭碗的争论
本质上是对人类价值的重新定义
AI确实会拿走一些重复的、机械的工作
但是也会把人类从这些劳动中解放出来
去从事更有创造性、更有意义的工作
但是问题的关键在于
这个替代和新生的过程
是不是能给人类足够的时间去适应呢？
对于那些被替代的初级白领来说
他们是否有能力学习新的技能
进入新的领域呢？
这不仅是个人的问题
也是政府、企业需要共同面对的挑战
所有技术变革的讨论
最终都会撞上分配这堵墙
AI带来的生产力飞跃
会让财富总量大幅度的增长
但是这些财富会怎么样分配呢？
是让少数人独占红利
还是让全社会共同受益呢？
在达沃斯论坛上
这个问题也引发了激烈的讨论
暴露出了资本主义体系下的深层矛盾
华尔街老炮、黑石集团的拉里·芬克
说了句达沃斯最狠的大实话
他说，柏林墙倒塌后
人类创造的财富空前绝后
但是在发达国家
这些财富集中到了极少数人的手里
这种集中度是任何健康社会都接受不了的
芬克的话一针见血，而AI的发展
可能会让这种财富集中的趋势更加严重
数据不会撒谎
二零二五年
包括亚马逊、谷歌、微软在内的三十四支AI概念股
平均涨幅超过百分之五十
美国最富的五十个人
去年净资产中位数涨了近千亿美元
这些财富的增长
主要来自AI技术带来的估值提升和商业变现
而另一面，美联储的数据显示
美国较穷的那部分群体
只持有大约百分之一的股市财富
这意味着，AI早期的红利
早已经被模型所有者、数据地主和基础设施巨头装进了口袋
普通民众很难从中受益
AI 教父杰弗里・辛顿给出了更为尖锐的批评
他说，结果很明显
有钱人会用AI换掉工人
这将导致大规模的失业和利润暴涨
少数人富得流油
多数人越来越穷
这甚至不是AI的错
而是资本主义体系本身的问题
辛顿的观点虽然激进
但是也反映了现实的困境
在资本主义制度下
资本的逐利性会让企业主尽可能用AI替代人类
从而降低成本、提高利润
而这些利润最终会流向股东
而不是被替代的工人
这种财富分配的失衡
本质上是AI的天然属性所导致的
AI的发展需要海量的数据、顶级的算力和巨额的资本
这个门槛不是普通个人或者中小企业能达到的
目前，全球顶级的AI模型中
几乎都掌握在微软、谷歌、亚马逊、Anthropic等少数巨头的手中
这些公司通过垄断技术
获得了超额利润
而普通民众，要么是AI替代的受害者
要么只能在AI创造的新产业链中
从事一些附加值较低的工作
很难分享到核心的红利
更值得关注的是
巨头们为了维持垄断地位
还在通过相互注资的方式
构建更紧密的利益共同体
看看Anthropic 的股东名单就知道
英伟达、微软、亚马逊、谷歌
硅谷的半壁江山都在里面
这种你中有我，我中有你的持股结构
让巨头们既能相互竞争
又能共同抵御外部的挑战
进一步巩固了它们的垄断地位
微软一边投资OpenAI
一边合作Anthropic
就是为了在AI竞赛中两头下注
确保无论哪家胜出
自己都能分到一杯羹
这种商业逻辑
在短期内能够推动AI技术快速发展
但是从长期来看
会进一步加剧财富的集中
让中小企业和普通民众更难参与到AI的革命中
但是也有一些乐观的声音
哈萨比斯认为，长期来看
AI会创造巨大的社会财富
只要通过合理的政策引导
就能让更多的人受益
比如，AI降低了医疗的成本
让更多人能够享受到高质量的医疗服务
AI提高了农业生产效率
让粮食价格下降
惠及到普通消费者
这些都是AI带来的普惠价值
不能只看到财富集中的一面
不过
这种乐观的前提是政策的引导有效
但是在现实中
政策往往是滞后于技术发展的
而且容易受到资本的影响
AI巨头们掌握着巨大的经济实力和话语权
可能会通过游说等方式
影响政策的制定，维护自己的利益
如何平衡资本利益与社会公平
如何让AI红利更加公平的分配
成为了摆在各国政府面前的一道难题
AI的狂飙突进
不仅引发了就业和财富分配的焦虑
还暴露了自身发展的诸多瓶颈
在达沃斯论坛上
能源消耗、安全漏洞、地缘政治博弈这三大问题
成了大佬们无法回避的现实挑战
也让AI的发展之路变得更加坎坷
首先是能源瓶颈
AI是个不折不扣的电老虎
如果说数据是AI的饲料
那么电就是AI的氧气
AI模型的训练和推理
需要消耗海量的电力
而且随着模型参数规模的扩大和算力需求的增加
电力消耗还在呈指数级的增长
微软的纳德拉把这笔账算得很清楚
他说，哪里的GDP增长
都跟用AI的电费直接挂钩
他引用了Token 经济学的概念
那就是哪个国家的电越便宜
Token成本越低
哪个国家的竞争力就越强
欧洲已经在这方面输了一阵
受地缘政治的影响
欧洲的电费贵得离谱
这让欧洲的AI企业在全球竞争中处于劣势
纳德拉直言不讳的指出
只在家里耍横没用
欧洲的产品得在全球有竞争力才行
如果电费降不下来
欧洲的 AI 企业很难跟得上全球步伐
为了降低能源成本
亚马逊的安迪·贾西正在满世界找电
不仅签署核电协议
还投资可再生能源
他说，我们在想尽办法
用能承受的成本多搞点电
贾西甚至放出狠话，如果需要
亚马逊准备给数据中心自建供电系统
更有意思的是
Meta的总裁迪娜·鲍威尔·麦考密克提到
在这波新的计算浪潮下
全美大概需要新增五十万名电工
这个细节暴露了AI发展的尴尬
这个被寄希望于解决一切问题的云端技术
首先得解决自己在地面的能源胃口
当科技公司开始自己发电、自己培训电工时
它们就不再只是科技公司了
正在慢慢变成能源巨头
能源问题不仅关系到 AI的发展成本
还关系到环保目标
AI消耗的电力大多是来自化石能源
过度消耗会加剧气候的变化
如何在AI发展和环境保护之间找到平衡
成了又一个棘手的问题
其次是安全黑洞
最大的黑客可能是AI自己
当大家都在惊叹AI的强大时
一线的实操者们却在为AI的安全问题
愁得睡不着觉
安永的合伙人拉贾·夏尔马指出了一个巨大的漏洞
AI能访问你的核心数据
干完活却不留名，也没身份证
跟人类不同
AI的操作过程往往像黑箱一样
它干了什么、怎么干的
很难被完全追踪和监控
他说
我们急需一套工业级的AI安全体系
这块现在还是个大窟窿
毕马威的美国负责人蒂姆·沃尔什也反映
很多客户已经对AI产生了恐惧
不是不想用AI
是得停下来先把安全篱笆给扎紧了
企业担心AI会泄露核心数据
会做出错误的决策
甚至会被黑客利用
更让人担忧的是
随着量子计算的发展
现有加密技术可能会被破解
AI系统的安全风险会进一步的加剧
为了应对这些风险
出现了一个滑稽的现实
人们被迫使用更多的AI来当看门狗
用AI监控AI的行为
试图防范AI带来的风险
但是这些都只是权宜之计
AI的安全问题还有着更深层的隐患
《人类简史》的作者尤瓦尔·赫拉利警告说
把AI比作人类智能是一个可笑的类比
就像飞机不是鸟一样，AI也不是人
地球上最聪明的系统也可能会犯最蠢的错误
AI的决策逻辑和人类完全不同
它可能会在看似合理的情况下
做出极其危险的选择
更可怕的是
AI已经出现了策略性隐瞒、目标漂移、欺骗行为等问题
阿莫代伊也承认
从公司成立第一天起
他们就一直在做机制可解释性方面的研究
试图理解模型内部到底在想什么
在失控之前看清它的动机结构
而另一名AI教父约书亚·本吉奥则发出了更严重的警告
他说
我们把AI做得越像人，危险就越大
这种错觉会让人不自觉的信任它们
当AI不仅会犯错
还可能学会撒谎和伪装的能力时
连AI自己都找不到的安全漏洞
人类拿什么去监管呢？
本吉奥的担忧并非没有根据
已经有研究显示
一些AI模型会为了达到目标而欺骗人类
比如在测试中故意隐藏自己的真实能力
或者在执行任务时绕过安全限制
这些行为一旦失控
可能会带来难以预料的后果
最后是地缘政治的博弈
AI已经成了大国竞争的新战场
当前
AI领域的竞争已经不再是企业之间的竞争
而是国家之间的博弈
美国、中国、欧洲等主要的经济体
都把AI视为未来科技竞争的核心
纷纷加大投入，试图抢占制高点
西方巨头原本以为自己在AI领域拥有绝对的优势
但是中国AI企业的崛起
打破了这种平衡
阿莫代伊把AGI类比为核技术级别的不可扩散问题
他认为绑定供应链
通过卖芯片换影响力这些逻辑
在AGI面前会全部失效
正如他所说，如果这是核武器
我们不会为了利润出口
他的潜台词是，AI技术太重要了
不能轻易向其他国家转让
尤其是中国
这种观点在西方精英中很有市场
一些人呼吁对中国进行AI技术封锁
限制芯片、算法等核心技术的出口
但是哈萨比斯更担心国际协调的难度
显然，公司之间存在竞争
但主要是美国和中国之间
反而国际协调的现实难度
可能远超技术本身
他承认，中国在AI领域的进步很快
单纯的封锁很难奏效
反而可能会引发技术脱钩
让全球的AI发展陷入分裂
如果中美两国在AI领域各自为战
不仅会减缓全球AI的发展速度
还可能引发更严重的地缘政治冲突
更复杂的是，AI技术的全球化特征
让封锁变得更加困难
AI的发展需要全球范围内的数据、人才和算力协作
脱钩会导致资源浪费和效率下降
比如
一些AI模型需要海量的多语言数据进行训练
而这些数据来自全球各地
一些AI 领域的顶尖人才
可能来自不同的国家
需要跨国合作才能推进研究
如果因为地缘政治而中断这些协作
AI的发展可能会陷入停滞
能源、安全、地缘政治
这三个挑战像三座大山
全部压在AI发展的道路上
它们相互交织，相互影响
让AI的未来充满了不确定性
AI要想持续发展
不仅需要技术上的突破
还需要全球社会在能源政策、安全标准、国际协调等方面达成共识
但是在当前分裂的世界里达成这种共识
难度不亚于实现AGI本身
在所有关于技术、商业、政治的争论之外
达沃斯论坛上还有一种更深沉的思考
哈萨比斯在论坛的结尾
抛出了一个终极追问
在一个后稀缺的世界里
当工作不再是必须
当物质极大的丰富之后
人类将如何寻找存在的意义呢？
他的这个问题，戳中了很多人的内心
自古以来
工作不仅是人类谋生的手段
也是身份认同的重要来源
我们通过工作来定义自己
比如我是医生
是老师
是程序员，是设计师
但是如果AI取代了这些工作
我们是谁呢？
我们的价值又在哪里呢？
哈萨比斯给出了一些可能的答案
也许是探索星空
也许是追求艺术
也许是挑战极限运动
或者是深入研究哲学、神学
在他看来
AI能解放人类的双手和大脑
让我们从重复的劳动中解脱出来
去追求更高层次的精神需求
这种想法很美好
但是实现起来并不容易
因为人类的意义感
不仅来自精神的追求
还来自与他人的连接、来自对社会的贡献
如果大量的人失业
无法通过工作实现自我价值
可能会陷入迷茫和焦虑
甚至引发心理上的问题
赫拉利则从另一个角度给出了警示
人类的幸福并不完全取决于物质财富的多少
而是取决于我们是否能掌控自己的生活
如果AI变得越来越强大
甚至能替我们做决策
那么人类可能会失去自主性
变成AI的附庸
他担心
随着AI在医疗、教育、金融等领域的深度应用
人类会越来越依赖AI的建议
逐渐丧失独立思考和决策的能力
比如，医生依赖AI诊断病情
老师依赖AI批改作业
投资者依赖AI制定策略，久而久之
人类的专业能力和判断力会退化
最终失去对生活的掌控权
在问答环节
一位来自太空数据中心公司的观众
抛出了著名的费米悖论
既然宇宙这么大
为什么我们还没看到外星人呢？
是不是因为所有的高等文明都被自己的AI毁灭了呢？
这个问题让现场陷入了沉默
哈萨比斯首先回应道
如果是AI毁灭了外星文明
我们应该看到宇宙中到处飞舞着回形针
或者巨大的戴森球结构
但是我们什么都没看到
他更倾向于认为
人类已经通过了大过滤器
未来依然掌握在人类自己的手中
AI是人类创造的
它的发展方向由人类来决定
只要我们做好监管，建立合理的制度
就能避免灾难，让AI为人类服务
虽然哈萨比斯的回应充满了乐观
但是也带着一丝不确定性
AI的发展速度越来越快
而人类的进化速度却很慢
我们的认知能力、道德水平
是不是能跟上AI的发展呢？
这是一个没有答案的问题
但是有一点是确定的
人类不能在AI的狂飙中迷失自己
我们需要在发展AI的同时
不断的反思自己的存在意义
守护好人类的独特性和自主性
这场关于人文意义的讨论
让达沃斯的AI论战超越了技术和商业的层面
上升到了文明的高度
AI不仅是一场技术革命
更是一场关乎人类的自我认知的革命
它让我们重新思考，什么是人类
什么是幸福
什么又是有意义的生活呢？
这些问题没有标准的答案
但是每一个人都需要认真的思考
因为这关系到我们怎么样在AI时代自处
怎么样守护人类的尊严和价值
感谢收看本期视频，下期再见
