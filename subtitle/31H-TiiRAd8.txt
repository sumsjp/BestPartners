大家好，这里是最佳拍档，我是大飞
AI界的泰斗级人物Yann LeCun
我们熟悉的杨立昆
刚刚和硅谷科技圈的第一播客Lex Fridman进行了一次3小时的深度对话
大飞我第一时间学习了一下
绝对是新鲜出炉
这里也跟大家一起分享一下巨头最新的思考
这段谈话的核心
是Yann LeCun对人工智能未来发展的深度思考
特别是他对开源AI的潜力和挑战的独到见解
LeCun可谓是AI领域的"常青藤",
他是Meta的首席AI科学家、纽约大学教授、图灵奖得主
更是AI发展史上的开创性人物之一
一直以来
LeCun和他的团队都在大力支持和推动开源AI的发展
他们毫无保留地分享了许多里程碑式的大模型
比如Llama 2和即将推出的最新Llama 3
针对某些人对AGI迫在眉睫的危言耸听
LeCun直言不讳地予以批驳
他坚信AGI终有一天会问世
但那将是人类的福音
而非灾难
在谈到AI的未来时
LeCun抛出了一些令人耳目一新的观点
尤其是针对GPT-4和即将发布的Llama-3等大语言模型的评论
他指出
尽管这些模型在语言处理上非常出色
但是仍然难以被视为"超人智能"的载体
因为它们还不具备理解世界运转规律、把握物理法则、记忆检索信息、持久储存记忆、逻辑推理和行动规划等人类智能的关键要素
LeCun强调,相比语言输入
我们实际上更多地依靠感官输入来认知世界
换言之,我们的知识和认知
很大程度上源自对客观现实的观察和交互
而非单纯的语言学习
LeCun进一步剖析了大语言模型的局限性
在他看来,大语言模型无法像人类那样
进行深度思考和周密规划
它们只是本能地一个接一个地吐露词句
他质疑大语言模型是否真的构建了一个内在的世界模型
以及我们能否仅凭语言预测
来塑造对世界的深刻理解
语言在信息传递上的"带宽"和表现力有限
因此单靠对词语序列的预测
难以建立完善的认知模型
与之相对的,是通过观察世界
领悟事物演变的内在逻辑
LeCun特别以视频预测为例
来佐证他的观点
过去十年
我们苦心孤诣地尝试用视频数据来训练生成模型
但是收效甚微
究其原因
正如我们无法准确预测特定语境中的下一个词一样
我们同样难以穷举视频中所有可能出现的帧
问题的症结在于
我们还不知道如何高效地刻画高维连续空间中的概率分布
作为一种可能的解题思路
LeCun提出采用蕴含潜变量的模型
这类模型能够表征我们尚未感知、亟需补全的各类世界信息
然而
尽管这种途径在像素预测上取得了不俗的效果
但是在实践中却难以奏效
LeCun还探讨了训练系统学习图像表征的难题
我们虽然掌握了一整套技术
但是在面对残缺图像的时候
往往难以高质量地复原
为了突破瓶颈
LeCun提出了一种"联合嵌入"的新方法
这个方法的基本思路是
先用编码器分别处理完整图像和残缺图像
再训练一个预测器
来预测完整图像的表征
在LeCun看来
通过自监督学习掌握抽象表征
是智能系统的重要一环
我们不应该只局限于对底层细节的建模
而应该在多个抽象层次上描述世界万象
与此同时
我们要尽可能多地从输入中榨取信息
但是又要避免提取那些难以预测的冗余
有趣的是
"联合嵌入预测"架构竟然可以学习到一些常识
比如预测"捣蛋"的猫咪会如何激怒主人
这个架构采用了"非对比"技术
涵盖基于蒸馏的BYOL(DeepMind)、FAIR、iJEPA和DINO等方法
它们的共同点是
先将原始输入(比如图像)编码为特征表征
再对输入施加扰动
然后训练一个预测器来拟合原始输入的表征
LeCun认为
大语言模型在处理高阶概念和规划任务上大有可为
但是在应对底层操作和细节把控时则力不从心
为此,我们需要借助JPEA这样的工具
在不失真的前提下提升表征的抽象层次
尽管AI和大语言模型在语言应用上初露锋芒
但是它们还不具备人类智能的全部特质
举例来说
它们难以理解和模拟人类的共同经历
以及那些低阶的物理知识
此外
大语言模型在推理能力上也有先天不足
因为它们的计算开销与输出词元的数量成正比
而与问题本身的复杂性无关
LeCun给未来的AI系统设计指明了一个新的方向
与其过度依赖于自回归预测
不如在完善的世界模型基础上
开展推理和规划
他坚信
这个范式更接近人类的思维方式
面对错综复杂的问题时
我们会投入更多认知资源
展开深入思考和缜密规划
这段对话还探讨了基于能量的模型
在互联网领域的应用前景
特别是在对话系统和语言模型中的潜力
这类模型可以度量某个回答对于特定问题的契合度
进而通过在可能解空间中寻优
最终输出最佳答案
这个过程需要以语言模型为基座
在抽象表征空间中开展运算
与其穷举候选答案再选择最优
不如直接在连续空间上应用梯度下降
快速收敛至最优解
这种优化驱动的方法已在视觉领域崭露头角
通过对良好输入的表征进行预测
再基于预测误差
也就是系统能量来迭代优化
强化学习
尤其在更新世界模型和目标函数的时候
也是一个不可或缺的利器
LeCun还评论了基于人类反馈的强化学习(RLHF)的有效性
这个范式会先训练一个质量评估器
再通过反向传播调整系统参数
让它只输出高分答案
针对外界对谷歌Gemini 1.5的种种诟病
尤其是它生成不实或者敏感的图像、对部分话题避而不谈的毛病
LeCun旗帜鲜明地指出
开源才是破解偏见和审查困局的金钥匙
在他看来
一个零偏见的AI系统只能存在于理想国
因为偏见本身就是主观的
中国有句成语，所谓见仁见智
与其另起炉灶
不如拥抱百花齐放的AI生态
未来,AI助手将无处不在
成为人机交互的"中间人"。
LeCun由此出发
畅想了一个多元化的AI未来图景
与其让屈指可数的科技巨头垄断人类的知识宝库
不如让顶尖系统开放源代码
供所有人使用和微调
他以与法国政府、印度Infosys公司创始人、非洲初创企业Kera的合作为例
阐释了他推动AI多样性的不懈努力
谈到开源模型的商业前景
LeCun认为大可不必过于悲观
如果这些模型物有所值,即便免费供应
公司也能从广告和企业服务中获利
他坦言,科技巨头如今困局重重
内有不满的员工、狂躁的高管、内讧的董事会
外有压力团体、极端主义监管机构、政府机构、媒体舆论的接连炮轰
种种乱象无不都在消解组织的战斗力
归根结底,LeCun笃信
开源和多元是祛除AI系统偏见和审查弊病的两剂良方
只要在系统中设置合理的"护栏",
我们就能让AI助手更安全、更纯净
即便在仇恨言论和危险言论这样的灰色地带
适度的微调也许可以作为一个不错的权宜之计
值得欣慰的是,尽管有学者对AI系统
尤其是大语言模型的社会影响表示担忧
但是有理有据的证据还不多见
比如,迄今为止
还没有确凿的案例表明
大语言模型会怂恿用户制造生化武器
要知道
炮制这类武器需要实打实的专业知识
而这恰恰是大语言模型的知识盲区
展望未来
LeCun对即将发布的Llama 3和后续版本充满期待
作为真正意义上的开源AI系统
它们有望在感知、记忆、规划、推理等方面不断突破
最终迈向人类水平的通用智能
当然
实现这一宏伟蓝图需要软硬件的协同进化
对于AI可能带来的灾难性后果
LeCun并不十分认同
在他看来
AI系统不大可能成为一个威胁人类的物种
因为它们没有争夺主导权的野心
不过,AI武器化的风险却是实实在在的
因为它们能左右人心,控制民意
随着AI助手不可逆转地介入人机交互的方方面面
这种威胁只会与日俱增
此外
LeCun还从社会学的视角解读了新技术的冲击波
面对颠覆性的文化运动或技术革命
人们往往会产生一种本能的恐惧
唯恐自己的文化、工作、孩子的未来和生活方式受到波及
最后
LeCun畅想了人工智能在机器人领域的美好前景
他认为
机器人将在未来十年中大放异彩
尽管业界对机器人寄予厚望已久
但是除了一些预设的程序
很少有有革命性的突破
症结还是出在如何让系统理解世界运转的规律
并且根据规律来制定行动计划
为了解决这个难题
LeCun首先阐释了分层规划的概念
并以从纽约到巴黎的旅行为例
形象地说明了如何通过逐层分解来达成目标
在此基础上
他进一步探讨了如何利用认知和深度学习来训练系统学习分层感知表征
以及如何将这种学习应用到行动规划中去
LeCun由衷地憧憬
AI终有一天能提升全人类的智力水平
就好比每个人身边都有一帮比自己更聪明的AI助手
它们俯首帖耳,言听计从
还能以更高效、更优质的方式执行任务
届时
每个人都像是一群"超级员工"的领导者
LeCun还将AI的普及与印刷术的发明相提并论
认为二者都是让人类"脑洞大开"的重大突破
当然
这两项技术也可能引发一些连锁反应
比如宗教冲突和就业市场的结构性调整
但归根结底
LeCun对人性和AI的未来前景保持乐观
他笃信人性向善的本质
也相信AI能放大人类的善意
好了
以上就是LeCun这次访谈的主要内容
想要了解细节的朋友可以去看一下原视频
虽然AI这次浪潮被炒得很火热
有极端的激进派
也有极端的消极派
但是我一直觉得LeCun是以比较冷静的态度看待的
既不吹嘘，也不诋毁
虽然他所积极推动的世界模型
被Sora拿去借鉴抄了一下热度
自己推出的JEPA也没有得到太多业界的响应
但是他的观点和看法一致是非常一致的
而且在他的带领下
Meta通过推出开源大语言模型Llama系列
从前期非常被动的局面中脱身
也是非常难得的
但是大模型开源的这个问题
在前几期节目的评论中
我还是能看到很多不同意见的
很多可能是业内的人士
希望通过开源大模型来推动行业的进步
但是大部分普通人群
明显对开源是比较担忧的
担心被坏人拿去利用，造成破坏
说白了
还是这次大模型的能力和想象空间
超出了以往大家的理解
接下来如何发展
我们还是要拭目以待一下
好了感谢大家的观看，我们下期再见
