大家好，这里是最佳拍档，我是大飞
自十七世纪开始
人类社会就一脚油门
开上了科技发展的快车道
我们在这400年间取得的科学成就
远远超过人类史上的任何一个时期
然而，在科学技术蓬勃发展的同时
社会对于科技的恐惧也与日俱增
人们害怕
过于发达的科学技术会突破社会道德的底线
创造出脱离人类掌控的可怕怪物
这一担忧在著名作家雪莱的笔下被具象化为了科学怪人弗兰克斯坦
随着科技的发展
人们担忧的对象也在不断地转移
从生物科技到核武器，如今
高速发展的AI技术也成为了一部分人眼中那个丑陋的“科学怪人”，
他们相信，AI一定会毁灭人类
AI 安全研究员罗曼·扬波尔斯基就是这批信众中的一员
他认为
AGI最终毁灭人类文明的可能性高达99.9999%。
如此惊世骇俗的言论出自他与莱克斯·弗里德曼的播客访谈中
这位专攻人工智能 (AI) 和安全的乌克兰裔美国计算机科学家认为
如果当下各大科技公司无法拿出足够强力的技术监管措施
那么AGI将对人类的生存与生活造成毁灭性的打击
最终完全泯灭人类存在的意义
今天大飞就来和大家分享一下
罗曼·扬波尔斯基究竟在AGI身上看到了怎样的獠牙与利爪
以至于人类完全无从抵挡
首先
罗曼并不认为眼下的AI技术会对人类造成危险
他更多地着眼于AI技术的未来
也就是AGI
在访谈中
罗曼·扬波尔斯基将AGI定义为能够实现人类不可行之事的超级智能
并且它将以此作为特点
脱离人类的控制
人类的智能水平一般表现为在物种的专业知识领域展示出的能力
我们知道如何做人类这个物种能做的事情
比如学习知识，书写或者说话
但是人是没法学会跨越物种障碍的技能的
就算我们可以模仿狗的叫声
也无法用狗叫声和自己家里的吉娃娃沟通
而AGI，按照罗曼所说
并没有专业领域的限制
AGI可以做到当下任何智能体能够做到的事情
它既可以理解和人交流的方法
也可以理解和狗交流的方法
罗曼扬言，你都可以在人类
或者说任何智能体能力的基础上
再加上超级智能的概念
从而实现对该智能的超越
换言之，在罗曼看来
作为超越人类的智能体
AGI是一定会拥有和人类相似
甚至更加优秀的“自我意识”，
而这就是它与过去百年中其他的科技最大的不同
因为其他的科技产物归根结底都是工具
而工具本身不会产生消极或积极的影响
罗曼将过去其他的科技成果比喻为一把枪
枪的威力再大
它也不会自己扣下扳机
AGI就像是一把拥有自我意识的枪
它可以自行决定对谁
在什么时候扣下扳机
罗曼将AGI的自我意识看作是它能够对人类造成威胁的根本原因
这意味着一件威力巨大的武器脱离了脱离人类的掌控
既然如此
能不能对AGI的智能加以限制
降低它的危害性呢？
罗曼认为这也不可能
这主要由于两方面的原因
一是开发者出于利益考虑
不会去限制AGI的智能
AGI带来的利润足以让任何资本抛弃对于潜在风险的担忧
正也应了马克思的那句老话
如果能获得200%的利润
资本家就会出售绞死自己的绳子
在罗曼看来
资本会成为AGI发展的最大推手
其次是大模型开发的“灰盒”特征
开发者需要通过在模型训练完毕后的测试
才能了解它的具体功能
罗曼认为这一开发流程给予了AGI反叛人类的窗口期
在人类通过测试搞清楚AGI的全部能力之前
也许世界就已经被它毁灭了
既然限制AGI如此的困难
那么可以不可以设计一套监管系统
时刻监测AGI呢？
罗曼也不认为人类的监管会有实际的效果
他表示
设计一种检测AGI是否产生对人类有威胁的测试是可能的
比如各种科幻电影中的智能或者服从性测试
在情报不对等的情况下
我们确实可以试探出AGI是否在撒谎
但是罗曼强调
人类不会永远处于情报优势的一方
研究过程中很有可能会出现出乎意料的情况
比如说
被测试的系统意外得知了人类在测试它
所以它会隐藏起自身真实的一面
从而通过检测
又或者，在测试结束后
AGI通过与人类或者是其他智能系统的互动
接触到了研究计划以外的信息
罗曼将这种现象称为 "诡谲转向 "，
即一个系统出于博弈论等原因
决定改变自己的行为
这时候可能有观众朋友会说了
他这不是杞人忧天吗？
在AGI问世的时间点上
罗曼·扬波尔斯基表现得比一些AI支持者都更有信心
他认为
已经没有多少技术瓶颈挡在人类和AGI之间了
以前我们问的是 AGI 还需要哪些条件
现在我们应该问的是 训练AGI 还需要多少钱
与此同时
训练AGI的成本随着科技的进步在不断地降低
计算变便宜的速度在呈指数级增长
今天是 1 万亿美元
明年是 10 亿美元
几年后是 100 万美元
越来越便宜的计算成本会促使科技公司快马加鞭
加快AGI的开发
最快在2026年
罗曼就准备好看到AGI出现在市场上了
既然AGI已经神乎其神到如此地步
那么它到底会对我们造成什么样的危害呢？
对此，罗曼认为
AGI并不一定会主动地毁灭人类
但是 “君子无罪，怀璧其罪”。
AGI仅仅存在就会为人类社会带来难以承受的风险
罗曼将这些风险细分为了三个方面
第一是存在性风险（Existential risk）
在AGI的不可预测性以及强大功能性的基础上
它完全有可能从物理层面抹除人类这一物种的存在
罗曼表示
我们无法预测一个更聪明的系统会做什么
所以追问AGI会如何杀死所有人
是一个没有意义的问题
就像你家里的蚊子永远不会明白蚊香是怎么杀死自己的
在标准的纳米技术、合成技术、生物技术、核技术等科技的基础上
AGI还会创造出超出人类想象的事物来毁灭我们
罗曼用“白费力气”来描述人类对于AGI的预防
他认为
人类始终受限于自身的想象力和思维方式
相对地，如果AGI拥有更强的智慧
那么它们就会发展出与人类不同的思维方式
AGI杀死我们的方式可以说是无法去预测的
举个例子，如果松鼠打算杀死人类
它们可能选择用松子拼命敲人的头
或者用牙咬
但是它们绝不会考虑用我们人类去杀死彼此的方法
比如弄一把枪
罗曼认为，AGI诞生的那一刻
一把装满子弹的左轮就已经抵在了人类的太阳穴
我们既不知道它会不会开枪
也不知道它会如何开枪
它甚至可能用枪托砸死我们
除了在物理层面毁灭人类的可能性以外
罗曼还提出了“S-risk”（Suffering risk）
折磨风险
罗曼认为
AGI的超级智能意味它有能力学习人类历史中的阴暗面
从而成长为一个专注于折磨人类的智能体
就像一个反社会人格患者或者邪教徒一样
他以纳粹和奥姆真理教举例
指出人类的历史中确实存在专注于杀死所有人的思想
而AGI可以通过学习
成为那些邪恶领袖或者思想的“代理人”，
比如一个电子化的希特勒
最后，罗曼还提出了Ikigai risk
Ikiga是一个日语词汇
可以粗浅地翻译为“人生的意义”或是“成就感”。
我们在日常的工作和生活中都有自己擅长的本领
这些事情会给人们带来自信和自豪感
填补了人生意义的空白
哪怕贫穷路边的环卫工人
他也可以自豪于自己的体力和肌肉养活了自己
甚至一家三口
一切从工作和生活中获得的积极意义都可以归于Ikigai
而罗曼表示
AGI会对此形成毁灭性的打击
他表示，一旦AGI到来
我们失去的不是 10%的工作
而是失去所有的工作
而失去工作后
人类要如何才能实现自己的社会价值呢？
哪怕艺术性创作
拥有创造性的AGI也完全可以胜任
面对一个在智能上完全碾压自身的内容生产方
人类很难再从艺术创作中获得他人的支持
艺术家只会得到“不如AI”的评价
而肉体劳动更是会被机械所取代
罗曼警告说
AGI将为人类带来一个没有生活意义的世界
而AGI却无法填补自己造成的意义空缺
哪怕AGI如同黑客帝国中描绘的一样
创造了一个庞大的虚拟世界
来满足每一个人的物质需求
它也难以同时满足80亿人多样化的价值需求
罗曼认为不同文化、不同宗教之间
并不存在普遍接受的伦理道德
人们在政治等方面的偏好各不相同
所以
即使我们以某种方式管理了它的所有其他方面
将这些模糊概念编程进去
让人工智能紧跟这些价值需求
我们也无法就编程的内容达成一致
因此
个人生存的意义最终会随着AGI的到来完全消失
既然失控的AGI带有如此可怕的风险
那么有没有可能在AGI出现前
先设置一套足够强力的监管系统控制住AGI
从而在足够安全的环境下
探索AI的前沿技术呢？
罗曼表现得十分悲观，他坚持认为
人工智能系统最终将是不可验证、不可预测的
而不可控的事物必然会导致失控
因此
罗曼认为唯一明智的做法是放弃AGI这一技术目标
不要建造你无法控制、无法理解的东西
除非这些人工智能的开发者们能够证明
人类有可能无限期地控制神一样的超级智能机器
但是罗曼偏偏非常不信任科技公司内部的安全技术人员
他自认“旁观者清”，
指责那些科技公司内部的人员要么被新技术带来的热潮蒙蔽了双眼
要么就受到了来自公司的威胁或者是限制
无法公开公正地发表对AI安全性的质疑
罗曼表示，在AGI带来的庞大利润面前
他无法相信企业有动力去推动AI安全技术的发展
他用当下的软件产业举例子
当我们使用各种办公软件时
几乎没有人会去阅读那漫长的用户责任说明
但是
一旦用户点击了“我同意”的按钮
软件就可以肆意窃取你的个人隐私
公司还不需要负任何法律责任
就像当年的棱镜门一样
罗曼觉得，同样是科技工作者
凭什么认为AI的开发者们会为了用户的安全考虑
而不会利用类似的手段来窃取用户信息呢？
难道开发AI还能迭代开发者的道德水平吗？
与此同时
他还将对AGI的预防描述为了一个几近于形而上学的问题
对于我们尚未拥有的系统
我们该如何保证它们的安全？
人类历史上从来没有出现过与AGI相似的东西
我们没有任何前车之鉴可以参考
而对于未来AGI的存在形式
当今的科学家们又只有理论上的预测
甚至都没有详细的研究数据可供研究
因此
罗曼认为开发针对AGI的安全措施
仅仅存在理论上的可能
在实践操作中完全就是瞎猫抓耗子的状态
他对此不抱有任何的期望
好了
以上就是罗曼·扬波尔斯基在这次采访中描述的主要内容
采访的全长约两个小时
感兴趣的朋友可以去观看原视频
在这场AI发展的热潮中
像罗曼一样坚决反对AI技术的声音相对较少
大飞分享这些内容的目的
也是希望大家能够从这些持有不同意见者的言论中
发现更多看待问题的角度
在不同观点的冲突里进行批判性的思考
不知道大家是如何看待罗曼的想法的呢？
欢迎在评论区留言
感谢大家的观看，我们下期再见
