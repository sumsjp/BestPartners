大家好，这里是最佳拍档
对于AI领域来说
2025年绝对是值得被铭记的一年
这一年里
大语言模型不再是一个简单的文本生成工具
而是在技术架构、应用形态、交互方式甚至智能本质上
都完成了一系列的突破
12月19日
前特斯拉AI总监、OpenAI的早期核心成员安德烈·卡帕西
发表了一篇名为《2025大语言模型年度回顾》的文章
以其独特的技术洞察力
总结了六大重塑大语言模型领域的范式变化
接下来
大飞就来为大家拆解一下这六大范式革新
看看2025年的大语言模型行业
到底发生了哪些足以影响未来十年的关键转变
在2025年之前
整个行业生产级的大语言模型训练流程
已经形成了一套稳定而且经过验证的标准配方
这套配方从2020年左右的预训练开始
后续叠加了2022年的SFT和RLHF两个关键阶段
在很长一段时间里
这套组合都是所有实验室
训练生产级大语言模型的核心框架
但是这套框架存在着一个难以突破的瓶颈
那就是模型的推理能力
始终停留在模仿人类反馈的层面
无法真正形成自主的问题拆解和逻辑推导
因为无论是SFT还是RLHF
本质上都依赖于人类提供的标注数据
或者反馈信号
而人类很难清晰的定义
什么是最优的推理路径
比如解一道复杂的数学题时
中间哪一步该拆分、哪一步该验证
这种隐性的推理逻辑
既难以用文本标注传递给模型
也无法通过简单的点赞或者差评反馈
让模型学会
而2025年
RLVR（Reinforcement Learning from Verifiable Rewards）的出现
彻底打破了这个瓶颈
成为了大语言模型训练流程中
不可或缺的新的核心阶段
RLVR的核心逻辑，简单来说
就是为模型构建一系列可自动验证结果的训练环境
在这些环境中
模型的每一个输出都能被系统自动判断正确与否
并且获得对应的奖励信号
这样一来，无需人类参与反馈
模型通过持续优化获取奖励的目标
就能自发形成一套解决问题的策略
这些策略在人类看来
就是推理能力的体现
卡帕西特别提到
DeepSeek团队的R1论文中
就有大量的这类案例
经过RLVR训练的模型
在解高等数学题的时候
会像人类学生一样
先写出已知条件、拆分问题模块、进行中间计算验证
最后得出结论
在调试代码的时候
会逐行排查语法错误、逻辑漏洞
甚至主动添加测试用例
验证修复效果
这些行为
都是之前的SFT或RLHF阶段无法实现的
因为之前的训练模式中
模型只能看到人类的最终答案或反馈
却看不到人类如何一步步想到答案
而RLVR通过可验证奖励
让模型自己摸索出了这套推理方法论
更重要的是
RLVR与SFT、RLHF存在着本质上的区别
后两者在计算规模上属于轻量级微调
训练周期短、参数更新幅度小
而RLVR面对的是客观且无法作弊的奖励函数
这使得模型可以进行更长周期的优化
相当于之前的训练是给模型讲题
而RLVR是让模型自己刷题
并且即时批改
这种高强度的自主训练
带来了能力上的质变
这种质变最直观的体现
来自OpenAI的产品迭代
2024年底发布的o1
是行业内首个展示RLVR潜力的模型
但是当时的能力提升还相对有限
而2025年初推出的o3
成为了RLVR技术成熟的拐点
很多用户在使用o3时都能直观感受到
模型不再是快速给出答案
而是先思考再回答
甚至会在输出中
明确标注我需要先验证这个前提
这里可能存在逻辑漏洞
我再检查一遍等等
这种思考过程的可视化
正是RLVR训练的直接成果
而RLVR还带来了一个行业性的连锁反应
那就是计算资源的重新分配
原本各大实验室计划用于更大规模预训练的算力
大部分都被投入到了RLVR的训练中
因为实践证明
RLVR每单位算力带来的能力提升
远高于单纯扩大模型的参数规模
这也导致2025年大语言模型行业的一个显著特征
主流模型的参数规模并没有明显的增长
但是训练周期大幅延长
尤其是RLVR阶段的运行时间
成为了决定模型能力的核心指标
除此之外
RLVR还为行业带来了一个全新的能力调节旋钮
通过控制模型的思考时间
来调节模型在特定任务上的表现
这种按照任务需求
调节推理深度的模式
让大语言模型的实用性大幅提升
也为后续的应用开发提供了更灵活的技术基础
2025年
另一个足以颠覆行业认知的范式变化
是我们终于开始以正确的视角
来理解大语言模型的智能本质
卡帕西用一个非常形象的比喻总结了这一点
我们不是在培育进化中的动物
而是在召唤幽灵
这个比喻背后
是大语言模型与人类、动物等自然智能
在本质上的巨大差异
首先，两者的优化目标完全不同
人类的大脑是在数百万年的进化中
为了部落生存而优化的
我们的感知、记忆、推理能力
本质上都是为了应对丛林中的危险、获取食物、繁衍后代
这些核心的生存需求
而大语言模型的神经网络
是在海量文本数据上
为了模仿人类文本
在数学谜题中获取奖励
以及在LM Arena中获得人类投票而优化的
两种截然不同的优化压力
注定了两者的智能形态会存在天壤之别
这种差异最直观的表现
就是大语言模型的锯齿状智能（Jagged Intelligence）
模型在某些领域的能力达到天才级
但是在另一些看似简单的领域
却表现得像个认知能力不足的小学生
卡帕西在文章中
分享了一张非常形象的图
图中用蓝色曲线代表人类智能
红色曲线代表AI智能
两条曲线都呈现锯齿状
但是锯齿的位置完全不同
人类的智能锯齿多集中在专业领域的深度上
而AI的智能锯齿则分布在能力维度的均衡性上
这张图也揭示了一个关键事实
那就是不仅AI的智能是锯齿状的
人类的智能同样如此
只是两者的短板领域不同
这种锯齿状智能的存在
直接冲击了行业长期依赖的基准测试体系
卡帕西在2025年明确表达了对基准测试的冷漠和不信任
核心原因在于
几乎所有的基准测试都是可验证的环境
而这些环境
恰好是RLVR和合成数据生成技术
可以针对性优化的
在2025年的基准测试竞赛中
各大实验室形成了一套新的优化逻辑
先分析基准测试所覆盖的嵌入空间
然后构建相似的训练环境，通过RLVR
让模型在这些特定领域形成能力尖峰
从而在测试中取得高分
这种为测试而训练的模式
让基准测试的能力评估价值大幅下降
一个在所有基准测试中拿到满分的模型
可能在实际应用中依然漏洞百出
因为它的能力只是覆盖了测试场景
而不是具备了通用能力
这也引出了一个行业亟待思考的问题
当大语言模型能轻松碾压所有基准测试
但是依然无法实现AGI的时候
我们该用什么标准来衡量AI的真实能力呢？
2025年的行业实践给出了一个初步的答案
那就是从测试集分数
转向真实场景的落地效果
而这种评估标准的转变
也进一步推动了大语言模型技术
从追求纸面分数向解决实际问题倾斜
如果说RLVR和锯齿状智能
是大语言模型底层技术的范式变化
那么2025年另一大值得关注的趋势
是应用层的重构
而这一重构的标志性产品
就是Cursor
卡帕西认为，Cursor的迅速崛起
最核心的价值不在于它是一个好用的AI编程工具
而在于它首次清晰地揭示了
大语言模型应用的新层级形态
在2025年
Cursor for X已经成为行业热议的话题
这里的X可以是编程、设计、法律、医疗、教育等
任何的垂直领域
那么
这个新应用层到底有什么不同？
被卡帕西在2025年的Y Combinator演讲中
详细拆解了Cursor这类大语言模型应用的核心特征
总结起来有四个关键的维度
第一个维度是上下文工程（Context Engineering）
与通用大语言模型不同
Cursor这类垂直应用会针对特定领域
预先构建最优的上下文框架
这种针对性的上下文构建
解决了通用大语言模型的一个核心痛点
那就是用户需要花费大量时间
来描述背景信息
否则模型就无法精准的理解需求
而Cursor通过领域专用的上下文工程
让用户无需额外解释
就能让模型快速切入核心任务
第二个维度是复杂有向无环图
也就是DAG的大语言模型调用编排
在通用大语言模型的交互中
用户与模型的沟通通常是单轮或多轮对话
而Cursor这类应用的底层
是将多个大语言模型调用
串联成复杂的DAG结构
每个步骤的输出作为下一个步骤的输入
同时系统会实时平衡性能和成本
这种编排式调用
让大语言模型的能力从单次响应
升级为了流程化的解决复杂任务
第三个维度是应用的专用GUI
通用大语言模型的交互界面
大多是聊天框
而Cursor为编程场景设计了专用的GUI
这种领域专用GUI的核心价值
是让人类和大语言模型之间的协作
更加符合特定场景的工作流
第四个维度是自主度滑块（Autonomy Slider）
这是Cursor最具创新性的设计之一
用户可以根据自己的需求
调节AI的自主参与程度
这种可调节的自主度
解决了通用大语言模型的一个关键问题
AI的参与要么过度，要么不足
而自主度滑块让AI成为了可定制的协作伙伴
从而适配不同用户、不同场景的需求
卡帕西对这个应用层趋势的判断是
大语言模型实验室与应用开发者的分工
将会越来越清晰
大语言模型实验室的核心任务
是培养出具备通用能力的大学生
也就是提供基础模型
具备语言理解、知识储备、推理等核心能力
而应用开发者的核心任务
是将这些大学生
培养成垂直领域的专业人才
让通用模型在特定领域形成专业能力
最终落地为可部署的产品
这种分工模式
也让行业看到了应用层创新的巨大潜力
大语言模型实验室无需包揽所有场景的落地
而可以专注于基础模型的优化
应用开发者则可以基于成熟的基础模型
聚焦于垂直领域的需求挖掘和体验优化
在2025年
已经出现了大量Cursor for X的创业项目
比如Cursor for 医疗
Cursor for 法律
Cursor for 教育等等
这些垂直应用的爆发
让大语言模型从通用工具
真正渗透到了各行各业的具体工作流中
成为了提升生产效率的核心生产力工具
在2025年的大语言模型领域
另一个极具创新性的范式变化
来自于 Anthropic 推出的Claude Code
卡帕西认为
Claude Code的核心突破有两个
一是它首次让大语言模型Agent的概念
从理论走向了实用
二是它选择了本地运行的部署模式
与OpenAI的云端Agent策略
形成了鲜明对比
而在卡帕西看来
Claude Code的选择更符合当前的技术阶段
首先
Agent的核心能力就是循环式的工具使用与推理
与传统大语言模型单次响应用户需求不同
Claude Code这类Agent能像人类一样
根据任务目标
自主决定需要使用什么工具
如何使用工具
如何根据工具反馈调整策略
并且持续循环这一过程
直到完成复杂任务
而Claude Code的另一个核心特征
本地运行
则是其区别于其他大语言模型Agent的关键
卡帕西认为
OpenAI在Agent方向上的策略走偏了
OpenAI将其这部分能力集中在云端容器部署
通过ChatGPT进行调度
优势是算力强、模型规模大
但是缺点也同样明显
一是隐私安全风险
二是环境适配性差，三是有交互延迟
而Claude Code选择在本地运行
恰好解决了这些痛点
它直接安装在用户的电脑上
所有数据处理、工具调用、推理计算都在本地完成
无需上传云端
从根本上保障了隐私安全
同时
它能够深度适配用户的本地环境
无论是Windows、macOS还是Linux系统
无论是Python、Java还是Rust等开发语言
无论是本地数据库还是私有软件工具
Claude Code都能直接调用和交互
此外，本地运行带来的零延迟
让AI Agent与用户的协作更流畅
这种实时反馈的体验
是云端Agent所无法比拟的
卡帕西强调，Claude Code的成功
还在于它的形态设计
它采用了简洁而强大的命令行界面（CLI）
而不是复杂的图形界面
这种设计看似复古
实则精准适配了开发者的工作习惯
对于程序员、数据分析师等专业用户来说
CLI界面操作高效、可自动化、可批量处理
比图形界面更能提升工作效率
而这种本地运行+CLI界面的组合
也让AI的形象发生了转变
它不再是一个需要打开网页访问的服务
而是一个可以居住在你电脑里的小幽灵
小助手，随时可以响应你的指令
与你协同完成工作
这种交互形态的变化
它的意义其实远超一个工具的革新
它标志着大语言模型从远程服务走向本地伙伴
从被动响应走向主动协作
在2025年
越来越多的用户会开始习惯
电脑里有一个AI Agent的生活
这种普及
也会让大语言模型的渗透率大幅提升
从专业领域走向更广泛的个人用户场景
2025年，大语言模型还带来了一个
足以改变软件行业生态的范式变化
卡帕西称之为氛围编程，Vibe Coding
这个听起来有点随性的术语
其实是卡帕西在一条突发奇想的推文中
偶然创造的
没成想却意外成为了2025年行业最热门的概念之一
因为它精准捕捉了AI赋能编程的核心形态
你可以用自然语言描述想要的效果
然后让AI自动生成代码
而用户无需关注代码的具体实现细节
简单来说，就是忘记代码，只谈需求
氛围编程的核心突破
是大语言模型跨越了自然语言到代码的能力阈值
在2025年之前
AI生成的代码往往需要大量人工修改才能使用
而到了2025年
经过RLVR训练和垂直优化的大语言模型
已经能够精准理解自然语言中的隐性需求
并且生成高质量、可直接运行的代码
这种能力的突破
带来了两个层面的颠覆性影响
第一个层面是全民编程时代的到来
在传统软件行业
编程是一项高门槛的技能
需要掌握特定的编程语言、语法规则、算法逻辑
普通人想要开发一个简单的工具
往往需要花费几个月
甚至几年的时间学习
而氛围编程彻底打破了这个门槛
无论是学生、教师、设计师
还是职场白领、自由职业者
只要能清晰地用自然语言描述自己的需求
就能通过AI生成对应的软件工具
这意味着
编程不再是专业开发者的专属权利
而是成为了一种全民可及的基础技能
就像现在使用Word、Excel一样简单
第二个层面是专业开发者的效率革命
对于专业程序员来说
氛围编程不是替代他们
而是解放他们
开发者可以将大量时间
从编写重复代码、实现基础功能中解放出来
专注于核心逻辑设计，架构优化
创新功能的研发等更高价值的工作
卡帕西分享了自己2025年的亲身实践
他在开发nanochat项目时
需要一个高效的BPE分词器
但是他并不熟悉Rust语言
按照以往的做法
他要么学习Rust语言
要么采用现有的开源库
而通过氛围编程
他直接用自然语言描述了分词器的需求
AI自动生成了对应的Rust代码
不仅性能达标
还完美适配了nanochat的架构
此外，他还通过氛围编程
快速开发了多个演示项目
比如menugen、reader3等等
甚至为了查找一个bug
专门生成了一个临时应用
因为在氛围编程的模式下
代码变得免费、短暂、可塑造
甚至单次使用后可以丢弃
开发成本几乎为零
卡帕西在之前的文章中
曾经提出过一个核心的观点
那就是与以往的技术不同
大语言模型的技术扩散
其实是普通人受益更多
而不是专业人士、企业或者政府
氛围编程正是这个观点的最佳佐证
以往的技术革新
比如计算机、互联网、手机
首先受益的是企业和专业人士
普通人需要经过很长时间
才能享受到技术红利
而大语言模型带来的氛围编程
让普通人直接获得了开发软件的能力
这种赋能是即时而且平等的
而这种全民编程的趋势
也将深刻改变软件行业的生态
未来的软件市场
也许将不再是少数大公司主导
而是海量个人开发者和小团队百花齐放
每个人都可以根据自己的需求开发工具
然后分享给有同样需求的人
软件的形态也将从通用大产品走向垂直小工具
更精准地满足用户的个性化需求
同时，未来的程序员
不再是代码的编写者
而是需求的定义者，逻辑架构师
AI协作管理者等等
核心能力将从代码熟练度
转向需求拆解能力
系统设计能力，以及AI协同能力
如果说氛围编程改变了大语言模型的输入方式
那么2025年另一大交互形态的革新
来自大语言模型的输出方式
这个革新的标志性产品
正是谷歌的Nano Banana
卡帕西认为
Nano Banana是2025年最具颠覆性的模型之一
因为它首次预示了大语言模型的GUI时代的到来
而这个时代的核心逻辑
就是让大语言模型
用人类喜欢的方式沟通
要理解这个革新的意义
我们需要先回顾大语言模型的交互现状
在2025年之前
大语言模型的主要交互方式是文本聊天
用户输入文本指令
模型输出文本结果
这种方式的优势是直接、高效
因为文本是大语言模型最擅长的数据形态
但是缺点也同样明显
不符合人类的信息接收习惯
卡帕西指出
人类其实不喜欢阅读大量文本
因为文本的信息密度低、读取速度慢、需要投入大量的注意力
而人类天生喜欢视觉化、空间化的信息呈现
这也是为什么图形用户界面
能够在传统计算机领域取代命令行界面
成为主流的交互方式
而Nano Banana的核心创新
不在于它能够生成图像
而在于它实现了文本生成、图像生成、世界知识的深度融合
模型的权重中同时包含了语言理解、视觉生成、世界知识三大能力
能够根据用户的需求
自动选择最优的信息呈现方式
卡帕西认为
大语言模型作为下一代的计算范式
它的发展路径与20世纪70、80年代的计算机
有许多相似之处
当时的计算机从大型主机走向个人计算机
从命令行走向GUI
而现在的大语言模型
正处于从通用文本工具
走向专用视觉化工具的关键节点
当前的文本聊天交互
就相当于计算机的命令行时代
高效但是门槛高
而未来的大语言模型 GUI
将相当于计算机的Windows或Mac OS时代
直观、易用
能够让更多人轻松使用大语言模型的能力
值得注意的是
大语言模型 GUI的发展
并不是要取代文本交互，而是互补
对于简单查询、快速指令等场景
文本交互依然是最高效的
而对于复杂信息、知识传递、决策支持等场景
视觉化交互将成为主流
2025年的行业实践
已经出现了一些早期案例
预示着大语言模型的交互方式
正在从单一文本
走向文本+视觉+动效的多模态融合
而这种融合
将进一步降低大语言模型的使用门槛
推动它从专业工具
走向全民普及的基础设施
回顾2025年大语言模型领域的六大范式变化
我们能够清晰地看到一个核心特征
那就是大语言模型正在以一种矛盾而真实的姿态
快速成长
它既比我们预期的更聪明
又比我们预期的更笨拙
它既具备了颠覆行业的潜力
又面临着诸多待解的挑战
卡帕西曾经在Dwarkesh的播客中
表达过一个看似矛盾
但是又极具洞察力的观点
他同时相信
大语言模型领域会持续快速进步
但是也认为还有大量工作要做
未来的大语言模型
无论是底层技术的优化
还是应用层的创新
抑或是行业规范的建立
都还有巨大的探索空间
虽然2025年即将过去
但是大语言模型的革命
也许才刚刚开始
正如卡帕西在文章结尾所说的
Strap in
系好安全带，未来几年
我们恐怕还将见证更多颠覆认知的技术突破
更多改变生活的应用落地
而作为这场革命的见证者和参与者
我们既要保持对技术的敬畏之心
也要怀揣对未来的期待
感谢收看本期视频，我们下期再见
