大家好，这里是最佳拍档，我是大飞
现在网络上到处都充斥了AI生成的内容
文字、图片、声音、视频
越来越多的模态被AI攻占
我们今天就来简单聊一聊
AI生成的内容
到底能不能被有效地识别出来？
我们以现在最流行的AI检测工具GPTZero为例
如果我们把美国宪法的文本
放到GPTZero里
它会告诉你这份文件几乎肯定是由AI生成的
同样，对于《圣经》中的内容
检测工具会告诉你
有88.2%的几率是AI写的
而国外一个大学的教授
由于怀疑学生使用AI写论文
就把学生的论文放到了像GPTZero这样的AI检测工具中
用检测工具的结果
直接挂掉了大部分学生
但是实际上
大部分的学生其实都是自己写的论文
这把教授和学校都搞得焦头烂额
那么
为什么AI检测工具会有这么离谱的检测结果呢？
这就必须要理解这种AI检测器的原理是什么了
我们可以从GPTZero的创始人那里
获得一些有用的信息
虽然不同的AI写作检测器
使用的检测方法略有不同
但是它们的原理都是类似的
那就是用一个经过了大量文本训练的AI模型
然后建立一套推测规则
用来判断这篇写作更是人类写的还是AI生成的
以GPTZero为例
它的核心是一个神经网络
这个网络是基于大量的、多样的人类写作和AI生成的文本训练的
但是训练数据的重点是英文散文
然后
这个系统使用像「困惑度」（Perplexity）
和「突发性」（Burstiness）这样的特性
来评估文本并进行分类
在机器学习中
困惑度是衡量一个文本
偏离AI模型在训练期间所学到的内容程度的一个指标
正如AI公司Hugging Face的玛格丽特·米切尔博士所说
「困惑度是这种语言基于我所看到的内容
有多令我感到惊讶的一个函数」。
所以，测量困惑度的原理就是
当AI模型，比如ChatGPT生成文本时
它们自然会选择它们最擅长的内容
而这些内容就来自它们的训练数据
输出的内容离训练数据越近
困惑度就越低
但是人类是一种更混乱的写作者
或者至少从理论上说是这样的
我们可能会突然写出一些天马行空的文字
或者是有自己独特的写作风格
但是人类也可以写出低困惑度的文字
特别是当按照法律或者某些学术风格来写作的时候
除此之外，人类使用的许多短语
其实出奇的常见
或者说是完全可预测的
比如说作为人类
如果我们要猜测「给我来一杯」这句话中的下一个词是什么
那么大多数人可能会在这个空格中填上
「水」、「咖啡」、「茶」、「饮料」等等这些词
实际上
一个接受了大量文本训练的语言模型
也会这样做
因为这些短语或词组在写作中经常出现
所以从AI的角度来看
任何这几个结果的困惑度都会非常低
因为预测会相当准确
现在如果出现一个不太常见的填空答案
「我想要一杯蜘蛛」。
那么人类和一个训练有素的语言模型
就都会感到相当惊讶
或者说感到「困惑」，
什么是一杯蜘蛛呢
它的困惑度会很高
因此，如果一篇文本中的语言
对于经过训练的模型来说
并不令人惊讶
那么文章整体的困惑度就会很低
所以AI检测器更有可能将这段文本
认为是AI生成的
这就是为什么「美国宪法」为认为是AI生成
背后的原因
本质上，宪法文章中所使用的语言
在这些模型中已经非常根深蒂固了
以至于对于AI检测器来说困惑度非常低
从而做出了错误的判断
GPTZero的创建者Edward Tian曾经说过
《美国宪法》是一个被反复输入到许多大语言模型训练数据中的文本
因此
这些大语言模型训练的结果就是
能够很容易地生成与宪法和其他常用训练文本相似的文本
而GPTZero在预测这些大语言模型所生成的文本时
就会出现这种现象
问题在于
我们人类也完全有可能创作出困惑度很低的内容
比如说，我们写的文章中都是大白话
常用语句
类似于我想要一杯咖啡这样的句子
这就会让AI检测器的结果变得很不靠谱了
因此，仅仅利用语言的困惑度
来鉴定文本是不是AI生成的
这种方式并不可行
那么还有其他的方法么？
GPTZero衡量文本的另一个属性是「突发性」，
指的是某些词或者短语
在文本中快速连续或者「突然」出现的现象
本质上
突发性是在评估文本全程的句子长度和结构的变化性
人类往往会有比较动态的写作风格
产生的句子长度和结构是比较多样的
比方说
我们可能会写一句长而复杂的句子
接着是一句短而简单的句子
或者我们可能在一句话中使用一连串的形容词
然后在下一句中一个形容词也不用
又或者是突然出现一大段的排比句
这种变化性是人类创造性和自发性的自然产物
另一方面，AI生成的文本
倾向于更加一致和规整的节奏
至少目前为止还是这样的
处于早期阶段的大语言模型
生成的句子长度和结构会更加规则
这种缺乏变化性的现象
会造成突发性分数较低
从而表明文本可能是AI生成的
但是，我们稍微想一下
就会知道
突发性也不是检测AI生成内容的万全之策
就像困惑度一样
人类也可能以一种高度结构化、一致的风格来写作
导致突发性分数很低
反过来
一个AI模型可能经过特定文本的训练
可以来模仿更人性化的句子长度和结构的变化性
提高它的突发性分数
实际上，随着AI语言模型的改进
有研究表明
它们的生成结果已经越来越像人类的写作
最终，可能不会存在一个非常简单
而且巧妙地区分人类写的文本和机器写的文本的方法
AI写作检测器
虽然可以做为一种猜测性的判断
但是它的误差边际太大
不能完全依赖它们给出准确的结果
那AI检测器还有没有用呢？
应该说，而对AI生成的内容
特别是文字内容的检测
在未来会越来越重要
因为
在未来要想训练ChatGPT这样规模的语言模型
可能现有的人类数据已经快不够用了
去年11月份
MIT的研究人员就进行过一项研究估计
认为机器学习的数据集可能会在2026年之前
耗尽所有人类的「高质量语言数据」。
于是很多大佬们都表示
未来可能会用AI生成的数据来训练AI
但是这个美好的愿望
可能会面临一个非常现实的问题
那就是至少目前看来
AI生成的数据对于训练AI来说
可能是有毒的
最近
莱斯大学和斯坦福团队研究发现
将AI生成的内容喂给模型
只会导致模型的性能下降
研究人员对此给出一种解释
叫做「模型自噬障碍」，
简称MAD
研究发现在使用AI数据之后
经过第5次迭代训练后
模型就会患上MAD
换句话说
如果不能给模型提供「新鲜的数据」，
即由人类标注的数据
那么它的输出质量将会受到严重影响
一方面，研究者们在研究
如何方便地给AI生成的数据打水印
让新生成的AI数据能够方便地被识别出来
从而避免被拿来进行AI训练
另一方面
面对未来可能大量出现的、没有水印的AI生成数据
把它们和人类数据区别开
本来就是一件非常重要的事情
否则整个人类世界的信息
也会被逐渐污染掉
没有人知道什么是真实发生的
什么是AI生成的
目前来看，在如何检测AI生成数据上
还需要进一步的技术突破
大家对这方面有没有什么好的想法
可以发在评论区讨论一下
好了，本期的视频内容就到这里
感谢大家的观看，我们下期再见
