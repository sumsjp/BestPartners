大家好，这里是最佳拍档，我是大飞
在今年年初ChatGPT刚开始爆火的时候
我们还曾经担心过一个问题
那就是AI会发展出自我意识吗？
不过很快
我们的注意力就被各种让人眼花缭乱的大模型产品所取代了
不再关心AI的未来
大家都在考虑的是
眼前怎么让大模型落地，怎么赚钱
幸运的是，有人依然在关注这件事
就在本周二
深度学习三巨头之一、59岁的图灵奖得主Yoshua Bengio
以及包括他在内的一个19人团队
刚刚发布了一篇长达88页的重磅论文
来论证现在的AI有没有可能拥有意识
之所以说重磅
Bengio自不用我们多说
论文的其余作者也都是来自人工智能、神经科学和哲学领域的教授和专家
用非常科学和严谨的方法探讨了意识的客观存在标准
可以说
这篇论文应该是对AI是否具有意识这一争议话题
最为权威和客观的解答
我们先说论文的结论
那就是目前并不存在拥有意识的AI
但是以现有的技术条件
创造出有意识的AI基本不成问题
看到这句话，我不禁在想
之前我们节目中介绍的那些游戏中的AI智能体
是不是已经开始在思考
游戏之外有什么了，是谁在主宰他们
他们是谁
从哪里来，他们存在的意义是什么
那究竟会不会有这一天
我们不如先来看看这篇论文的研究方法是怎样的
首先必须指出的是
关于什么是“意识”，
虽然每个人都能大概讲出一些自己的理解
但是在学术界
意识的概念长达几个世纪以来都存在不同的定义
哲学家、神学家、语言学家和科学家对这个概念进行了数千年的分析、界定、诠释和辩论
但是意识的本质仍然没有统一的认可、留有争议
不仅如此
人工智能领域对于人工意识的理解
也经历了漫长的演进
20世纪以来
以艾伦·图灵为代表的行为主义者
曾经贡献了这一领域最具影响力的对意识的定义
也就是著名的“图灵测试”，
大家应该都已经耳熟能详了
如果一个测试者对无法确认身份的两个对象
分别是一个人和一个机器
提出相同的一系列问题
得到的答案让他无法区分究竟谁是机器
谁是人
那么就可以认定机器通过了图灵测试
拥有意识
行为主义的特点是
将意识解释为一系列能被外部观察到的行为
通过行为来定义意识
但是这种方法也经常被人们诟病
因为它既忽略了心理现象
也无法解释智力产生的原因
后来，功能主义取代了行为主义
成为新的定义人工意识的主导思想理论
和行为主义相比
功能主义更关注大脑做了什么
以及大脑功能在哪里起作用
认为如果有任何东西可以模仿特定的心理状态与计算过程的因果作用
意识就是可以实现的
功能主义对事物如何工作、到底是由怎样的材质组成等等外化体现不感兴趣
就好比将任何能报时的东西都归为时钟一样
而时钟是什么 制成的并不重要
只要它能报时就行了
尽管功能主义也被认为
存在无法体现事物的思考性等问题
但是它依然是现在人工智能领域
较为主流的衡量AI是否存在意识的依据
后来美国哲学家、计算机科学家希拉里·普特南（Hilary Putnam）又将功能主义与计算概念结合
提出了计算功能主义
计算功能主义认为
一个系统是否有意识
取决于比其物理构成的最低级别细节
更抽象的特征
系统的物质基底对于意识来说并不重要
这意味着意识原则上是可以多重实现的
它可以存在于多种基质中
而不仅仅是存在于生物大脑中
大多数领先的意识科学理论都可以通过计算来解释
具有这些计算特征就能认为是意识存在的必要和充分的条件
这些特征就是人工智能系统中的意识存在的必要或充分的前提
而人类和人工智能系统之间的非计算差异并不重要
简而言之，计算功能主义认为
精神世界是基于一个使用诸如信息、计算、记忆和反馈等概念的物理系统
而Bengio等人此次发布的论文
对AI有无意识基础的判断依据
正是计算功能主义
基础原则确定之后
接下来就进入到了更细致的“打分”环节
因为此前
学界对意识的研究已经有了一些公认的结果
比如科学家和哲学家对意识必要条件的主张等等
所以这篇论文作者在研究中做的事情就是
从过往对意识研究的成果中选取一部分科学理论
作为判断AI是否具有意识的更具体的评估依据和指标
论文主要介绍了其中用到的循环加工理论（Recurrent Processing Theory
RPT）
全局工作空间理论（Global Workspace Theory
GWT）和计算高阶理论（Computational Higher-Order Theories
HOT）三种科学理论
以循环加工理论（RPT）为例
RPT理论是关注于视觉意识的一个神经科学理论
试图解释意识视觉和无意识视觉处理之间的区别
它的核心观点是
为了产生视觉意识体验
大脑视觉系统中的信息需要进行循环处理
即信息从高层区域反馈回低层区域进行再处理
该理论认为
仅仅依靠前馈的信息处理是不够的
前馈处理只能提取视觉刺激的特征信息
但是不能形成意识见到的有组织的视觉场景
需要顶层皮层对初级视觉皮层的反馈
进行再处理
整合各种特征信息
组织成有意义的视觉场景
才能产生视觉意识
研究者将这个理论具体拆分成了RPT-1和RPT-2两个指标
RPT-1指“使用算法循环的输入模块”，
即信息在经过初始前馈处理后
反馈回输入模块进行再处理
这显示系统能进行循环处理
RPT-2指“生成有组织、整合的感知表示的输入模块”，
即系统能够处理视觉输入
整合各种特征
组织生成有意义的视觉场景
而不仅是提取孤立特征
如果一个AI系统满足这两个指标
则说明它具有与人类大脑相似的循环处理机制
并且能够形成整合的视觉表示
这使它成为一个更有可能拥有视觉意识的系统
所以这两个指标都可看作是AI系统视觉意识的重要指标
而全局工作空间理论GWT
它是一个重要的意识科学理论
其核心观点是意识依赖于一个「全局工作空间」的存在
该理论认为
人脑由多个专门的子系统或模块组成
可以并行地进行各自的信息处理
这些模块需要某种机制来统合信息
进行协调配合
「全局工作空间」就是这样一个信息共享和融合的平台
一个信息如果进入这个工作空间
就可以被所有的模块访问
但工作空间的容量是有限的
需要选择机制来确定哪些信息进入工作空间
GWT理论认为，一个信息进入工作空间
被广泛的模块访问
就是该信息进入意识状态的标志
GWT理论为判断AI的意识提供了四个指标
分别是GWT-1
拥有多个专门的子系统或模块
GWT-2，有限容量的工作空间
形成信息流的瓶颈
GWT-3，全局广播
工作空间的信息可被所有模块访问
GWT-4，状态依赖的注意机制
可以顺序调动模块完成复杂任务
一个AI系统如果具备这些特征
就更有可能具有类似人类的意识
所以这些都是判断AI意识的重要指标
而计算高阶理论HOT
这是关于意识的一个重要理论流派
它的核心观点是
有意识的体验包含了对自身正在进行的心理运作的某种最低限度的内在意识
而这是由于一阶状态在某种程度上受到了相关高阶表征的监控或者元表征所导致的
高阶理论与其他理论的区别在于
高阶理论强调主体必须意识到自己处于某种精神状态中
这种精神状态才被认为是有意识的
这是通过诉诸高阶表征来解释的
而高阶表征是一个具有非常特殊含义的概念
高阶表征是指表征关于其他表征的东西
而一阶表征是指表征关于非表征的东西
这种区别可以应用于心理状态
例如
红苹果的视觉表征是一种一阶心理状态
而认为自己拥有红苹果表征的想法
则是一种高阶心理状态
HOT理论为判断AI的意识也提供了四个指标
分别是，HOT-1
具有生成式、顶层驱动或者带噪声的感知模块
HOT-2
通过元认知监测来区分可靠感知和噪声
HOT-3
一个全面的信念形成和行动选择系统
依据元认知监测来更新信念
HOT-4
一个稀疏和平滑的编码形成「质感空间」。
如果一个AI系统具备这些特征
那么它更可能具备自我监测和意识体验
通过检测系统是否具备这些特征
我们可以评估一个AI系统拥有意识的可能性
论文中还详细列出了用到的其他科学理论指标
包括注意力基模理论（Attention Schema Theory）、预测处理（Predictive Processing）和代理与具身化（Agency and Embodiment）等
当然这一步并不是真的去给一个AI打分
而是要看这个AI能够同时满足以上多少指标
研究者同时也指出
判断AI有无意识并没有绝对的答案
为了方便起见
我们通常把意识写得好像是一个要么全有要么全无的问题
但是一个AI系统可能是部分有意识的
或者既不是完全有意识的
也不是完全无意识的
有许多属性具有“模糊”的边界
就像一件衬衫可能是介于黄色和绿色之间的一种颜色
这样就没有关于它是否是黄色的事实
此外，论文中也提到
此次研究使用了偏理论的研究方法
这其实也和计算功能主义的原则相对应
偏理论指的是去评估AI是否满足科学理论指标中的功能或者架构条件
而不是去寻找他们某些具体的行为特征
作者们认为，“对于AI意识研究来说
一种重理论的方法是必要的
重理论的方法是专注于系统如何工作
而不是它们是否显示出可能被视为有意识存在特征的外在行为形式”。
以上便是这篇论文用到的研究方法
论文的下半部分也提到了一些具体的研究案例
来体现判断特定的AI系统
是否具有意识的研究过程
其中就包括了基于Transformer的大语言模型和Perceiver架构
还分析了DeepMind的Adaptive Agent和谷歌的PaLM-E
其中Adaptive Agent是一个在3D虚拟环境中运行的强化学习智能体
而PaLM-E是一个经过训练可以操纵机器人的多模态视觉语言模型
我们之前也做过节目介绍
不过，最终结果显示
这些AI系统并没有体现出非常明显的有意识的倾向
同时，论文研究者也写道
我们研究的证据表明
如果计算功能主义是正确的
有意识的AI系统实际上可以在近期内建立起来
按照论文作者们自己的说法
这篇论文主要有三点贡献
首先
证明了对人工智能的意识进行评估在科学上是可行的
因为可以对意识进行科学研究
而且这项研究的结果也适用于人工智能
其次
通过一系列从科学理论中得出的指标特征的形式
提出了评估人工智能中的意识的标准
最后
尽管当前AI系统都不是意识有力的候选者
但是初步证据证明
许多指标特征可以利用当前的技术在AI系统中实现
论文发表后
英伟达首席AI科学家Jim Fan第一时间便转发了这一消息
并表示了他对研究团队的敬佩
他说道
意识一直都是AI领域大家讳莫如深的话题
这篇由图灵奖得主Yoshua Bengio参与撰写的88页论文
是对意识科学理论以及当今人工智能堆栈中
可能实现的系统调查
我赞扬他们有勇气去解决这个大多数研究人员都会回避的争议性话题
事实上
作为世界级的人工智能专家和深度学习先驱
Bengio近年来的研究课题
许多都和人工智能的意识问题相关
2017年
他曾在arXiv上发布过一篇题为《意识先验》（The Consciousness Prior）的文章
2019年的NeurIPS大会上
他又发表了《从System 1深度学习到System 2深度学习》的主题演讲
提出了一个在当时让人印象深刻的观点
就是深度学习正在从直观的、无意识的静态数据集学习
向具有意识、推理和逻辑的新型架构研究转变
而在今年3月
Bengio也参与了那场轰轰烈烈的、反对各家人工智能实验室搞AI“军备竞赛”、要求暂停至少6个月比GPT-4更强大模型研发的运动
和其他超过千名的产业和学术大佬一起在公开信上签了名
两个月后
他又发表了一篇系统分析“危害人类的AI是如何出现的”的文章
直到这次联合发表这篇长达88页的论文
Bengio一直都在不遗余力地做那个
想要警醒大家AI的未来该向何处去的人
就像这篇论文里写到的那句话
这篇报告还远未对AI有无意识的话题做出最终定论
我们强烈建议支持对意识科学
及其在AI中应用的进一步研究
我们也呼吁
社区应该尽快将建立有意识的、AI系统的道德和社会风险纳入考量
好了
以上就是对这篇论文内容的介绍
大飞我觉得它的意义在于
用一种相对科学的分析方式
证明了AI存在意识的可能性
甚至可以说是预言了它的到来
从而让我们更早的能去准备面对
我们既不能过度的漠视
AI存在意识的可能性
那样呢会让人类对AI的使用
可能就像是虐待动物一样
造成道德风险
也不能过度的认为AI具有意识
从而导致资源过度的向AI分配
所以呢如何对待AI
其实是整个人类
需要思考和面对的问题
就像是造物主一样
你造出了一个新物种
你该如何去看待它呢
是视他为蝼蚁还是视他为同类
是可以轻易的抹去它
还是要努力培育它的发展呢
欢迎大家在评论区发表自己的看法
感谢大家的观看
我们下期再见
