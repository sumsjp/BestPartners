大家好
这里是最佳拍档
我是大飞
不知不觉呢
距离GPT4的首次公开问世
已经过去一个月了
之前呢我们介绍过GPT4
作为一个多模态的大语言模型
它不仅能够生成文字的内容
还能够理解图像的输入内容
让用户直接与图片进行对话
在发布的时候
OpenAI向外界演示了GPT4是如何通过
一张手绘的草图
来生成一个网站的
让当时不少的这个围观群众
看的是目瞪口呆
不仅如此
它还能get到这个图像里的笑点
识别数学题目并且依次给出解答步骤
我始终觉得
图像对话才是GPT4
真正令人心神所往的地方
但是可惜的是
这个功能到现在仍然没有对外开放
除了像Be My Eyes
可汗学院等等少数几家
与OpenAI有合作的企业之外
大部分的人
还是只能体验GPT4文本的对话能力
原本我认为只能等OpenAI发布更新之后
才能体验上这个功能
那没想到呢今天看到了这样一个项目
项目的名称叫做MiniGPT4
是来自阿布杜拉国王科技大学
的几位博士做的
它能够提供类似于GPT4的图像理解
以及对话的能力
让你抢先一步感受到
图像对话的强大之处
那我们先来看一下它的演示视频
这个项目有几个特点
第一点就是多模态
也就是能够读懂图片
在这个示例中呢
它可以回答图片是关于什么内容的
有多少种颜色
甚至能够说明这个图片
是属于什么风格的
第二点
5个作者中有4个应该都是中国人
第三点 低成本
仅仅用了4块的A100
训练了仅仅10个小时
绝对称得上是迷你
第四点就是整个项目是开源的
项目的Github地址
我会放在视频的评论区供大家参考
另外呢
这个项目还非常良心的
提供了7个演示地址
也方便大家去体验
MiniGPT4呢
将BLIP-2的冻结视觉编码器
与冻结LLM Vicuna对齐
只使用了一个投影层
然后呢
开发团队用了两个阶段来训练MiniGPT4
第一个传统的预训练阶段呢
是使用了4个A100在10个小时之内
训练了大约500万对
对齐的图像和文本数据
第一阶段之后
Vicuna能够理解图像了
但是呢
它的生成能力受到了严重的影响
为了解决这个问题
并且提高整个模型的可用性
他们又提出了一种新的方法
即通过模型本身和ChatGPT一起
来创建一些高质量的图像文本对
那在这个基础上
他们创建了一个小型
但是质量很高的一个数据集
共有3,500对
那第二个微调阶段呢
就是在对话模板中
对这个数据集进行训练
从而显著的去提高
模型的生成的可靠性和整体的可用性
那令我们惊讶的是
这个阶段的计算教效率反而很高
用一台A100只需要7分钟左右
最终MiniGPT4
产生了许多新兴的视觉语言能力
与GPT4所展示的能力非常类似
比如说
对于这个示例中的粉红色的图标
如果我们询问MiniGPT4
对于这个图标的看法
他经过Vicuna理解之后会回答
这个标志的设计简单而简约
粉红色的线条
画了一只火烈鸟单腿站在水里
这个设计干净利落易于识别
适合在各种场合使用
例如海滩度假村的标志
或者以火烈鸟为主题的活动
使用火烈鸟作为符号
为设计增加了一些
奇思妙想和乐趣
令他令人难忘和引人注目
总的来说呢
这是一个精心设计的标志
它有效的传达了品牌的信息
这个内容应该说是
我们大家很多人都没法做到的
就是描述的很详细
那MiniGPT4这个算法模型呢
还可以进行本地化的部署
如果大家有兴趣呢
可以在评论区回复
有需要的话
我们可以给大家录一个安装和使用的教程
建议先体验一下在线的演示环境
那根据MiniGPT4的实验结果表明
GPT4的先进能力理论上可以归因于
它使用了更先进的大模型语言
也就是说
未来在图像声音视频等等领域呢
基于这些大模型所制造出来的应用
实际的效果呢应该都不会太差
这个项目也证实了
大语言模型在图像领域的可行性
接下来呢
相信应该会有不少的开发者跑步入场
将GPT4的能力进一步的
往音频视频等等领域延伸
让我们可以看到更多有趣
令人惊艳的AI应用程序
好了今天的分享呢就到这里
感兴趣的小伙伴们呢
欢迎订阅我们的频道
我们下期再见
