大家好这里是最佳拍档
我是大飞
现在呢国内有越来越多的公司
都想去跟这一波AI的浪潮
研究如何基于开源的大模型进行微调
打造一个支持中文的大语言模型
然后把它运用到自己的业务场景里面
但是一旦你开始动手
就会发现许多的问题
尤其是多语言方面
像OpenAI的GPT-4以及Google的PaLM2
虽然他们对多语言的支持已经做得很不错了
但是呢他们俩都是闭源的
而目前已经开源的大语言模型
主要也有以下几个痛点无法解决
第一个就是大多数是不能商用的
比如说Mata开源的LLaMA
以及基于LLaMA衍生的Vicuna等等
都是无法商用的
只能用于学术研究
当然国内一些不讲武德的这个做法
咱们不在讨论范围之内
那国内清华和智普开源的像ChatGLM的
模型权重它也是不能商用的
第二点呢就是对非英语的语言支持
一般大部分的开源模型
训练的语料呢都是以英文为主
非英语的对话效果都很一般
但是世界上有超过80%左右的人
是不讲英语的
那么如何解决这部分人的使用痛点
也是很关键的
在国内支持中文的对话是刚需
但是我们也试了一些开源的模型
中文的支持其实都非常一般
很少有能够达到可用的程度
不过最近
SambaNova与Together公司
联合推出了一个类ChatGPT的开源模型
BLOOMChat
不仅有1,760亿的参数
支持中文英文日文法文等等46种语言
还可以支持代码生成
包括Python Java PHP
Ruby C++等等13种编程语言
它的许可呢也是基于Apache 2.0的
所以可以用于研究和商业使用
那与目前市面上大多数的
同类的开源模型相比呢
BLOOMChat在预训练数据 指令调优
功能扩展 AI对齐等方面拥有很大的优势
对于企业和个人开发者来说
无论是用于商业化的项目
还是技术研究
都是一个不做的选择
那我们接下来呢
就详细介绍一下这个BLOOMChat
这个BLOOMChat模型呢
它的思路来
源于之前的一些工作的启发
就是在一个语言中进行指令的微调
可以提升多语言模型
在另一种语言中的效果表现
所以呢他们就使用了OpenChatKit
olly 2.0以及OASST1
这些以英文为主的数据训练集
然后呢在这个BigScience
在2022年7月份开源的大语言模型BLOOM上
进行了微调
所以BLOOMChat也算是一个组合的模型
通过将市面上最强大的开源模型
与海量的数据训练集相融合
属于这个开源界的变形金刚了
BLOOMChat是在SambaNova提供的AI计算平台
RDUs上进行训练的
由各个语言的native speaker
也就是母语说母语的人
来评测模型的回答效果
从BLOOMChat发布的测试数据来看
与GPT-4相比
在英文中文法语等6种语言的人工评估中
BLOOMChat的响应首选次数为45.25%
较弱于GPT-4
在同样是6种语言的环境下
BLOOMChat与OpenAssistant
LLaMA-Adapter
以及BLOOMZ等等这些开源模型去相比
BLOOMChat的响应在65.92%
成为最佳的开源产品
尤其是在中文的领域
国外的大多数的开源的类ChatGPT模型呢
几乎都不支持中文
即便是支持中文
但是它使用的训练数据集也是非常少的
在回答问题方面
非常容易出现生硬老套而且出错的这种情况
但是根据BLOOMChat所展示的中文示例来看
它对中文的回答的逻辑词语的搭配
丝滑程度几乎可以与ChatGPT相媲美
BLOOMChat的翻译能力也非常出色
根据他在多个翻译任务上的表现来看
BLOOMChat仅比GPT-4差一点
比OpenAssistant
LLaMA-Adapter BLOOMZ这些开源模型的性能呢
要高出一大截
BLOOMChat用来微调的指令数据有两类
第一类是由程序自动合成的对话数据集
OpenChatKit
它的数据量很大
而且呢这个训练数据集
本身就是由Together公司
联合其他两家公司开源出来的
第二类呢
是人工写出来的高质量问答数据集
Dolly 2.0和OASST1
数据量呢比较小
这个微调呢也是分两步进行的
第一步对OpenChatKit的每个数据源
按照100K的数据量进行采样
然后训练一轮
这是因为OpenChatKit它包含了多种的数据源
而且呢数据量比较大
所以对OpenChatKit的每个数据源
就要先进行采样
得到很多的子数据集
然后再完整微调一遍所有的子数据集
第二步呢
是对Dolly 2.0和OASST1
结合在一起的数据集
做三轮的微调
不过呢与大多数的聊天语言模型一样
BLOOMChat也有一些局限性
第一点就是存在幻觉的现象
这是所有大语言模型现在的通病
第二点呢
可能在单个回复中
会无意的去切换语言
影响输出的连贯性和可理解性
第三个呢
可能会产生重复的短语或者句子
导致回复的内容
缺乏吸引力和有效的信息
第四点呢
在生成代码或者是解决复杂数学问题方面的效果
还相对比较一般
第五点呢
可能会无意中生成
含有不适当或者是有害的内容的回复
那介绍完模型呢
我们再简单介绍一下
推出这个模型的背后两家公司
Together是一家AI的开源厂商
前不久呢刚刚获得了2,000万美元
大约1.4亿元人民币的种子轮融资
他的开源产品RedPajama-INCITE
具备性能强资源消耗低的特点
普通的笔记本就能跑
此外Together还曾经完美复制了
LLaMA模型上的训练数据集
按照他的论文的数据模式呢
从维基百科 Github等等这些数据来源
抓取了1.2万亿的训练数据
并且进行了开源
而SambaNova是一家企业级的生成式AI平台
为金融销售政务医疗保险
制造汽车等等行业
提供从模型数据预训练
指令调优 本地部署
特殊的场景化部署
运维等等一站式的解决方案
他的产品已经在金融医疗制造等等领域
实现了场景化的落地
所以呢这次SambaNova与
Together联合推出的BLOOMChat模型
与之前这些大部分学术机构推出的开源模型相比
在技术层面的有很大的优势
因为他们不仅有着实际项目落地的经验
而且能够得到客户的实时反馈
这对于BLOOMChat的功能迭代
安全防护这方面呢都有着巨大的帮助
总结一下
BLOOMChat是一个完全开源的
参数超千亿
专门针对于多语言支持的对话大语言模型
大家如果在实际中呢
有自己去构建大语言模型的需要
不妨拿BLOOMChat试一试
也许就会有一些意想不到的惊喜
那这个模型所有的相关的数据集
和代码包括微调和推理的脚本
都免费开源在了他的Github上面
我们呢也会把相关的地址链接
放在视频的说明和评论区里
好了今天的分享呢就到这里
感兴趣的小伙伴们
欢迎订阅我们的频道
我们下期再见
