大家好，这里是最佳拍档
刚刚
谷歌发布了最新模型 Gemini 3 Flash
它专门为速度而生
可以帮助每个人更快地学习
构建和规划任何事物
早在模型发布前
Google AI Studio开发者平台和Gemini API 的产品负责人Logan Kilpatrick
就在 X 上发布了一条只有三个闪电符号的推文
当时就有大批网友猜测
这意味着谷歌即将发布主打速度至上的 Flash 版本模型
果然
谷歌 Gemini 3 Flash 模型如约而至
过去一年，从 Gemini1.5到3.0
谷歌持续强化在多模态
长上下文和推理能力上的技术纵深
同时也在不断压低模型的调用成本
试图在企业级应用和开发者生态中
建立更加具有性价比的护城河
在这个背景下
主打高性能与低延迟的Flash系列
被视为Gemini体系中
最贴近真实业务场景的一条产品线
随着外界对更快
更便宜和更易部署的模型的呼声不断升高
谷歌今晚发布的Gemini Flash 3
也被普遍认为
是谷歌在推理效率和规模化的落地层面的
一次关键落子
谷歌称，从今天起
Gemini 3 Flash将面向全球数百万用户推出
包括 Google AI Studio、Gemini CLI和Google Antigravity中的Gemini API开发者
并且所有用户都可以通过Gemini应用和AI模式
在搜索中使用
同时
Vertex AI 和Gemini Enterprise的企业也可以使用
那么，这款模型性能到底怎么样呢？
根据谷歌在官网的介绍
Gemini 3 Flash速度和规模
无需以牺牲智能为代价
它在博士级别的推理和知识基准测试中
都展现出了前沿性能
比如GPQA Diamond达到了90.4%，
Humanity's Last Exam在不使用工具的情况下
达到了33.7%，相比之下
Gemini 3 Pro的得分为37.5%，
Gemini 2.5 Flash的得分为11%，
而最新发布的GPT-5.2的得分为34.5%，
这说明
Gemini 3 Flash足以媲美规模更大的前沿模型
并且在多项基准测试中
显著超越了目前最佳的2.5版本模型
Gemini 2.5 Pro
此外，它在 MMMU Pro测试中
也取得了令人瞩目的 81.2% 的成绩
与 Gemini 3 Pro 的性能相当
除了前沿的推理能力和多模态处理能力以外
Gemini 3 Flash的设计目标是
极高的效率，从而突破质量
成本和速度之间的帕累托极限
在最高思维水平下进行处理时
Gemini 3 Flash能够灵活调整其思考时间
对于更复杂的应用场景
Gemini 3 Flash可能需要更长的思考时间
但是根据测试结果
它平均使用的token数量比 2.5 Pro要少 30%，
从而能够以更高的性能
更准确地完成日常任务
在定价方面
Gemini 3 Flash相比前几代模型
更加具有性价比
Gemini 3 Flash 的定价为
每百万个输入token 0.50 美元
每百万个输出 token 3 美元
音频输入价格
仍然为每百万个输入 token 1 美元
虽然这看上去
比 Gemini Flash 2.5 的每百万个输入token 0.30 美元
和每百万个输出token 2.50 美元略贵
但是谷歌声称
新模型的性能优于 Gemini 2.5 Pro
速度更是它的三倍
而且在处理思维任务的时候
它平均比2.5 Pro 少用30%的token
这意味着，在某些任务中
用户可能会节省总体使用的 token 数量
在编程性能上
Gemini 3 Flash 拥有 Gemini 3 专业级的编码性能
同时延迟极低
能够在高频的工作流程中
快速的推理和解决任务
在用于评估编码能力的基准测试SWE-bench Verified中
Gemini 3 Flash的得分高达 78%，
不仅超越了2.5系列
甚至超越了Gemini 3 Pro
它在Agent编码，生产就绪系统
和响应式交互式应用程序之间
实现了一个理想的平衡
此外，Gemini 3 Flash在推理
工具使用和多模态功能方面的强大性能
非常适合希望进行更复杂的视频分析
数据提取和视觉问答的开发人员
这意味着它可以实现更智能的应用
比如在强调手部追踪的发射球益智游戏中
实现多模态推理
提供近乎实时的AI辅助
还可以近乎实时地构建和进行A/B测试
新的加载旋转器设计
从而简化从设计到编码的过程
甚至使用多模态推理
来分析图像并且添加上下文UI叠加层
几乎可以实时地
将静态图像转换为交互式体验
哪怕只接受一条指令提示
也可以编码出三种独特的设计变体
此外，值得一提的是
Gemini 3 Flash也开始作为搜索中
AI 模式的默认模型推出
全球用户都可以使用
基于 Gemini 3 Pro的推理能力
Gemini 3 Flash的AI模式
能够更加有效地解析用户问题的细微差别
它会考虑用户查询的每一个方面
提供周全而且易于理解的答案
同时从网络各处
提取实时的本地信息和实用链接
最终
它能有效地将研究与即时行动相结合
用户将获得一份条理清晰和条理分明的分析报告
以及具体的建议
谷歌表示
它们对Gemini Flash的定位
更偏向于一个主力机型
而非高端的展示型模型
Gemini Models的高级总监兼产品负责人Tulsee Doshi
在接受TechCrunch的简报时指出
如果对比价格表中输入和输出的定价
可以明显看到Flash在成本上要低得多
这让它更适合承担大规模和批量化的任务处理需求
能够切实帮助企业降低使用门槛和整体成本
自从Gemini 3发布以来
谷歌在API上的处理规模迅速放大
目前每日处理的token数量已经超过了1万亿个
同时，谷歌也正与OpenAI展开一场
围绕着新品发布节奏和模型性能的正面竞争
本月初
随着谷歌在消费者市场的份额上升
ChatGPT的整体访问量出现下滑
OpenAI CEO Sam Altman因此向内部团队发出了一份
被称为红色警报的备忘录
随后
OpenAI 接连发布了GPT-5.2以及新的图像生成模型
并且强调它们在企业级应用的需求持续增长
OpenAI还披露
自二零二四年十一月以来
ChatGPT的消息量已经增长了大约 8 倍
尽管谷歌并没有直接回应与 OpenAI之间的竞争关系
但是大家普遍认为
新模型的密集发布
正在推动整个行业加速前进
Doshi也表示，目前整个行业的状态是
各类模型都在快速的演进
相互竞争，并且不断突破性能边界
同样令人印象深刻的是
各家公司都在非常积极地推出新模型
她同时提到
谷歌也在持续引入新的基准测试体系
和模型评估方法
这个趋势本身
也让团队对行业的发展感到振奋
谷歌的新模型发布后
在全球引发了热烈讨论
在X和Reddit 等平台上
大量开发者与技术爱好者对Gemini 系列模型
特别是Flash版本
都表达了多元的观点
在X上
有些用户使用过Gemini 3 Flash后
认为它的准确度几乎与 Gemini 3 Pro不相上下
但价格更低，速度更快
Browserbase的创始人Paul Klein IV在X上发文称
他们提前获得了 Gemini Flash的访问权限
当真正用起来的那一刻
他们都惊呆了
在Reddit上，也不禁有用户感叹
真是太疯狂了
还有用户表示
从没见过能力这么强的轻量级模型
但是也有用户指出，基准测试的成绩
并不能说明它在真实场景中也同样表现出色
尤其是在实际应用中
使用场景往往非常多样化
远比那些单轮对话的基准测试样本更为复杂得多
尤其是对比Gemini 3 Pro和Opus 4.5
这两款模型本身都非常出色
但是如果只看基准测试
Gemini理应整体表现更强
可在实际使用中它却一次次令人失望
相反，Opus 4.5却不断带来惊喜
不过，也有用户认为
谷歌最近几次的发布
已经充分彰显了行业领头羊的地位
OpenAI似乎已经被拍在沙滩上了
那么大家是怎么看这次谷歌新模型的发布呢
欢迎在评论区留下自己的使用体验
感谢收看本期节目，我们下期再见
