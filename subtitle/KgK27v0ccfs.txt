大家好，这里是最佳拍档，我是大飞
距离OpenAI Sora发布正好两个月的时间了
这期间可谓是闹得沸沸扬扬
虽然各大网友、专家是纷纷点评
但是很少见到Sora的作者亲自下场解读
不过好在4月7号
人工智能社区AGI House邀请到了Sora的核心作者Tim Brooks和Bill Peebles
对Sora进行了一次分享
不仅介绍了Sora的目标、方法和一些技术细节
还有Sora的最新进展
以及Sora面临的主要挑战等等内容
二人更加认为，Sora不仅能模拟一切
还是前往AGI的一辆直通车
今天
我们就来看看Sora的两位作者都说了什么
首先开场的是Tim Brooks
他也是文生图模型DALL·E 3的作者
去年1月份刚从加州大学伯克利分校博士毕业
但是他在本科到博士期间
已经在Facebook、Google和英伟达都实习了一遍
Tim上来就把Sora最经典的视频
Tokyo walk
给观众播放了一遍
Tim表示
这个视频对Sora团队来说非常特别
因为它是一分钟的高清视频
这也是团队一直以来的目标
当他们试图寻找什么能够推动视频生成技术前进的时候
确定了生成长度为一分钟的1080p视频
会是一大里程碑
而这个视频证明他们达到了目标
这段视频包含了许多复杂的元素
比如反射和阴影
其中有个非常有趣的地方
是视频中出现的那个蓝色标志
在画面中
一位女性角色正在穿越这个标志
而即使在她走过之后
该蓝色标志仍然保持原位不动
这对于视频生成技术来说是一个巨大的挑战
就是保持物体的持久性和长时间的一致性
Sora不仅能做到这一点
还能够生成多种不同风格的视频
确实神奇
此外，Tim表示
Sora也能理解整个三维空间
摄像机能像人一样在三维空间中移动
而且它深刻理解了世界的几何和物理复杂性
除了能够生成内容外
它实际上还从所训练的视频中
学习到了很多关于物理世界的知识
在展示了一系列早已火爆全网的Sora演示视频后
Tim开始讲起了之前那篇题为“Sora初体验”的博客文章
文章中分享了多个获得Sora使用权的艺术家们的创作成果
比如Shy Kids利用Sora制作的“气球人”短片
这些作品充分展示了艺术家们如何利用Sora技术
来表达独特的世界观和生活哲思
Tim希望Sora能够进一步促进内容创作的普及化
帮助更多富有创新精神的个人
轻松地将自己的创意转化为实际作品
并与全世界共享，他说道
Sora并不是像ChatGPT那样的通用型AI产品
而是一个专注于探索技术边界、价值及安全性的研究项目
通过与包括红队在内的多方合作伙伴共同测试
团队希望能够深入理解并确保这项技术的安全可靠
Tim在演讲中还引用了强化学习之父Rich Sutton在《苦涩的教训》（The Bitter Lesson）中的观点
那就是在AI发展的道路上
依赖于计算能力的通用方法最终会胜出
并且这种优势会随着计算资源的指数级增长而越发显著
在《苦涩的教训》原文中
Sutton援引了计算机国际象棋、计算机围棋、语音识别领域和计算机视觉等领域的多个案例
来证明这一观点
指出人工智能研究者常常试图模仿人类思维模式来构建AI系统
这种做法在短期内可能奏效
但是从长远看会限制技术的进步
而真正的突破性成果
来自于那些能够利用大规模计算进行搜索和学习的方法
因此，苦涩的教训在于
过分追求将人类知识内化进AI系统
可能会导致错过真正推动领域发展的路径
如果想要了解《苦涩的教训》全部内容
大家可以去看我们之前的一期节目
在此基础上
Tim认识到了算力的重要性
他认为随着时间的推移
我们拥有的算力也在不断增加
如果有一种方法能够充分利用这一点
那么它就会变得越来越好
随后Tim讲解了一些有关Sora的技术细节
他指出，语言模型成功的原因
就在于它能够扩展的能力
通过将所有形式的文本数据转化为统一的Token表示
并使用Transformer模型进行训练
从而形成了能够处理多种任务的深度语言模型
像ChatGPT这些模型
因为能够吸收并理解大量多样化的文本数据
所以展现出了强大的泛化能力和广泛应用前景
为了对视觉数据实施类似语言模型的处理方式
Sora将不同格式、分辨率、纵横比的视频和图像
切割成了空间时间中的碎片
也叫patch，类似于积木一样
然后在这些碎片上训练Transformer模型
这种做法使得模型能够适应不同维度和格式的视觉内容
并且能够随着计算能力和数据量的增加
不断优化性能
进而生成不同纵横比的高质量视频内容
Sora模型还支持零样本学习
可以将一段视频转换为另一种样式或者内容的视频
通过利用扩散模型和SD编辑技术
Sora能够在保持原始视频结构的基础上
进行创造性的编辑
比如风格迁移、场景变换等等
模型还能实现视频间的平滑过渡
创造出生动自然的效果
随后，Tim通过一系列的示例
展示了模型如何创造性地
将迥异的视觉素材无缝融合在一起
比如无人机视角与水下蝴蝶、罗马斗兽场与水下环境、地中海景观与姜饼屋等等
体现了模型对视觉内容深度理解和创造性重组的能力
Tim还展示了一个很酷的应用
比如用DALL-E 3生成这张图像
然后用Sora让这个图像动起来
此外，模型还可以进行延长视频
或者动态化静态图像等等有趣的操作
展示了模型在视觉内容生成与编辑方面的巨大潜力
目前Sora还处于初级阶段
所以Tim也鼓励大家去深入了解更多的技术和应用案例
接下来
讲解AGI的部分接棒给另一位核心作者
Bill Peebles
Bill大名William，本科就读于MIT
主修计算机科学
参加过GAN和text2video的研究
他还在英伟达深度学习与自动驾驶等团队实习
研究计算机视觉
Bill首先强调了以Sora为代表的视频模型
在通向通用人工智能AGI路径上的重要性
他认为视频模型的发展对于模拟人类互动、理解物理世界以及捕捉复杂情境至关重要
通过Sora的表现
团队已经观察到模型在处理和生成复杂视觉场景方面的进步
包括对人类活动、动物行为
以及其他智能体在三维空间中的互动的模拟
Bill还提出了和Tim同样的观点
那就是这里面的关键和大语言模型是一样的
那就是扩展性
随着计算资源的增加
模型展现出了更强的理解和生成能力
比方说从无法识别狗
到能够生成包含狗在内的精细场景
再到模拟动物的行为细节和3D环境的一致性
Bill指出
Sora在没有经过直接编程的情况下
通过自我学习逐渐理解了3D几何结构
这是模型涌现能力的一个体现
此外，Sora在处理物体持久性问题上
也取得了显著进展
这意味着在连续生成的视频中
同一物体在不同时间点的状态能够得到恰当的延续
尽管目前在模拟某些物理交互上仍然有所不足
比如处理较为复杂的力学现象
但是Sora已经在模拟现实世界和虚拟环境的物理规则方面
迈出了重要的一步
Bill甚至把Sora看做是视频版的GPT-1
虽然当前Sora还存在着局限性
以及在面对某些复杂物理交互时
存在许多挑战
尽管如此
Sora团队对未来的发展依然充满信心
认为随着研究的深入和模型的迭代
视频模型将极大地推动通用人工智能领域的发展
随后二人回答了观众的几个问题
首先关于AI智能体在场景中的理解和互动
这部分信息在Sora中其实是隐含处理的
以Minecraft为例
团队并没有显式地定义
智能体在哪里去模拟玩家行为或者与环境互动
大部分机制都是隐性的
比如3D信息、场景元素等等
这些都不是显式编码的
而是通过模型自我学习获得的
也就是说
我们所见到的所有Sora的酷炫功能
其实都是从模型中推断出来的
而非直接指定
虽然现在Sora还不能针对特定内容来进行模型微调
但是如果有针对性的数据集
也就是用户希望模型去适应的内容
理论上是可以进行微调的
这也是团队在积极努力的一个方向
第二个问题与模型的实现有关
Sora采用的是扩散模型
而不是自回归Transformer
这意味着它不是通过语言模型的方式来进行逐帧预测
而是从一个全噪声视频开始
通过迭代模型来逐步消除噪声
直至得到清晰的样本
在这个过程中
Sora并没有严格遵循“扫描线顺序”，
或者其他固定的空间顺序
而是能够同时对视频中的多个时空区域
进行去噪处理
大部分情况下
Sora会一次性对整个视频进行全局去噪
不过还有另一种可选方案
也就是先生成较短的视频片段
随后根据需要再进行延展
现阶段
Sora的主要用户反馈来自于合作的外部艺术家
一方面
艺术家们渴望获得更多的创作控制权
例如对相机视角和运动轨迹的掌控
另一方面
团队需要确保在让更多人接触到这款工具的同时
保证Sora的安全性和责任性
防范潜在的滥用风险和虚假信息生成等问题
为了评估Sora生成的视频
团队采取了多种评估手段
包括但是不限于模型的损失值
利用图像质量指标对单帧进行评估
同时也投入大量时间手动审查生成的样本
尤其需要注意的是
这个评估过程不是针对于单一的提示词
而是涉及到大量提示词和对应输出的综合比较
因为输出结果可能存在随机噪声
最后
Bill对于AGI的道路表达了满满的信心
他认为目前拥有的数据量
足以实现通用人工智能
并且随着技术的进步
每当遭遇数据限制时
我们总能找到新的方式来提升模型性能
因此
无论目前手上拥有什么样的数据
只要我们持续创新和改进
就能够支撑起通用人工智能的研发之路
好了
以上就是Sora作者这次分享的主要内容
大飞我完整视频看下来
感觉对技术细节的深入探讨并不多
更多的还是在宣传Sora的发心、特性和愿景
尤其是对于Scaling Law和通往AGI的坚定信念
并没有重点解答网络上对于Sora的质疑
略微有些小失望
其实Sora发布后，最多的质疑声音
就是Sora到底是否理解了现实的物理世界
至少从Sora目前发布的视频来看
现在的技术路线还是无法处理相关性与因果性的矛盾
也无法处理局部合理与整体荒谬的矛盾
虽然可以生成稳恒态的视频片段
但是往往无法处理临界态的流形边界
所以以Yann LeCun为代表的一派
一直在诟病Sora根本无法理解真正的物理世界
当然Tim和Bill也没有拿出非常可信的理论依据
只是以生成的演示视频来证明
确实缺少信服力
也存在着夸大的嫌疑
不过，如果站在Sora作者的角度
我却又能有些理解
当你通过不断地扩大算力
看到模型从狗屁都生成不了
到逐渐能生成人物、画面、动作、交互、物理关系甚至分镜转换
这种冲击其实是很震撼的
你会从怀疑Scaling Law
到相信Scaling Law
再到信仰Scaling Law
正像苦涩的教训里说的
不相信Scaling Law的人终会被打脸
现在的AI发展
确实有点开始向着信仰之战演变了
一边在使劲的堆砌算力
一边在努力尝试用小模型打败大模型
但是不管怎么样
大飞我觉得对于所谓的通用人工智能AGI
我们还是应该多保留一些敬畏之心
不要轻易断言达到了AGI，要知道
OpenAI在ChatGPT出来之前
也没有几个人相信Scaling Law的
这也是对我们人类自己的敬畏和反思
在这个过程中
我们追求的
究竟是真正全人类的福祉
还是一个又一个虚无缥缈的幻念呢？
感谢大家观看本期视频
欢迎大家在评论区发表自己的看法
我们下期再见
