大家好，这里是最佳拍档，我是大飞
最近一段时间
AI界掀起了一场关于大语言模型能否通向AGI的激烈争论
一边是以OpenAI、Google等为代表的企业界
他们坚信当前的模式和Scaling Laws能够实现AGI；
另一边是以Richard Sutton、Gary Marcus、Yann LeCun等为代表的学术界重量级人物
他们对此提出了尖锐批评
Sutton认为
当前的大语言模型过度依赖人类的标注数据
缺乏真正的学习机制；
而Marcus则反复指出大模型的推理能力存在根本缺陷
只是随机鹦鹉
LeCun更是直言
单纯大语言模型永远无法达到人类水平的智能
双方争论不休
各自都有充分的论据支撑
然而，这场争论持续至今难有定论
根本原因就在于一个关键的问题
AGI的定义究竟是什么？
虽然大家都大致认同
达到人类水平的智能就是AGI这个表述
但是AGI具体应该包含哪些维度？
如何客观评估？
这些关键问题却一直模糊不清
也正是这种定义上的模糊性
让不同阵营都能为自己的观点找到支撑
为了解决这个问题，10月16日
AI三巨头之一
图灵奖得主约书亚·本吉奥领衔的豪华国际研究团队
发表了一篇重要论文《AGI的定义（A Definition of AGI）》，
试图为这个模糊的概念做迄今为止最清晰的定义
文章的27名作者涵盖了人工智能领域
特别是AI安全、伦理方向的全球顶级学者、研究员和行业领袖
包括AI安全中心的主任丹·亨德里克斯Dan Hendrycks
加州大学伯克利分校计算机安全、隐私保护领域的顶尖专家宋晓冬Dawn Song
DDN之父克里斯蒂安·塞格德Christian Szegedy
斯坦福HAI的主任埃里克·布林约尔松Erik Brynjolfsson
未来生命研究所（FLI）的创始人马克斯·泰格马克Max Tegmark
以及谷歌的前CEO埃里克·施密特Eric Schmidt和Skype的联合创始人让·塔林Jaan Tallinn等等
他们得出的结论
基本和当下大语言模型是否能通向AGI的争论一致
在新的AGI定义下
像GPT-5这样的顶尖AI
在AGI应该具备的一半左右核心维度上表现极佳
但是在另一半上表现极差
少数维度得分基本为0
而这些偏科的维度
正好与大语言模型批评者所提到的能力缺失
完全相符
今天我们就来解读一下这篇论文
看看究竟应该如何来重新定义AGI
论文开篇就为AGI给出了一个清晰而直观的定义
AGI是一个在认知通用性（versatility）和熟练度（proficiency）上
能够达到、或者超过一个受过良好教育的成年人水平的人工智能
其中，通用性
也就是广度
它强调的是AGI不能是偏科生
真正的通用智能需要在广泛的认知领域都具备能力
而不仅仅是在单一或者少数几个任务上表现出超人水平
其次，熟练度，也就是深度
指的是在每一个认知领域
AGI的能力都需要达到一定的深度
也就是受过良好教育的成年人的水平
这排除了那些只能完成表面任务、缺乏深层理解的系统
通过锚定受过良好教育的成年人
这个现实世界中唯一的通用智能范例
新的AGI定义成功地将一个抽象的概念
转化为了一个可供参考和测试的实体
有了这个定义
接下来的逻辑就很清晰了
既然AGI的定义是达到人类水平
那么衡量AGI的最佳方式
就是用一个能够衡量人类智能的最科学、最全面的蓝图
还好，这个蓝图有现成的
它就是卡特尔-霍恩-卡罗尔（Cattell-Horn-Carroll）理论
简称CHC
CHC理论是由雷蒙德·卡特尔首先提出的
在1993年经过约翰·卡罗尔系统地回顾和重新分析了自20世纪30年代以来的460多项认知能力
研究修正整合形成的一个智力理论
因此，它是近一个世纪以来
科学家通过对成千上万人的大量认知能力测试数据
进行统计学上的因素分析（factor analysis）最终综合而成的
目前在心理测量学界最受认可、证据最充分的人类智力结构模型
CHC理论将人类的认知能力
描绘成一个三层级的金字塔结构（Three-Stratum Structure）
顶层 (Stratum III)， 一般智力因素
也叫g因子，这是金字塔的塔尖
代表了一种普遍的、贯穿所有认知活动的智力能力
这可以理解为大脑处理器的核心算力
中层 (Stratum II)，十大广义能力
这是CHC理论的核心
它将一般智力分解为大约10个相对独立的广义能力
是构成我们智能的主要模块
底层 (Stratum I)，
包括大约80多种狭义能力
这是金字塔的基座
也是最具体的能力层
每一个广义能力都由多种更具体的狭义能力构成
比如，晶体智力 (Gc)，
可以进一步分解为词汇知识、通用信息等等
流体智力 (Gf)可以分解为归纳推理、演绎推理等等
可以说，这篇重新定义AGI的论文
基本上就是对这个金字塔结构的改编和操作化
按照CHC的十大广义能力
AGI的能力也被分为十大方向
每个方向会平均占有AGI满分评分中的10分
其中，通用知识 (K)，
表示对世界常识、科学、历史、文化等事实的理解
读写能力 (RW)，
表示理解和生成书面语言的熟练度
数学能力 (M)，
涵盖算术、代数、微积分等领域的知识与技能
即时推理 (R)，
在不依赖先验知识的情况下
解决新颖问题的能力
比如演绎与归纳
工作记忆 (WM)，
指的是在注意力中主动保持、处理和更新信息的能力
即短期记忆
记忆存储 (MS)，
指的是从经验中持续学习、巩固和存储新信息的能力
长期记忆检索 (MR)，
指的是精准、流畅地从记忆中提取知识
并且避免产生幻觉的能力
视觉处理 (V)，
能够感知、分析、推理和生成图像、视频等视觉信息的能力
听觉处理 (A)，
能够识别、区分和处理声音、语音、音乐等听觉刺激的能力
速度 (S)，
能够快速、自动化地执行简单认知任务的能力
他们有的是融合了部分CHC的十大广义能力
有的直接就是一一对应的，最终
这十个方向完整覆盖了CHC理论的所有领域
和由CHC理论转化出的智商量表一样
它还具备极高的可操作性
论文为每一个大项下的各个分项
都提供了具体的定义、测试样例
甚至是现有的公开数据集作为参考
这样一来
任何研究者都可以依据这个蓝图对AI系统进行评估
不过，CHC量表本身就是个复杂量表
到底应该取什么值
作为AGI100分的标准呢？
文章给出的结论是，这个标准非常高
它定义了一个理想化的、认知能力全面发展
而且高度熟练的个体
100%的AGI分数所代表的
是一个高度熟练的（highly proficient）、在所有被测试的维度上都达到了精通（mastery）水平的个体
但是这个精通的意思
并不是将所有受过良好教育的人的顶尖技能聚合在一起
它不要求AGI同时拥有爱因斯坦的物理学能力、莫扎特的音乐天赋和莎士比亚的文学才华
相反
它衡量的是一个个体可能达到的、在认知上全面且强大的能力水平
那如果用这个新的AGI标准
去衡量当今最先进的AI模型
它们的表现又会如何呢？
论文的评估结果显示
当代AI的能力发展
呈现出了一种极不均衡的犬牙交错的认知剖面图
根据论文的评估
GPT-4的AGI总分为27%，
而GPT-5的总分可以达到58%
不过总分虽然翻倍了
但是进步却非常的不平均
AI的强项在于那些可以从海量数据中直接学习的领域
比如说
在通用知识（K）、读写能力（RW）和数学能力（M）上
模型表现出了极高的熟练度
这与大家的普遍认知是相符的
大语言模型是一个强大的知识库和文本处理工具
但是
在长期记忆存储（MS）这类能力上
无论是GPT-4还是GPT-5
在这一项上的得分均为0%。
这意味着
目前的AI系统患有严重的失忆症
它们无法从与用户的持续互动中积累经验、形成个性化的记忆或者修正错误
每一次对话都是一次冷启动
这从根本上限制了它们成为真正的智能伙伴或助手
而且在速度的提升上
也基本是裹足不前
此外
在即时推理（R）、视觉推理（V）、听觉处理（A）等需要灵活、抽象思考和深度理解物理世界能力的领域
现有的模型也存在严重的短板
尽管GPT-5在这些方面表现出了显著的进步
但是相较于100%达标，仍然很远
此外
研究团队还对这十大方向的能力
进行了更加细致的拆分
然后基于这些更细微的分项
团队考察了GPT4和GPT5的得分
从结果中我们可以更清晰的看到
即使是当下最强大的模型GPT-5
依然存在明显的短板
除去GPT4和GTP5都有的长期记忆问题以外
我们还能发现
当前模型最大的短板有三点
分别是不可靠，没有主动学习能力
以及对世界的浅薄认知
首先，在长期记忆检索 (MR) 模块下
有一个名为幻觉的关键分项
GPT-4和GPT-5在这一项上的得分同样是 0%。
虽然GPT5号称大幅减少了幻觉率
但是相较于人类
它的幻觉水平依然过高
这就使得AI在不借助外部工具的情况下
成为了一个完全不可靠的信息来源
论文指出
目前业界广泛使用的检索增强生成（RAG）技术
正是一种掩盖这个核心缺陷的能力扭曲
其次，在即时推理 (R) 模块中
即使是大幅进步的GPT-5
在名为适应的分项上也得到了 0% 的分数
这项能力是通过人类智力测试常用的
威斯康星卡片分类测验来进行评估
要求Agent在规则被悄悄改变后
能够放弃旧的规则、适应新的规则
AI的失败表明
它擅长在固定规则下执行任务
但是当环境发生未经明确告知的变化时
它会表现出极端的认知僵化
无法灵活调整策略
因此，当前的AI缺乏一种元认知能力
很难意识到自己当前的方法不再有效
这种僵化在动态、开放的真实世界中将是致命的
限制了AI自主解决复杂问题的能力
这也正对应了Sutton的批评
第三，在视觉处理 (V) 上
GPT-5虽然能在感知和生成上得分
但是在更高级的视觉推理和空间扫描上
得分为 0%。
这意味着它虽然能够识别图片里有什么
但是无法理解复杂的空间关系
或者进行心理旋转等抽象的视觉推理
在听觉处理 (A) 上
GPT5也能很好地进行语音识别和语音合成
但是在理解语言声音底层结构的音素编码和节奏能力上
得分同样为 0%。
这说明即使GPT-5的多模态能力有较大的进展
但是它还是停留在输入/输出的表面层次
并没有能够理解物理规律、空间逻辑的世界模型
换句话说
它打开了连接物理世界的窗户
但是还远远没有理解窗外的风景
而这正是Sutton和Yann LeCun批判的第二点
从这些更细分的评价来看
反大语言模型联盟的批评确实是一针见血
通过刚才的AGI建模
我们可以看到当下模型的许多短板
但是在日常使用中
我们经常有一种GPT很懂我
AI真的无所不知的感觉
为什么呢？
这篇论文也对此做了解释
它提出了能力扭曲（Capability Contortions）这个概念
现在的AI系统
常常会利用它压倒性的优势能力
比如巨大的工作记忆和计算速度
来掩盖或者绕过它基础能力的根本性缺陷
从而制造出一种看似通用的脆弱假象
文章主要提到了两种能力扭曲的问题
它们都是试图用取巧的办法
尽可能的掩盖得分为0的长期记忆短板
第一种是用工作记忆来伪装长期记忆
模型通过支持越来越长的上下文窗口
来处理海量的信息
但是这本质上是工作记忆的暴力延伸
而非真正的长期记忆存储
用户需要将历史信息反复喂给模型
这种方式不仅计算成本极高、效率低下
而且当任务时间跨度超过上下文窗口的限制时
就会彻底失效
第二种是用外部搜索来伪装成内部记忆检索
为了解决幻觉的问题
模型普遍会采用检索增强生成（RAG）技术
在回答问题之前先从外部数据库中搜索相关的信息
论文一针见血地指出
它掩盖了模型在两个层面的记忆缺陷
一是无法精准、可靠地
从自身庞大的参数知识中进行检索；
第二个更关键的是
它完全没有一个动态的、可更新的、用来记录个体经验的私有记忆库
因此，不能仅仅因为一个模型
能够在某些任务上表现出色
我们就误认为它具备了底层的通用智能
只有识别并且解决这些被掩盖的根本性缺陷
才是通往AGI的正途
总的来说
这个AGI定义框架最重要的价值在于
它将一个长期模糊的概念
转化为了具体可测的指标
无论是支持还是反对当前AI发展路径的人
都有了一个共同的讨论基础
当然，这个框架也有一定的局限性
研究者也承认
当前的测试主要是基于英语和西方的文化体系
权重设置也可能需要进一步的讨论
但是作为首个系统性的AGI评估标准
它为AI的发展提供了一个重要的指导方向
从GPT-4的27%到GPT-5的58%，
我们不仅看到了AI能力的快速提升
同时，这些数字也清晰地告诉我们
真正的AGI之路依然任重道远
好在，现在我们有了一张清晰的地图
知道该往哪个方向努力
以及还有多远的路要走
感谢大家收看本期视频
我们下期再见
