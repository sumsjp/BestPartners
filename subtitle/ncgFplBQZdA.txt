2016年
AlphaGo以一步出乎所有人意料的“第37手”，
击败了世界冠军李世石
这一步“神之一手”，
从此成为了AI做出超乎人类直觉、实现颠覆性突破的象征
如今，一个关键的问题摆在我们眼前
当下的AI
是否正在悄悄走出新的“第37步”呢？
最近
诺奖得主、谷歌DeepMind的CEO德米斯·哈萨比斯在与Lex Fridman长达两个半小时的深度访谈中
直面了这一疑问
他认为
AI正在逼近一场技术变局的临界点
在带来巨大变革潜力的同时
也伴随着失控或者被滥用所导致的“末日风险”。
在这场访谈中
哈萨比斯还回答了关于AI与未来的几个核心问题
比如，AI将如何改变科学？
AGI何时到来，我们又该如何判断？
以及人类的终极未来是什么？
今天
大飞就来给大家总结一下这场访谈的核心内容
相信一定会引起大家的更多思考
两人的对话
从探讨AI能力的边界开始
哈萨比斯首先重申并且深化了他在诺贝尔奖演讲中
提出的一个前瞻性的论断
那就是自然界中任何可以通过演化生成
或者被发现的模型
原则上都能通过智能算法
被高效地学习和重现
他解释道
这个论断的信心源自于DeepMind的核心项目实践
无论是AlphaGo面对围棋的天文数字般的可能性
还是AlphaFold解析蛋白质折叠的复杂组合空间
它们的本质都是在看似无穷的搜索空间中
通过构建智能模型来引导搜索
从而将“不可能”的任务变得“可处理”。
哈萨比斯指出，这种方法之所以可行
关键在于自然系统并不是随机的
而是有着深刻的“结构性”。
无论是生命体在演化压力下的“适者生存”，
还是山脉形态、行星轨道
在漫长时间尺度下形成的“最稳定者存活”（survival of the stablest）
都体现了某种内在的规律和模式
这些历经时间考验而留存下来的结构
为AI的学习提供了宝贵的“先验知识”。
因此
神经网络能够通过学习这些非随机的结构
高效地“逆向工程”出自然的解决方案
反之
对于纯粹完全随机、缺乏内在结构的抽象问题
比如大数分解
这种学习范式是不适用的
可能需要依赖暴力计算或者量子计算等其他的路径来解决
而AI的长处
在于解码那个由演化精心塑造的、充满结构的自然世界
当谈到谷歌最新的视频生成模型Veo 3时
讨论深入到了AI是否具备“理解”这个能力的核心问题
哈萨比斯认为
Veo 3展现出的能力远超娱乐或者模拟的范畴
它触及到了AI理解现实的本质
他承认，Veo 3对世界的理解
并非人类哲学层面的深刻思考
但是它已经能够高度逼真地模拟世界的运行方式
它最令人震撼的地方
并非是模仿人物动作的逼真
而在于对光影、材质、流体等物理效果的精准再现
这表明
Veo 3已经具备了一种所谓直觉物理（Intuitive Physics）的能力
这是一种类似于小孩子通过观察习得的、关于世界如何运作的本能知识
而非基于公式的学术知识
这个进展颠覆了AI领域里一个长期以来的重要假设
哈萨比斯坦言，在几年前
他自己也曾经是“具身智能”（Embodied AI）理论的支持者
认为AI必须通过物理实体与环境互动
才能够真正理解“杯子会摔碎”这类物理常识
然而，Veo 3的出现证明
仅仅通过观察海量的视频数据
AI似乎也能够学到关于现实世界的深刻结构
这让他倍感惊讶，并且意识到
现实世界本身可能蕴含着比我们想象中更丰富的、可供学习的视觉信息
展望未来
哈萨比斯认为下一步是将这些生成的视频世界
变为所谓可交互的世界模型
当AI不仅能够生成逼真的场景
还能让用户进入其中进行互动的时候
它就真正拥有了在“思维中”模拟世界的能力
而这正是通往通用人工智能AGI的必要基石
对于哈萨比斯
这位从青少年时期便投身于游戏AI设计的思想家来说
他对未来的展望聚焦在了一个终极梦想
那就是构建一个能够实时响应、并且围绕玩家想象力而动态演化的开放世界
他首先剖析了当前开放世界游戏面临的根本困境
尽管这类游戏备受青睐
但是开发成本高昂
而且往往只能提供一种“选择的幻觉”。
开发者需要预设大量的内容
来应对玩家的自由行动
或者依赖不稳定的“涌现”系统
最终仍然难以摆脱预设脚本的束缚
哈萨比斯认为
无论是早期《上古卷轴》随机生成的方式
还是现代3A大作的复杂分支方式
都没有能够实现真正意义上的开放
在这个方向上，未来的突破口
应该在于以AI驱动的实时生成系统
哈萨比斯预言，在未来五到十年
AI将能够根据玩家的每一个决策
实时生成连贯的、富有张力的剧情和世界细节
这不仅仅是一项技术的飞跃
更是游戏设计哲学的一次根本变革
从开发者预设内容
转向玩家与AI共同创造叙事
他将这个愿景与他早期参与的、采用强化学习的《黑与白》项目联系起来
认为核心思想是一脉相承的
都是想让游戏体验成为玩家行为的直接映射
在更深层次的方面
哈萨比斯将构建这种终极模拟游戏的挑战
与计算理论中的“P与NP问题”相类比
他认为
创造一个逼真的、允许玩家“为所欲为”的虚拟世界
它的复杂性本质上是在探索“宇宙是什么”的物理学与哲学命题
在AI时代
当虚拟与现实的界限日益模糊
游戏将不再仅仅是娱乐
而可能成为人类释放想象力、探索存在意义的重要媒介
随后
对话转向了DeepMind的前沿研究
哈萨比斯详细阐述了AlphaEvolve所代表的、一种极具潜力的新方向
那就是“混合系统”（Hybrid Systems）
他解释道
这个系统的核心是一种精妙的分工协作
基础大语言模型扮演“创意提出者”的角色
负责生成潜在的、新颖的解决方案
而进化算法则扮演“高效探索者”的角色
在模型指引的广阔搜索空间中
进行探索与优化
这种结合的目的
正是为了克服传统进化算法的瓶颈
哈萨比斯指出
过去的进化算法虽然能够对现有组件进行组合与筛选
却难以进化出真正全新的属性
然而
通过与具备海量知识和生成能力的基础模型融合
AI有望模拟自然进化中最关键的特性
那就是组合式的涌现与分层构建
如同生物从单细胞演化到复杂生命一样
每个阶段都获得了前所未有的新能力
而AlphaEvolve的目标
正是要让AI系统具备这种创造新能力的能力
他强调
这种探索并非是盲目的随机尝试
而是一种由目标函数引导的、有方向的创新过程
它的价值在于
能够让AI跳出人类现有的知识边界
去发现真正新颖的解决方案
正如AlphaGo通过蒙特卡洛树搜索
下出“第37手”一样
这对于实现科学领域的重大突破至关重要
最终
哈萨比斯将这个技术的探索上升到了哲学高度
他感叹
进化本身作为一个相对简单的算法
在物理基底上运行了数十亿年
却创造出宇宙中最惊人的复杂性与多样性
而像AlphaEvolve这种混合系统的研究
正是人类试图理解、掌握并且运用这一宇宙中最强大创造力量的缩影
在探讨AI能否达到甚至超越人类智慧的时候
一个核心的概念被提了出来
那就是“研究品味”（Research Taste）
这并不是指技术的熟练程度
而是指顶尖科学家在选择研究方向、提出关键问题和设计精妙实验的时候
所展现出来的深刻洞察力与判断力
哈萨比斯认为
这正是甄别卓越科学家与优秀科学家的关键分水岭
也是当前AI最难模仿和建模的能力
他提出了一个核心论断
那就是在科学探索中
提出一个出色的猜想
往往比证明它更具挑战性
尽管AI在解决复杂的、已经被明确定义的数学问题上
展现出了巨大的潜力
甚至未来还可能攻克千禧年难题
但是这些都还是属于“解题”的范畴
而所谓的“出题”，
也就是提出一个让陶哲轩这样的大师认可的、触及学科本质的深刻猜想
则需要一种当前AI还远没有具备的、爱因斯坦式的想象力飞跃
那么，究竟什么是“出色的猜想”呢？
哈萨比斯解释道
它必须满足几个严苛条件
首先要有精准的定位
它应该处于一个“最佳的平衡点”上
既非无从下手，也非显而易见
这样才能够有效的推动知识边界
其次，信息价值要最大化
无论最终被证实还是证伪
它都必须能像二分搜索一样
将庞大的“假设空间”进行有效的分割
从而让研究者获得同等价值的宝贵信息
在真正的基础研究中
只要实验设计得当
便无所谓“失败”。
第三，猜想要具备可证伪性
也就是说
它必须在当前技术框架内是可被检验的
这一系列的要求
决定了“研究品味”是一种高度创造性的整合过程
而非简单的模型搜索
它也标志着当前AI与人类顶尖智慧之间
存在的本质差距
随后
对话进一步延伸到了科学领域最迷人的谜题之一
生命的起源上
哈萨比斯对此展现出了浓厚兴趣
并且认为AI有望成为解开这个谜团的理想工具
他引述了尼克·莱恩等前沿学者的观点
强调了生命诞生过程的极端复杂性与偶然性
尤其是从单细胞到多细胞生物
那长达十亿年的演化跨越
他设想
AI可以通过强大的模拟与组合空间搜索的能力
来重演这个过程
我们可以将地球早期热液喷口附近的“原始化学汤”，
设定为初始条件
利用AI来探索从无机物
涌现出类细胞结构的可能路径
最终，在哲学层面
Fridman与哈萨比斯共同认为
生命与非生命之间
可能并不是一道清晰的壁垒
而是一个从物理、化学到生物学的连续统一体
是否能够打破这种二元对立的认知
也将是我们理解宇宙的关键一步
哈萨比斯坦言
他投身AI研究的终极动机
正是源自于对这种根本性问题的痴迷
他感慨道
现实世界充满了“在眼前尖叫的谜题”，
我们甚至无法清晰定义生命与意识
对引力与量子力学的本质也知之甚少
面对这些宏大的未知
人类社会发展出了一种高效的“认知回避机制”，
即通过日常的忙碌
来分散对这些终极奥秘的注意力
而AGI的终极愿景
正是要创造出一个能够帮助人类
直面并且系统性解答这些根本性问题的强大工具
从而让我们能够真正理解
现实的本质究竟是什么
对于AGI何时到来
哈萨比斯给出了一个审慎的预测
到2030年，实现AGI的概率大约为50%。
不过，他立即指出
这个预测的背后其实是一个更根本的问题
那就是我们应该如何定义并且识别真正的AGI？
哈萨比斯坚持了一个极高的标准
那就是AGI必须具备与人类大脑相媲美的、全面的认知通用性
而非当前AI系统普遍存在的“能力参差不齐”现象
他强调，一个真正的通用系统
它的智能水平在所有认知领域
都应该保持一致的卓越
并且拥有真正的创造与发明能力
为了验证这个标准
他提出了一个双轨并行的测试框架
其中一个是全面的基准测试（Comprehensive Benchmarking）
通过涵盖数万个人类认知任务的测试集
系统性地检验AGI在能力广度与稳定性上的表现
确保它没有认知短板
另一个是里程碑式的突破（Milestone Breakthroughs）
这类似于AlphaGo下出的“第37手”，
也就是那些颠覆人类认知的、决定性的时刻
哈萨比斯列举了几个有代表性的测试
比如在科学发现方面
在仅提供1900年以前的物理知识的条件下
系统能否独立推导出相对论？
或者在创造性发明方面
系统能否发明一个在深度、优雅与美学上
堪比围棋的全新游戏呢？
他进一步解释道
即便人类专家无法预见到这些突破
但是凭借他们的专业知识
应该能够做到“事后理解”其中的深刻性与有效性
尤其当AGI能够清晰解释推理过程的时候
这种可解释的、颠覆性的创造力
才将是AGI到来的明确信号
在实现AGI的路径上
当前AI领域还存在着一个核心辩题
那就是AGI将通过现有技术的持续规模化（Scaling）达成
还是必须依赖一到两个全新的基础性突破呢（Foundational Breakthroughs）？
哈萨比斯对所谓的“硬起飞”（Hard Takeoff）
也就是AI通过递归自我改进
来实现智能爆炸的观点持保留态度
他指出
尽管AlphaEvolve等系统已经能够在像优化矩阵乘法的任务上
实现增量式的自我改进
但是它们依然缺乏对抽象和高层指令的理解与执行能力
这与AI难以提出全新科学猜想的问题根源相同
他用s型曲线来比喻这个困境
那就是现有系统非常擅长在当前的s型曲线上爬坡
也就是在现有的范式内进行优化
但是关键问题在于
仅靠“爬坡”是否足够呢？
还是说，系统必须具备从一条S曲线
“跃迁”到另一条更高阶曲线的能力呢？
哈萨比斯坦言，目前还没有系统
明确展现出这种实现范式飞跃的能力
比如说独立构想出Transformer这样的革命性架构
面对这种不确定性
DeepMind也采取了另一条双轨并行的战略
他们将一半资源用于最大化现有技术
比如Transformer架构的规模化潜力
另一半资源
则投入到“蓝天探索”（Blue-sky Research）的项目中
致力于寻找下一次范式革命的火种
哈萨比斯对此表现出了充分的自信
他认为，当挑战从纯粹的工程问题
转向“研究+工程”的复合领域时
恰恰最能发挥DeepMind的优势
回顾过去十余年
现代AI领域80%-90%的重大突破
都来自于谷歌
同时
他并不担忧高质量数据耗尽的问题
并且指出
强大的模拟技术将能够生成海量的、符合真实世界分布的合成数据
为AI的持续发展提供燃料
展望未来数十年
德米斯·哈萨比斯将人类文明进步的基石
押注于核聚变与太阳能
这两大终极能源解决方案
他认为
太阳能作为“天空中的聚变反应堆”，
它的潜力
取决于储能与材料科学的突破
而地面核聚变则是一个工程与控制论的问题
一旦解决
人类将进入一个由近乎免费、无限的清洁能源驱动的全新时代
这个能源突破将引发一系列连锁反应
甚至将从根本上重塑人类社会
首先，资源稀缺的现状将被终结
廉价能源将使海水淡化和氢能提取的成本大幅降低
从而解决水资源与太空运输的瓶颈
并且为小行星采矿等新的领域
铺平道路
其次是“激进丰裕”（Radical Abundance）时代的到来
人类将历史上首次摆脱土地、材料、能源等核心资源的“零和博弈”，
从根本上化解诸多因为资源稀缺而引发的冲突
为保护自然环境和实现全球发展
提供物质基础
哈萨比斯强调，在这样的背景下
人类社会的核心议题
将从资源的获取转向资源的公平分配
确保技术进步的红利能够惠及到每一个人
而AI，正是实现这一切
并且引导人类走向卡尔·萨根所梦想的“宇宙意识”的关键工具
在激烈的AGI竞赛中
哈萨比斯展现出了一种超越传统商业竞争的领导者格局
他明确的表示
用“输赢”来衡量AGI的发展并不恰当
因为它的影响太过深远
关乎全人类的未来
他将DeepMind的角色定义为技术的安全引领者
它的核心责任是确保这个强大的技术
被安全、负责任地带给世界
基于此
他提出了几个关键的战略原则
首先是合作优先于对抗
他积极的维护与其他前沿实验室的良好关系
认为重大的科学突破
应该是全人类的共同胜利
他甚至对通过合作一些副项目来增进彼此之间的互信
也对培养协同能力持开放态度
其次，面对高薪挖角
他认为真正的顶尖人才
是被“站在研究最前沿
并且塑造技术未来”的使命感所吸引的
而非单纯的金钱激励
他将竞争对手的高薪策略
视为一种追赶者的合理战术
但是相信
DeepMind的科学文化和使命感
构成了更深层次的护城河
他甚至预言
当AGI实现和能源问题解决以后
现有的经济体系、乃至“金钱”本身的意义
都可能被重塑
因此，当下的薪资之争
在宏大的历史进程中
只是一个次要问题而已
在具体的执行层面
哈萨比斯也分享了谷歌和DeepMind
是如何将宏大的愿景
转化为行业领先的产品的
面对“大公司病”的挑战
他强调以“初创公司的心态”，
来保持敏捷与决策果断
同时充分利用谷歌世界级的产品平台
来实现“研究”与“落地”的高效结合
他的产品哲学
其实根植于早年的游戏设计经验
核心还是“前沿技术与用户体验的跨学科融合”。
不过，他也指出
无论是科学研究还是产品设计
“品味”都是最关键的能力
他认为艺术与科学、产品与研究之间
并没有什么绝对上的界限
而是一个连续的整体
在AI生成的界面方面，他预言
未来的交互将超越低带宽的打字
进入一个由AI动态生成的、高度个性化的界面时代
界面将根据用户的审美、习惯与任务需求
实时演化
从而实现简洁、优雅且高效的人机交互
他还清晰地阐述了Gemini模型的发布规律
主版本号，比如3.0的更新
代表着为期大约6个月的、包含架构创新的“核心训练”周期
而次版本号，比如2.5
则更多是基于同一个基础模型的“训练后优化”。
同时，通过“蒸馏”技术
团队会推出覆盖“帕累托前沿”，
也就是性能与成本/速度的最优平衡点的、不同规模的模型
比Pro、Flash等等
从而为开发者提供丰富的选择
最后
他强调了对基准测试的辩证看法
认为它们是必要的度量衡
但是绝对不能“过度拟合”。
真正的目标是实现“无遗憾的改进”（no-regret move）
也就是在提升某个能力的同时
不损害其他的能力
最终打造一个由真实用户反馈驱动的、全面而强大的通用系统
在回应关于人类文明自我毁灭的概率
也就是P-Doom这个终极的问题时
哈萨比斯首先明确拒绝了
为它赋予具体数值的做法
他认为任何试图对“末日概率”进行精确量化的行为
本质上都是缺乏科学依据的
甚至近乎荒谬
然而，他紧接着强调
这并不意味着风险可以被忽视
他给出的核心判断是
这个概率绝对是非零的
而且不容忽视（non-zero and non-negligible）
这个事实本身就足以引发最高级别的审慎
面对AI技术发展中
高度不确定性与高风险并存的局面
哈萨比斯认为人类文明正处在一个关键的岔路口
一条路会通往解决疾病、能源等重大问题
并且走向星际的空前繁荣
而另一条路则可能会导向灾难性的“末日场景”。
在这个背景下
他提出了唯一一个理性而且明智的行动纲领
那就是“谨慎乐观地前行”（Proceed with cautious optimism）
这个立场其实包含了双层含义
首先，我们必须积极的拥抱AI
因为它可能是解决气候变化、资源短缺等现有全球性危机的唯一有效工具
放弃AI本身就是一种巨大的风险
其次，我们还必须清醒地认识到
AI伴随着巨大的、尚未能完全量化的潜在风险
因此
必须以科学方法对它进行更深入的研究、定义和管理
当前投入的精力与资源
与挑战的严峻性相比，还远远不够
最后，哈萨比斯进一步将AI风险
清晰地划分为了在两大不同的时间尺度上、需要同时应对的类型
首先是滥用风险（Misuse Risk）
即“恶意行为者的问题”，
它指的是不负责任的个人、组织或者国家
利用日益强大的AI技术来从事恶意活动
这个问题带来了一个深刻的治理难题
那就是如何在“开放科学”所带来的巨大利益
与“防止技术武器化”的迫切需求之间取得平衡
这是一个目前还没有明确答案的棘手挑战
其次是失控风险（Loss-of-Control Risk）
即“对齐与控制的问题”，
它指的是随着AI系统自主性的增强并且逼近AGI
AI的内部目标或者行为
可能会偏离人类的初始意图
导致不可预见的、灾难性的后果
对于这个问题，核心在于
如何设计并且构建一个有效的安全护栏（Safety Guardrails）与对齐机制
确保超级智能系统的行为
始终与人类的核心价值观和长远利益保持一致
实际上
由于这两类风险是相互交织的
所以增加了问题的复杂性
最终会要求整个国际社会协同努力
就AI的安全与治理
达成关键共识与基本协议
好了
以上就是德米斯·哈萨比斯这次访谈的主要内容了
希望能够给大家带来一些启发
感谢收看本期视频，我们下期再见
