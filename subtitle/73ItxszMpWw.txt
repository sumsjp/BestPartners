大家好，这里是最佳拍档，我是大飞
最近这两天，GPU Utils更新了一篇
关于英伟达H100显卡供需现状的分析文章
里面透露了很多行业数据
包括主流厂商目前拥有显卡的数量
以及他们对显卡的需求量
我觉得是对目前整个AI市场
GPU情况的一个很好了解
整个文章内容很长
我从中总结了一些核心的数据和观点
跟大家分享一下
首先我们可以看一下
这些是对GPU供需和AI
最重要的一些公司及其CEO
不光山姆奥特曼说过
OpenAI目前因为受到GPU的限制
正在推迟他们的一些功能计划
包括微调、专用容量、32k上下文窗口
以及多模态等等
马斯克也说过，现在GPU比药还难买
目前的状况很简单
就是H100 GPU供应短缺
对于想要100台或者1000台H100的公司来说
Azure和GCP实际上已经耗尽了容量
而AWS即将出局
而这都是因为英伟达给他们的配额不足
那么究竟都有哪些公司需要H100呢？
首先
需要1000张以上的H100或者A100的公司有三类
一是训练大语言模型的创业公司
包括OpenAI、Anthropic、Inflection、 Mistral AI等等
二是云服务提供商，包括三大云巨头
Azure、Google Cloud、AWS
还有Oracle
以及像CoreWeave、Lambda这样的私有云
三是像特斯拉这样的大公司
那么谁需要100张以上的H100或者A100呢？
就是那些主要是对大型开源模型进行微调的初创公司
现在大多数的高端GPU
几乎都被拿来做大语言模型的事了
包括训练或者微调
为什么所有的公司都在几乎需要H100
或者说的更明确点
就是8-GPU HGX H100 SXM服务器
因为目前它是推理和大语言模型训练最快的
通常也是最具性价比的推理显卡
有几个关键指标跟大语言训练有关
包括内存带宽、FLOPS、缓存和缓存延迟、FP8计算、CUDA核心数以及互联速度
比如InfiniBand
关于什么是InfiniBand
我们回头会专门做一期节目介绍
那之所以首选H100而不是A100
因为如果跟A100相比的话
H100 16位推理快大概3.5倍
16位训练快大概2.3倍
因此它的效率提高了3倍
但成本仅为1.5到2倍
结合整体系统成本
H100每美元产生的性能更高
可能是A100的4-5倍
关于H100的详细性能评测
我们也会找时间做一期节目介绍
而且对于很多初创公司来说
模型的启动、训练或者改进速度至关重要
而H100可以使用更多数量的GPU
更好地扩展并提供更快的训练时间
那在训练和运行大语言模型过程中
除了GPU的成本最高以外
还有很多其他的成本
比如系统RAM和NVMeSSD的价格
InfiniBand的网络成本，这些都很高
运行集群的总成本的10-15%，
可能会用于电力和托管部分
其中电力成本可能占5-8%，
而托管成本
比方说土地、建筑、员工等等
可能占5-10%。
为什么这些公司不考虑用AMD的GPU呢？
主要有几方面原因
一方面你需要花时间让一堆的AMD GPU运转起来
而在这上面耗费的时间
会影响产品的开发进度
可能会比竞争对手更晚上市
所以CUDA现在是NVIDIA的护城河
而且AMD的可用性也令人担忧
现在台积电CoWoS的产能都被英伟达吸走了
即使MI250可能是一个可行的替代方案
但是现在也不可用
在H100大面积采购之后
A100可能会被更多的用来进行推理
而V100因为缺乏bfloat16的数据类型
没有这个很难轻松地训练模型
所以这些AI厂商很少有用V100的
然后文章作者对一些服务器的型号做了一些解释
比如说HGX H100
这个是英伟达的服务器参考平台
OEM用来构建4GPU和8GPU服务器
而DGX 100是指具有8个H100的英伟达官方H100服务器
英伟达也是唯一供应商
GH200指的是1个H100 GPU再加上一个Grace CPU
而DGX GH200，是指的256倍的GH200
在2023年底上市
也可能只会由英伟达提供
大多数公司都会选择购买8-GPU HGX H100
而不是 DGX H100
或者4-GPU HGX H100服务器
那购买这些GPU的成本是多少呢？
1个包括8块H100 GPU的DGX H100（SMX接口）
价格为46万美元
其中10万美元是必需要购买的支持
初创公司可以获得大约5万美元的初始折扣
最多可用来购买8台DGX H100
总共64个H100
1个包括8块H100的HGX H100（SMX接口）
价格在30-38万美元之间
具体取决于服务器的规格
以及销售可以给到的折扣和支持级别
这个型号的高端价格
包括支持服务在内的36-38万美元
可能跟DGX H100差不多
而换成PCIe接口的HGX H100
价格大约是30万美元
具体价格看规格型号
PCIe卡的市场价格约为3万到3.2万美元
而SXM卡一般不单独出售
通常仅随4-GPU和8-GPU的服务器出售
从目前的市场采购需求来看
大约70-80%的需求是SXM的H100
其余的是PCIe的H100
接下来，重点来了
这些知名的大厂到底手上有多少GPT
首先
GPT-4的训练规模是10000-25000张A100
Meta大约有21000张A100
Tesla大约有7000张A100
Stability AI大约有5000 A100
Falcon-40B是在384个A100上进行了训练
而Inflection使用了3500张H100
来训练与GPT-3.5能力相当的模型
GCP大约有25000张H100
Azure可能有10000-40000张H100
甲骨文应该也是类似
而Azure把大部分容量给了OpenAI使用
CoreWeave大概有35000-40000张H100
但是这个不是他们现有的数量
而是跟英伟达预订的数量
其他一些初创公司，如果只用来微调
可能会买了数十张或者数百张H100
而如果主要做训练的，至少在数千张
那么这帮大公司总共需要多少张H100呢？
按照文章所说
OpenAI可能想要50000张
Inflection想要22000张
Meta也许25000张，但据说更多
大的云厂商可能想要30000张
Lambda和CoreWeave以及其他私有云
可能总共想要100000
像Anthripic，Helsing，Mistral
Character
这些创业公司
总共架起来可能想要10000张
最终去除一些重复计算
大约估算市场需求达到了大约432000张H100
如果按照每张卡大约3.50万美元
大约相当于150亿美元的GPU
这还不包括像字节跳动、百度和腾讯这些想要大量H800的中国公司
我们再来看看英伟达的产能是多少
2023年2月至4月
数据中心的收入为42.80亿美元
预计5-7月可能会在80亿美元左右
如果按照刚才估算的数字
够英伟达干到明年去了
虽然作者也说，这个估算可能不准
会被夸大，但是我个人觉得还好
并不夸张，甚至搞不好还保守了点
最重要的一点事，最终H100的分配
还是要取决于英伟达更愿意将它分配给谁
接下来
我们再说说H100的供应瓶颈在哪
首先现在只有台积电在生产H100
台积电有4个生产节点为5nm芯片提供产能
分别是N5
N5P，N4，N4P
而H100只在N5或者是N5P中的4N节点上生产
是一个5nm的增强型节点
而英伟达需要和苹果
高通和AMD共享这个节点的产能
而A100是在台积电N7生产线
台积电晶圆厂
需要提前12个月就对各个客户的产能搭配做出规划
而H100到从生产到出厂大约需要半年的时间
按照某位退休的半导体行业专业人士的说法
晶圆厂并不是台积电的生产瓶颈
CoWoS（3D堆叠）封装才是台积电的产能大门
除此之外，H100的内存
也可能存在产能不足的问题
因为内存类型、内存总线宽度和内存时钟速度
都会影响GPU的内存带宽
而其中的高带宽内存HBM
正是保障GPU性能的关键组件
按照业内人士的说法
主要的问题是HBM
制造它是一场噩梦
由于HBM很难生产，供应也非常有限
生产和设计都必须按照它的节奏来
而H100在SXM上使用的是HBM3
而在H100PCIe上
实际上是HBM2e
HBM3内存
英伟达几乎都是采用SK Hynix的产品
可能会有一部分三星的产品
应该没有镁光的产品
英伟达希望SK Hynix能提高产能
他们也在这么做
但是三星和镁光的产能都很有限
而且制造GPU还会用到包括稀土元素在内的许多其他材料和工艺
也会成为限制GPU产能的可能因素
按照英伟达的说法
下半年会供应更多的GPU
但是没有明确的数量
不过现在市场上已经出现了GPU恶意囤积的现象
H100的下一代产品要在2024年末到2025年初才会宣布
期间可能会推出120GB水冷版的H100
不过业内人士称
到今年年底所有的H100已经卖完了
最后
我们再说说英伟达是怎么来分配手里的H100的
首先
英伟达会为每个客户提供H100的配额
但是打个比方，如果Azure说
我想要10
000个H100，全部给Inflection用
会跟它说
我想要10
000个H100自己用，得到不同的配额
英伟达更关心最终的客户是谁
因此如果英伟达对最终的使用客户感兴趣的话
云平台就会得到更多的H100
而且英伟达更喜欢拥有好品牌的客户
或者拥有强大血统的初创公司
这从他们投资Inflection和CoreWeave上就可以看的出来
还记得我们刚才说到GPU数量的时候
CoreWeave拿到的配额实际上是比Google Cloud还多的
关于英伟达投资的这两家公司
回头我们有空也会做节目详细说一下
最近硅谷出来的新公司确实太多了
由于时间关系
其实文章中还有很多部分
比如说谁在卖H100
几个云平台的对比
以及哪些公司使用了哪些云平台
我来不及一一详细介绍
大家有空可以去看下原文
客观来说
虽然现在对GPU的渴求有泡沫和炒作的成分存在
但是需求量也确实也摆在那
至少到今年年底
H100都会处于非常短缺的情况
如果文章的内容都属实
我觉得可以再考虑买一波英伟达的股票
谁让它的H100实在是太香了呢
当然这个不构成投资建议
大家自行决定
文章末尾也称英伟达现在是城堡中的绿色之王
green king of the castle
老狠了
好了，今天的视频内容就到这里
感谢大家的观看，我们下期再见
