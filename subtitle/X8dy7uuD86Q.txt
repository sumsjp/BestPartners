大家好，这里是最佳拍档，我是大飞
我们现在在网上
能看到很多AI制作出来的视频或者动画
之前我们频道也发过一个完全用AI制作的电影短片《Frost》，
但是效果看起来都并不完美
原因就是现在AI视频
依靠的都是“关键帧”
如果帧与帧之间的联系不紧密
就会出现一种诡异的“闪烁画风”，
而这也是目前
AI生成视频最大的瓶颈之一
不过现在，来自南洋理工大学的团队
终于解决了这个问题
研究也在网络上掀起了不小热度
那么
究竟是如何做到让AI视频不“闪烁”的呢？
首先我们了解一下，AI生成视频会“闪烁”
本质上是前后帧不连贯导致的
其实视频都是由一张一张图片组成起来的
只不过利用的人眼的特点
当这些图片快速闪动的时候
人眼就会把它识别为连续的画面
因为AI现在对每一帧图片的处理结果都是不一样的
于是你就会看到
视频中的物体、人物总是在变幻不同的样子
举个例子
这是同一个视频中截取的两帧画面
用AI根据这两帧来“重绘”图像
乍一看问题不大
但是细节上却有不少差异
例如
其中一帧生成的人物头上有“金色发带”，
而在另一帧中却消失了，这样一来
看似AI生成的几十帧图像风格差不多
连起来细节差异却非常大
所以视频也就容易出现闪烁的现象
为此
来自南洋理工大学的几名研究人员
提出了一种新的框架
你只需要输入一段视频
念上一段“咒语”，AI就能瞬间秒懂
并当场给你把视频重画一遍
不仅完美hold住各类风格
最关键的是，帧帧丝滑流畅
就连建筑物这种细节较多的视频
也几乎看不出“AI制作”
这个框架的解决思路
就是提升AI生成视频时帧与帧之间的连贯性
包含了关键帧翻译（key frame translation）和完整视频翻译（full video translation）两部分
第一部分关键帧翻译
是基于扩散模型来生成关键帧
基于跨帧约束
来加强这些关键帧之间的一致性
第二部分完整视频翻译
则通过基于时间感知的匹配算法
将其他帧与关键帧“连接”起来
而框架的核心，在于第一部分
研究人员给这部分
提出了一种新的分层跨帧一致性约束方法
在原视频的基础上
利用光流来约束帧与帧之间的关系
其中
第一帧相当于整个视频的“锚点”，
用来控制视频的整体走向；
后续的每一帧
则都会以前一帧作为参考
防止生成的图像偏离最初的风格、形状、纹理和颜色等
至于视频生成的模型
核心采用的则是Stable Diffusion+ControlNet的组合
但是经过了改进
如图所示
红色虚线是原本Stable Diffusion等扩散模型采样过程
黑色线条则是经过调整后的过程
当然，在不同的采样阶段
跨帧约束也不一样
包括形状感知、像素感知等
相比之前的AI视频生成模型
这个框架最大的优势在于
当输入一个新视频的时候
它不需要再用这个视频材料来重新进行训练
换而言之就是零样本学习
你只需要输入一段提示词+一段视频
框架就能自动将视频“翻译”出你想要的效果
例如，这是团队利用改进后的框架
重新生成的一段相同风格视频
可以看到，和改进前的扩散模型相比
几乎看不出闪烁了
那么
生成这么一段视频是否需要很长的时间呢？
至少从生成帧的效率来看
速度还是不慢的
其中关键帧和Stable Diffusion出图的速度差不多
平均在14.23秒左右
非关键帧就非常快了
每帧只需要1.49秒
如果视频不长、甚至只有十几帧的话
不到一分钟就能搞定一段视频的转换
研究者们将这个新框架
和之前的几类文本生成视频的框架进行了对比
包括FateZero、vid2vid-zero、Pxi2Video和Text2Video-Zero等等
显然新框架目前是最流畅、鬼影也最少的
而且，不仅仅是单纯的“视频翻译”，
研究者们还展示了提示词对于视频生成的控制效果
例如在相同的输入下
你只要更改一段提示词中的“关键字”，
AI就能在几乎不改动其他元素的情况下
生成一段新的视频
比方说换个发型、换种风格
或是将狗头换成狐狸头等等
除此之外
作者们还请来了23名志愿者
对新框架生成的视频质量进行了综合评分
评估指标有三个
分别是提示词和输入帧的关联度、时间一致性和视频整体质量
结果显示
这个框架在“人类评分”中均取得了不错的水平
那说完了这个研究
我们再来说说背后团队
论文的四位作者均来自南洋理工大学
一作杨帅，是南洋理工大学助理教授
本科和博士毕业于北京大学
目前的研究方向是基于人像的编辑、文本风格化、图像翻译等
周弈帆，南洋理工大学研究工程师
本科毕业于北京理工大学
拿过ACM-ICPC金牌
研究方向包括文本挖掘、基于机器学习重建入射光场等
刘子纬，南洋理工大学助理教授
香港中文大学博士
研究方向是计算机视觉、机器学习和计算机图形学等
吕健勤（Chen Change Loy）
南洋理工大学和香港中文大学副教授
他的研究兴趣集中在计算机视觉和深度学习方向
包括图像、视频恢复和生成
以及表征学习等
目前这个项目的代码还没有开源
不过论文中表示
“会有的”，实际测试效果如何
我们可以期待一下
那基于这种技术
我觉得AI朝制作影片
生成电影又迈出了一大步
持续稳定的图像画面
会比现在这种以一帧画面为基础
再配上少许动画的形式
观看体验更好、更一致
也许很快就会有一部，真正意义上
完全由AI生成的
接近于我们现在观影效果的影片出现了
好了，今天的分享就到这里
感兴趣的小伙伴们
欢迎订阅我们的频道，我们下期再见
