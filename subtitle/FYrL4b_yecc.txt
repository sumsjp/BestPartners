大家好，这里是最佳拍档，我是大飞
在当下的科技圈
人工智能领域的竞争可谓是硝烟弥漫
OpenAI与DeepSeek不断推陈出新
你方唱罢我登场
在各种技术赛道上激烈角逐
就在大家的目光都聚焦在这两家的较量时
谷歌DeepMind却带着它的最新成果
悄然惊艳了整个科技界
今天
咱们就来深入聊聊谷歌DeepMind研发的AlphaGeometry 2
看看它究竟凭什么能在数学推理领域掀起波澜
甚至超越IMO金牌得主的平均水准
国际奥林匹克数学竞赛
也就是大家熟知的IMO
在数学界有着相当高的地位
它面向全球高中生
汇聚了无数数学天才
IMO的题目以难度高而闻名
每一道题都像是一座难以攀登的高峰
需要参赛者对数学概念有极为深刻的理解
还得能创造性地运用这些概念
展现出超强的思维能力和解题技巧
而几何题，作为IMO的四大题型之一
有着独特的地位
它不像其他题型那样零散
而是各部分之间联系紧密、逻辑统一
是进行基础推理研究的绝佳素材
也正因如此
IMO的几何题成为了检验AI系统高级数学推理能力的理想标杆
任何一个人工智能想要证明自己在数学领域的实力
都得在IMO几何题上接受考验
时间回溯到2024年7月
谷歌DeepMind推出了AlphaGeometry 1
也就是AG1
AG1的出现
在当时数学和人工智能交叉领域
引起了不小的轰动
AG1创新性地将语言模型和符号引擎结合在一起
形成了一个神经符号系统
这种独特的架构让它在面对IMO几何题的时候
展现出了强大的解题能力
在2000到2024年的IMO几何题中
AG1的解题率达到了54%，
这个成绩已经相当了不起
距离IMO金牌得主的水平仅有一步之遥
当时就被人们称为数学领域的“AlphaGo时刻”。
我们都知道
AlphaGo在围棋领域打败了顶级棋手
改变了整个围棋界对人工智能的看法
而AG1在IMO几何题上的表现
也让人们看到了人工智能在数学领域的巨大潜力
不过，AG1虽然取得了成功
但是它并非完美无缺
就像任何一项新技术
在发展初期总会存在一些局限性
AG1的性能受到几个关键因素的制约
首先
它所使用的特定领域语言范围有限
这就好比一个人知识储备不够丰富
遇到一些超出他认知范围的知识点
就会感到力不从心
其次，符号引擎的效率也有待提高
就像一辆汽车发动机不够强劲
行驶起来就不够顺畅
最后
初始语言模型的容量也限制了它的发挥
就像一个小仓库，装不下太多的东西
由于这些限制
当考虑2000年至今的所有IMO几何问题时
AG1的解题率只能停留在54%。
但是，也正是这些不足
为后续的改进指明了方向
也促使谷歌DeepMind的团队不断探索
最终打造出了更强大的AlphaGeometry 2
简称AG2
为了克服AG1的局限
谷歌DeepMind的研究人员付出了大量的努力
对系统进行了全面升级
AlphaGeometry 2由此应运而生
并且在多个方面都有了质的飞跃
先来说说领域语言的扩展
AG2不再局限于AG1那样相对狭窄的语言范围
而是将触角伸向了更广泛的几何概念
它涵盖了轨迹定理和线性方程等重要内容
还能处理非构造性问题陈述
这意味着AG2对几何知识的理解更加全面和深入
能够应对更加复杂多样的几何问题
打个比方
AG1就像是一个只能在小池塘里游泳的人
而AG2则像是学会了在大海里畅游的高手
面对各种复杂的水域环境
都能够应对自如
符号引擎作为AlphaGeometry的核心组件
在AG2中也得到了全方位的升级
谷歌将它称为演绎数据库算术推理
也就是DDAR
在AG2里，DDAR有了三项关键的改进
第一个改进是处理二重点的能力
在一些几何问题中
会出现两个名称不同但是坐标相同的点
也就是二重点
以前的DDAR在处理这类问题时存在困难
举个例子，假设有这样一个几何问题：
在点X处两条线a、b相交
需要证明点X位于某个圆ω上
按照传统思路
直接证明a、b的交点在ω上可能会比较困难
但是如果换个角度，重构问题
先构造一个新点X′作为a与ω的交点
然后证明X位于b上
再利用X和X′都在a、b上
得出X = X′，最后就能证明X位于ω上
这个过程看似复杂
但是在实际解题中却很有效
而AG2的DDAR通过重新实现
具备了处理这种二重点推理重构的能力
这大大增强了它解决复杂几何问题的实力
第二个改进是算法速度的提升
在处理几何问题的时候
DDAR算法需要处理一系列的规则
并且尝试将每条规则应用于所有点的组合
这个过程中有两个比较耗时的部分
一个是候选搜索步骤
另一个是子句匹配步骤
在AG1中
搜索相似三角形候选的最坏情况
时间复杂度高达O(N^8)，
指数级的子句匹配也是成本高昂
为了提高速度
谷歌的研究人员设计了改进的DDAR2算法
对于相似三角形的搜索
他们会遍历所有的点三元组
对它们的形状进行哈希处理
如果两次识别出相同的形状
就可以检测出相似的三角形对
对于圆内接四边形的搜索
他们会遍历所有的点X和线段AB对
并对（A
B，∠AXB）的值进行哈希处理
一旦这样的三元组重复出现
就能确定一个圆内接四边形
通过这种方式，大大提高了搜索效率
第三个改进是实现方式的优化
为了进一步提升速度
谷歌使用C++来实现DDAR核心计算中的高斯消元法
新的C++库通过pybind11导出到Python
速度比DDAR1快了300多倍
研究人员还进行了基准测试
选择了一组25道DDAR1无法解决的IMO问题
在配备AMD EPYC 7B13 64核CPU的机器上运行测试50次
结果显示
DDAR1平均需要1179.57±8.055秒才能完成计算
而DDAR2仅需3.44711 ± 0.05476秒
速度提升效果显著
在训练数据方面，AG2也进行了优化
和AG1一样
谷歌采用合成数据生成方法
从随机图采样开始
利用符号引擎推断出所有可能的事实
并通过回溯算法提取证明事实所需的前提、辅助点和推理步骤
但是AG2在数据生成上有了更大的突破
一方面，它扩大了数据生成的来源
探索两倍大小的随机图
使得生成的问题更加复杂
生成的定理复杂程度提升了两倍
证明步骤更是多了10倍
同时，在数据分布上也更加均衡
无论是不同类型的问题之间
还是有无辅助点的问题之间
都实现了更合理的分布
另一方面
谷歌还改进了数据生成算法
在AG1中
获取最小问题的搜索是指数级的
对于大量的点而言不太可行
而在AG2中
谷歌切换到了贪婪丢弃算法
这种算法就像一个聪明的筛选器
仅使用线性数量的检查就能判断一组点是否足以证明目标
大大提高了数据生成的效率
搜索算法作为解决问题的关键一环
在AG2中也有了全新的设计
在AG1中，使用的是简单的束搜索
而AG2则设计了一种名为搜索树的共享知识集合
简称SKEST的新算法
这种算法可以并行执行多个不同配置的束搜索
并且通过知识共享机制
让这些搜索树相互帮助
具体来说，在每个搜索树中
一个节点代表一次辅助构造尝试和一次符号引擎运行尝试
如果尝试成功，所有搜索树就会终止
如果尝试失败
节点会把符号引擎证明的事实写入共享事实数据库
这些共享事实经过过滤
只保留与原始问题相关的内容
这样就能为同一搜索树中的其他节点
以及不同搜索树中的节点提供帮助
在系统设计上
谷歌使用TPUv4为每个模型提供多个副本
让同一模型内的不同搜索树
根据自身策略查询同一服务器
并且
对DDAR工作器与LM工作器进行异步运算
DDAR工作器之间也相互协调
从而确保工作分配合理
还能共享计算资源
AG2的语言模型也有了很大的改进
在训练设置上
AG1是一种定制版的Transformer
分两个阶段进行无监督训练
而AG2则利用Gemini训练流程
将训练简化为一个阶段
对所有数据进行无监督学习
它使用了基于稀疏混合专家（MoE）Transformer的新模型
以Gemini 1.5为基础
并且使用AG2数据进行训练
谷歌通过三种不同的设置来训练多个不同大小的模型
包括使用领域特定语言中的自定义分词器从头开始训练
使用自然语言微调已经预训练的自定义专业数学Gemini模型
以及使用额外的图像输入
从头开始进行多模态训练
在推理设置上
AG2让语言模型在提出辅助构造之前
了解DDAR所做的推论
将更多信息输入到语言模型中
比如给定原始问题前提
DDAR可推导出的事实集
以及假设目标谓词为真时
DDAR可推导出的事实集等等
这样大大丰富了神经符号接口
经过这一系列的改进
AG2的实力究竟如何呢？
咱们来看看实际的竞赛结果
2000 - 2024年IMO共有45道几何题
谷歌将它们转化为了50道AlphaGeometry问题
也就是IMO - AG - 50
在这些题目上
AlphaGeometry 2它成功解决了其中的42道题
这个成绩首次超越了IMO金牌得主的平均水平
从具体数据对比来看，其他系统
比如OpenAI o1和Gemini thinking在IMO - AG - 50上的解题数都是0
AG1的解题数相对较少
而AG2无论是在IMO - AG - 50还是IMO - AG - 30上
解题数都远超其他AI模型
这充分证明了AG2在解决IMO几何问题上的强大能力
谷歌还对推理设置进行了消融实验
研究发现，对于单个搜索树
最优配置是束大小128、束深度4以及样本32
通过这些实验
也让我们更加了解不同推理设置对AG2性能的影响
应该说
这次AlphaGeometry 2的推出具有重要的意义
它不仅仅是在IMO几何题上取得了优异成绩
更重要的是
它标志着人工智能在处理复杂数学推理任务方面
实现了重大飞跃
对于推动人工智能在数学领域的研究和应用
有着深远的影响
在未来
或许人工智能可以帮助数学家们解决更多长期以来悬而未决的难题
为数学研究开辟新的思路和方法
同时，在教育领域
它也有可能成为一种辅助教学的工具
帮助学生更好地理解和掌握几何知识
提升数学学习的效率
AG2也让我们看到
随着技术的不断进步
AI在各个领域的应用将会越来越广泛
也倒逼着我们必须要尽快去思考
如何更好地利用AI来为人类创造更多的福祉
好了，以上就是本期视频的内容
感谢大家的观看，我们下期再见
