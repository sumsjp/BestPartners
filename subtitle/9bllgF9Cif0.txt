大家好，这里是最佳拍档
你有没有想过
为什么当大语言模型在考试、写代码、解方程上一路开挂时
我们依然没有靠谱的家务机器人呢？
为什么L5级的自动驾驶迟迟无法落地呢？
AI能耗居高不下的根源到底是什么呢？
这一切问题的答案
可能都藏在杨立昆在达沃斯论坛上的一场深度对话中
作为卷积神经网络的奠基人之一
杨立昆的每一次发声都足以影响整个AI行业的发展方向
这次他和计算机视觉资深专家马克·波莱菲斯的对话
全是直击行业痛点的硬核思考
从具身智能的本质定义
到生成式AI的路径误区
再到能够颠覆现有范式的联合嵌入预测架构
甚至包括AI硬件的未来发展方向
每一个观点都值得我们去思考
下一场AI革命会从哪里爆发
今天我们就来给大家分享一下
首先，什么是具身智能呢？
很多人都会误以为
具身智能就等同于机器人
但是杨立昆在对话中
明确纠正了这个认知偏差
他指出
具身智能的范畴远远比我们想象的更广阔
它既包括能够感知、理解、推理
并且在现实世界里采取行动的实体AI
比如自动驾驶汽车、人形机器人
也涵盖了那些没有实体
但是需要处理现实世界数据的非具身物理AI
像制造流程的优化、涡轮喷气发动机的控制、工业过程的调控
这些都属于具身智能的应用场景
那么
判断一个系统是不是属于具身智能的核心标准是什么呢？
答案是数据的形态
只要数据是以高维的、连续的、带噪声的信号序列的形式呈现
那么它就属于具身智能的研究范畴
最典型的例子就是视频
机器人身上的本体感受传感器收集到的信号
也同样符合这个特征
从本质上来说，具身智能所面对的
是一个和语言世界有着天壤之别、充满了不确定性的物理世界
这就解释了为什么大语言模型在语言领域所向披靡
却在物理世界里寸步难行
杨立昆毫不避讳的指出
大语言模型的成功
很大程度上是因为语言相对简单
它是离散的、符号化的
有着明确的规则和逻辑
虽然大语言模型可以通过律师资格考试、解复杂的方程、写高质量的代码
但是这并不意味着它们拥有真正的智能
更不代表了它们能够处理现实世界的复杂问题
这就是为什么我们到了今天
都还没有能够应对日常突发状况的家务机器人
以及消费端的L5级自动驾驶
说到L5级自动驾驶
这绝对是AI行业里最让人期待
同时也是最让人失望的领域之一
我们都知道
Waymo等公司号称已经实现了L4级的自动驾驶
但是它的落地方式充满了取巧的成分
杨立昆在对话中揭露
这些L4级的系统之所以能够运行
完全依赖于完整的高精度地图
并且对运营的时间和空间进行了严格控制
简单来说
它们只能在特定区域、特定时段内安全行驶
一旦超出这个范围
系统就可能会失效
这种方式虽然在技术上实现了突破
但是成本非常高
根本无法大规模的普及到消费端
更关键的是
这种依赖海量数据的训练模式
从本质上就走偏了方向
杨立昆指出，一个十七岁的少年
只需要十到二十小时的练习就能学会开车
而AI系统已经积累了数百万小时的训练数据
却依然无法达到人类的驾驶水平
这背后的核心差异
就在于人类拥有成熟的世界模型
我们在开车的时候
能够预判行人的走位、感知路面的状况、应对突发的交通状况
而这些常识
是当前依赖于模仿学习和强化学习的AI系统完全不具备的
同样的问题也出现在人形机器人领域
现在很多公司都会发布机器人完成高难度动作的视频
但是杨立昆直言
这些动作全是预先计算好的
目前没有任何一家公司知道
怎么样让这些机器人变得足够聪明
可以应对复杂的现实任务
那么这些机器人的常识
甚至还不如一只家猫
家猫还能在陌生的环境中找到食物、躲避危险
而机器人一旦遇到训练数据中没有的场景
就会瞬间宕机
为什么会出现这种情况呢？
答案就在于
当前工业界追捧的技术路线存在着根本缺陷
现在很多企业都在把大语言模型
扩展为视觉语言模型和视觉语言动作模型
希望通过文本优先的思路
让AI同时处理视觉、语言和动作任务
但是杨立昆明确指出
这种方法存在着重大缺陷
很难真正奏效
视觉语言模型的核心思路
是将视觉表示和语言Token结合
再利用大语言模型的架构进行处理
而视觉语言动作模型则是在这个基础上
输出具体的动作序列
但是这些模型的本质
都是利用数据驱动的方式实现脚本式的自动化
它们只能在当动作遵循固定的脚本、需要不断重复的场景下才能发挥作用
一旦遇到了从来没有训练过的全新情境
这些模型就会变得极其脆弱
甚至完全无法应对
这让杨立昆不禁提起了二十世纪八十年代的专家系统
当时最热门的职业是知识工程师
他们的工作是将专家的知识转化为规则和事实
再通过推理引擎来克隆专家的能力
这种方法不需要机器来学习
完全由人工构建
但是最终以失败告终
因为系统太脆弱了
知识迁移的成本太高
只能在极少数的领域适用
杨立昆预测
视觉语言动作模型最终也会面临同样的命运
它们可能在一些特定场景中具有部署价值
但是永远无法实现真正的智能
因为它们缺乏预测行动后果、进行规划和推理的核心能力
而导致这一切问题的根源
在于当前AI行业对生成式AI的盲目追捧
杨立昆在对话中毫不客气的指出
生成式AI是理解物理世界的错误路径
他主张彻底放弃在像素层级进行预测的生成式架构
比如扩散模型
因为这种试图重现每一个细节的努力
不仅是徒劳的
而且也是无法帮助AI理解世界结构的
为什么生成式模型在物理世界中注定会失败呢？
因为现实世界中的细节是无限的、不可预测的
杨立昆举了一个很生动的例子
如果让生成式模型预测一个房间的后续画面
它可能能够预测出房间里有门、有桌子
但是它永远无法精确预测在座每个人的长相
也无法还原出女士裙子上的复杂纹理
因为这些细节包含的信息量太大了
根本不可能被精确的预测
更重要的是，生成式模型的预测方式
完全违背了智能的本质
智能的核心在于能够忽略无关的、而且不可预测的细节
从而进行长期、有效的预测
而生成式模型恰恰相反
它试图还原每一个细节
这就导致了它无法把握事物的核心规律
只能在短期、局部的预测中发挥作用
比如训练生成式模型预测未来十毫秒的视频画面
它可能在短期内非常精准
但是随着时间的推移
预测的结果会迅速偏离现实
那么，正确的路径应该是什么呢？
杨立昆给出的答案是
非生成式的联合嵌入预测架构
这种架构的核心思想
是让AI在抽象表示空间中进行预测
而不是在原始的像素空间或者输入空间
简单来说
就是让AI学会抓住事物的本质特征
忽略那些无关紧要的细节
从而构建出能够理解世界规律的世界模型
要理解联合嵌入预测架构的优势
我们首先要明白
分层世界模型的重要性
杨立昆在对话中详细解释了这个概念
他举了一个规划从纽约到巴黎旅行的例子
当我们制定行程时
绝不会在毫秒级的肌肉控制维度去规划
比如每一步该迈多大、该用多少力气
因为这既复杂又没有必要
我们会在极高的抽象层级上规划
先去机场
再乘飞机
然后将这个大目标分解为更小的子目标
比如下楼、打车前往机场
接着再分解为更具体的动作
比如走向电梯、按电梯按钮、走出大楼
最终
才会落实到肌肉控制的低层级动作上
这种分层规划的能力
正是当前AI系统所缺失的
也是联合嵌入预测架构想要实现的核心目标
一个真正智能的AI系统
需要具备多层级的世界模型
低层级模型负责高细节、短期的动作预测
比如肌肉控制、物体的即时运动
高层级模型则负责抽象、长期的规划
比如旅行安排、任务目标设定
低层级的动作往往无法用语言来描述
而高层级的规划则可以通过语言来进行沟通
那联合嵌入预测架构是如何实现这种分层世界模型的呢？
关键在于它的训练方式
与生成式模型不同
它不会试图重建原始的输入信号
而是通过自监督学习的方式
学习输入信号的抽象表示
在训练过程中，系统会读取一段视频
通过遮掩其中的一部分进行损坏
然后将完整的视频和损坏的视频
分别输入两个编码器
训练预测器从部分损坏的视频中
预测出完整视频的抽象表示
整个系统会进行端到端的训练
最终生成一个能够捕捉世界核心规律的抽象表示空间
更重要的是
它的预测可以基于预想的动作进行调节
也就是说，当AI想要执行某个动作时
它可以通过世界模型预测出这个动作会导致的结果
从而判断这个动作是不是合理
这种从预测到规划，再到行动的闭环
正是人类和动物应对世界的方式
也是构建真正AI Agent的关键
杨立昆还强调
AI系统学习的抽象层级
取决于训练时设定的时间跨度
如果训练系统预测未来十毫秒的状态
它只能掌握低层级的细节规律
如果将预测跨度提升到十分之一秒或者一秒
系统就会自动学习更高层级的抽象特征
而层级结构中位置越高的模型
预测的时间跨度就越长
这种根据预测跨度自动调整抽象层级的能力
让联合嵌入预测架构能够像人类一样
在不同的场景下使用合适的抽象层级来理解世界
比如，我们描述一个房间里的互动时
不会使用粒子物理学的层级
虽然量子场论能够极其精确的描述所有细节
包括神经化学反应和大脑的想法
但是这在实践中完全行不通
因为它需要测量海量的数据
并且进行复杂的计算
我们会使用心理学、社会学或者经济学的抽象层级来理解
这才是最有效的方式
同样
AI系统也需要学会选择合适的抽象层级
才能高效地理解和预测世界
要构建这样的世界模型，数据是关键
相比文本数据
视频数据无疑是训练物理常识的最佳选择
杨立昆指出
人类婴儿正是通过观察世界
才逐渐学会了重力、物体恒存等直觉物理学常识
婴儿需要九个月的时间才能理解
失去支撑的物体会下落这个概念
六个月大的婴儿还无法意识到物体不会漂浮
而十个月大的婴儿就已经掌握了这个规律
AI系统也可以通过视频数据的自监督学习
获得类似的物理常识
杨立昆团队已经进行了相关的实验
他们开发的视频模型V-JEPA 2
在相当于一百年时长的视频数据上进行了训练
这个数据量听起来非常庞大
但是实际上只相当于YouTube一天的视频上传量
具体数字大约在10 的 17 次方到10 的 18 次方个字节之间
以每秒两兆字节的速率计算
这个数据量比目前最大的大语言模型所用的文本数据还要多一百倍
整个互联网上的文本数据大约只有10 的 13 次方个字节
这么庞大的视频数据
到底能够让AI学到什么呢？
答案是物理常识
为了验证这一点
研究团队采用了和心理学家测试婴儿相同的方法
向AI展示一些违背物理规律的视频
比如小球被扔向空中后突然停住、或者变成立方体消失
结果发现
AI模型的预测误差会急剧飙升
这说明了它已经理解了基本的物理规律
认为这些场景是不可能发生的
这是人类第一次看到具备这种常识层级的AI模型
也是联合嵌入预测架构有效性的有力证明
杨立昆强调
这才是AI发展的正确路径
通过非文本数据的自监督学习
让系统获得远超大语言模型的物理常识
因为文本数据只能传递人类已经总结好的知识
而视频数据中蕴含的物理规律、因果关系
是文本无法完全表达的
要实现人类水平的智能
我们必须让AI直接观察和理解现实世界
而非仅仅依赖人类的语言描述
说到这里
就不得不提到杨立昆著名的蛋糕类比
这个类比清晰的阐述了自监督学习、有监督学习和强化学习在智能系统中的角色定位
也解释了为什么当前AI训练方式的效率低下
杨立昆认为，智能系统就像一块蛋糕
其中自监督学习是蛋糕的主体
它负责让AI了解世界、学习抽象表示、建立世界模型和进行预测
这种学习方式不需要观察专家的行为
也不需要他人指导
只需让AI观察世界的自然流逝
就能够自主获取知识
这是智能的核心
人类和动物学到的大部分知识
都是通过这种方式获得的
比如章鱼，它们从未见过自己的父母
却能在几个月内掌握生存所需的所有技能
这正是自监督学习的力量
蛋糕上薄薄的一层奶油
是有监督学习、模仿学习、行为克隆或者逆强化学习
这部分的作用是让AI模仿人类或者专家行为
快速掌握特定技能
但是大多数动物其实并不需要这一步
而且这部分学习在整个智能系统中所占的比重非常小
而蛋糕上的樱桃，则是指强化学习
它的作用仅仅是对AI的行为进行微小的微调
因为强化学习的样本效率非常低
根本无法支撑复杂系统的构建
杨立昆举了一个很形象的例子
如果要通过强化学习
训练一辆自动驾驶汽车在悬崖边行驶
它可能需要冲下悬崖几千次
才能意识到这是危险的
再花几千次，才能学会如何避免掉落
而且这种经验无法迁移
当它遇到另一个不同的悬崖时
可能还需要重新学习
这个例子深刻地揭示了强化学习的局限性
十二年前
很多人认为可以通过强化学习
从零开始训练自动驾驶汽车
但是很快就发现这是不切实际的
需要的试验次数太多，成本太高
而且系统非常脆弱
杨立昆强调
强化学习之所以能够在游戏中取得成功
是因为游戏可以生成海量的训练数据
而且环境是可控的、可重复的
但是在现实世界中
这种条件并不存在
真正高效的学习方式
应该是以自监督学习为基础
构建出成熟的世界模型
然后用有监督学习快速掌握特定的技能
最后用强化学习进行微调
就像一个从没有做过家务的十岁孩子
第一次清理餐桌、装洗碗机就能够成功
他不需要专门的训练
因为他的世界模型已经告诉他
怎么样拿碗
怎么样摆放，怎么样操作机器
多做几次后，他会变得更加熟练
这就是强化学习的微调作用
十七岁的青年学习开车也是同样的道理
世界模型让他能够预判
在悬崖边右转会冲下悬崖
从而避免危险
这比通过无数次试错学习要高效的多
这也解释了心理学中系统一和系统二的区别
系统一是不需要思考的自动化任务
比如熟练后骑自行车、打字
系统二则涉及到前额叶皮层
通过调用心理世界模型来规划行动
比如第一次学开车、制定旅行计划
当前的AI系统大多数只能实现系统一的自动化任务
而联合嵌入预测架构的目标
是让AI具备系统二的规划和推理能力
除了算法和模型以外
硬件也是制约AI发展的关键因素
尤其是能耗问题
人类大脑的运行功率仅仅是二十瓦左右
却能够实现极高的实时反应能力和复杂的认知功能
而当前的AI系统
仅仅是训练一次大语言模型
就需要消耗海量的电力
这背后的核心差异在哪里呢？
杨立昆给出的答案是数据的搬运方式
在人类大脑中
神经元是原地存储和计算的
每个物理突触和神经元
都对应一个处理单元
信息不需要在内存和计算引擎之间来回搬运
因此能耗非常低
但是在当前AI硬件中
受限于制造工艺
我们必须使用硬件多路复用技术
让同一块硅片反复计算不同的神经元
这意味着数据需要不断在内存和计算引擎之间穿梭
而能耗几乎全部消耗在了数据的存取和传输上
虽然GPU通过层级内存缓解了这个问题
但是在目前的CMOS工艺下
我们依然无法实现让每个神经元对应一个计算设备
要解决这个问题
就需要全新的硬件技术
比如自旋电子学、碳纳米管或者光学器件
这些技术能够在纳米尺度上实现模拟存储和原位计算
从而大幅降低数据搬运所带来的能耗
杨立昆还提到，这种低功耗的AI系统
不需要像当前电子设备那么快
因为它是超大规模并行的
人类大脑的运行频率仅为10Hz左右
视网膜的工作频率约为15Hz
这也是电影设定为每秒二十四帧的原因
因为人类会将连续的帧
感知为流畅的运动
从感知信号到做出反应的整个反馈回路
人类大约需要三百毫秒
虽然看起来很慢
但是足够应对大多数现实场景
猫的大脑更小，反应速度更快
能够在眼镜蛇发起攻击的瞬间躲开
这正是超大规模并行计算的优势
除了能耗
硬件的架构偏置也同样重要
当前学术界顶尖的视觉AI
大多都使用视觉Transformer
但是在视频处理中
高分辨率视频生成的Token数量非常庞大
导致Transformer的计算量变得非常夸张
相比之下
卷积网络能够以更少的数据实现相同的性能
而且实时性更强
杨立昆引用了Soumith Chintala的ConvNext研究
研究证明
如果将Transformer的优化技巧应用到卷积网络中
两者的表现几乎难分伯仲
架构本身并没有本质上的优劣
关键在于怎样优化
更重要的是
目前所有的实时视觉AI系统
全部采用的是卷积网络
而不是Transformer
因为实时性是这些系统的硬性要求
而当前的Transformer无法满足这种性能需求
聊完了算法、数据和硬件
我们再回到具身智能的落地问题上
通过视频数据的自监督学习
AI可以获得物理常识和世界模型
但是怎么样将这些能力
转化为具体的具身行动呢？
这也是具身智能面临的最后一公里挑战
当前的问题在于
模型在迁移到新设备时
往往需要从头开始训练
比如一个在模拟器中训练好的机械臂控制模型
当它被部署到真实的机械臂上时
由于硬件参数、环境条件的差异
可能完全无法工作
而且目前的VLA模型
高度依赖特定的相机位置和机械臂配置
缺乏像卷积神经网络的位移不变性等核心归纳偏置
简单来说
就是模型只能在固定的环境中工作
一旦环境发生了变化
性能就会急剧下降
杨立昆的团队在V-JEPA 2.1的实验中
尝试解决了这个问题
他们的方案分为两个阶段
第一个阶段
在长达百年的自然视频数据上
对模型进行预训练
让AI学习视频的特征表示并且填补画面空白
在这个阶段
模型不关联任何特定的动作或者具身
也不涉及机械臂的控制
纯粹就是为了构建对物理现实的高阶抽象表示和预测能力
第二个阶段
他们固定了预训练好的编码器
只微调预测器
并且引入动作作为输入
此时
系统会接收机器人的位置信息、世界状态、下达指令
以及随后的状态变化
训练出两个子模型
一个是机器人本身的机械动力学模型
负责描述关节电机施加扭矩后
手臂或腿的运动方式
另一个是环境模型
负责预测周围环境的变化
此外，还需要一个交互模型
因为环境可能会独立演变
比如空手握拳时，环境不受影响
但是在玻璃杯旁握拳时
就会拿起杯子
AI必须能够建模这种交互关系
实验结果证明
这种训练方式非常有效
第二阶段的微调并不需要海量数据
只需要通过模拟系统动力学
就能够获得足够的训练样本
而且训练出的模型具有很强的通用性
可以用来规划拿起杯子、倒水等各种不同的动作
快速适应不同的具身设备和环境条件
这个方案的核心创新
在于将世界模型的构建和具身动作的适配
分离开来
世界模型是通用的
能够适用于各种不同的具身和环境
而具身动作的适配则是针对性的
只需要少量的数据进行微调
这种通用加专用的模式
既保证了模型的泛化能力
又降低了部署成本
为具身智能的落地提供了一条可行的路径
杨立昆还提到，在硬件架构方面
卷积网络的归纳偏置虽然重要
但是在海量视频数据的自监督学习中
这种偏置可能不再是必需的
因为视频数据提供了几乎无限的信息
模型可以通过数据自主学习到位移不变性等核心特征
但是在实时性要求高的场景中
卷积网络依然是更优的选择
未来的具身AI硬件
可能会根据具体的应用场景
灵活选择卷积网络或者Transformer架构
甚至是两者的结合
在对话的结尾
杨立昆分享了他对未来十年AI发展的愿景
也透露了他新创办公司的核心目标
那就是构建能够理解物理世界、处理任何模态数据的AI系统
这些系统能够构建分层世界模型
利用模型进行规划和推理
具备预测行为后果的能力
其性能将远超当前的大语言模型
杨立昆坚信
这将是一场全新的AI革命
而联合嵌入预测架构正是这场革命的核心
与当前的大语言模型范式不同
未来的AI将不再依赖于自回归的Token预测
而是基于规划的非生成式范式
这种范式上的转变
将让AI从鹦鹉学舌式的语言模仿
升级为洞察本质式的世界理解
他强调，这种非生成式的AI
并不是指模型不会生成任何的内容
而是指它不会试图重现原始的输入信号
在非生成式的联合嵌入预测架构中
预测是在抽象表示层进行的
目标是捕捉世界的核心规律
而不是还原细节
这种方式让AI能够忽略无关的信息
进行长期、有效的预测
从而具备真正的智能
杨立昆还提到，实现这种AI系统
概念上并不存在特别大的挑战
人类其实一直在进行类似的在线自适应
比如当你拿起一个比预想中更重的物体时
会立即调整用力的大小
当你发现自己的预测出错时
会通过观察实际情况
来修正自己的世界模型
这种能力
正是非生成式联合嵌入预测架构想要实现的核心功能
在他看来
现在正是实现这种AI革命的最佳时机
因为实验结果已经证明
通过视频数据的自监督学习
AI可以获得基本的物理常识
分层规划的技术路径已经清晰
他的新公司正是要将这些技术整合起来
打造出具备常识、能够预测行为后果的AI Agent
这场革命一旦爆发
可能将彻底改变AI的应用场景
我们将拥有真正可靠的家务机器人
它们能够应对各种突发状况
自主完成清洁、做饭等复杂任务
L5级自动驾驶也将不再是遥不可及的梦想
AI能够像人类一样应对各种交通场景
实现安全、高效的出行
人形机器人将走出实验室
进入工厂、医院、家庭
成为人类的得力助手
更重要的是
这种AI系统的能耗将大幅降低
能够像人类的大脑一样
以极低的功率运行
为具身智能的普及奠定基础
当然，这场革命也面临着不少的挑战
怎样进一步扩大视频训练数据的规模和质量呢？
如何优化联合嵌入预测架构的训练效率呢？
怎样研发出支持原位计算的低功耗硬件呢？
这些问题都需要整个行业共同努力来解决
但是正如杨立昆所说的
实验结果已经证明了这条路径的可行性
剩下的就是工程上的优化和突破
作为AI领域的传奇人物
杨立昆的每一次探索都走在行业前沿
他始终在质疑主流、探索真相
这次他提出的非生成式AI范式
或许将为未来AI的发展指明新的方向
让我们拭目以待
感谢收看本期视频，我们下期再见
