大家好，这里是最佳拍档
2月5日
SemiAnalysis创始人、CEO兼首席分析师迪伦·帕特尔
接受了The MAD播客的独家专访内容
作为半导体领域的权威研究机构
SemiAnalysis的研究覆盖半导体供应链、云生态、机器学习模型等多个核心领域
甚至会通过数据中心卫星监测和资金流动分析
追踪万亿美元级的AI基础设施建设
在迪伦·帕特尔的研究体系中
他将算力比作AI时代的货币
而英伟达则是这一算力体系的央行
而在这期播客中
帕特尔核心解答了英伟达为何从一芯通吃转向产品组合策略、推理计算的专业化意味着什么、AI基建的资本投入是否是泡沫
以及美中在AI领域的战略博弈到底走向何方等问题
而这些问题
恰恰也是当下AI行业最核心的未解之谜
今天我们就来给大家分享一下访谈的核心内容
首先，聊起当下AI芯片领域的最热点
无疑是英伟达以200亿美元收购Groq的交易
这也是英伟达有史以来规模最大的一笔收购
而这家公司在2025年9月的融资轮中
估值仅为69亿美元
甚至其去年还严重错过了营收目标
这样的收购让很多人感到困惑
但是在帕特尔看来，这笔交易的背后
是英伟达从通用GPU通吃
到专业化芯片布局的核心转型
也是英伟达应对AI行业变革的必然选择
要理解这个转型
首先要明确一个核心前提
当下的AI模型架构
其实还处于高度不确定的发展阶段
虽然行业内基本认同
模型的核心是自回归的下一个token生成
但是模型的运作方式还在不断演变
而随着AI模型的不断发展
它的工作负载已经庞大到足以容纳专业化生存的空间
针对特定领域的专用芯片甚至能带来10倍的性能提升
这也是专用芯片崛起的核心原因
而Groq这家公司
正是专用芯片领域的代表
团队由谷歌TPU的创始人打造
虽然它并不适用于通用工作负载
但是它的核心优势在于极致的速度
尤其在极速的解码和自回归Token的单流处理上
拥有不可替代的技术优势
而这恰恰是英伟达的短板所在
除此以外
AI模型还有一个尚未定论的演进方向
那就是从单一思维链推理
转向多流并行的思维链推理
谷歌和OpenAI发布的Pro模型已经展现出这个趋势
模型可以从海量上下文中切换
并行生成多个流
而这种架构需要对应的专用芯片
这类芯片对延迟的要求没那么苛刻
但是更注重计算的宽度而非深度
英伟达显然看到了这个趋势
因此除了收购Groq补齐极速解码的短板
还自研了CPX芯片
专门用于创建KV缓存、处理上下文
这款芯片甚至对视频模型也适用
因为视频模型对内存带宽并不敏感
无需为通用芯片的昂贵内存付费
而英伟达之所以会如此激进地布局
核心源于CEO黄仁勋的偏执式经营理念
帕特尔将它总结为安迪·格鲁夫的
只有偏执狂才能生存的精神核心
而黄仁勋的这份偏执
本质上是对失败的极度警惕
黄仁勋执掌英伟达超过30年
带领英伟达走过濒临破产的阶段
如今成为全球市值最高的公司之一
但即便如此
黄仁勋依然保持着时刻的不确定性
每天要处理上千封邮件
始终警惕着行业竞争的威胁
在帕特尔看来
如果黄仁勋只是按部就班地制造主流的通用GPU
那么竞争对手迟早会在成本和性能上对英伟达形成碾压
进而动摇其75%的高利润率以及4倍的市场溢价
尤其是在AI模型每三个月就迭代一次的当下
如果芯片架构需要三个月才能适配新模型
那么英伟达的传统优势将荡然无存
更重要的是，英伟达面临的竞争格局
已经远比想象中激烈
在大厂层面
谷歌的TPU、AMD的GPU、亚马逊的Trainium都具备极强的竞争力
Meta的MTIA也在推荐系统和生成式AI领域
形成了细分优势
微软的Maia虽然目前竞争力稍弱
但未来的发展潜力不容小觑
而在初创公司层面
Etched等新一代AI芯片公司获得了大量融资
上一代的Cerebras、Tenstorrent依然在市场中活跃
这些公司都在打造独特的芯片架构
试图在细分领域实现突破
而除了美国的企业
中国也有许多AI芯片公司在做令人兴奋的探索
成为了英伟达不可忽视的竞争力量
也正因如此
英伟达选择了全架构覆盖的策略
产品不仅包括GPU
还涵盖了CPU、网络芯片、NVLink Switch、网卡等庞大的芯片组
同时通过收购公司
获取核心技术和顶尖工程师团队
在英伟达的竞争优势中
Cuda的软件护城河一直是被行业津津乐道的核心
但是在帕特尔看来
当下的Cuda护城河
已经迎来了根本性的演变
甚至可以说
它的传统底层优势正在被逐步稀释
首先，英伟达GPU上运行的大部分软件
并非由英伟达自身开发
而是来自开源开发者生态
这是Cuda护城河的核心基础
而如今这个基础正在发生变化
以vLLM和SGLang为例
这些主流的大模型推理库已经将AMD GPU视为一等公民进行支持
同时vLLM也在大力支持谷歌TPU和亚马逊Trainium
其他初创公司也在跟进对多芯片的支持
这意味着开源生态不再是英伟达的专属阵地
其次
开发者的使用习惯也发生了根本性变化
Cuda的核心价值
在于允许开发者对GPU进行底层编程
但是如今大多数AI芯片的消费者
并不会直接进行底层编程
而是选择下载开源的推理引擎和模型
编写能编译成GPU代码的PyTorch代码
这就形成了一条清晰的用户曲线
当vLLM等开源工具开始全面支持其他芯片时
Cuda的传统优势自然就被削弱了
英伟达也意识到了这一趋势
因此发布了Triton推理服务器等开源软件
来简化用户的使用流程
同时开发了KV缓存管理器等核心工具
打造新的软件护城河
帕特尔以Cursor为例
这类应用的工作负载需要抓取代码库、提取相关部分放入大模型的提示词上下文
还会在智能体模式下循环多次、折叠上下文、暂存数据
这个过程中
推理成本的核心并不是解码
而是输入token的预填充
根据测算
每百万输出token的成本大约为10美元
而输入token的成本大约为3美元
但是如果频繁切换上下文
大部分成本都会花在预填充上
解决这个问题的核心
就是避免重复生成KV缓存
将它存储在SSD中
需要时再加载到CPU或GPU内存中
这就是英伟达KV缓存管理器的核心作用
而这个技术已经超越了传统的Cuda范畴
涉及内存管理、存储管理、调度逻辑、数据传输、跨节点KV缓存分布
以及应对网络拥塞等多个维度
这也是英伟达的核心专长
为了验证各芯片在开源生态中的性能
帕特尔的团队还开展了开源测试项目
测试结果显示
各芯片的性能经常变化
因为软件的更新速度极快
而在与AMD的竞争中
双方呈现出交替跳跃的发展模式
虽然当下英伟达的Blackwell芯片远胜于AMD的MI系列芯片
而当英伟达推出Rubin芯片后
AMD会被进一步拉开差距
但是随后AMD发布的新芯片
可能会在硬件上赶上甚至略微领先
不过软件层面依然会落后
帕特尔预测
AMD在AI芯片市场的份额将始终保持在个位数
即便如此，依托英伟达的万亿体量
个位数的市场份额依然具备极高的商业价值
对于AI芯片初创公司来说
帕特尔直言
这些AI芯片初创公司
想要在市场中立足
胜率不足1%，而唯一的出路
就是专业化
因为英伟达掌控着全球最优质的半导体供应链
能优先获得最新的内存、工艺和封装技术
在通用领域的正面竞争中
初创公司只会被彻底碾压
即便是AMD
凭借着强大的工程能力试图在通用领域与英伟达竞争
也始终难以实现超越
更不用说体量更小的初创公司
尤其是，AI模型的发展速度太快
当芯片最终问世时
AI模型的发展方向可能已经偏离了当初的优化方向
而这就要求初创公司的布局
必须基于对两三年后AI发展的精准预判
这无疑极大地提升了创业的难度
聊完AI芯片的企业竞争
我们再来看看全球范围内的AI地缘博弈
其中美中之间的半导体与AI芯片博弈
无疑是核心主线
帕特尔将其称为AI经济战争的核心战场
而这场博弈的核心
其实是两国各自的半导体本土化战略
首先来看中国
迪伦·帕特尔用半导体上瘾
来形容中国的半导体产业文化
而这种文化
也推动了中国半导体产业的爆发式增长和极致的制造业集群发展
早在2015年
中国就制定了中国制造二零二五等五年计划
设定了国产半导体的目标比例
虽然这些目标极为激进
但是中国在微控制器、普通电源芯片等中低端领域
已经实现了突破
微控制器的性能几乎和德州仪器、意法半导体的产品持平
普通电源芯片也具备极强的市场竞争力
而中国半导体产业的核心优势
在于其极致的专业化制造业集群
帕特尔在专访中提到
中国有很多城市专注于某一种产品的生产
甚至形成了完整的供应链
比如有专门生产灯罩的城市
有专门生产麦克风悬臂的城市
而这些城市不仅做产品组装
甚至还涵盖了核心零部件的生产
半导体产业也是如此
中国的各个省份和城市会发布专属规定
提供补贴、赠款和产业园
吸引半导体企业入驻
形成了适者生存的竞争机制
最终那些成功的地区真正发展了产业并占据了主导地位
这种分散式的产业发展模式
也让中国在半导体领域形成了其他国家无法比拟的完整产业链
帕特尔直言
在10年前甚至20年前的半导体技术节点上
中国已经拥有了完整的垂直整合产业链
这是其他任何国家都做不到的
即便是美国
如果没有海外的材料供应
也无法建立一条完全垂直整合的晶圆厂
即便只是制造20年前的技术
甚至40年前的技术都难以实现
但同时
中国的半导体产业也存在着短期内难以逾越的短板
那就是在光刻机、高端化学品、最精密气体或工具等上游核心技术和设备上
依然与国际顶尖水平存在差距
帕特尔认为，中国目前的光刻技术
大约落后国际顶尖水平10年
未来几年可能会缩短到5年
虽然在快速追赶
但想要达到阿斯麦尔的水平
还有很长的路要走
同样
在顶尖的半导体化学品、设备领域
中国也难以匹敌日本或美国的专业公司
在制造业供应链的最顶端
中国目前还很少处于领先地位
而这个短板
也直接影响了中国AI芯片的发展
目前中国的AI供应链中
依然缺乏最顶尖的芯片技术
华为就是最典型的例子
在被制裁前
华为在手机领域与苹果分庭抗礼
是台积电最大的客户
在电信领域稳居全球第一
其折叠屏手机的产品力甚至超过了三星
但是受限于芯片制裁
华为目前的芯片性能已不如从前
而且由于国内在内存、逻辑芯片及尖端工艺上的产能不足
华为根本无法满足市场对AI芯片的需求
虽然正在全力加速建设
但是短期内供需缺口依然巨大
而芯片制裁也直接影响了中国互联网企业的算力获取
字节跳动就是典型代表
作为全球第二大GPU租赁方
字节跳动的算力需求仅次于OpenAI
但是由于无法在中国境内直接购买英伟达的最先进芯片
字节跳动只能从甲骨文、谷歌等云厂商那里租用大量芯片
主要用于服务TikTok
即便如此
中国的AI模型和开源生态依然展现出了强大的实力
帕特尔指出
目前大多数AI软件都是开源的
而其中有大量的核心贡献者来自中国
AI模型领域也是如此
这也是英伟达对中国市场始终保持警惕的核心原因
英伟达对中国市场的复杂心态
体现在黄仁勋的多次中国行中
帕特尔认为
英伟达始终希望能继续向中国销售芯片
因为如果英伟达被禁止向中国销售芯片
中国就会被迫从零建立庞大的国内芯片和软件市场
进而形成软件与硬件的内部反馈循环
当中国无法再使用英伟达芯片时
国内的开源项目就不会再针对英伟达架构进行优化
而是转向适配华为等国产芯片
这不仅会削弱Cuda的护城河
更会让中国形成独立的AI生态
而当这个生态成熟后
还可以扩展到全球市场
这才是英伟达最核心的顾虑
我们再来看看美国的半导体制造业回流
也就是本土化策略
而这其中
《芯片法案》无疑是核心抓手
这项法案提供了500亿美元的补贴
推动台积电等企业在美国建设晶圆厂
目前台积电已经在美国亚利桑那州为英伟达、苹果、AMD生产芯片
还有韩国公司在德克萨斯州建设气体工厂等配套设施
从这个角度来看
《芯片法案》确实取得了一定的成效
但是在帕特尔看来
这500亿美元的补贴
对于庞大的半导体产业而言
只是杯水车薪
因为人们严重低估了半导体行业的规模和供应链的复杂性
半导体供应链是世界上最复杂的供应链
远比飞机制造庞大得多
全球市值前十的公司中
有八家都在设计半导体
包括谷歌、Meta和苹果
都高度依赖自研芯片
相比之下
其他国家和地区在半导体行业的补贴规模极为巨大
台湾地区的半导体产业总资本支出约为5000亿美元
而美国十年仅投入500亿美元
这样的规模差距
让美国的半导体本土化难以实现质的突破
更有趣的是，《芯片法案》的通过
其实还有一个偶然因素
那就是新冠疫情后的汽车缺芯问题
疫情期间，汽车销量暴跌
原本生产汽车微控制器的工厂被转而生产数据中心、PC和智能手机所需的芯片
而当汽车市场复苏后
车企却无法快速获得芯片
导致汽车价格飙升
这也让美国民众和议员意识到了半导体的重要性
这才推动了《芯片法案》的通过
但讽刺的是
这项法案的所有资金其实都流向了先进芯片
而汽车行业所需要的
其实是中低端的微控制器芯片
资金的流向与法案出台的初衷完全脱节
而美国半导体本土化的另一个核心难题
是晶圆厂的建设周期和技术难度
半导体晶圆厂是世界上最洁净的空间
甚至超过了医院和生物实验室
而半导体制造设备也是世界上最昂贵的设备
远超医疗器械和火箭
这也让晶圆厂的建设成为了一项极其复杂的工程
建设周期极为漫长
帕特尔认为
美国想要实现半导体的完全自给自足
不仅不现实，也不应该成为目标
因为全球化总体而言是好事
半导体产业的发展
本身就依赖于全球供应链的聚合
全球大约有15到20个国家有能力让整个半导体行业停摆
甚至奥地利的两家年收入不到十亿美元的小公司
在某些半导体细分领域却拥有90%的市场份额
这就是半导体产业的全球分工本质
除了芯片和地缘博弈
当下AI行业还有一个核心争议
那就是AI基础设施的资本支出是否存在泡沫
目前超大规模厂商的AI基建资本支出总额
将达到5000亿美元左右
这个巨额投入让市场充满了担忧
而帕特尔作为乐观主义者
认为这个投入并非泡沫
核心判断标准只有一个
AI模型的技术是否能持续进步
首先，从营收的角度来看
帕特尔做出了一个激进的预测
到2026年底
整个AI行业的ARR能达到1000亿美元
其中OpenAI贡献455亿美元
Anthropic贡献350到400亿美元
再加上谷歌、亚马逊、微软等企业的贡献
这个营收规模足以支撑基建投入
从财务模型来看
如果AI行业实现了1000亿美元的ARR
按照50%的毛利率计算
销货成本约为500亿美元
如果基础设施按5年折旧
支撑这500亿销货成本
大约需要2500亿美元的基础设施投资
而目前5000亿美元的资本支出
看似是需求的两倍
但是其中包含了大量的研发成分
而正是去年的超额支出
才带来了今年极其优秀的AI模型
帕特尔强调
只要AI模型的Scaling Law还在生效
模型的进步没有停止
那么这些基建投入就是合理的
一旦模型停止进步
这些支出才会成为徒劳
而从实际价值来看
AI已经开始创造巨大的经济价值
目前GitHub上2%的代码提交已经是由AI生成的
而全球软件工程师的薪资总额约为两万亿美元
这2%的AI生成代码
已经创造了可观的价值
而这个价值还在被市场大大低估
与资本支出争议相伴的
还有AI基础设施的能源和水资源问题
这也是公众对AI行业最主要的误解之一
AI数据中心的巨大能源需求
让市场担忧其会拖垮电网
帕特尔认为
与其说AI数据中心会摧毁电网
不如说其正在迫使电网进行扩张
而美国的电网之所以面临压力
核心原因是过去50年美国几乎没有新建多少电厂
更多是从煤炭转型到天然气
再加上电力行业曾经多次经历投资崩盘
导致如今的电力行业不敢轻易新建产能
这才是电网压力的核心原因
而在AI数据中心的能源选择上
天然气成为了首选
核心原因是它的灵活性
相比之下
核能的建设周期太长
即便是在建设速度最快的中国
建一座核电站也需要五年
远水解不了近渴
太阳能和风能则受限于稳定性和土地占用问题
无法满足AI数据中心的持续算力需求
而煤炭则因污染问题被淘汰
也正因如此
很多科技企业开始选择自建发电设施的模式
在建设数据中心的同时
配套建设天然气发电站
埃隆·马斯克就是这个模式的代表
而这也让独立发电商迎来了新的发展机会
这些企业可以通过建设专供数据中心的发电站
获得超额回报
甚至有企业通过收购旧煤电厂并重启
与超大规模企业合作
实现了极高的投资回报
而另一个被公众广泛误解的问题
是AI会耗尽水资源
帕特尔直言
这个说法完全是危言耸听
水资源问题的本质是分配与管理的挑战
而非总量的匮乏
从数据来看，预计到2027或2028年
数据中心将消耗美国10%的电力
但是在水耗方面连1%都不到
远低于农业、餐饮等行业
帕特尔的团队还做了一个有趣的对比
埃隆·马斯克那座巨型数据中心的用水量
仅仅相当于两家半汉堡店的消耗量
而汉堡店的高水耗
主要源于牛肉生产中饲料的灌溉用水
农业才是真正的用水大户
同时
现代数据中心大多采用闭环循环冷却系统
虽然蒸发冷却会损耗一些水
但是这种方式比传统冷却更节能
对环境更友好，进一步降低了水耗
而市场中出现的一些数据中心水耗争议
比如Meta在路易斯安那州建设的大型数据中心
遭到当地居民抗议
认为导致水质变差
其实是该地区的水力压裂开采所致
与数据中心无关
水力压裂才是当地水质问题的真正根源
这只是公众将对AI的误解转嫁到了数据中心身上
而在AI基建的融资层面
市场对英伟达与CoreWeave、谷歌与Fluid Stack等企业的合作存在循环融资的质疑
认为这种大厂与基建企业的合作存在金融脆弱性
但是帕特尔认为
这个说法完全是过度恐慌
甚至有编造阴谋论的嫌疑
这种合作本质上是大厂利用自身信用
加速AI基础设施建设的合理方式
并非不可持续的泡沫
以英伟达与CoreWeave的合作为例
英伟达向CoreWeave投资了20亿美元
这不仅是资金注资
更是一种认可标签，而核心的合作
在于英伟达为CoreWeave提供全方位的支持
包括收购、土地、电力、能源传输以及数据中心建设等资本密集型事务
而CoreWeave的融资逻辑也很简单
早期凭借与微软签订的GPU租赁合同
就能向金融机构贷款
因为有了顶级客户的背书
金融机构愿意为它提供资金
这个模式的本质
是大厂通过承诺购买算力或股权支持
为基建企业解决融资难题
属于合理的风险分担与生态激励机制
同样的逻辑也适用于甲骨文与OpenAI的合作
OpenAI需要大规模的算力支撑模型训练
因此与甲骨文签订了长期的算力租赁协议
甲骨文则为OpenAI的算力基建提供融资支持
虽然OpenAI目前可能只有支付第一年租金的资金
但是甲骨文相信它未来的增长潜力
愿意为其提供担保
而这个模式的核心
是基建的投入与AI模型的收入增长在时间上的匹配
虽然前期会出现亏损
但是随着模型的成熟和商业化的推进
后期的收益足以覆盖成本
所以这并非循环融资
而是AI产业发展的必然阶段
聊完了AI的硬件、资本、能源
我们再将视角转向软件层面
而当下软件领域最核心的变革
就是Claude Code等AI工具引发的生产力革命
帕特尔将其称为软件生产力的奇点
这场革命不仅正在加速软件开发与知识工作的自动化
甚至已经开始终结初级分析师等低阶的知识工作岗位
帕特尔在专访中分享了多个真实案例
第一个是他的室友
一位顶级的底层程序员
在2025年的圣诞假期
完全依靠Claude Code
在一周内从零开发了一个全新的即时战略游戏
而他全程没有写一行代码
只是通过向Claude Code下达自然语言指令
就完成了游戏的开发
第二个案例来自帕特尔自己的公司
团队中有一位半导体系统方向的分析师
拥有工程背景但是从未真正写过代码
这位分析师通过Claude Code
仅用三个小时就完成了一项复杂的晶圆厂分析工作
首先让Claude Code从卫星图像中计算晶圆厂的占地面积
然后让其查找相关的行业文件并提取核心数据
接着对比数据并制作专业图表
甚至还能根据公司的收购历史
剔除相关财务数据并进行同比例计算
最终为客户找到了精准的投资案例和行业细节
而这项工作
在过去需要专业的数据分析人员花费几天甚至几周才能完成
如今一位非专业人员通过AI工具
仅用三小时就轻松完成
这就是AI带来的生产力提升
而这场生产力革命的直接影响
就是低阶知识工作岗位的消亡
帕特尔直言
现在很多公司已经停止招聘L4级别的工程师了
因为Claude Code等AI工具已经能完成他们的大部分工作
而初级分析师岗位更是首当其冲
无论是成长型风投、公开市场还是私募股权领域的初级分析师
他们的核心工作就是寻找数据、清洗数据、制作图表
而这些工作都能被Claude Code等AI工具完美替代
企业不再需要为这些低阶工作支付薪资
这也让整个知识工作的结构发生了根本性的变化
帕特尔还指出
虽然目前Claude Code的用户体验还存在许多不足
但是这个问题将在六个月内得到解决
未来的AI工具将实现自然语言的无缝交互
用户甚至不需要掌握命令行、编程等专业知识
只需像与人交谈一样向AI下达指令
就能完成复杂的工作
而这也将让AI的渗透率进一步提升
目前全球软件工作和薪资市场的规模
大约为一万亿美元
而Claude Code的渗透率还不到2%
加上Codex、Cursor等其他AI编程工具
目前全球被标记为AI生成的代码提交比例约为5%
而当普通员工开始用AI自动化处理电子表格、办公流程等日常工作时
软件生产力将迎来新一轮的爆发
这也将彻底颠覆人们的工作方式
好了
以上就是本次迪伦·帕特尔专访的核心内容了
希望能对大家有所帮助
感谢收看本期视频，我们下期再见
