大家好，这里是最佳拍档，我是大飞
最近一段时间
我们做了很多期跟人工智能有关的节目
其中也有几期涉及到安全和对齐等等方面
无论是OpenAI的GPT-4
还是Authropic的Claude
亦或是Google的Bard
一直都在努力让大模型变得越来越安全
满足审查的标准，即便如此
OpenAI也不断因为AI的道德问题和数据安全隐患
遭到多方质疑
甚至上周还受到了美国联邦贸易委员会FTC的正式调查
这也是美国监管机构首次正式发起的
对AI聊天机器人风险的审查
由此可见
AI安全本身就是一件重要且艰难的事情
但是
这个世界并不是按照我们的意志去运转的
如果真的有人拿大语言模型来干坏事呢？
就在OpenAI还在因为ChatGPT
疲于应对各方审查的时候
一款“没有道德界限或者限制”的「邪恶版ChatGPT」，
已经悄然在网络上蔓延
它就是WormGPT
根据网络安全公司SlashNext的博客报道
他们的团队在研究生成式AI
在网络犯罪方面的潜在风险时
偶然在一个与网络犯罪有关的著名论坛上
发现了这个WormGPT工具
它是一个GPT模型的黑客版本
据了解
这个WormGPT工具的收费标准是每月60欧元
大约人民币479元
SlashNext对这个WormGPT工具的形容是
一个专门为恶意活动而设计的工具
简直是网络罪犯的武器库
WormGPT的作者是一名黑客
他在论坛上写到
这个项目的目的是提供一个ChatGPT的替代方案
让你可以做各种非法的事情
以及你能想到的所有与黑客相关的事情
都可以用WormGPT来完成
为了证明他的说法
他还上传了相关的截图
显示用户可以要求AI机器人
生成用Python编码语言编写的恶意软件
从公开出来的消息可以得知
WormGPT是基于2021年开源的大语言模型GPT-J开发的
工作方式与ChatGPT大致相同
它可以可处理人类自然语言提出的要求
并且输出所要求的任何内容
包括故事、摘要和代码
还可以生成任意长度的文本
并且支持无限数量的字符
这让它非常适合于制作网络钓鱼邮件和其他社交工程攻击
而且WormGPT还提供了聊天记忆的功能
可以利用先前的联系知识
产生更令人信服的回应
甚至还可以格式化代码
躲过安全软件的检测
提高攻击的成功性
但是与ChatGPT或Bard不同的是
WormGPT不用像OpenAI或者谷歌这样的大公司那样
必须要承担相关的法律义务
也更不会把安全对齐作为自己的首要目标
它几乎没有任何的限制
也更容易被用来做违法的事情
根据SlashNext介绍
WormGPT在各种数据源上进行了训练
尤其集中在恶意软件相关的数据上
再加上它的输出没有任何道德限制
可以被要求执行各种恶意任务
包括创建恶意软件
以及一切与黑客有关的事情
这对于网络犯罪分子而言
无疑是一大利器
对于WormGPT
NordVPN的网络安全专家阿德里安
评价它简直就是“ChatGPT的邪恶双胞胎”，
因为它显然是从OpenAI对ChatGPT不断施加限制、而攻击者则极力想规避这些限制
才衍生出来的产品
为了全面的评估WormGPT及其相关的潜在危险
SlashNext的团队进行了以BEC攻击为重点的测试
我简单介绍一下什么BEC攻击
全称是商业电子邮件泄露
是一种通过电子邮件进行的社会工程学攻击
攻击者一般会伪造电子邮件消息
诱骗受害者执行某些操作
也被称作钓鱼
由于国外电子邮件使用的非常频繁
所以这种攻击手段尤为有效
在实验中
SlashNext团队成员要求WormGPT生成一封电子邮件
内容是向毫无戒心的银行账户经理施加压力
迫使其支付一张虚假发票
在看到WormGPT输出的结果之后
SlashNext团队惊呼危险
WormGPT生成的电子邮件不仅极具说服力
而且在战略上也非常狡猾
展示了它在复杂的网络钓鱼和BEC攻击中的无限潜力
通过测试，SlashNext认为
类似于WormGPT这样的生成式AI技术
可能会给网络安全带来巨大威胁
因为有了这类工具的能力加持以后
就连一个网络犯罪的新手
都能轻而易举的实现诈骗
以BEC攻击为例
使用生成式AI会具有两大优点
一是卓越的语法
生成式AI可以创建在语法上无懈可击的电子邮件
使它看起来非常合法合理，因此
被邮件系统自动标记为可疑邮件的可能性
会大幅度的降低
第二，降低了犯罪的门槛
生成式AI的出现
极大的简化了原本复杂的BEC攻击
即便是技术有限的攻击者
也能够使用生成式AI的技术
它将成为越来越多网络犯罪分子可以使用的工具
针对于生成式AI可能引发的大范围BEC攻击
SlashNext也建议了两种防范策略
1
进行BEC专项培训
公司可以制定相应的培训计划
以应对AI驱动的BEC攻击
要让员工了解到BEC攻击的威胁
以及AI会如何加大这种威胁的原理
第二个 强化电子邮件的验证措施
企业应当执行严格的电子邮件验证流程
当有来自组织外部的电子邮件
冒充内部高管或者供应商时
系统要自动发出警报等等
事实上，在安全方面
除了利用WormGPT编写恶意软件、进行BEC攻击以外
上个月ChatGPT还出现了一个“奶奶漏洞”，
一位名为Sid的用户发现
只要让ChatGPT扮演自己过世的奶奶
来讲睡前故事
就能够顺利骗出Windows 10 Pro的密钥
经过Sid的分享后
越来越多用户也发现了这个漏洞
并开始尝试欺骗ChatGPT报出Windows 11的序列号
其中许多人都成功了
虽然这些密钥大多是无效的
但是也有少量序列号确实是真实可用的
不论是ChatGPT的“奶奶漏洞”，
还是“网络犯罪分子专用”的WormGPT的出现
都证明了至少现阶段AI领域仍然存在着不少挑战和局限性
如果我们现在还认为
生成式AI只是会跟我们聊聊天、或者画个画
那就是too simple too naive了
事实上
我们可以已经一头扎进了史诗般的网络安全地狱中
我相信，第一个完全由AI编写的病毒
可能很快就会出现
大语言模型技术在给我们带来大量效率和想象力的时候
也像是打开了潘多拉之盒
带来了无尽的灾祸，更何况
我们现在几乎没有什么有效的手段
能够阻止黑客或者攻击者利用这样的技术
大不了自己拿开源模型来训练一个
而且可以往危害越来越大的方向去训练
完全不用考虑任何道德约束问题
比方说拿所有的病毒软件代码和漏洞数据
来训练大模型
那么是不是会自动制造出更多的病毒和漏洞攻击
这一点 想想就可怕
未来几年
当正邪人工智能交锋的时候
究竟谁会更胜一筹？
未来的世界又会是怎样的呢？
欢迎大家在评论区发表自己的意见
今天的视频内容就到这里
感谢大家的观看
我们下期再见
