大家好
这里是最佳拍档
我是大飞
如果大家看过漫威的话呢
那么应该对钢铁侠的头盔呢
有很深的印象
通过这个头盔
你可以一眼识别
并且标记出眼前所有的人和物品
并且可以看到这些事物的特征和数据
现在Meta可能正在把这个科幻的设想
变成现实
当最近巨头们正在AIGC的领域
混战的时候
Meta默默的在人工智能的另一个重要分支
计算机视觉上搞起了大动作
上周三的时候呢
Meta发布了一篇名为
segment anything的论文
中文翻译过来就是分割一切
这个论文中呢
介绍了一个全新的segment anything model
简称SAM
可以用来识别图像和视频中的物体
甚至是AI从来没有训练过的物品
所谓的分割呢
用最通俗的话来说就是抠图
但Meta呢这次所展示的AI的抠图能力
远比我们之前想象的要更加强大
甚至在人工智能的领域呢
被认为是计算机视觉的GPT-3时刻
虽然智能抠图这件事呢
并不算是一个新鲜的事物
但是如果你尝试过一些p图软件
就会发现如果想把照片抠的快
抠的准抠的自然
其实是一件费时又费力的事情
而且对于单个主体的图片来说
可能还好处理一点
但是如果一个图片里有几十个物品
都要抠出来
那么目前的抠图软件和工具
都很难的处理好
从技术的角度来讲呢
图像抠图一直就是
计算机视觉领域的
一项经典而且复杂的任务
其中关键的难点
在于识别的时间和精准度
而Meta这次发布的SAM模型
可以说给出了一个几乎完美的解决方案
对于任何一张照片
Meta都可以快速识别照片中的所有物体
并且智能的将其分割成不同的形状和板块
你甚至呢
还可以点击图中的任何物品
进行单独的处理
这次的SAM呢还有一个很大的突破
在于即使是训练过程中
从未遇到过的物品和形状
它也能够将它准确的识别
并且分割出来
而且除了简单的识别
图片中的物体之外呢
这一次SAM还支持
用户使用交互性的方式
来分离出你想要的物体
比如说
你可以将鼠标悬浮在这个物体之上
就能够自动的定位出这个物体的轮廓
即使是颜色非常相近
或者是在连人眼都很难快速分辨的
倒影的图像中
SAM都能够非常准确的找到轮廓的边线
再比如呢
你也可以直接通过输入文字来查询
SAM就可以帮你找到并且标记出
这个图片中
你想找的这个文字所标记的对象
不仅仅是静态图片
SAM也能够准确识别视频中的物体
并且呢还能够快速标记出
这些物品的种类名字大小
并且自动用ID
给这些物品进行记录和分类
Meta表示未来这一技术
会跟AR、VR的头盔进行广泛的结合
这听上去呢
是不是确实有点
钢铁侠的头盔的味道了
听到这里呢
你是不是觉得这个模型已经很厉害了
但是别着急
Meta这次呢还有大招
除了能够把物品从图像中
精准的分离出来
SAM还能够支持对这个物品的编辑
也就是说呢
你可以把这个衣服
从这个模特身上换下来
再换一个颜色
改个大小放到另一个模特身上
你还可以
把你从静态图片中抠出来的椅子
进行3D渲染和编辑
让他从一个图片立刻就能够动起来
接着你还可以改变他的形状
或者进行更多的创意操作
在Meta发布了SAM之后呢
立刻就吸引了大量的关注
英伟达人工智能科学家Jim Fan表示
这次SAM最大的一点突破是
它已经能够基本的
理解"物品"的一般概念
即使对于一些未知对象
或者是不熟悉的场景
比如说水下和显微镜里的细胞
它都能够比较准确的理解
因此它表示相信SAM的出现
会是计算机视觉领域里的GPT-3时刻
不仅是Jim有这样的观点
一些AI研究专家甚至也表示
SAM之于计算机视觉
就像是GPT之于大语言模型
就在SAM发布之后呢
很多人也在第一时间上网进行了实测
不仅大部分网友基本都表示惊叹
一些网友呢还结合自身的工作领域
打开了SAM更广阔的应用的想象空间
有人将包含了众多复杂元素的图片
上传之后呢
SAM 可以毫无压力的把它们都识别出来
无论是近景还是远景
都可以基本准确的找到
大量的复杂的细微的元素
自然科学的研究者呢
将SAM和卫星图像结合在了一起
表示SAM能够很好的识别和找到
它标记的风貌类型
还有神经外科影像学的专家呢
将SAM用到了一个脊髓血管病
的案例文件之中
认为SAM在帮助判断和分析病情上
有很大的帮助
有生物学家输入了一张
显微镜下的组织图片
即使图中的形状特征呢毫无规律
但凭借着Zeroshot的技术
SAM也能够自动识别
多细胞结构中的腺体导管动脉等等
这名生物学家
认为Sam的产出结果
已经非常接近完美
未来应该能够节省大量手动注释的时间
还有呢
骑行爱好者将地图和SAM结合起来
认为能够帮助自己未来更快
更高效的给地图做标记
总体来看呢
跟过去的一些计算机视觉模型相比
SAM在几个方面有着显著的提升和不同
首先呢SAM开创性的跟Prompt结合了起来
它可以接受各种输入提示
例如点击框选
或者指定想要分割的对象
这种输入呢并不是一次性的指令
你可以不停的对图像下达不同的指令
从而达到最终的编辑效果
这意味着此前在
自然语言处理中的prompt模式
也开始被应用在了计算机视觉领域
此外SAM这次是基于1,100万张图片
和11亿个掩码的海量数据集
进行训练
这是迄今为止最大的分割数据集
是OpenImage V5数据集的6倍
这个数据集呢
涵盖了广泛的对象和类别
包括像动物植物车辆家具食物等等
这些图像的分辨率呢
都达到了1500x2250的像素
平均每张图像呢约有100个掩码
这次SAM采用了轻量级的掩码解码器
可以在每次提示仅仅几毫秒内的
网络浏览器中运行
同时呢SAM在各种分割任务上呢
具有很强的零样本性能
零样本也就意味着
Sam可以在不对特定任务或者领域
进行任何额外的训练或者微调的情况下
就可以对对象进行分割
例如呢SAM可以在没有任何
先验知识或者是监督的情况下
来分割人脸手头发衣服和配饰
SAM还可以以不同的方式来分割对象
例如红外图像或者是深度图
Meta表示呢
目前公司内部已经开始使用
SAM的相关技术
用在了Facebook Instagram等社交平台
对于照片的标记
内容审核和内容推荐上
而生成式人工智能
作为创意的辅助工具
今年也将被作为重点优先事项
纳入到Meta更多的应用程序中
这次最让很多业内人士惊喜的地方在于
无论是SAM模型
还是巨大的训练数据集
都是开源的
也就是说
目前任何人都可以在非商用许可下
下载和使用SAM模型以及它的数据
Meta这次推出的SAM模型呢
是希望进一步的加速
整个行业对图像分割
以及更通用图像以及视频理解的研究
随着SAM的演进和发展呢
这项技术呢可能会变成未来AR VR
内容创作设计等等更多领域的
强大的一个辅助工具
最后呢除了开放模型和数据集以外
Meta还推出了一个SAM的演示平台
即使你是一个完全不懂AI的普通用户
也可以在这个网站上呢
亲身体验一下它神奇的抠图功能
网址呢我放到评论区里了
感兴趣的小伙伴们快去试试吧
好了今天的分享就到这里
感兴趣的小伙伴们
欢迎订阅我们的频道
我们下期再见
