大家好，这里是最佳拍档
今天是二零二五年AI盘点的最后一期
作为AI领域的老牌玩家
谷歌在去年交出了一份足以改写行业逻辑的答卷
今天，我们就来完整复盘一下
谷歌一众核心决策层在二零二五年的演讲和访谈实录
还原一下谷歌在算力基础设施、模型架构演进
以及科学发现范式上的底层逻辑与递归重构
要想理解谷歌今年的所有动作
首先得搞懂一个核心的问题
二零二五年的AI，到底处在什么阶段？
谷歌的CEO桑达尔·皮查伊在今年的内部战略会上
拒绝了一个常见的类比
把AI比作火或者电这类传统的通用技术
他说
AI的本质是第一个能够递归式加速创造本身的元技术
传统技术需要人类工程师的外部迭代
比如电力需要发电机的改进、互联网需要协议的升级等等
但是AI可以用自身的能力来优化自己
比如用AI生成代码来改进训练框架
用AI生成合成数据
从而突破人类的数据瓶颈
这种自我迭代的递归循环
让它的进化曲线比摩尔定律更加陡峭
但是
这种超进化并没有带来完美的智能
反而呈现出了一种矛盾的锯齿状
这就是皮查伊引入的人工参差智能
Artificial Jagged Intelligence
简称AJI的概念
你可能见过这样的场景
谷歌的AlphaFold能解析3亿个蛋白质结构
比人类顶尖生物学家快几个数量级
Gemini 3能写出复杂的量子物理模拟代码
但是让它数strawberry里有几个r
它可能会出错
它能控制核聚变等离子体的磁场
却在高中数学的逻辑闭环题上反复栽跟头
DeepMind的CTO科雷·卡武库奥卢用一个实验
解释了这种参差的本质
他们内部的视频生成模型Veo
在训练到30%和60%时
生成的内容都是一团噪点
但是跨过某个阈值后
连贯的时空结构、光影关系、甚至物理规律
突然涌现出来
这种从0到1的相变，不是线性进步
而是突变
就像AlphaGo从零开始自我对弈
几小时内就超越了人类巅峰一样
AJI阶段的参差不齐
正是这种非线性涌现的必然结果
智能不是均匀的流体
而是在不同维度上
以不同速度爆发的离散能力集合
而在皮查伊看来
二零二五年的AI行业还有一个更关键的转向
从代码编写到意图指引的不可逆跃迁
这不是简单的聊天机器人升级
而是要构建大语言模型的操作系统
让大语言模型像CPU一样
调用搜索、工具、规划能力
处理复杂任务
他特别警告，Scaling Law是没有失效
但已经从数据无限模式
进入了数据受限模式
过去
堆更多的互联网数据、扩更大的模型参数
性能就会线性提升
但是现在
高质量的人类数据已经耗尽
再靠参数堆料，只会边际效益递减
未来的智能提升，必须靠两件事
一是合成数据策略
用Gemini Ultra这样的强模型来生成高质量的数据
再通过消融实验验证后
训练下一代模型
二是架构优化
用专家混合这样的稀疏架构
把参数规模和计算规模解耦
理解了AJI阶段的核心特征后
我们不禁要问，突破AJI
通往AGI的核心障碍是什么呢？
谷歌 DeepMind的CEO德米斯·哈萨比斯给出的答案是
构建能够逆向工程物理现实的世界模型
哈萨比斯对世界模型的定义
远超我们常说的视频生成
他说，像Genie 3这样的模型
价值不在于生成逼真的像素
而在于它能从海量视频中
在没有任何显式物理代码输入的情况下
自学出重力、惯性、光影反射的规律
这是对物理世界直观物理学的逆向工程
DeepMind的研究总监什洛米·弗鲁赫特
举了一个震撼的例子
当你在Genie 3生成的虚拟世界里
控制视角移开一个物体
过一会儿再回来时
那个物体还在原地
甚至状态会符合物理演化
比如杯子倒了，水会一直流到地面
这种一致性不是靠3D网格这些传统图形学工具设定的
而是从神经网络的自回归生成中涌现出来的
这证明了一个关键的结论
那就是亚符号的、随机的神经网络
完全能够构建出符合因果律的物理世界表征
这打破了只有显式建模才能模拟物理的传统范式
哈萨比斯甚至把这个技术拔高到了哲学层面
他提出了一个世界模型版的图灵测试
如果一个系统能生成逻辑一致、符合物理定律的交互式环境
经得起用户的任意探索
就证明它真正理解了这个世界的运行法则
而如果AI能够生成完美一致的物理世界
或许能为模拟理论提供一个实验视角
我们所处的现实
会不会也是一种计算的产物呢？
这个思路并不是空想
在科学领域
谷歌已经开始用世界模型突破人类的认知边界
比如用AI来控制托卡马克装置的等离子体
在微秒级内调整磁场
防止等离子体逃逸
这是可控核聚变的关键一步
GraphCast气象模型
比传统的天气预报精度更高
计算效率却提升了1000倍
哈萨比斯说，未来的世界模型
甚至可能发现人类尚未掌握的物理定律
AI正在从工具变成科学家
谷歌今天的AI优势
不是靠突然的技术爆发
而是源于十几年前的工程积累
二零二五年
杰夫·迪恩、德米斯·哈萨比斯等核心高管
首次公开了多个关键技术节点的考古细节
让我们看到AI大规模训练的原点
二零一二年，深度学习刚刚起步
单机GPU的显存和算力
根本撑不起大规模的神经网络
谷歌大脑团队为了解决这个问题
构建了一个名为DistBelief的软件系统
其中用了一个违背数学常识的策略
异步训练
正常来说，分布式训练需要同步更新
所有机器的模型副本
要基于同一版的参数计算梯度
再一起更新
但是异步训练不一样
200个模型副本被部署在不同的机器上
各自读数据、算梯度
然后把梯度异步发给参数服务器
服务器收到就更，不等待其他的副本
当时的凸优化理论认为
这会导致不同副本用不同版本的参数来计算梯度
引入巨大的噪声，模型肯定会发散
杰夫·迪恩回忆说
当时所有人都觉得这在数学上完全不成立
但是工程实测的结果颠覆了理论
在大规模数据和神经网络高容错性的加持下
这种粗糙的异步更新不仅没有发散
反而靠极高的吞吐量
暴力破解了收敛难题
二零一二年的猫脸识别实验
就是最好的证明
团队用一千万条YouTube视频帧
训练了一个十亿参数的模型
只设了一个目标
最小化图像重构的误差
结果
模型顶层神经元自发学会了识别猫脸、人脸、行人背部
在ImageNet的两万两千个类别测试中
相对精度提升了70%。
这个实验不仅验证了无监督预训练的价值
更奠定了后来Bert、GPT自监督学习的基础
TPU的诞生，也不是技术前瞻性的产物
而是被业务需求逼出来的
二零一四年
谷歌内部做出了一个高质量的语音识别模型
团队算了一笔账
如果把这个模型部署给一亿的安卓日活用户
每人每天用三分钟
现有的数据中心规模需要翻倍才能撑住
这在成本和物理空间上都不可能
于是
杰夫·迪恩的团队回归了第一性原理
深度学习推理的本质
是海量低精度的线性代数运算
比如矩阵乘法或者向量点积
但是通用CPU为了兼顾操作系统、数据库
保留了大量的高精度浮点单元
在AI负载下就是硅片浪费
于是
他们决定做一个舍弃通用性、只专注低精度运算的专用加速器
TPU v1
TPU v1采用了脉动阵列架构
最大化芯片内部的数据复用率
减少对内存带宽的依赖
实测数据显示
它比同期CPU、GPU的推理速度快十五到三十倍
能效比高出三十到八十倍
这个决策不仅解决了当时的语音识别算力危机
更让谷歌在十年后拥有了非对称成本优势
现在支撑Gemini大规模推理的
正是一代代迭代的TPU集群
和谷歌大脑自下而上的工程探索不同
DeepMind早期走的是自上而下的大教堂式设计
押注深度学习与强化学习的结合
解决智能体的通用决策问题
2013年的Atari游戏研究是第一个里程碑
系统只看屏幕像素
用DQN网络学会了二十六款游戏的策略
最惊艳的是打砖块游戏
它没有被教过任何的技巧
却自发发现了打穿一侧的墙壁
让球在上方反弹清屏的高级策略
这证明端到端的强化学习
能在高维空间里自主优化策略
而从AlphaGo到AlphaZero的演进
更验证了摆脱人类先验的重要性
早期的AlphaGo是混合系统
先用人类棋谱做监督学习冷启动
再用强化学习自我对弈
但是AlphaZero彻底抛弃了人类棋谱
从零开始自我对弈
结果
它发现了人类从未想到的围棋策略
因为它没被人类认知里的次优解束缚
哈萨比斯说
这个逻辑现在正在科学领域复现
比如Isomorphic药物研发平台
目前还需要硬编码原子键角度
物理重叠限制等等
来缩小搜索空间
但是它的终极目标是让神经网络内化所有的物理化学规则
实现端到端的可微学习
到那个时候
AI就不再需要人类预设公式
能从实验数据中重构自然规律
二零二五年AI行业的竞争
已经不是单一模型性能的比拼
而是系统能力的较量
谷歌公开的三大技术护城河
稀疏架构、全栈基础设施、原生多模态
正是它能领先行业的核心原因
杰夫·迪恩在演讲中抛出了一个颠覆性的观点
现代前沿大模型的架构
已经从稠密彻底转向了稀疏
传统稠密模型，比如GPT 3
每次推理都要激活所有的参数
不管你问的是早上好还是量子力学
都要调动千亿参数进行全脑计算
这是巨大的算力浪费
而谷歌大规模应用的专家混合架构MoE
把模型拆成了多个专家子网络
每个专家专精一个领域
系统里有个路由机制
能分析输入的每个Token
精准发给最擅长的一到两个专家
杰夫·迪恩披露了一个关键数据
Gemini推理时
只激活总参数量的1%到5%。
这种稀疏性带来的优势是指数级的
在训练端，保持同等精度的前提下
算力成本可以降低八倍
同样是十的二十五次方 Flops的预算
谷歌能训练出参数规模大十倍的模型
在推理端
虽然Gemini的总参数量是万亿级
但是单次推理的活跃参数
只相当于百亿级模型
延迟和成本大幅降低
但是稀疏性的门槛也是极高的
跨芯片、跨机柜的通信负载会暴增
谷歌为此构建了Pathways系统
能让一个Python进程控制数千个TPU芯片
最新的Ironwood TPU Pod集群
用3D环面光互连技术
把9216个TPU连成一个算力网络
自动处理数据流转和故障恢复
这种软硬件深度耦合的稀疏栈
是单纯堆GPU的竞争对手很难复制的
谷歌 Cloud的CTO威尔·格兰尼斯在二零二五年指出
AI基础设施的逻辑已经彻底变了
过去是训练优先
拼峰值算力和批处理吞吐量
现在是推理优先
因为模型大规模商用后
推理的算力消耗会远超训练
谷歌最新的Ironwood TPU Pod
就是为推理量身定做的
它的十倍性能提升、两倍能效提升
不是靠芯片制程
而是芯片、网络、编译器和模型的全栈优化
比如Gemini的设计会适配TPU的互联拓扑
最大化All Reduce的通信效率
TPU则针对Gemini的长上下文KV缓存
优化了存储层级
更关键的是它的抗脆弱性
威尔·格兰尼斯称之为成功危机
比如二零二五年的爆款应用Nano Banana上线时
每秒查询量超出了预估两个数量级
普通的GPU集群早就雪崩了
但是谷歌靠着动态引流、任务分片和全球资源池化等技术
可以在毫秒内把请求调度到空闲的TPU上
这种网络规模的稳定性
是只有做过搜索、YouTube的公司才能积累的能力
现在很多的多模态模型其实是缝合怪
比如用Vit处理图像
用ASR处理音频
再转成文本嵌入喂给大语言模型
这种方式会丢失大量的细节
比如语调情感、图像纹理等等
而Gemini从预训练的第一天起
就用单一神经网络
来直接处理文本代码
音频图像视频
这种原声设计的成本很高
图像视频的Token量远超文本
不同模态还会互相干扰
比如优化图像生成
可能会让文本推理变差
但是谷歌坚持这么做
因为它能带来更强大的涌现能力
比如Vibe Coding
Gemini 3能看一张韩语手写的食谱照片
直接生成带计量单位转换的英文交互式App代码
这不是OCR+翻译+代码生成的线性叠加
而是它理解了手写位置对应UI按钮的空间逻辑
再比如长视频推理
Gemini 2.5 Pro的一百万Token上下文
能处理几小时的板球比赛视频
精准找出所有三柱门被击倒的时间点
这需要它同时理解图像的内容和时序逻辑
DeepMind的CTO科雷·卡武库奥卢说
未来的目标是图像生成与文本生成的统一
现在Nano Banana Pro已经能做到
同一个模型
既能按文本来生成图像
又能像素级进行编辑
还能保持场景的一致性
这证明了模型对视觉特征和语义概念
有了统一的深层理解
当然，技术最终要落地为真正的产品
谷歌二零二五年在模型架构和产品形态上的多个突破
正在重新定义人与AI的交互方式
传统生成式模型的推理是线性一次性的
看到输入就直接输出下一个Token
没有中间的思考过程
所以处理数学题和复杂的规划任务时
容易出现逻辑断层
谷歌首席科学家杰克·雷说
Gemini 2.5 Pro之后
他们引入了测试时计算机制
AI在输出最终的答案前
会生成不可见的思考Token
在草稿空间里做多步推理、验证假设、修正错误
比如Gemini的Deep Think模式
能够并行探索多个解题路径
像AlphaGo的蒙特卡洛树搜索一样
评估不同思路的合理性，再选最优解
杰克·雷说
这是用推理时间来换智能精度
把Scaling Law的维度
从参数规模的数据量
扩展到了推理的计算量
现在Gemini处理国际数学奥赛题目时
能够展现出超越人类直觉的逻辑深度
就是靠这种思考机制
谷歌 Labs的产品负责人乔希·伍德沃德在二零二五年宣布
生成式界面的时代来了
过去的UI是工程师硬编码的
不管用户需求多灵活
只能用预设的模板
而Gemini 3能够实时流式生成UI组件
比如你想计划一场罗马的三天旅行
Gemini不会只给文本
而是会分析你的需求
动态生成带有轮播景点图、交互式地图、时间轴的定制网页
乔希称之为像素的流动性
界面的每个按钮、布局、交互逻辑
都是AI在运行时决定的
再比如查询冒泡排序算法
对于初学者来说
AI会生成交互式的动画来演示数据交换
而对于资深工程师来说
会直接生成优化后的代码和性能分析图表
这种千人千面的交互
正在打破App和网页的形态边界
科雷·卡武库奥卢和Gemini的产品负责人图尔西·多希
则在二零二五年重点介绍了Vibe Coding
它正在颠覆软件的生产方式
传统的低代码平台还需要用户懂循环条件判断
但是Vibe Coding已经能够消除想法和实现的所有中间层
他们展示了一个案例
图尔西用自然语言描述
想要一个80年代街机风格的贪吃蛇游戏
带有得分板和音效
Gemini实时生成了完整的Web应用
包括游戏逻辑、视觉风格、交互反馈
另一个案例则更加惊艳
用户画了一张手绘的网页草图
Gemini直接生成了对应的HTML和CSS代码
甚至能理解这里是按钮
点击跳转到详情页的逻辑
科雷说，这会让更多人成为建设者
医生能自己做医疗辅助工具
教师能做交互式课件
艺术家能开发生成式艺术应用
自然语言成了终极的编译器
把人类意图直接变成了可执行的软件
杰克·雷还探讨了记忆对AGI的重要性
虽然Gemini 2.5 Pro已经支持了一百万Token的上下文
能够像大海捞针一样
在海量文本中找事实，但是这还不够
当前的上下文仍然是有限的
而且推理的成本会随着长度线性增加
而谷歌的目标是终身记忆
让AI能跨越几个月、几年的时间
记住你的偏好、习惯、过往的经历
比如你去年跟它聊过
喜欢意大利小众酒庄的红酒
今年问推荐度假地点的时候
它能够自动关联到这个偏好
为了实现这个目标
谷歌正在探索神经图灵机的现代变体
把记忆从模型参数中解耦出来
存在外部的向量数据库里
让模型学会索引和检索这些历史信息
从而在不增加计算负担的同时
拥有近乎无限的记忆容量
杰克·雷说
这种终身记忆是AI成为个性化数字伴侣的前提
二零二五年
谷歌的核心高管们还首次公开了对AGI终局的具体判断
包括时间窗口、技术瓶颈、风险管控
甚至提到了将量子计算作为第二增长曲线
哈萨比斯今年明确给出了AGI的时间表
还需要五到十年
他认为
当前AJI阶段的核心瓶颈有三个
一是持续学习
现在模型训练后就冻结了
而AGI需要能从每次交互中实时更新知识
二是世界模型
模型需要理解物理因果律
而不只是文本的统计规律
三是长程规划
模型需要能拆解长期目标
而不是只预测下一个Token
他描绘的AGI终局是一个全能模型
把Genie、Veo、Gemini、AlphaFold的能力
融合进一个单一的模型中
这种融合不是功能上的堆砌
而是要利用能力的乘数效应
比如懂蛋白质折叠的模型
可能因为掌握微观物理
在宏观材料设计上有新的突破
懂视频物理规律的模型
能让机器人的操作精度大幅提升
Gemini 3的预训练负责人塞巴斯蒂安·博尔热奥则澄清
Scaling Law没有撞墙
只是动力源变了
过去主要靠人类数据
现在靠合成数据和架构效率
合成数据的逻辑很简单
用强模型生成高质量的数据
比如在数学、代码领域
模型能生成无限多可验证的题目和答案
而Genie 3生成的虚拟世界
能给具身智能提供无限的训练数据
哈萨比斯说
AlphaZero靠自我对弈生成的数据
已经超越了人类围棋历史总和
AI正在自己制作教材来训练自己
而架构效率的提升同样关键
杰夫·迪恩说
光是Pathways系统和JAX框架的算法优化
就能在不增加硬件的情况下
让性能提升一个数量级
现在的Scaling Law
增长引擎已经从人类数据
切换到合成数据+计算效率
暂时还看不到物理上的天花板
在幻觉方面
皮查伊今年在BBC专访中则直言
Transformer架构有个阿喀琉斯之踵
那就是概率性
大语言模型本质是下一个Token的预测器
靠统计规律来生成内容
不是靠逻辑查证事实
所以幻觉无法彻底根除
但是他强调，幻觉是创造力的代价
如果模型完全不出错
就只能复读已知的事实
也就无法生成新的诗歌、新的代码
因此，谷歌的应对策略是系统级防御
一是强调事实
强制模型调用搜索等外部工具来验证事实
不单纯依赖内部的权重
二是置信度校准，让模型学会元认知
知道自己何时在瞎编
然后主动拒绝回答
三是人机协作
在像医疗、金融这样的关键领域里
AI只给选项
最终决策权仍然在人类的手里
对于AI安全社区热议的毁灭人类概率
皮查伊提出了一个反直觉的观点
他认为这个概率是动态的
而不是一个固定值
他以核武器管控、臭氧层修复为例
认为当威胁足够具体时
人类会爆发出集体协作的能力
如果AI的风险真的逼近临界点
全球会自动统一目标
管控风险
谷歌的具体动作则包括
大规模的红队测试、开源Synth·ID水印技术
以及渐进式部署
皮查伊说，没有完美的AI
只能在创新和安全之间找到最佳的平衡
皮查伊在专访中还提到一个容易被忽视的点
那就是量子计算现在的进展
相当于5年前的AI
5年前的AI
正是Transformer刚刚诞生、ChatGPT爆发前夜的阶段
他预判，量子计算会在2030年左右
迎来ChatGPT时刻
为什么要布局量子计算？
皮查伊说，自然界的本质是量子的
AI靠概率统计模拟宏观规律
到一定阶段就会遇到瓶颈
而量子计算能基于物理本质
精准模拟分子结构、材料特性、生物过程等等
比如现在AI设计新的药物
还需要大量的实验验证
未来量子计算能直接模拟药物分子与靶点的作用
大幅缩短研发周期
这也是谷歌为未来十年埋下的伏笔
当AI的宏观模拟触顶时
量子计算会接棒成为探索宇宙本质的新工具
二零二五年，谷歌的技术落地
也已经在科学发现、编程、教育等领域
引发了结构性的变革
哈萨比斯把AI在科学领域的应用
称为新文艺复兴
核心是压缩时间
把原本需要十年、几十年的科研周期
缩到几个月甚至几天
在生物学领域
AlphaFold已经解析了三亿个蛋白质结构
覆盖了地球所有的已知生物
相当于给生物学家提供了完整的生命地图
Isomorphic Labs和礼来、诺华等医药公司合作
用AI来设计候选药物
2026年就会进入临床试验
将药物的发现周期从十年缩短到了几个月
在材料学领域
G·Nome模型发现了三十八万种稳定的新材料
这是人类过去几百年发现总量的十倍
其中包括更高效的电池电极、更强的超导体等等
在能源领域
AI控制核聚变等离子体的技术
已经能在微秒级调整磁场
这是可控核聚变商业化的关键一步
GraphCast气象模型，不仅精度更高
计算效率还提升一千倍
能够更早的预测极端天气
皮查伊在二零二五年还证实
谷歌内部25%以上的新代码
已经由AI来生成了
这说明AI编程已经从辅助工具
变成为主力的生产力
前端领域，生成式界面让从设计稿
到切图
再到写HTML和CSS代码的传统流程彻底失效；
后端领域
Vibe Coding让非技术人员也能描述需求
生成逻辑代码
而初级程序员和只负责把需求翻译成代码的码农
面临着失业风险
但是新的职业也正在诞生
比如AI裁判
专门评估AI生成代码的质量、合规性
还有AI系统架构师
通过设计多AI Agent协作的架构
理解系统边界比掌握语法更加重要
皮查伊说
代码会成为全人类的基础能力
但是编程职业会向高端架构设计收缩
此外
Gemini 3的跨语言、跨模态能力
正在打破知识传播的壁垒
比如把韩语手写论文
实时转成中文的结构化文档
把复杂公式转成交互式的动画
皮查伊说
这能够释放全球80亿人的认知潜力
AI会成为适应性的导师
根据学生的水平来动态调整教学的节奏
而人类的核心技能
正在从记忆与执行
转向系统思维、鉴别力和问题定义
这些AI无法替代的能力
够会成为未来教育的核心目标
回顾谷歌二零二五年的所有动作
我们能够清晰的看到一个趋势
AI已经完成了从单一工具到复杂系统的演进
AJI阶段的参差不齐，不是缺陷
而是技术爆发的必经之路
稀疏架构、全栈设施、原生多模态
构成了AI系统的硬件底座
思考机制、生成式界面、终身记忆
定义了AI与人类交互的软件形态
哈萨比斯说
二零二五年不会是AGI的终点
但会是从狂热到理性的转折点
未来五到十年
AI会从辅助工具变成基础设施
渗透到科学、医疗、能源的核心环节
而人类要做的，不是害怕AI超越
而是掌握与AI协作的能力
用AI的时间压缩特性来加速文明进程
同时用系统思维来把控风险的边界
也许
就像皮查伊在二零二五年的年终信中所写的
AI的机会
大于火、电、互联网的总和
我们正站在范式转移的临界点上
而理性、耐心与长期主义
会是穿越周期的唯一钥匙
感谢收看本期视频，我们下期再见
