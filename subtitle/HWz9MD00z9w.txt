大家好，这里是最佳拍档
过去几年
AI行业一直在进行一场轰轰烈烈的规模竞赛
大模型的参数量
似乎成了衡量技术实力的唯一标准
但是，这场竞赛的背后
是整个行业难以承受的成本压力和技术瓶颈
更关键的是
当模型的参数量突破5000亿后
通用能力的提升幅度不足5%，
但是算力消耗却会直接增加3倍以上
这种规模与效率失衡的困境
不仅让大模型的商业化落地举步维艰
更把无数中小企业挡在了AI革命的门外
而就在2026年新年第一天
DeepSeek团队发布了一篇题为《mHC:
流形约束超连接》的重磅论文
梁文锋再次署名
这篇论文提出的mHC架构
没有走堆砌参数的老路
而是从基础架构层面入手
彻底解决了传统超连接技术
在大规模训练中的稳定性难题
同时保持了显著的性能增益
今天我们就来给大家解读一下
要理解mHC架构的革命性
我们首先要回到大模型的基础
残差连接
过去十年里
残差连接（Residual Connection）一直是Transformer架构的核心组成部分
它通过在网络层之间建立直接的恒等映射路径
解决了深层神经网络训练中的梯度消失问题
简单来说
残差连接就像是给信号传递开辟了一条高速公路
让前向传播的特征和后向传播的梯度
都能稳定流动
这也是大模型能够不断加深层数、提升性能的关键基础
随着大模型规模的扩大
研究人员开始尝试通过扩展残差连接的宽度和多样化的连接模式
来进一步提升性能
这就催生了超连接Hyper-Connections技术
简称HC
超连接的核心思路
是打破传统残差连接的单一路径限制
让每个网络层都能与更多的层建立连接
从而增强特征传播的丰富性
理论上
这种设计能够让模型捕捉到更复杂的语义关联
带来显著的性能提升
但是在实际的大规模训练中
超连接技术暴露了严重的缺陷
首先是训练不稳定性问题
超连接的多样化连接模式
从根本上破坏了残差连接固有的恒等映射属性
导致前向传播的信号出现爆炸现象
后向传播的梯度也变得极不稳定
在DeepSeek的实验中
传统超连接在大规模训练时的最大增益幅度接近3000
这种剧烈的数值波动
会让模型训练过程充满不确定性
甚至直接导致训练失败
其次是显存消耗和计算效率的问题
超连接带来的大量跨层连接
使得模型的内存访问开销急剧增加
尤其是在处理百亿级以上参数模型时
显存占用会呈指数级增长
这也是为什么很多采用超连接架构的模型
虽然在小规模测试中表现出色
但是一旦扩展到千亿参数级别
就会面临练不动、跑不起的困境
最后是可扩展性受限
由于训练稳定性和显存消耗的双重制约
传统超连接模型很难在更大参数量、更长序列长度的场景下进行扩展
这与大模型向AGI进的趋势严重不符
对于中小企业来说
这些问题更是难以逾越的鸿沟
即便能够获取开源的超连接模型
也缺乏足够的算力支撑训练和部署
只能望而却步
这些问题并非个例
而是整个行业在追求性能提升过程中
遇到的共性瓶颈
当参数规模的扩张遇到天花板
当训练成本高到让头部企业都感到压力
AI行业迫切需要一种新的架构设计思路
在不牺牲性能的前提下
解决稳定性和效率的核心矛盾
而DeepSeek的mHC架构
正是在这样的背景下应运而生
流形约束超连接mHC的核心目标非常明确
那就是在完整保留超连接加宽残差流
带来的性能提升基础上
彻底解决它所导致的训练不稳定和显存消耗过大问题
为了实现这个目标
DeepSeek的研究团队提出了两大核心设计
流形约束机制和高效基础设施优化
我们先来看流形约束机制的设计思路
研究团队发现
传统超连接之所以会破坏恒等映射属性
关键在于其连接矩阵的随机性和无约束性
为了恢复恒等映射的核心优势
同时保留多路径连接的灵活性
mHC架构将连接矩阵约束在双随机矩阵流形（Doubly Stochastic Matrix Manifold）上
那么什么是双随机矩阵呢？
它是一种满足两个核心条件的矩阵
第一，矩阵中的所有元素都非负
第二，矩阵的每一行元素之和等于 1
同时每一列元素之和也等于 1
之所以选择双随机矩阵
背后还有两个关键的数学性质作为支撑
第一个性质是双随机矩阵的Spectral Norm不超过 1
这意味着双随机矩阵本身是一种 非扩张映射
它不会放大输入信号的幅度
当连接矩阵被约束为双随机矩阵时
信号在经过连接矩阵传递时
最大幅度不会超过原始信号
这就从数学上杜绝了信号放大的可能
第二个性质是双随机矩阵的 组合封闭性
也就是说
两个双随机矩阵相乘的结果
仍然是双随机矩阵
这样就保证了
即使信号经过多层网络传递
经过多个双随机矩阵连乘后
最终的映射仍然是双随机矩阵
仍然满足Spectral Norm小于等于1 的性质
从而确保了信号在整个网络传播过程中的稳定性
既不会被放大到爆炸
也不会被衰减到消失
更巧妙的是
当双随机矩阵的维度 n=1 时
它会退化为一个标量 1
这时候整个架构就完全恢复到了原始的残差连接
这意味着 mHC 架构与传统残差连接是完全兼容的
为技术迁移和落地提供了极大的便利
实现这个约束的关键算法
是辛克霍恩-诺普Sinkhorn-Knopp算法
这是一种迭代式的矩阵归一化算法
能够在有限的迭代次数内
将任意非负矩阵
转化为满足双随机约束的矩阵
在mHC的设计中
研究团队将迭代次数限制为20次
既保证了约束效果
又控制了额外的计算开销
实验数据显示，通过这种约束
mHC架构单层映射的后向梯度增益
仅略微偏离了1
而复合映射的最大增益幅度约为1.6
相比传统超连接的近3000
稳定性提升了整整三个数量级
更令人惊喜的是
mHC 架构并没有因为引入约束而牺牲性能
反而在大多数基准测试中
实现了对 HC 架构的超越
在 BBH推理任务上
mHC 比 HC 提升了 2.1 个百分点
在 DROP 阅读理解任务上
提升幅度达到了 2.3 个百分点
在 GSM8K 数学推理任务和 MMLU 多任务语言理解任务上
也分别实现了 0.6 个百分点和 0.4 个百分点的提升
这些数据充分证明
通过流形约束实现的稳定性提升
并没有限制模型的学习能力
反而因为训练过程更加平稳
让模型能够更好地收敛到更优的参数空间
从而实现了性能的进一步突破
更重要的是
这种流形约束是一种通用框架
并非针对特定模型或者任务设计
这意味着它可以无缝集成到各种基于Transformer的大模型架构中
无论是自然语言处理模型、计算机视觉模型
还是多模态模型
都能通过引入mHC架构
获得稳定性和效率的双重提升
这种通用性对于推动技术落地至关重要
避免了企业需要为适配新架构而进行大规模改造的成本
除了核心的流形约束机制
mHC架构还进行了严格的基础设施优化
来解决显存消耗过大的问题
传统超连接的大量跨层连接
会产生巨大的内存访问开销
这是导致显存占用激增的主要原因
为了解决这个问题
DeepSeek 团队采取了多方面的工程优化策略
其中最核心的包括算子融合、选择性重计算和通信重叠调度
算子融合是指将多个具有共享内存访问模式的计算算子
融合为一个统一的计算内核
在传统的 HC 架构中
多流残差的计算、连接矩阵的乘法、激活函数的应用等
都是独立的算子
每个算子都需要单独访问内存
导致大量的冗余数据传输
而 mHC 架构通过算子融合
将这些分散的计算步骤整合到一个内核中
减少了内存访问的次数和数据传输量
从而显著提升了内存带宽的利用率
更重要的是
这种融合在数学上是等价的
不会影响计算结果的准确性
只是通过改变计算的组织方式
实现了效率的提升
选择性重计算
则是针对多流残差结构带来的内存开销问题
提出的优化方案
n 路残差流在训练过程中会产生大量的中间激活值
如果将这些激活值全部缓存下来用于反向传播
会占用巨大的显存空间
尤其是对于 27B 这样的大规模模型
显存往往是最稀缺的资源
为了缓解这一压力
mHC 架构采用了 “前向丢弃、反向重计算” 的策略
在前向传播结束后
直接丢弃 mHC 内核产生的中间激活值
只保留初始激活值
而在反向传播阶段
通过重新执行 mHC 内核
来即时重计算这些中间激活值
这种策略的巧妙之处在于
它用少量的计算开销
换取了大量的显存空间节省
因为重计算的过程
不包含计算量较大的层函数
所以额外增加的计算成本非常有限
而节省下来的显存空间
则可以用来扩大模型的批量大小
或者增加训练数据规模
从而整体提升训练效率
同时
重计算过程与流水线通信依赖实现了解耦
因为每个阶段的初始激活值已经被缓存在本地
不会受到流水线调度的影响
这使得整个训练过程的调度更加灵活
计算设备的处理单元能够保持高利用率
通信重叠调度则是针对分布式训练场景的优化
在大规模模型训练中
通常需要多个 GPU 或多个节点协同工作
设备之间的通信开销
往往是制约训练速度的重要因素
mHC 架构通过优化任务调度策略
将重计算过程与设备间的通信过程进行重叠
让计算和通信可以并行进行
而不是串行等待
这种调度方式能够充分利用 GPU 的计算资源和通信资源
减少空闲时间
从而进一步提升整体训练效率
此外
mHC 架构还采用了混合精度训练策略
在不牺牲计算精度的前提下
最大化数值计算的速度
混合精度训练通过使用较低的精度
比如 FP16进行大部分的计算
同时用较高的精度
比如 FP32来存储关键参数和梯度
既减少了计算量和内存占用
又避免了低精度计算可能带来的数值不稳定性
这个策略与 mHC 架构本身的稳定性设计
形成了互补
进一步确保了训练过程的可靠性
这些工程优化措施的组合应用
使得 mHC 架构在实现理论创新的同时
成功控制了系统级开销
实验数据显示
当残差流扩展率 n=4 时
mHC 架构的额外训练时间开销仅为 6.7%，
远低于行业内很多架构创新的开销水平
对于企业和研究机构来说
这样的开销增长是完全可以接受的
因为它带来的是训练稳定性的巨大提升和性能的持续优化
相比之下，6.7% 的额外时间成本
能够换来的是训练失败率的显著降低、算力资源的有效节省
以及产品迭代速度的加快
整体性价比极高
最后，不得不说
DeepSeek这次又展示了工程上的极致优化
在所有人都在疯狂堆算力的今天
DeepSeek一门心思的通过高超的优化技术来提升模型性能
硬是开辟出了一条新的路线
更有意思的是
残差连接自从2015年何恺明提出后
此后十年间几乎没有根本性的改动
所以说，DeepSeek这次
开始瞄准了Transformer架构中最古老、也最基础的核心组件
不知道这会不会成为推倒整座长城的开始
另外，DeepSeek在论文中提到
已经在内部的大规模训练实验中佐证了论文的结论
这也许预示着
大概率我们能在春节期间
看到DeepSeek V4 或者 R2 模型的发布
让我们一起拭目以待吧
感谢观看本期视频，我们下期再见
