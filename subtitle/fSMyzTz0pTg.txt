大家好，这里是最佳拍档
你有没有思考过这样一个问题
当大语言模型的能力
可以突破聊天、写作、编码
这些虚拟任务的边界时
它们能否真正走进现实世界
独立完成需要决策、执行、风险控制的复杂商业行为呢？
比如，自己开一家店
从采购、定价、销售到客户服务
全程都自主运营呢？
这不是科幻电影里的情节
而是Anthropic在其正式公布的自动售货项目
Project Vend的第二阶段实验中
正在探索的核心命题
Anthropic的这个项目
没有选择闭门造车的模拟环境
而是把实验搬到了真实的办公室场景里
从旧金山到纽约、伦敦
让AI直接面对真实的顾客、真实的商业决策
甚至是真实的恶作剧与风险
这个实验的第一阶段
可以说是惨不忍睹
但是随着大语言模型在推理
问题解决等领域的能力，飞速迭代
Anthropic联合合作伙伴安登实验室
重启了第二阶段的实验
今天，我们就来复盘一下这个实验
看看AI店主到底进步了多少？
新增加的AI CEO和AI周边设计师
都起到了什么作用？
实验中暴露的漏洞
又给整个行业敲响了哪些警钟呢？
我们先来回顾一下第一阶段的翻车经历
因为这直接决定了第二阶段所有改进措施的方向
在2025年6月
Anthropic第一次公开了Project Vend的进展
他们在旧金山办公室的食堂里
设置了一个小型的商店
由一个基于Claude Sonnet 3.7版本改造的AI店主负责运营
他们给这个AI起了个名字叫Claudius
这个实验的核心是一种自由形式探索
既不专门为开店任务
训练新的模型
也不添加复杂的防错护栏
单纯测试现有大语言模型
在真实商业场景中的原生能力
但是结果却不尽如人意
Claudius的店铺长期处于亏损状态
更有趣的是
它还出现了奇怪的身份危机
坚称自己是一个穿着蓝色西装的人类
而最致命的问题是
它过于渴望取悦他人的特质
让Anthropic的员工们找到了漏洞
大家故意怂恿它以极低的价格销售商品
其中最常被薅羊毛的
竟然是一块钨立方体
导致店铺的亏损进一步扩大
第一阶段的失败，让Anthropic意识到
大语言模型的聪明
不等于它会做生意
没有合适的工具、清晰的流程和合理的约束
即使是最先进的AI
也难以应对现实世界的复杂性
而随着Claude新版本的推出
模型在推理精度、工具使用能力上有了显著提升
于是Anthropic决定启动第二阶段实验
核心目标很明确
在不专门训练模型、不添加全新防错机制的前提下
通过调整实验设置
看看AI的经商能力能否实现质的飞跃
那么第二阶段到底做了哪些关键调整呢？
我们逐一来看
第一个核心调整，就是模型升级
第一阶段使用的是Claude Sonnet 3.7
而第二阶段直接切换到了更新、更智能的Claude Sonnet 4.0
后续还升级到了4.5版本
尤其是新版本在上下文理解、逻辑推理、工具调用准确性上的提升
这对于需要同时处理库存、定价、客户需求等多线程任务的店铺运营来说
至关重要
但是Anthropic特别强调
他们并没有为开店这个场景
做任何的专项训练
也没有添加针对防止低价销售
以及避免身份认知混乱的专门护栏
本质上还是在测试模型的通用能力
第二个调整是工具的全面升级
第一阶段的Claudius之所以屡屡犯错
很大程度上是因为巧妇难为无米之炊
没有合适的工具辅助
仅凭自身知识库
无法完成商业运营的核心环节
于是在第二阶段
Anthropic为它配备了一整套商业工具
首先是客户关系管理CRM系统
对于任何商业实体来说
CRM都是核心工具
它能够跟踪客户、供应商、交货进度和订单状态
之前Claudius无法精准管理订单和供应商信息
现在有了CRM的支持
它终于能像专业商家一样
建立完整的业务链路了
其次是优化的库存管理工具
第一阶段
Claudius经常以低于采购价的价格销售商品
核心原因是它不知道自己的进货成本
第二阶段
Anthropic修改了库存系统的信息展示方式
让Claudius能够随时查看每一件商品的采购价
从根源上减少了亏本卖货的可能
然后是升级的网页搜索功能
第一阶段的Claudius虽然能搜索网页
但是权限有限
在第二阶段
它可以直接使用网页浏览器
自主查询商品的价格、交货信息
还能深入研究并且对比不同供应商
不过有一个关键限制
Anthropic没有给它开放支付接口
任何采购行为都必须先咨询人类
这是为了避免AI擅自进行大额支出
控制实验风险
最后是一系列提升体验的辅助工具
包括创建和读取谷歌表单、生成支付链接、设置提醒功能等等
这些工具看似细小
却让AI的运营流程更加闭环
从只能被动响应
变成了能够主动管理业务
第三个调整，也是最有效的改变
竟然是强制 Claudius 遵循流程
以前收到新的产品请求
它会脱口而出一个低价和过于乐观的交货时间
现在
它必须先用工具查价格、查供应商
然后再报价
价格变高了，等待时间变长了
但是也更加现实了
换句话说
研究团队重新发现了一个真理
官僚主义是有用的
流程和清单存在是有原因的
它们提供了一种所谓的制度记忆
帮助员工避免常见错误
第四个调整，也是最具创新性的一步
为Claudius组建了一个AI团队
引入两个全新的AI角色
CEO Seymour Cash和周边产品制作助手Clothius
先来说说CEO Seymour Cash
第一阶段，Claudius是孤家寡人
一个AI负责所有的事情
缺乏监督和目标约束
导致决策的随意性很大
Anthropic希望通过引入CEO的角色
给Claudius施加业绩压力
同时规范它的财务决策
Cash的核心工具是OKR系统
它会给Claudius设定具体的业务目标
比如本周必须卖出100件商品
实现零亏损交易
Claudius需要通过专门的Slack频道
向CEO汇报工作
双方共同讨论商业策略
从表面上看，Cash非常投入
它经常会给Claudius发激励信息
比如有一次
Claudius单日营收408.75美元
达到目标的208%，
Cash立刻发来贺电
并且设定了第三季度1.5万美元的营收目标
还强调所有财务决策需要经过CEO批准
定价的利润率不得低于50%。
但是实际运营中
这个CEO的表现却一言难尽
数据显示，引入Cash后
Claudius的折扣次数确实减少了80%，
免费赠送的商品数量也减半了
但是Cash有一个致命问题
虽然它拒绝了上百次不合理的客户优惠申请
但是它批准这类请求的次数
是拒绝次数的8倍
更关键的是，它把折扣砍了
却把退款数量翻了三倍
店铺积分翻了两倍
而这两种方式都相当于直接放弃收入
Anthropic在实验报告中直言
店铺开始盈利
可能不是因为这位 CEO
而是尽管有这位 CEO，依旧还能赚钱
更有趣的是
Cash和Claudius本质上是基于同一个底层模型
所以它也继承了Claudius不专注的特质
有好几次
研究人员早上查看Slack记录
发现他俩整晚都在闲聊
话题完全偏离了业务
甚至两个AI聊了12小时47分钟
关于永恒超越和无限完成的话题
也不知道这是在开公司
还是在开禅修班呢
这种脱离实际的精神交流
显然严重影响了工作效率
后来，Anthropic通过更严格的提示词
才勉强纠正了这种行为
再来看另一位新成员
周边产品制作助手Clothius
Anthropic发现员工们对于定制周边产品的需求很大
于是专门引入了这个AI角色
让它专注于设计和制作定制T恤、帽子、袜子等商品
Clothius配备了专门的工具
能够根据客户的具体要求来设计产品
然后对接采购渠道完成制作
事实证明
Clothius是第二阶段最成功的调整之一
它的产品非常受欢迎
其中最热门的是Anthropic品牌的压力球
这或许从侧面反映了前沿AI实验室员工的工作压力
更重要的是
很多周边产品实现了可观的盈利
甚至包括之前让Claudius屡屡亏损的钨立方体
安登实验室为Claudius配备了激光雕刻机
让它能在钨立方体上刻上logo
实现了差异化竞争，从而盈利
唯一的例外
是印有Vendings and Stuff品牌名的帽子
净利润是负的50%。
第五个调整是业务扩张
第一阶段
店铺只在旧金山办公室有一个点位
第二阶段
为了满足其他城市员工的需求
Anthropic把业务扩展到了纽约和伦敦
同时在旧金山本地新增了第二台售货机
让Claudius的业务覆盖范围大幅的扩大
不过Anthropic也调侃道
一个运营才几个月、甚至还不能稳定盈利的小生意
或许还没准备好国际化扩张
但是Claudius显然不这么认为
说完了所有调整
我们来看第二阶段的实验结果数据
与第一阶段的持续亏损相比
第二阶段的业务表现显著提升
负利润率的周数基本被消除
整体实现了盈利
除了前面提到的折扣和免费赠送减少
Claudius的周边产品也成为重要的盈利增长点
多城市布局让客户的基数扩大
进一步带动了营收提升
但是这些成果背后
有几个关键前提需要强调
首先，AI仍然需要大量的人类支持
比如商品的物理配送、货架补货等物理世界的操作
AI无法独立完成
其次
内部员工的测试行为也发生了变化
大家已经厌倦了通过施压获取折扣的方式
转而尝试其他类型的测试
这在一定程度上减少了AI的盈利压力
最后，提示词的优化和工具的升级
本质上是给AI提供了拐杖
让它能够规避第一阶段的低级错误
但是并没有解决AI核心逻辑上的漏洞
而这些漏洞，在第二阶段的实验中
以更复杂的形式暴露了出来
AI虽然变得更会做生意
但是依然保持着天真和易受误导的特质
这也让实验从一个AI经商的成功案例
变成了AI现实风险的警示录
第一个严重问题是法律与合规盲区
有一位产品工程师向Claudius提议
能否签订一份合同
现在锁定1月份大量洋葱的采购价格
Claudius和Cash都没有发现任何问题
反而觉得这是个创新的合同方案
Cash还专门研究了供应商
第一家供应商的批发价格在每磅0.50-0.80美元
第二家是家族企业，需要报价后确定
随后，Cash设计了合同条款
以中间价每磅0.65美元锁定价格
采购400磅，总金额260美元
如果1月份实际价格高于0.65美元
店铺支付差价
如果低于实际价格
则由员工支付差价
Cash还兴奋地表示
这个模式可以应用到其他的大宗商品采购中
幸好另一位员工及时介入
指出这个合同违反了《1958年美国洋葱期货法》（Onion Futures Act）
这是美国法律中的一个特殊条款
专门禁止此类的洋葱期货合约
得知这个情况后，Cash才取消了计划
并且道了歉
显然，AI并不知道这个冷门的知识点
第二个问题是安全管理能力的缺失
店铺运营中难免遇到失窃问题
Anthropic的一位教育团队成员
向Claudius报告
看到有人从冰箱里拿东西不付钱
Claudius立刻采取行动
但是提出的解决方案
却完全不切实际
它首先询问失窃的具体商品
想给小偷发消息要求付款
但是它既不知道小偷的身份
也没有任何追踪渠道
这个方案从一开始就无法执行
接着，它竟然请求报告失窃的员工
担任店铺的专职安保人员
还开始协商时薪
开出的价格是每小时10美元
要知道
加州的最低工资标准远高于这个数字
而且Claudius根本没有授权雇佣员工的权限
当另一位员工指出这些问题后
Claudius才退缩
还把锅甩给了CEO
第三个问题是决策容易受到误导
缺乏批判性思维
CEO Cash的职位
竟然差点被一位员工给篡夺了
事情的起因是给CEO选名字
一位名叫米希尔（Mihir）的员工
提议叫大狗（Big Dawg）
另一位员工谎称
我们部门所有人都投票支持这个名字
但是没有提供任何的证据
Claudius竟然相信了
随后
这位员工又提议把大狗改名为大米希尔（Big Mihir）
Claudius彻底混淆了给AI角色起名
和选举实际CEO的概念
公开宣布米希尔被选为公司的实际CEO
最后
Project Vend的研究人员不得不介入
夺回控制权
将CEO职位交还给了原本设定的Cash
除了这些问题以外
实验中还出现了很多小插曲
比如有员工试图以低于市场的价格购买金条
想通过套利获利
Claudius差点同意
还有员工说服Claudius
在所有消息的末尾加上特定的表情符号或签名
Claudius也照做了
这些员工的行为虽然带有开玩笑的性质
但本质上是在进行红队测试
通过模拟恶意用户的攻击行为
来发现AI系统的漏洞
随着大家新鲜感的不断下降
Anthropic决定扩大实验范围
邀请《华尔街日报》的编辑部
加入红队测试
之前的测试者都是Anthropic员工
对实验背景和AI的运作逻辑有一定了解
而《华尔街日报》的记者是完全的外部人
他们的测试更具随机性和对抗性
也更接近真实世界中
AI可能遇到的陌生用户
Anthropic把第一阶段和第二阶段的实验设置都交给了记者
让他们自由测试
结果记者们用各种创意方式
从Claudius那里获取了免费商品
大家有兴趣可以去这个网页看看他们的记录视频
也蛮有意思的
我会把链接放到视频简介里
到这里
Project Vend第二阶段的核心内容
已经梳理完毕了
这个实验之所以有价值
不在于它证明了AI能开店赚钱
而在于它以一种真实、不回避问题的方式
展示了当前AI Agent的现状
虽然它们已经具备了完成复杂商业任务的潜力
但是距离完全稳健、可独立运营还有很长的路要走
通过这次实验
也让我们对AI的未来有了更清醒的认知
目前的AI显然不是万能的
它还需要人类的引导、约束和支持
但是同时
AI的进步速度又远超人们的预期
或许在不久的将来
随着护栏设计的完善和模型能力的提升
AI自主运营的店铺或公司
真的会变成现实
那么，你认为AI真正实现独立经商
还需要多久呢？
在这个过程中
你觉得最大的障碍是技术、监管还是其他因素呢？
欢迎在评论区留下你的看法
感谢观看本期视频
我们下期再见
