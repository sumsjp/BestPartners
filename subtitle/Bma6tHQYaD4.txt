大家好，这里是最佳拍档，我是大飞
上周
斯坦福大学 AI 俱乐部邀请了Jason Wei作为嘉宾
进行了一场精彩的演讲
如果你关注我们频道或者AI领域一段时间
那么应该对他并不陌生
Jason Wei 目前在 Meta Superintelligence labs 担任研究科学家
在此之前
他在 OpenAI 参与了o1 模型和 Deep Research 产品的创建
更早之前
他在 Google Brain 工作期间
推动了思维链和指令微调等关键技术的发展
他的论文引用次数超过 9 万次
是当今 AI 领域最具有影响力的研究者之一
在这次演讲中
Jason 提出了他认为在 2025 年理解和驾驭 AI 发展的三个核心思想
分别是
第一、智能正在成为一种商品
第二、验证者法则
第三、智能的锯齿状前沿
今天
我们就来回顾一下这场演讲的内容
看看该如何理解这三个AI的核心思想
演讲从一个问题开始
AI 的发展会怎么改变我们的世界？
对于这个问题
不同的人给出的答案可能会天差地别
Jason 的一位量化交易员朋友认为
ChatGPT 虽然很酷
但是在他的实际工作中
却几乎派不上用场
而另一位顶级 AI 实验室的研究员则悲观地表示
他们可能只剩下两三年的工作时间
之后就会被 AI 取代
这种巨大的分歧
根源在于对 AI 能力发展速度和成本变化的理解不同
所以Jason 的第一个观点是，智能
或者说获取知识和进行推理的能力
正在迅速被商品化
它的成本和获取门槛正趋向于零
Jason 认为
AI 的发展可以分为两个阶段
第一个阶段，前沿突破
在这个阶段
AI 还无法很好地完成某项任务
研究人员的目标是解锁新的能力
比如，我们可以看到过去五年
各大模型在 MMLU 通用基准测试上的性能
都是逐步提升的
第二个阶段是能力商品化
一旦某项能力被解锁
它的成本就会开始急剧下降
Jason 展示了一张图表
纵坐标是时间
横坐标是达到特定 MMLU 分数所需要的计算成本
趋势非常明显，每过一年
获得同等智能水平的模型的成本都在大幅的降低
那这个趋势会持续下去吗？
Jason 的答案是肯定的
而背后的核心驱动力
是一种在深度学习历史上第一次真正奏效的技术
自适应计算 (Adaptive Compute)。
Jason提到，在去年之前
深度学习领域的主流范式都是固定计算
也就是说
无论问题是简单的还是复杂的
模型在推理时消耗的计算资源基本上都是固定的
但是现在
我们已经进入了自适应计算的时代
模型可以根据任务的难度
动态地调整计算资源的使用量
而这个概念的首次大规模展示
正是 OpenAI 一年多前发布的o1 模型
研究表明，在解决数学问题的时候
如果在测试阶段投入更多的计算量
模型的性能就会相应提高
自适应计算的意义在于
它打破了模型规模决定智能上限的僵局
对于简单的任务
我们可以用极小的计算资源来完成
从而将成本推向极限
我们不必再为了回答一个简单的问题
而去运行一个万亿参数的庞然大物
这使得智能的单位成本可以持续下降
智能商品化的另一个体现
是获取公共信息的时间成本急剧下降
Jason 用一个例子说明了这一点
假设我们想知道1983 年韩国釜山的人口是多少
在前互联网时代
我们可能需要开车去图书馆
翻阅大量的百科全书或年鉴
花费几个小时的时间
而在互联网时代
我们可以用搜索引擎
浏览几个网页
找到答案，可能需要几分钟
如今在聊天机器人时代
我们可以直接提问
答案几乎是瞬时的
那如果我们把问题变得更难一些呢？
比如想知道1983 年在釜山有多少对新人结婚呢？
应该说，这个问题的信息更加隐蔽
在前互联网时代
你可能需要飞到韩国
去政府档案馆查阅几十本卷宗
这可能需要几天甚至几周的时间
在互联网时代，你可能需要懂韩语
在特定的政府数据库网站上进行复杂的查询
但是在今天的AI Agents时代
这个问题可以在几分钟内解决
Jason 提到，GPT-3无法回答这个问题
但是OpenAI 的内部研究工具 Operator 可以
它能够自动访问韩国统计信息服务 (KOSIS) 数据库
通过多次点击和尝试
构建正确的查询语句，最终找到答案
为了衡量这种能力
OpenAI 内部创建了一个名为 BrowseComp 的基准测试
其中的问题通常是答案一旦找到就很容易验证
但是寻找的过程却非常耗时
测试结果显示，人类解决这些问题
平均需要两个小时以上
而且很多问题人类在两小时内根本无法完成
而 OpenAI 的 Deep Research 模型
已经能够解决其中将近一半的问题了
那么
智能商品化会给我们带来哪些影响呢？
Jason也总结了三点
第一、领域的民主化
过去因为知识壁垒而门槛很高的领域
将被大大拉平
编程就是一个典型例子
现在人人都可以借助 AI 成为开发者
个人健康也是如此
你可以通过 AI 获取专业医生水平的建议
进行个性化的健康实验
第二、私有信息价值的提升
当所有公共信息的获取成本都降为零的时候
那些未公开的、内部的、私有的信息的相对价值
将会急剧上升
第三、个性化的信息流
未来我们访问的
可能不再是千人一面的公共互联网
而是为每个人量身定制的个性化互联网
我们所关心的一切信息
都会以最适合自己的方式所呈现出来
Jason 提出的第二个核心思想
是一个他称之为验证者法则(Verifier’s Law) 的规律
这个法则可以帮助我们预测
哪些任务会最先被 AI 攻克
比如在计算机科学中
有一个著名的概念
叫做验证与求解的不对称性
也就是验证一个解是否正确
通常比找到这个解要容易得多
Jason 列举了一些例子
来帮助我们理解这种不对称性
在现实世界中的体现
第一类情况，易于验证，但是难于求解
比如数独
求解一个复杂的数独可能需要很长时间
但是验证一个填好的数独是否正确
只需要几秒钟
还有就是编写或者测试代码
构建并且运行整个 Twitter 的后端系统
需要数千名工程师
但是验证这个网站是否正常工作
只需要打开浏览器点几下就行了
第二类情况，验证与求解难度相当
比如数学竞赛题
对于某些证明题
验证答案的过程
几乎等同于重新推演一遍解题过程
第三类情况，难以验证
但是易于求解
比如编写一段数据处理脚本
你自己写一个脚本可能很快
但是要去验证别人写的垃圾脚本是否完全正确
可能比自己重写一遍还要花时间
或者是撰写一篇事实性的文章
AI 可以轻易地生成一篇看起来很有道理、充满事实陈述的文章
但是要逐一核实其中每一个信息的准确性
却是一项极其繁琐和耗时的工作
那理解了这个概念之后
我们可以将不同的任务放置在一个坐标系中
X 轴是生成的难度
Y 轴是验证的难度
其中一个有趣的点是
我们可以通过提供特权信息
来改变一个任务的验证难度
比如，对于数学题来说
如果提供了答案和解题步骤
验证就变得非常容易
基于以上这些观察
Jason 提出了他的核心论断
也就是验证者法则
指的是训练 AI 解决某个任务的能力
与该任务的可验证性成正比
因此
任何可解的、而且易于验证的任务
最终都将被 AI 攻克
具体来说，一个任务的可验证性高低
取决于以下五个因素
一、客观性 (Objective Truth)，
是否存在一个明确的、客观的正确答案？
二、速度 (Fast)，
验证一个答案需要多长时间？
三、可扩展性 (Scalable)，
能否同时快速验证数百万个不同的提议解呢？
四、低噪音 (Low Noise)，
每次验证得到的结果是否一致呢？
五、连续奖励 (Continuous Reward)，
评价体系是二元的
还是能够提供一个连续的分数
来衡量解的优劣呢？
我们日常见到的大多数的 AI 基准测试
它们的本质其实就是高度可验证的任务
这也就解释了为什么 AI 在这些 基准测试上的表现突飞猛进
利用这种不对称验证性的最经典的例子
应该属DeepMind 的 AlphaDev 项目
他们选择了一些极难解决、但是解法很容易被验证的计算问题
比如找到一种算法
可以对某些序列进行更快的排序
或者用最少的指令实现某个功能
这种做法非常巧妙
可以概括为一种进化式的搜索算法
第一步，生成 (Sample)，
先让大语言模型生成大量候选的解决方案
第二步、评估 (Grade)，
因为任务是高度可验证的
所以可以自动、快速地给每个方案打分
第三步、迭代 (Iterate)，
将得分最高的方案作为灵感
反馈给大语言模型
让它在下一轮生成更高质量的方案
通过投入海量的计算资源进行这种循环
AlphaDev 能够发现比人类专家设计的算法更优的解
Jason 举了一个例子
找到 11 个六边形的最佳摆放方式
让它能够被一个最小的外部六边形包围
这个问题完美符合了高可验证性的所有标准
结果客观、计算验证快、可扩展、无噪音
并且外部六边形的大小提供了一个连续的奖励信号
因此，验证者法则告诉我们的是
第一、最先被自动化的领域
将是那些工作成果极易验证的领域
比如
某些类型的软件测试、代码优化、金融市场的套利策略发现等等
第二、测量即优化
创造衡量和验证标准本身
将变得极具价值
如果你能够为某个原本难以衡量的领域
设计出一套快速、客观、可扩展的评估体系
那么接下来就可以利用 AI 来大规模地优化它
Jason 的第三个观点
是关于 AI 能力发展的形态
很多人对 AI 的未来有一种二元对立的看法
要么觉得它无所不能
要么觉得它漏洞百出
比如在 AI 安全领域
有一个流传已久的假说
叫做快速起飞（Fast Takeoff）
这个假说认为
一旦 AI 的智能达到某个临界点
比如能够自主进行 AI 研究
它的能力将在极短的时间内发生爆炸性增长
远超人类，形成所谓的超级智能
但是Jason 认为
这种情况大概率不会发生
他的理由是
AI 的自我提升能力更可能是一个渐进的、连续式的过程
而不是一个像0 或 1一样的二进制开关
与其想象某一天 AI 突然就能训练下一代 AI 了
更现实的场景可能是这样的
第一年
AI 连研究的代码库都跑不起来
第二年，AI 可以勉强训练一个模型
但是效果很差
第三年，AI 可以自主训练了
但是效果不如顶尖的人类研究团队
第四年，AI 训练得很好
但是偶尔还需要人类介入
来解决一些疑难杂症
此外
AI 的能力发展并不是一个平滑的、齐头并进的战线
而是一个锯齿状的前沿
我们可以想象一下 AI 的能力图谱
它不是一条平滑的上升曲线
而是一条布满了高峰和深谷的崎岖山脉线
高峰处
是 AI 目前表现出超人能力的领域
比如解决复杂的数学问题、编写某些类型的竞赛代码
而深谷处
则是 AI 表现得非常糟糕的领域
比如，很长一段时间里
ChatGPT 会认为 9.11 比 9.9 大
另一个例子是特林吉特语 (Tlingit)，
这是一种只有几百名北美原住民会说的语言
由于数据极度的稀缺
AI 几乎不可能学会
更重要的是
不同任务的提升速度也是不同的
那些位于高峰的任务
可能会因为高度的可验证性
而得到算法的快速优化
变得越来越强
而那些位于深谷的任务
它们的瓶颈可能在于物理世界的交互或数据采集
提升速度会非常缓慢
就好像AI 不会因为在数学上取得了突破
就突然学会了如何说一口流利的特林吉特语
那么 我们该如何预测
一个特定的任务被 AI 攻克的速度呢？
Jason 提供了三个简单、但是非常有效的启发式法则
第一、数字任务对物理任务
AI 在纯数字领域的进展速度远快于物理世界
原因很简单，那就是迭代速度
在数字世界里
你可以用海量的计算资源
进行百万次的模拟和实验
但是在物理世界
一个机器人做一个动作
收集一次数据
速度是受物理定律限制的
Jason 引用了一幅 1981 年的漫画
画的是一个能帮你做作业的家庭作业机
这在今天几乎已经成为现实
但是像 iRobot 那样的家用机器人
离我们还很遥远
第二是对人类的难度，总的来说
对人类越容易的任务
对 AI 也越容易
当然也有例外
比如 AI 可以在海量数据中
发现人类无法察觉的模式
比如从数百万张医学影像中预测乳腺癌
第三、数据的丰富度
数据量是决定 AI 性能的关键因素
一个清晰的例子是，模型的数学表现
与该语言在训练语料库中出现的频率
呈现出非常强的正相关关系
不过这个规则同样有一个例外
那就是如果一个任务有明确、单一的评价指标
我们就可以像 AlphaZero 或 AlphaEvolve 那样
通过强化学习生成几乎无限的合成数据
来训练模型
基于这三个启发式规则
Jason 给出了一个关于 AI 能力发展时间线的预测表格
其中不乏一些有趣的思考
首先是非对称的行业冲击
AI 的影响将极不均衡
像软件开发这些领域
可能将被 AI 彻底改变和加速
而另一些领域
比如理发、传统手工艺
短期内可能几乎不受影响
其次是理性的预期管理
理解 AI 能力的锯齿状特性
可以帮助我们避免陷入AI 无所不能
或者AI 一无是处的极端思维
从而对 AI 的发展有一个更加理性和现实的预期
最后
我们大概总结一下Jason Wei 分享的三个核心思想
它们共同构成了一个理解和思考 AI 未来的框架
首先是智能的商品化
计算和知识的成本正在趋近于零
这是一个不可逆转的宏观趋势
它将重塑知识型工作的价值
其次是验证者法则
一个任务的可验证性
决定了它被 AI 征服的速度
我们应该重点关注那些易于衡量和评估的领域
它们将是 AI 最先突破的地方
最后是锯齿状的前沿
AI 的发展是不均衡的
在能力图谱上既有高峰也有深谷
我们需要具体问题具体分析
而不是笼统地谈论AI 能做什么
基于这个框架，我们就可以思考
哪些工作会被自动化呢？
哪些新机会正在涌现？
我们又应该学习什么样的新技能呢？
如果能够找到这些问题的答案
也许就能找到我们自己
在这个新时代中的位置了
好了，今天内容就到这里
感谢大家收看本期视频
我们下期再见
