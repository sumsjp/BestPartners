大家好，这里是最佳拍档，我是大飞
我是万万没想到啊
国内的AI圈也竟然能堪比娱乐圈
没事就可以吃个瓜
前几天
国内开源大模型领域迎来了一个新的模型
Yi，据说上下文窗口大小突破了200k
能一次处理40万汉字
这个大模型是由创新工场董事长兼CE0李开复创立的大模型公司「零一万物」构建的
包括了Yi-6B和Yi-34B两个版本
根据Hugging Face英文开源社区平台和C-Eval中文评测榜单
Yi-34B推出时取得了多项SOTA国际最佳性能指标认可
成为全球开源大模型的双料冠军」，
击败了LLaMA2和Falcon等开源竞品
Yi-34B也成为当时唯一成功登顶Hugging Face全球开源模型排行榜的国产模型
号称全球最强开源模型
这个模型在发布后引起了国内外很多研究者、开发者的关注
国内很多科技媒体也进行了报道
大飞我本来也想做一期节目介绍一下
可是谁料它竟然翻车了
现在只能庆幸没轻易相信
昨天
前阿里巴巴副总裁、知名AI框架大牛贾扬清发朋友圈
感慨做小公司不容易
希望国内企业如果就是开源的模型结构
不要做换名伪装
免得小公司做一些多余的适配工作
原文的内容是这样写的
感叹一下做小公司不容易
1、上周
有某海外客户要我们帮他们适配某国内大厂的新模型
我们太忙
暂时还没时间给他们做适配
2、今天有朋友告诉我
这个大厂新模型exactly就是LLaMA的架构
但是为了表示不一样
把代码里面的名字从LLaMA改成了他们的名字
然后换了几个变量名
3、然后
海外有工程师直接指了这一点出来
还有人在Hugging Face上面放了个把名字改回去的checkpoint
说好了
现在你们可以直接用LLaMA的代码来load这个checkpoint了
我们是小公司也不想得罪大佬们
名字我就不说了
不过各位大佬，开源社区不容易
如果你们就是开源的模型结构
求高抬贵手就叫原来的名字吧
免得我们还做一堆工作就为了适配你们改名字
那么贾扬清不敢得罪的大佬是谁呢
没错
就是Yi模型背后的零一万物公司
而在数天前
在零一万物Huggingface社区中
有开发者同样指出，据我们了解
除了两个张量input_layernorm和post_attention_layernorm被重命名之外
Yi完全使用了LLaMA的架构
因为围绕llama架构有大量的投资和工具
所以对张量使用相同的名称是有价值的
开源社区肯定会重新发布Yi
并重新命名张量
以便有一个符合llama架构的版本
我们希望您能考虑在该模型获得大量采用之前
在您的官方模型中采用这一更改
以便它最终能够享受它应得的采用
还有研究者在Hacknews发出帖子
不仅提到Yi-34B模型基本上采用了LLaMA的架构
只是重命名了两个张量
而且Yi-34B的代码实际上是对LLaMA代码的一次重构
但是看似并未作出任何实质性改变
这个模型明显是基于原始Apache 2.0版的LLaMA文件进行的编辑
但是却未提及LLaMA
大家可以通过diffchecker查看一下
Yi和LLaMA的代码对比
我这里也贴出几张图给大家看一下
左边红色的Yi模型的代码
右边绿色的是LLaMA模型的代码
完整diff我会发在视频简介里
大家自行判断
此外
这些代码更改并没有通过Pull Request的方式提交到transformers项目中
而是以外部代码的形式附加上去
可能存在安全风险或者不被框架所支持
HuggingFace的排行榜甚至不会对这个上下文窗口最高可达200K的模型进行基准测试
因为它没有自定义代码策略
他们声称这是32K模型
但是实际上它被配置为4K模型
没有RoPE伸缩配置
也没有解释如何伸缩
当然按照零一万物的说法
模型本身是在4K的序列上进行训练
但是在推理阶段可以扩展到32K
目前
关于这个模型微调数据的信息为零
也没有提供复现他们的基准测试的说明
包括可疑的MMLU高分
随后，有网友表示
如果他们确切使用了Meta LLaMA的架构、代码库和所有相关资源
就需要遵守LLaMA规定的许可协议
于是为了符合LLaMA的开源协议
有位开发者将其名字改回并重新放到了huggingface上
针对于这个事，国内媒体机器之心
也向零一万物进行了求证
零一万物是这样回应的
GPT是一个业内公认的成熟架构
LLaMA在GPT上做了总结
零一万物研发大模型的结构设计基于GPT成熟结构
借鉴了行业顶尖水平的公开成果
同时基于零一万物团队对模型和训练的理解做了大量工作
这是我们首次发布获得优秀结果的地基之一
与此同时
零一万物也在持续探索模型结构层面本质上的突破
模型结构仅是模型训练其中一部分
Yi开源模型在其他方面的精力
比如数据工程、训练方法、baby sitting的技巧、超参数设置、评估方法以及对评估指标的本质理解深度、对模型泛化能力的原理的研究深度、行业顶尖的AI Infra能力等
投入了大量研发和打底工作
这些工作往往比起基本结构能起到更大的作用跟价值
这些也是零一万物在大模型预训练阶段的核心技术护城河
在大量训练实验过程中
由于实验执行需求对代码做了更名
我们尊重开源社区的反馈
将代码进行更新
也更好的融入Transformer生态
我们非常感谢社区的反馈
我们在开源社区刚刚起步
希望和大家携手共创社区繁荣
Yi Open-source会尽最大努力持续进步
好吧
这个声明跟国内的娱乐公关口气几乎一模一样
我们借鉴了一部分
但是还创新了很多
所以大家就散了吧
大飞我前一段做过一期节目
说的是国产IDE套壳VSCode的事
这还没过多久，大模型也来了
而且还如此的理直气壮
不禁让我对国内的研发环境再次失望
据说零一万物的新一轮融资还是由阿里云领投的
估值已超10亿美元
跻身AI 2.0独角兽行列
不知道投资人看到这个事会怎么想
是否值得10亿美元
我相信评论区很多人一定会说见怪不怪了
确实这种事也是一次又一次的发生
虚假宣传？
违反许可证规定？
实际基准作弊？
谁在乎呢？
大部分人可能想的也是拿来就用完了呗
可是，大飞我相信，人在做天在看
我们本来在AI这行业就落后别人很多
还想用这种方式来弯道超车
无疑是自绝后路
对这件事
我确实也不想发表过多评论
要不然又该有喷子说
你看你就会躲到这里说国内的不好
你又做了什么贡献
我确实也人微言轻，做不了什么贡献
但是我好歹不会套个皮说是自己研发、世界领先
我一直以为这只有广东数字这种能干的出来
当然了，科技圈现在确实也在娱乐化
说白了也是个江湖
毕竟大佬贾扬清都惹不起
我就更惹不起了
我只是好奇
李开复老师从一开始知不知道这件事
千万别再被这种事气坏了身体
这种事情还是直接甩锅团队的好
我真心希望国内在AI行业的朋友们
踏踏实实干点实在的吧
实在不行，也可以像我一样
搞个自媒体娱乐大家就好了
就别说自己多遥遥领先了
当然了，我也知道
不这样怎么好骗钱呢，是吧
我无非也是骗不到吃个酸葡萄罢了
好了，本期视频内容就到这里
欢迎大家在评论区发表自己的看法
我们下期再见
