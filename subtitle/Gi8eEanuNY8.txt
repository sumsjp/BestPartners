大家好这里是最佳拍档
我是大飞
最近AIGC这个领域呢依然很卷
谷歌最近公开了StyleDrop
这个论文一出感觉又是要刷屏的架势
它不仅可以根据梵高的抽象风格
创作出无数幅类似的画作
也可以用卡通风格来绘制呆萌的物体
甚至它还能精准的把控原图的细节
设计风格一样的LOGO
StyleDrop的魅力在于
它只需要一张图作为参考
无论多么复杂的艺术风格
都能够解构再复刻出来
感觉这个又是冲着设计师去的啊
这个职业最近好惨
看来AI准备给淘汰光了可能才罢休
据论文作者介绍
StyleDrop的灵感来源于
一款名为Eyedropper的取色工具
他也希望大家可以快速
毫不费力的从单个
或者是少数的参考图像中
挑选出你所需要的样式
然后来生成这个样式的图案
比如说一只树懒能够有18种的风格
甚至连水彩画上的纸张褶皱效果
都可以还原出来
而且这次在LOGO的设计上
有了非常大的提升
比如各种风格的英文字母设计
也可以支持梵高的风格或者
是过去一直很难生成成功的线条化
甚至可以将原图中的阴影笔触
也还原到每种图片的物体上
以及参考安卓的logo进行的设计
此外
研究人员还拓展了StyleDrop的能力
不仅能够定制风格
结合DreamBooth还能够定制内容
比如说
它可以生成一个梵高风格的小柯基
或者一个水彩笔风格的小猫
总之就是可以按照你的风格
来生成你的物体
按照惯例
我们再来讲一下StyleDrop的论文的内容
StyleDrop基于Muse构建
由两个关键的部分组成
一个是生成视觉transformer的参数有效微调
另一个是带反馈的迭代训练
之后研究人员再从两个微调模型中合成图像
这个Muse是一种基于
掩码生成式Transformer的
文本生成图像模型
它包含了两个合成模块
分别是用于生成尺寸为256*256的基础图像
以及超分辨率到512*512
或者1024*1024的尺寸
每个模块呢都由一个文本编码器T
一个Transformer G
一个采样器S
一个图像编码器E和解码器D组成
流程大概这样
T将文本提示映射到连续嵌入空间E
G对文本嵌入进行处理
来生成视觉token序列的对数
S通过迭代解码
从对数中提取到视觉token的序列
最后D再将离散的token序列
映射到像素空间I
StyleDrop对Muse Transformer层的架构
进行了简化
目的呢是为了能够支持参数高效微调
PEFT以及适配器
研究人员还提出了一个简单的
模板化的方法来构建文本提示
包括对内容的描述
后面跟着描述风格的短语
随后呢就是进行带有反馈的迭代训练
在这里呢研究人员还用到了两个方法
分别是CLIP得分和HF人工反馈
CLIP得分用来测量图像和文本的对齐程度
因此研究人员可以通过测量CLIP得分
即视觉和文本CLIP嵌入的余弦相似度
来评估生成图像的质量
然后呢研究人员再选择出
得分最高的CLIP图像
他们称这种方法为CLIP反馈的迭代训练
简称CF
实验中研究人员发现
使用CLIP得分来评估合成图像的质量
是提高召回率的有效方式
而且呢不会过多损失掉风格保真度
不过从另一方面来看
ClIP得分也可能不能完全与人类的意图对齐
也无法捕捉到微妙的风格属性
而HF人工反馈是一种将用户的意图
直接注入到合成图像质量评估中的
更直接的方式
它可以用来补偿CLIP得分无法捕捉到的
微妙风格属性的问题
因为到目前为止
还没有人对文本图像生成模型的风格调整
做过广泛的研究
因此研究人员提出了一个全新的实验方案
首先研究人员收集了几十张不同风格的图片
从水彩到油画 平面插画
3D渲染到不同材质的雕塑等等
然后呢他们使用适配器进行了调优
对于所有的实验使用了Adam优化器
更新了1,000步的适配器权度
学习速率为0.00003
最后的评估过程是基于CLIP
来衡量风格一致性和文本对齐
此外研究人员还进行了用户的偏好研究
经过实验
StyleDrop能够捕捉各种样式的纹理
阴影和结构的细微差别
对颜色偏移层次和锐角的细粒度把控也更好
好了今天的分享就到这里
欢迎大家订阅本频道
我们下期再见
