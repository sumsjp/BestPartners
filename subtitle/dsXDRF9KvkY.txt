大家好，这里是最佳拍档，我是大飞
上周五
OpenAI董事会突然把Sam开除的事件已经结束
闹了好几天之后Sam回归，董事会改组
而这件事的背后导火索有许多传闻
其中最重要的一个是OpenAI可能在最近有一项重大的技术突破
被认为是Sam和董事会分歧的重要原因
而今天
国外的路透社独家消息提到OpenAI内部一个称为Q*的项目取得了非常重大的突破
使得部分人认为AGI很接近
进而引发了一系列事件
今天我们就将根据目前的信息
汇总介绍一下Q*项目
并不一定代表
真实的情况
在路透社的独家报道中
Q Star是一个OpenAI内部的新模型
它可以解决一些数学问题
内部人士表示
虽然Q*模型目前仅仅可能只有小学生的水平
但是它可以解决一些数学问题
而与此前数学推理模型不同的是
Q*模型可能不是通过检索来解决问题
而是有可能有一点真正的人类推理能力
尽管当前Q*模型能力不那么强
但是它的测试结果很出色
让一些人看到这已经可能是接近AGI的能力了
而另一家非常著名的媒体
The Information在今天也有一个独家的报道
里面提到Sam被开除前
他在APEC会议上提到他在OpenAI经历过四次“知识界限”突破
最近的一次就在几周前
原话是“推开无知的面纱
推进发现的前沿"
不过
目前并没有关于Q*项目和模型的任何有价值的信息
但是也有很多人从历史的信息中猜测了一部分关于Q*模型技术相关的信息
我也总结了一下
首先
Q*可能是Q-Learning和A*的结合
斯坦福AI博士生Silas Alberti从命名习惯和能力上猜测
Q*可能是Q-Learning和A*的结合
或者是表示贝尔曼方程的最优解
Q-Learning是强化学习的一种方法
而A*算法用于在图形中找到从一个节点（起点）到另一个节点（目标）的最短路径
经常用在地图或者网络的寻址中
A* 算法和 Q-Learning可能结合的原因
是基于这两种算法的互补特性
这种结合可以在复杂的决策环境中发挥出更强大的能力
二者结合的潜在原因包括，1、互补性
A* 算法在已知环境中表现出色
而 Q-Learning在处理不确定性和学习环境动态方面更有效
将这两者结合可能创建一种能够有效处理复杂、动态环境的算法
2、路径规划和决策制定
A* 算法提供了有效的路径规划能力
而 Q-Learning能在不确定环境中作出最优决策
结合它们可能使算法能在不确定性较高的环境中找到最优路径
并在此过程中适应环境变化
3、提高效率
A* 的启发式搜索可以指导 Q-Learning更快地收敛到最优解
而 Q-Learning的适应性可以帮助 A* 算法更好地处理动态变化的环境
综上所述
结合 A* 算法和 Q-Learning可能会产生一种既能有效规划路径
又能适应环境变化并进行复杂决策制定的算法
这应该可以大大提高大模型的泛化和推理能力
贝尔曼最优解（Bellman Optimal Equation）是强化学习和动态规划领域的一个核心概念
由理查德·贝尔曼（Richard Bellman）提出
这个方程式描述了在一个决策过程中
如何找到使长期回报最大化的策略
不管怎么说
这种猜测都指向Q*很可能是一种采用了 AlphaGo 风格的蒙特卡洛树搜索
这种技术可能会让大模型大大提高推理能力
而且可能极大提高数学问题的解决能力
与报道传闻的突破一致
其次
Q*也可能是Ilya在2021年启动的GPT-Zero的突破
GPT-Zero被传闻是OpenAI的科学家Ilya Sutskever在2021年开始的OpenAI内部模型项目
目的是找出一条可行的路径让GPT-4模型能够解决推理、数学或者科学类的问题
而这也是类似DeepMind的AlphaGO的项目
大家应该都知道了
AlphaGo是一个由DeepMind开发的人工智能程序
专门设计用来玩围棋
这个项目的显著特点是它结合了机器学习和树搜索技术
使用深度神经网络来模拟人类围棋玩家的思维过程
AlphaGo首次引起广泛关注是在2016年
当时它在一场历史性的比赛中战胜了世界级围棋冠军李世石
此后，AlphaGo继续进化
其改进版本AlphaGo Zero甚至能够在没有任何人类围棋知识的情况下
仅凭自我对弈学习并达到超越专业水平的能力
注意，这里的最大的一个亮点是
后期的AlphaGo Zero已经不需要人类棋谱来提升能力
而是通过自我对弈学习提升
这也是OpenAI的GPT-Zero可能想解决的问题
即克服没有高质量数据情况下解决模型的继续训练
而Ilya Sutskever的GPT-Zero的目的也是希望可以用计算机生成的数据而不是真实的数据
来解决模型训练数据缺乏的瓶颈
而在最近的Ilya采访中
他表示最近的大模型的阻碍最大的是数据问题
但是这个问题可以被解决
Ilya表示，虽然无需赘述
但是这个问题可以被克服
显然这说明内部应该也有一些突破了
上述两个猜想一个是技术层面一个是数据层面
但是两种路径都是似乎指向用类似AlpahGO Zero的技术
来解决大模型的继续大规模训练的问题
而NVIDIA的高级AI科学家Jim Fan今天在推特上和马斯克、LeCun也讨论了这个问题
Jim Fan认为使用计算机合成数据可以提供下一次几十万亿高质量数据集
唯一的问题就是需要想办法确保数据的持续高质量和多样性
而马斯克也认为这是对的
因为一个硬盘就可以装下人类所有的书很可悲
但是合成数据可以生成更多
非常有潜力
而特斯拉据称也在用合成的数据来做训练
这也可以理解
毕竟可以用类似仿真的游戏让车不断行驶
而LeCun则表示
动物和人类只需少量的训练数据
就能很快变得非常聪明
他认为新的架构可以像动物和人类一样高效地学习
使用更多的数据
无论是合成数据还是非合成数据
只是暂时的权宜之计
因为目前的方法存在局限性
最终还是需要依赖模型架构的更新
让它可以像人类一样用少量数据就可以学习
最后总结一下
虽然没有更多详细的信息
但是大家普遍认为Sam说的OpenAI内部大模型技术的突破
应该就是指这个Q*的突破
可能下一代的模型在数学推理和科学任务上会有很大的提升
而这背后可能就是类似数据合成和强化学习的突破
以上就是目前有关Q*的一些信息
不知道大家觉得Q*，
究竟会是个什么样的模型呢
欢迎在评论区留言
感谢观看本期视频，我们下期再见
