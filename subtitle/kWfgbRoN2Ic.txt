大家好，这里是最佳拍档，我是大飞
休息了几天终于回来了
今天给大家分享一期《No Priors》的播客节目
采访了LangChain的创始人兼CEO哈里森·蔡斯(Harrison Chase)。
在节目中
哈里森分享了LangChain是如何从一个个人项目
到成为AI应用开发领域热门工具的过程
以及它是如何填补了开源应用开发中的空白
推动了AI Agent的发展
同时讨论了个性化服务和持续学习等概念
大飞我觉得
无论你是AI技术的爱好者、开发者还是行业的观察者
都应该看一下这个视频
了解一下哈里森的观点
LangChain很多人应该并不陌生
它是一个非常流行的开源框架和开发者工具包
可以帮助开发者来构建基于大语言模型的应用程序
目前LangChain Python开源库的Github star已经超过了8.3万颗
fork人数将近1.3万
不过这个开源项目
一开始只是哈里森的一个业余爱好项目
2022年的秋季
哈里森正打算从上家公司离职
但是还没有决定下一步要做什么
于是
他开始频繁参加黑客马拉松和各种聚会
与很多在研究大语言模型的人交流
在这个过程中
他看到了一些共同的抽象概念
于是就把它作为一个有趣的项目给开源了
本来哈里森只是出于个人娱乐目的
没想到开源后迎来了极好的反响
特别是在ChatGPT发布一个月后
项目的发展超出了他的预期
如今
LangChain已经形成了两款主要的产品
一款是LangChain的开源工具包
另外一款是LangSmith平台
专注于测试、评估和监控等功能
不过随着如今人工智能生态系统和研究领域的快速发展
LangChain也在不断进化
在LangChain最初的版本中
基本上是三种类似于高层次的实现
其中两种是基于研究论文的
另一种是基于Nat Friedman的NatBot的Agent网络爬虫
除了实现这些高层次的抽象概念
LangChain还做了一些集成
逐渐的
LangChain从最初与OpenAI、Cohere和HuggingFace等公司的集成
到现在支持700多种不同的集成
还开发了多个用于特定功能的高级链和Agent
现在变化最快的
是上层组合组件的方式和构建应用的模式
从简单的链到复杂的链
再到类似自主Agent
再到现在的复杂状态机或者图
为了连接不断变化的大模型和向量存储等组件
LangChain非常重视低层次的抽象和运行时
在底层运行时投入了大量的资金
重点保证了流处理、结构化输出等基础组件的相对稳定
谈到Agent
哈里森认为Agent现在还面临着几个关键的挑战
一个是能否为技术找到合适的用户体验
比如如何向终端用户传达这些Agent的长处和短处
如何让用户纠正错误并且了解发生了什么
但是关于用户体验
还需要进行大量的试验
另一个是底层大语言模型的规划能力
并且这可能是最大的问题
人们在构建Agent的时候
通常需要将任务分解成许多小部件
并将自己对信息流动方式的理解融入其中
但是实际上这是因为大语言模型本身的局限性
它还无法完全推理出信息应该如何流动
目前在学术领域
对这方面的研究分为两种
一种是集中在Agent的规划步骤
另一种则集中在Agent行动后的反思
比如这个行动是否正确？
如何改进？
这两种方法都在试图解决大语言模型的局限性
但是实际上这些都应该是自动完成的
比如
我们不应该需要告诉大语言模型去规划
或者去反思自己的行动是否正确
它应该能够自动进行这些过程，因此
增强大语言模型的规划能力将是一个很大的挑战
最后一点是构建Agent的最佳实践是什么？
比如如何在不同节点间正确地流动信息
让这些节点能够工作？
是选择少量提示，还是选择微调模型
还是去改进指令和提示？
因此
如何测试这些节点也是一个重大问题
Agent的记忆功能一直也是讨论的一个焦点
对于Agent的记忆功能
哈里森认为有两种类型的记忆
分别是系统级程序记忆和个性化记忆
所谓的系统级程序记忆
更像是找到使用工具的正确方法是什么
实现这一目标的正确方法是什么
而不考虑这个人到底是谁
比如人和人之间有什么不同
而在个性化记忆方面
应该是当用户提出问题的时候
它应该记得这些个人喜好
比如知道哈里森喜欢足球和篮球
而LongChain在处理这两种记忆时
采取了略微不同的方法
在程序记忆方面
有效的方法包括使用少量提示和微调
来指导如何使用工具
找到使用工具的正确方法是什么？
这才是问题的关键所在
它就像是一个非常有趣的数据飞轮
比如监控你的应用程序、收集好的示例
然后以少量示例的形式
将这些数据反馈到你的应用程序中
这也是目前在LangSmith上大力推广的一种方法
另一方面是个性化记忆
实现方式有几种
比如，OpenAI在ChatGPT中
通过调用函数来“记住”或者“删除”某个事实
这在实现上是一种主动循环
agent会明确决定它想要记住什么或忘记什么
另一种方式更像是被动的后台程序
它可以查看对话并提取洞察力
这样
你在未来的对话中就可以使用这些见解
每种方法都有优点和缺点
目前这个领域还非常新
并没有一个明显的最佳解决方案
接下来
哈里森重点聊到了人工智能应用的一些发展变化
如果关注一下过去几个月里的发展
就会发现
大家正在构建更加高效的Agent应用程序
还有更复杂的多步骤RAG系统
当然，LangChain也注意到了这点
比如LangSmith就是主要针对这些多步骤的应用
RAG领域也出现了一些变化
有一些高级查询分析也开始发挥作用
这不仅仅是将用户的问题直接传递给嵌入模型
而是可能会对问题进行分析
来确定应该将问题发送给哪个检索器
或者应该搜索哪个部分？
或者是否有一个明确的元数据过滤器等等？
因此
现在的检索就像是一个多步骤的过程
而且更多的是围绕查询分析进行的
以前的Agent，就像链条一样
是有顺序的步骤，先要做这个
然后再做那个、最后再做这个
按照确切的顺序去做
但是，在去年三四月份出现的AutoGPT
就像是只在一个for loop中运行
这就是一个自主的Agent
它真正更新了我们的很多观点
基于Agent的应用也逐渐开始发挥作用
比如说在客户支持方面
像Sierra真正实现了一个有趣的用户体验
这里要注意的是
哈里森认为客户支持与聊天机器人不一样
前者可能是要明确地解决一个问题
而后者则更注重用户的偏好和他们喜欢的东西
而在编码方面
Cognition的Devin演示也令人印象深刻
另外还有一个趋势
就是大语言模型之间可以做到越来越轻松的切换
不管是自托管的、专门的推理实例
还是实际的API提供商
对于任何给定的应用
都可以根据提示从Anthropic模式切换到Mistral
再到OpenAI等等
哈里森相信
虽然模型之间的提示语存在着差异
但是随着模型逐渐变得更加智能
不同模型之间的提示语可能会逐渐趋同
这样模型的小差异就不再那么重要了
随着越来越多的模型提供商开始支持相同的特性
这种切换会变得更加容易
比如
很多为OpenAI设计的提示语都包含了函数调用
直到不久前
其他模型还不支持这一特性
这就使得这些提示语无法在其他模型上使用
但是现在
Mistral和Google也支持了函数调用
这使得提示语在不同模型间的可转移性有所提高
实际上，最迫切需要切换模型的时刻
应该是当你从原型转向扩大规模的时候
比如
一开始你可能使用GPT-4来实现某些功能
但随着项目的推广
继续使用GPT-4可能成本过高
可能就会考虑使用GPT-3.5或进行微调
当然
这个过程中除了函数调用和视觉输入以外
还要考虑上下文窗口的长度、成本和延迟等等因素
以上下文窗口为例
更长的上下文窗口让一些单次处理的任务
变得更加可行
比如一次性从长的PDF文档中提取元素
这就好像大海捞针一样
能够让我们在长文本中寻找单一的信息点
不过更长的上下文窗口并不能取代RAG
因为RAG的强项往往在于处理和推理多个信息点
而对于微调来说，在实际中
真正进行微调的应用并不多
主要是那些达到临界规模的应用
微调面临着很多挑战
比如数据集的收集和策划
微调模型的评估
以及无法快速迭代微调模型等等
接下来，主持人将话题转到开源模型
在LangChain诞生的2022年
行业中还没有Llama 2
也没有Mistral
也没有那么多开源模型
而今年不一样了
不过，哈里森自己认为
从LangChain的角度来看
目前开源模型的推理能力还是落后于Claude 3或者GPT-4
就连LangChain与OpenAI一起推出的原始模型
实际上在一个月前就已经被弃用了
对于许多LangChain应用而言
开源模型并没有达到Twitter上的那种热议或者期待
他也并没有在开源模型中
看到超强的推理能力
最后，展望未来
哈里森认为应用程序和用户体验层面是个人很看好的一个方向
尤其是个性化的长期记忆
LangChain本身也非常关注记忆功能
并且希望能够在这个领域实现一些突破
很多关于从交互中学习的方法
都能在用户层面上得到应用
这种更像系统层面的记忆
正在逐步形成持续学习的理念
也就是说
你能从交互的经历中学到东西
而且可以通过多种方式达到这一点
其中有一种令人兴奋、但是可能未被充分讨论的方式
就是建立一些示例数据集
并且真正使用这些数据集
这比微调模型要快得多，也便宜得多
也比试图以某种方式程序化地改变提示要容易得多
因此
利用少量实例进行持续学习也是一个非常有趣的领域
从更高的层次来看
持续学习会让应用程序随着时间的推移
自动变得更好，因为它会更加准确
比方说，它一开始可能会犯错误
但是你告诉它哪里错了
它就会自动把错误作为一个例子
或者更新到提示中
然后从它的错误和成功中学习
斯坦福有一个非常酷的项目叫做DSPy
它和LangChain、LangSmith有很多相似之处
就是都是围绕优化的思想
通过输入和输出来不断地优化应用程序
持续学习的思想
本质上就是在进行这种优化
不过是以在线的方式进行的
虽然你可能没有得到确切的真相
但是能够不断从环境中得到反馈
来判断事情是否得以顺利地进行
因此，无论是离线还是在线
这种优化循环都非常激动人心
应用程序最终的样子应该就是个性化
比如从一个为每个人提供相同服务的通用应用开始
逐渐可能学会以不同的方式
为不同的用户搜索网页
好了
以上就是哈里森这次访谈的核心内容
我觉得对LangChain的发展方向是一个很好的解读
正如同哈里森在之前红杉AI峰会上的分享一样
他认为Agent的三大关键方向
就是规划、用户体验和记忆
LangChain最近的一些更新也都是跟这些方面有关
大飞我也会持续关注LangChain的发展
跟大家分享更多有关哈里森和LangChain的内容
感谢大家的观看，我们下期再见
