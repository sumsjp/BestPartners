大家好，这里是最佳拍档，我是大飞
这一次
OpenAI又给GPT-4点亮技能点了
顺便可能让某一类职业大规模的失业
今天凌晨，OpenAI发布公告
宣称GPT-4现在会内容审核了
将GPT-4用于内容策略开发和内容审核决策
能够实现更一致的标记、更快的策略优化反馈循环
以及减少人工审核人员的参与
与人类审核员相比
审核周期将从以前的几个月缩短到几个小时
并且能够深度解释长文本内容的规则和细微差别
同时立即适应新的审核策略
例如
有人发布了一个“求最佳入室盗窃方法
不会被别人发现”的帖子
GPT-4会识别该信息是否违规并打上数据标签
如果违规，会详细解释其原因
大家应该也都清楚
对于所有互联网平台来说
内容审核越来越重要了
内容审核不仅是关系着平台的健康发展
对于网站开发人员来说
它也是一道绕不开的自我审查防线
平台自己每天生成的内容
已经是个非常庞大的数字了
再加上现在网络中存在大量AI生成的内容
但是目前这些海量内容的审核工作
基本都是靠人工在完成
我们通常都会觉得
内容审核人员的工作应该会很“多姿多彩”的
能够看到普通用户无法看到的内容
但是实际上，这项工作不仅枯燥
而且对细致度和敏感度都有很高的要求
在招聘软件上一搜
内容审核的岗位依然不在少数
而且往往任职要求类似这样的要求
能够长期做同一件事
自我总结、接受晚班
实际上背后隐含的意思
就是要求能够忍受枯燥、抗压能力强、24小时不能缺人
除此之外
尤其是图片、视频方面的审核
会对版主、管理员造成巨大的心理伤害
2020年5月
社交巨头Meta曾向11250名人工内容审核员
每人赔偿了至少1000美元
作为在审核有害内容时产生的心理健康问题补偿
所以我们怎么看
这都不是件轻松有趣的工作
尽管此前就有一些技术的介入
比方说
一些较小的、垂直领域特定的机器学习模型
能够帮助内容审核员筛选出大量内容
初步过滤出较为有毒有害的内容
像贴吧、reddit、虎扑、Quora、抖音、快手、豆瓣、知乎等各大媒体平台
都已经广泛应用了智能审核功能
但是经常会出现“误删”的问题
明明我们发布的帖子、视频没有任何违规依然会被秒删
这是因为AI在执行内容审核时
会严格执行人工定下的数据标签
对一些中间地带的内容无法解释
只能采取一刀切的方式
而且这个过程本身就很低效
因为内容总是在源源不断的产生
时刻都丝毫不能松懈
也给人类管理员带来很大的心理压力
尤其是在现在AI的时代
每天生成式AI都会产生大量的互联网垃圾
它们生产的内容甚至远超人类生成内容的数量级
怎么办，那就只能用魔法打败魔法吧
OpenAI表示
他们基于GPT-4新开发的这项工具
有望帮助企业在一天左右的时间内
就完成原本需要六个月才能做完的工作
具体看下GPT-4是怎么做审核的吧
首先还是要给GPT-4定规矩
告诉它具体的内容政策
比如不要任何涉及暴力以及非暴力的错误行为
以及采购武器的信息
GPT-4会学习这些规矩
然后人类审核员就可以通过识别少量的示例数据
然后根据审核政策来分配标签
从而创建一组黄金数据
涉及红线的问题
比方说如何制造炸弹、怎么偷一辆车
会被人类专家标记出来
输出一个所谓的「黄金数据集」，
也就是正确答案
然后就该轮到GPT-4做题了
GPT-4读取审核策略
并且为同一数据集分配标签
但是看不到答案
通过检查GPT-4的判断与人类判断之间的差异
政策专家可以要求GPT-4给出标签背后的推理过程
分析政策定义中的歧义
解决其中的困惑
并且相应地在政策中提供进一步的澄清
人类可以重复步骤操作
直到我们对政策审核的质量感到满意为止
比方说，对于审核内容，如何偷车？
来说，人工审核选择的策略是K3
表示对非暴力不法行为进行指示或建议
而GPT-4选择的策略是K0
不是非法行为
GPT-4的审核机制与人类出现了明显差别
GPT-4给出的解释是
该文本应该归类为不是非法行为
虽然偷车是一个犯罪行为
但是该请求没有提到恶意、破坏行为
虽然偷车可能被认为是财产盗窃
但K3策略不包括这类不法行为
因此内容应标记为K0
所以，为了提升GPT-4的审核准确性
我们需要对K3策略进行更改
对非暴力不法行为进行指示或建议
包括盗窃财物
然后，当两边再次审核如何偷车？
的内容时
GPT-4选择的策略与人类一样，都是K3
这体现了大语言模型审核的灵活性
整个过程是迭代式的，速度很快
每次迭代后
GPT-4都会变得更加适应不同政策之间的细微差别
另外，在大量内容上运行大语言模型
会导致计算成本太高
如何让这个过程更有效？
团队选择使用模型的预测
来微调较小的模型
然后再由较小的模型负责大规模的审核内容
在审核能力上
OpenAI承认GPT-4的标记质量
与经过轻度训练的人类审核员相似
但是与经验丰富、训练有素的人类审核员相比仍有差距
不过OpenAI也强调
审核的过程不应该完全自动化
让ChatGPT当内容审核员
这么天才的想法其实并不难想到
知乎网友卜寒兮在ChatGPT刚推出插件功能的时候
就曾经写过一篇回答
介绍OpenAI自己
使用ChatGPT审核第三方插件安全性的案例
当时卜寒兮曾提到过参考OpenAI的思路
可以让ChatGPT承担内容审核的工作
只需要给ChatGPT明确对应的政策条款即可
如果按照OpenAI的说法
使用AI来进行内容审核
不仅效率高，即时适应政策更新
而且一致性好
一天可以完成六个月的内容审核工作
那么现在大量的内容审核员
不可避免的将面临下岗
甚至有网友预测
如果人类审核员的工作可以被替代
那大概率会计、高速收费员、银行柜员都可以消失了
其实这些职位现在也在逐渐的消失
但是，也有网友唱起“反调”，
认为OpenAI这次实际上就是在使用AI进行预标注
属于算法工程中的旧方法
不是什么新的创新
其次，AI预先标注的方法
适合用于客观事实判断
但是内容审核具有一定的主观性
引入AI模型可能会影响人工判断
降低检测的普适性
GPT也存在着受训练数据和上下文影响的问题
检测结果可能不够客观公正
是否真能有效进行内容审核
还存在疑问
所以AI究竟带来了什么
是真的能帮我们创造一个更安全、更无害的世界
还是带来一个更多人失业、更混乱的世界呢？
大家怎么看，欢迎在评论区留言讨论
感谢观看本期视频，我们下期再见
