大家好，这里是最佳拍档
2026年2月23日
Anthropic通过推文和博客
发布了一则震动行业的指控声明
将矛头直指中国的DeepSeek、月之暗面和MiniMax三家AI公司
Anthropic在声明中声称
这三家公司通过创建超过两万四千个虚假账户
与Anthropic旗下的Claude模型
进行了超过一千六百万次的交互
目的是系统性地提取Claude在推理、工具调用与编程等核心领域的能力
用来训练和改进自身模型
Anthropic将这种行为定义为工业级规模的模型蒸馏攻击
根据博客中的详细描述
三家实验室的操作模式被认为具有相似的攻击特征
包括使用虚假账户和代理服务绕过区域限制
通过高度结构化、重复性的提示词批量获取Claude的输出
重点瞄准Claude最具差异化优势的能力领域
包括多任务推理、代码生成、工具使用与编排等领域
并且通过多样化的账户类型规避检测
其中
DeepSeek进行了超过十五万次的交互
被Anthropic标记为极度危险
认为DeepSeek专门通过精心设计的提示词
诱导Claude输出内部的思维链
月之暗面超过三百四十万次
侧重提取智能体推理和数据分析能力
这与Kimi目前主攻长文本和复杂逻辑解析的产品定位高度一致
MiniMax则规模最大
超过一千三百万次
尤其是当Anthropic发布新模型时
MiniMax在24小时内就调整了策略
将近一半的流量重定向到新模型
进而捕获最新的能力特征
Anthropic在博客中强调
这三家实验室的行为并非正常的产品使用
而是通过九头蛇集群架构实施的有组织攻击
根据博客描述
这个九头蛇集群控制着约2.4万个虚假账号
它会利用住宅代理IP伪装成普通美国家庭用户
将巨大的并发请求打散
一旦某个账号被Anthropic的风控系统识别并封禁
集群会立刻自动注册新账号补位
以此实现全天候、不间断的数据窃取
不过，从技术角度来看
这套说辞多少有些包装过度
所谓的九头蛇
说白了就是国内开发者为了绕过Anthropic的地区封锁
被迫使用的多节点动态代理池
加上号池自动轮换脚本
这在早年的爬虫圈、黑产攻防领域
甚至在做海外电商抢单时
都只能称得上是基本操作
除了对行为本身的指控
Anthropic还提出了两点核心担忧
一是非法蒸馏得到的模型
往往不会继承原模型内置的安全防护机制
可能导致原本被限制的高风险能力
在缺乏约束的情况下扩散
带来安全隐患
二是大规模蒸馏会削弱美国在AI领域的技术领先优势
因为部分实验室可以通过提取能力而非自主研发来缩小差距
这也强化了出口管制的合理性
限制先进芯片的获取
不仅能限制直接的模型训练
还能遏制这种所谓的非法蒸馏行为
我们再来说说 模型蒸馏
它最初是机器学习领域的一项标准技术
经典定义可以追溯到2015年
核心逻辑是通过一个性能优越的教师模型
为参数规模更小的学生模型生成软标签或者中间表示
让学生模型能够在保持较低计算成本的同时
实现接近教师模型的性能表现
这项技术在视觉、语音和自然语言处理等领域被广泛应用
本质上是一种提升模型效率、降低部署成本的工程优化手段
但是随着大模型时代的到来
蒸馏技术的形式发生了重要演化
传统的蒸馏技术
大多需要获取教师模型的内部权重参数
而如今的前沿大模型几乎都采用闭源模式
仅通过API接口向用户提供服务
因此
一种新型的黑盒蒸馏技术应运而生
这种方法不需要访问模型的内部参数
而是通过大规模调用API接口获取模型的输出结果
再将这些输出数据作为训练素材
来训练自己的模型
从技术原理来看
黑盒蒸馏并不涉及对模型参数的逆向工程
而是基于可合法获取的输出进行再训练
这也为法律边界的界定带来了巨大争议
在行业实践中
蒸馏行为本身其实并不罕见
许多商业公司都会在内部
使用高性能模型为低成本模型生成训练数据
用于内部优化或边缘设备部署
这种做法通常被视为提升效率、控制成本的合理手段
但是蒸馏技术的合法性边界
往往取决于两个关键因素
一是是否违反了相关的服务条款协议
二是是否存在规避访问限制的行为
当蒸馏仅用于优化自身非竞争性模型时
通常不会引发争议
但如果是针对竞争对手的核心能力进行规模化、结构化的抽取
用于训练直接竞争的通用模型
性质就从效率优化转向了能力窃取
这也是Anthropic指控中国三家AI实验室的核心依据
不过，Anthropic的这些指控
从一开始就面临着诸多质疑
首先
最核心的质疑来自于Anthropic自身的数据来源问题
许多网友和行业人士指出
Anthropic自己的模型训练数据就存在严重的版权争议
其获取数据的方式
甚至比它所指控的蒸馏攻击更为激进
这就不得不提到Anthropic一项代号为巴拿马项目的秘密计划
根据美国联邦法官解封的版权诉讼相关文件显示
2024年初
Anthropic在美国的一座仓库中
开展了一项大规模的书籍扫描工程
整个扫描过程完全工业化流水线作业
工人们将刚采购的书籍送入机器
用液压切割机整齐切掉书脊
散开的书页被送入高速工业扫描仪
扫描完成后剩余纸张直接交给回收公司处理
有参与报价的服务商透露
Anthropic希望在六个月内完成五十万到两百万册书的数字化工作
这项计划的明确目标
就是以破坏性方式扫描全球所有书籍
并且不希望外界知道
Anthropic之所以要采取这种原始且粗暴的方式获取书籍数据
核心原因是对高质量训练数据的极度渴求
Anthropic的CEO达利奥·阿莫代伊
在2023年1月的内部文件中就写道
用书籍训练模型能够让AI学会如何写得更好
而不是仅仅模仿质量参差不齐的网络语言
书籍经过严格的编辑和校对
内容结构清晰、逻辑严谨
是网络文本难以替代的高质量语料
但是挨个与出版社和作者洽谈授权
不仅费时费力
成本也极高
因此Anthropic选择了这种破坏性扫描的方式
试图规避版权授权的麻烦
事实上，在巴拿马项目启动之前
Anthropic就已经通过更具争议的方式获取书籍数据
法院文件显示
Anthropic联合创始人本·曼恩曾经在2021年6月的11天里
从被称为影子图书馆的LibGen网站
下载了大量侵权小说和非小说类书籍
2022年7月
一个公开宣称在大多数国家故意违反版权法的Pirate Library Mirror网站上线后
曼恩更是兴奋地将网站链接发给其他员工
并留言来得正是时候
外加三个感叹号
对盗版资源的迫切需求可见一斑
尽管Anthropic事后声称从未用这些盗版数据训练过正式发布的商业模型
但是司马昭之心路人皆知
为了推进巴拿马项目
Anthropic还专门聘请了汤姆·特维主持相关工作
而他正是此前谷歌图书项目的核心参与者
这个项目曾经因为大规模扫描图书馆书籍
引发了长达多年的版权诉讼
根据相关披露
Anthropic主要通过两家书商批量采购书籍
分别是美国二手书零售商Better World Books和英国的World of Books
每次采购量动辄数万册
内部文件还显示
Anthropic员工曾经讨论接洽纽约公共图书馆
甚至考虑从资金不足的新图书馆获取书籍资源
面对指控
Anthropic最终以15亿美元的金额与相关方达成和解
创下了AI版权诉讼史上的赔偿纪录
但是细算下来
每本书的赔偿仅约三千美元
仅为美国版权法规定的法定赔偿上限
每本书15万美元的2%
更关键的是
和解协议并不要求Anthropic承认任何违法行为
法院对AI训练属于合理使用的认定仍然有效
这意味着Anthropic实际上用相对较低的成本
获得了继续使用这类数据的合法性背书
正是基于这些背景
当Anthropic指控中国公司非法蒸馏时
引发了十分强烈的反弹
埃隆·马斯克第一时间在X平台发文反讽说道
绝了
他们怎么敢偷Anthropic从人类程序员那里偷来的东西呢？
随后马斯克进一步补充道
Anthropic已经犯有大规模窃取训练数据的罪行
他们必须为其盗窃行为
支付数十亿美元的赔偿金
这就是事实
知名AI评论家加里·马库斯也毫不留情地批评道
Anthropic的行为
相当于一名肆无忌惮的盗贼抱怨自己被抢劫了
大量网友也在Anthropic的推文下留言
指出其双重标准
一家未经许可
就使用了所有人的数据进行训练的公司
现在却因为有人未经许可使用了它的数据而感到不满
Anthropic非法复制并销毁了数百万本书籍
每天在网络上进行数百万次API抓取
现在却抱怨别人通过付费API提取了它的数据
更让这份指控显得苍白的
是另一个行业内公开的秘密
不仅是中国在蒸馏
西方巨头同样在蒸馏中国模型
就在几个月前，开源界就曾爆出猛料
Meta在开发其内部代号为牛油果的项目时
使用了阿里巴巴的千问开源模型进行蒸馏训练
而法国的AI独角兽Mistral
也被前员工曝出其核心能力的飞跃
部分源于对DeepSeek模型的蒸馏
说白了
这其实就是一场全球范围内的算力套利
当你在领跑时，追赶者就会来蒸馏你
当你落后时
你也会毫不犹豫地去蒸馏新的领跑者
这在硅谷其实从来就不是什么新鲜事
那么，这仅仅是一份商业上的指控么？
如果我们把时间轴拉长一点
去翻一翻达里奥·阿莫代伊过去两年的公开发言
就会发现绝非偶然
在硅谷的一众大佬中
达里奥是向华盛顿兜售中国AI威胁论最积极的一位
从2023年他在参议院听证会上警告
坏的大模型可能导致生物武器袭击
到2026年初他在达沃斯论坛上公然宣称
向中国出口芯片就像向朝鲜出售核武器
他一直试图构建一套叙事
那就是只有Anthropic这样讲究安全的美国公司
才是对抗邪恶对手的最后一道防线
说白了
他长期以来都在用国家安全的意识形态作为护城河
试图换取美国监管层的庇护
然而，荒诞的是
就在他发出这份讨华檄文
试图再次自证忠诚的同一时间
在华盛顿五角大楼的会议室里
他正面临着自己亲手种下的苦果
不知道大家是否还记得
今年的1月3日
美国军方在委内瑞拉首都加拉加斯
执行了一场抓捕前总统尼古拉斯·马杜罗的突袭行动
这场行动最终导致了八十三人死亡
震惊全球
在这场军事行动中
美国军方通过著名的国防数据承包商Palantir
在机密系统内部署了Claude模型
它是目前五角大楼机密网络中运行的唯一、也是最强的商业AI模型
被用来快速处理战场情报、分析传感器数据和辅助目标定位
这是商业大模型首次被证实直接参与了致命的军事行动
事件曝光后
Anthropic内部立刻爆发了巨大的争议
Anthropic创立的初衷本是主打AI安全
在《使用条款》里白纸黑字的写着
绝对禁止将其AI模型用于促成暴力、开发武器或进行监控
事后
Anthropic的安全主管和高管团队向Palantir发去了质询
质问Claude是否被用于了致死行动
Palantir随后将这个质询转告了五角大楼
但是这一举动
彻底激怒了美国军方高层
在五角大楼看来
一家硅谷的商业公司
居然敢对国家机密军事行动指手画脚
这无疑是不可靠和不服从指挥的表现
于是，在委内瑞拉事件之后
美国国防部就发布了一份新的AI加速战略
立下了一个毫无回旋余地的硬性规矩
所有美国军方采购的商业AI模型
必须同意被用于所有合法目的
这句话换到军方的语境里，意思就是
科技公司必须彻底废除自己设定的所有道德和安全护栏
军方需要绝对的控制权和不受限制的使用权
在这场国家意志的碾压下
硅谷的巨头们展现出了极其灵活的底线
OpenAI早早作出了妥协
通过名为GenAI mil的项目
将定制版的ChatGPT部署给了美国国防部全部三百万人员
谷歌也表示了同意
而马斯克旗下的xAI
更是拿下了军方2亿美元的合同
毫无阻碍地清除了军事用途的限制
在庞大的军工复合体面前
目前只有Anthropic还在不得已的坚持
作为一家宣传AI安全至上的公司来说
达利奥曾经表示过
有两条红线绝对不能跨过
第一
绝对禁止将Claude用于对美国公民进行大规模的国内监控
第二
绝对禁止将Claude用于制造全自动致命武器
但是，五角大楼的诉求也非常直接
目前机密工作里综合能力最强的模型就是Claude
当军方需要最好的工具时
公司是没有任何讨价还价的余地的
为了逼迫达里奥就范
国防部长皮特·赫格塞斯祭出了一项极度致命的行政威胁
准备将Anthropic正式列入供应链风险名单
这个名单里的企业
通常是专门为认为是为外国敌对势力准备的
上一个被贴上这个标签、享受制裁待遇的正是华为
所以，一旦Anthropic被纳入名单
根据美国法律，所有美国国防承包商
甚至所有与政府有业务往来的财富100强企业
都必须提供自证
确保他们的工作流中绝对没有使用任何Claude的软件或API
而目前美国排名前十的企业里
有八家在深度使用Claude
这样一来
将直接切断Anthropic在企业级市场的几乎所有收入来源
相当于在商业上执行了死刑
而就在2月24日上午
达里奥走进了五角大楼的会议室
媒体披露的细节显示
这绝非一次友好的会谈
一位国防部高级官员在接受媒体采访时
放出了极其傲慢和粗俗的狠话
说，这绝不是一次友好的相互了解
这是一次，要么拉屎
要么让出茅坑的最后通牒
另一位军方官员更是毫不掩饰态度
认为达里奥的问题在于他太有意识形态了
虽然解开这个难题会很棘手
但是如果逼迫军方出手
一定会让他们付出惨痛的代价
如此来看，Anthropic在这个节骨眼上
突然对中国模型发出如此高调且充满政治意味的讨伐
原因呼之欲出
在走进五角大楼、面临可能被全面封杀的绝境前
达里奥需要交出一份投名状
或者说，凭空制造一些谈判的筹码
这份指控声明
实质上是想向政客和军方证明
中国公司正在疯狂窃取美国的技术
Anthropic是阻挡他们、维护美国AI霸权最核心的资产
是自己人
不能用对付外国企业的手段来绞杀
为了求生
如今的Anthropic也只能通过在台前撕咬同行
来假装他们最在意的是知识产权与合规
可是
当达里奥走出五角大楼的那间会议室
无论最终他选择放开红线
成为军方的附庸
还是承受公司被行政力量肢解的代价
某种意义上
那个纯粹由技术驱动的古典大模型时代
已经画上了句号
他或许算错了一点
当他主动把国家安全引入商业竞争的那一刻起
他就已经失去了对自己公司命运的定义权
五角大楼的逻辑很简单
既然你反复强调
你的AI是国家安全的关键资产
是战胜对手的核武器，那么这件武器
就绝不能掌握在一个商人手里
它必须被毫无保留地装进发射井里
达里奥为了自保而抛出的安全与对抗
仿佛是一记回旋镖
最终砸碎了他自己精心维护的道德屏障
至于这份声讨中国模型蒸馏的声明
不过只是一个配合演戏的借口罢了
在这个量级的博弈中
技术理想主义早已没有了位置
曾几何时
我们还在挑灯夜战阅读论文
争论Scaling Law的物理极限
在技术社区里天真的探讨
AGI应该如何造福人类
但是如今
AI行业的遮羞布已经被彻底扯下
它赤裸裸地向大众展示
在国家机器和军工复合体面前
所谓的技术信仰、开源道德、AI安全底线
都显得无比脆弱
再前沿的技术
也终究将沦为政治博弈的筹码和战争机器的燃料
感谢收看本期视频，我们下期再见
