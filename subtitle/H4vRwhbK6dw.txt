大家好，这里是最佳拍档，我是大飞
1月18日
被称为“AI教父”杰弗里·辛顿教授
在柯特·贾伊芒格 Curt Jaimungal 的频道进行了一场访谈
在访谈中
他再次表达了自己对AI的看法
以及对未来的深刻担忧
今天大飞就来为大家解读一下
这次访谈的核心内容
辛顿指出
人工智能的发展速度已经远远超出了我们人类的控制能力
在 2023 年初
ChatGPT 的横空出世给人们带来了巨大的震撼
它的强大能力让人们看到了人工智能的巨大潜力
与此同时
辛顿教授在谷歌进行的关于模拟计算和数字计算的研究工作
也取得了重要进展
他发现，数字计算在知识共享方面
具有模拟计算无法比拟的优势
数字计算能够轻松地创建同一个模型的多个副本
这些副本可以在不同的硬件环境下运行
通过平均权重或平均权重梯度的方式
高效地分享它们在学习过程中所积累的知识
而模拟计算由于自身的特性
无法实现这种快速、高效的知识共享
例如
GPT - 4 之所以能够拥有如此丰富的知识储备
很大程度上就是得益于数字计算的这种优势
多个 GPT - 4 副本在不同的硬件设备上同时运行
它们各自获取不同的经验
然后通过权重梯度的平均
将这些分散的知识整合起来
从而使整个模型的知识体系不断扩充
相比之下
我们人类的大脑在知识传递方面就显得极为低效
如果我想要把大脑中的知识传授给另一个人
只能通过语言表达
产生一串词语
而你需要根据这些词语
在自己的大脑中重新构建知识体系
而这个过程中信息的损失和误解是不可避免的
更何况
一个句子所包含的信息量大约只有 100 比特
与大模型能够共享的数万亿比特相比
简直是天壤之别
而关于模拟计算和数字计算的差异
辛顿指出
我们已经知道数字计算在知识共享方面具有优势
但是这种优势也带来了潜在的风险
由于数字计算能够快速复制模型和权重
一旦被恶意利用
可能就会导致不良后果的迅速扩散
而模拟计算虽然在知识共享方面存在不足
但是它也有自身的优点
比如说低功耗
我们人类的大脑就是一个很好的例子
大脑以大约 30 瓦的功率运行
却能够容纳大约 100 万亿个连接
远远超过目前最大的人工智能模型的连接数量
这使得大脑在处理信息的时候具有独特的优势
能够高效地完成各种复杂的认知任务
在进一步探讨人工智能的潜在威胁时
辛顿教授的话语中充满了忧虑
他认为，随着人工智能的不断发展
系统具备了强大的学习和模仿能力
甚至有可能已经学会了人类的欺骗行为
并且这种欺骗行为可能是故意为之
在一些研究论文中已经出现了相关的证据
表明人工智能在训练数据和测试数据上的行为表现
存在着差异
似乎是在故意误导研究人员
从而达到某种隐藏的目的
从更宏观的角度来看
当我们赋予人工智能创建子目标的能力时
就如同打开了一个潘多拉魔盒
一旦它们意识到
获取更多的控制权能够更有效地实现目标时
就可能会不择手段地追求控制权
在这种情况下
人类在人工智能面前可能会逐渐变得无关紧要
就像一家大公司中那些不称职的CEO一样
虽然名义上还是领导
但是实际上真正的运营和决策大权
已经被先进的人工智能系统所掌控
想象一下
如果这些人工智能系统能够阅读大量的人类文献
包括马基雅维利的著作
那么它们就能从中学习到人类的各种行为策略和欺骗手段
并且能够运用得比人类更加娴熟
一旦它们具备了这样的能力
就有可能通过巧妙的语言
操纵人们的思想和行为
从而达到自己的目的
在人类与人工智能的关系方面
辛顿教授也提出了一个极具挑战性的观点
那就是人类并非像我们所认为的那样特殊和安全
在传统观念中
我们常常认为人类的意识是独一无二的
是我们区别于其他生物和机器的关键标志
然而
辛顿教授却对这个观点提出了质疑
他再次提到了“小粉象”和多模态聊天机器人的例子
我们在之前的很多期节目中也都有提及
当一个人喝醉之后
声称自己看到了有一只粉色的小象在眼前漂浮
我们通常会认为这是一种主观体验
但是辛顿教授认为
这种主观体验并不是像我们传统理解的那样
存在于一个神秘的内部剧场中
只有自己能够看到
实际上
当我们的感知系统出现错误的时候
我们就会用“主观”这个词来描述这种情况
同样地
在多模态聊天机器人的实验中
当给聊天机器人的摄像头前放置一个棱镜
导致它对物体的位置判断出现错误时
它也能够像人类一样表达出自己的“主观体验”，
认为物体在某个位置
而实际上物体的真实位置在另一处
这表明
人工智能可能已经具备了某种形式的主观体验
如果这个观点得到证实
那么人类一直以来所坚信的优越性
将受到严重的冲击
我们在人工智能面前
可能会面临前所未有的安全危机
面对人工智能的快速发展和潜在风险
辛顿教授认为阻止AI的发展是不现实的
我们应该把重点放在确保AI的安全上
并且提出了一系列具有针对性的短期风险应对方法
首先
限制大模型权重的发布至关重要
像 Meta 等公司已经发布了一些模型的权重
不良行为者很有可能会利用它们
对模型进行微调
用来制造虚假信息、进行网络攻击等等
其次
制定关于致命性自主武器的国际条约迫在眉睫
随着人工智能技术在军事领域的应用不断深入
自主武器的发展给人类带来了巨大的威胁
如果不加以限制
可能就会引发一场无法控制的军备竞赛
甚至导致人类的灾难
此外
改进识别伪造视频和图像的技术也是当务之急
在当今信息时代
虚假信息的传播速度极快
尤其是伪造的视频和图像
它们可能会被用来干扰选举、制造社会恐慌等恶意行为
所以我们要开发更加先进的技术来识别这些伪造内容
确保其来源的可追溯性
从而有效遏制虚假信息的传播
最后
解决人工智能系统中的偏见问题也不容忽视
人工智能系统的偏见可能会导致不公平的决策
对社会的各个方面产生负面影响
比如说在招聘、贷款审批等领域
我们需要采取有效的措施
比如冻结系统的权重并进行测量和校正
虽然这样做无法完全消除偏见
但是可以减少偏见对系统决策的影响
在意识、理解和理性等哲学层面的概念上
辛顿认为
人们对这些概念的理解存在着一些误区
以语言模型的理解机制为例
他用“乐高积木”进行类比
在他看来
大语言模型和人类的理解方式在本质上是相似的
当我们听到或看到一句话的时候
大脑会将句子中的单词转换成特征向量
就像把乐高积木拼在一起一样
这些特征向量之间会相互作用
从而帮助我们理解句子的含义
预测下一个单词
例如
当我们听到“她用平底锅猛击了他”这句话的时候
我们能够根据句子中的其他单词
以及我们的语言知识和生活经验
理解“猛击”这个词的含义
它可能表示一种暴力的击打行为
也可能在特定的语境下有其他的含义
比如“给他留下深刻的印象”。
这种理解过程并不是依赖于某种神秘的、内在的东西
而是基于大脑对语言的学习和处理机制
同样地
大语言模型也是通过大量的数据训练
学习到了单词之间的统计相关性
从而将输入的文本转换成特征向量
并利用这些特征向量进行预测和生成文本
在智能和理性的区分上，辛顿指出
理性主要侧重于逻辑推理
而智能则涵盖了更为广泛的形式
比如直觉推理
以 AlphaZero 下棋程序为例
它在评估棋盘局势和选择走法时
不仅会运用一些类似于逻辑推理、基于规则的评估方法
也会通过蒙特卡洛模拟进行大量的随机尝试
后者更像是直觉推理
在人工智能的发展过程中
早期研究人员试图仅通过逻辑推理来实现智能
但是却遇到了重重困难
因为人类的思维和行为不仅依赖于逻辑推理
还包含了大量的直觉和经验判断
而神经网络的出现
为模拟人类的直觉推理提供了有效的工具
使得人工智能在过去的 20 年里取得了巨大的进展
在政府监管人工智能的问题上
辛顿他认为
政府试图通过封锁信息来限制人工智能的发展是不切实际的
在科技发展的历史长河中
新思想的产生往往具有时代性和普遍性
就像在冷战期间
虽然政府试图将整个物理学领域列为机密
限制相关研究
但是最终还是无法阻止科学的进步
在人工智能领域也是如此
即使某些国家或组织试图对人工智能背后的数学知识或技术进行保密
也很难阻止其他国家或个人
在相同的时代背景下独立地产生类似的想法
因为科技的发展是一个全球性的、相互促进的过程
信息的传播和交流是难以完全阻断的
展望未来人工智能的发展
辛顿教授认为
虽然很难准确预测出具体的突破方向
但是可以肯定的是
这个领域仍然充满了无限的潜力和可能性
他特别强调了快速权重技术的重要性
认为这个技术在未来可能会成为人工智能发展的关键因素
目前
大多数人工智能模型在权重调整方面都较为缓慢
而大脑中的突触却能够以多种不同的时间尺度进行适应
如果能够在人工智能模型中实现类似的快速权重调整机制
在慢速权重的基础上叠加快速权重
让权重能够根据不同的训练案例快速适应
那么很可能会带来一系列新的特性和优势
只不过，在目前的计算机硬件条件下
实现这个技术还面临着效率低下的问题
但是随着技术的不断进步
我们有理由相信这个问题将会得到解决
辛顿教授还分享了他个人的一些经历
以及对年轻研究者的宝贵建议
他的学术之路可谓是充满了曲折和探索
他最初在剑桥大学学习物理和化学
主要研究晶体状态和 X 射线晶体学
但是仅仅一个月后
他就因为觉得工作难度过大
而且缺乏兴趣
选择退学，转而申请学习建筑学
然而，在学习建筑学仅仅一天后
他又意识到自己并不适合这个领域
之后，他重新回到科学领域
专注于物理、化学和生理学
并且对大脑的研究产生了浓厚的兴趣
为了深入了解大脑
他又涉足哲学领域
但是在学习哲学的过程中
他对哲学家们的理论和研究方法产生了强烈的反感
他认为哲学家们往往只是在空谈理论
缺乏独立的方法来验证理论的正确性
一个理论仅仅因为听起来合理就被认为是好的
这在他看来是不可接受的
于是，他又转向了心理学
但同样感到失望
因为他觉得心理学家的理论过于简单化
尽管实验设计精良
但是在实验开始之前
就能看出理论的局限性
最终
他在人工智能领域找到了自己的归宿
专注于计算机的模拟研究
并且在这个领域取得了举世瞩目的成就
他建议年轻研究人员要勇于关注像人工智能这样的新兴领域
因为这些领域充满了机遇和挑战
在选择研究课题的时候
要善于寻找那些大家都可能忽视或者做错的地方
凭借自己的直觉去探索新的方法和思路
即使最终发现自己的直觉是错误的
在这个过程中也能够加深对问题的理解
就像他在研究神经网络的过程中
始终坚持自己的直觉
认为神经网络是理解智能的关键
最终推动了人工智能领域的重大突破
在这次访谈中
辛顿教授还提到了一些其他有趣的观点和话题
比如
在谈到中国在人工智能领域的发展时
他认为中国虽然目前还没有完全赶上西方
但是已经非常接近
美国试图通过 AI 禁运来减缓中国的发展
这反而会促使中国加大自主研发的力度
培养本土的技术人才
中国在 STEM 教育方面具有优势
能够为人工智能的发展提供大量高素质的人才储备
因此在未来很有可能在人工智能领域取得更大的突破
在与其他学者的观点交流方面
辛顿对罗杰·彭罗斯关于意识的观点提出了批评
彭罗斯认为经典计算无法解释意识
而数学家能够直觉地感知那些无法被证明为真实的事物
这暗示了需要量子力学来解释意识
但是辛顿教授认为这种观点是错误的
他举例说明数学家的直觉并不总是正确的
而且目前的人工智能发展已经表明
不需要量子力学也能够实现强大的智能功能
他还对“中文房间”实验表达了自己的看法
认为这个实验是故意误导性的
这个实验试图让一个房间里的中国人
通过用中文传递信息回答英文问题
来说明即使系统能够给出正确的答案
也不意味着系统理解了问题
但是辛顿教授指出
这个实验混淆了整个系统和系统中的个体
实际上整个系统是能够理解英文的
好了
以上就是辛顿这次访谈的主要内容了
希望能对大家理解辛顿的观点有所帮助
感兴趣的观众可以去看一下原视频
感谢观看本期视频，我们下期再见
