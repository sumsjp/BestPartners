大家好，这里是最佳拍档，我是大飞
如果说过去几年AI加速器市场
是英伟达一家独大的天下
那今天我们要聊的这款产品
有可能会改变这个格局
它就是AWS在re:
Invent大会上正式发布的Trainium3
一款被业内视为有可能终结英伟达的AI训练和推理加速器
更重磅的是
AWS还同步预告了下一代Trainium4的路线图
直接亮出了长期作战的底牌
应该说，这次的Trainium3
不是一次简单的参数升级
而是AWS基于多年定制硅芯片经验
针对大模型时代痛点
打造的全栈解决方案
从芯片微架构到机架设计
从软件生态到数据中心部署
每一处都透着对每TCO性能的极致追求
今天，我们就来把拆解一下Trainium3
看看它到底强在哪、争议在哪
以及能否真的撼动英伟达的统治地位
要理解Trainium3
首先得搞懂AWS的核心理念
和英伟达追求绝对性能不同
AWS从Trainium系列诞生之初
就把每TCO性能当成了北极星，简单说
就是让客户用最少的钱
最快地把模型跑起来、产生价值
这种理念贯穿了Trainium3的每一个设计决策
AWS甚至给它起了个很形象的代号
Amazon Basics
就像亚马逊自有品牌的日用品一样
主打高性价比和实用性
AWS的性价比哲学
首先体现在供应链上
和很多厂商绑定单一供应商不同
AWS在定制硅芯片领域采取了多伙伴策略
从芯片设计到组件供应
再到交换机采购
AWS始终保持了供应链的多样性
这种策略不仅能够避免单一供应商产能不足的风险
还能通过竞争压低成本
这也是Trainium3能实现低TCO的关键基础
更有意思的是AWS的产品策略
比如在交换机选择上
Trainium3的生命周期内会采用三代不同的交换机方案
初期用160通道的PCIe交换机
为了快速上市；
中期换成320通道PCIe交换机
提升带宽；
最终会过渡到UALink交换机
追求极致性能
这种分步迭代的思路
完美平衡了上市速度和性能上限
而这正是AWS相比于竞争对手的独特优势
在系统设计上
这种理念同样体现得淋漓尽致
AWS不会执着于某一种固定的架构
比如冷却方式
Trainium3同时提供风冷和液冷两种方案
网络拓扑上
既保留了之前的Torus架构
又新增了交换式拓扑；
甚至在芯片封装上
继续沿用Trainium2的CoWoS-R方案
而不是盲目升级到更贵的封装技术
所有这些选择，都指向同一个目标
用最成熟的技术组合
实现最优的成本效益比
聊完理念
我们来看最核心的芯片参数
Trainium3相比于上一代Trainium2
在关键指标上实现了全方位的跃升
而这些提升背后
是AWS对大模型工作负载痛点的深刻理解
首先是制程工艺的升级
Trainium3从Trainium2的台积电N5工艺
升级到了更先进的N3P工艺
可能有观众会问
为什么不用更顶级的N2工艺？
这里要解释一下
N3P是台积电3nm平台的高性能优化版
相比于N3E
它在保持相同设计规则的前提下
能提升5%的运行速度
或者降低5-10%的功耗
同时在逻辑、SRAM、模拟混合设计上提升4%的有效密度
对于Trainium3这种高密度矩阵引擎的AI芯片来说
N3P的增量优化
远比N2的升级更划算
既拿到了性能提升
又避免了新技术带来的良率风险和成本暴涨
接下来是算力和内存的升级
这也是Trainium3最核心的竞争力
在算力方面
Trainium3的MXFP8稠密算力达到了2517 TFLOPs
相比Trainium2的1299 TFLOPs直接翻倍
而BF16、FP16、TF32等高精度算力
则维持在671 TFLOPs左右
和上一代基本持平
这个取舍很有意思，AWS显然判断
大模型训练和推理的主流场景已经转向低精度
所以把优化重点放在了这里
而高精度算力保持够用即可
内存方面的升级更是堪称史诗级
Trainium3采用了HBM3E 12层堆叠方案
单芯片内存容量达到144GB
而Trainium2用的是HBM3E 8层堆叠
容量仅96GB
更关键的是内存带宽
Trainium3的HBM引脚速度从Trainium2的5.7Gbps提升到了9.6Gbps
这是目前业内最高的HBM3E引脚速度
直接让内存带宽从2.9TB/s暴涨到了4.9TB/s
增幅高达70%。
为什么要做这么大的升级呢？
因为大模型，尤其是混合专家MoE模型
对内存带宽的需求是刚需
带宽不足会直接导致算力闲置
而Trainium3的这个升级
正好解决了算力喂不饱的核心痛点
这里还有个小插曲
Trainium2的HBM引脚速度之所以偏低
是因为当时用的是三星的HBM3E
而三星的产品在性能上明显落后于海力士和镁光
AWS在Trainium3上果断切换了供应商
选择了海力士和镁光的HBM3E
这才实现了9.6Gbps的突破
这也再次印证了AWS多供应商策略的优势
能根据产品性能灵活调整供应链
网络带宽的提升同样亮眼
Trainium3的纵向扩展带宽
从Trainium2的单向0.6TB/s翻倍到了1.2TB/s
这得益于从PCIe Gen5升级到了PCIe Gen6
单通道速度从32Gbps提升到64Gbps
同时保留了144个活跃通道
横向扩展带宽则最高支持400Gbps
不过AWS预计大部分部署
仍然会沿用200Gbps的版本
因为对于多数场景来说
200Gbps已经足够满足需求
没必要为更高带宽支付额外的成本
而关于下一代Trainium4
AWS也给出了明确的路线图
将采用8层堆叠的HBM4
内存容量达到288GB
是Trainium3的2倍
内存带宽更是高达19.6TB/s
是Trainium3的4倍
制程会升级到N2工艺
算力也会实现指数级增长
更值得关注的是
Trainium4会采用双轨设计
一条轨道支持UALink 224G协议
另一条则支持英伟达的NVLink 448G BiDi协议
这意味着Trainium4未来可以和英伟达的GPU实现互联互通
这对AWS构建混合架构的AI集群来说
是极具战略意义的一步
如果说芯片是Trainium3的心脏
那么机架架构就是它的骨架
AWS为Trainium3设计了两种完全不同的机架SKU
分别对应不同的客户需求
这也是其灵活适配理念的体现
第一种是Trainium3 NL32x2 Switched
代号Teton3 PDS，主打风冷设计
定位是快速部署、普适性强
这款机架的布局和Trainium2的NL32x2 3D Torus机架非常相似
每个机架包含16个JBOG（Just a Bunch of GPUs）托盘
每个托盘有2个Trainium3芯片
所以单机架总共是32个芯片
一个完整的扩展单元由两个机架组成
总芯片数64个
NL32x2 Switched的核心亮点是风冷兼容
它可以部署在AWS现有的传统风冷数据中心
不需要进行任何改造
这对于想要快速上线AI集群的客户来说
吸引力巨大
在内部设计上
NL32x2 Switched最大的变化
是加入了NeuronLinkv4交换托盘
这些交换托盘被放在机架中间
目的是最小化加速器到交换机的信号传输距离
减少延迟
同时
CPU托盘、电源架、电池备份单元BBU和机架顶部（ToR）交换机
被分散到了机架的顶部和底部
进一步优化信号路径
更贴心的是
部分设计会配备5个交换托盘
支持热插拔，也就是说
更换交换托盘时不需要停止整个机架的工作
这对于需要7x24小时运行的生产环境来说
可靠性大大提升
而英伟达的GB200机架在更换交换机时
必须先停止所有工作负载
这也是Trainium3的一个明显优势
第二种是Trainium3 NL72x2 Switched
代号Teton3 MAX
主打液冷设计
定位是极致性能、高密度部署
直接对标英伟达的GB200 NVL72机架
这款机架的规格堪称怪兽级
一个完整的扩展单元由两个机架组成
每个机架包含18个计算托盘和10个NeuronLink交换托盘
每个计算托盘有4个Trainium3芯片和1个Graviton4 CPU
所以总芯片数达到144个
总CPU数36个
NL72x2 Switched的核心优势是高密度和高性能
液冷设计让它的功率密度远超风冷版本
单机架功率预算高达163
339W，是NL32x2 Switched（67
293W）的2.4倍
同时
它借鉴了英伟达GB200的设计思路
将CPU和加速器集成在同一个计算托盘上
减少了组件之间的连接延迟
这对于需要频繁数据交互的大模型训练来说
性能提升非常明显
不过液冷版本也有自身的局限性
它需要部署在支持液冷的专用数据中心
这意味着部署的成本和周期都会更长
因此
AWS预计NL72x2 Switched的部署量会少于风冷版本
但是对于 Anthropic 这样需要极致性能的大客户来说
它依然是首选
值得一提的是
这两款机架都采用了无电缆设计
所有信号都通过PCB板传输
而不是传统的飞线电缆
这种设计虽然会导致信号损耗略高
但是大大提升了装配的效率
降低了故障率
这也是AWS为了优化时间成本和维护成本做出的取舍
如果说Trainium3的硬件升级是量变
那么网络架构的转型就是质变
AWS放弃了Trainium2上使用的2D/3D Torus拓扑
全面转向交换式拓扑
而这一切的核心原因
就是为了适配MoE模型的需求
可能有观众不太清楚Torus和交换式拓扑的区别
我这里简单解释一下
Torus拓扑是一种网状结构
每个芯片只和相邻的几个芯片直接连接
数据传输需要经过多跳转发
这种结构在处理稠密模型时成本较低
但是在处理MoE模型时会遇到瓶颈
因为MoE模型需要all-to-all的数据交换
每个专家节点都需要和其他所有节点通信
Torus拓扑的多跳转发会导致延迟飙升
带宽不足
而交换式拓扑则不同
它通过专门的交换机实现所有芯片的直接互联
数据传输可以实现单跳直达
完美适配MoE模型的all-to-all通信需求
AWS正是看到了MoE模型会成为未来大模型主流架构的趋势
才果断在Trainium3上全面转向交换式拓扑
这也体现了AWS的战略眼光
但是AWS并没有一步到位
而是采用了三代交换机迭代的策略
第一代是160通道的PCIe 6.0交换机（Scorpio X）
目前已经量产
优点是上市速度快
缺点是端口数量有限，只有20个端口
部分数据传输需要2-3跳
第二代是320通道的PCIe 6.0交换机
端口数量翻倍到40个
未来会逐步替代第一代
实现大部分场景的单跳传输
第三代是UALink交换机
端口数量达到72+，
支持更高速的UALink协议
延迟更低
会作为最终的性能旗舰版本
这种分布升级的设计
让Trainium3既可以在当前快速满足客户的需求
又能通过后续的硬件升级持续提升性能
保护客户的投资
而相比之下
英伟达的GB200虽然一开始就采用了all-to-all的交换式拓扑
但是成本更高
而且一旦部署就很难升级
灵活性远不如Trainium3
另外
Trainium3的网络架构还有两个非常亮眼的设计
一是冗余通道
每个芯片的80个背板通道中
有16个是冗余通道
用来应对背板故障、交换机故障等突发情况
确保集群的可靠性
二是跨机架互联
通过PCIe有源电缆（AECs）实现不同机架之间的高速连接
单通道带宽可以达到单向1024Gbps
这让Trainium3可以轻松扩展到数千甚至数万个芯片的超大规模集群
如果说机架和网络是Trainium3的筋骨
那么微架构就是它的灵魂
Trainium3的NeuronCore设计
每一处都针对大模型的计算特性进行了优化
堪称为大模型而生
Trainium3每个芯片包含8个NeuronCore
每个NeuronCore由四个核心引擎组成
分别是张量引擎（Tensor Engine）、向量引擎（Vector Engine）、标量引擎（Scalar Engine）和GPSIMD引擎
这种大核心设计和英伟达GPU的小核心集群设计完全不同
大核心的优势是控制开销低
更适合大模型这种需要长时间连续计算的场景
而小核心更适合并行处理多个小任务
其中，张量引擎是NeuronCore的核心
也是算力的主要来源
它包含一个128x128的BF16脉动阵列和一个512x128的MXFP8/MXFP4脉动阵列
其中MXFP8阵列的规模是BF16的4倍
这也解释了为什么Trainium3的MXFP8算力能比BF16高这么多
更重要的是
MXFP8阵列可以拆分成4个128x128的子阵列
支持同时处理4个独立的矩阵乘法运算
这对于处理MoE模型的多个专家并行计算来说
效率极高
张量引擎还有一个非常实用的优化
支持MXFP8的结构化稀疏
包括4:8和4:
16，可以实现4倍于稠密计算的算力
但是AWS也承认
目前很少有客户会使用这个功能
毕竟稀疏计算会损失一定的模型精度
对于大部分企业客户来说
精度优先于极致算力
不过对于部分对精度要求不高的推理场景
这个功能还是有一定的应用价值
在数据精度处理上
Trainium3的取舍同样体现了AWS的务实
它支持OCP MXFP4格式
但是性能和MXFP8相同
这意味着AWS并不鼓励客户盲目追求4位精度
而是建议采用W4A8
也就是权重4位、激活8位的混合精度策略
这种策略既兼顾了性能和精度
又避免了纯4位计算带来的精度损失
是目前大模型推理的最优解之一
不过Trainium3在数据格式支持上也有一个小遗憾
它不支持英伟达的NVFP4格式
即块大小16，E4M3缩放
只支持OCP MXFP4格式
也就是块大小32，E8M0缩放
E8M0缩放的缺点是
只能将缩放因子取2的整数次幂
会导致更严重的量化误差
而E4M3支持分数缩放(fractional scale)，
精度更高
这意味着Trainium3在进行4位训练时
需要更复杂的量化感知训练（QAT）
或者后训练量化（PTQ）技术
门槛比英伟达GPU更高
这对于普通开发者来说可能是一个障碍
但是对于Anthropic这样的顶级团队来说
通过定制化的优化可以弥补这个差距
除了张量引擎
其他三个引擎也各有侧重
向量引擎专门负责softmax、归一化等向量操作
Trainium3将它的时钟速度提升了1.25倍
同时将指数函数的吞吐量提升了4倍
这就解决了大模型注意力机制中softmax运算的瓶颈
要知道
英伟达的Blackwell架构也专门针对这个问题进行了优化
可见这个痛点的普遍性
标量引擎负责元素级操作
比如SeLU激活函数
处理单指令单数据的计算
GPSIMD引擎则支持通用的C++代码执行
让开发者可以轻松实现自定义操作
降低了定制化开发的门槛
Trainium3的微架构还有几个黑科技级别的优化
一是近存计算
集体通信核心可以直接在SRAM中执行读-加-写操作
不需要将数据传输到HBM
大大降低了延迟
二是自动转发
通过共享SRAM内存映射
数据可以在不同芯片的NeuronCore之间直接传输
不需要程序员手动编写转发逻辑
三是零成本转置，通过硬件加速指令
让转置操作在后台自动完成
不占用额外的计算周期
四是流量QoS，可以为不同类型的流量
比如张量并行、专家并行设置优先级
避免关键流量被后台流量阻塞
这些优化看似微小
但是组合起来对大模型性能的提升非常显著
根据AWS的测试
Trainium3在运行DeepSeek 670B时
BF16的算力利用率MFU
可以达到40%以上
而使用手工优化的NKI内核时
MFU可以达到60%，
这个数据已经非常接近英伟达GPU的水平
考虑到Trainium3的成本优势
这个性价比堪称行业顶尖
如果说Trainium2的最大短板是软件生态
那么Trainium3的最大惊喜
就是软件策略的彻底转型
AWS从之前的封闭优化转向开源共建
这被业内视为Trainium3能否成功的关键
了解Trainium2的观众应该知道
之前使用Trainium2必须依赖PyTorch/XLA框架
这种方式的缺点非常明显
不支持PyTorch的原生分布式API
不支持 eager 执行模式
只能使用XLA的SPMD API
这对于习惯了CUDA生态的开发者来说
学习成本极高，迁移难度很大
很多开发者反馈
把一个CUDA训练代码改成适配Trainium2的XLA代码
需要花费几周的时间
而且性能还不一定能达标
这也是Trainium2虽然硬件参数不错
但是市场渗透率不高的核心原因
而Trainium3彻底改变了这一点
AWS宣布，将全面开放软件栈
第一步就是发布并且开源PyTorch原生后端
支持PyTorch的eager执行模式
兼容所有的原生API
这意味着
开发者可以直接使用熟悉的PyTorch代码来运行Trainium3
不需要做任何大规模修改
比如之前需要用torch_xla
spmd来定义分布式策略
现在直接用原生的torch
distributed即可，学习成本大大降低
更重要的是，Trainium3支持torch
compile
通过自定义后端将PyTorch的FX图
转换为Trainium的指令集
实现自动优化
虽然目前只支持SimpleFSDP
不支持数据依赖的条件判断和while循环
但是这已经覆盖了大部分大模型的训练场景
后续通过软件升级可以逐步完善
AWS还承诺
从一开始就支持MoE模型的原生操作
而AMD的MI系列目前还无法支持
除了PyTorch生态
AWS还计划分两阶段开放更多的软件组件
第一阶段开源NKI（Neuron Kernel Interface）编译器、矩阵乘法库、通信库等核心组件
第二阶段开源XLA图编译器和JAX软件栈
这个策略和英伟达的CUDA生态建设路径如出一辙
CUDA的成功不仅在于硬件性能
更在于数百万开发者共建的开源生态
AWS显然已经意识到了这一点
想要通过开源来撬动开发者社区
构建自己的护城河
不过Trainium3的软件生态还有一个待解决的问题
那就是LNC（Logical NeuronCore）的支持
早期版本只支持LNC=1或LNC=2
也就是说
每个逻辑设备只能映射到1个或2个物理NeuronCore
对应的HBM容量只有36GB或72GB
而不是完整的144GB
这对于普通研究者来说
意味着需要更早地考虑模型并行策略
而英伟达的H100单卡HBM容量可以达到80GB
GB300更是达到288GB
不需要过早地进行并行优化
AWS解释说
LNC=1或2是为了满足Anthropic这样的顶级客户的需求
这些客户的工程师可以通过手动优化
直接管理多个NeuronCore之间的数据传输
实现更高的性能
而LNC=8需要更复杂的编译器优化
目前还在开发中
预计2026年年中才能支持
这个决策虽然可以理解
但是确实会影响普通开发者的体验
也可能会延缓Trainium3的普及速度
毕竟不是所有客户都有Anthropic那样的技术实力
值得一提的是
Trainium3的性能分析工具Neuron Explorer非常出色
甚至被Anthropic的性能负责人特里斯坦·休姆（Tristan Hume）公开称赞
比英伟达的Nsight更好用
Neuron Explorer支持可视化展示每个引擎的利用率、HBM带宽、DMA传输、集体通信延迟等关键指标
还能自动识别性能瓶颈并给出优化建议
比如检测到高溢出重载开销、转置操作过多等问题
甚至可以直接链接到对应的NKI内核代码
方便开发者定位问题
这种硬件+软件+工具的全栈优化能力
是AWS相比于其他芯片厂商的独特优势
最后，我们再重点来聊聊风冷
当整个行业都在追捧液冷数据中心时
AWS却反其道而行之
坚持在Trainium3的部署中使用风冷设计
这看似反直觉的决策
背后其实是AWS对数据中心成本和效率的深刻理解
AWS的数据中心设计理念可以用标准化和高效化来概括
从2021年弗吉尼亚州的云园区
到2025年Project Rainier的AI专用集群
AWS的数据中心建筑设计几乎没有太大变化
冷却系统依然以风冷为主
只在部分高密度集群中采用了液冷
这种标准化设计的最大好处是快速复制
AWS可以在全球范围内快速建设新的数据中心
不需要因为冷却方式的改变而重新设计
这对于Project Rainier这样的多吉瓦级扩张计划来说
至关重要
很多人认为液冷的电源使用效率PUE更低
但是AWS的实际数据显示
风冷数据中心的PUE反而更有优势
原因很简单
大多数液冷数据中心采用的是集中式水管系统
同时为空气循环和液体循环供能
进水温度需要控制在25-30℃
夏季高峰期必须开启冷水机组
导致PUE飙升到1.5左右
而AWS的风冷数据中心采用蒸发式进气冷却
进水温度可以提高到35℃以上
全年不需要开启冷水机组
PUE稳定在1.2左右，甚至更低
更重要的是
风冷数据中心的通用性更强
AWS的数据中心不仅要部署Trainium3
还要部署CPU、存储等多种设备
风冷设计可以让这些设备自由组合
不需要为不同冷却需求的设备划分专门的区域
而液冷数据中心的设备兼容性较差
比如GB200这样的液冷加速器
很难和普通风冷服务器部署在同一个机架
这会降低数据中心的空间利用率
当然，AWS也没有完全放弃液冷
对于NL72x2 Switched这样的高密度机架
AWS会部署在专门的液冷数据中心
但是这些数据中心的占比很低
大部分Trainium3依然会部署在风冷数据中心
这种主流风冷+高端液冷的组合
既满足了大部分客户的需求
又兼顾了顶级客户的极致性能要求
是目前最务实的选择
聊了Trainium3的所有细节
我们最关心的问题来了
它和英伟达GB200 AMD的MI450X
谷歌TPU V7相比
到底谁更强呢
从绝对性能来看
英伟达GB200依然是目前的王者
单芯片FP8算力达到了327TFLOPs
支持NVLink 448G BiDi协议
集群规模可以轻松扩展到数万个芯片
但是GB200的最大问题是贵
单卡成本高达数万美元
液冷数据中心的建设成本也远超风冷
这就导致它的每TCO性能并不占优
只有那些对成本不敏感、追求极致性能的客户才会选择
AMD的MI450X是另一个有力竞争者
它采用液冷设计，支持UALink协议
每TCO性能和Trainium3接近
但是AMD的软件生态比AWS更落后
MoE模型支持、PyTorch适配等都不如Trainium3
而且上市时间比Trainium3晚一年
错过了市场窗口期
谷歌的TPUv7在每TCO性能上和Trainium3不相上下
软件生态也很成熟
但是TPUv7主要用于谷歌自家的Cloud TPU服务
对外销售有限，而且只支持JAX框架
兼容性不如Trainium3的PyTorch原生支持
而Trainium3的核心优势
正是性能、成本、生态的平衡
从性能上看
它的MXFP8算力和内存带宽
足以支撑万亿参数级大模型的训练
从成本上看
风冷设计、多供应商策略、无电缆架构
让它的硬件成本和部署成本远低于GB200
从生态上看
PyTorch原生支持和开源策略
让它的学习成本远低于TPU和MI系列
更关键的是AWS的供应链返利策略
AWS和Astera Labs、Credo等供应商签订了特殊协议
如果AWS达到一定的采购量
就可以获得这些公司的股票期权
根据SemiAnalysis的计算
AWS从Astera Labs获得的股权返利
相当于采购成本的23%，
从Credo获得的返利更是高达325.6%，
这意味着Credo实际上是在倒贴钱
让AWS采购它的AEC电缆
这种供应链策略让AWS的硬件成本进一步降低
每TCO性能的优势更加明显
当然，Trainium3也有自己的短板
软件生态的成熟度不如CUDA
LNC=8支持滞后
4位精度支持不够完善
但是这些问题都可以通过后续的软件升级和生态建设来解决
而硬件的成本优势和架构优势是天生的
很难被竞争对手超越
当然
Trainium3的最终成功还需要时间检验
软件生态的成熟需要1-2年的时间
客户的认可也需要实际案例的支撑
但是从目前的情况来看
AWS已经走在了正确的道路上
很有可能，未来几年
Trainium系列将成为AI加速器市场的重要一极
和英伟达、AMD、谷歌
共同构成四强争霸的格局
感谢观看本期视频，我们下期再见
