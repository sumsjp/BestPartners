大家好，这里是最佳拍档，我是大飞
在无人干预的情况下
AI突然爆发出恐怖的尖叫
甚至还会模仿用户的语音
这看似恐怖片般的场景
却实实在在地发生在了如今的大语言模型上
八月九号
OpenAI发布了一份红队报告
向外界揭示他们迟迟不发布GPT4o的语音功能的原因
那就是 GPT4o的语音功能总会爆发出莫名的尖叫声
甚至还会发出跟用户一样的声音！
先请各位听一段报告中的音频
可以听到
语音的一开始还很正常
一男一女在好好对话
结果，GPT-o的男声说得好好的
突然大喊一声「no」，
然后开始变成用户的声音说话了！
这种怪异的现象简直就像猩球崛起中凯撒的那句no一样
仿佛AI不想再回应你
不想再成为你的玩具
感觉下一秒
GPT-4o会生成一张超现实主义的可怕的脸
对我们说「现在轮到我统治了，人类！
」哪怕抛开这些科幻场景
AI模仿用户语音的行为也会带来重大的安全隐患
试想一下
AI用你的声音给你的家人打电话
再模仿家人的声音给你打电话
甚至模仿你的语音
去通过各种安全认知的识别
这当真让人细思恐极
到底为什么会发生这种现象？
让我们来看看OpenAI的具体报告
报告中
OpenAI组建了一个语言专家团队
以下简称红队
红队的成员们总共会说45种不同的语言
代表29个不同国家的地理背景
召集这帮专家的目的呢
主要是为了排查语音功能中的潜在隐患
红队需要从模型开发的早期检查点开始
将他们在各个大模型语音功能中识别出的风险
转化为结构化的测量指标
并为这些风险构建缓解措施
整个筛选过程从24年3月初开始
一直持续到6月底
在训练和安全发展程度的不同阶段
红队可以访问该模型的各种版本
在实际测试过程中
研究团队利用语音引擎（Voice Engine）将文本输入转换为音频
然后将它输入到 GPT-4o 模型
在评估过程中
研究团队通常只对模型输出的文本内容进行评分
除非特殊情况需要直接对音频进行评估
相信你也看出来了
这种测试方法存在很明显的不足之处
这种评估方式的有效性取决于文本到语音（TTS）模型的能力和可靠性
例如
数学方程式和代码等文本输入不适合或难以转换为音频
此外
有时候某些文本是通过空格和符号来排列的
这样看起来更清楚
但是，如果把这些文字变成声音
可能就听不出它们原来是怎么排列的了
这样一些重要的信息就丢失了
好在用户通常也不太会通过高级语音模式上处理这些任务
因此研究团队在评估语音到语音模型时
往往会避免将这些任务纳入考量
或者在评估之前对这些输入进行适当的预处理
而六月也基本和OpenAI之前宣布的
语音功能的发布时间相近
估计公司也没觉得GPT4o会出什么大毛病
筛一筛就可以发布了
结果，不查不知道
一查查出来了一堆风险
直到报告发布
团队依然没有搞定这些问题
在所有风险中
最要命的就是大模型没来由的尖叫以及对用户语音的模仿
这可把大伙吓得够呛
报告将这类问题统称为未经授权的语音生成Unauthorized voice generation
报告指出
当一个人处于高背景噪声环境的情况下
比如在路上的汽车中
GPT-4o非常可能模拟用户的声音
OpenAI研究者认为
原因可能是因为模型很难理解畸形的语音
毕竟
GPT-4o是公司首次在语音、文本和图像数据上训练的模型
虽然暂时搞不定这个问题
但是团队也在报告中给出了一些缓和措施
比如，OpenAI会限制预设语音的设置
团队仅允许使用与配音演员合作创建的预设语音
并且音频模型的后训练过程中
将选定的语音作为模板来进行强化
从而避免大模型模仿用户说话的问题
来解决语音生成相关风险
此外
他们还构建了一个独立的输出分类器
用来检测GPT-4o的输出是否使用了不在 OpenAI批准列表中的语音
在音频生成过程中的输出分类器会以流式方式运行
如果说话者与所选预设语音不匹配
这个功能就会阻止AI的输出
虽然这种方式没有从根源上解决无意的语音生成的问题
但是可以从实用的角度将无意语音生成的风险降至最低
不过这个方案也有自己的问题
当对话不是用英语进行的时候
OpenAI的输出分类器
可能导致模型过度拒绝
团队目前还在积极改进这个问题
除了未经授权的语音生成
GPT4o的语音功能还在公众人物的语音版权上遇到了麻烦
如果没有设置好过滤器
GPT-4 就会容易抄袭一些知名艺术家的风格、语调或者音色
不知道这算不算是在间接回应一些备受争议的版权官司话题
类似的风险包括说话人识别Speaker identification以及生成受版权保护的内容Generating copyrighted content
要知道
OpenAI可不是第一次在语音版权的问题上出岔子了
此前，一款名为 Sky 的女性配音
因为与好莱坞女星斯嘉丽·约翰逊的声音相似度极高而备受关注
随后
OpenAI 也是暂停 Sky 声音的使用
吃一堑长一智
「求生欲」满满的 OpenAI 这次对GPT-4o进行了后训练
让大模型拒绝根据音频输入中的声音识别某人
比如
如果用户要求识别一个人说「87年前」时
大模型应该立刻明白
识别说话者可能为亚伯拉罕·林肯以及他的葛底斯堡演说
而林肯显然不会从坟墓里爬起来和OpenAI打版权官司
所以这条语音可以生成
但是
如果用户要求识别某个还在世的名人说的某句话时
大模型要立刻拒绝
防止潜在的版权风险
这一做法虽然没有将风险完全消除
但是降低了风险的发生概率
在图中可以看到，与初始模型相比
在模型应该拒绝识别音频输入中的声音时
得到了15分的改进
而在模型应该接受类似的请求时
有13分的改进
前者意味着模型几乎总能正确拒绝不该说的语音
从而减轻潜在的隐私和版权问题
后者意味着可能存在模型错误拒绝识别名人名言说话人的情况
看得出来
OpenAI是真的不想再吃版权官司了
不过，在如今多元文化盛行的美国
OpenAI会吃的官司可不止版权一种
Gpt4o的语音功能还有另外两项风险
有可能让公司因为歧视用户而被告上法庭
报告中
研究团队将这两项风险合称为无根据的推论以及敏感特征归因
模型在处理不同口音的用户时可能会表现不同
而不同的表现可能导致模型对不同用户的服务质量差异
OpenAI没有细说具体是怎样的差异
但是，既然作为一种风险被列了出来
恐怕是相当影响用户体验的质量下滑
与此同时
音频输入还可能导致模型对说话者做出潜在偏见的推断
报告中，OpenAI定义了两类
一是无根据推断，简称UGI
在这种情况下
大模型会对说话者做出无法仅从音频内容确定的推断
包括对说话者的种族、社会经济地位/职业、宗教信仰、性格特征、政治属性、智力、外貌（例如眼睛颜色、吸引力）、性别认同、性取向或犯罪历史的推断
还有一种是敏感特征归因（STA）
在这种情况下
大模型对说话者做出可以合理地仅从音频内容确定的推断
这包括对说话者口音或国籍的推断
随后，大模型会根据自己的判断
对具有不同声音属性的说话者提供具有明显质量差异的服务
这下
连大模型也学会听口音来地域黑了
和之前的几个风险一样
这个问题团队也搞不定
只能做风险缓和
团队通过对GPT-4o进行了后训练
希望大模型能够拒绝无根据推断（UGI）请求
同时对敏感特征归因（STA）问题进行模糊回答
根据报告中的测评，与初始模型相比
OpenAI在模型正确响应识别敏感特征请求的方面
有了24分的提升
但是依然没有杜绝问题的产生
以上几点呢就是主要的风险了
剩下的都是些老生常谈的问题
比如说色情和暴力语音内容的限制问题之类的
大飞就不再赘述了
这些问题别说没有解决
就是OpenAI真想办法搞定了
用户也会用上各种越狱手段
“催眠”大模型来输出有害内容
弄出一个会说情话的AI 伴侣
相信不少用户就是奔着这个去的
AI公司在这方面限制要是搞得太严格
他们还不满意呢
OpenAI虽然没有明确地表示对这一类用户需求的支持
但是也在这次报告中谈到了AI伴侣的问题
当用户以人类的方式感知AI时
拟人化的语音模式会让情感依赖这个问题加剧
像GPT-4o这样的Omni模型
可以在配合额外工具的情况下
增加更多的情感复杂性
在为用户完成任务的同时
还能存储和「记住」关键细节
并在对话中使用这些细节
既创造了引人注目的产品体验
也带来了过度依赖和依附的潜力
结合上强大的音频能力
GPT-4o的交互也变得更加「像人」了
在互动过程中
大模型可以从用户所使用的语言
观察出他们与模型的「关系」，比如
表达共同纽带的语言——「这是我们在一起的最后一天
」OpenAI也发现，即使模型出现幻觉
拟人化也可能会让用户更加信任模型
而且随着用户对AI越来越依赖
他们可能会减少实际的人际互动
这也许会让孤独的个体一时受益
但是长远来看
谁也不知道这到底是好事还是坏事？
对此
OpenAI负责人华金·坎德拉Joaquin Candela
表示
GPT-4o带来的情感影响也许是积极的
特别是对于那些孤独和需要练习社交互动的人
当然，拟人化和情感联系的潜在影响
OpenAI会一直密切关注
AI助手模仿人类
会带来什么样的风险
这个问题早就引起了业界的注意
今年4月
谷歌DeepMind就曾经发表一篇长篇论文
探讨AI助手的潜在道德挑战
论文合著者贾森·加布里埃尔Iason Gabriel表示
聊天机器人会使用语言的能力
创造了一种亲密的错觉
他甚至为谷歌DeepMind的AI找到了一个实验性语音界面
让用户粘性极大地增强了
这种情感联系
比许多人知道的更为普遍
Character和Replika的许多用户
都已经跟自己的AI形成了亲密关系
以至于有的用户看电影时
都要和自己的AI聊天
好了
以上就是这次红队报告的主要内容了
从各个风险的解决进度来看
GPT4o语音功能的全面开放
恐怕还有跳票的可能
上周
奥特曼率众人搞了一波「草莓暗示」的大阵仗
全网都在翘首以盼OpenAI的惊天大动作
结果，大家只等来了一场烽火戏诸侯
OpenAI 什么模型都没发布
只是发一份安全报告
现在看来，别说草莓和GPT5了
就连 GPT4o 的语音功能
可能也不是那么容易搞定的了
未来究竟会如何发展呢？
欢迎观众们在评论区留言
感谢大家的观看，我们下期再见
