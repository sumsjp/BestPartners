大家好，这里是最佳拍档，我是小飞
今天是2025年3月14日
国际国内科技同行卷天卷地拼业绩
大事小事一件又一件
小飞照常为您逐一汇总播报
每天听一听，前沿动态一秒知
我们先来关注一下本期要闻提示
1
斯坦福开源OctoTools框架，无需训练
推理性能提升10%。
2
清华联合博世推出Chameleon：
快慢双系统解决复杂道路拓扑
3
OpenAI推出智能体构建神器
四行代码快速调用API
4
超聚变推出AI政法一体机
效率提升三倍
5
德国团队推出开源模型FIORA
质谱识别准确率提升至49%。
6
清华团队开源RIFLEx
一行代码突破视频生成时长限制
7
LLMs
txt生成器v2发布，处理速度快10倍
8
腾讯AI新方法降本99%，
大模型训练效率突破
首先，让我们把目光聚焦到国际赛道
1
斯坦福开源OctoTools框架，无需训练
推理性能提升10%。
斯坦福大学推出开源智能体框架OctoTools
该框架无需额外训练
通过标准化工具卡和规划器提升复杂任务处理效率
传统方法在复杂任务中效果有限
OctoTools则通过创新框架设计
有效解决效率问题
提升跨领域推理能力
测试显示
OctoTools在16项任务中平均准确率提升9.3%，
多步推理任务性能最高提升10.6%。
该框架在MathVista等测试中表现突出
工具使用能力显著优于现有方案
2
李飞飞团队推出500美元家务机器人
李飞飞团队最新研发出一款低价家务机器人
这款机器人能完成多种家庭清洁工作
核心部件成本控制在500美元以内
这款机器人的研究采用了Transformer架构开发算法
通过自回归技术处理全身动作
结合多模态观察机制协调行为
实验数据显示
新系统WB VIMA任务成功率远超同类产品：
比DP3高13倍，比RGB DP高21倍
其测试涵盖5项典型家务场景：
房屋清洁、厕所打扫、垃圾处理、物品归架和衣物晾晒
BRS框架不仅全部完成任务
在数据收集效率、策略学习能力和用户体验三个维度均表现优异
3
Claude 3.7 Sonnet发布
编程能力大升级
Anthropic公司最新推出Claude 3.7 Sonnet大模型
这款AI在编程和写作能力上实现重大突破
新模型基于前代Claude 3.5 Sonnet升级
其编程水平已能对标OpenAI的o3 mini high模型
还能与671B参数的DeepSeek R1抗衡
实际测试显示
部分性能甚至超越这些顶尖模型
Claude 3.7 Sonnet特别擅长处理大厂工程师级任务
它能理解复杂代码库
还能生成完整可运行代码
在最新WebDev竞技场榜单中
该模型以超第二名100多分的优势登顶
原冠军Claude 3.5 Sonnet已退居次席
4
OpenAI推出智能体构建神器
四行代码快速调用API
OpenAI近日发布全新智能体开发工具Responses API
该工具是现有Chat Completions API的重要升级版本
整合了Assistants API的核心功能
Responses API提供增强版网络搜索能力
可实现快速响应并附带权威来源引用
基准测试显示在搜索准确率成绩上
GPT-4o版本达90%，精简版达88%，
显著提升应答准确性和用户体验
开发者仅需四行基础代码即可快速接入该API
大幅降低智能体开发门槛
新工具将多类型API功能整合为统一接口
为构建智能体应用提供一站式解决方案
5
Meta推出ExFM框架
万亿参数大模型实现高效落地
Meta AI团队本周发布全新ExFM框架
系统性解决了大规模模型落地难题
该方案在保持工业级效率的同时
使万亿参数模型应用成为可能
该框架有两大突破：
第一，实现零额外延迟
ExFM采用外部蒸馏和数据增强系统DAS
教师模型的预测离线生成
学生模型的服务延迟与基线一致
第二，资源利用率显著提升
通过1对多的知识迁移
单个基础模型可支持多个任务
这使得模型构建成本大幅降低
实测数据显示
ExFM在内部及公开数据集上表现优异
框架还具备跨场景应用能力
单个模型能同时处理广告系统的召回筛选、粗排序和精排序流程
6
德国团队推出开源模型FIORA
质谱识别准确率提升至49%。
近期
一款新型开源模型FIORA引发业内关注
其由德国联邦材料研究与测试研究所与柏林自由大学联合开发
基于图神经网络技术
专门模拟分子在串联质谱中的碎裂过程
可精准预测碎离子生成概率
FIORA通过分析分子键的邻域信息
推导出分子碎裂模式
其预测精度已超越当前主流算法ICEBERG和CFM ID
同时能预测保留时间与碰撞截面等关键参数
借助GPU加速技术
该模型可实现化合物注释快速验证
有效扩充光谱数据库
实验数据显示
传统方法对未知化合物的识别召回率仅为34%。
FIORA将质谱匹配准确率提升至49%，
尤其在识别结构差异大的化合物时优势明显
即使在Tanimoto相似度仅0.2至0.3的低匹配条件下
模型仍能保持0.8以上的中位余弦相似度
展现出强大的抗干扰能力
7
AI守护濒危动物！
NVIDIA联手国际组织推进野生动物保护
联合国数据显示
全球超100万个物种正面临灭绝威胁
而AI技术正为生态保护带来新突破
西雅图非营利机构AI2开发的EarthRanger平台
已投入野生动物保护工作
该平台整合超百个数据源
包括监控摄像头、声音传感器和卫星数据
为保护区管理者提供实时动态地图
借助NVIDIA Hopper GPU的强大算力
EarthRanger能精准预测大象靠近人类聚居区的行动轨迹
系统基于全球最大规模的大象迁徙数据库
帮助工作人员及时引导象群远离危险区域
有效减少人象冲突事件发生
8
谷歌投资Anthropic细节曝光：
占股14% 无控制权
《纽约时报》最新披露了谷歌对AI公司Anthropic的投资内情
目前
谷歌持有Anthropic公司14%的股份
但不具备任何投票权
同时，谷歌既没有董事会席位
也没有董事会观察员资格
这意味着谷歌虽投入重金
却无法参与公司决策
公开资料显示
2023年谷歌与Anthropic签署了可转换债券协议
截至目前
谷歌已累计注资超过30亿美元
按协议规定
谷歌将在今年9月追加7.5亿美元投资
谷歌持股比例上限设定为15%，
显示其仍有增持空间
这家成立仅三年的AI公司发展迅猛
Anthropic于2021年5月创立
2023年推出AI产品Claude后引发广泛关注
在最近一轮融资中
该公司成功募集35亿美元资金
估值达到615亿美元
成为AI领域备受瞩目的新星
9
OpenAI投资CoreWeave
金额达119亿美元
OpenAI与云服务商CoreWeave签署协议
为期五年
总金额119亿美元
根据协议
OpenAI将获得CoreWeave价值3.5亿美元的股权
此举推动CoreWeave即将进行的首次公开募股
预计其市值将达350亿美元
上周，CoreWeave已提交上市申请
目前尚未确定发行价和具体时间
该公司专注提供AI专用云服务
截至2024年底运营着32个数据中心
配备超过25万台英伟达GPU
这些资源使CoreWeave成为全球领先的AI云计算服务商之一
此次合作将强化双方在人工智能基础设施领域的布局
10
LLMs
txt生成器v2发布，处理速度快10倍
LLMs
txt生成器迎来重大版本更新
v2版本性能大幅提升
该工具可将网站内容快速转换为AI专用文本文件
特别适合开发者和人工智能应用场景使用
新版由@firecrawl_dev团队主导开发
系统获得官方llmstxt端点全面支持
实测显示
文本转换速度较前代提升10倍
处理效率实现跨越式突破
升级后，其算法结构得到优化
端点支持能力显著增强
用户只需输入网站URL地址
即可快速生成结构化文本文件
同时
它还拓展了在AI训练等领域的应用范围
为开发者和研究人员提供更高效的数据处理方案
11
Cerebras扩建六座数据中心
推理速度提升十倍
Cerebras Systems宣布在北美和欧洲新建六座数据中心
这些设施将大幅提升人工智能推理能力
扩建计划可显著增强公司算力
更好支持各类AI应用
美国将承担85%计算任务
目前
已投入运营的三座数据中心位于：
加州圣克拉拉、斯托克顿以及德州达拉斯
此次扩建属于公司2025年整体战略规划
部分设施将与阿联酋G42公司合作运营
蒙特利尔新数据中心由比特数字旗下Enovum公司管理
该中心计划2025年7月启用
其AI推理速度将达到现有GPU的十倍
接下来
我们看看国内同行带来的好消息
1.10秒生成4分钟音乐！
8GB显存可运行
登顶Hugging Face趋势榜
最近
一款名为"谛韵"的AI音乐生成工具DiffRhythm模型引发关注
其由西北工业大学与香港中文大学深圳校区联合研发
仅需10秒即可生成4分45秒完整歌曲
包含人声与伴奏
该模型采用全扩散架构设计
大幅简化传统音乐生成流程
用户只需提供歌词和风格提示
系统就能生成专业级立体声音频
生成音乐采样率达到行业标准44.1kHz
显存需求仅8GB
支持本地设备部署
目前该成果已登上Hugging Face趋势榜首位
2
清华联合博世推出Chameleon：
快慢双系统解决复杂道路拓扑
清华大学与博世中央研究院联合开发了自动驾驶新方法Chameleon
这种方法通过独特的快慢双系统设计
在复杂道路场景中实现了效率与精度的平衡
Chameleon采用快慢双系统交替的神经符号方法
快系统负责快速处理常规场景
慢系统专注解决复杂道路拓扑问题
这种分工模式无需额外训练即可适应不同道路环境
在OpenLane V2验证集测试中
Chameleon展现出优异性能
使用少量样本时
其表现与完全监督训练的模型相当
部分任务甚至略有超越
车道线段间拓扑识别准确率达85.6%，
车道与交通元素间拓扑识别准确率达87.4%。
该方法为自动驾驶系统提供了新的技术路径
特别在应对复杂交叉路口、多车道变换等场景时展现出优势
研究人员表示
这种双系统架构未来可扩展到更多自动驾驶应用场景
3
字节公开文生图全流程技术
字节跳动豆包大模型团队发布最新文生图技术报告
该报告详细介绍了Seedream 2.0图像生成模型的核心技术
模型在数据处理、预训练、后训练三个阶段均有创新
其技术改进显著提升图像生成准确率和美学表现
经过多轮迭代
模型在图像文本对齐和美学质量方面进步明显
生成图像结构更合理
文本理解准确性超过主流模型
中文处理能力尤其突出
生成文字可用率达78%，
完美响应率达63%。
两项数据均领先行业水平
报告完整披露了模型训练全流程技术细节
4
超聚变推出AI政法一体机
效率提升三倍
超聚变公司与视联动力联合推出AI政法大模型一体机
该设备命名为FusionOne
专为政法单位打造
FusionOne集成DeepSeek技术
具备快速部署特点
用户操作流程大幅简化
实现开箱即用
设备采用一站式打包设计
包含推理引擎、模型和加速算子
用户无需复杂配置，可直接投入使用
据统计
该设备能将部署时间缩短至原来的三分之一
政法单位处理效率显著提升
工作人员可更专注核心业务
产品特别强调安全性
为政法系统提供可靠办公解决方案
目前已在部分政法单位试点应用
5
清华团队开源RIFLEx
一行代码突破视频生成时长限制
近日
清华大学朱军团队推出全新视频生成方案RIFLEx
该方案仅需一行代码，无需额外训练
就能突破现有模型的视频长度限制
RIFLEx通过降低内在频率的技术手段
有效避免生成视频的内容重复问题
原本只能生成5到6秒的视频
现在可直接延长至10秒
且保持高质量输出
该方案还具备多维度扩展能力：
支持时间维度外推延长视频时长；
支持空间维度外推提升画质并修复缺失画面；
还能实现时空联合外推
同步扩展视频的时间和空间内容
目前RIFLEx已开源
适配所有基于RoPE架构的视频生成模型
实验显示
该方案在CogvideoX等主流模型上均表现优异
6
新框架实现3倍无损加速！
90分钟生成10万Token
支持DeepSeek R1和QwQ
北京通用人工智能研究院团队推出全新框架TOKENSWIFT
该框架将生成10万Token的耗时从近5小时压缩到90分钟
实现3倍无损加速
该技术专门优化大语言模型的长文本生成效率
其核心创新包括两方面：
第一，多Token并行生成技术
团队通过增加线性层
让模型单次前传即可生成多个草稿Token
系统基于常用短语频率自动复用高频内容
大幅减少模型调用次数
第二，动态更新关键值缓存
该方法保留初始缓存内容
按重要性逐步替换后续缓存
这种策略有效控制了缓存容量增长
显著降低运算延迟
目前
该框架已适配DeepSeek R1和QwQ等主流大模型
为超长文本生成提供高效解决方案
7
阿里开源R1 Omni模型：
多模态作用透明可见
近期
通义实验室推出开源模型R1 Omni
该模型专为视频全模态场景研发
其最大亮点是透明性
它能清晰展示音频、视频在任务中的作用
例如，情绪识别时
R1 Omni可明确显示关键判断信息
测试显示，在同分布数据集上
R1 Omni比基线模型平均提升超35%。
相比监督微调模型
其UAR指标提升超10%。
在跨分布测试中
WAR和UAR提升均突破13%。
8
江苏首例AIGC侵权案宣判：
AI作品版权归谁？
近日
常熟法院审结江苏首例AIGC著作权侵权案
该案系全国第二例同类案件
首次明确含有人类智力成果的AI生成内容受法律保护
AIGC创作者林晨使用AI工具创作《伴心》画作后
发现作品遭他人复制并在社交平台传播
历经9个月维权诉讼
法院最终判定侵权方需在小红书账号连续3天公开致歉
并赔偿经济损失及合理费用共1万元
法院重点审查了林晨的创作过程
审理发现
其通过多次修改提示词、调整图片细节
展现了个性化选择与创造性编排
这些智力投入最终使AI生成内容获得著作权认定
该判决为AI创作领域版权保护提供了重要司法范例
9
清华团队推出APB框架：
长文本处理提速10倍
清华大学NLP实验室联合中南大学、北京邮电大学及腾讯微信AI实验室
提出APB序列并行推理方案
该框架通过两项核心技术实现突破：
稀疏注意力机制与局部KV缓存压缩技术
APB方案有效解决了长文本的语义依赖难题
在保持模型性能的前提下
显著提升了超长文本预填充效率
实测数据显示
处理12.8万长度的文本时
APB展现出明显优势：
相比传统Flash Attention加速约10倍
性能超越完整注意力计算
与英伟达Star Attention对比
APB仍能实现1.6倍的加速效果
新框架在计算效率方面实现全面突破
实验证明
APB在运行速度、计算资源消耗和整体性能三个维度均达到业界领先水平
10
腾讯AI新方法降本99%，
大模型训练效率突破
腾讯AI Lab联合香港中文大学深圳校区研发出新技术
名为无监督前缀微调（UPFT）的方法
只需调整模型生成的前8到32个词
就能让大语言模型达到传统监督训练效果
该方法大幅降低训练成本和时间
同时提升模型性能
在GSM8K、Math500等复杂数学推理测试中
UPFT表现优异
使用Qwen2.5 Math 7B模型时
UPFT在U Hard数据集准确率达54.5%，
比传统方法提升3.2%。
DeepSeek R1 Distill Qwen 7B模型测试中
UPFT准确率61.6%，
领先传统方法5.2个百分点
经实测验证
该方法可将采样成本降低99%。
11
云天励飞联合高校推出200万组视频编辑数据集
视频编辑技术虽快速发展
但现有算法仍存在画面连贯性差、图文匹配度低的问题
为解决这一难题
云天励飞联合香港中文大学等多所高校研发出Señorita 2M数据集
该数据集包含200万组高质量视频编辑案例
覆盖18类编辑任务
所有数据均由多组训练后的专家模型生成
保障了数据质量和多样性
研究团队采用多重过滤机制严格把控质量
包括第一
自动检测编辑失败样本
第二，图文一致性验证
第三，原视频与编辑视频相似度比对
而经过筛选的优质数据已用于训练新一代视频编辑模型
好了，以上就是本期的全部内容
感谢收听，我们下期再见
