大家好，这里是最佳拍档，我是大飞
从春节到现在
DeepSeek的热度还在持续攀升
伴随而来的还有很多误解和争议
有人说它是"国货之光"，
也有人说它"不过是抄袭OpenAI"。
今天这期视频我们就来澄清关于DeepSeek的五大误解
让大家能够更加真实、客观的来认识它
网上关于DeepSeek的误解与争议
其实主要集中在五个方面
一、DeepSeek到底是不是底层创新？
到底有没有蒸馏ChatGPT？
二、DeepSeek的成本
真的只有550万美元吗？
三、如果DeepSeek真的那么高效
那么全球各大AI巨头的巨额投入
是不是都打了水漂？
四、DeepSeek是否采用了PTX编程
能否真的能够绕开对英伟达CUDA的依赖？
五、DeepSeek虽然全球爆火
但是是否会因为合规、地缘政治等问题被国外禁用？
我们先说第一个误解
也是普遍争议最大的
DeepSeek到底是不是颠覆式创新
有没有蒸馏、甚至抄袭？
显然
从现在所有已经了解的信息来看
包括国内外AI行业巨头和专家们的看法
DeepSeek对行业发展的促进价值是值得肯定的
但是说它颠覆还为时尚早
从一些专业的测评来看
在很多关键问题上
DeepSeek给出的答案并没有超越ChatGPT
比如有人测试
模拟典型的小球在封闭空间的弹跳代码
DeepSeek编写出来的程序表现和o3-mini相比
从物理学的遵循度角度来看
还是有差距的
所以，我认为对于DeepSeek
我们既不要过度神话它
也不要无脑贬低它
关于DeepSeek的技术成就
目前存在两种极端观点
一种把它的技术突破
称为"颠覆性革命"，
另一种则认为这不过是对国外模型的模仿
甚至还有猜测
它是通过蒸馏OpenAI的模型获得的
因为微软对媒体说
自己有DeepSeek使用了ChatGPT数据的证据
所以一些人也借题发挥
把DeepSeek贬低的一钱不值
事实上，这两种观点都过于片面
更准确地说
DeepSeek的突破是一次面向产业痛点的工程范式升级
为AI推理开辟了一条新的路径
从技术角度来看
它主要做了三个层面的创新
首先通过训练架构瘦身
比如GRPO算法通过省去传统强化学习中必须的Critic模型
将复杂的算法简化为可落地执行的工程方案；
第二，采用了更为简单的评估标准
比如在代码生成场景中
直接使用编译结果和单元测试的通过率
来替代人工评分
这种基于确定性的规则体系
有效打破了AI训练中的主观偏差难题；
最后
在数据策略上找到了一个精妙的平衡点
通过自主进化的Zero模式
与只需要数千条人工标注数据的R1模式结合
既保留了模型的自主进化能力
又保障了人类的可解释性
但是
这些改进并没有突破深度学习的理论边界
也没有彻底颠覆OpenAI o1和o3等头部模型的技术范式
而是通过系统级的优化
解决了产业的部分痛点
值得称赞的是
DeepSeek完全开源并详细记录了这些创新点
让全世界都能借助这些进展
来改进自己的AI模型训练
我们再来说蒸馏的问题
前几天专门在一期介绍模型压缩的视频中
介绍了蒸馏
传统意义上的蒸馏
指的是对token概率
也就是logits的训练
而ChatGPT并没有开放这类数据
所以基本上不可能去蒸馏ChatGPT
这种说法本身就是错误的
因此，从技术角度看
DeepSeek本来就不应该受到这样的质疑
由于OpenAI o1相关的思维链推理过程 也从来没有公开过
所以单纯依靠蒸馏ChatGPT
根本就无法实现如今的成果
不过，DeepSeek的训练中
可能确实也部分利用了一些蒸馏的语料信息
或者做了少许的蒸馏验证
但是这个对它整个模型的质量和价值影响
应该说是很低的
在现实中
基于对领先模型的蒸馏来验证优化自己的模型
其实是很多大模型团队的一个常规操作
但是毕竟这需要通过API
能获得的信息其实非常有限
不太可能起到决定性的影响因素
况且相对于海量的互联网数据来说
通过API调用领先大模型能获得的语料
可以说是杯水车薪
顶多也就能用在对策略的验证分析
而无法直接用作大规模的训练
换个角度来说
如果非说DeepSeek蒸馏了ChatGPT
那么又怎么说ChatGPT爬了大量的互联网数据供自己所用呢？
有人可能会说OpenAI的服务协议里写了怎么怎么样
但是很多网站也写了不让爬
不一样被爬了么？
所有大模型都需要从互联网获得语料训练的
而领先的大模型也在不断为互联网贡献语料
换句话说
每个领先的大模型其实都摆脱不了被采集、被蒸馏的宿命
所以真没必要把这个看的那么重要
真这样未免也显得格局太小
况且也很难有实证
对于AI这个赛道
最终只能是大家你中有我
我中有你，共同奔向AGI
我们再来说第二个误解
DeepSeek的成本真的只有550万美元么？
应该说，550万美元成本
这个结论既正确也错误
因为没有说清楚是什么成本
要想说清楚
首先我们有必要理解这个数字是从何而来
这个数字最早出现在DeepSeek-V3的论文中
这篇论文比DeepSeek-R1的论文早发布了一个月
而DeepSeek-V3是DeepSeek-R1的基础模型
这意味着DeepSeek-R1实际上就是在DeepSeek-V3的基础上
进行了额外的强化学习训练
因此，从某种意义上说
这个成本数据本身就不够准确
因为它没有计入强化学习训练的额外成本
不过这部分额外成本可能也不高
估计就几十万美元
那么
DeepSeek-V3论文中声称的550万美元成本
是否是准确的呢？
首先
DeepSeek报告的是基于当前市场价格估算的成本
我们并不知道他们的2048个H800 GPU集群实际花费了多少
因为通常情况下
整批购买GPU集群会比零散购买更便宜
另外一点在于
这只是最终训练运行的成本
在达到最终训练之前
还有许多小规模的实验和消融研究
这些都会产生相当可观的成本
而这部分成本并没有在报告中体现
此外，还有许多其他的成本
比如研究人员薪资和集群运维成本等等
根据SemiAnalysis报道
DeepSeek的研究人员薪资据传高达100万美元
这与OpenAI或Anthropic等AGI前沿实验室的高端薪资水平相当
我个人觉得这个数字比较夸张
在国内几乎从没有听过研究员能拿到这样的薪资水平
通常里面还要包含大量期权和福利的溢价
但是我们也不能因为把这些额外成本都算到训练成本里去
因为其它AI公司在人员上也会花费大量的薪资
也通常不会计算到模型的成本中去
像之前我们做的一期节目中
Semianalysis估算DeepSeek有5万张GPU
买服务器的费用和运营的费用分别要达到16.29和9.44亿美元
我个人也觉得是过于夸张的
即便有幻方在背后的支持
要想全靠自有资金
拿出总计将近200亿人民币的资金去做基建
也是相当困难的
市场上不可能没有任何反应和消息
况且中国一向喜欢从技术层面压缩成本
所以我个人觉得DeepSeek的硬件和基础设施成本远没有这么高
当然
由于DeepSeek保密工作确实也做的太好
外界没有人准确知道DeepSeek究竟拥有多少块卡
以及各个型号的占比究竟如何
所以这一切都只是估算
总的来说
如果把所有的设备、服务器、运营等成本全部算下来
成本肯定会远超550万美元，但是
如果只是把这550万美元看做是净算力成本
那也已经十分高效了
我们再说第三个误解
巨额的AI资本投入是不是浪费
其实这是一个广为流传
但是相当片面的观点
确实
DeepSeek在训练效率上展现出的优势
暴露出了一些头部的AI公司在计算资源使用上
可能存在着一定的效率问题
甚至英伟达短期的暴跌
也可能也与这个误读广为流传有关
但是这并不意味着
拥有更多计算资源是一件坏事
从Scaling Laws的角度来看
更多的计算能力始终意味着更好的性能
自从2017年Transformer架构问世以来
这个趋势也一直延续
而DeepSeek的模型
说白了也是基于Transformer架构的
虽然AI发展的重点在不断地演变
从最初的模型规模
到数据集大小
再到现在的推理计算和合成数据
但是“更多计算等于更好性能”这个核心规律
并没有改变
虽然DeepSeek找到了一个更高效的办法
但是Scaling Laws依然有效
更多的计算资源
依然代表着能获得更好的效果
更何况，DeepSeek能有今天的成就
一定程度上还要感谢基础模型能力的极大提升
而这正是巨大算力提升所带来的结果
说实在的早些时候不是没有人尝试过纯强化学习的办法
只不过那个时候基础模型太差了
根本没有现在这么好的学习能力
所以也一直体现不出来效果
第四个误解，DeepSeek是否采用了PTX
绕过了对CUDA的依赖？
在DeepSeek的论文中
提到了DeepSeek采用了PTX
也就是并行线程执行编程
通过定制的PTX优化
减少了L2缓存的使用和对其他SM的干扰
让DeepSeek的系统和模型
可以更好地释放底层硬件的性能
对于论文中的这段内容
网络上流传着两个解读
一种声音认为
这是绕开了CUDA的垄断；
另外一种声音是
因为DeepSeek无法获得最高端的芯片
为了解决H800 GPU互联带宽受限的问题
不得不下沉到更低一层
来提升跨芯片的通信能力
但是实际上，这两种说法都不准确
首先
PTX指令实际上是CUDA驱动层内部的一个底层组件
只不过绝大部分算法工程师不会接触到这一层
但是它仍然属于CUDA生态系统
所以
说用PTX绕过CUDA的垄断显然是错误的
但是
PTX确实是直接和底层的硬件去发生交互的
能够实现对底层硬件更好的编程和调用
所以用通俗的话来讲
DeepSeek这种优化方案
应该更不是在芯片受限的现实条件下
不得已为之，而是主动去做的优化
因为不管芯片用的是H800还是H100
这种方法都能够提高通信的互联效率
最后
我们再来说说DeepSeek在国外被封禁的误解
DeepSeek爆火之后
英伟达、微软、英特尔、AMD、AWS五大云巨头都上架或者集成了DeepSeek
国内来看
华为、腾讯、百度、阿里、火山引擎也都支持部署了DeepSeek
但是
网络上有一些过度情绪化的言论
一方面是
看到国外云巨头上架了DeepSeek
认为老外被打服了
其实，这些公司对于DeepSeek的部署
更多是因为商业的考量
作为云服务厂商
肯定要尽可能多地支持部署最受欢迎、及能力最强的模型
从而为客户提供更好的服务
当然同时也能蹭一波与DeepSeek相关的流量
或许会带来一部分的新用户转化
所以说，集中部署是真
但是说是对DeepSeek情有独钟
或者是被打服了，就是过分夸大了
更有甚者
还编造出了DeepSeek遭受攻击之后
中国科技圈组成复仇者联盟
共同驰援DeepSeek的爽文
另外一方面，还有人说
因为地缘政治等现实原因
很快国外就会陆续禁止DeepSeek使用
虽然我们确实看到一些国家陆续在封禁DeepSeek的使用
但是这里我们必须要分清楚
其实我们所说的DeepSeek
实际上包括了两个产品
一个是DeepSeek App
另一个是github上的开源代码库
前者可以看做是后者完整能力的一个展示
而后者代表了一个更为蓬勃的开源生态
直接采用了MIT许可
还支持商用
现在被限制使用的
其实是DeepSeek的App
而云服务商接入和提供的
是DeepSeek开源软件的部署
所以这两件事情应该区分开来看待
好了
以上就是对网上一些关于DeepSeek的信息和误解的澄清了
目前对DeepSeek的讨论已经远远超越了纯技术的范畴
大家已经在这次技术的进步上
套上了太多其他的色彩
不过
与其让我们自己陷入过度吹捧或者全盘否定
不如更加客观、冷静得来看待这件事的发生
毕竟
也许这场AI马拉松才真的刚刚开始
感谢大家收看本期视频
我们下期再见
