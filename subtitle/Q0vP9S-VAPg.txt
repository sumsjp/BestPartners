大家好，这里是最佳拍档，我是大飞
前几天
Google DeepMind的CEO德米斯·哈萨比斯（Demis Hassabis）
参加了All-In Podcast的播客专访
在这期节目中
他不仅直言我们离AGI就还差1到2个根本性的突破
5年内就能实现
甚至还透露
DeepMind正在打造“机器人的Android”平台
要彻底改变机器人行业的格局
今天大飞就来给大家分享一下这期专访的内容
看看在这位大佬的眼中
又藏着AI行业未来发展的哪些方向
首先
访谈从最让人好奇的诺贝尔奖经历开始
哈萨比斯在专访里说
诺贝尔奖的通知方式特别的“反套路”，
官方会在正式公布前十分钟才给获奖者打电话
当他接到那通来自瑞典的电话时
整个人都是懵的
根本来不及消化“自己拿了诺奖”这个消息
要知道
诺贝尔奖可是科学界的“圣杯”，
尤其是对做AI应用的人来说
能拿到这个奖
意味着AI在科学发现中的价值被彻底认可了
之后他去瑞典参加了为期一周的颁奖典礼
还和皇室成员共处
最让他震撼的环节
是诺贝尔奖官方从保险库取出的“签名簿”
哈萨比斯说
当他翻开那本厚厚的册子
看到的全是科学史上的“群星名字”，
理查德·费曼（Richard Feynman）、玛丽·居里（Marie Curie）、阿尔伯特·爱因斯坦（Albert Einstein）、尼尔斯·玻尔（Niels Bohr）
等等等等
最后他亲手把自己的名字写了进去
那种“和历史对话”的感觉
是任何荣誉都替代不了的
主持人问他
之前有没有预感到会获奖
哈萨比斯的回答很实在
虽然听到过一些传闻
但是诺贝尔奖的保密工作做得像“瑞典的国家宝藏”一样
在信息这么透明的时代
能做到完全不泄露，特别难得
而且他也清楚
诺贝尔奖评选不只是看科学突破本身
更要看对对现实世界的影响
因为很多成果的影响需要二三十年才能显现
所以他从没想过自己会这么快拿到这个奖
这次获奖对他来说
完全是“意外之喜”
聊完这份属于科学的荣誉
访谈开始聚焦于哈萨比斯背后的团队
Google DeepMind
很多观众可能好奇
在Alphabet这么庞大的体系里
DeepMind到底是干什么的？
哈萨比斯给出了一个很形象的定位
那就是整个Google和Alphabet的AI引擎室”
这里要先补个背景
几年前Google把旗下所有AI团队
包括原来的DeepMind
都整合到了一起
成立了现在的Google DeepMind
哈萨比斯说，他们的核心任务就是
造模型、做整合
虽然核心模型是Gemini
但是不只有Gemini
还有视频模型Veo、交互式的世界模型Genie等等
这些模型现在已经嵌到了Google的几乎所有产品里
包括数十亿用户在用的AI Overviews、Gemini
还有大家日常用的Workspace、Gmail
背后都有这些模型的支撑
这种“前沿研究+快速落地”的模式
对DeepMind来说是个巨大的优势
他们能一边做着最顶尖的AI研究
一边让数十亿用户实时的体验成果
不用像很多实验室那样
研究成果只能躺在论文里
而且哈萨比斯透露
Google DeepMind现在有5000人左右
其中80%以上是工程师和博士研究员
总共差不多有4000个核心技术人员
这种“高学历密度”的团队
也是他们能持续出成果的关键
接下来
我们进入这次专访的“技术重头戏”，
Genie世界模型
哈萨比斯说，这个模型必须亲眼看到
才能理解它的厉害之处
主持人也特意准备了视频
咱们就跟着他们的描述
来看看一下Genie到底牛在哪
首先，Genie不是游戏
也不是一个预先制做好的视频
它是用文本提示实时生成的一个交互式的世界
比如你输入“一个可以粉刷的房间”，
Genie就能生成一个3D环境
你用方向键和空格键就能在里面走
甚至能拿起“油漆刷”在墙上画画；
更绝的是，你走到某个区域之前
那个区域的像素都还没生成
完全是“走到哪生成哪”
哈萨比斯举了个例子
视频里的玩家刷完墙后转头
能看到自己刚才留下的油漆痕迹
而且这些痕迹不是预制的
是AI根据“粉刷动作”实时算出来的
你还能输入“穿着公鸡服装的人”、“水上摩托艇”，
这些元素会立刻融入场景
没有一点违和感
可能有观众会问，这不就是3D游戏吗？
其实区别大了
传统3D游戏需要用Unity或者Unreal这样的渲染引擎
程序员得先写好所有物理规律
比如光线怎么反射、物体怎么碰撞
再建立好3D模型，最后渲染出画面
但是Genie完全不用考虑这些
它是通过看数百万个YouTube视频
自己“逆向工程”出了世界的物理规律
比如水的光影反射、物体的材质感
它都能自己学会
不用程序员一行行的去写代码
哈萨比斯说
这对他个人来说特别有感触
他90年代刚入行的时候
就是给游戏写代码、做图形引擎的
深知手工做这些有多难
你要画多边形、调整物理参数
一个小细节就要改很久
现在看到AI能“开箱即用”地处理这些
他自己都觉得“不可思议”
那Genie的意义在哪呢？
哈萨比斯说得很明确，要想实现AGI
AI不能只懂语言和数学
必须去理解物理世界
比如机器人要帮你递东西
得知道“杯子拿太松会掉”；
智能眼镜要给你指路
得知道“台阶要迈过去”，
这些都是最基础的物理规律
而Genie就是在练这个“理解能力”
用哈萨比斯的话说就是
如果你能生成这个世界
就证明你的系统真的懂它背后的规律
聊完Genie
对话的内容自然过渡到了机器人
毕竟“理解物理世界”的最终目的
就是让AI在现实里帮我们做事
主持人问哈萨比斯
现在AI的视觉、语言、动作模型整合到哪一步了呢？
能不能做到“我说话
机器人就干活”了呢？
哈萨比斯说
如果你试试Google的Gemini Live
用手机对着周围的东西
它已经能“看懂”物理世界了
比如能够识别出“这是杯子”“那是桌子”
下一步就是要把这个能力装到智能眼镜里
让它变成你的“随身助手”，
比如当你逛街的时候
它能提醒你“前面有你要找的店”，
或者嵌到谷歌地图里
给你更精准的导航
而在机器人领域
他们做了所谓的“Gemini机器人模型”，
也就是在Gemini的基础上
用机器人数据做了微调
去年夏天他们放了个演示视频
桌面上有两个机械臂
你跟它说“把黄色的物体放进红色的桶里”，
它能直接把这句话转化成动作
精准地抓起黄色物体，放进桶里
哈萨比斯强调
这种多模态能力是专用机器人模型比不了的
因为专用模型只能干一件事
而Gemini机器人模型不仅能够理解你的话
还懂物理世界
这样才是安全、灵活的
主持人还提到
之前问过谷歌CEO桑达尔·皮查伊（Sundar Pichai）
会不会做“机器人的Android”，
就像Android系统支撑了无数手机那样
用一个通用平台来支撑所有的机器人呢？
哈萨比斯这次给出了肯定的答案
这就是他们的核心策略之一
当然，他们也在走另一条路
“垂直整合”，
把最新模型和特定机器人形态绑在一起
做深度优化
比如工业用的机械臂和家用机器人
形态不一样
就需要针对性整合
这里有个很有意思的争议
人形机器人到底实用吗？
有人说“人形太通用
不如专用机器人效率高”
而哈萨比斯的观点是“两者都有用”
他说，五到十年前
他也觉得专用形态更好
尤其是对于工业场景来说
比如实验室里的机器人
就该按实验的流程来设计；
生产线上的机械臂
就该按流水线来优化
但是对于家用或通用机器人来说
人形太重要了
因为我们的世界是按人类设计的
台阶是给人走的，门把手是给人握的
桌子高度是按人的身高来的
与其花大钱改造世界适应机器人
不如让机器人“长得像人”，
直接适配现有环境
这样成本会更低，也更实用
所以他判断
未来专用机器人会在工业里发光
人形机器人会在日常生活里普及
主持人追问，未来五到七年内
会不会出现数百万、上亿台的机器人呢？
哈萨比斯说
现在机器人领域还处在“黎明时分”，
就像个人电脑的70年代
还在PC-DOS阶段
但是有个区别就是
现在的发展速度是“一年顶过去十年”
他预计未来几年会有更多的“惊艳时刻”，
但是前提是算法得再进步
机器人模型也要更可靠
对世界的理解要更全面
但是哈萨比斯也提到，目前来看
硬件方面是个比较大的挑战
如果现在建工厂生产几十万台机器人
等你造出来
六个月后可能就有更灵巧、更便宜的新版本了
到时候老版本就没人要了
所以现在的关键是“找到能规模化量产
又能快速迭代的硬件方案”，
这也是整个行业都在攻克的难题
聊完机器人
主持人把话题又拉回到了科学上
毕竟哈萨比斯的核心目标之一
就是用AI加速科学发现
主持人问他
AI最有可能在哪些科学领域带来突破呢？
都需要什么样的模型呢？
哈萨比斯说
用AI加速科学发现、改善人类健康
是他“毕生追求”的事业
他认为AGI会是“科学探索的终极工具”，
现在DeepMind已经做了很多尝试
比如除了用AlphaFold来破解蛋白质结构
他们还用AI来设计新材料、控制聚变反应堆的等离子体、优化天气预报
甚至解奥林匹克数学竞赛题
而且有意思的是，同一种模型
微调一下就能应对不同领域的难题
这说明AI的通用性正在慢慢显现
但是现在大家看到的
还只是“冰山一角”
不过他也坦诚说道
现在的AI还有个很大的局限
那就是没有真正的创造力
它能验证你提出的猜想
比如“这个蛋白质结构对不对”，
但是不能自己提出新的猜想、新的理论
哈萨比斯说
这种“创造新概念”的能力
是AGI的核心标准之一
主持人追问
那人类的创造力到底是什么呢？
哈萨比斯举了个思想实验
如果给AI输入1901年以前的所有知识
它能不能像爱因斯坦（Albert Einstein）在1905年那样
自己提出狭义相对论呢？
如果能
就说明AI在创造力上迈出了关键一步
还有AlphaGo的例子
虽然它击败了围棋世界冠军
还下出了“第37手”这样的创新棋步
但是它不能创造一款像围棋一样“优雅、精妙”的新游戏
只能在现有的规则里玩
哈萨比斯说，AGI现在缺的
就是“创造美、欣赏美的能力”，
以及顶尖科学家那种“非线性的直觉飞跃”
他解释说
优秀科学家和伟大科学家的区别
就在于创造力
优秀的能把技术练到极致
伟大的能从其他学科“借鉴灵感”，
比如从生物学里的规律
想到物理学的问题
AI现在还做不到这种“跨领域的类比”，
也没有所谓的“一致性”，
比如有些模型被吹成了“博士级的智能”，
但是换个问法
它连高中数学题都能算错
真正的AGI，不应该会犯这种低级错误
显然
哈萨比斯在这里阴阳了一下OpenAI的GPT-5
随后，他给出了一个明确的时间线
那就是我们离AGI还有五到十年的时间
期间需要1到2个根本性的突破
可能是在“持续学习”方面
比如教AI新的知识
它能马上学会，不用重新训练
也可能是在“跨领域的推理”上
他不觉得靠着“堆数据、堆参数”就能实现AGI
必须还得有底层架构方面的突破
主持人还提到一个说法
那就是现在大语言模型的性能在趋同
提升速度变慢了
哈萨比斯直接否定了这种说法
至少从DeepMind的内部来看
进步还在加速
比如Gemini模型、Veo模型
还有大家反响特别好的NanoBanana
都在持续突破
提到NanoBanana，哈萨比斯特别骄傲
这款图像生成工具最牛的地方就是“一致性”，
你让它去修改图里的某个细节
比如“把蓝色的杯子改成红色”，
它只会改杯子，其他部分完全不变
这样你就能反复调整
直到做出满意的效果
他说，这就是未来创意工具的方向
用户不用学复杂的操作
直接对话就能够创作
这呢还有一个很重要的趋势
那就是创造力的民主化
哈萨比斯说
以前呢学Photoshop你得买一本厚厚的指南
练几个月才能学会抠图、羽化；
而现在用NanoBanana，直接说
把这个人抠出来
背景换成草原，AI就能做到
但是这不是说“人人都能成顶尖创作者”，
顶尖的导演、艺术家
他们的“叙事能力”和“艺术风格”，
还是AI替代不了的
AI能做的
是让他们的效率提升10倍甚至100倍
比如导演达伦·阿伦诺夫斯基（Darren Aronofsky）用他们的Veo工具来做电影
能够快速把脑子里的想法变成画面
不用再等团队熬夜做特效了
主持人又追问道
未来会不会变成“每个人都有自己的专属内容”呢？
比如我说“要一首大卫·马修Dave Matthews风格的歌”，
AI马上就能写出来；
我说“要一款以《勇敢的心》为背景的游戏
主角是我”，
AI马上就能生成出来
哈萨比斯说
这种“共创式的娱乐时代”肯定会到来
但是顶尖创作者的角色并不会消失
而是会变成“世界观的编辑者”
他们会来设计核心的故事线、设定世界规则
然后普通人在这个框架里完成自己的创作
比如一款游戏
创作者设计好背景和核心玩法
玩家能自己添加剧情、修改角色
这样既有集体的共鸣，又有个人特色
聊到这里
主持人问了个很实际的问题
哈萨比斯现在还管理着Isomorphic公司吗？
这家公司是做什么的？
哈萨比斯回答道
他还在管着Isomorphic
这是一家从DeepMind分出来的公司
专门做药物发现
核心技术来自于AlphaFold
但是AlphaFold只是第一步
知道了蛋白质结构
不代表能做出药物
而Isomorphic要做的
是围绕AlphaFold去建立一系列的模型
比如设计能和蛋白质精准结合的化合物
以及预测化合物有没有副作用
他的目标也很激进
那就是在未来十年
把药物研发的周期从几年甚至几十年
缩短到几周甚至几天
现在Isomorphic已经和礼来（Eli Lilly）、诺华（Novartis）这些大的药企合作
还有自己的内部研发项目
主攻癌症、免疫学领域
还和MD安德森癌症中心这样的顶尖机构合作
哈萨比斯说，明年某个时候
他们的候选药物就能进入“临床前阶段”，
也就是在动物身上做实验
之后再交给药企推进人体临床试验
这里涉及到一个比较专业的问题
就是用AI来做药物发现
是用概率模型还是确定性模型呢？
概率模型是“靠数据来猜”，
比如“这个化合物有效的概率是80%”；
而确定性模型是“靠规则来算”，
比如“根据化学原理
这个化合物一定能和蛋白质结合”
主持人问哈萨比斯
他们更倾向于哪种呢？
哈萨比斯说
他们现在做的是“混合模型”，
AlphaFold就是一个典型的例子
它有个“概率部分”，
用神经网络和Transformer从数据里学习规律
但是也有“确定性的部分”，
把已知的化学、物理规则嵌进去
比如“原子不能重叠”、“键角不能超过某个范围”等等
为什么要这样呢？
因为生物学和化学领域的数据往往不够多
如果让AI自己学这些基础规则
就会浪费大量的算力；
如果直接嵌进去
就能让模型更高效、更准确
不过，混合模型的难点在于“平衡”，
怎么让数据驱动的部分和规则驱动的部分协同工作
而不是互相干扰
比如AlphaGo，也是混合模型
有学习人类棋谱的部分
也有自己探索的部分
而且他们还会不断的优化
比如AlphaGo的升级版AlphaZero
他们把AlphaGo里“针对围棋的规则”全删掉
让它从零开始自我对弈
结果AlphaZero不仅学会了下围棋
还学会了下国际象棋和将棋
通用性大大提升
哈萨比斯说，未来AGI的突破
可能也会来自这种“混合模型的优化”，
先靠混合模型解决问题
再把经验反哺给纯学习模型
从而慢慢实现“端到端学习”
最后
主持人问了一个所有人都关心的问题
如今AI的能源需求越来越大
未来会不会出现“能源危机”呢？
哈萨比斯的回答很辩证
那就是两个趋势同时存在
一方面
DeepMind一直在优化模型的效率
比如模型蒸馏（Model Distillation）”，
用一个大模型教小模型
让小模型的性能可以接近大模型
但是能耗和延迟降低10倍甚至100倍
现在Google每天要给数十亿用户提供AI服务
必须靠这种技术来控制成本和能耗
但是另一方面
AI的能源需求还在增长
因为大家对AGI的期待越来越高
需要训练更大、更复杂的模型
实验更多新的想法
这种“前沿探索”所需要的能耗
暂时还降不下来
不过哈萨比斯还是很乐观的
认为长期来看
AI节省的能源会远远超过它所消耗的
比如AI能够优化电网
让电力分配更加合理
减少浪费；
还能设计出新的材料
比如更高效的太阳能板、更轻的电池；
还能提升新能源的效率
比如让风力发电机根据风向自动的调整角度
他说，未来十年
AI会成为“解决气候变化的一个关键工具”，
它的贡献会远大于能耗
作为收尾
主持人让哈萨比斯描绘了一下十年后的世界
哈萨比斯说，AI领域的变化太快
十年后的细节很难预测
但是如果能在十年内实现AGI
一定会开启“科学和艺术的新黄金时代”，
能源问题可能靠着聚变来解决
癌症可能依靠AI药物来治愈
普通人也能靠着AI来实现自己的创意
他说，这就是他一直坚持做AI的原因
不是为了技术本身
而是为了让人类的生活变得更好
好了
我们今天对这期专访的分享就到这里
希望能通过提炼这些细节
让大家能够更加看清楚AGI的发展路径
感谢收看本期视频，我们下期再见
