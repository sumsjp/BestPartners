大家好，这里是最佳拍档，我是大飞
今天要和大家聊的
是一场可能会被写入AI发展史册的神仙对话
2025年
六位亲手塑造了现代AI世界的奠基人
因为共同获得伊丽莎白女王工程奖而齐聚一堂
这六个人，每一位单独拿出来
都是能撑起一个领域的顶流
深度学习三巨头杰弗里·辛顿、杨立昆、约书亚·本吉奥
英伟达的算力双引擎
CEO黄仁勋和首席科学家比尔·达利
以及李飞飞
在这场对谈中
他们不仅复盘了AI从无人问津到席卷全球的40年
还激烈辩论了一个核心的问题
那就是我们现在经历的是真实的产业革命
还是即将破裂的泡沫？
更关键的是，关于AGI的时间线
他们给出了从5年到20年
甚至有人说这个问题本身就是错的
今天，我们就来回顾一下这场对谈
从他们每个人的顿悟时刻说起
正是这些藏在实验室里的灵光一闪
最终串联成了今天AI爆发的导火索
先从约书亚·本吉奥说起
他的第一个顿悟时刻
是研究生时期读辛顿的论文
当时他正在找研究方向
读了辛顿关于神经网络的文章后
他突然觉得原来智能不是靠复杂的编程
而是靠简单的原则
他立马兴奋起来
感觉也许有一些简单的原则
就像物理定律一样
可以帮助我们理解人类智能
还能构建智能机器
这个想法让他一头扎进深度学习
后来成为三巨头之一
而他的第二个顿悟时刻
是在GPT问世后的2022年左右
他突然意识到
AI如果能理解语言、有自己的目标
却没人能控制这些目标，会有大问题
他开始在想，如果它们比我们更聪明
会发生什么？
如果人们滥用这种力量，会发生什么？
于是他彻底调整研究方向
开始专注于AI安全和目标对齐
然后是比尔·达利
他的顿悟时刻都和算力有关
第一个是1990年代末
他在解决内存墙问题的时候
突然想到为什么不让计算跟着数据走
而不是让数据跟着计算走？
于是他设计了流处理架构
把计算拆成多个独立的内核
每个内核处理一部分数据
数据像流水一样在内核之间传递
计算和数据读取同步进行
这个架构一下子突破了内存墙
后来成了GPU的核心设计
第二个顿悟时刻是2010年他和吴恩达的早餐会
吴恩达当时在谷歌用16000个CPU训练一个识别猫的神经网络
达利听了之后
觉得GPU应该能做得更好
他回去后和同事用48个英伟达GPU重复实验
结果不仅速度更快
成本还更低
当他看到结果的时候
就坚信不疑这就是英伟达应该做的事情
从那以后
英伟达的GPU从游戏卡彻底转向AI卡
开启了算力革命
杰弗里·辛顿的顿悟时刻
是1984年那个不起眼的语言模型实验
当时他用反向传播训练一个小模型
让它预测单词序列里的下一个单词
他本来没抱太大期望
结果模型居然能自动理解单词的含义
他说仅仅通过尝试预测符号串中的下一个单词
它就能学会如何将单词转换成捕获单词含义的特征集合
并且让这些特征之间产生交互
从而预测下一个单词的特征
辛顿当时就意识到
这可能是让机器理解语言的关键
但是他也无奈地说
这花了40年才走到今天
原因就是我们没有算力，也没有数据
1984年，他只有100个训练样本
电脑的算力还不如现在的手机
直到2010年后
有了GPU和海量互联网数据
这个1984年的想法才终于长成了今天的大语言模型
黄仁勋的顿悟时刻
是2010年同时收到三个实验室的信号
当时多伦多大学、纽约大学、斯坦福大学的研究团队
几乎同时联系英伟达
说我们用你们的GPU训练深度学习模型
效果特别好
黄仁勋本身是芯片设计师
他突然发现深度学习的软件设计
和芯片的硬件设计居然有相似的逻辑
他说那时我意识到
也许我们可以开发出能够很好地扩展的软件和能力
就像我们多年来扩展芯片设计一样
这个发现让他决定
英伟达不仅要做GPU硬件
还要做AI软件生态
后来的事情大家都知道了
随着AI模型越来越大
对GPU的需求越来越高
英伟达成了全球AI算力的垄断者
李飞飞的顿悟时刻
第一个是2006年意识到
数据是AI的瓶颈
当时她在研究图像识别
试了所有的主流算法
但是模型的泛化能力都很差
她和学生分析后发现
问题不是算法不好
而是数据太少
她说我们决定在那时做一件疯狂的事情
在三年内创建一个互联网规模的数据集
名为ImageNet
这个决定花了她三年时间
发动了全球上万名志愿者标注图片
最终建成的ImageNet
成了深度学习的燃料
2012年AlexNet正是用了ImageNet
才实现了图像识别的突破
她的第二个顿悟时刻
是2018年在谷歌担任首席科学家的时候
当时AI已经开始进入医疗、金融、农业等各个行业
她突然意识到AI是一项文明级技术
会影响每个人
但是我们没有指导框架
于是她回到斯坦福
创立了以人为本的AI研究所
提出以人为本的AI框架
强调AI要考虑人类价值观、伦理
不能只追求技术指标
最后是杨立昆
他的顿悟时刻早在本科时就有了
当时他痴迷于智能的本质
发现1950-60年代的科学家们
曾经尝试让机器自我学习
而不是手动编程
这个想法让他特别兴奋
因为他觉得自己没法从头开始构建一台智能机器
最好让它自己训练自己
但是他在读研究生时
却找不到研究这个方向的导师
当时AI领域正流行符号主义
没人相信机器能自我学习
直到他看到辛顿的论文
才找到同道中人
1985年，他和辛顿第一次见面吃午饭
两人居然能互相接话
辛顿用法语写了一篇关于反向传播的论文
杨立昆能看懂里面的数学逻辑
两人当场就争论起监督学习和无监督学习哪个更重要
杨立昆当时认为
监督学习是唯一能落地的范式
辛顿则坚持无监督学习才是智能的核心
没想到，两人的争论最终走向了融合
不过
后来杨立昆也说大型语言模型只是在学习数据结构的方式
这正是他和辛顿当年争论的无监督学习的延伸
这些顿悟时刻
没有一个是突然的奇迹
但正是这些时刻，像一个个齿轮
最终咬合在一起
推动了AI从理论走向实践
聊完过去，对谈的核心话题来了
2025年的今天，全球AI投资热潮汹涌
英伟达市值一度突破万亿美元
大模型、AI应用遍地开花
但这到底是像2000年互联网泡沫一样的虚假繁荣
还是真正的产业革命？
这个问题
六位先驱的回答分成了两派
但又不是简单的是或否
首先是非泡沫派
代表人物是黄仁勋和比尔·达利
作为英伟达的掌舵者和技术核心
他们的观点直接基于算力需求的真实性
黄仁勋的论点非常直接，他说
今天你能找到的几乎每个GPU
都被点亮并且使用着
这和互联网泡沫时的暗光纤完全不同
他这里提到的暗光纤
是2000年互联网泡沫时的一个典型现象
当时企业疯狂的铺设光纤
但是实际使用量极低
很多光纤是闲置的
或者说是暗的，最终导致泡沫破裂
而现在的GPU
不管是用于大模型训练、AI应用推理
还是自动驾驶、医疗影像分析
几乎没有闲置
黄仁勋说
产生真正有价值、而且需求旺盛的东西
所需要的计算量非常巨大
AI需要许多工厂来生产token
产生智能
而且，这种智能生产的需求是真实的
因为AI是首次增强人类智能的技术
过去像蒸汽机、电力这样的技术
增强的是人类的体力
而AI增强的是脑力
这是千年一遇的变革
他还补充道
今天大多数人仍然没有使用AI
但是未来每个人的每一刻
都会以某种方式与AI互动
从这个角度看
当前的算力需求还只是冰山一角
不存在泡沫
比尔·达利则从技术趋势的角度
支撑了黄仁勋的观点
他提出了三个不可逆的趋势
第一个是模型效率提升
比如大语言模型的注意力机制
从早期的全注意力，到分组注意力GQA
再到多查询注意力（MQA）
现在能用更少的计算量达到更好的效果
这意味着过去太贵用不起的AI应用
现在能落地了，需求会被进一步激发
第二个是模型能力的增强
不管是语言理解、逻辑推理
还是图像生成、视频分析
AI的能力还在持续提升
而且这种提升需要更强大的GPU支撑
所以达利说我们不会倒退
只会拥有更好的模型
这些模型仍然需要GPU
第三个是应用场景的爆发
现在AI才刚刚进入医疗、教育、制造、农业等领域
只不过可能是最终需求的百分之一
未来应用场景会越来越多
算力的需求也自然会持续增长
基于这三点
他明确的表示这里面没有什么泡沫
因为我们正处于多重指数增长的早期阶段
而且它会持续下去
然后是部分泡沫派
代表人物是杨立昆，他的观点更冷静
也更聚焦于技术范式的局限性
杨立昆并不否认当前AI应用的价值
他说基于大语言模型可以开发很多应用
从这个意义上来说
我们不处于泡沫之中
大语言模型是当前的主导范式
有很多可挖掘之处
这证明了软件和基础设施投资的合理性
像AI办公助手、智能客服、代码生成等工具
确实在提升效率
这些需求也是真实的
但是他认为
AI在某种意义上存在着泡沫
那就是某种程度上认为当前的大语言模型范式
将被推到拥有人类级别智能的程度
他个人不相信这一点
杨立昆的理由很明确
当前的大语言模型本质上是基于语言的模式匹配
它能生成流畅的文本
是因为它学习了海量语言数据中的规律
但是它缺乏对真实世界的理解
就好像我们还没有像猫一样聪明的机器人一样
猫能轻松在房间里跳跃、躲避障碍物
理解物体的空间关系
但是现在的AI机器人
连基本的空间导航都做不好
杨立昆认为，要想实现人类级别智能
需要突破当前的大语言模型范式
在空间智能、因果推理、多模态交互等方面有基础性的突破
但是当前的投资热潮
很多都集中在扩大模型的参数规模上
认为参数越大，智能越高
这其实是一种路径依赖
可能会导致资源浪费
这就是他说的泡沫
李飞飞则从学科年轻性的角度
补充了杨立昆的观点
她认为，从市场角度看
AI热潮会有自我调整
但是从长期趋势看
AI仍然是一个非常年轻的领域
物理学有400多年历史，AI还不到70年
她特别提到了空间智能的缺口
也就是AI对真实世界空间关系的理解能力
她说即使是今天最强大的大语言模型模型
也无法通过基本的空间智能测试
李飞飞认为，AI未来的突破点
不仅在语言，还在感知和行动的结合
因此
她认为当前的投资如果只集中在大语言模型
而忽略其他领域的发展
可能会导致局部过热
但是从整个AI学科的发展来看
未来还有很多前沿需要开拓
长期趋势是向上的
约书亚·本吉奥则更关注风险与不确定性
他说
仅仅因为我们过去在改进技术方面取得了很多成功
并不意味着未来也会一样
如果没有能达到预期
就会产生经济后果
他现在正在推动国际AI发展跟踪计划
组织专家监测AI技术的进展、风险及缓解措施
本吉奥认为，当前的AI热潮中
很多企业对AI的短期预期过高
比如希望AI在一两年内取代大量人类工作
或者解决复杂的医疗、气候问题
但是实际上AI的落地需要时间
这个过程可能需要5-10年
如果短期预期无法实现
可能会导致投资撤资
出现局部回调
但是这并不意味着AI本身是泡沫
而是预期与现实的错配
总的来说，六位先驱的分歧
本质上是技术乐观主义与科学审慎性的平衡
这种分歧不是坏事
反而说明AI领域的思考越来越深入
没有陷入到盲目乐观或者全盘否定的极端状态
如果说对泡沫的争议是关于现在
那么AGI什么时候到来就是关于未来
对于这个问题
六位先驱的回答差异更大
甚至可以说是完全分歧
首先是激进预测派
代表人物是约书亚·本吉奥和杰弗里·辛顿
他们对AGI的到来时间最乐观
也最直接
约书亚·本吉奥给出的时间线是大约5年
但是他的预测有着明确的限定
那就是如果我们延续这种趋势
大约在5年内
AI就能达到一名员工在他的工作岗位上的能力水平
这里的工作岗位能力
指的是特定领域的专业能力
比如客服、数据录入、基础代码编写、简单的文案创作等等
这些工作的核心是规则明确、重复性高、依赖数据
而AI在这些领域的进步速度确实很快
本吉奥的理由有两个
一是AI规划能力的指数级增长
过去6年
AI在多步推理上的能力提升是指数级的
从只能解决简单问题
到现在能处理复杂的逻辑链；
二是AI从事AI研究的能力
现在已经有企业在开发AI研究员
让AI自动设计实验、分析数据、优化模型
这些工具能大幅加速AI自身的迭代
本吉奥说
这可能会成为一个改变游戏规则的加速器
如果AI能够自己改进自己
那么智能提升的速度会远超人类的想象
不过他也强调这只是基于趋势的推测
存在不确定性
我们应该持不可知论，不要妄下断言
杰弗里·辛顿的预测稍微保守一些
但也同样很明确
他说
如果把AGI定义为机器在辩论中总是能胜过你
我们可能会在不到20年的时间内达到那个目标
辛顿的定义很有意思
他选择辩论能力作为AGI的标志
是因为辩论需要逻辑推理、事实记忆、语言表达、临场应变等综合能力
这正是人类智能的核心
辛顿的信心来自他对神经网络潜力的长期信念
他从1980年代就坚信
神经网络能模拟人类大脑的学习方式
他说过去40年
我们缺的是算力和数据
现在这两个瓶颈都被打破了
GPU算力还在指数级增长
互联网数据量也在持续增加
神经网络的潜力会不断释放
辛顿并不认为AI会取代人类
但是他相信AI在特定领域的能力会超过人类
而这种超越会在20年内实现
然后是工程务实派
代表人物是黄仁勋和比尔·达利
他们更关注AI的实际应用价值
而非AGI的时间线
黄仁勋的观点很直接
AGI何时到来的问题其实无关紧要
因为我们拥有足够的通用智能
可以在未来几年内将这项技术
转化为大量对社会有用的应用
他举了几个例子
现在的AI已经能辅助医生诊断癌症、帮助工程师设计更高效的芯片、协助农民提高作物产量
这些应用不需要人类级别的智能
但是能切实的解决问题，创造价值
黄仁勋认为，纠结于AGI何时来
反而会忽略当前技术能做什么
AI的价值不在于是否和人类一样聪明
而在于是否能增强人类能力
他说我们不需要等AGI到来
今天的AI就能帮我们解决很多的重要问题
这些才是更值得关注的
比尔·达利则更加直接
他说这是一个错误的问题
因为我们的目标不是构建人工智能来取代人类
或者比人类更优秀
而是构建人工智能来增强人类
达利的理由来自他的工程背景
他设计GPU的初衷
就是让AI成为人类的工具
而不是对手
他举了一个例子
人类无法识别22000个物体
也无法快速解决奥林匹克数学题
但是AI可以
这样人类就能做那些独属于人类的事情
比如发挥创造力、富有同情心、与他人互动等等
达利认为，AGI的定义本身就很模糊
什么是人类级别的智能？
是会思考？
会感受？
还是会创造？
与其争论这个模糊的概念
不如专注于如何让AI更好地辅助人类
这才是技术的核心目标
最后是细致解构派
代表人物是李飞飞和杨立昆
他们没有给出具体的时间线
而是更深入地分析了AGI的本质
李飞飞认为
机器的某些部分将取代人类智能
而机器智能的某些部分
将永远不会与人类智能相似或相同
因为它们是为了不同的目的而建造的
她举了两个例子，一是图像识别
AI能识别22000个物体
远超人类的能力
但是这是因为AI处理图像的方式和人类不同
二是语言翻译
AI能翻译100种语言
人类很难做到
但是AI不懂翻译内容背后的文化内涵
李飞飞说我们应该细致入微并且立足于科学事实
就像飞机能飞
但它们不是像鸟一样飞
基于机器的智能会做很多强大的事情
但是人类智能在创造力、情感、伦理判断等方面
始终有不可替代的地位
因此
她认为AGI何时到来这个问题本身就有问题
因为AI和人类智能是一种互补而非替代关系
不存在谁达到谁的水平的说法
杨立昆则强调
AGI不会是一个单一事件
而是能力逐步扩展的漫长过程
他说不会有一天突然宣布
我们实现了AGI
而是AI会先在某个领域超过人类
再在另一个领域超过人类
逐步覆盖更多的能力
但是这个过程会持续几十年
甚至上百年
杨立昆认为
当前的AI还处于感知智能的阶段
下一步是认知智能阶段
再下一步才是通用智能阶段
每个阶段都需要基础科学的突破
不能急于求成
他说我们可能在未来5-10年内
在认知智能上有重大进展
但要达到通用智能，还需要更长时间
甚至可能需要新一代的计算架构
而不是现在的GPU
这场对谈的最后，主持人说
我们的共识在某种程度上是
未来就在今天
但是永远不会有一个确定的时刻
这句话其实是对六位先驱观点的最好总结
他们没有在泡沫与否AGI何时到来这些问题上达成一致
但是这种没有共识
恰恰是AI领域最宝贵的状态
它说明这个领域还充满活力
没有陷入僵化的思维
每个观点都有扎实的技术和逻辑支撑
也都在推动行业思考如何更理性地发展AI
更重要的是，六位先驱虽然观点不同
但都有一个隐性的共识
那就是AI的未来
需要技术突破与人文关怀的结合
没有技术突破，AI就是空中楼阁
但是没有人文关怀
AI可能会偏离服务人类的初衷
这场对谈还有一个细节让我印象深刻
当主持人问
你们现在还是朋友吗，杨立昆笑着说
1985年我们一起吃午饭
就能互相接话
现在我们还是会争论
但争论的是技术，不是立场
这种基于事实的争论
正是科学进步的动力
好了，今天的内容就到这里
感谢大家收看本期视频，我们下期再见
