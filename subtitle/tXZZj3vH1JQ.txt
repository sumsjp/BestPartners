大家好，这里是最佳拍档，我是大飞
过去几年
人工智能这个话题彻底点燃了人们的想象力
无论是科技从业者、研究者
还是普通大众，都在好奇
机器究竟能否拥有真正的智能？
而智能本身，又到底是什么？
今天给大家分享的
是人工智能领域的顶尖专家
马毅教授的一期访谈
通过他的研究、著作以及对智能本质的深刻思考
希望能让我们穿透人工智能的表象
触摸到底层的数学原理与核心逻辑
马毅教授的履历堪称传奇
他是香港大学计算数据科学学院的首任院长、香港大学数据科学研究所所长
同时也是加州大学伯克利分校的客座教授
也曾担任过电气工程与计算机科学全职教授
作为IEEE会士、ACM会士
他在稀疏表示和低秩结构领域的开创性工作
从根本上塑造了现代计算机视觉和机器学习的发展方向
而他近期出版的著作《学习数据分布的深度表示》，
更是提出了一套基于简约性和自洽性两大原则的智能数学理论
这套框架催生出了被称为CRATE架构的白盒Transformer
与那些依赖经验猜测的黑盒模型不同
CRATE的每一个组件都能从第一性原理推导而来
说到这本书的诞生，马毅教授提到
深度学习在过去十年
彻底改变了人工智能的实践方式
但是大约在八年前
当他回到伯克利分校后
开始尝试从更具有原则性的角度
去理解深度学习的本质
这本书正是他和团队以及众多同行
过去八年多研究成果的结晶
不仅解释了深度网络背后的核心原理
更触及了智能本身的通用规律
两年前，马毅教授加入香港大学后
希望将这些领域内的最新进展
融入课程体系
于是和学生、同事们一起
将这些知识系统整理成了教材
这门课程今年在港大开设
明年也将登陆伯克利分校
这也是学术界首次尝试以一种更具有原则性的方式
同时阐释深度网络与智能的核心逻辑
那么，简约性和自洽性
这两个听起来有些抽象的原则
究竟如何解释自然智能与人工智能的呢？
马毅教授首先强调
智能是一个内涵极其丰富的概念
它有不同的层级和阶段
我们必须先从科学和数学的角度厘清这个概念
才能深入研究其背后的机制
而他们关注的
是一种贯穿于所有生命形式的基础智能
那就是生物如何学习外部世界的知识
将其转化为记忆
用更流行的说法就是世界模型
并且利用这些记忆进行预测、反应和决策
从而更好地生存
这种智能是人类与动物共通的
也是当前人工智能研究中
最核心的探索方向之一
对于这种基础智能而言
简约性和自洽性是两大核心支柱
马毅教授解释道
我们对世界的认知和知识
本质上是在发现那些可预测的规律
而这些规律往往具有极低的自由度
也就是所谓的低维结构
无论是压缩、去噪还是降维
本质上都是为了捕捉这种低维结构
找到数据最简洁的表示方式
这正是简约性的核心
把事情做到尽可能的简单
但又不能过于简单
而后半句就指向了自洽性
自洽性要求我们的记忆或世界模型
必须能够准确地模拟和还原现实世界
不能因为追求简单
而丢失了关键的预测能力
这恰恰也是这种基础智能的核心工作方式
既要通过简约性捕捉关键规律
又要通过自洽性保证模型与现实的一致性
谈到这里
就不得不触及一个关键问题
压缩与抽象的区别是什么？
记忆与理解的边界又在哪里？
这也是当前人工智能领域最核心的争议之一
马毅教授举了一个很形象的例子
生命演化的过程
其实就是一种知识压缩的过程
生物通过DNA将亿万年演化中习得的世界知识
编码并传递给下一代
这种编码本质上就是压缩
但这种更新机制极其残酷和低效
依赖随机突变和自然选择
耗费大量的资源和时间
而且充满不确定性
这和当前大模型的发展路径惊人地相似
众多团队在没有明确原则指导的情况下
通过试错和经验探索
那些幸运取得效果的模型被广泛推广
主导了整个领域的实践
从这个角度看
当前的人工智能其实还处于智能演化的早期阶段
和生命演化早期的知识积累方式类似
主要依赖于数据的压缩与统计规律的提取
但随着生命的演化
生物发展出了大脑和各种感官
学习机制发生了根本性的转变
知识不再仅仅通过DNA遗传
个体开始能够通过视觉、触觉等感官直接观察世界
自主学习和压缩信息
构建属于自己的记忆
这种知识存储在大脑中，而非基因里
这也是我们如今讨论的智能最主要的形式
一种依赖大脑功能的、个体可习得的智能
不过
当前的大语言模型虽然也在对数据进行压缩
但是马毅教授指出
它们的压缩方式与人类的认知过程
存在着本质区别
人类的语言本身
就是亿万年演化和大脑发展的产物
是我们用来编码通过感官获得的世界知识的代码
语言是对大脑中世界模型的抽象
是人类共享知识的一小部分
因为很多感官体验和隐性知识
是无法用语言表达的
而大语言模型所做的
是将这些已经是压缩后产物的文本
再次当作原始信号进行压缩
提取其中的统计结构和关联
这种方式或许能让模型记忆文本、生成文本
但是它跳过了语言与物理世界、感官体验的连接
因此很难称得上是理解
就像蒂姆·斯卡夫提到的
有些压缩方式能达到深层抽象的层次
而有些只是表面的语义提取
当前的大语言模型
更像是在进行后者
它们虽然能处理海量文本
但缺乏对世界的深层抽象理解
这也是为什么它们在需要抽象组合推理的任务中
表现糟糕的原因
马毅教授认为，从机制上看
当前大语言模型使用的
还是提取经验知识的那套逻辑
通过捕捉数据中的关联和低维结构
再将它应用到文本上
这种机制本身很难导向真正的理解
要理解真正的智能
我们还需要从智能的四个阶段说起
马毅教授在书中详细阐述了这四个阶段
分别是DNA层面的知识积累、个体大脑的经验学习、社会层面的知识共享
以及科学层面的抽象认知
这四个阶段虽然机制不同
比如DNA的知识传递依赖突变和选择
大脑的学习依赖感官和反馈
社会知识的积累依赖语言和文字
科学的进步依赖假设和演绎
但是它们都有一个共同的核心
那就是从数据中提取结构
捕捉可预测的规律
通过压缩、去噪、降维等方式积累知识
并且用于预测和决策
而简约性和自洽性这两大原则
贯穿于这四个阶段的始终
在科学出现之前
人类的知识积累主要依赖经验主义
通过观察、试错、积累
比如中医、印度传统医学
经过数千年的实践
积累了大量有效的知识
就像DNA的演化一样
虽然缺乏系统的组织
带有一定的偶然性
但确实能解决实际问题
但是大约在3000年前
人类的认知发生了一次质的飞跃
我们开始能够进行抽象思考
这种思考超越了纯粹的经验观察
比如，自然数的概念
我们明明只能数到有限的数字
却能意识到数数这个过程
可以无限进行下去
再比如几何学中两条平行线永不相交的公理
无限延伸本身就是一种无法通过经验观察验证的抽象概念
但人类却能理解并基于此构建整个几何体系
这种从经验到抽象的跃迁
正是科学诞生的基础
卡尔·波普尔曾经说过
科学是过度简化的艺术
这种简化不是简单的压缩
而是带有假设和演绎的抽象
马毅教授提出
这正是当前人工智能与人类智能的核心差距
当前的大模型擅长记忆和模拟经验数据的分布
但是人类能够通过抽象思考
提出超越数据的假设和理论
进行严谨的逻辑演绎
这才是理解的本质
而这个问题
也成为了人工智能领域的下一个核心挑战
压缩与抽象之间
究竟是否存在本质的区别呢？
如果存在，这种区别是什么呢？
我们如何让机器也具备抽象和演绎的能力呢？
这个问题
其实和图灵当年面对的什么是可计算的
以及如今仍未解决的P是否等于NP一样
是一个需要被形式化、被严谨探讨的基础科学问题
马毅教授认为
这正是智能从经验积累到科学认知的相变
也是真正的人工智能应该追求的目标
回顾1956年人工智能诞生时的最初设想
研究者们想要实现的
正是这种具备抽象思考和演绎能力的智能
而不是如今这种依赖数据和统计的经验型模型
那么，智能究竟是通用的
还是领域特异性的？
蒂姆·斯卡夫举了一个道路建设网络的例子
这个系统能建造道路
具备一定的适应性
但是它由于受限于材料和技术
只能建造特定类型的道路
这就引出了一个疑问
智能是否也受到领域的限制呢？
马毅教授回应道
道路建设网络只是一个特定的案例
而智能的不同阶段和形式
虽然在具体实现上存在差异
但是核心机制是共通的
那就是发现数据中的结构
区分随机与规律
而这正是简约性原则的体现
无论是DNA的演化、大脑的学习
还是科学的进步
本质上都是在寻找可压缩、可预测的结构
只是它们的实现方式
比如物理载体、优化机制、编码方式有所不同
有些是离散的
有些是连续的
有些可以用数学物理方程描述
有些则只能通过神经网络等形式存储
但是
这些差异并不影响核心原则的通用性
智能的核心是发现结构的能力
而非具体的领域知识
谈到这里，就不得不提到控制论
这个由诺伯特·维纳在20世纪40年代提出的概念
对理解智能系统有着深刻的启示
马毅教授指出，早期的控制论研究者
关注的是动物和人类的基础智能
大脑如何通过感知和行动的交互
快速构建世界模型
通过预测、试错和学习不断优化
但是很多人对控制论的理解过于狭隘
认为它只是关于控制
但实际上
控制论的核心是探索智能系统的必要特征
比如如何通过信息论记录信息
如何通过反馈控制纠正错误
如何通过博弈论优化决策
甚至如何处理非线性问题
这些都是一个自主智能系统必须具备的能力
遗憾的是
在过去十年的人工智能实践中
这些核心思想被逐渐遗忘了
而马毅教授认为
我们应该从这段历史中汲取经验
重新重视智能系统的本质特征
从信息论到编码率降低系统
马毅教授的研究经历了一个漫长的探索过程
作为控制论专业出身的学者
他早年曾经深入学习过通信、随机过程和信息论
这些知识在多年后成为了他研究智能本质的关键
当他意识到，基础智能的核心
是追求高维数据中的低维分布时
一个关键问题浮现了出来
如果有两个低维模型都能解释同一组数据
我们该如何选择呢？
比如
八个点既可以被看作是独立的零维点
也可以被看作是一条一维直线上的点
甚至是一个二维平面上的点
从传统的熵的角度来看
这些模型的体积都是零或无穷大
无法有效区分
这就迫使他转向了香农提出的有损编码理论
有损编码提供了一种更通用的体积度量方式
能够区分不同的低维模型
即使这些模型的支持集是退化的
如今非常流行的扩散去噪模型
本质上就是在做这件事
通过添加噪声构建道路
再通过去噪过程降低熵
最终收敛到数据的真实分布
但是马毅教授强调
记忆的构建不仅仅是找到数据分布
更重要的是组织分布
如果我们只是一味地追求最小的复杂度
比如柯尔莫哥洛夫复杂度
最终得到的代码会是随机的
而人类的大脑记忆是高度结构化的
不同类型的物体在皮层中有着清晰的组织
空间认知在海马体中有序存储
这种结构化的目的
是为了高效地访问和使用知识
我们需要在不同的场景下快速调用记忆
进行预测、生成和估计
因此，最大编码率的降低
不仅是要降低编码率以找到数据分布
更要将分布转化为结构化、有组织的表示
最大化编码率的降低幅度
从而实现高效的记忆访问
这也让我们想到了流形假设
自然数据往往分布在低维流形上
而几何深度学习的核心思想
就是将对称性和几何结构
作为归纳偏置融入模型
马毅教授的研究与这个思想不谋而合
他的四本书始终围绕着数据中的结构这个核心主题
在第一本关于3D视觉的著作中
他就强调了对称性在感知中的重要性
但他同时指出
当前很多所谓的3D理解模型
比如那些生成点云、网格或高斯泼溅的模型
其实并没有真正理解3D世界
它们只是在生成可供人类观察的视觉效果
而人类的3D理解是基于对物体、关系的认知
当我们看到一个场景时
大脑会自动识别出这是手、这是杯子、这是苹果
会理解物体之间的空间关系
而这些是当前模型完全做不到的
为了验证这一点
马毅教授团队一年前做了一项名为Eyes Wide Shot的测试
让当时最先进的多模态模型
来解决一些简单的空间推理问题
比如某个物体的左边是什么、空间中有多少个物体、什么东西在某个物体的后面等等
结果令人震惊
所有模型的表现都极其糟糕
大多数甚至不如随机猜测
只有Gemini和GPT的表现略高于随机水平
但远低于人类的理解能力
这背后的核心问题是
当前的模型缺乏人类大脑中那种结构化的3D世界模型
人类能够轻松在以自我为中心、以物体为中心和以环境为中心的参考系之间切换
而这种能力是实现具身智能、与世界交互的基础
如果没有这种结构化的模型
所谓的世界模型和具身AI都只是空谈
谈到编码率公式中的ε
马毅教授认为这是一个极其深刻的问题
他花了近30年才逐渐理解
在扩散去噪模型中
添加噪声正是ε的一种体现
本质上是构建道路
就像罗马帝国通过修路连接整个世界一样
噪声让模型能够遍历整个空间
再通过去噪过程找到数据的真实分布
但噪声还有另一个关键作用
即使我们观察到的流形上的点是有限的
噪声也能帮助这些点连接起来
形成连续的结构
就像渗流现象一样
当雨点落在地面上
要么是孤立的水滴
要么是一片湿润的区域
不存在中间状态，这就是一种相变
当数据的密度足够高
噪声会让我们意识到
用一个连续的平面来解释数据
比记忆中的每一个孤立的点
更简约、更经济
这或许正是抽象思考的起源
从有限的经验样本
跃升到对连续、通用结构的认知
这种对低维结构和简约性的追求
也解释了为什么很多非凸优化问题
在实际中并没有理论上那么难
传统的非线性优化理论认为
非凸问题往往存在大量的局部极小值
难以找到全局最优解
但是马毅教授在研究稀疏结构和低维结构时发现
那些来自自然数据的非凸问题
其目标函数往往具有高度的规律性和对称性
优化景观非常良性
没有停滞的临界点
没有过多的虚假局部极小值
甚至局部极小值都具有清晰的几何和统计意义
而且，维度越高
这种良性特征越明显
这就是所谓的维度之福
这也间接解释了
为什么梯度下降等简单算法
在训练深度神经网络时总能找到不错的解
因为深度网络本质上是在高维空间中寻找低维分布
其目标函数的景观是良性的
马毅教授进一步指出
智能的本质不是去解决最难的问题
而是先识别出那些容易学习、容易理解的结构
自然选择让生物优先学习最常见、最有用的知识
以最小的能量和努力获得最大的生存优势
这正是简约性原则的体现
科学的发展也是如此
从牛顿力学这样简单的模型开始
逐渐过渡到广义相对论、量子力学等更复杂的理论
因此，理解智能
应该从理解那些最常见、最简约的结构开始
而不是一味追求最坏情况下的理论边界
这也引出了深度学习中的一个关键现象
为什么超大模型往往能够自我正则化
泛化能力更好
还会出现双重下降的现象？
马毅教授解释道
深层网络的每一层本质上都是在执行压缩、去噪或收缩映射
即使模型被过度参数化
这些操作也会不断将解
推向数据的低维结构
比如
无论将一条一维直线嵌入到二维、三维还是百万维空间
只要每一层的操作都是向这条直线收缩
模型就不会过拟合
因为所有参数都在共同推动解
向低维结构收敛
就像幂迭代法总能找到主成分一样
因此，只要模型的核心是压缩和去噪
过度参数化不仅不会导致过拟合
反而能帮助模型更好地捕捉低维结构
那么
既然压缩和简约性原则如此强大
我们是否还需要归纳偏置呢？
马毅教授认为
归纳偏置不应该是经验性的魔法调味剂
而应该被形式化为第一性原理
比如，仅仅假设数据分布是低维的
就能推导出深度网络的核心架构
包括CRATE Transformer和混合专家MoE架构
如果我们还希望模型具有平移不变性
那么卷积结构就会自然地从这个假设中推导出来
因为卷积不是人为强加的
而是为了满足压缩+平移不变性这两个原则的必然结果
一个好的理论
应该基于少量清晰的归纳偏置
其余的都通过演绎推导得出
而不是依赖大量经验性的调整
这种基于第一性原理的方法
也为持续学习提供了新的思路
持续学习的核心挑战是
模型如何在不断接收新数据的同时
不忘记旧的知识
并且持续优化自己的世界模型
马毅教授认为
记忆的形成是一个编码过程
而预测和梦境则是解码过程
通过解码
我们可以验证记忆的准确性
如果基于记忆的预测与实际观察一致
说明记忆是可靠的
如果存在偏差，就需要调整记忆
但是与人工神经网络不同的是
人类和动物不需要直接测量外部世界的误差
就能校正记忆
这是一个闭环的自我校正过程
就像猫在捕猎时，即使偶尔失误
也能快速调整
这是因为它们的世界模型具有高度的自洽性
马毅教授和学生的研究发现
只要外部世界的数据分布具有足够的低维结构
即使感知过程存在噪声或信息损失
这种闭环式的自我校正仍然可以实现
因为低维结构提供了足够的约束
让大脑能够区分预测与观察的差异
从而持续优化记忆
这种机制本身就具有通用性
智能的通用性不在于积累了多少知识
而在于这种编码-解码-校正的闭环机制
任何科学理论都是可证伪的
都有其适用范围
但构建和修正理论的能力
才是智能的核心
基于这些理论
马毅教授团队提出了CRATE系列架构
取得了一系列突破性成果
比如，他们发现多头自注意力机制
可以被推导为编码率降低目标的梯度步
而多层感知机MLP
则可以作为稀疏化和特异化算子
这意味着
Transformer这种在实践中被偶然发现的架构
其实可以从第一性原理严格推导出来
这背后必然有其深层原因
Transformer的自注意力机制
本质上是在计算数据中的相关性和协方差
用这些信息来稀疏化、组织数据分布
ResNet的残差连接反映了迭代优化的本质
MOE则体现了聚类相似数据、区分不同数据的思想
这些成功的架构
都在某种程度上捕捉到了智能的核心原则
更重要的是，基于第一性原理的推导
不仅能解释现有架构
还能对其进行大幅简化和优化
马毅教授团队发现
很多现有架构中存在大量的冗余组件
通过理论分析可以剔除这些冗余
让架构更简洁、更高效
比如说
DINO是当前最先进的视觉表示预训练模型之一
基于对比学习
训练过程复杂，包含大量超参数
但马毅教授团队意识到
DINO的核心目标是捕捉数据中的结构
因此对其进行了大幅简化
剔除了数十个不必要的超参数
让架构复杂度降低了10倍
同时训练效率和性能都得到了提升
这项工作引起了Meta和Google团队的高度关注
目前他们正在尝试将这种简化架构进行大规模扩展
与ViT架构相比，CRATE不仅性能相当
更具有极强的可解释性
在CRATE中
每个注意力头、每个通道都能学到具有明确语义、统计和几何意义的视觉模式
比如专门识别动物腿部、耳朵、面部的通道
而这种清晰的功能分工在ViT中很难观察到
这是因为ViT等传统架构存在大量冗余
虽然也能学到有用的特征
但是这些特征被淹没在复杂的网络结构中
难以定位和解释
这也是为什么会有彩票假说
也就是网络中只有部分中奖的子网络在真正发挥作用
而其余部分是冗余的
而CRATE的每个组件都是为了实现特定的目标而设计的
因此不需要后续的剪枝、蒸馏等操作
天生就具有简洁性和可解释性
对于很多研究者关心的
编码率降低是否必须依赖数据空间的预测
或者重建损失这个问题
马毅教授回应道
编码率降低中的损失
是通过ε来控制的
它捕捉的是样本之间的连接关系
但是为了确保学到的分布
能够真实反映原始数据
解码过程是必要的
就像人类的预测和梦境一样
解码可以验证记忆的准确性
如果有条件直接在数据空间测量误差
可以直接使用，但在自主学习场景中
模型需要能够内部验证误差
而理论证明
在数据分布具有低维结构的前提下
这种自主验证是可以实现的
最后
对于想要了解更多马毅教授的研究、尝试构建这类原则性架构的工程师和研究者
马毅教授表示，团队的大部分架构
包括CRATE、TOSSED、简化版DINO等等
都已开源在GitHub上
虽然这些开源模型受限于学术资源
规模只达到了GPT-2或ImageNet-1K的级别
但是完整的代码和方法论都已公开
此外
他的著作《学习数据分布的深度表示》是系统学习这些理论的最佳入口
书中不仅有完整的理论体系
还有与实际任务的结合案例
目前
港大和伯克利的课程也在逐步公开相关的实践代码和教学资源
为研究者提供了从理论到实践的完整学习路径
总结一下，人工智能的发展
从早期的经验探索
正在逐步走向理论驱动的新阶段
马毅教授的研究让我们看到
智能并非神秘莫测的黑箱
而是可以通过简约性和自洽性等核心原则来解释、来形式化的数学问题
未来
随着这些理论的不断完善和实践
我们或许能够突破当前大模型的局限
构建出真正具备理解、抽象和演绎能力的智能系统
这不仅是人工智能的进步
更是人类对自身智能本质的深刻认知
感谢收看本期视频，我们下期再见
