大家好，这里是最佳拍档
最近
专注于 AI 领域的分析师 Alberto Romero 曝出
其实 OpenAI 的GPT-5 已经真实存在
推向大众创造不了相应的经济价值
才不公布
他在一篇逻辑链条极为完整的文章
《This Rumor About GPT-5 Changes Everything》中提出了这样的结论
并且指出
AI 厂商们几乎耗尽了可用于预训练的全部高质量数据源
这些顶尖的AI 厂商开始守护自己的宝贵知识
不再对外分享成果
因为假如有 3 亿人在使用你的 AI 产品
那短短一周的运营开支
就会直接让绝大多数企业资金链断裂
今天就来给大家分享一下这篇文章
本视频由AI播报
如果告诉大家，GPT-5 已经真实存在
各位会怎么想？
如果 GPT-5 不但真实存在
而且正在我们看不到的地方塑造世界
又该如何呢？
这里不妨提出这样的假设
OpenAI 已经开发出了 GPT-5
但是决定只在内部运行
因为这样的投资回报
要远高于将它发布给上千万 ChatGPT 用户
毕竟这样他们获得的回报就不只是金钱
而是其他更为宝贵的东西
本文将整理我所掌握的一切资料
尝试证明这个猜想的合理性
先让我澄清一下，这纯粹是个人猜测
所有证据都是公开透明的
并不存在任何泄密或者内幕传言之类的消息
事实上，这篇文章既是分享的结果
也是我构建理论的过程记录
再次重申
我并没有获取内部消息的权限
毕竟能接触到的人
肯定会受到保密协议的约束
唯一能够用来说服大家的
就是接下来的逻辑链条
当然，我的想法很可能大错而特错
如果读完全文
各位有什么意见或者反馈
也请在评论区中友好讨论
在讨论 GPT-5 之前
我们先要从同样未能如约亮相的 Anthropic Claude Opus 3.5 聊起
正如大家所知
三大 AI 研发机构 OpenAI、 Google DeepMind 还有 Anthropic
都发布了一系列搭配不同性价比组合的模型方案
OpenAI 拿出了 GPT-4o、GPT-4o mini 以及 o1、o1-mini 等
Google DeepMind 的阵容是 Gemini Ultra、Pro 以及 Flash
Anthropic 则带来了 Claude Opus、Sonnet 以及 Haiku
他们的目标非常明确
那就是迎合尽可能多的客户群体
有些企业愿意不计成本来追求更高的性能表现
也有一些企业更加关注成本效益
希望以相对低廉的价格享受接近顶尖的模型性能
另外一些公司则关注价格亲民、性能说得过去的解决方案
到这里，一切还算和谐顺畅
但是在 2024 年 10 月发生了一件怪事
当时大家都以为 Anthropic 会公布 Claude Opus 3.5
用来作为对 GPT-4o（2024 年 5 月推出）的回应
但是相反，他们在 10 月 22 日
只拿出了 Claude Sonnet 3.5 的更新版本（人们称之为 Sonnet 3.6）
（人们称之为 Sonnet 3.6）
于是问题来了，Opus 3.5 去哪了？
Anthropic 阵营似乎压根没有能够跟 GPT-4o 正面抗衡的选手
这可太奇怪了
下面来看当时大众讨论与 Opus 3.5 实际发布情况的具体时间表
10 月 28 日，我在帖子中表示
有传言称 Sonnet 3.6
其实是备受期待的 Opus 3.5 训练失败之后的某个中间检查点版本
同样是在 10 月 28 日
ClaudeAI subreddit 上出现了一篇文章称
Claude 3.5 Opus 已遭废弃
并且附有指出 Anthropic 模型页面的链接
可是截至今天
这个页面仍然没有只言片语提到过 Opus 3.5
有人猜测剔除 Opus 3.5 是一项战略性的举措
目的是避免在即将到来的融资轮之前
失去投资者们的信任
11 月 11 日
Anthropic 的 CEO Dario Amodei 在 Lex Fidman 的播客上
否认他们已经放弃 Opus 3.5
并且辟谣称，虽然没有确切的日期
但是据我们所知
Claude 3.5 Opus 的发布计划仍然存在
很谨慎、很含糊，但是意思很明确
11 月 13 日
彭博社发表评论证实了早先的传闻
经过训练之后
Anthropic 发现 3.5 Opus 在评估中的性能优于旧的版本
但是考虑到模型大小以及构建和运行的成本
其表现未能达到应有的水平
这可能也是 Dario 没有给出确切发布日期的理论依据
尽管 Opus 3.5 的训练顺利完成
但是最终结果却令人失望
请注意，其中的重点并不是绝对性能
而是相较于实际性能的成本投入
12 月 11 日
半导体专家 Dylan Patel 和他的 Semianalysis 团队
给出了最后一次反转
也终于把所有线索编织成了一个连续且合理的解释
Anthropic 完成了对 Claude 3.5 Opus 的训练
而且性能表现良好并进行了适当扩展
但是该公司最终并未发布
相反
该公司决定使用 Claude 3.5 Opus 来生成合成数据
并且进行奖励建模
借此在使用用户数据的同时
显著改进 Claude 3.5 Sonnet 的性能水平
简而言之
Anthropic 确实训练出了 Claude Opus 3.5
但是由于性能达不到内外部对Opus 3.5这个名头的期待
他们最终选择放弃
Dario 认为换种训练方式应该可以改善结果
所以称计划仍在继续
但是没有给出明确日期
彭博社则证实
Opus 3.5 的性能比现有模型更好
但是不足以证明其推理成本
即用户需要承担的使用价格的合理性
Dylan 和他的团队则从神秘的 Sonnet 3.6 与莫名失踪的 Opus 3.5 之间
发现了某种关联
那就是后者在公司内部被用于生成合成数据
用来改善前者的性能表现
于是我们整理出了这样的逻辑关系
使用功能强大、价格昂贵的模型来生成数据
借此提升其他功能稍弱、但是价格更为便宜的模型的性能
这样的过程被称为蒸馏
作为一类常规实践
蒸馏技术能够帮助 AI 厂商改进他们的小体量模型
顺利摆脱对于高成本预训练的过度依赖
蒸馏有多种实现方法
这里我们不做过多讨论
大家只需要明确一点
就是充当教师的强模型
会将学生模型从“小、便宜、快但弱”
转变为“小、便宜、快且强”
由此来看
蒸馏技术几乎让强模型成为一座金矿
Dylan 也解释了 Anthropic 使用 Opus 3.5
来帮助改进 Sonnet 3.6 的合理性
因为新版 Sonnet 与旧版相比
推理成本并没有发生巨大变化
但是模型性能却迎来了颠覆性的提升
因此
相较于直接发布蒸馏之后性价比更高的 3.5 Sonnet
3.5 Opus 确实成了一个在经济意义上非常尴尬的版本
接下来再回到成本问题
蒸馏可以降低推理成本
同时提高性能
而 Anthropic 之所以选择不发布 Opus 3.5
是因为除了性能未达预期以外
它在内部也确实能够发挥更大的价值
Dylan 认为
这也是开源社区能够快速追赶 GPT-4 的原因
因为各个开源大模型能够从 OpenAI 的这座富矿中汲取能量
于是结论就很明确了
Sonnet 3.6 不仅成本更低
而且已经能够代表最先进的水平
甚至超过了 GPT-4o
Anthropic 中端模型的表现优于 OpenAI 的旗舰产品
这大概率要归功于有 Opus 3.5 参与的蒸馏过程
当然也可能还有其他原因
毕竟 5 个月对于 AI 大模型来说已经是段很长的周期了
突然之间，人们意识到
高成本并不一定对应着高性能
OpenAI 掌门人 Sam Altman 也亲自发出警告
称“越大越好”的时代已经结束
可这也意味着
那帮顶尖 AI 厂商开始守护自己的宝贵知识
不再对外分享成果
参数数量不再是衡量性能的可靠指标
我们只能将关注点转移到基准性能上
最后一次正式披露参数规模的 OpenAI 模型
是 2020 年的 GPT-3
为 175B 参数
到了 2023 年 6 月
有会议称 GPT-4 将是一套混合专家模型
总共拥有大约 1.8 万亿参数
Semianalysis 随后在一份评估中具体证实了这一点
得出结论称 GPT-4 拥有 1.76 万亿参数
而时间已经来到 2023 年 7 月
直到一年半之后的 2024 年 12 月
专注于 AI 未来影响的 EpochAI 组织研究员 Ege Erdil 才估算出
一大批行业领先的 AI 模型
其中包括 GPT-4o 和 Sonnet 3.6
其实比 GPT-4 要小得多
但是GPT-4o 和 Sonnet 3.6在基准测试中的表现
均优于 GPT-4
当前的顶尖模型
例如原始 GPT-4o 以及 Claude 3.5 Sonnet
可能在规模上比 GPT-4 小一个数量级
其中 4o 拥有大约 200B 参数
3.5 Sonnet 约有 400B 参数
当然这只是我粗略得出的结论
实际情况可能在上下两倍之间浮动
他还深入解释了在 AI 厂商未公布任何架构细节的前提下
自己是如何得出这个数字的
但是这对本文讨论的问题并不重要
最关键的是一个答案正渐渐浮现
Anthropic 和 OpenAI 似乎都遵循着类似的轨迹
他们的最新模型不仅比上一代更强
而且更小也更便宜
我们基本可以肯定
Anthropic 是通过将 Opus 3.5 蒸馏成 Sonnet 3.6 来实现这个目标
那么 OpenAI 又是怎么做到的呢？
有人可能认为
Anthropic 选择蒸馏方法是因为他们遇到了一些特殊情况
即 Opus 3.5 的直接训练结果令人失望
但是事实上
其他厂商也基本走上了类似的道路
Google DeepMind 和 OpenAI 都报告
称其最新训练模型的性能低于预期
但是请注意
低于预期并不代表着性能更差
造成这种情况的具体原因我们姑且不论
毕竟原因可能是数据不足造成的收益递减、 Transformer 架构的固有局限性、 预训练 Scaling Law 停滞不前等等
总而言之
Anthropic 遇上的情况其实非常普遍
但是还记得彭博社的报道吗？
性能指标的好坏只取决于成本
Edge 就解释了具体的原因
ChatGPT或者GPT-4 热潮带来的需求激增
和生成式 AI 的加速普及
导致各个 AI 厂商承受着巨额的亏损
几乎无法正常经营
这种情况促使各方都迫切希望降低推理的成本
虽然训练只需要运行一次
但是推理成本却与用户数量和使用频率
成正比增长
假如有 3 亿人在使用你的 AI 产品
那短短一周的运营开支
就会直接让绝大多数企业资金链断裂
从这个角度看
OpenAI 的思考逻辑跟 Anthropic 肯定是完全相同的
蒸馏技术之所以有效
就是因为它能够将这两大现实挑战
转化成同一项优势
那就是通过为人们提供更小的模型
来解决推理成本问题
同时停止发布大体量模型
来避免因为性能达不到公众预期而遭受批评
Ege 认为
OpenAI 还可能选择了另外一种方法
那就是过训练
它的基本思路是在比最优计算量更多的数据之上
再训练一个小模型
当推理成为模型运行的大部分、或者核心成本来源时
最好在更多 token 上再训练较小的模型
但是现在来看
过训练这条路其实走不通
根据马斯克和 Ilya Sutskever 前段时间的说明
各家 AI 厂商几乎耗尽了可用来预训练的全部高质量数据源
于是只能再次回归蒸馏
Ego 总结称
我认为 GPT-4o 和 Claude 3.5 Sonnet
很可能都是从更大的模型当中蒸馏而来的
到目前为止
整个推测过程都让我们愈发的相信
OpenAI 正出于同样的原因
比如性能不佳或者成本控制
以同样的方式
比如蒸馏
重复着 Anthropic 在 Opus 3.5 上做过的一切
例如训练后不公布
那么open AI的类似模型在哪里
可能的名头又是什么呢
说到这里
我们已经完成了对Anthropic
Opus 3.5故事的回溯
再把从中得出的蒸馏方法转移到了 OpenAI 这边
认为二者都面临着类似的难题
自然很可能选择类似的解法
然而这套理论中又出现了新的障碍
那就是由于 OpenAI 是行业先驱
所以他们可能面临着 Anthropic 等竞争对手
未曾遇到过的关隘
其中一大核心障碍
就是训练 GPT-5 的硬件要求
Sonnet 3.6 的性能与 GPT-4o 相当
但是发布时间滞后了五个月
所以我们可以假设 GPT-5 恐怕性能虽然更强、 但是体量也要更大
于是对应着更高的训练成本与推理成本
也许整个训练周期要耗费 5 亿美元左右
甚至让人怀疑当前的硬件
到底能不能做得到
Ege 再次给出了重要指示
他认为能做到
但是也仅限于训练阶段
为 3 亿用户提供如此庞大的推理服务
则根本没有可能性
从理论上讲，即使只借助目前的硬件
也足以支撑起比 GPT-4 大得多的模型
比如 50 倍于 GPT-4 的巨型版本
拥有约 100 万亿参数
同时以每百万输出 token 3000 美元 和每秒 10 到 20 个 token 的速度
提供服务
然而要做到这一点
这些大模型就必须证明
自己确实能为客户创造相应的经济价值
很明显
哪怕是对微软、谷歌或者亚马逊来说
它们分别是 OpenAI、DeepMind 和 Anthropic 背后的金主
承担这个水平的推理成本都不具备合理性
那么 AI 厂商要如何解决这个问题呢？
思路很简单
要想将拥有数万亿参数的模型推向大众
就得证明能创造相应的经济价值
既然创造不了，那就不公布
于是乎
“比现有产品性能更好” 和“但没有先进到足以证明其巨额运行成本的合理性”
就成了两个并行的条件
事实上
此前《华尔街日报》报道 GPT-5 和彭博社报道 Opus 3.5 的时候
也都给出了惊人相似的一致结论
由于最终结果令人失望
厂商们决定将其保留在内部作为大型的“教师”模型
负责蒸馏出较小的“学生”模型
再将后者实际推向市场
于是
我们就得到了 Sonnet 3.6 和 GPT-4o及o1
又便宜又好的效果让用户们相当满意
所以哪怕大家仍然在期待着 Opus 3.5 和 GPT-5 的横空出世
也不会影响到 AI 厂商们靠现有服务赚得盆满钵满
说到这里
其实我还没有完全说服自己
虽然一切证据都与结论并不冲突
但是合理跟真相之间
仍然隔着十万八千里
所以接下来
我要再给大家补充点别的信息
还有其他证据表明
OpenAI 在以这种方式运营吗？
除了低于预期的性能和可能造成损失之外
他们还有什么理由要把 GPT-5 藏起来吗？
我们能从 OpenAI 高管们对于 GPT-5 的公开声明中
找到哪些蛛丝马迹吗？
他们一再推迟模型发布
难道不会给公司声誉造成风险吗？
毕竟
OpenAI 是 AI 革命的先驱力量
而 Anthropic 只要摸着石头过河就行
很多事情 Anthropic 可以做
并不代表 OpenAI 也能有样学样
说到钱
让我们来挖掘一点关于 OpenAI 和微软合作伙伴关系的相关细节
首先就是大家都知道的事实
AGI 条款
在 OpenAI 关于其组织结构的博文中
提出了五项治理条款
用来描述其运作方式
以及与非营利组织、董事会和微软之间的关系
其中第五条将 AGI 定义为
“在最具经济价值的工作上
拥有超越人类能力的高度自主系统”
并且确定一旦 OpenAI 董事会声称已经实现 AGI
“此类系统将被排除在与微软间的 IP 许可
及其他商业条款之外
现有条款内容仅适用于 AGI 之前的技术”
不用说
两家公司都不希望合作关系破裂
OpenAI 虽然设置了这一条
但是也会尽一切努力避免实施
其中一种方法就是推迟发布
可能被标记为 AGI 的系统
很多朋友会质疑
但是 GPT-5 不可能已经实现了 AGI 吧？
这里我就要聊聊第二个不为人知的秘辛了
OpenAI 和微软对于 AGI 设有一条秘密定义
虽然与科学目的无关
但是在法律上构成了二者合作关系的基础
那就是AGI 应该是一套
“可以产生至少 1000 亿美元利润”的 AI 系统
如果 OpenAI 以 GPT-5 尚未准备好为借口
将其私藏
那么除了控制成本和防止公众的强烈抨击之外
至少还能实现另外一个效果
避免声明 GPT-5 是否符合前面提到的这条 AGI 定义
虽然 1000 亿美元利润确实是一个恐怖的数字
但是没有什么能阻止雄心勃勃的客户
以它为基础来建立新的业务、赚取新的利润
而另一方面
我们也几乎可以肯定的是
如果 OpenAI 预计 GPT5 每年能够带来 1000 亿美元
大约合 7245.1 亿元人民币的经济性收入
那他们应该不会介意执行 AGI 条款
并且直接跟微软分道扬镳
大多数公众对于 OpenAI 不发布 GPT-5 的情况
都有如下假设
不发布 GPT-5
是因为性能还达不到预期
哪怕真的不够好
内部版本的 GPT-5 也大概率 比我们在当前市面上能接触到的大模型更好
毕竟一套不计成本、只求性能的模型
跟现在这些需要以低成本方式
服务 3 亿用户的模型之间
肯定存在着天壤之别
之前他们之所以允许我们访问模型
是因为他们需要普通用户的数据
但是现在情况不同了
他们甚至不单想要钱
那只是微软的目标
OpenAI 想要的是通用人工智能 AGI、想要超级人工智能 ASI
更想要青史留名、征服整个世界
感谢大家的耐心，文章已经接近尾声
相信看了这么多
我提出的论据已经基本指向一个可能性很高的结论
OpenAI 也许正在内部运行 GPT-5
就如同 Anthropic 在内部运行 Opus 3.5 一样
OpenAI 甚至根本不打算发布 GPT-5
能亮出来给公众看的最强成果
也就是 ChatGPT o 系列和 Claude Sonnet 系列模型了
随着 OpenAI 对于 Scaling Laws 的探索愈发深入
GPT-5 需要突破的预期门槛也越来越高
而且
现在就连我们的数据都没有多大价值了
训练新的基础模型
包括GPT-5、GPT-6 乃至之后的版本
对于 OpenAI 内部来说肯定是有意义的
只是不一定要作为产品推出
对于这家 AI 先驱来说
唯一重要的目标
就是继续为下一代模型产出更好的数据
从现在开始
这些基础模型可能会在后台运行
帮助其他模型实现单凭一己之力无法完成的壮举
这就如同一位隐居深山的世外高人
哪怕我们无缘得见
也终会看到其徒子徒孙在江湖上大放异彩
而且即使 GPT-5 最终发布
影响其实也并不大
毕竟到那个时候
OpenAI 和 Anthropic 肯定已经意识到了
他们掌握了绝对的领先地位
不必担心自己偶尔露出的一点高招
对其江湖地位构成威胁
可能正因为如此
OpenAI 才会在短短三个月之内
从 o1 发布到了 o3
后续还可能继续推出 o4 和 o5
同样的
他们也才会在社交媒体上表现得如此兴奋
因为他们找到了一种新的、更强大的生态闭环
所以，千万别以为
接近 AGI 意味着我们能够随意访问到越来越强大的AI 享受到越来越先进的自主技术
唯一可以相信的
就是他们的模型会越来越领先
而每一代新模型的推出
都是在为他们的技术火箭
添加新的喷射引擎
至于事实是否真的如此
就让时间给我们答案吧
