大家好，这里是最佳拍档，我是大飞
未来的算力规模要再增长100倍
这是黄仁勋在GTC2025上给出的一个预测数字
相信在如今这个时代
没有人会比他更相信算力永不眠的传说
在这次的GTC大会上
黄仁勋拿出了全新的Blackwell Ultra GPU和下一代Rubin架构
试图证明算力的需求还在持续激增
只是不知道这些算力能否被充分、合理地消耗掉
不管怎么说
我们先来看看这次GTC 2025
老黄又都说了些什么
首先要介绍的是Blackwell全家桶
去年英伟达发布了Blackwell架构
并且推出了GB200芯片
今年正式将名称改为Blackwell Ultra
从硬件构成来看
它是由两颗采用台积电N4P（5nm）工艺的Blackwell架构芯片
与Grace CPU封装在一起的
同时搭配了更为先进的12层堆叠的HBM3e内存
将显存直接提升到了288GB
相比之前有了大幅增长
而且，它还支持第五代NVLink
片间互联带宽可以达到1.8TB/s
而第一代的带宽只有160GB/s
凭借着存储的升级
Blackwell GPU在FP4精度算力上
能够达到15 PetaFLOPS
再基于Attention Acceleration机制
它的推理速度比Hopper架构芯片提升了2.5倍
为AI推理和训练等应用场景提供了更加强大的支持
基于Blackwell Ultra GPU
英伟达还推出了AI推理专用机柜Blackwell Ultra NVL72
这个机柜由18个计算托盘组成
每个计算托盘里都配置了4颗Blackwell Ultra GPU和2颗Grace CPU
算下来
整个机柜包含了72颗Blackwell Ultra GPU和36颗Grace CPU
这样的计算核心配置
使得机柜的显存达到了20TB
总带宽也高达576TB/s
此外
机柜还配备了9个NVLink交换机托盘
也就是18颗NVLink交换机芯片
节点间的NVLink带宽能够达到130TB/s
不仅如此，它还内置了72张CX-8网卡
提供14.4TB/s的带宽
并且搭配Quantum-X800 InfiniBand和Spectrum-X 800G以太网卡
大幅降低了网络延迟和抖动
可以有效支持大规模AI集群的运行
同时
机架整合了18张BlueField-3 DPU
用来增强多租户网络、安全性和数据加速
与前一代的产品GB200 NVL72相比
新一代的AI性能提升了1.5倍；
和Hopper架构的DGX机柜相比
新的NVL72能够为数据中心带来50倍增收的机会
就拿6710亿参数DeepSeek-R1的推理任务来说
基于H100每秒只能实现100 token
而采用Blackwell Ultra NVL72方案
每秒可以达到1000 token
于是完成同样的推理任务
H100需要1.5分钟
而新的NVL72仅需15秒
按照计划
Blackwell NVL72的相关产品会在2025年下半年上市
客户涵盖了服务器厂商、云厂、算力租赁服务商等多个领域
比如Cisco、Dell、AWS、Google Cloud、以及CoreWeave、Lambda、Yotta等等
在这次大会上
英伟达还提前预告了未来的“核弹”级GPU
Rubin芯片
按照英伟达的路线图规划
2026年即将上市基于Rubin架构的下一代GPU
以及更强的机柜Vera Rubin NVL144
Vera Rubin NVL144配备72颗Vera CPU和144颗Rubin GPU
采用288GB显存的HBM4芯片
显存带宽达到13TB/s
还搭配了第六代NVLink和CX9网卡
在性能方面
它的FP4精度推理算力达到了3.6 ExaFLOPS
FP8精度训练算力也达到了1.2 ExaFlOPS
性能是Blackwell Ultra NVL72的3.3倍
而到了2027年
还有更加强悍的Rubin Ultra NVL576机柜
它的FP4精度的推理和FP8精度的训练算力
分别是15 ExaFLOPS和5 ExaFLOPS
是Blackwell Ultra NVL72的14倍
说它是一头性能怪兽一点也不为过
对于那些对算力有较高需求
但是又不需要搭建超大规模AI集群的客户
英伟达还推出了基于Blackwell Ultra的DGX Super POD“超算工厂”。
这是一个即插即用的AI超算工厂
主要面向生成式AI、AI Agent和物理模拟等AI场景
能够满足从预训练、后训练到生产环境的全流程算力扩展需求
基于Blackwell Ultra定制的DGX Super POD有两个版本
一个是内置DGX GB300
也就是1个Grace CPU 加2个Blackwell Ultra GPU 的版本
这个版本总计288颗Grace CPU + 576颗Blackwell Ultra GPU
能够提供300TB的快速内存
在FP4精度下算力为11.5 ExaFLOPS；
另一个版本是内置DGX B300的
这个版本不含Grace CPU芯片
采用风冷系统
具有进一步的扩展空间
主要适用于普通的企业级数据中心
除了上述产品以外
英伟达在今年1月份的CES上
展示的概念性AI PC产品Project DIGITS
在GTC 2025大会上也有了正式名称
DGX Spark
它搭载了GB10芯片
在FP4精度下算力可以达到1 PetaFlops
内置128GB LPDDR5X内存
配备CX-7网卡和4TB NVMe存储
运行基于Linux定制的DGX OS操作系统
支持Pytorch等框架
并且预装了英伟达提供的一些基础AI软件开发工具
能够运行2000亿参数模型
整机尺寸和Mac mini相近
两台DGX Spark互联
还可以运行超过4000亿参数的模型
虽然它被归类为AI PC
但是本质上应该属于超算范畴
因此被放在了DGX产品系列中
不过，也有人对这款产品提出了质疑
认为它FP4的宣传性能可用性低
换算到FP16精度下
性能只能跟RTX 5070
甚至是售价250美元的Arc B580对标
性价比不高
同时
英伟达还推出了一款基于Blackwell Ultra的AI工作站——DGX Station
这个工作站内置了一颗Grace CPU和一颗Blackwell Ultra GPU
搭配784GB的统一内存、CX-8网卡
理论上能提供20 PetaFlops的AI算力
此外
考虑到很多人在AI推理中会使用RTX 4090这类产品的
英伟达在本次GTC大会上进一步加强了Blackwell和RTX系列的整合
推出了一系列内置GDDR7内存的AI PC相关GPU
产品覆盖桌面、笔记本以及数据中心等多个场景
在桌面GPU方面
有RTX PRO 6000 Blackwell工作站版、RTX PRO 6000 Blackwell Max-Q工作站版、RTX PRO 5000 、4500以及4000 Blackwell；
笔记本GPU方面
有RTX PRO 5000 、4000 、3000、2000 、1000 以及500 Blackwell；
数据中心GPU方面
则有NVIDIA RTX PRO 6000 Blackwell服务器版
如此丰富的产品SKU
体现出了英伟达在AI硬件市场的全面布局和强大的竞争力
我们再来看看英伟达在硅光芯片领域的进展
在此之前
业界一直对英伟达的CPO网络交换机产品充满期待
但是它却迟迟未上线
在本次GTC大会上
黄仁勋对此做出了解释
原来在数据中心中
大量使用光纤连接
光学网络的功耗相当于计算资源的10%，
光连接的成本直接影响着计算节点的Scale-Out网络和AI性能密度的提升
不过
这次英伟达一次性推出了Quantum-X和Spectrum-X 硅光共封芯片芯片
以及由它们衍生出来的三款交换机产品
分别是Quantum 3450-LD、Spectrum SN6810和Spectrum SN6800
其中
Quantum 3450-LD拥有144个800GB/s的端口
背板带宽达到115TB/s，采用液冷散热；
Spectrum SN6810拥有128个800GB/s端口
背板带宽为102.4TB/s
同样是液冷；
Spectrum SN6800则具备512个800GB/s端口
背板带宽高达409.6TB/s
也是液冷设计
这些产品都被归类到“NVIDIA Photonics”平台中
这是一个基于CPO合作伙伴生态共同研发的平台
根据英伟达给出的数据
整合光模块的Photonics交换机相比传统交换机
性能提升了3.5倍
部署效率也能提高1.3倍
扩展弹性更是提升了10倍以上
而在软件生态方面
英伟达如今已经将它看做是自己AI能力的一个核心
老黄在会上给了将近半个小时的时间来介绍
首先是Nvidia Dynamo
它是一个开源软件
专为推理、训练以及跨整个数据中心加速而设计
在现有Hopper架构上
它可以让标准Llama模型的性能翻倍
而对于DeepSeek等专门的推理模型
Dynamo的智能推理优化
更是能将每个GPU生成的token数量提升30倍以上
这主要得益于Dynamo分布式架构设计
它把大语言模型的不同计算阶段
也就是理解用户查询和生成最佳响应这两个过程
分配到了不同的GPU上进行处理
这样每个阶段都可以独立优化
进而提高了系统的吞吐量
加快了响应速度
在输入处理阶段，也就是预填充阶段
Dynamo会利用多组GPU并行
高效地分配资源来处理用户的输入
而在生成输出tokens的解码阶段
Dynamo则更加注重GPU的专注和连贯
通过优化GPU间的通信和资源分配
Dynamo确保了响应生成的连贯和高效
它一方面充分利用了NVL72架构的高带宽通信能力
最大化token的生成效率；
另一方面，通过“Smart Router”功能
将请求定向到已经缓存了相关KV键值的GPU上
避免了重复计算
大大提高了处理速度
由于避免了重复计算
一些GPU资源被释放出来
Dynamo还可以将这些空闲资源
动态分配给新的传入请求
凭借这一系列的创新设计
Dynamo最高可以让单个AI查询
无缝扩展到多达1000个GPU上
充分利用数据中心的资源
与此同时
用户每秒获得的token数量更多了
模型的响应速度也更快了
不过，虽然Dynamo是完全开源的
支持从PyTorch到Tensor RT的所有主流框架
但是目前只对英伟达的GPU有效果
通过Dynomo
英伟达显然是想构建起反击Groq等推理AISC芯片的防线
进一步巩固自己在AI推理领域的地位
在训练模型方面
英伟达在这次GTC上还推出了一款新模型Llama Nemotron
它是由Llama系列模型衍生而来
主打高效、准确
经过英伟达的特别微调
这款模型相较于Llama本体
在算法上进行了修剪优化
变得更加轻量级，只有48B参数
并且还具备了类似于o1的推理能力
与Claude 3.7和Grok 3一样
Llama Nemotron模型内置了推理能力的开关
用户可以根据自己的需求选择是否开启
这个系列分为入门级的Nano、中端的Super和旗舰Ultra三个档次
每一款都针对不同规模的企业需求进行了设计
为了训练这款模型
英伟达使用了自己生成的合成数据作为微调数据集
总数约60B token
不过与DeepSeek V3相比
它的训练效率还存在一定的差距
DeepSeek V3用了130万个H100小时完成了完整的训练
而仅有DeepSeek V3 1/15参数量的Llama Nemotron模型
只是微调过程，就用了36万H100小时
在推理效率上
Llama Nemotron Super 49B模型比上一代模型有了显著提升
其token吞吐量能够达到Llama 3 70B的5倍
在单个数据中心GPU下
它每秒可以吞吐3000 token以上
不过
和DeepSeek在开源周公布的数据相比
差距依然比较明显
应该说
英伟达开发Llama Nemotron推理模型
更多的还是为了布局AI的下一个未来
也就是AI Agent
为此
英伟达还启动了一个NVIDA AIQ项目
它直接提供了一个以Llama Nemotron推理模型为核心的AI Agent工作流
通过一套预配置的工作流模板
帮助开发者更容易地整合NVIDIA的技术和库
在此基础上
英伟达还推出了AI数据平台
可以把AI推理模型直接接到企业数据的系统上
形成一个针对企业数据的Deep Reasearch
另外
AIQ还非常强调可观察性和透明度机制
这样开发团队能够实时监控Agent的活动
并且基于性能数据持续的优化系统
在具身智能领域方面
英伟达这次首先公布了Cosmos模型的升级版
Cosmos是一个能通过现在画面
去预测未来画面的模型
它可以从文本/图像输入数据
生成详细的视频
并且通过将当前状态与动作相结合来预测场景的演变
因为这需要理解世界的物理因果规律
所以英伟达也称Cosmos是世界基础模型WFM
这次升级后的模型
包含了三部分能力
第一部分Cosmos Transfer
可以将结构化的视频文字输入转换为可控的真实感视频输出
凭空用文字产生大规模合成数据
这解决了当前具身智能最大的瓶颈
也就是数据不足的问题
第二部分Cosmos Predict 能够从多模态输入生成虚拟世界状态
支持多帧生成和动作轨迹预测
这意味着，给定起始和结束状态
模型可以生成合理的中间过程
也就是对核心物理世界的认知和构建能力
第三部分是Cosmos Reason
它是个开放且可完全定制的模型
具有时空感知能力
能通过思维链推理来理解视频数据
并且预测交互结果
从而提高规划行为和预测行为结果的能力
有了这三部分能力的叠加
Cosmos如今可以做到从图像到文字输入
再到机器人动作输出的完整链路
推出仅两个月
1X、Agility Robotics、Figure AI这三家头部公司就都开始在使用了
基于Cosmos
英伟达还训练了Isaac GR00T N1人形机器人基础模型
它采用双系统架构
有快速反应的“系统1“和深度推理的“系统2“。
由于经过全面微调
所以这个模型能够处理抓取、移动、双臂操作等通用任务
而且可以根据具体的机器人进行完全定制
机器人开发者可以用真实或者合成的数据
来进行后训练
比如说英伟达与谷歌DeepMind和迪士尼合作开发Newton物理引擎
就用了Isaac GR00T N1作为底座
驱动了一个非常少见的迪士尼BDX机器人
在具身智能算力支持方面
英伟达如今已经构建了三位一体的算力体系
从去年开始
老黄就在GTC上强调一个「三台计算机」的概念：
一台是DGX，就是大型GPU的服务器
它用来训练AI，包括具身智能
另一台AGX
是NVIDIA为边缘计算和自主系统设计的嵌入式计算平台
它用来具体在端侧部署AI
而第三台就是数据生成计算机Omniverse+Cosmos
如今
这套体系在本次GTC中又被老黄重提
而且特别提到
靠着这套算力系统能够诞生十亿级的机器人
靠着这套体系
英伟达实现了从算力、训练到部署的完整闭环
回顾这次GTC 2025大会，总的来说
Blackwell Ultra有些挤牙膏的味道
但是Rubin架构值得期待
另外对比硬件层面上的画饼充饥
这两年英伟达在软件层面上可以说是疯狂跑马圈地
已经完成了从模型优化、模型封装
到应用构建的全栈解决方案
如果再加上这次新增的Agent和AI infra
恐怕是想吃掉除了基础大模型以外的所有机会
可见老黄胃口之大
而在机器人市场
英伟达更是想要将模型、数据、算力三要素都抓在手里
垄断具身智能的上下游环节
其中每一个都可能是个千亿美元的市场
如果在硬件以外
英伟达再能通吃软件或者机器人市场中的任何一个
恐怕就真的没有人能撼动它的垄断地位了
不过
这场豪赌也是英伟达和黄仁勋从来没有经历过的
目前胜负依然难料
我们也只能静观其变
感谢大家收看本期视频
我们下期再见
