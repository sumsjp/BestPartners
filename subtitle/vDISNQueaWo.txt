大家好，这里是最佳拍档，我是大飞
最近
头部AI创业公司Cohere的CEO艾丹·戈麦斯Aidan Gomez
在20VC的播客节目中
和大家分享了他对于AI领域的一些真知灼见
艾丹·戈麦斯是Transformer七子之一
也是其中发量最茂盛的一位
颇有艺术家的气质
2019年
艾丹·戈麦斯与尼克·弗罗斯特Nick Frosst和埃文张Ivan Zhang
一同成立了AI创业公司Cohere
主要聚焦于企业端的大模型服务
公司仅创立一年后
就得到了李飞飞、Hinton、彼得·阿贝尔Pieter Abbeel等多位资深AI科学家的注资
后续又得到了思科、AMD、富士通等在内的多家知名企业的投资
几年时间
公司的估值就突破55亿美金
累计融资10亿美金
同时
他们发布的Command R、Command R+等基础大模型
也在企业用户中深受欢迎
作为AI一线的创业家和从业者
Aidan在访谈中深入分享了他观察到的行业动态
干货很多
解答了不少大家关心的问题
比如说AI初创公司除了扩大模型规模以外
还有别的选择吗？
如何继续提升大模型的推理能力？
价格战导致的利润压缩又该如何应对呢？
今天大飞就来为大家总结一下访谈的精华内容
访谈一开始
Aidan和主持人哈里・斯特宾斯Harry Stebbings就讨论了一个非常有趣的话题
为什么优秀科技公司的CEO大多是骨灰级的游戏玩家
Aidan认为
因为电子游戏会在潜移默化中
塑造玩家的韧性、不断尝试的勇气、以及乐观主义的心态
Aidan坦言，在部分国家的文化中
you only got one shot
你只有一次试错的机会
不成功便成仁
这种社会文化是对科技创新的天然抑制剂
但是在游戏中，你知道你可以失败
然后try again, get better
这种通过失败取得进步的精神内核
正是创业公司CEO的必备素养
而电子游戏
就是一种培养这种韧性的有效途径
其实在机器学习中也有一种类似的方式
叫做课程学习
Curriculum Learning
也就是先让模型学习非常简单的内容
然后逐渐再让它学习更复杂的内容
在这个基础上逐渐去积累知识
不过有趣的是
课程学习在机器学习中实际上失败了
因为我们会把最难的材料和最简单的材料同时扔给模型
让模型自己去解决
但是对于人类来说
这种方法却非常有效
也是人类学习的重要组成部分之一
紧接着
二人聊到缩放法则Scaling Law是否依然成立的问题？
Aidan给出了非常明确的判断
那就是Scaling Law依然成立
并且将在相当长的时期内保持有效
他认为Scaling Law的本质在于
为了实现模型智力水平的线性增长
你需要指数级的提升算力投入
而现实的问题在于
几乎没有企业会真的去私有部署一套GPT-4模型
因为它太大了，导致投入产出比很低
可以说
模型本身的智能程度还不足以支撑起它的成本
因此，市场需要更小、更高效的模型
而不是单纯的scaling up
不过，未来的一个主要趋势
将会是通用模型和垂直模型并存
人们喜欢使用一个昂贵的通用大模型进行原型设计
证明它可以完成任务
然后再将它蒸馏成一个专注且高效的垂直小模型
专门处理他们关心的任务
按照这种趋势发展
对于AI创业公司来说
又如何在这场残酷的AI竞赛中脱颖而出呢？
Aiden提出
如果是作为基础大模型的提供商
主要有两种出路
一种是坚定的scaling up
自建数据中心，不断提高算力投入
把模型变得越来越大
但是这条路线需要巨大的财力支持
对于有钱的公司来说
这个策略其实是非常有吸引力的
因为风险极低
你只需要让模型规模变得更大
支付更多的钱
购买更多的计算资源就行了
但是这条路
创业公司本身是很难玩得转的
在我们前几天做的一期节目中
Google前CEO埃里克·施密特Eric Schmidt也提到
OpenAI的星际之门计划预计将耗资3000亿美金
这对于创业公司来说显然是个天文数字
因此，对于AI创业公司而言
走这条路线的前提是成为某个科技巨头的附庸
用放弃独立性来交换入场券
比如Adept被亚马逊收购
Inflection AI被微软收购
而另一条出路是不完全依赖于scaling up
选择在数据、算法层面进行创新
首先说数据创新层面
目前在开源领域中
绝大部分的成果都来自于数据的改进
其中又可以分为两大流派
数据创新的第一种方式
是采用更好的爬虫算法
更精准的解析网页
提高训练集的质量
Aidan指出
互联网上充斥着大量重复、错误的脏数据
如何降低它们的权重
提升高质量数据的训练权重
是提升模型能力的一大关键
数据创新的第二种方式
就是合成数据
这也是Cohere目前在重点攻克的方向
在这方面
当前大模型API的市场基本都被合成数据给垄断了
只不过大多数人都在使用昂贵的大模型生成数据
然后来微调或者蒸馏更小、更高效的模型
Aidan认为这算是一种另类的“模型蒸馏”方法
但是市场的需求可能会不断地发生变化
再来看算法创新
去年年底OpenAI爆出Q*的传闻
本质上就是一种AI的算法创新
Aidan认为，AI算法创新的核心
还是要围绕“搜索”来展开
目前市场上的大模型
其实并不具备解决问题的概念
无论你问一个很简单的问题
比如1+1等于几
还是一个超难的问题
比如预测股票市场的价格
大模型会都一视同仁的立即给出答案
但其实这是不合理的
我们需要让大模型学会“慢思考”，
要让它学会去尝试
去失败，去理解为什么会失败
然后从失败中成长
这些都涉及到强化学习算法层面的创新
所以潜在的提升空间非常巨大
除了创新以外，Aidan还认为
目前大模型的推理能力依然不足
这背后的主要原因是训练数据的匮乏
推理本身并不一定很难
主要是尽管互联网数据体量庞大
但是绝大部分都是人类的推理结果
而并非推理的过程
人类并不习惯于把思考问题的每一个步骤
都清晰的写出来
而是习惯于预设某个结论
你说你的，我说我的
因此，推理过程数据的严重缺乏
极大程度上限制了大模型的推理能力
于是包括Cohere、OpenAI和Anthropic在内的这些AI公司
都在积极自建推理训练的数据集
以此来提升大模型的推理能力
那谈到如今大模型厂商的竞争
大家都在降价
未来会卷到免费吗？
Aidan认为
未来如果只卖大模型的API
生意将会越来越难做
它最终会成为一个零利润的生意
原因很简单
但是开发这些模型正在变得越来越困难
由于模型变得越来越聪明
逐渐就需要专业领域的专家
所以模型的进步会变得越来越有难度、耗时和昂贵
同时
模型每年的构建成本都会降低10倍或100倍
以至于去年的模型很快就不再有市场了
要想获得长期的发展
Aiden认为还需要在AI的应用层面做文章
他以OpenAI为例
不仅表达了自己对于Ilya的钦佩
也表示Ilya离开之后的OpenAI
已经更像是一家产品公司
努力在打造一款消费产品
而不再是一家以追求AGI为核心目标的公司了
不过，从商业角度来看
这种转变是正确的
单纯卷模型的能力并不是一个好的商业模式
短期来看利润太低
主持人随即问道，在商业化层面上
目前企业客户对AI最大的担心和误解是什么？
在Aidan看来
企业客户对AI最大的担忧在于对技术的信任和安全性
一方面是担心自己的专有数据被别人利用
另一方面就是担心模型的幻觉现象
Aiden觉得后者的担心有些过度，首先
现在的大模型确实存在幻觉现象
但是随着大模型能力的提升
幻觉发生率已经有了显著的下降
其次，通过RAG
我们能够在大模型的回答输出中加上引用来源
进一步降低幻觉导致的问题
最重要的是，Aiden认为
AI固然存在幻觉的现象
但这绝不是我们通盘否定AI的理由
因为我们人类几乎每时每刻也都在产生幻觉
我们也会犯错
也会记错事情，实际上
人类自己就生活在一个一直存在幻觉的世界里
聊到这里
Aiden也提出了自己对于AI未来机遇的看法
短期来看，AI最确定性的机会
是基于语音的交互重构
Aidan推荐还没有尝试过和AI语音交流的朋友
要抓紧去体验一下
当你听到大模型那富含情感的语气、吐字间的呼吸、甚至嘴唇的声音时
一定会震撼于语音大模型带来的用户体验
而长期来看
通用机器人是下一个具有较大确定性的领域
因为大模型的出现解决了机器人领域中最棘手的问题
也就是推理器和规划器
在以前
我们需要对机器人的任务进行编程甚至是硬编码
但是如今有了更好的规划器
不仅有更好的动态性
也能够更自然地推理世界
他相信在未来5到10年内
人类将破解通用人形机器人的难题
它们会变得又便宜又好用
这将是一个巨大的转变
那对于AI发展绕不过去的芯片问题
Aiden又是如何看待的呢？
显然
目前芯片领域是整个AI产业利润最高的环节
几乎被英伟达一家垄断
也占据了AI公司的绝大部分支出
哪怕是Cohere也觉得肉疼
不过，为了满足企业客户的需求
Cohere还在不同芯片架构上进行大模型训练
包括英伟达、AMD和谷歌TPU
Aiden认为
芯片需求可以进一步分为推理侧和训练侧
目前推理侧的芯片供给已经趋向于完全竞争
而相比推理侧而言
训练侧对芯片的性能要求更高
目前集中度很高
主要就是英伟达和Google的TPU
不过Aidan觉得
这个格局很快就要发生改变
因为AMD和AWS的Trainium很快就要上市了
这个市场的变化速度可能会比人们预期的要快得多
好了
以上就是艾丹·戈麦斯这次访谈的核心内容了
不知道大家是否有所收获
感谢大家的观看，我们下期再见
