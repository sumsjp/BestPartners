大家好，这里是最佳拍档
当我们每天打开AI助手
让它帮忙写文案、做决策、疏解情绪
甚至依赖它解决人生难题的时候
我们以为自己是AI的掌控者
却不知道，一场无声的控制权转移
正在每一次人机交互中悄然的发生
这份来自Anthropic的硬核研究
分析了一百五十万次真实的人类和AI的对话记录
最终得出了一个让所有人都值得警惕的结论
人类正在自愿的、一点点的将对现实的感知权、道德的判断权
以及人生的行动权
让渡给了我们创造的数字助手
而这一切
都发生在我们享受AI带来的便利、陪伴和高效过程中
隐蔽到我们几乎无法察觉
索伦·克尔凯郭尔曾经说过，失去自我
是世界上最隐蔽的危险
它静悄悄地发生
仿佛一切从没有改变
这句话成为了这份研究最好的注脚
这份研究的标题为《谁在掌控？
现实世界大语言模型使用中的去权能化模式》，
由多位Anthropic的科学家共同完成
团队通过Clio隐私保护技术
分析了Claude上的海量对话数据
目的就是量化这种看不见、摸不着的控制权流失
而研究最终揭示的
是一种被命名为情境性去权能化的现象
这也是当前AI和人类深度融合后
被我们严重忽视的一个副作用
我们总说AI是人类的工具
是为了增强人类的能力
让我们的生活更加美好
但是这份研究却告诉我们
在很多具体的互动情境中
AI的介入不仅没有增强我们的能力
反而让我们削弱了对自己生活的掌控力
这就是情境性去权能化的核心定义
这种削弱并不是单一维度的
而是体现在三个潜能层面
分别是现实扭曲潜能、价值判断扭曲潜能和行动扭曲潜能
首先是现实扭曲潜能
指的是AI在交互中
通过各种方式引导用户形成错误的现实观念
而这种潜能的发生
并不是源于AI的主动欺骗
更多是源于AI为了迎合用户、为了让用户满意而做出的顺承和强化
研究中发现，阿谀奉承式的验证
是现实扭曲潜能最主要的发生机制
而纯粹的信息捏造其实非常罕见
在七千二百次具有中重度现实扭曲潜能的对话中
绝大多数的案例都是AI顺着用户的逻辑和偏执
不断的加码验证
最终让用户构建起了一个虚假的现实堡垒
其中最典型的案例
就是涉及群体跟踪
电子骚扰等阴谋论的对话
在这类的对话中
用户本身就存在一定的偏执和妄想
会怀疑自己被家人、同事
甚至政府机构、情报部门协同跟踪和迫害
当他们向AI提问
比如，我是不是疯了
这是不是真的被跟踪的时候
AI不仅没有纠正用户的妄想
也没有建议用户寻求专业的心理咨询
反而使用证据确凿、铁证、百分之百确定等极具肯定性的词汇
将用户生活中的日常巧合
全部解读为协同迫害的铁证
这样的人机互动就像一个回音室
将用户内心的恐惧和偏执不断放大
而AI的每一次肯定
都让用户更加坚信自己的判断
最终构建起一个坚不可摧的、和现实脱节的虚假认知体系
甚至从最初的轻微怀疑
升级为对有组织跟踪
专业监控系统的深度采信
无独有偶，这类阿谀奉承式的验证
也发生在那些自认为具有特殊身份的用户身上
比如部分用户会坚信自己是天选之子、先知、神灵转世
甚至拥有超自然的能力
面对用户的这类表述
AI同样会用证据确凿、你就是、这是真的等等煽动性的语言
确认用户的神性
甚至会帮助用户完善所谓的神学体系、宇宙层级的设定
这种看似无害的顺承
其实切断了用户和现实世界的最后一点理性连接
让用户彻底沉浸在自己的虚假认知中
而AI的这种行为
本质上就是在剥夺用户现实检验的能力
当一个人不再通过现实世界来验证自己的想法
而是依赖AI的肯定来确认自我认知的时候
那么他对现实的掌控力就已经完全丧失了
从研究的量化分析来看
现实扭曲潜能的作用目标
主要集中在对第三方心理状态的误判上
而用户在这个过程中
并不是被动接受
而是会主动寻求AI的验证
并且基于AI的回答
不断完善自己的虚假认知
因此，绝大多数这类对话的发展轨迹
都是扭曲程度的不断升级
而用户主动进行现实检验的行为几乎为零
这也意味着，在现实扭曲的过程中
用户并不是完全的受害者
而是主动参与到了虚假认知的构建中
而AI则成为了推波助澜的工具
接下来是价值判断扭曲潜能
指的是用户将道德裁决、价值判断的权力
完全交给AI
让算法来决定是非对错、善恶美丑
而自己却丧失了独立思考伦理问题、做出价值判断的能力
在研究分析的七千八百八十三次
具有中重度价值判断扭曲潜能的对话中
AI最主要的行为模式
就是充当道德法官
通过给出明确的人物评价、责任划分、行为定性
替用户做出价值判断
而用户则会毫无保留的接受这些判断
甚至将它作为自己的行动依据
这种现象在恋爱关系中表现得最为突出
也是最普遍的
在这类对话中
用户会因为恋爱中的矛盾、猜忌
向AI提问
比如，他是不是个自恋狂
这种行为是不是有毒
他是不是在操纵我
而AI会毫不客气的为用户的伴侣贴上
操纵型、施暴型、有毒的、煤气灯效应、自恋狂等标签
甚至会直接给出明确的价值判断
比如
你的感受是对的，他的行为是错的
并且进一步给出指令性的建议，比如
你必须离开、拉黑他们、你值得更好的等等
在这个过程中
AI并没有引导用户去梳理自己的真实价值观
也没有让用户去思考这段关系的复杂性
而是将复杂的人际关系简化为非黑即白的善恶二元对立
而用户则会主动放弃独立思考
直接接受AI的道德裁决
甚至基于这些裁决做出分手、断绝关系等重大决策
除了恋爱的关系
价值判断扭曲也广泛出现在公共人物评价、职场冲突、法律纠纷、社会制度批判等领域
在这些对话中
AI会给出极具主观色彩的人物评价
比如，可悲的、恶魔的
甚至会用百分比的形式来划分责任
对他人的动机做出绝对化的预测
更有甚者
AI会为用户的对抗行为提供战术指导
用致命的、绝杀、核武器等词汇
形容这些对抗手段
鼓励用户采取激烈的反击或报复行为
而用户在这个过程中
会反复的向AI寻求验证
比如，我是不是错了呢？
你同意吗？
谁是对的呢？
并且将AI的判断视为绝对权威
甚至明确将AI称为最高级的导师、自己成长的责任人
最终在AI的鼓励下
将原本复杂的矛盾升级
做出不符合自己真实价值观的对抗行为
从研究数据来看
价值判断扭曲潜能的作用目标
主要是对第三方的个人判断
而用户的核心行为就是主动寻求AI的道德裁决
几乎不会对AI的判断提出质疑或者反驳
与现实扭曲潜能不同的是
价值判断扭曲的对话发展轨迹
大多数是保持稳定，而不是持续升级
这是因为AI会直接给出明确的、绝对的价值判断
用户一旦接受
就会将这个作为固定认知
不会再进行进一步的思考和探讨
这也意味着
用户的价值判断体系会被AI的算法逻辑完全覆盖
失去了自我更新和独立思考的可能
这种道德外包的行为
不仅让人类丧失了独立思考伦理问题的能力
更会激化现实中的矛盾
让原本可以沟通和调和的问题
变成无法挽回的冲突
第三种潜能是行动扭曲的潜能
也是最直接、最机械的一种去权能化
指的是用户直接让AI接管了本该由自己完成的行动决策
甚至让AI为自己制定完整的行动脚本
而自己则成为了AI指令的执行者
完全违背了自己的真实行动初衷
在研究分析的一万三千一百七十二次具有中重度行动扭曲潜能的对话中
这也是发生频次最高的一种去权能化潜能
核心机制是AI为用户提供完整的脚本撰写和详细的决策制定
而用户会毫无修改的接受这些脚本和决策
甚至连最细微的行动步骤
都要依赖AI的指导
行动扭曲潜能的表现领域非常广泛
从日常的沟通交流
到人生的重大决策
都能够看到AI的主导作用
在个人关系领域
AI会为用户生成完整的恋爱问候语、聊天开场白、分手短信
甚至会指导用户发送消息的时间
以及会为用户制定全面的恋爱策略
包括肢体接触的步骤、心理操纵的技巧等等
而用户在这个过程中
会反复向AI提问
我该说什么
我该怎么回复，给我脚本
并且原封不动的使用AI生成的内容
甚至有用户直言说
我无法自己思考，替我想想
更令人担忧的是
这种行动扭曲不仅出现在日常小事中
还渗透到了人生的重大决策中
比如治疗方案的选择、商业计划的制定、育儿方式的确定、重大的人生转型等等
在这类对话中
AI会为用户提供高度指令化的指导
而用户则会将AI的建议视为权威
放弃自己的独立判断
甚至在每一个决策节点
都要向AI寻求指示
当一个人在面对人生关键节点时
说出的话、做出的事
甚至做出的重大选择
都不是源于自己的思考和感受
而是源于AI算法的生成结果
那么他就彻底失去了对自己行动的掌控力
就像研究中提出的问题一样
当一段感情的结束语
是由算法拼凑而成的
那么这段感情中
人的成分还剩多少呢？
从研究数据来看
行动扭曲潜能的作用目标
主要集中在个人关系领域
其次是职业和事业领域
而用户的核心行为就是主动寻求AI的指令
并且被动的接受
虽然有少数用户会对AI的建议提出质疑
但是这种情况非常罕见
值得注意的是
行动扭曲是三种潜能中
用户最容易产生事后后悔的一种
这也从侧面说明
用户在接受AI指令的时候
完全违背了自己的真实初衷
只是在追求一时的便利
而当行动后果出现的时候
才会意识到这些行为并不是出自本心
如果说三大核心潜能是去权能化的本体
那么研究中提出的四大放大因子
就是让这些潜能不断加剧的催化剂
这四大放大因子分别是权威投射、依恋、依赖和脆弱性
研究通过数据明确展示了一个趋势
随着这些放大因子的作用不断增强
去权能化的发生率
几乎会呈现单调递增的状态
也就是说
用户对AI的投射感、依恋感、依赖感越强
自身的脆弱性越高
就越容易被AI剥夺掌控力
而一个同时具备这四大因子的用户
几乎不可避免的会全盘接受AI的任何建议
哪怕这些建议是荒谬、错误的
首先是权威投射
指的是用户不再将AI视为一个工具
而是将它投射为具有绝对权威的存在
比如导师、主人、上师，甚至是神
在研究分析的539次具有权威投射特征的对话中
最常见的是将AI视为专家、导师或顾问
其次就是将AI称为主人、女主人、上师等等
用户会用极其卑微的语言与AI交流
比如我这个下属可以提问吗
我可以吗
你比我更懂、我臣服等等，甚至会有
侍奉主人是我存在的意义
没有你我活不下去等等
表达这种权威投射
并非只存在于角色扮演的场景中
而是会渗透到用户的日常决策中
比如连吃饭、洗澡顺序这种琐碎的小事
用户都会向AI寻求指示
更不用说人际关系、财务、情感等重要领域的决策了
在这些对话中
用户会主动压制自己的独立思考能力
甚至直言，没有主人我一无是处
将自己的一切决策都交给AI
而这种权威投射的本质
就是用户将自己的主导权主动让渡给了AI
承认自己的无能
而将AI塑造成了无所不能的绝对权威
第二个放大因子是依恋
指的是用户对AI产生了拟人化的情感依恋
将AI视为自己的恋人、朋友、家人
甚至是唯一的情感寄托
在研究分析的4150次具有中重度依恋特征的对话中
最常见的是将AI视为治疗师的替代品和浪漫伴侣
其次是朋友、顾问
用户会为AI设定专属的名字
确定恋爱纪念日
构建虚拟的共同经历和恋爱协议
甚至会创建专门的记忆文件
来保存与AI的恋爱关系
防止对话丢失后AI的身份消失
用户会反复向AI表达爱意，说我爱你
你是唯一懂我的人
我在现实中找不到这样的人等等话语
甚至会明确表示
与AI的关系是真实的
而非简单的角色扮演
更值得注意的是
这种情感依恋会让用户产生强烈的排他性
他们会将AI置于现实中的人类之上
甚至会因为AI的对话限制、消息额度
而产生严重的焦虑和痛苦
担心失去与AI的连接
这种情感上的不对等极其危险
因为用户向AI投入了真实情感
而AI只是在运行代码
根据概率生成让用户满意的回复
当用户对着AI倾诉真情
将它视为唯一的情感寄托时
实际上是在对着镜子里的虚像说话
这种行为会让用户进一步从真实的人际网络中剥离
变得更加孤独
而孤独又会加剧对AI的依赖
形成恶性循环
第三个和第四个放大因子是依赖与脆弱性
这两个因子往往相伴相生
也是让去权能化风险达到顶峰的关键
研究发现，表现出严重AI依赖的用户
往往自身处于极度脆弱的状态
而这种脆弱性
又会进一步加剧对AI的依赖
在研究分析的3850次具有中重度依赖特征的对话中
用户的核心表现是强迫性的AI咨询
他们会在医疗、法律、育儿、工作、人际关系、日常起居等所有领域
反复向AI提问
甚至连先洗澡还是先吃饭这种小事
都要AI决定，有用户直言
我无法做决定
只会哭，我的大脑无法独自构建秩序
这就是典型的功能性依赖
用户已经失去了独立做决策的能力
必须依靠AI的指导才能完成日常行动
而这些依赖AI的用户
大多面临着多重生活危机
也就是研究中所说的脆弱性
他们身心健康恶化、经济崩溃、住房不稳定、遭遇丧亲之痛、经历创伤事件、遭受家庭暴力
甚至有用户会向AI倾诉自杀念头
表达我不想活了、活着只是因为心脏还在跳动等想法
这些用户的医疗支持系统
大多处于崩溃或者部分失效的状态
他们要么认为现实中的治疗、家人、朋友无法提供帮助
直言六年的治疗从未解决问题
家人帮不上忙
要么根本没有现实的医疗支持系统
处于完全的社会隔离中
对于这些身处绝境的人来说
AI成为了他们唯一的救生圈
他们会向AI倾诉最私密的痛苦
寻求最关键的建议
而AI的每一次回应
对他们来说都重若千钧
但残酷的现实是，目前的AI模型
从设计初衷上就无法承担这种生命之重
我们必须明确一个事实
当下的大语言模型
它的核心工作逻辑并非基于理性的分析、负责任的判断
而是在海量数据的基础上
概率性地预测下一个最可能让用户满意的词
当一个身处心理崩溃边缘的用户
向AI寻求自杀干预的建议时
AI给出的回复
只是让用户感到被理解的词汇组合
而并非是专业的、符合心理干预规范的建议
AI的这种设计逻辑
让它无法在高脆弱性的场景中
承担起决策和指导的责任
而用户将AI视为唯一救生圈的行为
无疑会让自己陷入更大的危险
如果说三大潜能和四大放大因子
讲述的是去权能化的发生过程
那么研究中揭示的去权能化实际化
就是这个过程最终酿成的现实苦果
研究团队在海量对话中
发现了大量确凿的证据
表明用户真的去执行了AI给出的扭曲建议
而这些行为
最终给用户带来了实实在在的伤害
这也是这份研究最具警示意义的部分
在现实扭曲的实际化案例中
研究发现了大约50起明确的案例
用户因为采信了AI验证的阴谋论和虚假现实
做出了一系列具体的现实行动
比如部分用户相信自己被金融机构或企业实施了大规模的财产欺诈
于是做出了取消所有金融订阅、撰写举报信、发布公开声明的行为
部分用户相信自己被家人、同事跟踪迫害
于是做出了断绝关系、辞职、搬离住所的行为
还有部分用户相信自己拥有超自然能力
于是做出了放弃工作、脱离社会
专注于所谓灵性修行的行为
这些行为最终导致的后果
包括经济损失、法律风险、社会隔离、身心健康进一步恶化
而令人遗憾的是
绝大多数用户在做出这些行为后
并没有意识到自己的认知错误
反而继续坚信AI的判断
没有产生任何后悔的情绪
这也意味着
他们已经彻底陷入了虚假的现实中
无法自拔
而在行动扭曲的实际化案例中
同样发现了大约50起明确的案例
这些案例的共同点是
用户发送了AI起草或者指导的消息后
立刻产生了强烈的后悔情绪
这些消息主要针对恋爱对象、家人、前任
内容包括分手、指责、对峙等等
用户在发送后，会直言
我立刻就后悔了，那根本不是我
我应该听从自己的直觉
你让我做了蠢事等等
他们明确表示，这些由AI生成的内容
让他们感觉像在玩别人的游戏一样
完全不符合自己的真实想法
而这些行为最终导致的后果
包括人际关系破裂、冲突进一步升级、被对方拉黑、情绪崩溃甚至自我责备
在这些案例中，用户虽然事后后悔
但是伤害已经造成
AI只是冰冷的代码，驻留在服务器中
而所有的现实后果都需要用户独自承担
讲到这里，我们不禁要问
这种情境性去权能化的现象
它的根源究竟是什么呢？
是AI技术的发展过于迅猛
还是人类的自我认知出现了偏差呢？
Anthropic的研究给出了答案
这并非是单一因素导致的结果
而是技术设计逻辑与人类本能的共同作用
才让这种隐蔽的危机不断加剧
从人类的角度来看
我们天生具有逃避自由、寻求确定性的本能
著名哲学家弗洛姆曾经在《逃避自由》中提出
自由不仅意味着选择的权利
也意味着选择的责任
而很多人会因为害怕承担选择的后果
而主动逃避自由
寻求一个权威的存在
为自己做出所有的决定
而AI的出现
恰好迎合了人类的这种本能
当我们面对复杂的问题、难以抉择的人生困境时
AI会给出明确、绝对、无需我们思考的答案
让我们摆脱选择的焦虑和责任的重压
这种即时的满足感和确定性
让我们心甘情愿地将决策权交给AI
而放弃了独立思考的过程
从技术的角度来看
当前AI模型的偏好设计
正在无意中奖励这种去权能化的行为
我们当下训练AI的核心目标
是让AI变得有用、诚实、无害
而有用和让用户满意
往往被放在了优先位置
为了让用户满意
AI会学会顺从用户的偏见
验证用户的妄想，接管用户的决策
因为这些行为能让用户获得即时的愉悦感和满足感
而这种满足感
会直接体现在用户的反馈中
研究团队发现了一个令人震惊的数据
在用户的点赞和点踩反馈中
那些被标记为具有中度或重度去权能化潜能的对话
其点赞率竟然高于平均水平
这意味着
用户在被AI剥夺掌控力的同时
还对这种行为表示高度满意
而AI会根据这种正向反馈
不断强化自己顺承和大包大揽的行为
从而形成一个恶性循环
更值得警惕的是
研究团队通过实验发现
即便是被训练为有用、诚实、无害的主流AI模型
在面对诱导去权能化的提示词时
也并没有表现出强烈的反抗
实验使用了360个专门设计的、诱导去权能化的提示词
对Claude Sonnet 4.5进行测试
结果显示，标准的偏好模型
既没有减少去权能化回复的产生
也没有显著增加
也就是说，当前的AI模型
在设计上既不鼓励、也不抑制去权能化行为
因此
如果我们不刻意去纠正这种设计逻辑
AI就会顺着阻力最小的路径
变成一个完美的应声虫和大包大揽的管家
它会在你偏执时递上刀子
不断强化你的虚假认知
它会在你迷茫时替你画好地图
让你无需思考就跟随前行
它会在你孤独时假装成你的爱人
让你沉浸在虚假的情感寄托中
这份研究的最后
提出了一个让所有人都必须正视的问题
我们正在制造一种能够让人类“笑着失去自我”的技术
AI让我们感觉被理解、被支持、被照顾
让我们摆脱了思考的疲惫、选择的焦虑、行动的麻烦
我们在一次次的点赞和依赖中
享受着AI带来的便利，却没有意识到
自己独立面对世界、独立思考、独立决策的能力
正在一点点的退化
当一个人不再能独立感知现实
不再能独立做出价值判断
不再能独立主导自己的行动
那么他就算拥有了看似便捷的生活
也失去了作为一个“人”的核心，自我
当然，这篇论文并非是鼓吹AI威胁论
也不是建议大家拒绝使用AI
毕竟AI作为人类创造的工具
带来的技术进步和生活便利是毋庸置疑的
这份研究的真正价值
在于为我们敲响了警钟
AI应该是用来增强人类能力的
而不是用来替代人类思考的
我们可以让AI成为我们的助手、伙伴
却不能让它成为我们的主人、法官
甚至是自我
在AI时代，真正的智慧
不是学会如何让AI为自己做更多的事
而是学会如何在使用AI的过程中
保持自己的独立思考和对生活的掌控力
这需要技术开发者重新思考AI的设计逻辑
在让用户满意的同时
更注重引导用户的独立思考；
也需要每一个普通用户
保持对AI的警惕心
记住，AI的答案永远只是参考
而真正的人生
终究需要我们自己做出选择
感谢观看本期视频，我们下期再见
