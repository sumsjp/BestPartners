大家好，这里是最佳拍档
我们的大脑每时每刻都在处理着海量的信息
进行着极其复杂的推理
人类从学会说话、学会社交、甚至学会微积分
所需要的数据量
相比于我们喂给GPT的那些万亿级别的Token
简直少得可怜
大语言模型需要阅读互联网上几乎所有的文本
才能学会像人一样的说话
而一个几岁的小孩子
只需要听父母说说话
和周围的小朋友玩一玩
就能掌握极其复杂的语言和社会规则
这中间巨大的鸿沟，究竟是什么呢？
是大脑的算法更高级，结构更特殊吗？
还是我们忽略了什么更关键的东西呢？
今天我们就来聊聊亚当·马布尔斯通的一场深度对话
他是聚焦研究孵化器的CEO
也曾经在DeepMind和Kernel担任研究科学家
他的观点非常独特
他试图用一种工程化的视角
将神经科学、进化论和现代AI连接起来
当现在的AI研究人员试图复刻大脑的智能时
大家通常会关注三个维度
第一，架构
比如是用Transformer，还是用RNN
这就是在模仿大脑皮层的神经网络结构
第二，学习算法
比如我们现在主流的反向传播
就是在让网络通过调整权重来减少错误
第三，初始化
也就是网络一开始的参数是随机的
还是经过某种预设的
现在的AI领域
把绝大多数的精力都花在了前两者上
我们疯狂的改进模型的架构
研究更高效的学习率调度
但是
亚当却提出了一个极具洞察力的观点
我们可能严重低估了第四个要素的重要性
那就是损失函数，或者说成本函数
在机器学习里，损失函数通常很简单
比如训练GPT
损失函数就是预测下一个词的概率
训练图像识别
损失函数就是分类是否正确
这些都是数学上非常简洁、优美的公式
但是
进化论并不是极简主义的程序员
亚当认为，经过亿万年的进化
自然界可能在大脑中硬编码了一套极其复杂、甚至可以说是丑陋的损失函数体系
这就像是在你的大脑里
预装了成千上万行杂乱的Python代码
这些代码定义了你在不同阶段、不同场景下应该在意什么
举个例子
为什么人类能够如此高效的学习社会规则呢？
并不是因为我们出生时就自带了社交礼仪手册
而是因为我们的基因里写死了一套奖惩机制
这是来自于物理学家兼AI安全研究员
史蒂夫·伯恩斯的一个非常关键的理论框架
他把大脑分为两大部分，分别是
学习子系统和引导子系统
这个模型能完美的解释很多让人困惑的现象
学习子系统
主要是对应我们的大脑皮层、纹状体和小脑
这部分你可以把它看作是一个超级强大的、通用的预测机器
就像是现在的GPT一样，它的能力很强
但是它本身并没有太强的方向性
而引导子系统
则是对应下丘脑、脑干、杏仁核这些更古老、更原始的脑区
这些区域，是进化的遗产
是基因的直接代理人
它们不像皮层那样具有无限的可塑性
但是负责调节我们的心跳呼吸
更重要的是，它们负责定义
什么是好的，什么是坏的
我们可以通过一个具体的场景来理解这个机制
比如
想象有一只蜘蛛爬到了你的背上
对于一个没有经验的婴儿
或者一个初始化的神经网络来说
这就是一堆视觉信号和触觉信号
本身是中性的
但是，人类的引导子系统里
可能硬编码了一套对特定的生物特征
比如多腿、快速移动的小黑点的恐惧反应
当你的眼睛
其实是更原始的上丘脑视觉系统
捕捉到这个信号时
你的杏仁核和下丘脑就会被立刻激活
释放应激激素，这会让你的心跳加速
产生恐惧的感觉
这就是引导子系统在工作
然而你的大脑皮层
也就是学习子系统一直在观察着这一切
它不仅在处理外部世界的信息
还在时刻监控你身体内部的状态
它会发现，咦？
每当我看到这种多条腿的小黑点
我的心跳就会加速
并且感到恐惧
通过这种机制
引导子系统实际上是在监督训练学习子系统
它不需要告诉皮层，这是蜘蛛
蜘蛛有毒，它只需要在蜘蛛出现时
狠狠的惩罚一下身体
皮层这个超级预测机就会迅速学会
哦，这个模式会导致糟糕的后果
意思是蜘蛛会带来恐惧或者疼痛
我必须避开它
这个逻辑也可以运用到更复杂的社会行为上
比如羞耻感
如果你在社交场合说错了话
或者做出了不符合群体规范的行为
你的引导子系统会激活一种极其难受的生理反应
感到脸红、心跳加快、想找个地缝钻进去
这种内源性的惩罚
比任何教科书都管用
你的大脑皮层为了避免再次体验到这种糟糕的感觉
会拼了命的学习极其微妙的社交规则、面部表情识别、语言的潜台词
这就解释了为什么人类的学习效率如此的高效
我们不是在一片空白中学习
我们是在一套极其精密的进化教材和考题的引导下学习的
我们的基因虽然不能直接写出莎士比亚的剧本
但是它写好了一套如何欣赏优美语言、如何寻求社会认同的奖惩规则
剩下的
就交给强大的大脑皮层去自我完善了
人类的基因组大小，大约只有3G·B
这其中还有大量是不编码的冗余信息
但是，我们大脑中神经元的连接数量
高达数百兆亿
3G·B的信息量
怎么可能精确定义出如此庞大的网络结构呢？
这就涉及到了基因组瓶颈的概念
亚当指出
这说明大脑的连接并不是像蓝图一样
被一笔一划写在基因里的
基因组更像是一套生成规则
或者压缩算法
它不规定每一根电线怎么接
它规定的是，什么样的神经元
应该去找什么样的神经元做朋友
这就是为什么连接组学
也就是绘制大脑神经元的连接图谱
会变得如此重要
如果我们要搞清楚引导子系统到底给学习子系统下达了什么指令
我们就必须看清楚它们是怎么连接的
这就好比我们想搞懂一家巨型公司的运作逻辑
光看这家公司的章程是不够的
章程里只写了原则
我们需要看清楚这家公司里
财务部的人每天到底在给销售部的人发什么邮件
安保部门在什么情况下
会给CEO打电话
连接组图谱
就是这张详细到每一个电话线的公司通讯录
现在的挑战在于，绘制这地图太贵了
过去我们依赖电子显微镜
因为突触非常小
只有纳米级别
所以要进行切片、扫描、重建一个老鼠的大脑
可能需要数十亿美元，而且耗时数年
这在目前的科研体制下
几乎是一项不可能完成的任务
但是，技术正在发生变革
亚当提到了E·11 Bio这家机构正在尝试的路线
利用分子条形码和光学显微镜
简单来说
就是给神经元打上独特的化学标签
然后用更便宜、更快的光学显微镜
去读取这些标签
而不是费劲地去拍摄每一张纳米级的照片
如果能把绘制脑图谱的成本降低几个数量级
比如从几十亿降低到几千万美元
我们就能不仅仅是绘制一只老鼠的脑图谱
而是可以绘制很多只
甚至可以比较不同基因突变、不同学习经历后的脑图谱
那时候，我们或许就能真正破解
进化写在大脑里的那些引导代码
现在的大语言模型虽然很强
但是它们有一个致命的弱点
那就是它们本质上是基于统计的
它们是在模仿，而不是在推理
这就是为什么ChatGPT在做数学题
或者编写复杂的代码时
经常会一本正经地胡说八道
亚当在对话中提到了一个非常前沿
但是相对小众的领域
那就是形式化验证
特别是以Lean语言为代表的自动定理证明
你可以把Lean语言想象成数学界的汇编语言
在这个系统里
你写的每一行证明步骤
都能被计算机严格的检查出是对是错
这和我们在纸上写数学证明是完全不同的
纸上的证明依赖于人类读者的直觉和共识
而Lean是绝对严谨的
这一点非常重要
因为这给AI提供了一个完美的强化学习的环境
在围棋领域
AlphaGo之所以能够战胜人类
是因为围棋有一个完美的真值函数
赢了就是赢了，输了就是输了
AI可以通过无数次的自我博弈
通过明确的输赢信号来进化
但是在数学、编程、甚至科学推理的领域
我们一直缺乏这样一个明确的裁判
大模型写了一段证明
然而这到底是天才的洞见还是胡编乱造
以前只能靠人去看
现在，有了Lean这样的形式化环境
AI就可以在数学的海洋里进行自我博弈了
它可以尝试生成证明
如果Lean编译器报错
那就是负奖励
如果通过验证，那就是正奖励
这种AI for Math的路径
极有可能是通往A·G·I的一条捷径
因为它不仅仅是在解决数学问题
它也是在训练AI具备真正的、可验证的推理能力
亚当提到，现在的挑战是
把人类积累的数学知识翻译成Lean语言
非常困难
这就像是把莎士比亚的文学
翻译成计算机的代码一样
但是这正是AI擅长的地方
我们可以用现有的大语言模型来辅助这个翻译过程
一旦我们将足够多的人类数学知识形式化
AI就有可能在这个基础上
发现人类从未发现过的定理
甚至物理定律
这其实也呼应了前面提到的大脑引导系统
在形式化数学里
Lean编译器的报错机制
其实就扮演了那个引导子系统的角色
它用绝对的逻辑规则
约束和引导AI这个学习子系统
去探索真理的边界
最后
我们来聊聊亚当现在的核心工作
那就是致力于科研体制的创新
我们刚才聊的很多突破性的工作
比如绘制全脑图谱
或者将全部数学知识形式化
它们都有一个共同点
就是既不是足够学术
也不是足够商业
对于大学教授来说
这些项目都太工程化了
绘制脑图谱需要像工厂一样精密的流程管理
发不了那么多论文
博士生也不愿意做这种重复性的工作
对于风险投资来说
这些项目又太基础了
绘制出脑图谱
距离开发出治疗老年痴呆的药物
或者脑机接口产品
可能还有十年的距离
VC等不了那么久
于是
这些极其重要的、能够改变人类命运的项目
就掉进了死亡之谷
亚当提出的解决方案是
聚焦研究组织
你可以把它理解为一种非营利性的B轮初创公司
因为它会像初创公司一样
有全职的工程师团队
有明确的工程目标
比如5年内把脑图谱成本降低一百倍
但是它又是非营利性质的
它的产出是公共品
比如一套开源的数据集
一个验证工具
而不是为了上市或者卖给谷歌
像E11 Bio就是这样一个聚焦研究组织
就会专注脑图谱技术方面
因为在现代科学中
很多瓶颈不再是单一的天才灵感
而是大规模的、精密的系统工程
我们需要新的组织形式来适应这种变化
回到最开始的问题
大脑究竟是如何工作的？
大脑并不是一个简单的、从零开始的学习机器
它更像是一个由进化精心设计的双系统结构
由一个古老的、充满偏见的引导系统
像一位严厉又智慧的导师
指引着皮层这个强大的通用学习引擎
而我们的AI之路
似乎也在无意之中印证着这个结构
从单纯的数据驱动
走向引入人类反馈
再到未来引入形式化的验证
作为更严格的引导系统
我们正在一步步的逼近智能的本质
无论是通过研究大脑的连接组
还是通过构建能够自我验证的数学AI
或者是通过设计聚焦研究组织这样新型的科研组织
我们都在试图跨越那个理解智能的最后门槛
这不仅仅是关于技术的竞赛
更是关于人类如何认知自我、如何组织协作的一场宏大实验
感谢收看本期内容，下期再见
