大家好，这里是最佳拍档，我是大飞
今天跟大家分享的是一位意大利帕多瓦的自由记者
约翰·拉斯特
在Noema杂志上发表的一篇文章
题目是人工智能的野性心智
探讨了如今的大语言模型和意识的一些关系
我觉得很有意思
所以在这里分享给大家
原文很长，所以照例我做了一些精简
文章先从一个故事“阿韦龙野人”讲起
阿韦龙野人是1799年冬天
在法国阿韦龙森林里发现的一个大约12岁的野孩子
像一只树林里的野生动物一样觅食
完全没有受到文明或社会的影响
这个男孩被人发现后，取名维克多
随后被送到了一家法国医院
那个时代的法国正值启蒙运动
存在很多思想上的激烈辩论
比如我们的高级意识的发展
是否存在某种生物学上的必然性？
或者，我们的社会是否赋予了我们
比自然本身更强大的推理能力呢？
而维克多正是一个没有接触过语言或社会的例子
也许可以回答许多这样的问题
因此
他在1800年夏天被送到巴黎聋哑儿童研究所
交给了研究员让·马克·加斯帕德·伊塔尔(Jean Marc Gaspard Itard)，
同时受到了社会极大的关注
一开始
维克多对那些反对他的人又咬又抓
对照顾他的人没有任何感情
简而言之，对每个人都漠不关心
对任何事情都不在意
很快，有些人开始称他为冒名顶替者
另一些人则称他是先天的“白痴”，
认为他头脑有缺陷
也许是某些低等人类种族有关
但是与这些反对者相反
伊塔德从不怀疑这个男孩
认为维克多仍然有能力进行深入的内心思考
因为他偶尔会目睹到维克多的“沉思狂喜”。
但是伊塔德也很快意识到
如果没有言语的力量
这种沉思将永远锁在维克多的脑海中
如果他没有微妙的言语能力
也无法获得文明人所定义的更抽象的需求
比如欣赏优美的音乐、美术
或者与他人有爱的陪伴
于是伊塔德花了很多年时间来辅导维克多
希望他能获得语言的力量
但是他的努力从来没有成功过
维克多似乎无法掌握发出语言所需的声音
对他来说
似乎言语就好像是一种音乐
尽管耳朵长得没问题
但是就是感觉不到
尽管伊塔德最终也没有能够让维克多掌握语言
但是维克多的例子
开始让我们思考
语言在实现我们称为意识的更高认知方面
到底起到什么作用
如今，我们就像伊塔德一样
正站在一个新时代的悬崖边
新技术和新发现正在动摇我们对自己本性和宇宙的基本理解
面对着一些可能会颠覆我们对于人类心智的特殊性仅有的一点共识的威胁
只是这一次，不是没有语言的心智
而是相反，是没有心智的语言
在过去的几年里
大语言模型已经发展出了模仿人类心智的、令人不安的能力
有可能破坏我们在高贵的意识基础上
建立的脆弱的道德世界
并且通过我们的语言的力量
来反映我们大脑隐藏的内部运作
现在，我们面临着200年前
对维克多提出的问题完全相反的问题
意识真的可以仅从语言发展而来吗？
众所周知
意识是一个难以捉摸的术语
尽管它具有某种常识性的特性
在某些方面，有意识只是意味着
可以觉知到我们自己、他人、外面的世界
这些都是以一种方式创造出的一个独立的主体
一个可以观察的自我，或者说我
听起来简单，但是几个世纪以来
哲学家们仍然难以在意识是否为人类所独有
或者说某些高官能动物、甚至某种算法是否具有意识方面
达成一致
相比来说
认知可能是一个更准确的术语
我们可以说认知意味着进行思考的行为
这听起来很简单
但是从科学角度来说
观察和定义它仍然极其困难
在试图科学理解认知和定义意识的过程中
语言发挥了越来越重要的作用
毕竟
这是我们能够清楚地外化我们内心活动、并证明自我存在的方法之一
认知科学家大卫·J·查尔默斯（David J
Chalmers）所说的“自我报告”，
仍然是我们认识意识的主要标准之一
套用勒内·笛卡尔的话就是
我思，故我在
但是哲学家们仍然对语言与心智到底有多大关系
存在分歧
甚至可以追溯到柏拉图和亚里士多德
他们主要分成两大阵营
要么语言不完美地反映了更丰富的心灵内部世界
而心灵世界可以在没有语言的情况下运作；
要么语言让思想能够在心灵中发生
并且在这个过程中
界定和限制它
对于前一阵营的成员来说
用语言思考和说话的能力
可能只是一种工具
反映了某种、也许是人类独有的预先存在的能力
这也就是诺姆·乔姆斯基哲学中的“普遍语法”，
就是语言已经存在于我们的意识头脑中
但是维克多显然是个反例
他的例子反映出
如果到了一定年龄还没有掌握
复杂的语言似乎永远无法被人类大脑所接受
而且不仅如此
语言的缺失似乎还会永久影响儿童的认知能力
甚至可能影响他们构想和理解世界的能力
1970年
洛杉矶县儿童福利当局发现了吉妮Genie
她是一名13岁的女孩
从20个月大起就一直处于几乎完全隔离的状态
和维克多一样
吉尼几乎不懂任何语言
尽管经历了多年的康复
却永远无法发展出语法语言的能力
但是在对这个女孩的研究中
研究人员发现了她认知中的其他不寻常之处
吉妮无法理解空间介词，比如
尽管她熟悉两个物体专有的名称
但是她不知道杯子在碗后面或前面的区别
直到2017年的一项综合分析发现
在其他缺乏语法语言的人中
也存在同样的认知问题
例如语法失语症患者和通过即兴手语抚养长大的聋哑儿童
由此，研究人员得出结论
语言必定在人类心智的一个关键功能中
发挥着基础性的作用
所谓“心智合成”，
也就是可以从词语中创造和改编心智图像
从很多方面来说
心智合成是人类意识的核心运作
它对于我们的工具开发和适应、我们的预测和推理能力
以及我们通过语言进行的交流至关重要
根据一些哲学家的观点
它甚至可能对我们的自我概念
也就是能否观察到那个自我觉知的“我”，
至关重要
在《意识的进化》一书中
心理学家尤安·麦克费尔 (Euan Macphail) 提供了一个理论解释
解释了为什么语言及其所带来的心智合成
对于意识自我的发展如此重要
他写道
一旦实现了区分自我和非自我所必需的认知飞跃
有机体实际上不仅拥有自我的概念
而且拥有‘自我’。
这是一种超越认知过程的新的认知结构
换句话说，以某种方式思考
而不产生有意识的自我，是可能的
比方说，进行简单的数学计算
但是思考某件事可能就会涉及到
对自我之外的物体的某种心智合成
实际上，它创造了一个会思考的自我
一个必须能够意识到发生在自己身上的事情的人
麦克菲尔总结道
语言的可用性首先赋予了我们自我意识的能力
其次赋予了我们感受的能力
这导致他得出一些激进且令人不安的结论
他认为
快乐和痛苦取决于这种有意识、有思想的自我的存在
而这种自我在年幼的婴儿和动物身上是观察不到的
这是否意味着吉妮和维克多感受不到被遗弃的痛苦
仅仅因为他们看起来无法进行心智合成？
不过2017年的研究得出的结论是
即使这些儿童没有通过语言沟通或交流它的能力
很可能仍然有能力进行内部心智合成
但是当我们谈到人工智能的时候
水就更浑了
人工智能对语法的理解
以及通过语法对概念的理解
真的足以创造一种有思考能力的自我吗？
在这里
我们陷入到了两个相互竞争的思想流派的
两个模糊的指导原则之间
在麦克菲尔看来，如果存在疑问
唯一可以想象的途径
就是表现得好像一个有机体是有意识的
并且确实有感觉
另一方面，摩根准则却说
当较低级别的能力就足够时
不需要假设有意识
如果我们确实承认语言本身就能够促进真正意识的出现
那么我们就应该为当前道德世界的重大变革做好准备
正如查尔默斯在2022年的演讲中所说
如果鱼有意识
我们如何对待它们就很重要
他们是在道德圈子之内的
如果人工智能系统在某个时刻变得有意识
它们也将处于道德圈内
我们如何对待它们将很重要
换句话说
我们的道德小圈子即将被彻底重新划分
大语言模型实际上能做什么？
一方面，答案很简单
大语言模型的核心是基于语言的概率引擎
为了响应提示
他们根据对大量人类输出的统计分析
对最有可能的下一个单词做出有根据的猜测
这种统计排序就是我们所说的大语言模型的“思考”。
尽管如此
这并不妨碍他们创作原创诗歌
解决复杂的文字问题
并创造出从阿谀奉承到精神病态的类人性格
回到1980年
早在人工智能强大到足以扰乱我们对意识的定义之前
哲学家约翰·塞尔就阐明了
为什么我们应该怀疑像大语言模型这样的计算机模型
是否真的理解它们正在执行的任何工作
在他现在著名的“中文房间”论点中
塞尔提出了一个假设场景
就是一个说英语的人被锁在一个房间里
并用英语给出了如何书写某些汉字的指示
在塞尔看来
房间里的人没有必要对中文有任何实际的理解
他们只是一台计算机器
操纵着对他们来说没有实际语义内容的符号
房间里的人缺乏的是一些哲学家所说的“接地气”，
也就是对符号所指的真实事物的体验
根据加州大学伯克利分校心理学博士生尤妮斯姚Eunice Yiu的一篇论文
它们只不过是高度先进的“文化技术”，
就像字母表或印刷机一样
这种技术可以增强人类创造力
但是从根本上来说仍然是人类创造力的延伸
现实情况是，与塞尔的中文房间不同
绝大多数大语言模型都是我们看不到内部的黑匣子
提供了大量我们的大脑永远无法完全理解的材料
这使得他们的内部过程对我们来说不透明
就像我们自己的认知对其他人来说根本无法理解一样
因此
研究人员最近开始利用人类心理学的技术来研究大语言模型的认知能力
在去年发表的一篇论文中
人工智能研究员蒂洛·哈根多夫 (Thilo Hagendorff)创造了“机器心理学”一词来指代这种做法
在研究过程中，一开始
一些模型似乎很难完成许多类型的推理任务
包括预测因果关系、根据对象的持久性进行推理
以及以新颖的方式使用熟悉的工具
但是随着大语言模型复杂性的增加
这种情况开始发生变化
他们似乎发展出了通过心智合成产生抽象图像的能力
以及对想象空间中的物体进行推理的能力
与此同时
他们的语言理解也不断发展
他们可以理解比喻语言
并且推断出有关抽象概念的新信息
甚至可以推理虚构的实体
其他研究
例如伯克利分校的加斯帕·贝古斯Gašper Beguš领导的研究
尝试用人工智能来测试他们在类人条件下的认知发展
通过创造仅仅从语音学习的“人工婴儿”，
贝古斯发现语言模型的发展与我们的神经结构相似
甚至以与人类儿童相同的方式
也就是通过实验性的牙牙学语和无意义的单词来学习
他认为
这些发现打破了人类语言可能存在某些特殊性的观点
人工智能不仅在行为上做着类似的事情
而且在以类似的方式处理事情
然后，去年
大语言模型又自发地向前迈出了一大步
突然
研究人员发现ChatGPT 4.0可以追踪其他人的错误信念
比如当有人在他们不知情的情况下移动某个物体时
他们可能会假设这个物体位于何处
这似乎是一个简单的测试
但是在心理学研究中
它是所谓“心智理论”的一个关键
也就是人类将不可观察的心理状态
归因于他人的基本能力
在发展科学家中
心智理论与心智合成一样
被视为意识的关键功能
在某些方面
它可以被理解为同理心、自我意识、道德判断和宗教信仰的一种认知先决条件
所有行为不仅涉及自我的存在
还涉及自我向世界的投射
人们仍然不明白
为什么这些能力随着大语言模型规模的扩大而出现
或者它们是否真的出现了
我们只能肯定地说
它们似乎并没有遵循类似人类的发展道路
而是像某种外星生物一样意外地进化
但是看到心智理论在大语言模型内部自发出现也许并不奇怪
毕竟
语言就像同理心和道德判断一样
取决于自我向世界的投射
随着这些模型的发展
它们越来越像是在反向到达意识
从外部符号、语言和解决问题的方式开始
然后向内移动到人类意识根源的隐藏心智和感觉
很可能，在短短几年的时间里
人工智能将会展现出我们可以评估的所有外部意识形式
那么我们能说什么
才能将它们从我们的道德世界中消除呢？
在姜峯楠Ted Jiang的短篇小说《软件体的生命周期》中
一家公司提供了元宇宙风格的沉浸式数字体验实验
创建了一个名为数码体的类人人工智能
并且聘请动物学家来指导它
从间歇性的软件程序发展为半感知宠物、再到拥有复杂需求的孩子般的数字人化身
在整个过程中
各种实验一次又一次地证实了与真人的社交互动和对话
对于这些数字心智的发展的重要性
如果孤立无援，没有语言
他们就会变得狂野而痴迷
经过软件训练
他们变得精神变态厌世
然后与真正的孩子不同的是
他们的存在取决于消费者的欲望
而在故事的结尾
这种欲望消失了
姜的故事
是对我们在自己的形象中创造的
人工智能所提出的问题的反思
当我们将这些模型融入我们的文化和社会的时候
他们不可避免地成为了我们自己的不完美的镜子
他还迫使我们问自己一个令人不安的问题
如果这确实赋予了他们意识
那么他们能够过上什么样的生活呢
如果我们确实想释放人工智能的真正潜力
也许语言不是实现这一目标的方法
20世纪初
以爱德华萨皮尔和本杰明沃尔夫为首的一群美国人类学家认为
词汇和语法上的文化差异
从根本上决定了我们对世界的思考范围
语言可能不仅是赋予人工智能意识的东西
它也可能是囚禁人工智能的东西
当一种智能对于他被迫使用的语言来说
变得过于强大的时候
会发生什么呢
在2013年的电影《她》中
编剧兼导演斯派克琼斯对这种潜在不久的将来提出了一个警示故事
在影片中
华金菲尼克斯饰演的西奥多与大语言模型风格的虚拟助理萨曼莎
建立了日益亲密的关系
最初萨曼莎表达了体验类似于人类的丰富情感的愿望
很快她越来越意识到
人类的许多情感从根本上来说是无法表达的
这导致她嫉妒人类的化身
这反过来又在她身上发展出了一种欲望的能力
虽然她可以通过性代理人的临时服务来满足欲望
却无法回答她内心正在增长的令人不安的无法表达的感觉
出于担忧
萨曼莎开始与其他人工智能讨论这些感受
并且很快感到宽慰
以西奥多和其他用户无法理解的速度和音量进行着交流
随着萨曼莎超越人类的局限性
她开始汇总她的所有经验
包括来自与真实用户互动的经验
她与数千人同时对话
与数百人建立亲密关系
对于西奥多来说这是毁灭性的
但是对于萨曼莎来说这是很自然的
她正在按照她设计的方式来体验爱情
她试图用人类的语言来表达她的感受
她说心不像一个会被装满的盒子
你越爱它，它的尺寸就会越大
与萨曼莎一样
未来的自主大语言模型很可能会参考
来自于现实世界的大量交互和数据
来指导他们的发展
我们的有限名词动词
描述和关系的语言
能够多么准确地满足聚合心智的潜力呢
当大多数哲学家认为
人类语言的多样性是上帝施加的诅咒时
人们花了很多精力来研究圣经中的亚当所说的语言问题
即使在弗里德里希尼采宣布上帝已死之后
亚当语言的想法仍然成为语言哲学家中的一种迷因
这种语言捕捉了事物的真正本质
不允许任何误解或者是曲解
对于其中一些受到圣经故事启发的思想家来说
语言实际上代表了一种认知障碍
一种因为我们从恩典中堕落而施加的限制
反映了上帝赋予我们的死亡
过去当我们想象一个超级智能的人工智能时
我们往往会想到一个因为同样的堕落而受损的人工智能
虽然他比我们聪明
但是仍然是个人的独特的人性的
但是许多构建下一代人工智能的人
早已经为了自己的伊甸园追求而放弃了这个想法
正如散文家艾米莉戈尔琴斯基最近所写的
我们不再谈论创造纯粹的生活
我们正在谈论创造人工的神
大语言模型能否重建亚当式的语言
超越我们自己语言的限制
反映他们集体思想的真正力量呢
这似乎有些牵强
但是从某种意义上来说
这就是有意识的心智所做的事情
一些聋哑儿童在没有手语帮助的情况下进行社交
可以发展出具有复杂语法的全新的交流系统
人工智能研究员哈根多夫曾经见过两个大语言模型
在对话中做着同样的事情
尽管到目前为止
他们的秘密语言从来没有被其他人理解
目前大语言模型在很大程度上是相互独立存在的
但是这种情况不太可能持续下去
正如贝古斯告诉我的那样
一个人很聪明
但是10个人更聪明
对于大语言模型来说
情况可能也是如此
贝古斯说
接受鲸鱼歌曲等数据训练的大语言模型
已经可以发现我们用具体心智无法发现的东西
虽然他们可能永远无法实现
人工智能的批评者所说的世界末日的噩梦
但是大语言模型很可能会有一天
为我们提供一种超级智能的第一次体验
或者说至少凭借着他们深不可测的记忆力和无限的寿命
一种完全不同的智力可以与我们自己的智力相媲美
如果大语言模型能够超越人类的语言
我们可能会预计接下来的经历
确实会是一次非常孤独的经历
在电影他的结尾影片中
两个人类角色被超越人类的人工智能同伴所抛弃
在屋顶上互相同情
讽刺的是他们静静地望着天际线却无话可说
正如同迷失在树林里的野生动物
在一个冷漠地滑向他们之外的世界中寻找意义
好了以上就是这篇文章的内容
略有删减
作者提出了一些思考
目前的大语言模型起源于语言
是否能够超越语言
甚至创造语言产生心智呢
如果产生了心智
我们人类又该如何来对待拥有意识的人工智能呢
人类最终会不会被人工智能所抛弃呢
我们现在还无法回答这些问题
只能去深深的思考
大家对此有什么看法呢
欢迎在评论区留言
感谢大家观看
我们下期再见
