大家好，这里是最佳拍档，我是大飞
不知道大家有没有发现，最近两年
AI领域的讨论已经从“要不要做AI”变成了“怎么把AI做好”。
从2023年生成式AI爆发开始
到2025年的今天
越来越多的公司不再纠结于AI的可能性
而是埋头在产品开发、团队搭建、成本控制这些实际的问题上
最近
曾经作为管理硅谷众多科技巨头家办的ICONIQ资本
抓住了这个转折点的时机
发布了一份长达68页的报告
拆解了300家正在开发AI产品的软件公司的实战经验
无论是AI原生公司
还是所谓的AI赋能公司
相信它们的踩坑经验、成功做法
都能带给我们很多的启发
今天大飞就来给大家分享一下
要聊AI产品的开发
首先我们得搞清楚
现在市面上的AI公司到底有哪些类型
根据报告的调研，主要分为两类
分别是AI原生公司和AI赋能公司
AI原生公司
指的是核心产品或商业模式完全由AI驱动的公司
它们的价值几乎都来自于模型训练、推理和持续的学习
这类公司在调研中占了32%，
它们的特点是产品的迭代速度非常快
报告里提到，只有1%的AI原生公司
还停留在产品发布前的阶段
而AI赋能公司则有11%卡在这个阶段；
更关键的是
47%的AI原生产品已经进入了规模化的阶段
也就是说产品已经验证了市场契合度
正在快速扩大用户群和基础设施
这背后可能的原因是
AI原生公司在团队构成、基础设施和融资模式上更有优势
能够更快的跳过试错阶段
而AI赋能公司往往需要把AI“嫁接”到现有的工作流中
难免就会遇到更多的阻碍
AI赋能公司则分为两种
一种是在旗舰产品中嵌入AI功能
比如给现有的CRM系统加一个AI推荐模块
这类公司占31%；
另一种是开发独立于核心业务的AI产品
比如一个做协作工具的公司
额外再推出一个AI写作助手
这类公司占37%。
对于这些公司来说
AI更像是一个提升现有产品价值的工具
而不是全部
比如 Salesforce、Atlassian这些传统SaaS巨头
现在都在核心产品里面加入了AI功能
目的是提升自动化、个性化和用户的生产力
但是底层的商业模式和用户体验并没有大的改变
这两种路径的差异
从一开始就决定了它们在产品开发、团队搭建甚至成本结构上的不同
接下来
我们就从产品开发的具体环节来看看
这些公司都在做什么
以及它们都遇到了什么问题
不管是AI原生还是AI赋能公司
目前最热门的产品类型基本分为两类
代理工作流和应用层产品
其中
有79%的AI原生公司都在做代理工作流
所谓代理工作流
简单来说就是让AI像“代理Agent”一样去自主完成一系列的任务
比如自动处理客户咨询的全流程
从理解问题到查找资料再到生成回复
甚至能够根据用户的反馈来调整策略
除此之外
垂直领域的AI应用和水平领域的AI应用也很受欢迎
AI原生公司中分别有65%和56%在开发这些应用；
而AI赋能公司则占比较低
分别是49%和40%。
这也反映了两类公司的不同定位
AI原生公司更专注于通过AI来解决具体的业务流程问题
而AI赋能公司则希望通过AI来增强现有平台的通用性
在模型使用上
有80%的公司会依赖第三方AI API
比如GPT和Claude
但是高增长的公司明显更“激进”，
77%的高增长公司会在现有的基础模型上微调
54%会从头开发专有模型
而其他公司这两个比例分别是61%和32%。
为什么会有这种差异呢？
高增长公司通常资源更加充足
而且需要为企业客户提供深度的定制化服务
以及根据客户的数据和需求调整模型
这时候微调或者自研就成了必要选项
而资源有限的公司
更倾向于直接用第三方API
这样能最快把产品推向市场
减少前期投入
从模型的提供商来看
OpenAI的GPT模型依然是绝对主流
有95%的全栈AI公司都在使用
其次是Anthropic的Claude
和Google的Gemini
值得注意的是
平均每家公司会用2.8个模型
也就是“多模型的策略”越来越普遍
比如
有的公司在处理简单的文本生成时选择用GPT-4
而处理长文档分析时选择用Claude
处理多模态任务时则使用Gemini
这样既能够优化性能
又能够控制成本
还能避免过度依赖单一的供应商
在选模型的时候
不同场景的优先级也完全不同
如果是面向客户的产品
准确性是绝对第一位的
74%的公司把它排在第一
而成本排在第二
占比为57%，这和去年的情况很不一样
去年成本在客户产品中几乎是最不重要的
今年排名上升
可能是因为像DeepSeek这样的低成本模型出现
让成本成了更为关键的竞争因素
但如果是内部使用的AI工具
成本就成了头号的考量
占比为74%，
其次是准确性，和隐私
毕竟内部工具不直接产生收入
控制成本更重要
而且内部数据往往涉及到机密信息
隐私保护自然也就成了重点
在训练和适配技术方面
最常用的是检索增强生成RAG和微调fine-tuning
分别有69%和67%的公司在使用
高增长公司还特别喜欢用提示词技术
比如少样本学习和零样本学习
这可能是因为它们需要快速适配不同客户的需求
而提示词技术能够在不重新训练模型的情况下
调整输出
和去年相比
用RAG和微调的公司明显增多了
按理说，基础模型越来越强
微调的需求应该减少
但是实际的情况是
企业客户对定制化的要求更高了
这时候微调依然是必要的
在部署模型的时候
最大的三个难题分别是
幻觉现象、可解释性与信任、以及证明投资回报率ROI
分别占比为39%、38%和34%。
另外
计算成本和安全也是比较大的两个问题
比如，一个AI产品上线后
用户量突然增加
API的调用费可能飙升，直接吃掉利润；
而如果模型被恶意攻击
生成有害内容
还可能面临法律风险
在基础设施方面
大多数公司都选择了“轻资产”的模式
68%的公司完全使用云服务
64%依赖外部AI API提供商
这样做的好处很明显
那就是可以减少前期投入
不用自己维护服务器
还能快速上线产品
但是这也带来了新的问题
供应商的选择、服务等级协议
也就是SLA的谈判
以及按调用次数计费的成本管理
都成了战略级别的事情
如果API提供商突然涨价
或者服务中断
整个产品就会受影响
所以很多公司会和供应商签长期协议
甚至考虑备用方案
只有23%的公司采用了云+本地的混合模式
不到10%完全用本地的基础设施
这些公司往往有着一些特殊的需求
比如金融机构因为合规要求
必须把数据放在自己的服务器里；
或者对实时性要求极高
比如自动驾驶的AI模型
需要本地计算来减少延迟
在市场方面
现在最流行的定价模式是混合定价
占比为38%，
也就是结合订阅制和按使用量、或者按结果付费
比如，基础的功能收月费
超过一定使用量后额外收费
或者根据AI帮客户节省的成本来抽成
AI赋能型的公司大多会把AI当做一个“增值项”，
40%放在高端套餐里
33%免费提供
这其实是把AI作为吸引客户升级或防止客户流失的工具
而不是主要的收入来源
比如很多SaaS工具会说“高级版包含AI分析功能”，
以此来推动客户从基础版升级
但是报告指出
这种模式可能不会长久
随着AI的成本越来越高
免费提供会压缩产品的利润空间；
而用户使用上的差异很大
重度用户用得多
成本高，轻度用户用得少
收入低，这就会让定价变得很尴尬
所以37%的公司计划在未来12个月调整定价
比如转向更为灵活的按使用量计费
或者根据AI带来的具体价值来定价
随着AI产品的规模化
透明度也越来越重要
在产品的规模化阶段
25%的公司会提供详细的模型透明度报告
47%会解释AI如何影响结果
而在 pre-launch 阶段只有6%会提供详细报告
这其实也很合理，说明产品越成熟
客户越会要求知道AI的工作原理
尤其是对于企业客户来说
在合规方面
只有13%有专门的AI合规团队
29%的公司有正式的AI伦理和治理政策
47%至少遵守GDPR、CCPA这些数据隐私法
说明很多公司还在“应付”合规
而不是主动去建设合规体系
随着各国的AI监管越来越严
这可能会成为未来的风险点
另外
有66%在用human-in-the-loop的方式
确保AI的公平和安全
简单来说就是在关键决策环节让人类审核
比如AI生成的合同
会让律师再检查一遍
在团队方面，公司规模越大
越可能有专门的AI领导
比如首席AI官、机器学习负责人等等
年收入1亿美元以上的公司中
至少50%都有专门的AI领导
而年收入低于1亿美元的公司只有33%。
这是因为规模大了，AI业务更复杂
需要有人去统筹战略、技术和合规
而小公司可能会让CTO或产品负责人直接兼管了
在岗位方面
目前最常见的AI岗位是AI/机器学习工程师
88%的公司都有、有数据科学家的公司占比为72%、有AI产品经理的公司占比67%。
但是招人很难
AI/机器学习工程师平均要70天才能招到
数据科学家68天，AI产品经理67天
这比普通工程师难招多了
主要是因为合格的人才少
竞争激烈
还有一些新兴的岗位也在崛起
比如提示工程师和AI设计专家
这些岗位需要懂技术又懂业务
所以现在也成了香饽饽
然而，46%的公司觉得招人不够快
主要原因是“缺乏合格的候选人”，
其次是成本高和竞争激烈
有一家公司的技术负责人就说
我们想招有大模型部署经验的工程师
但是市场上这样的人太少了
稍微有点经验的
薪资要求比普通工程师高50%以上
还经常被挖墙脚
因此为了应对
很多公司会自己培养人才
比如让现有工程师参加AI培训
或者和高校合作实习项目
平均来看
公司会计划让20%-30%的工程师专注在AI方面
高增长的公司会更高，甚至能达到37%。
这说明AI已经从“边缘项目”变成了“核心业务”，
需要足够的工程师去投入
从成本方面来看
AI赋能公司的研发预算中
AI的开发成本大概占10%到20%
年收入越高
比例相对越低
2024年 1亿美元以上的公司大约为10%到15%
而低于1亿美元的公司为14%。
这可能是因为大公司研发基数大
AI只是其中的一部分
小公司则更聚焦
愿意把更多预算投到AI上
不过
这个比例在2025年有了明显的上涨
普遍增加了5%-10%，
说明大家都在加大AI投入
那钱都花到哪里了呢？
不同阶段，成本的结构也不一样
在产品发布前
57%的AI预算花在了人才上
因为这时候主要是搭团队、做研发；
到了规模化阶段
人才成本占比会降到36%，
而基础设施和云成本升到22%，
模型推理成本升到13%，
这是因为用户多了
服务器、API调用这些“可变的成本”也就上来了
其中，API的使用费是最难控制的
70%的公司把它排在第一
其次是推理成本、模型再训练和更新等等
API的使用费难控制
是因为它和用户的使用量直接挂钩
而用户行为是很难预测的
比如突然有个活动
用户量就会暴涨，API费用可能翻倍
为了省钱
41%的公司在用像Llama 3这样的开源模型
37%在尝试优化推理效率
比如压缩模型大小
28%（口误）在用模型蒸馏或者量化技术
举个例子
有的公司把大模型从700亿参数压缩到70亿
推理成本降了70%，性能只降了5%，
对很多场景来说完全能接受
模型训练的月成本
也会随着产品的成熟度上升
发布前平均为16.3万美元
规模化阶段为150万美元
推理成本涨得更猛，规模化阶段
高增长公司每月要花230万美元
普通公司也要110万美元
数据存储和处理也不便宜
规模化阶段的高增长公司
每月要花260万和200万美元
普通公司也要花190万和180万美元
从这些数字我们就能看出
AI产品的“规模化成本”很高
不是光把模型开发出来就行的
还得有足够的资金来支撑后期的运营
这也是很多初创公司需要大笔融资的原因
除了开发对外的AI产品以外
公司也在用AI提升内部的效率
这部分的预算在2025年几乎翻倍
对于年收入10亿美元以上的公司来说
内部AI生产力预算从2024年的平均342万美元涨到2025年的604万美元
在公司内部
有70%左右的员工能够接触到AI工具
但是只有50%会持续使用
大公司则更难推动
年收入10亿美元以上的公司
只有44%的员工持续用AI
而小公司则有57%。
这可能是因为大公司流程复杂
员工习惯难改
而且数据安全顾虑更多
纽约人寿的首席数据和分析官唐·武（Don Vu）就说
只部署工具肯定不行
尤其是大企业
要让员工真的用起来
得培训、找最积极使用AI的员工来带头
最重要的是高管的持续支持
不然很容易不了了之
在企业的研发部门内部
最常用的AI场景是编码辅助、内容生成和编写助理
以及文档和知识检索
效果最好的也是编码辅助
65%的公司认为它对生产力的提升最大
高增长公司甚至有33%的代码已经是AI写的
普通公司是27%。
但是挑战也是明显的
46%的公司说“找不到合适的使用场景”，
42%认为“很难证明ROI”。
那么
究竟应该如何衡量内部AI的效果呢？
75%的公司会跟踪生产力提升
51%会跟踪成本节省
但只有20%会跟踪收入提升
毕竟内部工具通常都不会直接创造收入
具体方法上，14%只跟踪定量指标
16%只跟踪定性指标
30%既跟踪定量又跟踪定性指标
不过，还有17%的公司完全没开始衡量
这其实是很危险的
因为如果不知道效果
就不知道该优化还是放弃
在AI的工具栈方面
PyTorch和TensorFlow这两个深度学习框架最流行
加起来占了一半以上的使用量
但是托管平台也不甘示弱
AWS SageMaker和OpenAI的微调服务用的人也很多
说明团队分成两派，一派喜欢用框架
自己掌控整个过程
一派则喜欢用托管服务，省事
Hugging Face的生态和Databricks的Mosaic AI Training也在崛起
它们提供了一些更高层的工具
让训练更简单
比如不用自己写复杂的分布式训练代码
直接调用API就行
在开发方面
LangChain和Hugging Face的工具集最火
因为它们能简化提示词链、批处理和模型接口这些工作
70%的公司还会用私有或自定义的API
说明很多公司会基于公开模型做二次开发
然后封装成自己的API供内部使用
安全工具也越来越受重视
30%的公司会用Guardrails来做安全检查
防止AI生成有害内容
23%会用Vercel的AI SDK进行快速部署
这些工具能让应用更稳定、更合规
在监控和观测方面
近一半的公司还在用传统的APM工具
比如Datadog、New Relic
而不是专门的AI监控工具
这可能是因为这些工具已经融入了现有流程
团队不想再学新的工具
但是专门的AI监控工具也在增长
LangSmith和Weights & Biases各有17%的使用率
它们能够跟踪提示词的效果、检测模型漂移
这些是传统工具做不到的
在推理优化方面
英伟达的TensorRT和Triton推理服务器
加起来占了60%以上
说明英伟达在推理优化领域几乎垄断
毕竟它们的GPU可以说是行业标杆
软件和硬件也配合得好
能把速度和效率做到极致
在非英伟达的方案里
ONNX Runtime占了18%，
它的优势是可以跨硬件
在CPU、GPU和其他加速器上都能跑
适合那些不想被英伟达绑定的公司
在数据处理和特征工程方面
Apache Spark和Kafka是绝对的主力
分别有44%和42%的公司在用
Spark适合大规模的批处理
Kafka适合实时流处理
这两个几乎是大数据处理的标配
但是小规模的数据处理
还是离不开Pandas
有41%的公司在用，它简单灵活
适合快速分析和原型开发
在编码辅助方面
GitHub Copilot几乎垄断了市场
75%的开发团队在用
它和VS Code深度集成，支持多种语言
而且背后有GitHub的海量代码训练
效果确实好
Cursor排名第二，有50%的公司在用
它更专注于AI驱动的编辑体验
比如实时重构代码
对很多开发者来说很顺手
其他一些工具
比如Codeium、Sourcegraph虽然也有用户
但是份额远不如前两个
说明编码辅助工具已经形成了“双巨头”的格局
总结一下，从这份报告来看
2025年的AI开发已经进入了“深水区”，
不再是拼谁能先做出一个AI功能
而是拼谁能把AI产品做稳定、做合规、做经济
同时搭建起能持续创新的团队和体系
AI原生公司凭借着天生的优势跑得更快
但AI赋能公司通过在现有产品中嵌入AI
也能找到自己的位置
在模型选择上
多模型策略成为了主流
而成本和定制化成了竞争的关键
定价和合规越来越复杂
需要平衡用户体验、成本和监管要求
人才依然是最大的瓶颈
尤其是既懂技术又懂业务的复合型人才
对想要入局的公司来说
有几个教训值得借鉴
首先要明确AI能解决的具体问题
不要为了AI而AI
其次是控制好API的成本
避免规模上去了利润没了
以及尽早搭建合规体系
别等监管来了再补课
最后就是要重视内部AI工具的落地
提升团队效率往往比对外宣传更重要
如今来看，AI已经不再是未来的趋势
而是现在的日常
怎么把它做好
考验的不只是技术能力
还有战略眼光、组织能力和成本意识
希望今天的内容能给大家一些启发
无论是创业还是职场
都能更好地把握AI带来的机会
感谢大家收看本期视频
我们下期再见
