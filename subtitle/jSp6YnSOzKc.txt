大家好，这里是最佳拍档，我是大飞
2023年3月
如果你偶然进入了纽约大学的某个礼堂
可能会以为自己在参加一场纯粹的神经科学会议
演讲者们大谈特谈动物实验中的脑损伤创建手术
以及如何使用电极来获取大脑信号
甚至还扯到了语言分析和心理学
不过
这其实是一个关于人工智能的研讨会
讨论的内容却不是算力或者模型
那么神经系统和心理学到底与 AI 有什么关系呢？
事实上
最先进的AI系统已经在规模和复杂性上
可以比肩自然界中的人类大脑
而AI研究人员几乎在像研究人类大脑一样研究它们
他们开始借鉴一些传统上以人类为唯一研究对象的学科
比如心理学、语言学和心灵哲学
从而尝试更好地理解大模型
而他们的发现也开始对这些领域产生影响
纽约大学心理学和数据科学助理教授格雷斯·林赛（Grace Lindsay）就认为
这些学科如今的目标和方法如此接近
以至于可以考虑合并为一个领域
统称为“神经系统理解”（neural systems understanding）
今天大飞就来跟大家聊聊
传统的神经科学与最新的人工智能
有哪些新的结合和发现
从十年前的视觉感知到最近几年的语言处理
多层或“深层”人工神经网络
已经成为了大脑建模的最先进方法
至少在重现外部行为方面是这样
这种转变直接颠覆了日常的科学方法论
很多过去无法在人体上进行的实验如今成为可能
研究人员可以给模型相同的刺激
并将它的内部活动与活体大脑的数据直接进行比较
就像在人类或猕猴身上做实验一样
再比如说
一个人工神经网络可能能识别披头士乐队的所有成员
但是无法分辨出鼓和吉他
但是这种奇特的现象在人脑中是不可能出现的
归根结底
是因为这些系统的工作方式与大脑截然不同
人工智能不依赖于所谓的神经元和突触
他们的训练方案也和儿童通常的学习方式大相径庭
但是
如此不同的机制却仍能够产生和人类相似的智能输出
这让许多科学家认为
细节实际上并不重要
低级别的组件
无论是活细胞还是逻辑门
都会被计算任务的要求塑造成更强大的结构
谷歌DeepMind的认知心理学家安德鲁·兰皮宁（Andrew Lampinen）认为
只要架构足够优秀
表征会更容易受到数据和训练过程的影响
这表明在广泛的系统中
预测和理解语言的计算瓶颈是相似的
鉴于这种相似性
林赛与哥伦比亚大学心理学和神经科学教授尼古拉斯·克里格斯科特
以及其他著名计算神经科学家在2019年的一篇论文中指出
科学家们应该开始利用神经网络架构和学习算法
而非精细的生物机制
来解释大脑的功能
机器学习先驱、图灵奖得主约书亚·本吉奥（Yoshua Bengio）也认为
神经科学更加适合具有描述性的事物
因为观察起来更容易
但是机器学习的思维和理论
更加有助于解释为什么的原理
AI与神经生物学首先结合的一个领域
就是视觉神经科学
这其实也情有可原
在20世纪50年代中期
第一个硬件神经网络就是为了模仿自然视觉感知而设计的
即便如此，在接下来的几十年里
AI研究人员并没有太在意这些软件和生物之间的联系
到了2010年代
当图像识别网络开始媲美人类水平
我们依然不清楚
这东西的生物仿真性究竟能做到什么程度
为了回答这个问题
麻省理工学院的神经科学家们开发出了一种基本的实验范式
首先向猴子展示视觉刺激
并且测量猴子的大脑反应
然后他们用相同的刺激
来训练一系列的人工神经网络
并提取AI的“表征”，
也就是神经网络产生的最高抽象层次的输出
最后将这个数据与猴子的大脑数据输出进行比较
听着很简单
但是这实际上是一个庞大的工程
要知道，大脑的活动是千变万化的
如果只是单纯地对比
那么研究人员很可能得到的是某一个时间段的比较成果
而忽略了其他时间段可能出现的例外情况
为了解决这个问题
科学家首先要构建一个与神经网络本身不同的“映射模型”。
通过计算模拟大脑和真实大脑在某些数据子集上的关系
然后在另一个数据子集上测试这种关系
从而尽可能地还原大脑
经过实验研究人员发现
猴子大脑和人工神经网络
可以以类似的方式对相同的视觉刺激作出反应
麻省理工学院认知神经科学教授南希·坎威舍尔（Nancy Kanwisher）认为
模型中的激活和大脑中的激活之间有着惊人的相似程度
即使它们是完全不同的
一个是计算机程序
另一个是一堆由自然选择优化的生物黏液
但是它们最终对类似问题
有着令人惊讶的类似解法
自此
这些AI网络改变了计算神经科学家进行研究的规模
通过这些方法
研究人员可以同时比较十几个模型
2018年
研究人员建立了一个域名为 Brain-Score
org 的网站，来对视觉模型进行排名
这个网站现在已经有超过200个模型
每个模型都代表视觉皮层工作方式的某种直觉
所有这些模型在某些任务上都表现得跟人类基本一致
因此排名代表了模型更加细微的方面
比如说它们是否犯了我们大脑犯的同样错误
以及它们的反应时间是否与我们的反应时间一样变化
虽然这些网络常常与大脑本身一样晦涩难懂
但是这次
研究人员至少可以直接访问网络中的人工神经元
尽管它们只是机器中的变量
例如
林赛和他的同事们搞了一个人工神经网络
来探索所谓的“祖母神经元”。
这种神经元只有在你看到自己的祖母或者某个特定的人的时候
才会被激活
林赛的团队证实
一个基于图像训练的人工网络也有类似的神经元
只有在某些物体出现的时候才会被激活
但是当他们追踪网络中的信息流动时
发现这些变量与网络识别人物或物体的整体能力无关
它们仅仅是偶然选择性地进行响应
因此林赛认为
从这些人工神经网络模型中可以看到
神经元对图像的响应方式
并不一定能够说明它对物体的分类作用
而人工神经网络的出现
也让深入研究视觉的处理层次成为可能
传统的神经科学
一般都是通过简单的视觉刺激
来测量早期处理层中神经元的反应
比如视网膜、外侧膝状体和初级视觉皮层
但是这些方法很难描述处理广泛和复杂几何图案的后期层细胞
不过
人工神经网络却可以帮助找到这些特征
研究人员通过训练AI 模型
可以识别蓝色咖啡杯和蓝色花朵的图像
这些物体在像素层面上看起来几乎一样
并且会在早期层次上引发相似的反应
只有在后期层次上它们的差异才变得明显
林赛表示
机器所发展出来的高级表征
应该与大脑的表征相匹配
你只需要将大脑看作是一种数据分析工具
一种表示数据的不同方式
然后在大脑中寻找这种表征
换句话说，这更加与语言有关
而非大脑
实际上，借助于人工神经网络
研究人员甚至可以在现实环境中观察大脑的运作
行话叫做“生态有效实验”。
在传统的刺激-反应实验中
必须把小鼠麻醉
从而消除小鼠大脑对某些简单刺激反应测量中的噪音
但是有了人工神经网络
研究人员就可以让动物自由活动
通过收集眼动追踪和其他行为数据
然后再输入神经网络
从而发现不太明显的模式
这样就降低了对实验控制条件的需求
那么如今的大语言模型
又对神经科学有什么影响呢？
要知道，在传统的神经科学中
理解视觉已经够困难的了
而理解语言更是难上加难
一群神经元是如何掌握句子的意义呢？
教科书中的神经科学方法根本无法解决这样的问题
研究人员可以详细绘制猫的视觉皮层
但是不能绘制猫的语言区域
因为它没有
动物模型最多只能捕捉语言的某些狭窄特征
而现在
GPT等大语言模型的出现则填补了这一空白
虽然在机械层面上
这些模型与大脑的结构相去甚远
因为与语言相关的大脑区域被认为是一个反馈回路的丛林
而语言模型则是一个前馈系统
其中数据从输入到输出是没有环路的
但是
这些系统确实有一些特殊的transformer层
可以像人类大脑一样
行使一些语言的反馈
比如说跟踪单词的上下文
最新研究表明
这些transformer层与大脑中海马体的运作十分相似
不过只能算是一个简化的版本
2021年
麻省理工学院神经科学教授叶夫利娜·费多连科Evelina Fedorenko和她的同事们
开始采用视觉领域同行们十年来一直在使用的AI技术
他们从文献中收集人们阅读和聆听句子时的大脑反应
这些反应是通过fMRI成像
或者是为癫痫患者植入的颅内电极测量得到的
然后，他们利用相同的句子
训练了一系列不同的语言模型
并且创建了一个人类和机器神经活动之间的映射模型
实验发现
这些网络不仅生成了与人类近似的文本
而且是以大致上类似于人类的方式生成的
在他们测试的各种系统中
GPT-2尤其擅长模仿人类
这可能是由于GPT本质上是一个高级的自动更正算法
可以基于之前的内容预测下一个单词
因此，团队认为
人类大脑的语言区域可能也是如此
费多连科他们的研究还表明
大脑和机器之间的差异并没有看起来那么显著
虽然AI模型的学习方式肯定与人类的学习方式不同
但是，实际上
大语言模型在训练大约1亿个单词
相当于一个孩子在10岁时听到的单词数量之后
它们对于语言的熟练程度其实就可以达到人类的水平
进一步来说
当我们理解一个句子的时候
大脑主要依赖的是语法结构
还是单词的含义呢？
在今年4月发表的一篇论文中
费多连科的两名研究生通过各种方式调整句子
看看它们是否影响模型与大脑数据的匹配
在实验中他们发现
对句子的轻微改变
比如去掉“the”，或者交换连续的单词
几乎对AI没有影响
虽然这些改变可能违反了语法规范
但是并没有触及单词的含义
但是
当研究人员以影响含义的方式破坏句子结构的时候
比如改变名词和动词
模型就受到了很大影响
以包含所有26个字母的著名句子“The quick brown fox jumped over the lazy dogs
” 为例
如果研究人员输入的变体是“Quick brown fox jumped over lazy dogs
”，显然
我们的大脑可以从扰乱的句子中形成与原句相同的心理图像
而AI模型也可以做到
由于模型形成的表征编码了一个足够高级的含义
因此不受小词的影响
但是
如果输入的变体是“The quick brown jump foxed over the lazy dogs”，
模型的输出就会与人类数据偏离
表明它生成的表征与之前有很大不同
句子的结构虽然没有改变
仍然是<冠词> <形容词> <形容词> <名词> <动词> <介词短语>，
但是模型必须依赖额外的语义信息
也就是一只狐狸可以跳
但一个跳不能“狐狸”。
费多连科认为
这在某种程度上与乔姆斯基学派的观点是相反的
因为他们长期以来强调的是
句法是语言的核心，而含义是次要的
好了
以上就是神经科学跟人工智能结合的一些案例
目前
这个领域还面临一个巨大的挑战
就是如何将视觉语言与其他认知分离
比如逻辑、社会认知、创造力、运动控制等等
南希·坎威舍尔认为
在这些方面大语言模型还无能为力
尽管它们确实拥有庞大的记忆和某些推理能力
但是仍然只能模拟大脑的语言区域或者视觉区域
因此当ChatGPT等大语言模型产生“幻觉”的时候
其实我们应该意识到
这并不是它们的失败
而是因为我们在强迫它们回答超出能力范围的问题
她还提醒道
过去20年的认知神经科学告诉我们
语言和思维在大脑中是分开的
这对于大语言模型也是一样
回到视频开头的那场纽约大学会议
许多演讲者都提到
虽然AI系统并不能让人获得完全可靠的答案
但是它却能帮助人类理解大脑和神经科学
因为AI系统与人脑足够的接近
可以让神经科学家直接进行比较
但是它们又足够不同
可以帮助人类寻找感知和智能的普遍原则
这些AI系统已经表明，智能是普遍的
不仅只限于人类
甚至不限于哺乳动物
能够提取所接触世界中显著特征的认知系统中
那么大家是如何看待神经科学与AI的结合呢？
AI能够帮助我们理解大脑的运作么？
欢迎在评论区留言，感谢大家的观看
我们下期再见
