大家好，这里是最佳拍档，我是大飞
9月22日，《时代》杂志的网站上
刊发了对如今已经69岁的维诺德·科斯拉（Vinod Khosla）的
一篇有关人工智能的专项采访
我们先简单介绍一下维诺德·科斯拉
他可以算是硅谷最杰出的人物之一了
在20世纪80年代
他和斯科特·麦克尼利（Scott McNealy）
安迪·贝克托尔斯海姆（Andy Bechtolsheim）一起
共同创立了极具影响力的计算机公司Sun Microsystems
并且在2010年将公司出售给甲骨文
随后他建立了风险投资公司
科斯拉风险投资（Khosla Ventures）
对世界各地的绿色技术、医疗保健和人工智能初创公司
进行了大笔的投资
包括2019年对OpenAI的5000万美元早期投资
如今
他也被称为风险投资的四大巨头之一
今天大飞就来带大家深入了解一下
这位独具慧眼的亿万富翁
到底对如今的人工智能发展有什么见解吧
其实这位大佬和人工智能的渊源
可以追溯到2000年
那一年，科斯拉就曾经说道
人工智能将重新定义做人的意义
后来在2011年，他在一次滑雪事故中
膝盖的前交叉韧带受伤
不同的医生针对他的治疗情况
给出了相互矛盾的意见
他从此对如今的医疗保健系统感到十分失望
后来在一篇备受争议的博客文章
《我们需要医生吗？
》中，科斯拉提出
人工智能算法可以比医生更好地完成这项工作
从那时起
科斯拉的公司就开始投资许多的机器人和医疗技术公司
2014年
科斯拉在图像人工智能领域进行了第一笔深度学习投资
不久之后又投资了人工智能放射学
比如放射技术公司Rad AI
2018年底，他决定投资OpenAI
这对他来说是一个巨大的赌局
通常他自己也不会下这么大的赌注
但是他同时也希望能够有机会投资
高风险高回报的技术突破和科学实验
尤其是那些大胆、早期和有影响力的项目
显然，当时的OpenAI非常大胆
也非常早期
所以即便当时没有人打算投资OpenAI
科斯拉依然断定它今后将产生巨大的影响
虽然从科斯拉的第一笔投资到现在
已经过了十多年了
但是自称技术乐观主义者的科斯拉
仍然坚持他当年的断言
今年8月他在接受《时代》杂志采访的事后
还公开表示，在未来
几乎人类目前所有的专业知识
人工智能模型都能免费的提供
为了人类的利益
我们也将拥有大量这样的模型
在去年萨姆奥特曼（Sam Altman）被短暂解雇的时候
科斯拉是公开表示
希望奥特曼重返最高职位的投资者之一
他直言不讳的说道，坦率地讲
我们需要摆脱那些有效利他主义的疯子
他们真的只是宗教偏执狂
他指的
当然是那些策划让奥特曼下台的公司董事会成员
同时
他还公开反驳了董事会成员们的担忧
他说，人类永远在面临风险
我们必须要去管理这些风险
但是这并不意味着
我们要完全放弃像人工智能这样强大技术所带来的好处
虽然科斯拉年事已高
但是在他的眼里
因噎废食这种做法是绝对不可取的
不过，人工智能可能会带来的风险
如今也是显而易见的
那么对于这些风险
在科斯拉看来到底该如何进行预防呢？
科斯拉解释道
Anthropic曾经发表过一篇论文
研究了目前这些人工智能模型的可解释性问题
虽然现在AI离我们想要达到的目标还很遥远
但是相关研究已经在不断得取得进展了
有很多研究人员正在全职研究如何描述模型
以及如何让模型按照我们希望的行为方式来输出
这是一个非常复杂的问题
但是科斯拉相信
只要我们付出努力
一定会在这些模型正式大规模投产之前
拥有能够确保模型安全的技术工具
事实上
他认为国家目前对大学的主要资助
应该主要用在进行安全研究上
科斯拉直言
他确实认为人工智能模型的安全性
在未来十年间会逐步发生改善
但是如果要求在模型部署之前
各方面都完全发展成熟
那就不切实际了
此外
科斯拉风险投资也是为数不多的
否认“只有大语言模型是人工智能
我们不需要其他人工智能模型”这种说法的公司之一
因此
他们正在通过投资一家名为Symbolica AI的英国初创公司
来证实这一点
这家公司采用了完全不同的人工智能方法
通过与自带可解释性的语言模型一起工作
从而达到更高的计算效率
虽然现在还不能完全确定这种方法是否能够起作用
但是这并不意味着我们不应该去尝试
科斯拉说道
他宁愿在尝试之后发现失败
也不愿意不进行尝试就宣告失败
尽管人工智能在具备可解释性之后
也许可以降低一些风险
但是对于这些技术的创造者
比如像萨姆奥特曼这样的人或者公司
我们究竟应该提出什么样的责任和要求
才能确保他们真的在关注相关的研究
并且确保他们始终将安全的思维融入到技术本身呢?
科斯拉不认为现在市面上的主要模型厂商
都在忽视安全这一点
只不过
他们显然不想分享拥有的所有技术
更不可能真正做到无条件的开源
尽管每个人的方法都略有不同
但是其实大家的目的都是一样的
在花费了数十亿美元之后
主动分享他们所获得的一切成果
从资本主义的角度来看也不是一个好方法
但是这并不意味着这些公司不会关注安全问题
科斯拉相信
每个相关的从业者其实都有在关注
甚至坦率地讲
当涉及到机器人技术等领域的时候
安全问题甚至会变得比其他传统行业更加重要
作为2024年《时代》评选的100位
在人工智能领域最有影响力的人之一
科斯拉坚信
人工智能可以取代人类的工作
包括教师和医生在内的几乎一切工作
并且实现让人类摆脱奴役的未来
他认为，因为有了人工智能
人类才将会拥有足够的财富
来选择该做什么和不该做什么
但是，这个未来也许还存在着另一面
当我们用人工智能取代了初级医疗保健等一系列的东西时
劳动力市场会发生什么样的变化呢？
我们又该如何去想象未来的工作呢？
科斯拉依旧坦诚地说道
这一切很难预测
虽然人类很喜欢在未来发生之前预测一切
但是社会的发展是渐进式的
技术的发展也是渐进式的
具体的发展情况
是任何人都很难预测的
所以我们现在预测这些
其实没有特别的意义
不过科斯拉非常乐观地认为
在未来的10年里
每个专业人士都会得到一个人工智能的实习学徒
以此类推
每个程序员也都会拥有一个AI实习程序员
每个医生都会拥有一个AI实习医生
每个老师都会拥有一个AI实习教员
在人类的监督下
这些实习AI可以给人们提供更多的照顾
或者专业知识的应用
不过，这会对经济带来通缩的影响
因为专业知识开始变得廉价或者普及
到后面
也许一个老师可以做原来五个老师的工作
因为背后有五个人工智能的实习生在帮助他们
再往后
科斯拉认为AI最终会取代所有这些工作
人类只能先选择如何与AI共存
来共同补充或优化当下的工作
不过，科斯拉认为现在说这些还太早
毕竟未来是社会的选择结果
至少未来十年
还将是实习AI与人类结合的时代
至于完全取代专业人士
那是更远的未来才会发生的事情
拿看病举例，在美国
普通的初级保健医生每年平进只能看一次普通病人
而在澳大利亚，每年可以看4到5次
因为他们的医生和患者比例不同
但是在有了人工智能的帮助后
美国可以变得像澳大利亚一样
每年可以看五次病人
而不需要培养5倍的医生
所以说，虽然遥远的未来很难预测
但是未来十年内的走向却非常清楚
历史的大潮是不会因为小小的磕绊而停下来的
科斯拉指出，我们在自动驾驶汽车上
已经看到了人工智能的便利性
如果将这些模型可以应用到所有领域
那么人类就可以去做更多的事情了
当然
社会可以选择哪些行业应用人工智能
哪些不应用
这些都可以根据历史和现实进行调整
但是从长远来看
在三十年到五十年之后
人类对于工作的需求将逐渐接近于消失
不止是在美国
在全世界的大部分地区
大多数的工作都不是从业者们的理想工作
而借助于人工智能
我们将会有足够丰富的资源来选择想做什么
不想做什么
科斯拉说道
也许会有更多的孩子成为像美国体操天后西蒙·拜尔斯（Simone Biles）那样的人
或者努力成为下一个篮球明星
但是他也重申
大多数的这些选择应该是由社会做出的
而不是技术来决定，什么是允许的
什么是不允许的
更不可以在技术的允许下罔顾社会现实
我们必须要承认的是
社会的监管一定是有作用的
虽然也不能因为过度的监管而导致科技发展的停滞
关键还在于监管的程度和时机
科斯拉认为
现在还不能放慢科技发展的步伐
从而导致美国落后于其他国家
因为大家正在竞争技术的主导地位
这个世界也并不只有一个美国
坦率地说
欧洲很多国家已经因为过度的监管
将自己排除在了所有主要技术领域的发展和竞争之外
包括人工智能
这种过度的监管只会是自缚手脚
也注定了欧洲在未来的科技竞争中
不会成为主导者
科斯拉还认为，在未来
美国很明显会被几个模型公司主导
像谷歌、OpenAI、Meta和Anthropic这样的机构
将拥有最先进的AI模型
但是
这并不意味着全世界都必须依赖于美国的模型
比方说，在日本和中国
不光是汉字的使用不同
两个国家对国防的需求也不同
如果想要在国防安全中发挥AI的作用
那么就不得不依赖于本土的模型
当然印度也是如此
如果中国有了自己的模型
印度肯定也会争取有自己的模型
欧盟也有Mistral，所以说
AI模型将会根据国家的区分而存在
这是大家很早就认识到的一个趋势
也就是说
拥有大量人口的国家和地区
都会想要自己的AI模型
可是，随着这种国家模式的出现
我们又该如何确保
人工智能的利益在全世界范围内的公平分配呢？
科斯拉认为这确实是一个需要注意的事情
但是他的态度相对乐观
认为这种公平分配会自动的发生
人工智能所带来的许多服务
都将成为免费的政府服务
并且逐渐会更加容易获得
比如为每个人提供一个初级的保健医生和一个AI老师
因为我们已经在其他技术上看到了这种情况的发生
比如互联网
1996年的时候互联网还很昂贵
但是现在智能手机在西方已经相当普及
在发展中国家也正在逐渐普及
所以人工智能也像互联网一样
会随着科技的发展而逐渐普及开来
好了
以上就是科斯拉这次访谈的主要内容了
诚如他所言
他也确实是一个技术乐观主义者
对于人工智能未来的发展
他几乎充满信心并且毫不担心可能带来的危险性
认为只要做好风险管理
就都是可以避免的
那大家对于他的观看有什么看法呢？
AI的国家模式能否带来各个国家之间的相安无事呢？
欢迎在评论区留言，感谢大家的观看
我们下期再见
