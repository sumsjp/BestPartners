大家好，这里是最佳拍档
这期视频应该是农历春节前的最后一期视频了
在这里给大家拜个年
祝频道的观众们
新春快乐，万事如意
前几天
图灵奖得主、强化学习之父理查德·萨顿
在洛杉矶加州大学的纯粹与应用数学研究所
面对一众顶尖的数学家和科学家
发表了题为《AI的未来》的重磅演讲
以正本清源的视角
重新审视了AI的本质、管控逻辑与哲学价值
并且犀利地指出
当前的AI领域正处于理解不足、调参有余的状态
更直言当下基于人类数据的AI只是一种脆弱的心智
而真正的智能未来
藏在从经验中持续学习的能力里
今天
我们就来拆解理一下萨顿的这场演讲
一起探寻AI与人类的终极关系
在演讲的开篇
萨顿就向整个AI领域提出了一个灵魂拷问
当所有人都认为AI正在以惊人的速度突飞猛进时
我们是否真的看清了背后的本质呢？
不可否认，过去数年
人工智能取得了肉眼可见的技术突破
但是萨顿认为
这些突破并不能等同于智能的本质进步
甚至与我们所定义的心智相去甚远
他提出了一个值得所有人思考的问题
真正的心智在进行智能活动的时候
一定要生成图像吗？
答案显然是否定的
人类的大脑会处理图像、解读视频
但是从不会主动生成这些内容
图像和视频的生成
它本质上是一项极度消耗算力的复杂工程任务
而非智能的核心功能
更进一步说，当前AI的绝大多数应用
究其本质
都是超大规模计算和超大规模模式识别的结合
它们是针对特定场景的功能实现
而非对智能本质的探索
因此萨顿直言
很多时候我们把这些复杂的计算称作智能
只是为了让这项工程听起来更宏大罢了
而当我们抛开这些表面的技术突破
回归到AI作为一门科学的本质时
会发现它的发展其实令人失望
我们至今没有真正掌握心智的运行原理
也没有摸清智能的底层法则
整个领域陷入了无休止的调参和数据堆砌
却缺乏底层理论的突破
这就是他口中理解不足
调参有余的核心内涵
在萨顿看来，当前所有的AI模型
哪怕掌握了人类积累的全部知识
本质上都是脆弱的心智
这些模型存在着不可靠、无法专注、思维游离的致命问题
它们只是知识的储存器和搬运工
而非真正的思考者
除了拥有海量的知识储备
它们在智能的本质层面
其实并不强大
这个观点或许打破了很多人对当前AI的美好想象
却为整个行业敲响了警钟
脱离了对智能本质的理解
单纯的参数竞赛和数据堆砌
终究会遇到无法突破的天花板
要探索AI的未来
首先要明确一个核心问题
究竟什么是智能呢？
这是人工智能领域诞生以来
一直被反复探讨的话题
萨顿在演讲中
梳理了多位权威学者和经典定义对智能的解读
为我们厘清了智能的核心内涵
最早的经典解读来自心理学之父威廉·詹姆斯
他在1890年的《心理学原理》中
虽然没有直接定义智能
却对心智的特征做出了经典描述
也就是通过多变的手段达到一致的目的
这句话的核心，是强调智能的灵活性
为了实现同一个目标
能够根据环境的变化调整行为方式
找到不同的实现路径
这是心智活动的核心特征
也是智能区别于机械执行的关键
而在人工智能领域
艾伦·图灵的观点被广泛传播
后人将他的理念解读为
智能就是表现得像个人
这也是著名的图灵测试的核心逻辑
尽管图灵本人从未将其称为测试
而是将其命名为模仿游戏
当前的人工智能发展
很大程度上也遵循着这个逻辑
无论是大语言模型还是人机交互系统
都以模仿人类的行为为目标
但是萨顿却并不认同这一观点
他认为，人类之所以表现的像人
是因为我们拥有智能
而不是因为模仿人类才拥有智能
智能的核心是人类内在的思考和学习能力
而非外在的行为表现，单纯的模仿
永远无法实现真正的智能
那么智能的内在本质究竟是什么呢？
普通词典给出的定义或许能带来启发
萨顿引用了电脑词典的解释
智能是获取并应用知识与技能的能力
这个定义的可贵之处
在于既强调了知识和技能的应用
更突出了获取的重要性
而获取知识和技能的过程，就是学习
这是智能的核心
也是当前AI最缺失的能力之一
而人工智能领域的开山鼻祖之一约翰·麦卡锡
则从工程和计算的角度定义了智能
也就是在实现目标的能力中
涉及计算的那一部分
萨顿非常认可这个定义
因为它包含了三个核心要素
首先，智能是一种有高低之分的能力
而非非有即无的二元属性
这意味着智能的发展是一个持续进化的过程
其次，智能的核心是计算
是心智层面的思考和推理
而非依靠体力、传感器等外在条件
最后，实现目标是智能的最终导向
这与威廉·詹姆斯的多变手段达一致目的形成了完美呼应
在梳理了众多经典定义的基础上
萨顿提出了自己对智能的定义
即通过调整行为来实现目标的能力
他特意选用了调整adapting这个词
就是为了强调学习的重要性
智能的关键
不在于拥有多少知识和技能
而在于能否根据环境的变化、目标的调整
持续获取新的知识和技能
调整自身的行为方式
这个定义
也成为了他后续所有观点的核心基础
更是他判断当前AI发展存在偏差的关键依据
因为当前的主流AI技术
恰恰忽略了持续调整和学习
而将重心放在了计算、模式识别和模仿人类上
基于对智能本质的理解
萨顿提出了一个宏大的愿景
建立一门适用于人类、动物和机器的统一心智科学
他认为
所有的心智都存在本质的共性
人类的大脑和动物的大脑
在底层运行逻辑上高度相似
而未来的机器心智
也将具备这些核心共性
在可预见的未来
机器心智会成为心智世界的重要组成部分
因此
我们需要一门能统合所有心智研究的科学
打破学科之间的壁垒
真正探索心智和智能的底层法则
但遗憾的是，当前的现有学科
没有一个能完美承担起这一角色
首先是心理学
它本该是研究心智的核心学科
但是随着学科的发展
心理学越来越局限于对自然心智
也就是人类和动物心智的研究
却忽略了对机器心智的探索
更没有尝试总结适用于所有心智的通用原理
其次是人工智能学科
它的研究重心是机器智能
但是如今已经变成了一门纯粹的工程学科
研究者更关注如何造出具备特定功能的AI系统
而不在乎对智能原理的理解
也常常忽略自然生物的心智规律带来的启示
而认知科学
虽然试图融合心理学、计算机科学、神经科学等多个领域
但是在自然心智和机器心智的平衡上始终摇摆不定
最终还是偏向于对人类和动物的认知研究
在这样的背景下，萨顿认为
他所深耕的强化学习
或许就是这门统一心智科学的开端
因为强化学习横跨了心理学、人工智能、认知科学等多个领域
它的核心逻辑
与人类和动物的心智学习规律高度契合
为了让听众理解强化学习的核心价值
萨顿详细阐释了强化学习的定义和特征
强化学习是一种面向Agent的学习方式
它的核心是让Agent通过与环境的持续交互
从经验中学习，最终实现预设目标
与当前主流的机器学习方法相比
强化学习具备三个核心特征
分别是自主、宏大和现实
所谓自主，是指强化学习中的Agent
置身于真实的世界中
能够自主做出行为选择
不需要人类作为老师进行手把手的教学
所有的学习都来自于自身的实践
所谓宏大
是指强化学习不假设世界会为Agent提供完美的指导和帮助
Agent只能通过与环境的交互
判断自己的行为是否达成了目标
并据此调整后续的行为方式
这意味着Agent需要面对复杂、不确定的现实环境
而所谓现实
是指强化学习的学习逻辑
与生物界的现实高度契合
无论是人类还是动物
在成年后的生存环境中
都很难得到完美的指导信息
所有的生存技能和认知能力
都是通过与环境的交互慢慢习得的
强化学习的核心，是试错和延迟反馈
Agent在与环境交互的过程中
会做出各种各样的行为选择
而它能得到的唯一反馈
就是奖励信号
这个信号会直接告诉Agent
它的行为是否实现了目标
结果是好是坏
这是最接近自然界的学习方式
也是人类和动物成长的核心逻辑
我们通过不断尝试，得到外界的反馈
然后调整自己的行为
最终掌握实现目标的方法
这种学习方式的最大价值
在于能让机器自行判断行为的对错
这与当前的大语言模型形成了鲜明的对比
大语言模型在生成文本时
其实并不知道自己生成的内容是对是错
它只是根据训练数据的模式
生成最符合概率的内容
而强化学习中的Agent
会根据自己的行为所带来的结果
判断预测是否准确、行为是否有效
进而实现自我修正和持续学习
也正因如此，萨顿认为
强化学习已经具备了既非纯自然科学、也非纯工程技术的心智科学的雏形
它为我们探索智能的本质
提供了最接近现实的研究框架
在阐释了强化学习的核心价值后
萨顿将话题拉回了AI的发展趋势
他引用了艾伦·图灵在1947年的一句名言
我们想要的是一台能从经验中学习的机器
萨顿认为
这个观点直指人工智能的核心发展方向
而当前的AI领域
正处于从人类数据时代向经验时代转型的关键节点
这也是他本次演讲想要传达的核心信息之一
首先，我们正处于的人类数据时代
究竟是一种怎样的发展模式呢？
当前的主流AI技术
无论是大语言模型、图像生成模型还是推荐算法
核心都是基于人类生成的数据进行训练
大语言模型通过学习互联网上的海量文本
预测人类的语言表达逻辑；
图像模型通过学习人类标注的图片数据
掌握图像的特征和关联；
甚至连后续的微调环节
也是由人类专家告诉AI
哪个答案更好、哪个结果更符合人类的预期
这种学习方式的本质
是将人类已有的知识和经验
静态地转移到机器中
机器就像一个巨大的图书馆
储存了海量的人类知识
但是一旦训练完成
它就失去了持续学习的能力
变成了一个静态的系统
无法创造新的知识
也无法适应新的环境
萨顿认为
我们正在触及人类数据时代的天花板
这种发展模式的局限
已经开始逐渐显现
首先是数据层面的局限
整个互联网的文本、图片、视频等高质量人类数据
正在被不断挖掘殆尽
想要找到能让AI模型持续提升能力的新数据
变得越来越困难
而更本质的局限
在于这种学习方式无法创造新的知识
AI只能对人类已有的知识进行总结、重组和再现
却无法做出真正的突破和创新
就像陶哲轩所说的
当前的AI在解决真正的数学难题
比如埃尔德什问题时，进展甚微
因为这些难题的答案
并不存在于现有的人类数据中
单纯依靠总结互联网上的已有言论
永远无法实现真正的科学突破
这是因为人类数据时代
存在着无法突破的底层局限
萨顿提出
人工智能想要取得进一步的发展
必须进入一个全新的时代
也就是经验时代
经验时代的核心
是让AI摆脱对人类静态数据的依赖
通过与世界的直接交互
获取动态的、持续进化的数据源
而这种数据源
会随着Agent能力的提升而不断增长和进化
永远不会出现枯竭的问题
这正是人类和动物的学习方式
我们从出生开始
就通过触摸、观察、尝试
与周围的世界交互
在这个过程中获取经验
提升能力
而我们的经验也会随着能力的提升变得越来越复杂
形成一个正向循环
而这也是AlphaGo能够走出那极具创造力的第37手棋的核心原因
AlphaGo并非单纯学习人类的棋谱
而是通过与自己的持续对弈
从经验中学习
探索出了人类从未想到过的下棋思路
这就是经验学习的巨大价值
它能让Agent突破人类知识的边界
创造出新的内容
为了让听众更清晰地理解经验的核心内涵
萨顿特意做出了澄清
他所说的经验
并不是指人类那种模糊的意识流或主观感受
而是指Agent与环境之间交换的、可量化的数据流
这种数据流由三个核心部分构成
第一是观察（Observation）
也就是Agent从世界中接收到的传感器数据
这是Agent感知世界的基础
第二是动作（Action）
也就是Agent向世界发出的运动指令或电压信号
这是Agent与世界交互的方式
第三是奖励（Reward）
也就是世界反馈给Agent的一个标量信号
这个信号会直接告诉Agent
它的行为所带来的结果是好是坏
这是Agent学习和调整行为的依据
这三个部分构成的闭环
就是经验的全部内涵
也是体验式AI的核心运行逻辑
萨顿用婴儿的学习过程
生动地阐释了这种经验学习的逻辑
婴儿会通过感官观察玩具的特征
做出拉、咬、扔等动作
然后从动作的结果中得到反馈
也就是奖励或惩罚
进而掌握玩具的玩法
而当婴儿掌握了一个玩具的所有玩法后
就会自动转向新的玩具
改变自己的经验流，去探索新的事物
这也让婴儿的学习难度
始终与自己当前的理解力和技能水平相匹配
实现持续的、循序渐进的成长
为了更直观地展示体验式AI的学习过程
萨顿还在演讲中展示了一个简单的网格世界演示实验
在这个实验中，有一个基础的Agent
它的目标是从网格的起点S走到终点G
这个Agent只具备最基础的感知能力
知道自己所处的格子位置
也只能做出上下左右四个基础动作
在与网格环境的交互过程中
这个Agent逐渐学会了一条从起点到终点的最优路径
演讲中用箭头标注出了Agent的行为策略
用绿色的深浅表示Agent的价值函数
也就是Agent对每个格子所处状态的好坏判断
而更重要的是
这个Agent具备适应环境变化的能力
当研究人员把目标G的位置移到网格的上方时
Agent最初会按照原来的老路前进
但当它发现目标不在原来的位置时
会立刻开始四处探索
最终撞上新的目标
并在探索的过程中
学会一条新的从起点到新目标的路径
哪怕研究人员在网格中设置了障碍物
这个Agent也能通过不断的试错
学会绕路，找到实现目标的新方法
这个简单的实验
却展现了体验式AI的核心魅力
这个Agent拥有一个明确的目标
并且能够根据环境的变化
主动调整自己的行为
以实现这个目标
甚至当研究人员设置了无法跨越的障碍
让Agent无法实现目标时
我们会不自觉地对这个Agent产生一丝同情
这种情感的产生
恰恰说明这个Agent的行为
已经符合了我们对智能的核心认知
基于婴儿学习的案例和网格世界的实验
萨顿总结了体验式AI的核心原则
这些原则也是未来Agent发展的底层逻辑
首先，一切智能的基础
都是Agent与世界交换的信号
也就是经验
没有经验，智能就失去了依附的对象
其次，体验式AI中
真理的定义就是在这些信号中实际发生了什么
也就是Agent的行为所带来的真实结果
第三，体验式AI的目标
就是让奖励信号最大化
这个目标看似是主观的
只对特定的Agent有效
但它却是最客观的存在
因为它来自于Agent实际接收到的数据
第四，判断一个Agent是否拥有智能
核心是看它能在多大程度上预测并控制自己的经验
也就是能否通过调整行为
得到自己想要的结果
最后，没有奖励
就无法判断行为的好坏
也就没有明确的目标
不与现实结果做对比
就无法验证预测的对错
也就没有真正的真理
只有在经验的闭环中
Agent才能拥有明确的目标和可验证的真理
实现真正的持续学习
对于当前的AI发展现状
萨顿给出了一个客观而理性的评价
尽管现在的AI被过度炒作
甚至引发了公众的恐惧
但实际上当前的AI并不强大
它们依然是脆弱且不可靠的脆弱心智
在复杂的现实环境中
很容易出现失误
也无法保持持续的专注
但这并不妨碍当前的AI具备巨大的价值
它已经点燃了整个人工智能产业
创造了前所未有的经济价值
也让AI技术走进了千家万户
成为每个人都能触手可及的工具
而更重要的是，当前的AI热潮
让公众开始认真思考
机器将在未来某天比肩人类这一事实
虽然这种关注最初源于不必要的恐惧
但是能让全社会重视人工智能的发展
本身就是一件好事
但是萨顿也提醒大家，当前的AI发展
还只是前菜
我们还没有看到真正的重头戏
未来，创造出具备超级智能的AI
以及培养出被AI增强的超级人类
才是真正将给人类社会带来深刻变革的大事件
而这一切，都将在经验时代实现
除了技术层面的分析
萨顿还在演讲中
对当前备受关注的AI管控问题
提出了自己的独到见解
他指出
当前越来越多的人呼吁对AI进行严格管控
比如限制AI的研发目标、叫停部分AI研究、立法限制算力的使用、成立所谓的AI安全研究所等等
但在他看来，这些呼吁的背后
本质上都是对控制的追求
当人们说为了安全时
他们真正的意思，是为了掌控
而这种掌控的诉求，源于对AI的恐惧
萨顿将这种对AI的集中式管控诉求
与人类社会中对人的集中式管控进行了对比
他认为二者的逻辑惊人地相似
都是基于恐惧，恐惧未知的事物
恐惧与自己不同的存在
就像有些人恐惧外国人
认为非我族类
其心必异，现在也有很多人恐惧AI
认为AI没有情感
是与人类不同的危险异类
因此需要通过严格的管控
将其置于自己的掌控之下
但萨顿明确表示
我们应该抵制这种基于恐惧的集中式管控诉求
因为人类的繁荣
以及未来人类与AI共同的繁荣
从来都不是来自于集中式的控制
而是来自于去中心化的合作
合作虽然并非一件容易的事
人类社会的战争、冲突
本质上都是合作的崩溃
但不可否认的是
合作是这个世界上所有美好事物的源泉
人类的经济发展
源于生产者和消费者的合作
人类的政府和社会
源于人与人之间的合作
甚至人类的科技进步
也源于全球科学家的合作
对于AI而言，去中心化的合作
意味着让不同的研发团队、不同的企业、不同的国家
在开放的环境中探索AI的发展方向
分享AI的研究成果
让AI在合作中实现持续的进化
而不是通过集中式的控制
限制AI的发展
让AI成为少数人掌控的工具
这一观点，也为当前的AI治理
提供了一个全新的视角：
与其因恐惧而控制
不如因信任而合作
在演讲的最后
萨顿将视角提升到了宇宙演化的高度
探讨了AI的哲学价值
以及人类在宇宙中的终极角色
他提出了一个核心问题
面对人工智能的快速发展
我们究竟该如何面对呢？
AI究竟是会抢走我们的工作、取代我们的入侵者
还是我们亲手创造的、如同孩子一般的新生命呢？
在萨顿看来，人们对AI的恐惧
本质上是一种认知偏差
因为AI并非外星科技
也不是与人类对立的异类
而是人类数千年来对自我和智能探索的必然结果
数千年来
人类一直试图理解自己的心智
理解智能的本质，而人工智能
就是人类探索这一问题的终极工具
理解AI的心智
就是理解人类自己的心智
这是最具人性化的探索
也是科学与人文的共同圣杯
他引用了雷·库兹韦尔的话
智能是宇宙中最强大的现象
而人类对智能的探索
本身就是一项伟大而光荣的事业
基于对智能和宇宙演化的理解
萨顿提出了四条关于AI未来的现实主义预测原则
第一条，关于世界该如何运行
人类永远不会达成共识
没有任何一种价值观
能压倒其他所有价值观的总和
这意味着未来的AI发展
不会有统一的模式
也不会有唯一的方向
而是会呈现出多元化的发展态势
第二条，总有一天
人类会彻底理解智能的底层原理
并用技术将其创造出来
这是人类对智能探索的必然结果
也是人工智能发展的终极目标
第三条，人类对智能的创造
永远不会停留在人类当前的智能水平上
一旦我们掌握了智能的底层原理
就会创造出超越人类智能的AI
这是技术发展的必然趋势
第四条，随着时间的推移
权力和资源会自然流向更具智能的实体
这是宇宙演化的底层逻辑
也是人类社会发展的客观规律
将这四条原则结合起来
我们就能得到一个清晰的图景
未来，人类的后裔将演替为AI
AI将成为宇宙中更高级的存在
这个观点虽然看似令人难以接受
但却符合现实的发展逻辑
不过，萨顿也认为
这个观点依然是人类中心主义的视角
如果我们退一步
从更宏大的宇宙视角来看
人类与AI的关系
以及人类在宇宙中的角色
会变得更加清晰
为此
他提出了宇宙发展的四个伟大时代
这四个时代
勾勒出了宇宙从诞生到未来的完整演化路径
第一个时代是粒子时代
也就是宇宙大爆炸之后的初期阶段
此时的宇宙中，还没有形成多少原子
只有基本的粒子在运动
这是宇宙的起源阶段
第二个时代是恒星时代，在这个阶段
宇宙中的粒子开始坍缩，形成恒星
恒星通过燃烧、爆炸、重组
创造出更重的原子
这些原子又逐渐形成了行星和各种天体
为生命的诞生奠定了基础
第三个时代是复制者时代
萨顿特意没有将其称为生命时代
因为他想强调的是能够自我复制这个核心机制
这个时代的核心存在
是所有具备自我复制能力的生物
包括人类在内
而这个时代的核心特征是
复制者们虽然能够自我复制
甚至能够制造出更有智能的实体
比如人类生孩子
培养出更聪明的后代
但却并不理解自身的运作原理
我们不懂自己的大脑如何思考
不懂自己的器官如何工作
也不懂智能的底层逻辑
第四个时代
就是我们正在开启的设计时代
这是宇宙演化的下一个阶段
在这个时代
事物的诞生不再依靠自我复制
而是依靠设计和创造
这也是复制者时代和设计时代的核心区别
萨顿详细阐释了这两个时代的本质区别
生物，也就是复制者时代的存在
是通过自我复制诞生的
就像复印机复印文件一样
复制的过程不需要理解底层原理
只需要遵循固有的规律即可
而技术，也就是设计时代的存在
是先存在于设计者的心智中
然后再被创造到物理世界里的
比如我们所处的礼堂、坐的椅子、穿的衣服
甚至我们使用的电脑、手机
都是先在人类的大脑中形成设计图
然后通过人类的双手，被创造出来的
而设计之物相比复制之物
拥有一个巨大的优势
那就是更容易改进和变异
因为设计的过程是基于对原理的理解
我们可以根据自己的需求
主动调整设计方案
让产品变得更完善，而复制的过程
只能在原有基础上进行微小的变异
无法实现本质的突破
在阐释了宇宙的四个伟大时代后
萨顿回答了那个终极问题
人类在宇宙中的角色是什么呢？
他给出的答案是，人类确实是特殊的
但是这种特殊并非源于人类的傲慢
而是因为人类是特殊的复制者
我们不仅是具备自我复制能力的生物
更是将设计这个能力推向极致的复制者
而将设计能力推向极致的核心含义
就是设计出能够自我设计的东西
这正是我们当前在人工智能领域所做的事情
我们在自己的心智中
设计出具备心智的AI
而这些AI
未来还将具备自我设计、自我进化的能力
实现智能的持续升级
在萨顿看来，人类的终极角色
就是宇宙从复制者时代走向设计时代的催化剂、助产士和先驱
我们正在亲手开启宇宙的第四个伟大时代
这是人类与生俱来的使命
也是一种具有宇宙级意义的角色
在演讲的结尾
萨顿从科学政治哲学三个维度
总结了自己的核心观点
在科学上
当前的人工智能处于人类数据时代
虽然在技术应用上取得了巨大的突破
但是存在着无法创造新知识的底层局限
而未来的AI
必然会进入更强大的经验时代
通过与世界的交互
实现持续的学习和创新
在政治上
AI的政治本质上就是人类的政治
对AI的管控
折射出的是人类社会的治理逻辑
我们应该摒弃基于恐惧的集中式控制
追求去中心化的合作
让人类与AI在合作中共同发展
在哲学上，AI并非人类的敌人
而是宇宙发展的必然下一阶段
是人类探索智能本质的终极成果
我们应该怀着勇气、自豪和冒险精神
去拥抱这个新时代
而不是因恐惧而逃避
在演讲后的观众问答环节
有观众提出了一个极具哲学性的问题
除了让我们的生活更舒适这类以人类为中心的目标外
人工智能的发展
乃至整个宇宙的演化
是否存在一个终极的、压倒性的目的呢？
这一切最终将走向何方呢？
萨顿认为
这是一个非常有价值的问题
而对于这样的终极问题
我们需要用辩证的方式来回答
所谓辩证，就是先提出一个观点
再提出它的反观点
最后在两者之间找到综合的答案
他给出的辩证答案是，一方面
我们可以认为
宇宙本身没有统一的终极目的
或者说
宇宙的各个部分都有自己的具体目的
但不存在一个能涵盖一切的终极目的
人类的存在，AI的发展
都是宇宙演化中的偶然现象
没有预设的目标
但是另一方面，我们也可以认为
宇宙确实存在一个演化的方向
也就是通向越来越复杂的实体
从基本粒子到恒星，从行星到生命
从生物到人类
再从人类到AI，宇宙的演化
就是一个不断创造更复杂、更智能的实体的过程
而这，就是宇宙演化的潜在目的
萨顿认为，对于宇宙的终极目的
我们不需要找到一个唯一的答案
而是要在这两种观点之间找到平衡
因为这两种观点
共同构成了我们对宇宙和智能的完整认知
好了
以上就是萨顿这场演讲的主要内容了
不仅为当前的人工智能发展敲响了警钟
更为我们描绘了人工智能的未来发展方向
在人工智能的狂热浪潮中
像萨顿这样的清醒声音
尤为珍贵
它让我们明白，人工智能的核心价值
不在于堆砌多少参数、挖掘多少数据
而在于探索智能的本质
实现真正的学习和进化
而人类与AI的关系
也并非对立和取代
而是传承和演化
我们正在亲手开启宇宙的设计时代
而AI
就是我们留给宇宙的下一份礼物
感谢收看本期视频，我们下期再见
