大家好，这里是最佳拍档
今天
我们来聊Google Gemini 3模型背后的故事
以及分享一位行业巨擘的深度见解
他就是 Gemini 3项目的预训练负责人
塞巴斯蒂安·布尔若
作为全球顶尖的人工智能研究者
同时也是Metis名单成员
这是他首次参与播客录制
在对话中
他不仅揭秘了Gemini 3的底层构建逻辑
更抛出了多个足以撼动行业认知的硬核观点
从模型研发到团队管理
从行业的趋势到未来的展望
每一个话题都很有深度和启发性
所以今天给大家分享一下
首先
我们不得不聊一聊Gemini 3的成功密码
很多人可能会觉得
这样一款实现了跨代级飞跃的模型
背后一定有某个惊天动地的核心技术突破
但是布尔若却给出了一个看似朴素、却蕴含深意的答案
他提到
Gemini的联合负责人奥雷尔·维尼在Gemini 3发布时曾经表示
模型的成功秘诀
其实就是更优质的预训练和后训练
而这背后
是庞大的团队共同努力的结果
不同于大家对于天才灵感会主导创新的固有认知
Gemini 3的进步
并不是源于一两个关键性的突破
而是两百多人的团队在模型、数据、基础设施、评估等多个维度
进行了无数次像素级的微小改进
这些改进和创新的合力
最终才促成了模型的巨大飞跃
布尔若作为预训练的负责人之一
他的工作既要致力于提升模型的性能
也包括复杂的协调和整合工作
要知道，预训练团队规模相当庞大
大约有将近两百个人
每天都围绕着预训练的相关领域忙碌
涵盖了数据筛选、模型架构的优化、基础设施搭建、评估体系完善等多个方面
因此，协调这么多人的工作
让每个人都能发挥所长、取得进展
其实是一项非常复杂而且耗时的任务
但是布尔若认为这非常重要
因为从长远来看
成功的关键在于整合众多人的工作成果
而不是依赖少数人的领先
短期来看
少数人的突出贡献可能会带来一定的效果
但是只有让整个团队形成合力
才能实现真正的跨代级突破
这也正是Gemini 3成功的核心逻辑之一
通过极致的集体让卓越平庸化
这里的平庸化并不是指能力普通
而是强调每一个微小改进的积累
通过每一个团队成员的付出
最终汇聚成不可阻挡的创新力量
布尔若提到
行业正在从数据无限时代
转入数据有限模式
这个范式的转变切实改变了许多研究方向
以及我们思考问题的方式
在过去，很多人认为
只要不断堆砌算力、扩大数据的规模
模型的性能就会持续提升
但是现在的情况已经不同了
虽然缩放定律还没有触顶
规模仍然是预训练中一个非常重要的方面
能够以相对可预测的方式提升模型性能
但是人们之前可能高估了规模的作用
它并不是唯一的因素
如今，架构创新和数据创新的重要性
甚至超过了单纯的规模扩大
真正的胜负关键在于
怎么样在有限的数据池里
通过架构优化挤出更多的智能
这一点在DeepMind的实践中也得到了体现
布尔若和他的团队曾经开展过Chinchilla项目
这个项目重新研究了
在固定的训练计算资源下
怎样调整模型规模和数据规模
才能训练出性能最佳的模型
他们发现，与之前的认知相比
数据规模的扩展速度应该更快
而不是一味的扩大模型规模
这个发现对模型训练完成后的部署成本和使用成本
有着重要的影响
另外一个分支项目是Retro
这个项目更侧重于架构方面的创新
探索了如何通过让模型能够从大型文本语料库中检索信息
来提升模型的性能
也就是说
不要求模型将所有的知识都存储在参数中
而是让模型在训练和推理的过程中
都能够查找特定的信息
这个思路至今仍然具有重要的实践意义
在这样的行业背景下
研究品味成为了决定模型生死的关键因素
这也是布尔若非常强调的一点
他认为，如今的研究品味很难量化
但是有几个关键要素
首先，研究不能是孤立的
必须能够和其他人的研究相互配合、相互整合
比如
某项模型改进虽然能提升单一指标
但是如果让其他人使用模型的难度
增加了百分之五
那么这很可能不是一个好的权衡
因为它会拖慢整个团队的研究进度
进而影响整体进展
其次，要对复杂性保持着警惕
研究中能够承受的复杂性是有限的
同时也需要控制研究风险
因此
团队往往会放弃性能最优、但是复杂度过高的方案
在性能上做一些让步
选择复杂度比较低的版本
因为这有助于未来取得更多的进展
除此之外，研究品味还包括一种直觉
如何能够在计算资源有限的情况下
判断哪些研究方向可能可行
哪些可能不可行
毕竟，大多数的研究想法都不会成功
研究者需要判断
在某个方向上投入多少精力后
应该转向其他方向
或者是不是应该继续坚持
而且在深度学习领域
一个负面结果并不意味着某个方法行不通
而往往意味着还没有找到让它可行的方法
所以意识到这一点也非常关键
布尔若提到
在资源极其昂贵的预训练阶段
最难的不是决定做什么
而是决定不做什么，这种取舍的智慧
正是研究品味的核心体现
在研究过程中
还有一个重要的平衡问题
那就是短期目标和长期目标的权衡
布尔若表示
总会有一些关键路径上的事情需要完成
比如模型的某个部分需要改进
或者知道模型的某个部分不够优化
这时侯就需要投入大量的精力来解决这些眼前问题
这样做
一方面是因为这些改进肯定会提升模型的性能
是相对安全的赌注
另一方面
那些看起来不够完善的部分
在未来模型规模扩大或者能力增强的时侯
往往会引发更多的问题
因此认真对待并解决这些问题非常重要
而另一方面则是更具探索性的研究
这些想法可能会应用在下一个版本
或者再下一个版本的Gemini
它们可能会对模型性能产生更大的影响
但是目前还没有得到充分验证
这种平衡并没有一个固定的答案
而且具有一定的周期性
比如，在模型规模扩张的阶段
探索性研究通常会多一些
因为此时没有太多需要并行解决的紧急问题
但是在即将推出新架构或者新模型之前
工作的重点会转向降低风险
更多关注执行层面
值得一提的是
在DeepMind
研究和产品之间的张力相对较小
因为所有的领导层都有研究背景
他们非常清楚
虽然在一定程度上可以强制加速特定的基准测试和某些目标的实现
但是最终
研究工作的进展才是最为关键的
这也让研究团队能够更加专注在长期价值的创造上
说到团队
DeepMind的组织架构也为研究的顺利推进
提供了重要的保障
从最高层面来看
有预训练团队和后训练团队
在预训练团队中
有专门负责模型、数据、基础设施和评估的人员
其中评估工作被布尔若认为是非常重要
但是往往被低估的部分
做好评估其实是一件非常困难的事情
此外
还有庞大的团队负责基础设施和部署工作
各个团队之间紧密协作
形成了高效的研发体系
这种架构设计
既保证了专业领域的深度钻研
又实现了跨领域的协同配合
为模型的持续迭代提供了有力的支撑
从宏观架构来看
Gemini 3是一个基于Transformer的混合专家架构
与前一个版本相比
架构并没有发生太大的变化
不过
Gemini 3的一个重要特性是原生多模态
这意味着并不存在专门处理图像、音频或者文本的独立模型
而是由同一个神经网络同时处理所有这些不同的模态
这种设计虽然带来了显著的性能优势
但是也涉及到了成本问题
布尔若提到
原生多模态的成本主要体现在两个方面
一是复杂性成本和研究成本
因为要处理更多的任务
尤其是不同模态之间的相互作用
这会影响到研究的多个方面
增加复杂性
所以需要花费更多的时间来进行思考和研究
二是计算成本
和纯文本相比
图像的输入规模通常会更大
如果采用简单直接的处理方式
实际的计算成本会更高
但是通过相关研究可以提高这些处理过程的效率
而且带来的收益在很大程度上超过了成本
所以这也是DeepMind坚持训练这类模型的原因
在预训练数据方面
Gemini 3的预训练数据是多种数据来源的混合
本质上是多模态的
包含了许多不同模态的信息
而行业内有一个备受关注的问题
就是数据枯竭
人们经常讨论未来是不是会面临数据不足的困境
布尔若认为这种情况并不会发生
虽然行业正在从数据无限转向数据有限的模式
但是这并不意味着数据量减少了
而是数据量是有限的
这种范式转变促使研究方向发生了调整
就像在大语言模型出现之前
很多人是基于ImageNet等基准测试开展研究的
因此诞生了很多适用于该阶段的技术
如今
同样会在数据有限的范式下涌现出新的创新
合成数据也是当前行业内的一个热门话题
布尔若认为合成数据是一个有趣的领域
但是使用时必须非常谨慎
因为很容易误用
通常情况下
人们会使用一个性能强劲的模型来生成合成数据
然后通过小规模的消融实验
来验证合成数据的效果
但是这里的一个关键问题是
能不能生成合成数据来训练一个未来模型
并且让这个新模型的性能
优于生成合成数据的原始模型呢？
DeepMind在这方面投入了大量时间进行思考和研究
在预训练的发展方向上
布尔若提到了长上下文的能力
他认为这是一个非常有潜力的方向
在Gemini 1.5中
DeepMind在长上下文的能力方面取得了巨大飞跃
使得如今的模型和Agent能够处理像代码库之类的大型任务
他预测未来的一两年内
在这方面将会有更多的创新
不仅会提高长上下文处理的效率
还会进一步扩展模型的上下文长度
此外
注意力机制也是一个重要的研究方向
最近取得的一些有趣发现
将在未来的几个月内
塑造许多的研究方向
还有一个容易被忽视、但是至关重要的方面
就是评估
布尔若强调
评估在预训练中非常困难
因为它需要弥合两个差距
一方面
日常训练和评估所使用的模型
通常会比最终规模化后的模型更小、性能更弱
因此评估方法必须能够预测大模型的性能
仍然能够为大模型指明正确方向
也就是说，它必须是一个良好的指标
另一方面，还存在后训练差距
模型在预训练后并不会直接投入使用
还会进行后续训练
因此在预训练阶段或者对预训练模型进行的评估
必须能够很好的反映模型在后续训练中的表现
因此，评估方面的进步
在很大程度上推动了模型和数据改进方面的进展
因为它让研究者能够准确的衡量
模型或者数据的实际改进效果
为了保证评估的准确性
DeepMind的评估体系在很大程度上是在内部构建的
而且越来越倾向于在内部构建
因为外部基准测试虽然可以在短期内使用
但是很快就会受到污染
这些基准测试的内容
会以不同形式在网络上传播
如果训练数据中包含了这些内容
就很难检测出来
因此，想要避免自欺欺人
真正了解模型的实际性能
唯一的方法就是创建独立的评估集并且严格保密
关于对齐问题
布尔若表示大部分的对齐工作是在后续训练阶段进行的
但是预训练阶段也有一些相关工作
当被问到如果核心数据集来自互联网
而互联网上有很多不良信息
对齐的首要原则
是否是将这些不良信息排除在模型训练之外的时侯
他给出了一个耐人寻味的答案
他说，模型需要了解这些不良信息
才能知道要远离它们
因此至少需要让模型接触一部分这类信息
以便它能够识别这些不良内容
并且避免产生相关输出
否则当用户提到某些不良信息的时侯
模型可能根本不知道用户在说什么
也就无法判断这是不良信息
在对话中，主持人还提到了DeepThink
这是在Gemini 3发布几天后推出的思考模型
虽然布尔若没有透露太多的具体信息
但是他解释了这类思考模型的工作原理
和仅在模型内部进行的计算不同
这类模型会在序列长度层面进行计算
让模型有更多的思考空间
模型会开始提出假设、测试假设、调用一些工具来验证假设、进行搜索等等
最后可能会回顾整个思考过程
为用户提供一个明确的答案
而对于谷歌的Gravity项目
布尔若认为Agent在执行层面的工作中能够带来最大的影响
比如监控实验进程等等
而视觉感知方面对于Agent来说非常重要
因为我们现在开始要求模型能够和计算机屏幕进行交互
因此
具备出色的屏幕理解能力非常重要
这也是预训练阶段的一个重要方面
此外
持续学习也是一个重要的研究方向
所谓持续学习
本质上是指随着新知识的发现
不断用这些知识更新模型
比如明天出现了一项新的科学突破
而昨天训练的基础模型并不知道这项突破
如何让模型快速吸收这类新的知识
就是持续学习要解决的问题
在这个方面
布尔若认为过去几年已经取得了很大的进展
这主要体现在后训练和搜索方面
通过使用搜索工具进行搜索调用
模型可以获取新的信息
这也正是Retro项目所做的事情
通过检索数据
尝试将知识语料库和推理部分分离开来
另一方面
持续学习也和长上下文的能力相关
一种实现方式是不断扩展用户的上下文
让模型在上下文中获取更多的信息
从而具备持续学习的能力
但是这可能还需要一场更大的范式转变
比如改变训练算法
让模型能够持续从来自现实世界的数据流中进行学习
当被问到人工智能领域是不是存在过度投资时
布尔若表示现在情况已经好多了
大约两年前
很多人还在试图创建专门的模型
来解决那些通用模型在半年或者一年内
就能够解决的任务
但是现在人们已经逐渐意识到
对于通用任务或者不需要极端专业模型的任务
通用模型可能就能完成
这意味着
关于如何使用模型、如何构建模型应用框架等方面的研究
变得越来越重要
同时如何提高模型和这些应用框架的稳健性
让它们能够减少错误并且从错误中恢复
也是一个重要的研究方向
访谈中
我们还可以了解到布尔若的个人成长轨迹
这位顶尖AI研究者的经历其实非常有启发意义
他的成长背景相当多元
在欧洲的多个地方长大
经常搬家
他出生在荷兰，7岁时搬到瑞士
父亲是瑞士人，母亲是德国人
在瑞士完成了少年大部分学业和高中初期课程
主要使用法语，部分课程使用德语
十五岁时，他又搬到了意大利
在那里完成了高中学业
直到十九岁左右
小时候的布尔若就对编程产生了浓厚的兴趣
他的父亲有技术背景
所以布尔若在十岁或者十一岁的时侯
就开始和父亲一起学习编程
并且一直很喜欢这项技能
在学校里
他在数学和科学方面也表现非常出色
数学考试从来不用特意复习
就能够取得不错的成绩
原本他打算去苏黎世联邦理工学院深造
但是偶然看到一份大学排名
发现剑桥大学位居榜首
于是便决定申请试试
没想到几个月后收到了录取通知书
随后在剑桥大学计算机实验室完成了本科和硕士学业
毕业后进入DeepMind
对布尔若来说算是一个幸运的契机
他硕士期间的一位讲师
同时也是DeepMind的研究员
在最后一堂课结束的时候
他鼓起勇气向这位讲师请求推荐
对方爽快的答应了
帮他获得了DeepMind的面试机会
二零一八年
当时的DeepMind还没有并入谷歌
他以研究工程师的身份加入了公司
最初
他参与的是和强化学习相关的项目
训练无监督网络
来学习Atari游戏环境中的关键点
并尝试让Agent玩Atari游戏
但是他并不喜欢其中的合成性质
一直想从事和真实世界数据相关、能够产生实际影响的工作
于是开始转向表征学习领域
训练能够很好进行表征的神经网络来完成各种任务
他参与的第一个相关项目
名为基于真实世界数据的表征学习
当时之所以要在项目名称中
加上基于真实世界数据这个限定
是因为人们会默认项目使用的是合成环境或者合成数据
而从那以后，情况发生了彻底改变
真实世界数据成为了大模型训练的核心
之后，他参与了Gopher项目
这是DeepMind发表的第一篇关于大语言模型的论文
当时的团队大约有十到十二人
从那时起他就深刻的意识到
这类研究需要团队协作
单靠个人是无法完成的
也正是从那时起
他开始专注于预训练的工作
进行大规模的预训练
这不仅培养了他的研究兴趣
也让他找到了自己热爱的领域
从最初的研究工程师
到如今掌管百余人规模预训练团队的负责人
布尔若的职业轨迹
既体现了他对技术的执着追求
也展现了他在团队管理和研究型工程方面的卓越能力
最后，聊到个人未来的职业发展
布尔若表示
他非常喜欢在日常工作中和众多优秀的人合作
并且从他们身上学习
这在很大程度上驱动着他
每天上班
他都会和非常聪明的人交流
他们会教给他很多新的知识
这是他非常享受的一点
而且现在有很多不同因素正在共同作用
AI领域还有很多方面有提升的空间
他对未来充满了好奇，因为目前来看
这类工作的进展似乎看不到尽头
他觉得
能够见证这个过程
看看行业能够走多远
这真的非常有趣
同时他认为至少在未来一年左右
AI行业快速发展的趋势不会放缓
回顾这场深度对话
布尔若为我们揭开了Gemini 3的神秘面纱
也让我们对AI行业的现状和未来有了更加清晰、更加深刻的认识
AI的下半场已经到来
正如布尔若所强调的
它将属于全栈研究员
属于那些能够整合技术栈、注重团队协作、兼具研究品味和工程能力的从业者
而Gemini 3的成功
仅仅是未来序幕刚刚拉开的一角
我们有理由期待
在众多研究者的共同努力下
AI将为我们带来更多惊喜
感谢收看本期视频，我们下期再见
