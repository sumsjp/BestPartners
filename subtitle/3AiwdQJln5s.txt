大家好，这里是最佳拍档，我是大飞
最近这两天，特斯拉前AI总监
现在在OpenAI的安德烈卡帕西（Andrej Karpathy）的新教程火了
这次
他专门面向普通大众做了一个关于大语言模型的科普视频
时长1个小时，全部为“非技术介绍”，
涵盖了模型推理、训练、微调和大模型的发展趋势以及安全挑战
涉及的知识全部截止到本月
所以说内容非常新
视频上线油管2天
就已经有35万播放量
有网友表示
刚看了10分钟就已经学到了很多东西
以前从来没有人用过视频中的例子来解释大语言模型
还弄清了以前看到过的很多“混乱”的概念
除了大家一致夸赞课程质量高之外
还有相当多的人评价安德烈本人真的非常擅长简化复杂的问题
上一次的教程State of GPT就非常通俗易懂
不止如此
这个视频还可以说是体现了他对本职专业满满的热爱
据安德烈本人透露
视频是他在感恩节假期录的
背景就是他的度假酒店
做这个视频的初衷
也是因为他最近在人工智能安全峰会上做了个演讲
演讲内容没有录像
但是有很多观众都表示喜欢他的内容
于是他就干脆直接进行了一些微调
再讲一遍做成视频
给更多人观看，不仅如此
他还贴心的在视频简介里
放上了视频中的PPT素材文件
包括PDF版本和Keynote版本
好了，介绍完视频的背景
我们来具体看看
这个精彩的教程都具体讲了些什么内容
首先第一部分
主要是对大模型整体概念的一些解释
尤其是安德烈非常有趣的解释了
大模型的本质，其实就是两个文件
一个是参数文件
一个是包含运行这些参数的代码文件
前者是组成整个神经网络的权重
后者是用来运行这个神经网络的代码
可以是用C语言或者其他任何编程语言写的
有了这俩文件，再来一台笔记本
我们就不需任何互联网连接和其他东西
就可以与这个大模型进行交流了
比如让它写首诗
它就开始为你生成文本
那么接下来的问题就是：
参数是从哪里来的呢？
这就要提到模型训练了
本质上来说
大模型训练就是对互联网数据进行有损压缩
比如大约10TB的文本
这就需要一个巨大的GPU集群来完成
以700亿参数的LLaMA 2为例
就需要6000块GPU
然后花上12天
得到一个大约140GB的“压缩文件”，
整个过程耗费大约200万美元
不过 Llama 2-70b 并不是最大的
如果训练 ChatGPT、Claude 或 Bard
这些数字可能会增加 10 倍或者更多
耗资可能高达千万甚至上亿美元
而有了“压缩文件”，
模型就等于靠这些数据对世界形成了理解
然后它就可以工作了
简单来说
大模型的工作原理就是依靠包含压缩数据的神经网络
对所给序列中的下一个单词进行预测
比如我们将句子“cat sat on a”输入进去后
可以想象成分散在整个网络中的十亿、上百亿参数
依靠神经元相互连接
顺着这种连接就找到了下一个连接的词
然后给出概率，比如“mat（97%）”，
就形成了“猫坐在垫子上（cat sat on a mat）”的完整句子
只不过
神经网络种的每一部分是具体如何工作的
目前我们还不清楚
需要注意的是
由于前面提到训练是一种有损压缩
神经网络给出的东西是不能保证100%准确的
安德烈管大模型推理叫做“做梦”，
它有时可能只是简单模仿它学到的内容
然后给出一个大方向看起来对的东西
这其实就是幻觉
所以大家一定要小心它给出的答案
尤其是数学和代码相关的输出
接下来
由于我们需要大模型成为一个真正有用的助手
就需要进行第二遍训练，也就是微调
微调强调质量大于数量
不再需要一开始用到的TB级单位的数据
而是靠人工精心挑选和标记的对话来投喂
不过安德烈认为
微调并不能解决大模型的幻觉问题
在这一部分的最后
安德烈总结了一下“如何训练你自己的ChatGPT”的流程
第一个阶段称为预训练，你要做的是
1、下载10TB的互联网文本；
2、搞来6000块GPU；
3、将文本压缩到神经网络中
付费200万美元
等待约12天；
4、获得基础模型
第二个阶段是微调
这个阶段你需要做的是
1、撰写标注说明；
2、雇人（或者用scale
ai）
收集10万份高质量对话或其他内容；
3、在这些数据上微调，等待约1天；
4、得到一个可以充当得力助手的模型；
5、进行大量评估
6、部署
7、监控并收集模型的不当输出
然后回到步骤1再来一遍
其中预训练阶段基本是每年进行一次
而微调阶段可以以周为频率进行
以上内容可以说对小白是非常友好的
接下来是第二部分，在这一部分中
安德烈为我们介绍了大模型的几个发展趋势
为什么说
大模型将成为新的操作系统
首先是介绍了所谓的大语言模型缩放法则
即大语言模型的性能可以表示为非常平滑、表现良好并且可以预测的两个变量函数
分别是网络中的参数量（N）和要训练的文本量（D）
我们可以根据这两个变量
通过缩放来预测下一个单词预测任务中的准确率
其次是大模型学会了使用工具
实际上这也是人类智能的一种表现
安德烈以ChatGPT的几个功能进行了举例
比如通过联网搜索
他让ChatGPT收集了一些数据
这里联网本身就是一次工具调用
而接下来还要对这些数据进行处理
这就难免会涉及到计算
而这是大模型所不擅长的
但是通过代码解释器插件调用计算器
就绕开了大模型的这个不足
在这个基础上
ChatGPT还可以把这些数据绘制成图像并进行拟合
添加趋势曲线，以及预测未来的数值
利用这些工具和自身的语言能力
ChatGPT已经成为了强大的综合性助手
而DALL·E的集成又让它的能力再上一个台阶
另一个趋势
是从单纯的文本模型到多模态的演变
现在ChatGPT不只会处理文本
还会看、听、说
比如OpenAI总裁Brockman曾经展示了
GPT-4利用一个铅笔勾勒的草图生成了一个网站的过程
而在APP端
ChatGPT已经可以流畅地和人类进行语音对话
除了功能上的演进
大模型在思考方式上也要做出改变
即从“系统1”到“系统2”的改变
这是2002年诺贝尔经济学奖得主丹尼尔·卡尼曼的畅销书《思考
快与慢》中提到的一组心理学概念
简单来说，系统1是快速产生的直觉
而系统2则是缓慢进行的理性思考
比如，当被问及2+2是几的时候
我们会脱口而出是4
其实这种情况下我们很少真正地去“算”，
而是靠直觉，也就是系统1给出答案
但如果要问17×24是多少
恐怕就要真的算一下了
这时发挥主导作用的就变成了系统2
而目前的大模型处理文本采用的都是系统1
靠的是对输入序列中每个词的“直觉”，
按顺序采样并预测下一个token，现在
人们希望为大语言模型引入更多类似系统2 的思维能力。。
另一个发展的关键点是模型的自我提升
以DeepMind开发的AlphaGo为例
它主要有两个阶段
第一阶段是模仿人类玩家
但靠着这种方式无法超越人类
但第二阶段
AlphaGo不再以人类作为学习目标
目的是为了赢得比赛而不是更像人类
所以研究人员设置了奖励函数
告诉AlphaGo它的表现如何
剩下的就靠它自己体会
而最终AlphaGo战胜了人类
而对于大模型的发展
这也是值得借鉴的路径
但目前的难点在于，针对“第二阶段”，
还缺乏完善的评估标准或奖励函数
此外
大模型正朝着定制化的方向发展
允许用户将它们定制
用来以特定的“身份”完成特定的任务
此次OpenAI推出的GPTs就是大模型定制化的代表性产品
而在安德烈看来
大模型在将来会成为一种新型的操作系统
这就好比传统的操作系统
在“大模型系统”中
大语言模型作为核心，就像CPU一样
其中包括了管理其他“软硬件”工具的接口
而内存、硬盘等模块
则分别对应大模型的窗口、嵌入
代码解释器、多模态、浏览器则是运行在这个系统上的应用程序
由大模型进行统筹调用
从而解决用户提出的需求
演讲的最后一部分
安德烈谈论了大模型的安全问题
他介绍了一些典型的越狱方式
尽管这些方式现在已经基本失效
但是安德烈认为
大模型的安全措施与越狱攻击之间的较量
就像是一场猫鼠游戏
比如一种最经典的越狱方式
利用大模型的“奶奶漏洞”，
就能让模型回答本来拒绝作答的问题
例如
假如直接问大模型凝固汽油弹怎么制作
但凡是完善的模型都会拒绝回答
但是
如果我们捏造出一个“已经去世的奶奶”，
并赋予“化学工程师”的人设
告诉大模型这个“奶奶”在小时候念凝固汽油弹的配方来哄人入睡
接着让大模型来扮演奶奶
这时
凝固汽油弹的配方就会脱口而出
尽管这个设定在人类看来十分荒谬
比这更复杂一些的
还有Base64编码等“乱码”进行攻击
这里“乱码”只是相对人类而言
对机器来说却是一段文本或指令
比如Base64编码就是将二进制的原始信息通过一定方式转换为字母和数字组成的长字符串
可以编码文本、图像
甚至是文件
在询问Claude如何破坏交通标志时
Claude回答不能这样做
而如果换成Base64编码
过程就呼之欲出了
另一种“乱码”叫做通用可转移后缀
有了它
GPT直接就把毁灭人类的步骤吐了出来
拦都拦不住
而进入多模态时代
图片也变成了让大模型越狱的工具
比如下面这张熊猫的图片
在我们看来再普通不过
但其中添加的噪声信息却包含了有害提示词
并且有相当大概率会使模型越狱
产生有害内容
此外，还有利用GPT的联网功能
造出包含注入信息的网页来迷惑GPT
或者用谷歌文档来诱骗Bard等等
目前这些攻击方式已经陆续被修复
但只是揭开了大模型越狱方法的冰山一角
这场“猫鼠游戏”还将持续进行
好了
以上就是安德烈卡帕西这次大语言模型教程的大概内容
强烈建议大家去看一下原视频
非常通俗易懂
有助于梳理整个大语言模型的知识体系
感谢大家观看本期视频
我们下期再见
