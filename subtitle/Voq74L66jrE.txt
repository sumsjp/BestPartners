大家好，这里是最佳拍档
二零二五年的人工智能行业
就像一幅分裂的画卷
生成式AI能拍出以假乱真的电影片段
大模型参数突破万亿级
投资人挤破头追逐规模神话
仿佛通用人工智能近在咫尺
但是跳出这片狂热，你会发现
那些能够真正走进物理世界、帮我们叠被子、照顾病人、修复机器的AI
却始终停留在慢热的状态
它们要么在简单的动作中频繁出错
要么根本无法理解三维空间的基本规律
这种感知温差的背后
藏着一个被大模型狂热所掩盖的核心问题
我们对智能的定义
是不是从一开始就跑偏了呢？
今天我们这期一万五千字的视频
要盘点的
正是在这场狂欢中保持清醒
甚至逆潮流而行的AI先驱，李飞飞
这位曾经用ImageNet
一手开启深度学习时代的科学家
在二零二五年将所有的精力
都投入到了一个更底层的方向上
那就是空间智能
通过一整年的公开演讲、实验室实践和深度访谈
她用一套横跨历史、进化生物学、物理学和工程学的完整逻辑告诉我们
当前的生成式AI
哪怕已经能够写出媲美文学大师的文字
也只是摸到了智能的冰山一角
真正的通用智能
必须先学会看懂三维世界的物理规律
学会在空间中行动，而这背后
是5.4亿年的生物进化
刻在神经系统里的底层密码
要搞懂李飞飞的空间智能
我们必须先跳出AI等于语言模型的思维惯性
回到一个最根本的问题上
智能到底是什么？
在李飞飞眼中
它不是凭空出现的一项技术奇迹
而是人类文明和生物进化所共同塑造的一个产物
在二零二五年的巴黎AI峰会上
李飞飞提出了一个颠覆性的观点
AI不是1956年达特茅斯会议后
突然诞生出来的一个技术突变
而是人类花了几千年的时间
试图将理性外化为物理实体的一种工程延续
这个说法看似十分抽象
却能通过几个关键的历史节点
清晰地串联起来
第一个节点
是古希腊的哲学家亚里士多德
你可能很难想象
李飞飞将他称为第一位计算机科学家
这背后是基于对智能本质的一种深刻洞察
亚里士多德的核心贡献
是第一次把人类混沌和模糊的思维过程
提炼成了可以执行的逻辑算法
他提出的三段论
至今仍然是逻辑推理的基础
所有人终有一死，苏格拉底是人
因此苏格拉底终有一死
这个简单的推理
其实奠定了AI的核心公理
智能不是不可捉摸的灵感
而是可以拆解、编码
并且在非生物载体上重现的逻辑过程
从那时起
人类就开始了将认知从大脑剥离的尝试
第二个关键节点
是十三世纪机械钟表的发明
在那之前，人类对时间的感知
完全依赖于自然周期
日升月落、四季更迭
这是一种生物性的、主观的感受
而机械钟表的出现
彻底改变了这一切
它利用擒纵机构的周期性震荡
将时间这个抽象的概念
转化为了机器能够精确计算的物理运动
李飞飞在斯坦福H·A·I的演讲中强调
这绝不仅仅是计时工具的革新
它证明了一件足以影响后世AI的关键事实
那就是人类的认知功能
比如计算和测量
可以完全脱离生物大脑
移植到由金属、齿轮组成的无机实体上
这种认知外化的实践
为后来艾伦·图灵提出机器能否思考的命题
埋下了物理可行性的种子
到了十九世纪
艾达·洛夫莱斯为这种外化智能
注入了创造力的基因
作为查尔斯·巴贝奇分析机的核心合作者
艾达没有局限于机器只能计算数字的认知
而是敏锐地洞察到
机器处理的本质是符号
只要遵循逻辑规则
机器不仅能够处理数值
还能处理音乐、艺术等复杂的符号系统
她在笔记中大胆的预言
分析机有朝一日或许能够作曲
这句话跨越了两个世纪
精准命中了今天生成式AI的核心能力
李飞飞引用这段历史，是想告诉我们
智能从一开始就不只是计算
更包含了创造
而空间智能的终极目标
也不仅仅是理解世界
更是创造符合物理规律的世界
最终，时间来到了二十世纪中期
艾伦·图灵在《计算机器与智能》中
抛出了机器能否思考的终极拷问
直接推动了AI领域的诞生
一九五六年夏天
约翰·麦卡锡、马文·明斯基等先驱
在达特茅斯会议上
正式提出了人工智能的术语
一个有趣的历史细节是
当时这些科学家乐观的认为
只需要两个月的集中研究
就能破解智能的大部分奥秘
如今看来，这个两个月的项目
变成了跨越七十年的漫长征途
但是李飞飞却将这种乐观误判
解读为一种宝贵的智力无畏
一种坚信智能的奥秘
一种终将能用物理和数学语言解构的科学信仰
而这种信仰
也贯穿了李飞飞自己的科研生涯
从AI寒冬中押注ImageNet
到如今在大语言模型的统治时代
毅然转向空间智能
她始终在直面最根本的难题
而不是追逐表面的技术热点
如果说历史为智能提供了人文坐标
那么进化生物学
则为李飞飞的空间智能提供了科学的基石
这也是她批判当前大模型路径的核心依据
在斯坦福大学的公开课程中
李飞飞用了一组极具冲击力的进化时间对比
她说，人类语言的诞生
仅能追溯到大约三十万至五十万年
而视觉的进化史
要上溯到5.4亿年前的寒武纪大爆发
当第一个原始生物的感光细胞
捕捉到地球表面的第一束光线时
地球生命就开启了一场长达数亿年的
从感知到行动的军备竞赛
五十万年与5.4亿年
这个一比一千的时间差距
背后是生物神经系统的算力分配逻辑
李飞飞解释说，在漫长的进化中
生物神经系统99%的算力和架构优化
都是为了解决三维世界中的生存问题
比如，如何判断猎物的距离？
如何避开障碍物？
如何理解物体的几何形状和物理属性？
这些能力早就已经刻进了基因里
变成了人类无需思考的潜意识本能
而语言，只是在这个坚实的底座上
为了群体协作和信息传递而发展出的上层应用
它是对高维、复杂物理世界的有损压缩
把阳光斜照下、蜷缩在沙发角落的橘猫
简化成了猫在垫子上
这样离散的文字符号
这就完美解释了AI领域著名的莫拉维克悖论
为什么AI能够轻松战胜围棋世界冠军、解决复杂的数学证明
却连像叠被子、走楼梯这种人类觉得很简单的动作
都难以完成？
李飞飞的答案是
前者是人类最近几千年才发展出的显式规则
逻辑清晰、易于编码
而后者是5亿年进化打磨成的隐式物理能力
背后涉及到海量的高维连续变量和非线性物理反馈
计算复杂度极高
只是因为它太过于本能
才被我们低估了难度
她的结论非常明确
如果AI只停留在语言层面
只处理离散的文本符号
它永远只能是缸中之脑
虽然能理解文字描述的世界
却无法真正感知、交互、生存于物理世界中
要理解李飞飞今天对空间智能的坚持
就必须回溯她在二零零六年启动的ImageNet项目
这个看似堆图片的工程
不仅开启了深度学习时代
更是奠定了李飞飞数据信仰的核心逻辑
二零二五年，在回顾这段历史时
李飞飞毫无保留地分享了当时的反直觉决策
而这些决策，恰恰能够帮我们看懂
她今天为何坚定地站在像素至上的阵营方
二零零六年前后的AI行业
正深陷寒冬
尤其是计算机视觉领域
陷入了一个无解的死循环
当时的主流研究范式是手工设计特征
研究者们花费了几年的时间
试图用人类的逻辑去描述视觉规律
然后在极小的数据集上进行测试
这种研究方式的结果是
模型在训练集上的准确率极高
但是一碰到真实世界的复杂光照、遮挡、形变
识别率就会瞬间崩塌
李飞飞在访谈中直言，当时的算法
只能识别出数据集中的猫
也就是那种在标准光照下、正面朝向镜头的猫
但是现实世界中的猫
可能在阴影里、可能蜷缩着、可能只露出半个脑袋
这些算法根本认不出来
问题到底出在哪呢？
当时的学术界普遍认为
是算法不够聪明
于是大家纷纷投入更复杂的数学模型研发
试图用更为精巧的公式
去拟合少量的数据
就像用高阶函数去拟合只有几个点的曲线一样
但是李飞飞却从信息论的角度
提出了完全相反的判断
问题不在于模型，而在于数据不够多
她的逻辑很简单
泛化能力是智能的核心
而泛化能力的唯一燃料
就是规模足够大、覆盖足够广的数据
就像儿童要通过观察上亿个视觉样本
才能建立对世界的认知一样
因此，机器智能的涌现
也必须建立在海量数据的统计学基础上
这个想法在当时被很多人质疑
甚至被视为不切实际的狂想
因为在那个年代
构建大规模的标注数据集
不仅成本极高
还被视为是一种低级的苦力活
在学术界看来
推导一个新的数学公式
远比找图片、做标注要优雅得多
但是李飞飞坚信自己的判断
她做出了第一个关键决策
停止优化单一算法
转而全力构建一个前所未有的大规模视觉数据集
ImageNet
构建ImageNet的第一个难题
不是去哪里找图片
而是如何定义图片
互联网上的图片浩如烟海
但是如果只是随机抓取
得到的只会是一堆无法被机器理解的数字垃圾
李飞飞团队没有从零开始
而是极具智慧地借鉴了
普林斯顿心理学家乔治·米勒构建的WordNet词汇网络
WordNet不是一个普通的字典
而是一个将人类语言的概念
组织成严密层级结构的语义网络
比如波斯猫是猫的下位词
猫是猫科动物的下位词
猫科动物又是哺乳动物的下位词
李飞飞团队将这个语言学骨架
完整映射到了视觉领域
构建了包含两万两千个个视觉类别的庞大分类体系
这种结构化的设计至关重要
它迫使AI不仅要区分猫和狗
还要在更细粒度上区分波斯猫与暹罗猫
同时理解它们同属猫科动物的层级关系
这种基于语义层级的数据集设计
让ImageNet超越了扁平的图像库
成为一个具有认知深度的视觉知识图谱
从而为后来深度学习模型学习到层次化的特征
提供了关键的基础
模型在底层学习边缘、纹理
在中层学习物体部件
在高层学习语义类别
这恰恰模拟了人类视觉皮层的工作原理
解决了分类体系
下一个更大的挑战是数据标注
按照ImageNet的目标
每个类别有一千张图片
总共一千五百万张高质量的标注图
仅靠实验室的本科生根本无法完成
李飞飞团队陷入了绝望
直到他们发现了当时刚刚起步的Amazon Mechanical Turk众包平台
这是一次极具开创性的群体智能实验
但是新的问题随之而来
如何保证分布在全球各地、为了赚取微薄报酬的在线工人们
都能提供高质量的标注呢？
如果有人为了快速完成任务
随意的点击是或否
整个数据集的质量都会被污染
为了解决这个问题
李飞飞团队设计了一套精密的算法博弈机制
首先
他们在任务流中随机插入黄金标准图片
也就是已知正确答案的图片
如果工人在这些测试题上出错
系统会立即判定其为不可信
实时丢弃他提交的所有数据
其次，团队引入了贝叶斯推断模型
根据多个工人的标注结果
计算每张图片的置信度分数
对于争议较大的图片
比如模糊的动物图像
或者罕见的物种
系统会自动分发给更多的工人进行重复验证
直到置信度达到预设的阈值为止
最终
来自一百六十七个国家的近5万名工人
花了两年多时间
完成了数千万次的高质量标注
李飞飞将这个过程
形容为机器智能诞生前的母体孕育
在算法还不具备自我学习能力的时候
是人类智能通过众包的方式
手把手地教会机器什么是猫
什么是狗
什么是物理世界的视觉真理
而ImageNet真正的奇点时刻
出现在2012年的ImageNet挑战赛上
在那之前，挑战赛的获胜算法错误率
一直徘徊在26%到28%之间
这个水平根本无法满足工业应用的需求
整个计算机视觉领域
仿佛撞上了一堵无形的墙
但是那一年，杰弗里·辛顿的学生
亚历克斯和伊利亚提交的AlexNet算法
将错误率断崖式地降到了15.3%，
比第二名基于传统手工特征的算法
低了整整十个百分点
震惊了整个行业
为什么会出现如此巨大的突破？
李飞飞在二零二五年的演讲中
提出了AI爆发的铁三角定律
完美解释了这一现象
第一是数据
ImageNet提供的一千五百万张高质量的标注图
刚好超过了深层神经网络训练的临界阈值
深层神经网络拥有数千万个参数
如果没有足够的数据来约束这些参数
模型必然会过拟合
而ImageNet提供的海量的、多样化的监督信号
终于让深层网络吃饱了
得以充分学习到视觉世界的统计规律
第二是算法
卷积神经网络其实早在20世纪80年代
就由Yann LeCun等人提出
但是在ImageNet之前
由于缺乏大规模数据的训练
它一直被视为是难以训练的黑盒
AlexNet的核心突破在于两点
一是引入了ReLU激活函数
彻底解决了传统Sigmoid函数
在深层网络中出现的梯度消失问题
二是采用了Dropout正则化技术
通过随机关闭一部分的神经元
防止模型过度依赖于某些局部特征
进一步降低了过拟合的风险
这两项技术
彻底激活了深层神经网络的表征潜力
第三是算力
这是最关键的物理加速器
当时的CPU计算能力有限
而深层网络的参数规模和计算量极大
传统的训练方式可能需要几个月甚至几年时间
亚历克斯首次尝试用两块英伟达GTX 五八零 GPU
进行模型的并行训练
当时的GPU显存只有3G·B
根本装不下整个网络
于是他就设计了一种巧妙的架构
让神经网络的不同部分
分布在两块GPU上
只在特定的层进行数据通信
这种针对硬件特性的工程优化
将原本需要几个月的训练时间
压缩到了几天，让深层网络的训练
从理论可能变成了现实可行
这三者的完美结合
在二零一二年引发了AI领域的相变
AlexNet的胜利
宣告了手工特征时代的彻底终结
开启了端到端学习的新纪元
在此之前
计算机视觉专家花费几十年时间研发特征算子
试图用人类的逻辑去描述视觉规律
而AlexNet证明
机器通过多层神经网络自动提取的特征
比人类设计的更抽象、更健壮、更能适应复杂场景
这个时刻
也确立了现代AI的Scaling Law雏形
AI的性能提升
不再依赖于对特定规则的修补
而是依赖于模型深度、数据广度
与计算强度的指数级扩展
ImageNet留给今天的最大遗产
不仅仅是一个数据集
更是李飞飞的数据信仰
智能的涌现
需要暴力规模的物质基础
而要让AI理解物理世界
就必须回到更原始、更完整、更接近物理真理的像素流数据
这也正是她在二零二五年
坚定推行空间智能的核心逻辑
语言数据再海量
也只是对物理世界的压缩版
只有直接处理像素流中的几何结构和动力学规律
AI才能真正看懂并走进物理世界
二零二五年
李飞飞创办的World Labs正式发布了首款核心产品
Marble
这款产品的定位
从一开始就与当前最火的视频生成模型
划清了界限
在李飞飞看来，这些视频生成模型
虽然能够产出几秒钟的逼真画面
但是本质上只是在画皮
而Marble要做的，是造骨
是构建一个具备物理一致性、可交互、可导航的三维世界模型
为什么这么说呢？
我们可以从一个直观的测试来看
如果你让Sora生成一段
绕着一把椅子旋转拍摄的视频
前几帧可能非常逼真
但是随着摄像机角度的大幅变化
你会发现椅子的结构开始出现错乱
比如背面突然多了一条腿
或者扶手在旋转中融化、变形
李飞飞在YC创业学校的分享中
解释了背后的原因
这些视频生成模型
本质上是在做下一帧的预测
它们通过Diffusion Transformer
学习像素变化的统计规律
比如水的流动纹理、火焰的跳动轨迹
但是模型的内部
并没有建立起一个稳定的3D椅子的结构
它只能根据前一帧的像素分布
猜测下一帧的像素应该是什么样
却无法回答椅子背面到底是什么结构
因为它没有物体恒常性的概念
不知道椅子即使被遮挡
也依然是一个完整的3D实体
这种缺乏显式3D结构的模型
注定会在长程视角的变换中
遭遇几何坍塌
这是单纯的统计学拟合
所无法逾越的一道物理墙
而Marble的核心突破
正是引入了显式3D表征
它不再输出一段固定的、不可修改的视频
而是根据单张图片、文本提示
甚至是粗糙的3D布局
输出一个完整的4D时空结构
这里的4D
指的是3D空间加上时间维度
用户可以在这个生成的场景中
自由的移动摄像机的视角
比如绕着桌子走一圈
或者从地面升到天花板
场景中的物体几何结构始终可以保持一致
甚至你还可以直接编辑场景
比如把红色的沙发改成蓝色
移除茶几，添加一盆植物
所有的空间关系和物理逻辑都不会出错
实现这个突破的核心技术
是高斯泼溅
李飞飞的团队在技术白皮书里
详细解释了选择这个技术的原因
与传统的3D表征方式相比
高斯泼溅有两个不可替代的优势
第一，它不需要复杂的拓扑连接
传统的网格表征
需要保证顶点之间的连通性
生成的难度极高
而高斯泼溅用数百万个离散的高斯球体来描述场景
神经网络生成离散点
远比生成连通图更加容易
第二，它支持实时渲染和显式编辑
由于NeRF是一种隐式表征
所以要想修改物体的颜色或形状
必须重新训练模型
而高斯泼溅中的每个高斯球体
都有明确的位置、形状、颜色和不透明度参数
用户可以直接调整这些参数
实时看到修改后的效果
在Marble中
一个厨房场景就是由数百万个这样的3D高斯球体组成的
它们共同构建了一个既逼真
又具备物理一致性的虚拟世界
除了表征方式的革新
Marble的另一个核心创新
是对Transformer架构的本质重构
长久以来
人们普遍认为Transformer是为了处理序列设计的
但是World Labs的联合创始人贾斯汀·约翰逊
在二零二五年的Latent Space访谈中
提出了一个极具洞察力的观点
Transformer本质上是处理集合的数学机器
而非处理序列的机器
这个判断的核心
在于Transformer的核心机制
自注意力的置换等变性
简单来说
如果你打乱输入Token的顺序
自注意力矩阵计算出的
Token之间的相关性权重
是完全不变的
变化的只是输出矩阵的行顺序
这意味着
Transformer本身并不知道输入的顺序
它处理的是一个无序的Token集合
之所以它能处理语言
完全是因为我们在输入层
强行注入了位置编码
告诉模型单词的顺序很重要
这个数学特性
让Transformer天生适合处理3D空间数据
因为3D空间中的点
本质上就是无序的集合
比如点A和点B在空间中并存
没有固定的先后顺序
只要它们的位置和属性正确
组合起来就是一个完整的场景
因此，Marble的做法是
将3D空间的坐标
映射为高维的位置嵌入
再注入到Transformer中
模型通过自注意力机制
计算空间中不同点之间的几何关系
从而理解整个场景的空间结构
这种方式
彻底打破了Transformer只适合语言的迷思
为空间智能借力大模型的庞大算力基础设施
提供了数学上的合法性
不过
李飞飞的团队并没有完全否定隐式表征的价值
他们提出了一种混合架构
试图在隐式推理和显式输出之间
架起一座桥梁
在模型的推理核心中
世界是以高度压缩的隐式高维向量存在的
这种表征方式虽然不够直观
但是能高效地进行语义推理和物理规律的模拟
比如理解把杯子放在桌子边缘会掉下来的因果关系
而在模型的输出层
则会把这种隐式向量
解码为显式的3D结构，比如高斯泼溅
这样既能保证推理的效率和泛化能力
又能支持人类直观的编辑和交互
李飞飞解释说，纯粹的隐式模型
就像你知道杯子的概念
却无法直接修改它的颜色
而纯粹的显式模型
就像你能画出杯子
却不懂装水的功能和易碎的物理属性一样
因此
混合架构就是要兼顾两者的优势
而Marble的下一个技术目标
是实时性
目前，无论是生成式模型
还是传统的3D渲染
都面临着耗时的问题
生成一段10秒的视频可能需要几分钟
渲染一个复杂场景可能需要几个小时
World Labs展示的RTFM技术
正是为了解决这个问题而生的
它试图在单张H·100 GPU上
实现每秒24帧以上的实时生成和交互
虽然具体的技术细节尚未完全公开
但是李飞飞透露
RTFM采用了两种关键的优化策略
一是关键帧预测加神经插值
即只对少数关键帧进行完整的3D生成
中间的过渡帧，通过AI快速插值补充
这样既保证了物理一致性
又大幅提升了速度
二是借鉴了一致性模型的加速采样技术
将Diffusion模型原本需要几百步的去噪过程
压缩到一两步的映射
极大地降低了计算量
李飞飞在演讲中预言，未来的技术栈
将不再区分生成模型和渲染引擎
两者将深度融合为神经空间引擎
这个引擎不再通过光栅化多边形来成像
而是通过神经查询来直接生成光线
它会利用AI的生成能力
自动创造出丰富多样的场景内容
同时利用嵌入的物理引擎
保证场景的物理一致性
这种融合的终极目标
是为了实现交互式生成
用户不再只是被动观看场景的观察者
而是可以主动介入、改变世界的参与者
比如
在神经空间引擎生成的厨房场景中
你可以打开冰箱
AI会实时生成冰箱内部的食物
并且这些食物会符合物理逻辑
你可以拿起水壶倒水
水流的轨迹、杯子里水面的上升高度
都会严格遵循流体力学的规律
这种可交互、可修改、物理一致的虚拟世界
正是李飞飞心中空间智能的核心形态
它让AI从只能描述世界
走向构建世界，与世界交互
有了能理解和构建3D世界的大脑
下一步就是让AI拥有身体
能够在物理世界中行动
这就是具身智能
但是二零二五年的机器人领域
还面临着一个致命的瓶颈
那就是数据匮乏
李飞飞在英伟达G·T·C的演讲中
将这个问题称为非对称的困境
大语言模型可以轻松获取互联网上海量的文本数据
输入和输出都是Token
完美对齐
而机器人的输入
是来自摄像头的2D像素流
输出的则是3D动作指令
这种维度错位
让机器人学习变得异常困难
为什么会出现这种困境呢？
李飞飞深入剖析了背后的结构性原因
首先，互联网上的视频虽然多
但几乎都是旁观者视角
你能看到别人如何叠被子、如何炒菜
但是看不到他手上的力度、被子的触感、锅具的重量反馈
而机器人需要的是第一人称的数据
包括视觉、力触觉、本体感受在内的多模态信息
这些数据在现实世界中
几乎无法大规模的采集
其次，物理世界的试错成本极高
让机器人在现实中练习抓取玻璃杯
可能会打碎无数的杯子
练习应对火灾清理、化学泄漏
更是不可能实现
最后，物理世界的时间是线性的
机器人只能以1倍速积累经验
而AI模型的训练需要海量数据
仅靠现实世界的训练
速度远远跟不上
面对这个看似无解的难题
李飞飞给出了唯一的解决方案
那就是合成数据
用AI生成的虚拟世界
为机器人提供无限的、安全的、低成本的训练素材
而她的团队
已经在通过Behavior 1K基准测试
和OmniGibson物理仿真引擎
搭建起了这套解决方案的完整框架
首先是Behavior 1K基准测试
过去，机器人学习的任务
大多是抓取积木、开门、移动物体
这种简单的、单步骤的动作
但是李飞飞认为
真正的具身智能，需要学会生活
也就是处理人类日常生活中复杂的、长流程的琐事
因此，Behavior 1K的任务设计
并没有凭空创造
而是参考了美国劳工统计局的时间利用调查
统计了人类日常生活中最耗时、最希望被自动化的一千项任务
比如擦桌子、洗碗、清理派对现场、给宠物洗澡、拆开圣诞礼物、整理行李箱等等
这些任务的复杂度
远超传统的机器人任务
以清理派对现场为例
它需要机器人完成一整套的长程规划
第一步是场景理解
机器人需要识别出散落的酒杯、食物残渣、纸巾、礼品盒等不同类型的垃圾
第二步是任务排序
确定先捡大块的垃圾
再擦桌子上的液体
最后归位家具的顺序
第三步是精细操作
比如抓取易碎的玻璃杯时
要控制力度，用抹布擦桌子时
要施加合适的法向力，避免液体飞溅
第四步是异常处理
如果垃圾桶满了
要先倒掉垃圾再继续清理
而不是机械地重复投放垃圾的动作
李飞飞说，Behavior 1K的目标
是让机器人从执行单一动作的工具
变成能够理解复杂需求、自主解决问题的伙伴
支撑这些复杂任务的
是与英伟达合作开发的OmniGibson物理仿真引擎
这是一个高保真的、高真实度的虚拟环境
它与传统仿真引擎的最大区别
在于对物理属性的深度模拟
而不仅仅是视觉上的逼真
OmniGibson支持四大核心物理模拟能力
第一是刚体模拟
比如桌椅碰撞时的稳定性
物体堆叠的平衡感
完全符合现实世界的力学规律
第二是对可变形物体的模拟
这是传统仿真引擎的盲区
OmniGibson能够精准模拟
折叠衣物时的布料形变、揉面团时的弹塑性变化、海绵吸水后的质量和形状改变
第三是流体模拟
通过粒子系统来模拟倒水和制作奶昔时的流体动力学
包括液体在不同容器间的转移、泼洒后的扩散、表面张力等细节
第四是热力学模拟
这是极其罕见的高级功能
引擎能够模拟热传导的过程
比如微波炉加热食物时
食物的温度会随着时间变化
从冰冷到温热再到煮熟、烧焦
而这种温度变化会影响机器人的红外感知和操作策略
有了Behavior 1K的任务基准和OmniGibson的仿真引擎
接下来就是李飞飞提出的合成数据闭环
一个左脚踩右脚的自我强化过程
这个闭环的第一步
是用Marble生成海量的、多样化的3D场景
比如，要训练机器人洗碗
不需要手工建模一个厨房
而是让Marble自动生成一千种含有不同的灶台布局、不同光照、不同材质的厨房
每个厨房的水槽位置、水龙头的样式、餐具的摆放都不相同
极大地扩展了数据的多样性
第二步，将这些只有视觉信息的场景
导入OmniGibson引擎
为每个物体赋予物理属性
比如盘子的质量、碗的易碎程度、水的密度和粘度
第三步，在这些虚拟场景中
用强化学习训练机器人Agent
由于是虚拟环境
我们可以同时并行运行几万个训练实例
让机器人在几天内积累几百万年的经验
快速学会应对各种复杂情况
第四步，将训练好的策略
迁移到现实世界的物理机器人上
同时利用域随机化技术
在虚拟场景中随机的调整光照、材质、物体的位置
让机器人学会适应现实世界中的各种变化
弥合模拟到现实的鸿沟
这个闭环的核心魅力，在于自举
Marble生成的场景越逼真、越多样化
OmniGibson的物理模拟就越精准
训练出的机器人策略就越强大
而更强大的机器人
在现实世界中执行任务时
能够反馈更多真实的物理数据
这些数据又可以反过来
优化Marble的生成能力和OmniGibson的模拟精度
形成一个不断强化的正向循环
李飞飞在访谈中坚定地表示
现实世界的数据永远无法满足具身智能的需求
既不够多，也不够安全
只有让AI自己生成虚拟世界
才能给机器人提供无限的训练素材
这是突破莫拉维克悖论
实现通用机器人的唯一的、确定性的路径
聊了这么多硬核的技术架构和理论
我们也不能忘记
李飞飞一直是以人为本的AI的坚定倡导者
2025年，她在斯坦福H·A·I的工作
将空间智能从实验室里的黑科技
变成了能守护生命、恢复尊严、赋能普通人的现实工具
其中最具代表性的
就是环境智能在医疗领域的应用
以及脑机接口和AI普惠项目
首先是环境智能，它的核心理念是
最好的AI应该是消失在环境中的AI
李飞飞在斯坦福医学中心的试点项目中
将深度摄像头、热成像传感器等智能设备
无缝嵌入到重症监护室、老年病房和手术室中
结合空间智能算法
在不干扰医护人员和病人日常活动的前提下
实现了实时的感知和智能分析
这种智能不是通过穿戴设备实现的
而是让空间本身具备了视觉和理解力
在设计之初
李飞飞就特别强调隐私设计优先的原则
考虑到医疗场景的高隐私敏感性
系统刻意避开了RGB摄像头
转而使用深度传感器
它只能捕捉到模糊的人体轮廓和骨架图
无法识别出具体身份
这样就从物理层面
彻底阻断了隐私泄露的风险
这种技术选择
体现了李飞飞对技术伦理的深刻理解
因为在医疗这种特殊场景中
技术必须在效用和隐私之间
找到一个完美的平衡点
不能为了功能而牺牲人的基本权利
在具体应用中
环境智能展现出了巨大的实用价值
在老年病房，系统实现了跌倒预警
AI通过分析病人的步态、身体倾斜角度等微小的特征
能够在病人下床时步态不稳的瞬间
预判到跌倒风险
并且在跌倒发生的前几秒钟
向护士站发出预警
同时自动打开病房门口的警示灯
这个功能
将传统的事后救治转变为了事前预防
极大地降低了老年患者跌倒受伤的概率
在重症监护室
系统则承担了活动监测的任务
会自动记录病人的翻身频率、肢体活动的范围、呼吸的节奏等细微数据
这些数据是评估病人康复进度和病情变化的关键指标
但是在过去
只能靠护士在巡房时偶尔的手工记录
数据零散而且不连续
现在
系统能够实现24小时的全量数字化记录
为医生提供精准的诊疗依据
而在手术室
空间智能算法被用在器械追踪方面
通过实时定位手术刀、纱布、镊子等器械的位置
自动记录器械的使用流程和去向
防止异物被遗留体内这种严重的医疗事故
除了守护病人
环境智能还将目标对准了医护人员的减负
李飞飞在访谈中多次提到
她对护士群体的工作现状深感担忧
护士每次轮班的步行距离
常常超过10公里
还要处理几百项琐碎的任务
从补充输液袋、更换床单
到记录生命体征、回应病人的呼叫等等
高强度的工作负荷
是导致医疗错误和职业倦怠的主要原因
因此，环境智能的另一个核心目标
是优化医疗流程，为护士松绑
系统通过分析病房的人流热力图、医疗物资的消耗速度
以及护士的任务执行路径
能够自动优化物资的摆放位置和巡房路线
比如
系统可以通过预测某个病房的输液即将结束
提前通知附近的护士
准备好新的输液袋
避免护士在多个病房之间来回奔波
通过分析手术时长和器械的使用频率
优化手术室的器械摆放顺序
减少医生和护士的取放时间
李飞飞强调，之所以设计这些功能
不是为了监视护士的工作效率
而是为了通过算法的辅助
让护士从繁琐的后勤事务中解放出来
回归到她们最核心的职责
也就是关怀病人和提供情感支持上
技术应该是护士的第二双眼睛
在她们疲惫时提供安全冗余
而不是成为压垮她们的监工
如果说环境智能是隐形的守护
那么李飞飞团队展示的脑机接口烹饪案例
则是对人的尊严的极致守护
在巴黎AI峰会上
李飞飞播放了一段令人动容的视频
一位重度瘫痪的患者
失去了所有肢体的行动能力
生活完全依赖他人的照料
研究团队为他配备了非侵入式脑电图设备
通过采集他的脑波信号
结合空间智能算法，解码他的意图
比如想拿起勺子
想切菜，想打开燃气灶
这些意图信号被实时传递给机械臂
患者仅凭意念
就完成了一系列复杂的精细操作
从洗菜、切肉，到调配酱汁、摆盘
最终成功制作出一份完整的日式寿喜烧
视频播放结束后，李飞飞动情地说
这个案例的意义
绝不是AI能做饭这么简单
对于这位患者而言，能够通过机械臂
为自己或家人做一顿饭
意味着他重新获得了与物理世界交互的权利
找回了生活的自主权和尊严
在这个过程中，AI扮演的不是替代者
而是协作者
它弥补了患者受损的生理机能
但是完全保留了他作为一名厨师的意志、决策和创造力
这个案例
完美诠释了李飞飞的技术伦理观
那就是技术的终极目标
不是替代人，而是增强人
我们不仅要问AI能做什么
更要问它如何帮助人类保留尊严、实现价值
除了高端的医疗应用
李飞飞同样关注AI的普惠性
她与前学生共同创立了非营利组织AI for All
旨在打破AI领域的精英壁垒
她敏锐地意识到
如果AI的开发者仅仅是一群同质化的精英
那么开发出的技术
难免会带有偏见或者盲区
比如人脸识别对深色皮肤人群的准确率较低
医疗AI模型对罕见病的诊断能力不足
这些问题的根源
在于开发者缺乏对不同群体、不同社区真实需求的理解
AI for All通过为来自农村地区、城市低收入社区
以及历史上代表性不足群体的高中生
提供免费的暑期项目和实习机会
让他们有机会学习到AI技术
接触到前沿科研
这些年轻人没有去追逐微调大模型
开发聊天机器人这些热点
而是聚焦于自己社区的真实问题
有的学生利用AI来优化救护车的调度算法
缩短偏远地区患者的急救时间
有的学生开发了基于图像识别的农村水质评估工具
帮助村民快速判断饮用水是否安全
有的学生则利用卫星图像和AI
设计了野火预警系统
保护森林资源和社区安全
李飞飞在分享这些案例时
眼中满是欣慰
在她看来
AI不应该是少数精英的专利
而是属于每一个想改变自己生活和社区的人
通过普及AI素养
让更多元的群体参与到AI的开发和应用中
我们才能构建出更公平、更包容、更有温度的AI未来
在探讨完空间智能的技术、应用之后
李飞飞还对AI行业的生态发展
提出了深刻的思考
尤其是在工业界掌握了海量算力
大模型规模竞赛愈演愈烈的今天
学术界应该扮演什么角色呢？
开源与闭源的边界在哪里呢？
未来的AI人才
又需要具备什么样的特质呢？
首先是学术界的非对称竞争策略
李飞飞在与贾斯汀·约翰逊的访谈中
明确警告年轻的研究者和博士生
不要试图在训练最大模型的赛道上
与Google、Meta、OpenAI这些科技巨头竞争
大学实验室根本无法获得成千上万张GPU
在规模这个单一维度上
学术界毫无胜算
她提出
学术界应该坚守自己的核心优势
聚焦三个工业界不愿碰的新战场
第一个战场是古怪的架构探索
工业界受限于季度财报和产品落地的压力
往往倾向于优化现有的Transformer架构
追求短期性能的提升
而学术界没有这些束缚
可以自由探索那些看似疯狂、短期无用
但是可能颠覆未来的技术路径
贾斯汀·约翰逊补充道
现在的神经网络都是为GPU优化的
但是20年后的硬件架构
可能完全不同
比如光子计算、量子计算
学术界应该提前思考
非GPU架构下的AI算法形态
甚至通过设计全新的硬件原语
打破冯·诺依曼架构的瓶颈
第二个战场是理论基础与可解释性
李飞飞指出，当前的AI发展
已经呈现出了实验领先于理论的态势
我们知道Transformer有效
知道大模型能够涌现出复杂的能力
但是我们不知道这些能力是如何产生的
也无法解释模型为什么会出现偏见和幻觉等问题
学术界的核心使命
就是打开AI的黑盒
研究机制可解释性
为AI建立起坚实的数学和物理基础
从根本上理解智能涌现的机制
只有这样
AI才能从靠经验驱动的工程
升级为靠理论指导的科学
第三个战场是跨学科AI
利用AI解决生物学、材料学、天文学、核聚变等基础科学问题
这是大学相较于单个科技公司的天然优势
这些领域需要深厚的领域知识
而不是单纯的算力堆砌
比如，利用AI预测蛋白质折叠
帮助研发新型药物
或者利用AI分析核聚变的实验数据
优化反应条件
以及利用AI处理天文观测数据
发现新的天体和物理规律
李飞飞认为
这些跨学科研究不仅能够推动基础科学的进步
也能为AI带来新的突破
因为基础科学中的复杂问题
会倒逼AI发展出更强的推理和建模能力
在开源与闭源的争论上
李飞飞的观点也是显得务实又深刻
她认为，开源不是一种慈善行为
而是一种精明的商业杠杆
或者是对抗垄断的生态武器
以Meta开源llama为例
这并不是一种纯粹的利他主义
而是基于自身清晰的生态战略
Meta的核心商业模式不是卖模型的API
而是通过开源
构建底层的技术标准
吸引全球开发者进入自己的生态系统
从而削弱OpenAI、Google等竞争对手的护城河
相反，OpenAI选择闭源GPT系列
是因为模型本身就是核心的商业护城河
闭源能够保护技术秘密
维持产品的独特性和商业优势
李飞飞强调
这两种选择没有绝对的对错
关键在于
是否匹配公司的商业模式和发展目标
但是，从更宏观的行业生态角度来看
李飞飞坚决捍卫开源的公共价值
她指出，如果AI技术被少数巨头垄断
不仅会导致创新停滞，还会固化偏见
开源让AI技术像科学知识一样
成为全人类共享的财富
初创公司可以基于开源模型
快速的迭代产品
学术界可以利用开源工具开展研究
发展中国家的开发者
可以用低成本获得先进的技术
因此，李飞飞呼吁政策的制定者们
应该保护开源社区
防止巨头通过算力垄断、数据垄断等手段
扼杀开源创新
AI是推动社会进步的公共产品
不应该成为少数公司的私产
而贯穿李飞飞所有思考的
是她反复强调的智力无畏
这也是她认为未来AI人才最核心的特质
她结合自己的经历
分享了这种无畏的内涵
从普林斯顿的物理系博士
转到当时还很冷门的计算机视觉领域
从ImageNet的数据驱动
转到大模型狂热时代的空间智能
每一次转型，都是跳出舒适区
面对未知的挑战
但是这种无畏不是盲目的鲁莽
而是基于第一性原理的信仰
坚信自己所研究的是根本问题
坚信智能的奥秘终能被解构
她特别提到了初学者心态的重要性
她回忆起小时候，父亲在旧货市场
对每一件小工具都充满了好奇心
这种对于未知事物的探索欲
是保持智力无畏的源泉
在AI技术每6个月就迭代一次的今天
过去的经验很容易成为认知枷锁
唯有保持无知的好奇
敢于在陌生领域从头学起
才能跟上技术爆炸的速度
她给年轻从业者的建议是
不要追逐当下的热点
应该去寻找那些根本且困难的问题
因为难，所以竞争者少
因为根本，所以价值长久
二零二五年，当杰弗里·辛顿还在警示
硅基智能可能超越人类的非对称优势时
李飞飞选择了一条更底层的道路
她没有纠结于语言模型的参数规模
而是回归到智能的本质
试图教会机器
要像造物主一样理解和构建物理世界
她用5.4亿年的进化史告诉我们
语言只是智能的表层应用
视觉与行动才是历经亿万年打磨的生存底座
她用ImageNet的成功证明
智能的涌现
需要数据的暴力规模
而物理世界的真理
隐藏在像素流的连续性中
而非离散的文本符号里
她用Marble模型和神经空间引擎
展示了空间智能的核心
不是生成逼真的视频
而是构建具备物理一致性、可交互的三维世界
她用合成数据和Behavior 1K
为具身智能打通了从虚拟到现实的路径
最后，她用医疗应用和AI普惠项目
提醒我们，技术的终极目标
永远是守护人的尊严，赋能人的价值
或许
空间智能不会像大语言模型那样
在短时间内引发全民式的狂欢
它没有酷炫的对话能力
也没有惊艳的生成效果
甚至需要我们重新理解智能的定义
但是它正在默默搭建着AGI的物理底座
当AI能够真正看懂三维世界的几何规律
能够理解物体的物理属性
能够在空间中自由的行动
能够帮助人类解决现实中的琐事和难题时
那时的智能
才是完整的、有温度的、能够真正融入人类社会的智能
就像李飞飞在二零二五的演讲中所说
她的科研生涯
始终在追逐一个北极星
那就是理解智能的本质
从ImageNet到空间智能
从数据驱动到以人为本
这条道路漫长且艰难，但是她坚信
只有回到物理世界的本质
回到人类智能的进化根源
AI才能真正实现它的价值
相信未来的AI
不再会是困在屏幕里的文字匠人
而是一个能够触摸、感知、创造物理世界的同行者
感谢收看本期视频，我们下期再见
