大家好，这里是最佳拍档，我是大飞
今天咱们来聊一聊人工智能领域中一位极具影响力的人物
理查德·萨顿（Richard Sutton）
以及他对于AI研究的最新见解
我们在前面的一期节目中刚刚介绍过
最近OpenAI的下一代模型Orion被爆出遇到瓶颈
“Scaling Law撞墙”的说法也越来越多
虽然业内对这个话题依然是争论不休
但是不可否认的是
大模型的发展确实不像去年那样迅猛
而被称为强化学习之父、阿尔伯塔大学教授的理查德·萨顿
他在2019年发表了被AI领域奉为经典的《苦涩的教训》，
The Bitter lesson
已经成了OpenAI研究员的必读文章
在这篇文章中
他指出AI在过去70年的研究
一个很大的教训就是过于重视人类既有的经验和知识
而他认为利用大规模的算力才是AI发展的关键
如今
他也会经常表示AI社区过于沉迷于深度学习
想要通过语言模型的方向来实现智能是没有前途的
他还曾经在一些播客节目中提到对杨立昆观点的支持
认为实现AGI需要明确的目标和一个世界模型
然后利用这个模型来制定行动计划
并且达成目标
而只靠当前的深度学习
是无法实现这个目标的
在加拿大阿尔伯塔机器智能研究所（Amii）近期的视频访谈中
他批评了深度学习主导了这个领域的研究
却忽视了自身的局限性
这让他他感到非常失望
不得不自己下场研究
他认为，深度学习做的是瞬态学习
在学习一个特定的阶段之后就不再学习了
所以他呼吁研究者们
应该要研究在现实环境中能够持续学习和适应的系统
对此，他最看好持续学习
也就是进行元学习、表示学习、在线学习
学会如何学习、如何泛化、以及如何构建状态表示的特征
这个过程将是一种全新的深度网络学习方式
他称之为动态学习网络
在这期访谈视频中
萨顿进一步阐述了持续学习的概念
并且对年轻的研究者给予了一些研究建议
正如他反对一股脑的投入到热门的深度学习研究一样
他希望研究者们对AI的流行趋势保持中立心态
选择一个既重要又可能做出成果的研究方向
好了，接下来我们来详细总结一下
萨顿在访谈中提到的关键内容
首先是他研究强化学习的早期灵感
他一直对能够与外界互动
并且从中学习的系统感兴趣
而将目标形式转化为奖励
其实就是强化学习的核心
不过可能令人惊讶的是
回顾他从1970年代入行人工智能领域到如今
真正涉及到系统与外界的互动、学习并且拥有目标的研究
其实并不多
早期的控制论以及模式识别和监督学习
大多只是在识别模式
缺乏与外界互动并且达成目标的能力
比如在多臂老虎机MAB
也就是研究在多个选择中
如何通过探索和利用最大化收益的决策问题中
虽然是在尝试获取最多的奖励
但是这种学习是无状态的
无法根据不同的情况来调整策略
从而达成目标
而且
AI研究最初就是想通过与世界的互动来实现目标
后来却逐渐转向了模式识别
这种转变使得一些早期重要的研究方向被大家所忽视
比如1954年，B
G
Farley和W
A
Clark在论文《利用数字计算机模拟自组织系统（Simulation of self-organizing systems by digital computer）》中谈到了试错法
然后逐渐发展为监督学习
随后萨顿又进一步解释了世界的概念
也就是那个我们与之互动并且交换信息的地方
他认为世界本身就是被构建出来的
我们向世界发送信息
世界也向我们的眼睛等感官反馈信息
所以
我们可以理解向它发送信息并接收信息的整个过程
这里的关键在于如何构建和转换模型
这样你就能进行规划
如果你能够规划
并且通过反复试错来学习
这就会逐渐产生思维
而在当前的人工智能背景下
他认为人工智能要想通过与世界互动来实现目标
就必须建立一个世界模型
我们必须设定一个目标
然后在多个时间尺度上建模世界
以及学习理解世界的正确结构、特征和概念等等
随着时间的推移
我们已经研究出了性能更好的线性映射方法
能够很好的学习线性关系
实际上
所有的算法一开始都是为线性情况定义的
而对于非线性的情况
会有非线性的版本
比如TD Lambda、Q-learning
线性版本的特点是学习迅速
并且可以适应世界的变化
但是它们无法学习非线性的映射
无法学习异或关系
也无法学习新的特征
然而，1986年发现的反向传播算法
虽然能够学习非线性映射
却不得不放弃快速变化和持续学习的能力
虽然说这是一种不错的权衡
但是问题在于
我们放弃的时间太久了
从某种程度上说过
这个领域的关注点已经发生了变化
大家只专注在能做到的事情上
而不再关注做不到的事情
比如深度学习
就是围绕着数据集能做什么来展开的
而GPT也是高度依赖于已有的知识
因此
虽然我们在语言方面取得了一些成就
但是放弃了持续学习与适应语言的能力
这就像我们丢了钥匙然后去路灯下找
虽然那可能不是钥匙在的地方
但是因为那里能看得见
萨顿觉得这个其实也无可厚非
但是问题在于
这个领域已经是完全压倒性地朝着一个方向发展了
以至于如果你想说“有些事情我们做不到”，
就会受到强烈的劝阻
所以这才是问题
总得来说
早期的机器学习是更加开放的
有兴趣的东西大家都会去尝试
后来呢进入了一个阶段
需要做复杂研究才能发表论文
虽然非线性学习取得了一定的成功
但是没有为其他的研究方向留出空间
所以萨顿认为
应该在实现非线性学习的同时
保持完全的持续性
萨顿还提到
深度学习做的是瞬态学习
在特定环境学习后就僵化不前了
而与之相对的是持续学习
从我们人类的自身学习经验来看
正常的情况应该是持续学习的
而瞬态学习其实是一种异常情况
现有的技术
比如重放缓冲区、归一化和提前停止等等
都是为瞬态学习而设计的
从而抑制了神经网络的持续学习能力
所以它不会在ImageNet数据集上表现得很好
因为这是为瞬态学习所设计的
这样带来的结果是
除了线性方法以外
我们缺乏能够持续学习的方法
也没有好的表示方法
这也成为了如今强化学习和AI领域进步的瓶颈
他还提到之前读博的时候
有同学负责非线性的部分
自己则专注强化学习
他本以为可以互相结合
取得很好的成果
但是40年过去了，还是没能解决问题
如今
非线性研究更是转向了离线瞬态学习
我们依然没有可以用来学习的策略、价值函数、世界模型以及世界转移模型的方法
也没有弄明白表示学习是什么
萨顿有些动情的说道
我们应该戒掉傲慢
这会妨碍我们看清真相，当然
我说这些话的时候
某种程度上也带着傲慢
我给了他们40年的时间来解决这个问题
但是现在看来
我必须自己去做
这样说确实有些傲慢
仿佛我认为自己能在短时间内搞定一切一样
但是实际上
我确实已经思考这个问题很久了
我真的希望不需要我来做
这是结果实在令人遗憾
萨顿认为
之前的研究其实已经偏离了正确的解决方向
他们觉得反向传播可以学习到泛化的表示
但是实际上，反向传播只是梯度下降
而梯度下降只能解决当前问题的特征
缺乏驱动学习系统找到泛化特征的机制
谈到未来的研究方向，萨顿指出
我们要去理解大脑是如何运作的
要去弄明白一个系统是怎样通过尝试各种不同的事情
以及通过试错的方式进行学习的
进而构建起一个关于世界的转换模型
只有这样我们才能够真正理解这个世界
才能够为我们找到决策的关键支撑点
比如
我到底应该去听这个讲座还是那个讲座？
我是不是应该去洗手间？
我要不要喝一口茶？
所有这些情况，我们必须做出选择
虽然低层次的选择是存在的
但是我们必须在自己的生活当中
找到那些有意义的选择
而所有这些都与一个模型紧密相关
因此
这就要求我们通过试错来进行学习
并且建立起世界模型
同时还能够运用这个模型来进行规划
这就是构成思维的一系列重要因素
萨顿也表示自己确实认同奖励假设
也就是所有的目标追求
都可以很好地理解为
对一个单一的外部接收标量信号进行最大化
即总体的单一目标就是获得奖励
但是奖励假设的特别之处在于
认为存在一个极其微小的标量值
而我们在努力让它最大化
于是，你会从一个进入脑海的数字
逐渐产生出像“我想组建一个家庭
我渴望成为一名成功的研究科学家”之类的想法
也就是从一个具体的事物中
能够产生出非常抽象的目标和概念
就如同语言模型一样
在关于智能的预测方面
萨顿认为未来几十年里
我们将探索理解思维的奥秘
这个过程可能会带来不适
但是也意味着在不断进步
他预测到2030年
我们有25%的概率能理解智能
虽然这并不代表着完全理解人类思维
但是我们能学会通过试错的手段
来实现目标、进行多抽象层次规划、构建良好的表示形式概括等等
这将会是一个类似神经网络结合多种算法
并且带有奖励机制的系统
一旦实现，这将会改变社会的现状
帮助我们更深入的认识思维
引发技术和经济变革
同时也改变我们人类自身
甚至影响教授知识和育人的方式等等
他还提到脑机接口技术
认为虽然它是一种接口
而且目前很难实现高带宽的输出
但是可能会存在其他更好的压缩信息的方法
找到比语言更高效的沟通方式
最后
理查德·萨顿对AI的研究人员们提出了一些建议
一是准备笔记本或者电脑
随时记录自己的想法
面对空白的纸张
写下那些模糊混乱的想法是很有价值的
尽量坚持每天写一页
另外要保持定期写作的习惯
通过解释脑海中的想法
来发现其中的价值
并且让这些想法逐渐地成长和变化
二是对流行趋势要保持中立
选择你认为既重要
又可能有研究成果的问题去研究
而不要受到研究方向是否流行或者冷门的影响
你可以先列出一些自认为有趣的事情
然后再确定研究方向
因为大多数研究不会立即就成功
或者立即见效，所以需要不断的尝试
好了
以上就是关于理查德·萨顿对于AI研究方向的观点了
希望能给大家带来一些思考和启发
在探索人工智能的道路上
显然我们还有很长的路要走
感谢大家观看本期视频
我们下期再见
