大家好，这里是最佳拍档，我是大飞
当 AI 行业里的巨头们还在追逐Scaling laws的时候
一位学界泰斗却发出了警示
那就是在某种程度上
AI行业已经迷失了方向
说出这句话的，不是别人
正是 Rich Sutton
作为强化学习之父、图灵奖得主
Sutton 在 RLC 2025 的讲台上
再次抛出了一套宏大的构想
直指 AI 的终极问题
超级智能将如何从经验中涌现？
他将这个架构命名为橡树OaK
全称为Options and Knowledge Architecture
这不仅仅是一个技术框架的发布
更像是一篇檄文
它深刻地批评了当前 AI 领域对大语言模型的路径依赖
并且试图将研究的焦点
重新拉回到那个最经典也最核心的命题上
我们究竟该如何创造一个能够像我们一样
通过与世界互动、在生命周期中不断学习和成长的智能体呢？
Sutton 认为
要回到通往「真正智能」的正确轨道上
我们需要做到几件事
1、能够持续学习的智能体
2、能够建立世界模型并且进行规划
3、能够学习高层次、可学习的知识
4、能够实现元学习泛化
而 OaK 架构
正是他对上述所有需求的回应
今天，就让我们来一起学习一下
Sutton究竟给我们描绘了怎样不同的新路线
在演讲中
Sutton 重新定义了 AI 研究的终极目标
他形容为一场伟大的远征
重要性堪比地球生命的起源
因为我们不仅是在制造一个强大的工具
更是在理解心智的本质
他说，说来奇怪
最大的瓶颈
是我们缺乏足够的学习算法
我们现有的算法，包括深度学习
都还非常粗糙
在随后的演讲中
Sutton 建立了一个宏大的世界观
这个世界观是他所有思考的基石
他将其称为大世界视角
这个视角的核心是一个简单却深刻的思想
那就是世界远比智能体本身要庞大和复杂得多
世界里包含了数十亿种其他的智能体
包含了所有的原子和物体的复杂细节
你的朋友、爱人、甚至是敌人头脑中发生的事情
都与你息息相关
在这个「大世界」中
智能体永远不可能获得关于世界的完整、精确的知识
因此，它的价值函数必然是近似的
策略是次优的
对世界的模型也必然是高度简化的
更重要的是
由于智能体无法观察到世界的全部状态
这个世界在它看来
必然也是非平稳的
这个看似简单的假设
却直接引出了 Sutton 对当前 AI 发展路径的第一个核心批判
设计时对运行时
设计时
指的是在工厂里、在模型发布之前
由人类工程师将知识和能力构建到智能体中的阶段
而运行时指的是智能体被部署到真实世界后
通过与环境的实时交互
来学习和成长的阶段
Sutton 毫不客气地指出
一个大语言模型
所有的事情都在设计时完成了
当它被部署到世界上使用的时候
它什么也不再做
不再学习了
他的观点非常明确
那就是所有重要的事情
都必须在运行时来完成
为什么？
因为在一个大世界里
你不可能在设计时里
预见到智能体将要面对的所有情况
比方说，一个家用机器人
它需要记住主人的名字、工作项目的内容、同事是谁
这些信息都不可能预先内置在它的领域知识里
它必须在运行时去学习、去适应
这就自然地引出了 Sutton 多年前提出的著名论断
苦涩的教训(The Bitter Lesson)，
其中写到，我们想要构建的
是能够像我们一样去发现的智能体
而不是包含了我们已经发现的东西的智能体
而大语言模型，在某种意义上
正是包含了我们已经发现的东西的极致体现
它通过在设计时吞噬海量的人类知识文本
构建了一个庞大的知识库
但是它却缺乏在运行时发现新的知识、抽象成新的概念的能力
Sutton 认为，这是一种本末倒置
真正的智能
它的核心能力应该是在运行时的学习
而设计时提供的
只应该是那些最通用的、能够支持这种学习的元方法
不过
他也指出了当前运行时学习所面临的巨大技术瓶颈
包括灾难性遗忘和可塑性的丧失
这也造成了今天的深度学习方法
在持续学习方面表现得并不好
这就是 Sutton 在演讲中抛出的时代之问
当整个行业都在为 scaling law 欢呼
将大模型的参数竞赛推向新的高潮时
我们是否忽略了通往真正智能所必需的、更根本的东西呢？
而OaK 架构，就是他给出的答案
在构建 OaK 架构之前
Sutton 首先清晰地定义了他所追寻的 AI 圣杯
需要满足的三个核心的设计目标
这三大准则支撑起了 OaK 架构的整个哲学思想
准则一，领域通用
智能体的设计本身
不应该包含任何关于特定世界的知识
应该说
这是一个非常激进但是又无比纯粹的目标
Sutton 强调
这并不是要否定领域知识在具体应用中的价值
如果你想快速开发一个能够解决特定问题的应用
内置一定的领域知识当然是高效的
但是如果你的目标是理解心智的本质
是寻找一个关于智能如何运作的、简洁而普适的理论
那么你就必须将那些任意的、内在复杂的外部世界的细节
排除在智能体的核心设计之外
而智能体的任务
正是去学习这个世界中那些古怪的、繁复的细节和高层结构
而不是将这些细节变成自身设计的一部分
我们想要的是一个简洁、优雅、能够理解任何世界的智能原理
而不是一个装满了特定世界知识的、复杂的百科全书
简单来说就是，关于特定世界的知识
应该让AI 自己去学习
而不是被人类工程师给硬编码进去
准则二，完全经验主义
智能体的心智
应该完全从运行时的经验中生长出来
而不是依赖于一个特殊的训练阶段
这个准则与对设计时和运行时的讨论
一脉相承
Sutton 的逻辑非常清晰
既然在一个大世界中
智能体必须具备在运行时学习、规划、构建和调整抽象概念的能力
那么，为什么不将这种能力
作为设计的唯一核心呢？
那些在设计时预先构建的能力
或许能让智能体在起跑线上抢跑
但是从概念的简洁性上来看
一个只依赖运行时经验的纯粹设计
无疑是更加根本、更为优雅的
也就是说
既然你必须有能力在运行时完成这些事
那为什么不干脆在一个地方把它们都做了呢？
准则三，开放式抽象
智能体应该能够持续不断地创造出
任何它所需要的概念和抽象
这个复杂度的上限只应该受限于它的计算资源
这才是通往超级智能的关键
智能体不能够只停留在学习预设的特征或概念上
它必须有能力在与世界的互动中
自己发现这个世界的联结
自己定义出新的、更加有用的概念
并且利用这些新的概念
去构建更为复杂的知识体系
同时
这个过程必须是开放的、永无止境的
为了给这三大准则提供一个明确的目标函数
Sutton 重申了他坚信不疑的奖励假说
所有我们所说的目标 (goals) 和目的 (purposes)，
都可以被很好地理解为
对一个接收到的标量信号
也就是奖励
它的累积和的期望值的最大化
这个假说
将智能体所有复杂的行为动机
统一到了一个极其简洁的数学框架下
无论是寻找食物、探索未知
还是进行艺术创作
这些行为的根本驱动力
都可以被建模为最大化某个单一的标量奖励信号
在一个足够复杂的世界里
仅仅是最大化一个简单的奖励信号
就足以涌现出我们所认为的智能的所有属性
到这里
Sutton 的AI 圣杯画像已经逐渐清晰
那就是一个领域通用的智能体
完全通过运行时的经验
在一个开放式的抽象创造过程中
以最大化标量奖励为唯一目标
最终成长为真正的超级智能
有了清晰的目标后
我们可以来揭开 OaK 架构的神秘面纱了
首先，让我们来拆解它的名字
OaK，也就是Options + Knowledge
我们先说Options，选项
在强化学习中
Option 指的是一个时间上扩展的动作
它不仅仅是一个原子动作
比如向左走一步
而是一个包含了自身策略 (policy) 和终止条件的行为片段
比如走到门口这个选项
而Knowledge ，知识，在 OaK 架构中
知识特指当你执行某个 Option 后
会发生什么的模型
这是一种更高层次的世界模型
它让你能够以更大的时间步长
来进行推理和规划
因此，OaK 的核心
就是让智能体不断地学习新的 Options
并围绕这些 Options 建立起关于世界的 Knowledge
让智能体能够在一个更高的、更抽象的层面上理解和规划世界
从而实现在更大的时间尺度上进行跳转
并且在世界的关键节点上剖析世界
从OaK 架构的整体示意图中
我们可以看到
它包含了经典强化学习智能体的所有组件
包括从世界接收观察 (Observation) 和奖励 (Reward)，
输出动作 (Action)，
内部有策略 (Policy)、价值函数 (Value Function)、世界模型 (Model) 和规划器 (Planner)。
但是其中最关键的不同在于
辅助子问题 (Auxiliary Subproblems)。
Sutton 认为
智能体不应该只有一个由环境给定的主任务
比如最大化奖励信号
它必须能够为自己创造新的、内部驱动的子问题
这其实也是一个困扰 AI 和认知科学多年的问题
那就是好奇心、内在动机和玩耍的本质是什么？
Sutton 用一个生动的例子解释了这一点
一只年幼的猩猩在树枝上摆荡
它不是为了获取食物
只是对摇摆这种感觉本身产生了兴趣
一个婴儿不断地摇晃拨浪鼓
也不是为了完成某个外部任务
而是为了重现和理解那个有趣的声音
这些所谓玩耍的行为
在 Sutton 看来
就是智能体在为自己设定子问题
那么这些子问题又是从何而来的呢
Sutton给出了一个极其简洁的机制
那就是从特征feature中来
当智能体在与世界交互的时候
他的感知系统会构建出
世界的状态特征
这些特征可以是任何东西
一个明亮的光斑、一个特定的声音
或者是一种特殊的感觉
因此，OaK 架构的核心思想是
任何一个足够有趣的特征
都可以成为一个新子问题的目标
而这个子问题就被定义为「尊重奖励的特征达成」。
具体来说，对于某个特征i
智能体会创建一个子问题
它的目标是
在不过多损失主任务奖励的前提下
尽可能地让特征i的值变高
这个定义的精妙之处在于
智能体在追求自己的小目标
比如探索一个有趣的声音时
不会完全忘记自己的大目标
比如生存
它会在两者之间进行权衡
再打个比方，为了喝到一杯咖啡
也就是达成「咖啡」这个特征
它会寻找一条安全的路径
而不会选择跳下悬崖
因为这会导致巨大的负奖励
通过这种方式
智能体得以源源不断地为自己创造出探索世界的内在动力
从而构建出一个持续发现、持续抽象的、永动机式的学习循环
Sutton 将它描述为一个由多个并行步骤构成的运行时循环
这个过程
正是 OaK 架构中那棵智慧之树的生长脉络
循环的第一步是特征构建
一切始于感知
因此智能体需要从与世界交互的原始数据流
比如观察和动作中
构建出对它当前所处状态的描述
也就是状态特征
Sutton 强调
这个过程不是为了逼近某个人类标注的标签
或者是某个外部世界的真实状态
而是为了服务于智能体自身的决策和学习
一个特征是否有用
取决于它能否帮助智能体更好地解决问题
循环的第二步是提出子任务
智能体内部有一个评估机制
当智能体构建或者发现了一个有趣的特征后
它会将这个特征本身变成一个新的目标
即一个子任务
然后，它会基于这些高价值特征
按照我们前面提到的
尊重奖励的特征达成原则
生成一系列新的子问题
Sutton 认为
智能体必须能够自己创造自己的子任务
而不是等待人类来设定
循环的第三步是学习选项
一旦一个子任务被提出
智能体就会利用强化学习的方法
去学习一个能够完成这个子任务的策略
也就是一个 Option
例如
针对再次发出摇铃声这个子任务
智能体可能会学到一个 Option
包含了一系列特定的手臂和手腕动作
以及在听到声音后就终止的条件
于是
OaK 架构中会同时存在大量这样的 Options
每一个都对应着一个由特征转化而来的子任务
循环的第四步是模型学习
当智能体拥有了大量的 Options 后
它接下来要做的
就是为每一个 Option 学习一个模型
这个模型要回答的问题是
如果我在某个状态下
启动了发出摇铃声这个 Option
世界会发生什么变化呢？
我会到达一个什么样的新状态呢？
在这个过程中我会得到多少奖励呢？
这是一种高层次、时间抽象的世界模型
它不再是对单步原子动作的建模
而是对整个行为片段
也就是Option的结果进行预测
这使得智能体的规划能力得到了质的飞跃
循环的第五步是规划
拥有了基于 Options 的高层世界模型后
智能体就可以进行高效的、长远的规划
它可以像在脑中下棋一样
推演执行一系列选项组合的后果
从而找到解决主任务的最佳宏观策略
并且以此来更新自己的整体策略和价值函数
另外，当面临一个新的目标
比如主线任务的奖励发生了变化时
它不再需要从原子动作开始
一步步地进行模拟推演
而是可以直接在 Options 的层面上进行思考
比如，它会想
我可以先执行走到门口的 Option
然后再执行打开门的 Option
等等等等
这种基于高层抽象的规划
它的效率和深度
远非单步规划所能比拟
Sutton 强调，规划的本质
就是通过模型来让价值函数与世界
动态保持一致
需要注意的是
这些步骤并非线性执行一次就结束
它们构成了一个永动的学习循环
而循环的关键就在于反馈
当智能体利用学到的 Options 和 Models 进行规划的时候
它会发现
某些 Options 对于解决主线任务特别有用
某些 Options 的模型更容易学习
预测更准
又或者在学习某个 Option 的策略或模型时
某些底层的状态特征比其他的特征更加有用
这些信息会形成一个反馈信号
反过来告诉第一步的特征构建模块
哪些类型的特征是有用的
哪些是无用的
这个反馈机制
会引导智能体去构建出更多、更好的新特征
而这些新特征
又会成为新一轮提出子任务的原材料
从而开启新一轮的 Option 学习、Model 学习和 Planning
就这样
智能体从解决简单子任务的过程中
发现了构建更复杂子任务所需要的特征
又从解决这些复杂子任务的过程中
发现了构建更更复杂任务的特征
这个循环不断往复
使得智能体的认知能力和抽象水平
就会像滚雪球一样，不断地自我提升
最终形成一个开放式的、没有上限的智能成长阶梯
这就是 Sutton 对超级智能如何从经验中涌现
给出的机械论的回答
它告诉我们，智能
本质上是一个自我驱动、自我创造、自我提升的永恒循环
尽管 OaK 架构的愿景激动人心
但是Sutton 在演讲中也坦诚地指出了
实现这个宏大愿景所面临的巨大挑战
以及当前仍然缺失的一些关键的技术拼图
其中，最关键的两个老大难的问题
正是我们视频开头所提到的
如何可靠的持续学习和新特征的元学习
我们先说前者如何可靠的持续学习
这是整个 OaK 架构的基石
无论是学习主线任务的价值函数和策略
还是学习成百上千个子任务的 Options 和 Models
所有组件都必须能够在运行时
持续不断地学习新的知识
同时不忘记旧的知识
Sutton 明确指出
我们还没有可靠的、能够用于非线性函数逼近器
即深度神经网络的持续学习算法
灾难性遗忘的问题
仍然是深度强化学习领域的一座大山
尽管已经有了许多的研究方向
但是目前还没有一个公认的、能够大规模应用的解决方案
其次是新特征的元学习
这是学习循环的起点
也是最具挑战性的一环
智能体如何从零开始
自动地、创造性地生成那些有用的新特征呢？
这个问题，也被称为新术语问题
可以追溯到上世纪 60 年代 Minsky 等 AI 先驱的思考
Sutton 认为
虽然 1986 年提出的反向传播算法本应该解决这个问题
但是事实证明
单纯依赖梯度下降来学习表征是远远不够的
当前的大多数方法都基于生成与测试的思想
也就是随机或者启发式地生成大量的候选特征
然后通过某种方式
比如对下游任务的贡献度
来评估和筛选
但是如何设计一个高效、可扩展、而且具有创造性的特征生成器
仍然是一个开放性的核心问题
Sutton 相信，解决这两个问题
将会是未来几年 AI 领域最重要的突破
一旦我们拥有了能够持续学习的深度学习方法
它将接管人们用深度学习所做的一切
应该说，Rich Sutton 的 OaK 架构
与其说是一个具体的算法
不如说是一个思想纲领
一个研究范式
它提醒着我们
在追逐模型参数和数据集规模的竞赛中
不要忘记 AI 研究最初的梦想
那就是创造一个能够自主学习、理解和改造世界的智能
总的来说
OaK 提供了一套关于心智如何运作的、极具说服力的计算理论
回答了这个领域深埋已久的一些问题
比如
高层知识如何从底层经验中学习呢？
答案是通过循环
概念是从何而来的呢？
答案是来自于为解决子任务而构建的特征
那么，推理的本质又是什么呢？
答案或许就是基于 Option 模型的规划
玩耍和好奇心的目的是什么呢？
答案是为了发现并且设定那些
能够构建我们认知结构的子任务
而感知的目的又是什么呢？
答案是
为了形成那些能够作为子任务基础的、有用的内部概念
同时无需人类标签的监督
对于整个 AI 行业而言
OaK也提供了一个全新的思考框架
一个可以指导未来几十年研究的宏大愿景
它强调了在当前大语言模型热潮中
可能被大家所忽视的几个关键能力
包括基于学习模型的规划
根植于经验而非人类标签的感知
以及子问题、选项和特征的自主发现
OaK让我们开始重新思考
究竟什么是真正的学习？
什么又是真正的智能呢？
正如 Sutton 在演讲结尾所说
OaK的愿景
正是如何基于运行时的经验
培育出一个开放性的超级智能
如果这条路是正确的
那么 AGI也许将始于经验
成于循环，达于无限
感谢大家收看本期视频
我们下期再见
