大家好，这里是最佳拍档，我是大飞
今天我们来补一期英伟达GTC相关的视频
大飞我觉得是除了黄仁勋的Keynote之外
信息量最大
也是最有价值的一期内容
尤其是对于在做、以及想要做英伟达股票的朋友来说
一定要听一听
当然，大飞我不做任何交易建议
大家自己判断
我们先简单回顾一下
在3月举行的GTC 2024大会上
英伟达的CEO黄仁勋公布了新一代芯片平台Blackwell
创新软件NIM、仿真平台Omniverse
以及适用于自主机器人的Isaac平台等等
引发了全球关注
会后
黄仁勋进行了两场媒体和分析师采访
其中就包括我们今天要讲的
一个半小时的GTC投资分析师问答
其中补充了大量黄仁勋没有在发布会上公开的内容
这次分析师问答活动
参与者不仅包括英伟达CEO黄仁勋
CFO科莱特·克雷斯Colette Kress
还包括美林、伯恩斯坦、瑞银、摩根士丹利、花旗、富国银行等一众金融机构的投资人
那我们就来看看他们之间都说了什么
活动一开始
黄仁勋首先做了一个开场白
回顾了第一天他的公开演讲
信息量就极大
他总结第一天的演讲其实谈了五件事
第一件就是这场新的工业革命
发生了两个转变
第一个转变是从通用计算转向加速计算
如果只看通用计算的趋势
它在过去几年中已经大大放缓
人们延长了数据中心的折旧周期
即使是购买一整套新的通用服务器
也不会显著提高整个数据中心的吞吐量了
通用计算已经走到了尽头
虽然还将继续需要它
因为还有很多软件在上面运行
但是加速计算的趋势是非常明显的
因为如果不转向加速计算
数据处理费用只会不断的上升
许多认识到这一点的公司
比如阿斯利康、Visa、美国运通、万事达卡等
已经通过英伟达将他们的数据处理费用降低了95%，
基本上是20倍的在减少
加速的好处是可以节省成本
并将这些节省下来的成本传递给客户
这样就可以持续进行计算
在过去的十年中
加速算法让计算的边际成本大大降低
使得一种新的软件方式成为可能
也就是今天的生成式AI
生成式AI使用计算机来编写软件
然后用GPU来处理大量的数据
从而产生token和服务，比如ChatGPT
这就像上一次工业革命的发电机
将水转化为电能一样
第二个转变的是
数据中心正在被加速
现在的数据中心不再是一个普通的数据中心
而是一家工厂
它不再像过去的数据中心那样被很多人共享
也不再做很多不同的事情
它只会一直运行一个应用程序
它的目标不仅仅是省钱
而是赚钱
另一种数据中心称之为AI发电机或者AI工厂
这将是一个新的事物、新的行业
第二件事是Blackwell
Blackwell的核心是一块芯片
但是它实际上是一个计算机系统
英伟达不仅仅是制造芯片
而是构建了一整台超级计算机
从芯片到系统
再到互连、NVLink、网络
其中最重要的是软件
英伟达通过一种可拆卸的方式
帮助客户来构建使用芯片的集成系统
并允许客户分批购买
客户可以把它连接到x86
或者PCI-Express结构
或者不同的NVLink域，或者以太网
当然
现在的以太网对AI来说并不友好
在三、四年后超级以太网到来之前
英伟达先在以太网的基础上提供了Spectrum-X
它可以进行自适应路由、拥塞控制、噪音隔离等等
AI应用并不关心网络的平均吞吐量
而是关心最后一个任务何时完成
这就像在班级中
我们关心的总是最后一个学生何时提交作业
而不是作业的平均提交时间
为此
英伟达创建了一个平台、以及相关的软件和硬件设备
然后将他们集成到客户的数据中心
考虑到每个客户的需求可能不同
比如安全需求、热量管理、管理界面等等
所以英伟达已经做了充分的准备
可以满足每个人的需求
人们总是把英伟达看做是一家芯片公司
但是实际上
英伟达其实是在建立数据中心
还把它分解成一个个小部分
然后作为组件出售
第三件事是谈到了一种新的软件NIM
即Nvidia Inference Microservices
实际就是将优化的AI推理引擎、标准API和对AI模型的支持
打包到云容器中
从而加速AI大模型开发的软件服务
现在在英伟达的网站上可以购买和下载这个工具
工具本身是免费的
但是使用这个工具来运行AI的成本
是每年每个GPU4500美元
你可以用NIM做很多事情
比如计算机视觉、语音识别、文本转语音、面部动画和机器人关节等等
只需要从网站上下载NIM
然后根据需求进行微调就可以了
英伟达还提供了一个叫做Retriever的微服务
它可以帮助你处理数据库
包括结构化和非结构化的数据
比如帮你从数据中提取有用的信息
并把这些信息转化为向量
然后索引到一个新的数据库中
所有这些都被称为NeMo
然后英伟达会把一个标准的NVIDIA基础设施
DGX云，放在世界上所有的云中
比如AWS、Azure、GCP和OCI中
这样
英伟达通过与世界各地的企业公司合作
创建AI
AI完成后就可以在DGX云中运行
这意味着把客户带到了世界的云中
从而将英伟达变成了一个平台公司
第四件事是AI的下一个浪潮，工业AI
重工业是世界上最大的行业
但是却从未真正从IT中受益
既没有从设计中受益
也没有从数字化中受益
而芯片行业已经完全数字化
所以我们说芯片设计
而他们则说药物发现
工业物理学和我们使用的大语言模型技术很相似
如果我们能标记文字、语音和图像
也能标记发音
甚至可以标记移动的蛋白质
包括物理学，就像标记语音一样
而理解它的含义
就像我们理解单词的含义一样
如果我们能够理解它的含义
并将它与其他模式联系起来
我们就可以做出生成式AI
12年前黄仁勋就看到了这个可能性
英伟达在ImageNet上也看到了
如果说ChatGPT是在模仿我们
那既然能模仿单词，也能够模仿动作
所以机器人的ChatGPT时刻也将到来
因此英伟达创建了Omniverse
想让这些AI也能够在基于物理的世界中进行实践
Omniverse不是一个工具
也不是一个引擎
而是一个可以增强其他人工具的API
比方说
达索公司正在使用Omniverse API来增强3DEXCITE
微软用来增强Power BI
罗克韦尔和西门子也把Omniverse用到了工业自动化上
而第五件事就是软件
英伟达认为自己是在创造新的市场
而不是争夺存量市场
包括实时光线追踪、Omniverse等等
但是这些东西创造出来
就需要有开发者来把它们集成到应用程序上
为此，很多技术都提供了SDK和云API
如果用一个图来表示
那么像Azure这样的供应商在底部
开发者在上面
而英伟达在中间创新技术
最后变成了芯片
而这一切的前提是软件，没有开发者
就不会有芯片的需求，因此
英伟达首先是一家算法公司
创建了这些领域专业的库
或者称为DSL SDK
包括cuDNN
它是一个专门用于深度神经网络计算的库
如果没有DNN，就无法使用CUDA
所以英伟达创造了DNN，同样
实时光线追踪引擎也导致了RTX的出现
当这些领域特定的库与软件开发者结合
创造出来各种应用程序并且有市场需求的时候
它就会为下面的基础创造机会
所以结论是
没有软件就无法创造市场
你可以制造芯片来改善软件的运行
但是如果没有软件
就无法创造一个新市场
英伟达的独特之处在于
是唯一一个能够创造自己市场的芯片公司
并且能够看到所有正在创造的市场
这就是为什么黄仁勋总是谈论未来
为什么英伟达必须要与整个行业合作
像设计芯片一样去设计药物
而不是像寻找松露一样去寻找药物
因此
英伟达决定把开发人员放在首位
他们想要简单易用的工具
想要有技术来解决他们面对的难题
对于他们来说
最重要的是有一个稳定的安装基础
因为如果没有硬件来运行他们的软件
他们的软件就无法使用
即使是AI软件也一样
然后是杀手级应用
因为杀手级应用带来了客户需求
而客户需求则需要硬件
启动这个循环是非常困难的
我们无法为每个行业去建造一个加速平台
所以才需要一个足够通用的加速计算平台
一个能运行一切的计算平台
而英伟达正是这样一个平台
如果你有需要GPU加速的软件
黄仁勋非常确定它一定可以运行在英伟达上
是因为它可能就是先在英伟达上运行起来的
好了
以上就是黄仁勋开场白的核心内容
对英伟达商业化版图的规划布局和底层逻辑
做了一个相当清晰的描述
但是还没有完
更多的内容还在后面他和投资人的问答对话上
我们重点挑选了几个
第一个问题是关于对软件业务发展的看法
黄仁勋回答说
NVIDIA的软件业务主要做两件事情
一是开发能优化计算机性能的算法
二是开发能解决一些复杂科学问题的新软件
比如纳维尔-斯托克斯Navier-Stokes的算法
英伟达将这些软件打包成企业软件
维护它们
跟SAP，ServiceNow，Adobe
Autodesk这些伟大的软件公司相比
英伟达的工作在更上一层
主要是AI和算法
第二个问题是关于潜在的市场规模
黄仁勋首先认为英伟达主要销售的是数据中心
大家看到的芯片只是产品的一部分
要把这些芯片集成到系统中
这是一个复杂的过程
因此英伟达为AI构建了整个数据中心
当前的市场规模是1万亿美元
每年有2500亿美元的市场
也正因为如此，黄仁勋认为
英伟达制造的是一个数据中心规模的加速计算平台
所以市场份额会比只卖芯片的公司更大
其次这个市场有多可持续
黄仁勋认为
如果英伟达只是依赖于AI的市场
那么市场份额就会有明显的天花板
但是因为英伟达在AI这方面做得太好了
导致大家好像忘记了英伟达还有其他的业务
比如计算机图形学和游戏
实际上
英伟达应该是一个加速计算公司
总的来说
加速计算的市场规模是1万亿
每年有2500亿美元的市场
而且不论是否使用AI
大家都需要进行可持续计算
比如处理SQL等等任务
再加上生成式AI
以后不光是生成文字、图像、视频、蛋白质、化学物质、动力学作用、操纵等等
还将生成预测、账单、物料清单等等
所以市场的可持续性是很强的
在谈到对ARM CPU和X86 CPU的看法时
黄仁勋认为
ARM的好处是可以围绕CPU来构建英伟达的系统架构
这样就可以通过NVLink让双方保持一致
也就是说，当CPU接触到一个寄存器时
GPU端的相同寄存器也会失效
这样双方就能在一个变量上连贯地协同工作
如今
X86和外设之间还无法做到这一点
在未来三到五年里
更大的NVLink域对于下一代人工智能来说至关重要
如果真的想获得良好的推理性能
就需要NVLink
大语言模型的推理
绝对不可能在一个GPU上完成
为了保证足够的响应速度和高吞吐量来降低成本
就要用到大量的GPU
而为了让大量GPU在没有开销的情况下协同工作
就需要NVLink
很多人一直认为NVLink的优势在于训练
实际上NVLink在推理能力上的优势也是超出预期的
相当于5倍和30倍之间的差别
这中间6倍的差距都是NVLink的功劳
而X86系统就很难做到这一点
不过英伟达两种都支持
会有两种版本
因此
从Hopper到Blackwell的过渡会很快
而且相当丝滑
最后
谈到下一代模型对GPU架构的影响
以及未来AI GPU的发展趋势
黄仁勋认为
所有下一代模型都是为了将当前一代系统的极限推向极致
比如
长上下文窗口、大规模的合成数据生成、自博弈、强化学习、树状搜索等等
这些模型必须学会如何推理和进行多路径规划
而这种规划、推理、甚至多步骤推理的系统可能相当抽象
学习路径可能相当长
就像下围棋一样
未来两三年内看到的系统是今天难以想象的
有些人担心互联网是否有足够数据
用来训练这些模型
但是其实不必担心
模型之间的交互、强化学习
都会生成大量的数据
今天
我们有一个计算机用于训练数据
但是明天
可能就需要两台计算机相互训练
就像AlphaGo一样
通过多个系统的竞争
我们可以更快地完成这些计划
所以
一些真正令人兴奋的突破性工作就在不远处
有一点可以肯定的是
GPU的规模还将更大
英伟达的SerDes是世界一流的
数据速率和能量消耗都很低
因此能够制造NVLink
NVLink是因为我们无法制造足够大的芯片
所以才在2016年
将八个芯片连接在一起
现在使用的是NVLink第5代
它允许将576个芯片连接在一起
从软件的角度讲
我们应该先从制造尽可能大的芯片开始
因为这样可以节省很多的电力和钱
但是这显然还不够
所以我们不得不将多个芯片连接到一起
Blackwell就是第一个这样的架构
我们把两个芯片连接在一起
传输速度可以达到惊人的每秒10TB
现在呢我们有了一个巨大的芯片
有576个GPU
但是这还不够
还需要连接更多的芯片
那怎么办呢
这时候infiniband就是最好的选择
其次是集成了加速计算层的以太网
也就是Spectrum x
这样呢我们就能够控制系统中的流量
从而避免出现长尾的现象
正如黄仁勋之前所说的
决定计算速度的是最后完成的那一个任务
而不是平均的吞吐量
好了
以上就是GTC这次分析师问答的精彩内容
黄仁勋在GPU和AI计算发展方向上
确实有着独到的看法
而且对英伟达的商业形态也有着更加深刻的理解
甚至还充分考虑了在构建合作生态方面的位置和作用
在大家可能还觉得英伟达只是一个卖显卡的公司的时候
这次的GTC已经告诉大家
英伟达实际上卖的是新一代的数据中心
以及在这之上新一代的基础设施和软件方案
所以这次GTC之后
很多投资机构立刻上调了英伟达的目标价
也算是市场的一种积极反馈
那大家是看多还是看空英伟达呢
欢迎在评论区留言
感谢大家的观看
我们下期再见
