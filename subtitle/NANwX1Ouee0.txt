大家好，这里是最佳拍档，我是大飞
对于前沿人工智能模型领域
尤其是开源模型来说
这两天可谓热闹非凡
AI 科技竞赛正在以前所未有的速度推进
换句话说，就是往死里卷
Llama3.1发布后
小扎开源模型的头把交椅都还没坐热乎
法国的Mistral AI团队就突然扔出王炸
发布最新开源模型Mistral Large 2
然后一脚就把llama3.1从王座上踹了下去
要知道
这距离Mistral Large首代发布都还不到半年
可谓是进步神速
Mistral Large 2模型最大的特点就是「刚刚好」。
他们的规模不夸张，有1230 亿个参数
虽然参数量低于 Llama 3.1 的 4050 亿
但是两者的性能却非常接近
与此同时，在多个基准测试中
Mistral Large 2可以与 GPT-4o、Anthropic 的 Claude 3.5 Sonnet 相媲美
瘦身反而成了Mistral Large 2的优势
由于体量较小
所以有着更加显著的成本效益
新模型还支持数十种新语言
除了初版已经支持的语言以外
这次还加上了葡萄牙语、阿拉伯语、印地语、俄语、汉语、日语和韩语
Mistral 方面表示
这套通用模型非常适合需要强大推理能力、或者高度专业化的任务
比如合成文本生成、代码生成以及 RAG（检索增强生成）等等
不过，值得注意的是
Mistral Large 2 虽然是开放的
但是只限于研究和非商业用途
它提供了开放的权重
允许第三方根据自己的需求对模型进行微调
这个协议是对用户使用条件的一个重要限制
对于想要自行部署 Mistral Large 2 的商业用途
必须提前获取 Mistral AI 商业许可证
接下来
大飞就来带大家了解一下Mistral Large 2 的详细信息
我们先来看看Mistral Large 2 的基本情况
早在今年 2 月
Mistral 就推出过具有 32k token 上下文窗口的初代 Large 模型
当时Mistral称这款产品“对于语法和文化背景
有着细致入微的理解能力”，
因此可以推理并且生成支持不同语言
包括英语、法语、西班牙语、德语和意大利语
而且与母语水平相当的流利文本
这次发布的新版模型
在之前的基础之上将上下文窗口增加到了 128k
与 OpenAI 的 GPT-4o 、 GPT-4o mini 以及 Meta 的 Llama 3.1 旗鼓相当
现在
他们不仅把自己之前画的饼给圆了
甚至还有意外之喜
那就是Mistral Large 2 的体积比同级别的模型瘦了一圈
前几天发布的Llama 3.1405B模型
就是因为其庞大的参数
劝退了很多个人开发者
刚一发布
就有一位勇敢的推特网友亲测
如果用一张英伟达4090运行Llama 3.1
需要等足足30分钟模型才能开始回应
结果只是缓缓吐出一个「The」，
而等到模型给出完整的回应
足足用了20个小时
根据Artificial Analysis的估算
你需要部署含2张8×H100的DGX超算
才能在本地运行405B
从这方面看
小扎对Llama 3.1成为开源AI界Linux的期待
可能和现实还有不少的差距
目前的硬件能力
很难支持405B模型的大范围全量运行
而Mistral AI却想用三分之一的参数实现和llama3.1相似的效果
确实，在参数量砍去一大半之后
本地部署难度就大大下降了
同样从ollama上下载模型
用96GB内存就可以顺利把Mistral Large 2运行起来了
虽然3 token/s的生成速度还是慢了一点
但是比起用20个小时等模型响应
已经是质的飞跃了
在功能方面
Mistral Large 2 和llama3.1 的对垒
就像一个一米四的小个子跳上擂台
要和一个两米高的大汉打拳击一样
然而，面对405B的壮汉
Mistral AI没有丝毫的怯场
对自己的作品相当自信
特意将Mistral Large 2与GPT-4o、Llama 3.1 405B、GPT-4等主流的开闭源大模型
进行了综合对比
而Large 2 的优秀成绩
也证明了Mistral AI的自信并非空穴来风
Mistral Large 2的一大亮点就是彪悍的多语言能力
考虑到许多业务场景会涉及到多语言的文档处理
而大多数模型都侧重于英语
所以多语言能力的薄弱
一直是妨碍大模型进一步拓展用户群体的障碍
像昨天发布的Llama3.1
就针对了八种不同语言进行了文本指令优化
但是其中偏偏没有中文
有人吐槽
Llama 3.1的中文能力差到还不如去用通义千问
而这次Mistral Large 2在语言上下了苦功夫
在大量的多语言数据上进行了广泛的训练
在英语、中文、法语、德语、西班牙语、意大利语、葡萄牙语、荷兰语、俄语、日语、韩语、阿拉伯语和印地语方面
都表现的非常出色
Mistral Large 2在多语言理解（MMLU）的预训练版本上
达到了84.0%的准确率
这个成绩已经超过了340B参数的Nemotron
而且与GPT-4的85.1%和Llama 3.1的87.3%，
基本处于同一水平
明显优于Llama 3.1 70b，高了6.3%。
可以说是将模型性能/成本的帕累托最优边界
又向前推进了一步
在优化模型多语言能力的同时
Mistral AI 也在自己传统的优势赛道
代码模型上更进一步
Mistral的AI以代码模型著称
致力于帮助各种编码环境和项目的开发人员
过去几个Mistral的AI模型
就在80多种编程语言的多样化数据集上进行了训练
能够精通包括Python、Java、C、C++、JavaScript和Bash在内的绝大部分编程语言
基于这些开发经验
Mistral Large 2也进行了非常大比例的代码训练
性能远优于初代的Mistral Large
与GPT-4o、Claude 3 Opus和Llama 3 405B等先进模型的表现不相上下
Mistral Large 2还增强了函数调用功能
经过训练
Mistral Large 2能够熟练的执行并行和顺序的函数调用
准确率甚至超过了GPT-4o
这意味着
Mistral Large 2可以成为复杂商业应用的核心引擎
除此以外
Mistral AI 还投入了大量精力来增强模型的推理能力
试图解决幻觉这个一直以来干扰模型推理能力的大麻烦
如今
几乎每家公司都在寻找尽量减少模型产生“幻觉”的方法
Mistral也不例外
他们在一份发表的新闻稿中表示
Mistral Large 2 训练过程中的重点关注点之一
就是尽量减少模型的幻觉问题
同时在文章中解释到
Mistral AI减少模型幻觉的主要方式是进行微调
Mistral Large 2经过微调后
能够更敏锐地做出反应
意识到自己不知道的事情
而不是编造看似合理的事情
当Mistral Large 2 在找不到解决方案
或者没有足够的信息来提供一个自信的答案时
Mistral Large 2 会承认自己答不出来
这种对准确性的追求
体现在了数学基准测试中模型性能的提高上
根据GSM8K和MATH两个基准测试的数据来看
Mistral Large 2与顶级模型不相上下
除此之外，在对齐和指令功能方面
Mistral团队在Mistral Large 2上也投入了很多精力
在WildBench、ArenaHard和MT Bench测试中
Mistral Large 2 表现出了擅长遵循精确指令和处理长时间多轮对话的优势
在其他一些AI的基准测试中
生成冗长的文本往往会提高测试分数
但是在实际的业务应用中
文本的简洁性反而至关重要
因为文本越简洁
交互越快，成本越低
根据Mistral 自己的说法
Large 2 的响应比先前的 AI 模型更简洁
不会一直喋喋不休，废话连篇
这张图展示了不同模型在MT Bench基准测试中
问题的平均生成长度，可以看到
Mistral Large 2 的回答明显比其他的模型要短上一截
以上就是Mistral Large 2 性能方面的介绍了
想必不少朋友已经开始磨拳擦掌
跃跃欲试了
目前
Mistral 公司已经通过其 API 商业平台以及 Google Vertex AI、Amazon Bedrock、Azure AI Studio 以及 IBM WatsonX 等云平台
开放了 Mistral Large 2 模型访问
HuggingFace上也可以直接下载权重
除此之外
用户不仅可以通过官方API平台la Plateforme访问或者微调模型
也可以使用已经部署了Mistral Large 2的免费聊天机器人le chat
与此同时
Mistral AI 正在将 la Plateforme 上的产品
整合为两个通用模型
分别是Mistral Nemo 和 Mistral Large
以及两个专业模型
Codestral 和 Embed
随着他们逐步淘汰 la Plateforme 上的旧模型
其他模型
包括 Mistral 7B、Mixtral 8x7B 和 8x22B、Codestral Mamba、Mathstral
仍然可以使用 Mistral AI 的 SDK
mistral-inference 和 mistral-finetune 进行部署和微调
Mistral 方面指出
他们的产品将继续突破成本、效率、速度与性能的极限
同时为用户提供更多新的功能
包括高级函数调用与检索
从而帮助用户构建起更多高性能的 AI 应用程序
好了
以上就是对于Mistral Large 2的介绍了
两天之内
两家大模型明星公司纷纷推出高端大模型
还都是开源的，网友们不禁感叹
第一次开源模型的革命
感觉突然一下子就爆发了
当然了
Mistral Large 2虽然还不能算是完全的开源
但是比完全闭源还是要好很多了
难道真的如同扎克伯格在文章中预言的那样
开源模型压倒闭源模型的转折点就要来了吗？
现在压力显然给到了OpenAI
再挤牙膏似的发布产品
可能就要说不过去了
那这次Meta和Mistral两家AI公司
会不会带动其他公司发布更多的开源模型呢
我们也会保持持续的关注
第一时间为大家介绍
感谢大家的观看，我们下期再见
