大家好，这里是最佳拍档，我是大飞
今天这个视频会分成两部分
大家可以在章节列表中选择自己想看的部分
我们先说一则新闻
就在Llama 2发布的2天后
7月21日
白宫主导并且召集了七家行业领先的人工智能公司
分别是亚马逊、Anthropic、谷歌、
Inflection、Meta、微软和 OpenAI
一起商讨如何实现「人工智能技术安全、可靠和透明的发展」
会后这些公司均已与白宫达成一致
并发表了自愿承诺书
这些公司做出的承诺
强调了人工智能未来发展的三个原则：
安全、保障、信任
也标志着在开发负责任的人工智能上
人类迈出了关键的一步
承诺书的内容大体上都是比较框架性质的
更像是过去半年
美国监管层对AI公司数次问询的
一次间接性的「成果展示」，
并不具备太多执行层面的意义
大家有兴趣可以去白宫网站上看下原文
我们这里仅总结一下关键内容
另外要注意的是，承诺书里的条款
并不是每一项所有公司都同意的
很多条款都只有个别公司承诺
所以也可以看出
大公司之间依然有很多的考虑和权衡
但无论如何，迈出这一步总是好的
承诺书的内容大概包括，1
第一点
产品公开前公司要确保它的安全性
首先是在发布人工智能系统前
要对人工智能的内部、外部进行安全测试
其次是与行业、政府、民间社会和学界
共享管理人工智能风险的信息
这一项倒是所有公司都通过了
2
搭建「安全第一」的人工智能系统
公司要投资网络安全和内部威胁防护措施
保护专有与未发布模型的权重
仅在考虑安全风险时，公开权重
同时建立强大的报告机制
鼓励第三方对人工智能系统中的漏洞即时反馈
迅速发现并解决问题
3
赢得公众的信任
其中就提到了要开发强大的技术机制
确保用户能够识别人工智能生成的内容
比如说水印系统
还要公开人工智能系统的功能、局限性以及适用范围
警示人工智能的安全风险和社会风险等
优先研究人工智能系统带来的社会风险
例如避免有害的偏见、歧视以及保护隐私
推出专门的人工智能来减轻这些危险
开发和部署前沿人工智能系统
解决如从癌症预防到缓解气候变化等社会问题和挑战
以上就是承诺书的一些核心内容
OpenAI在21日当天
也在网站上发布了自愿承诺书
内容与白宫中的声明基本一致
但是具体阐述更加细致
并且特意指出了承诺书中提到的特定模型
仅适用于总体上比当前行业前沿更强大的生成模型
那怎么理解这句话呢
其实就是指的GPT-4、Claude 2、PaLM 2、Titan
以及图像生成DALL-E 2等模型
我们暂且算作第一梯队的闭源模型吧
开源的都不在考虑之中
在整个承诺书里
我觉得最有实际意义的
就是承诺给人工智能生成的内容加水印这件事了
正好我们昨天做的一期视频
在聊到AI检测器的时候也涉及这个话题
今天就简单的来讲一讲
如何给AI生成的内容加水印
这个绝不是现在我们理解的
给图片上加个字那么简单
如果是那样的
也会很容易的被现在的AI给消除掉
这个水印是指token层面上的水印
前段时间
来自马里兰大学的研究人员
提出了一种高效的水印技术
可以让合成文本在很短的token跨度内被检测到
仅需25个token，同时误报率
就是将人类文本误判为机器生成的概率极低
添加的水印对人类来说是不可察觉的
但是可以通过算法识别为合成文本
在引言部分
作者为水印技术提出了若干项要求
分别是1
水印检测不需要通过调用大语言模型的API
或者知道模型参数就可以实现
2
模型不需要额外的训练
3
即便只有很小的一段生成文本
水印也可以检测到
4
除非大幅修改生成文本
水印无法被移除
5
针对水印检测
可以计算出一个严格的统计量
前两个要求是为了保证这个水印框架
在实际应用中的低成本
而后面三项是为了保证了添加水印的高可用性
事实上
Stanford四月发布的13B参数的vicuna模型
就应用了这个框架的水印技术
如果用一句话概括这篇论文
那就是将词表随机切分成红色token集合和绿色token集合
在模型输出时，针对logit向量
为绿色token集合添加权重
使得模型大大倾向于输出绿色token
在检测阶段
结合文本中的红色token集合以及绿色token集合进行统计
并计算统计量来确定是否包含水印
这里首先存在一个难题
就是如何往低熵序列中嵌入水印
首先，什么是低熵序列呢？
作者举了两个例子
假定红色部分是已经给出的提示语
那么这两个序列是机器生成的呢？
还是人类生成的？
显然要回答这个问题并不容易
尤其是第二个C语言循环代码的例子
这两个例子有一个共性
那就是信息熵过低
提示语极大程度上决定了接下来的序列内容是什么
低熵文本会导致两个问题，第一个
如果机器和人类都提供了相似但不相同的文本
那么分别二者相当困难
第二个
在这种文本插入水印也很困难
因为任何改动都可能导致高困惑度
以及非预期token的出现
接下来
我们就讲讲作者提供的水印方法的思路
第一种是Hard Watermarking，硬水印
这是一种简单嵌入的算法思路
首先根据生成序列预测下一个词的概率向量
然后根据生成序列最后一个单词确定随机种子
再根据随机种子确定绿色集合和红色集合的切分
最后只从绿色集合中挑选token
忽略红色集合中的token
这样的做法的好处是简单
但是严重影响了生成文本的质量
比如一些低熵的情形
例如Barack这个词的后面
在绝大部分情况下的预测是Obama
但是如果此时Obama在红色集合中
模型就会强行选用绿色集合中的另一个词
这显然不行
为了解决这个问题
作者提出了更有效的平替
一种更复杂的软水印算法
这种方法会根据每次模型输出的logits向量
对属于绿色集合的token增加常数delta
这样相当于提高了绿色集合tokens的logits权重
从而整体增大了绿色token的预测概率
这种方法相比于硬水印方法
更加有灵活度
不会显著降低输出文本的质量
同时保证低熵情形下
模型的正确输出
还以Obama为例
即使Obama是红色token
输出单词Barack之后
仍然会在下一个输出它
那么检测阶段如何计算统计量z呢？
对于任意给定的gamma
也就是绿色token集合
根据高斯分布，存在这样的等式
其中|s|G是绿色集合的单词数
T是全部单词数
gammaT可以理解为高斯分布的期望
而T gamma 1减gamma为方差
检测阶段的标准是当z>4时
就判定文本为机器生成
此时假阳率为3乘以10的负5次方
对于硬水印来说
当T大于16时就可以判定是否存在水印
而对于软水印来说
则需要考虑文本的熵
低熵的文本需要更大的长度
才可以判断是否存在水印
作者在第四部分细致研究了关于检测阶段灵敏度的问题
讨论了在熵值环境不同的情况下
绿色token集合的分布
包含了不少数学方面的讨论
我们直接跳过看实验部分
作者从C4新闻数据集中随机选取了若干文本
对于每段文本
作者将它从尾部切分成多个定长序列
作为baseline
剩下的部分则作为prompt
作者从数据集中进行多项采样
其实就是随机采样
直到获得至少500条长度为200正负5的token生成序列
生成时使用greedy策略或者beam search策略
通过实验，作者发现不同超参组合下
水印强度和文本质量之间是负相关的
二者的优化构成了一个帕累托最优问题
有趣的是，当绿色集合较小
等于0.1的时候
整体达到了帕累托最优
此外
作者还认为Beam Search和水印方法有强烈的协同作用
特别是当8-way Beam Search的时候
水印强度对文本质量几乎没有影响
同时，在不同超参组合下
水印强度也会随着token的数量上升
即样本基数越大，水印越显著
整个实验部分，作者做的非常详细
从ROC图上也可以看出
Beam Search比Greedy效果要好一些
大家有时间可以自己去看一下
最后
作者还介绍了一下几种消除水印
或者称攻击水印的方式
可能存在三种类型的攻击，第一类
文本插入攻击
在生成后添加可能位于红色集合中的额外token
并且可能会改变下游token中红色集合的计算
第二类，文本删除
从生成的文本中删除token
可能会删除绿色集合中的token
并且修改下游的红色token集合
这种攻击增加了生成token的成本
因为攻击者“浪费”了token
并且由于减少了语言模型的上下文长度
可能会降低文本的质量
第三种，文本替换
将一种token与另一种token交换
比方说
可能会换成一个红色集合中的token
这种攻击可以通过字典或者语言模型替换来实现自动化
但是可能会降低生成文本的质量
作者又进一步把攻击类型进行了分类
包括Paraphrasing Attacks
改写攻击
比如人为地替换机器文本中的用词
或者利用语言模型也是一种思路
但是必须要注意
这个时候攻击者必须使用一个较弱的语言模型来更改文本
但是这会降低水印的强度和语言文本的质量
因为如果攻击者有同等能力的语言模型
就可以不用水印算法来生成目标文本了
还有Discreet Alternations
精心替换攻击
攻击者可以通过一些细小但是精心的改变
比如在文本中插入多余的空格
或者错误拼写一些词
从而改变哈希值
不过对于一个比较成熟的水印检测器
应该能够先正则化文本
使它能够忽略这样多余的空格
因此这种层面上的攻击不是一个大问题
第三种就是Tokenization Attacks
令牌攻击，攻击者可以通过修改文本
使得下一个单词的底层token发生改变
比如将 “life.\nVerrilius” 修改为
“life.Verrilius”，去除了中间的换行符
这样就将原先的BPE分词结果
从V_err_ili_us变为Ver_r_ili_us
这就会导致更多的红色token
从而降低水印的强度
以上就是水印算法的核心内容
最后再概括一下
这个水印算法具备这样几个特性
1
水印可以在没有任何模型参数知识
或者访问语言模型API的情况下
通过算法进行检测
这个特性使得检测算法可以开源
即使模型不是开源的
这也使得检测变得廉价快速
因为它不需要加载或者运行大语言模型
2
可以使用标准语言模型
生成带有水印的文本
而不需要重新训练
3
水印可以从生成文本的连续部分中检测出来
这样即使只使用生成的一部分
来创建一个更大的文档
水印仍然是可以检测的
4
如果不修改相当比例的生成token
就无法去除水印
5
可以用严格的统计方法
来衡量水印是否被检测到
不过，马里兰大学提出的这个方法
仍然有一些问题尚未解决
比如对于图片和视频流媒体如何添加水印
或者当短跨度的水印文本
位于较长的非水印文本中时
测试水印的最佳方法是什么？
不过研究人员认为
他们实验的结果至少证实了
水印是可以成为对抗恶意使用生成模型的一种实用工具
应该说
对于大模型生成内容的水印算法
还有很多新的方法亟待探索
由于我能力有限
如果有任何错误或者缺漏
欢迎大家指出
也欢迎大家提出更好的一些研究意见
在评论区讨论
今天的视频内容就到这里
感谢大家的观看
我们下期再见
