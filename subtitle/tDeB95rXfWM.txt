大家好，这里是最佳拍档，我是大飞
千呼万唤始出来
大家期待已久的 Llama 3.1 官方正式发布了！
作为Llama 3系列中的顶配
最大的版本拥有4050亿个参数
使用了 16000 块 Nvidia H100 GPU 进行训练
是迄今为止最大的开源模型之一
突然
发生了拉玛3.1405B评测数据的泄露事件
有网友预计可能还会同时发布一个Llama 3.1-70B版本
因为“模型提前泄露”是META的老传统了
去年的Llama模型就干过一次
小扎也确实不负众望
一口气放出了8B、70B和405B三个版本
大上下文提升到了128k
一举成为近年最大的开源大模型
话不多说
今天大飞就来给大家讲讲llama 3.1的具体性能
Llama3.1最大的亮点
就是身为开源模型
却是个浑身肌肉的六边形战士
性能直追闭源模型的巅峰
GPT4o和Claude 3.5 sonnet
开源与闭源的争论一直是技术领域的热点话题
此前
一直是闭源模型在性能上略胜一筹
直到这次Llama 3.1的发布
开源模型终于可以与闭源模型巅峰一战了
Meta 在 150 多个涵盖多种语言的基准数据集上评估了新模型的性能
并且在真实场景中将 Llama 3.1 与竞争模型进行了比较
最受关注的405B版本
在性能上已经可与GPT-4o和Claude 3.5 sonnet相媲美
其中Human Evaluation主要用于评估模型在理解和生成代码、解决抽象逻辑问题方面的能力
图中可以看到
Llama3.1在20%的情景中超越了GPT4o以及Claude 3.5 sonnet
在50%以上的情况下持平
可以说是不分伯仲
而在基准数据集的测试中
Llama 3.1 405B虽然没有实现“遥遥领先”，
但是在给出的14个评测数据集中
Llama 3.1 405B在七个维度表现第一
Claude 3.5 Sonnet在六个维度取得第一
GPT-4与GPT-4o mini在四个维度取得第一
Llama 3.1 405B 在NIH/Multi-needle 基准测试的得分为 98.1
在性能评分上与GPT-4和Claude 3.5等不相上下
405B版本还以出色的整合海量文本信息能力
在ZeroSCROLLS/QuALITY基准测试得到了95.2分
对于关注RAG性能的AI应用开发者而言
十分友好
与此同时
8B 和 70B 模型在基准测试中也取得了显著进步
8B 模型在 MMLU 测试中从 65 分提升到 73 分
提高了8 分
70B 模型从 81 分提升到 86 分
提高了5 分
在 MATH 测试中
8B 模型的得分从 29 分
大幅提升到 52 分，提高了23 分
具体来说
在基准预训练模型的基准评测中
Llama 3.1 405B 在通用任务、知识推理、阅读理解上创下最新纪录
尤其是在MMLU、SQuAD 的细分基准上
提升最为明显
此外，在指令微调模型中
看得出 Llama 3.1 405B 比预训练模型更强
Llama 3.1 8B 和 70B 微调模型
同样在推理、代码、数学、工具使用、多语言等多项能力任务中
性能大幅提升
彪悍的性能自然会带来功能的多样化
这次发布的新模型
不仅能够编写代码、回答基础数学问题
还能用八种语言总结文件
分别是英语、德语、法语、意大利语、葡萄牙语、印地语、西班牙语和泰语
这时候
128K的上下文容量就可以发挥优势了
llama3.1 能够处理长达 50 页的文本
这种更大的上下文能力
使得模型在总结长文本和运行聊天机器人的时候
更加出色
现在，Meta旗下的多个终端
比如WhatsApp和Meta AI聊天机器人中
都开始使用Llama 3.1 405B
在数学和编程方面
用户可以通过分步解释和反馈
来获得数学作业方面的帮助
并且通过调试支持和优化建议
更快地编写代码，甚至通过专家指导
来掌握复杂的技术和科学概念
值得一提的是
Meta AI也将适用于Meta的智能眼镜
并将于下个月在美国和加拿大的Meta Quest上
以实验模式推出
Meta AI将取代Quest上当前的语音命令
让用户可以免提控制耳机、获取问题的答案、了解实时信息、查看天气等等
用户还可以将Meta AI与在头显中看到的视图结合使用
比如询问与在物理环境中所见事物的相关情况
除了这些已经公开的功能
Meta这次还画了个多模态的饼
他们在文章中表示
会使用组合方法将图像、视频和语音的功能集成到Llama 3.1中
让模型能够识别图像和视频
并且支持通过语音进行交互
不过这个功能正在开发中
还没有准备好发布
性能和功能都追赶上闭源模型了
Llama 3.1的训练数据自然也是没少吃
根据Meta在正式发布里附上的论文
Llama 3.1 在超过 15 万亿个 token的数据上进行训练
不过，给AI喂数据可不是填鸭
把资料咕咚咕咚往AI里灌就行了
作为 Meta 迄今为止最大的模型
如何使用超过 15 万亿个 token 训练 Llama 3.1 405B
是一项重大的挑战
为了能够在训练的同时
在合理时间内实现研究人员想要的效果
Meta优化了整个训练堆栈
使用了超过16000块H100
405B也是第一个在如此规模上训练的Llama模型
为了最大限度地确保训练的稳定性和便捷性
Meta选择了标准的仅解码器Transformer模型架构进行微调
而没有采用当前流行的混合专家模型（MoE）架构
这个决策使得Llama 3.1在支持128K上下文长度的同时
依然能够保证短文本的高质量输出
实现了对长短文本的灵活处理
而非仅仅专注于长文本
同时
研究团队实施了一种迭代的后训练方法
通过每一轮的监督式微调和直接偏好优化
生成高质量的合成数据来提升模型的各项功能
与之前的版本相比
Llama 3.1还增加了预训练和后训练数据的数量和质量
引入了更细致的预处理和管理流程
以及更严格的质量保证和过滤技术
为了应对405B模型的大规模运行需求
Meta把模型数据从16位（BF16）量化减少到8位（FP8）
大幅降低了计算资源的需求
让模型能够在单一服务器节点上运行
在Llama 3.1 405B模型的指令和聊天微调方面
开发团队致力于提升模型对用户指令的响应性、实用性和质量
同时确保高度的安全性
在后训练阶段
团队在预训练的基础上进行了几轮调整
每轮包括监督式微调（SFT）、拒绝采样（RS）和直接偏好优化（DPO）
此外，团队孩使用合成数据生成
来产生绝大多数的 SFT 示例
这表示他们并没有全部依赖真实世界的数据
而是通过算法生成的数据来训练模型
同时
团队还使用了多种数据处理方法来过滤这些数据
确保质量最高
并且扩大了微调数据的应用范围
除了以上这些改进以外
Meta也在探索一种新的策略
就是使用405B模型作为70B和8B模型的“教师模型”，
从大型模型中提炼出适合各行各业需求的小型定制模型
这种做法与GPT-4o mini的策略不谋而合
即“先做大
再做小”。
前OpenAI创始成员之一Andrej Karpathy曾对GPT-4o Mini做出评价
模型必须先变大
然后才能变小
因为我们需要它们自动帮助重构训练数据
使其成为理想的、合成的格式
他指出
这种方法能够有效地将大模型的深度和广度知识
迁移到更实用、成本更低的小型模型上
作为开源模型路线的领头羊
Meta在Llama模型的配套设施上也给足了诚意
Llama系统被设计为一个综合的框架
能够整合多个组件
包括调用外部工具
Meta的目标是提供一个更广阔的系统
让开发者能够灵活地设计并且创建符合自己需求的定制产品
为了在模型层之外负责任地发展AI
研究团队还发布了一个包含多个示例应用和新组件的完整参考系统
例如多语言安全模型Llama Guard 3和提示注入过滤器Prompt Guard
Llama Guard 3 是 Llama Guard 系列的最新版本
在 Llama 3.1 8B 上进行了微调
它专门为生产数据而构建
具有 128k 上下文长度和多语言功能
Llama Guard 3 可以对大语言模型的输入和响应进行分类
从而检测风险分类中被视为不安全的内容
而不安全级别总共有13种
包括暴力犯罪、诽谤等等
Prompt Guard 是一个基于 BERT 的小型 279M 参数分类器
可以检测提示词注入和越狱
它接受了大型攻击语料库的训练
建议使用与应用程序相关的数据进一步微调
这个模型可以分析出提示词是注入、越狱
还是正常的提示词
为了更好地定义组件接口
并且促进行业中的标准化
研究人员还与行业、初创公司和广泛社区合作
并在GitHub上发布了“Llama Stack”提议
这是一套标准化的接口
能够简化工具链组件
比如微调、合成数据生成
以及Agent应用程序的构建
强大的性能，多样的功能
庞大的参数规模，在如此多的优点下
llama3.1的开发成本也是水涨船高
开发者们也在犯嘀咕
付出了巨大训练成本的大公司们
还会继续开源吗？
毕竟，OpenAI就是前车之鉴
早期曾秉持开源精神
但是自从GPT3.5爆火后就开始商业化
再无开源，被群嘲为Closed AI
但是在Llama 3.1发布的当下
扎克伯格再次强调
要把开源进行到底！
除了发布模型
小扎还发表了一篇语重心长
富有理想主义的开源宣言《开源AI是前进之路（Open Source AI Is the Path Forward）》，
阐释了Meta为什么要开源、为什么开源对开发者有利等等观点
一开始，扎克伯格就提到
开源模型与闭源模型之间的差距正在逐渐缩小
去年
Llama 2还只与上一代最先进的闭源模型相当
今年
Llama 3可以与最先进的模型媲美
并在一些能力上处于领先地位
从明年开始
他预计Llama模型将成为业内最先进的模型
更何况
如今Llama系列模型已经在开放性、可修改性和成本效益方面
处于行业的领先地位
在小扎发布这篇文章的同时
三个模型已经在Meta的官网公开
各位网友可以下载尝鲜了
同时，Meta更新了许可证
允许开发人员使用包括405B在内的Llama模型的输出
来改进其他模型
同时
Meta的开源生态也进一步得到扩张
已经有超过25个企业推出了基于Llama 3.1的新模型
其中
亚马逊云科技、Databricks和英伟达正在推出全套服务
来支持开发人员微调和训练自己的模型
AI芯片初创企业Groq
也为Meta这次发布的所有新模型
构建了低延迟、低成本的推理服务
同时这些模型也将在亚马逊云科技、微软Azure、谷歌云、Oracle等主要云平台上提供服务
Scale AI、戴尔、德勤等公司
已经准备好帮助企业采用Llama新模型
并且使用自己的数据来训练定制模型
好了
以上就是这次Llama3.1系列模型发布的相关内容
从这次发布可以看出
开源、闭源大模型之间的差距正在缩小
并且大有齐头并进、互相赶超之势
Meta再度落子
也使得开闭源模型之争的定论更加扑朔迷离
而且在实际应用中
很多企业和开发者会根据具体需求和实际情况
来选择使用开源或者闭源模型
因此模型的具体能力、适用的真实场景等等
还需要时间来证明
对于Llama 3.1和扎克伯格的开源愿景
大家有什么看法呢？
欢迎在评论区发表
感谢大家的观看，我们下期再见
