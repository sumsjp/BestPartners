大家好，这里是最佳拍档，我是大飞
我们都知道
上个月OpenAI发布GPT-4o仅一天后
Ilya Sutskever和Jan Leike两员大将相继离职
安全团队分崩离析
由此掀起的离职潮，内幕爆料风波
纷纷指向了CEO Sam Altman的领导本身
在近期上线的《TED AI秀》播客节目中
前OpenAI的董事会成员海伦·托纳Helen Toner
再次爆料了OpenAI的宫斗内幕
同时指责了Sam Altman在安全方面的领导能力
不过
这次访谈海伦并不是针对于Sam Altman
作为乔治城大学安全与新兴技术中心的战略总监
同时也是OpenAI主张安全大于商业利益的前董事之一
Helen Toner更多是将重点放在了向公众阐释
她自己对人工智能安全问题的见解
她最后建议
每个人都有权利对技术的未来发展
持有自己的见解
所以不要盲信大公司和专家
而是依靠自己的经验去探索
去形成自己的见解
今天大飞就来跟大家分享这次访谈的主要内容
首先
主持人比拉瓦尔·西杜Bilawal Sidhu回顾了一下OpenAI的宫斗过程
我们之前也做过很多期节目
大家有兴趣的可以去看一下
但是主持人说的几句话我觉得比较关键
那就是海伦在OpenAI董事会的工作职责
是确保利润不应该成为决策的唯一驱动力
在OpenAI解雇并且重新聘用Sam Altman不到两周后
海伦辞去了董事会职务
当时内部调查仍在进行中
所以她被建议保持沉默
并且因此遭受了很多的批评
在当时的新闻报道和推特中
主持人对海伦的最初印象
是一个阻碍了进步的技术悲观主义者
或者是一个利用安全政策作为武器的疯狂权力追求者
但是
当主持人后来在TED大会上遇到海伦之后
逐渐转变了对她的印象
同时开始思考治理与监管之间的区别
接下来就是海伦对OpenAI事件的回顾
首先，她强调
OpenAI的董事会是一个非营利性质的董事会
它明确了公司设立的目的
是为了确保公共利益使命列为首位
优先于利润、投资者利益以及其他事项
但是多年以来
Sam通过隐瞒信息、误导公司内部信息
甚至直接对董事会撒谎
让董事会很难真正履行这一职责
海伦透露了一些之前大家可能都不太知道的内幕
比方说
2022年11月ChatGPT发布的时候
董事会竟然都没有事先得到通知
还是从Twitter上得知ChatGPT的
这确实有些夸张
另外
Sam没有告知董事会他持有OpenAI的创业基金
同时向董事会提供了关于公司安全流程的不准确信息
后来Sam更是开始向其他董事会成员撒谎
试图将海伦排挤出董事会
在经历了多次类似事件之后
董事会的四个人最终做出了解雇他的决定
因为他们觉得不能再相信Sam说的话了
而真正的转折点主要发生在去年10月份
董事会与OpenAI的几名高管进行了一系列深入的交流
他们首次吐露了很多因为感到不安、而一直埋在心里的话
除了他们对Sam的不信任以外
还特别提到了Sam所营造出来的压抑的工作环境
高管们用“心理虐待”这个词来形容
并且明确表示不认为Sam是引领公司迈向AGI的合适领导者
甚至他们还提供了Sam撒谎和操控行为的截图等证据
这件事导致董事会在几周的时间里
进行了非常密集的讨论
最终得出结论
那就是为了OpenAI的使命和组织本身
最好的做法是引入一位不同的CEO
董事会非常清楚一旦Sam听到风吹草动
就会利用一切手段来破坏董事会
所以他们很谨慎的进行计划
在11月17日采取行动之前
除了法务团队，几乎没有人提前知道
而对于之后大多数员工都支持Sam的回归
海伦给出了三点解释
首先
很早就有人向公司内部传达了一种观点
只有两种选择
要么Sam立即无条件复职
并且由他自己挑选全新的董事会
要么公司就会面临崩溃
因此许多人不愿见到公司瓦解
但是实际上董事会的方案并没有如此极端
其次，员工非常恐惧与Sam的对立
他们或多或少亲身经历
或者听说过Sam对批评者施加报复的行为
因此对于可能会招致的后果感到极度恐慌
所以
部分员工会生怕万一Sam真的恢复掌权
他们的处境会变得更加艰难
最后，Sam并不是第一次被解雇
在他创办Loopt和YC的过程中
都曾经有管理层提议解雇他
原因是他存在欺骗和制造混乱的行为
好了
以上就是海伦对OpenAI宫斗的回顾
大飞我并不认为这些信息一定都是真实的
但是有助于我们从其他角度来看待所发生的事情
当然
这个也并不是我们今天视频的重点
因为之后海伦还谈到了很多她对于人工智能监管的看法
首先
对于目前的人工智能是否需要监管的问题
海伦认为，随着AI不断变得更加复杂
可能会带来一系列潜在的危害
但是真正让监管者犯难的是
人工智能涵盖了许多不同的事物
其中很多其实并不需要监管，比方说
像Spotify通过AI来生成播放列表这种事
就不需要被监管
但是对于许多其他应用场景来说
至少应当设置一些基本的常识性界限
比方说，如今大公司已经将AI技术
融入了公共及私人区域已有的监控摄像头
引起了人们对于隐私、正当程序以及技术潜在滥用的担忧
海伦表示
这种现象在技术发展历程中很常见
那就是社会中已有的事物
会因技术进步而变得更快速、成本更低廉、普及度更高
监控是否被滥用这个问题的关键
还在于找出执法需求和过度使用技术之间的平衡
而有些商业上的场景
比如在咖啡店里
用AI监控来识别顾客的停留时长
显然存在法律上的问题和风险
不过
美国目前还缺乏统一的联邦隐私立法
也就是说，关于企业如何处理数据
法律上几乎是一片空白
在美国
受到保护的个人数据类型以及保护方式很少
所以之前很多制定法律的尝试都失败了
但是人工智能政策或许让人们看到了一丝成功的曙光
接下来
基于视频的AI诈骗会更加盛行
海伦建议大家应该立刻向家人或者不了解科技的朋友强调
必须要警惕这种诈骗行为
尤其是对任何声音都要保持高度的怀疑
因为现在很多银行还在使用语音识别来跟客户联系
应该尽量放弃这种方式
而对于视频
一定要注意视频通话中看似真实的人物
最近香港就有人用AI变脸冒充CFO
骗走了2亿港元
显然
基于内容的验证方式已经走到尽头了
不过我们需要去思考
目前的安全基准究竟在哪里？
因为很多住址信息和公司电话
本身就是公开的，在保证安全的同时
还要考虑生活的便捷性
再者，由于人工智能涵盖了众多领域
所以不存在单一的通用规范
比如自动驾驶车辆需要交通部门制定法规
而银行业的AI应用
则需要由银行业的监管机构来制定规范
好在现在已经有很多现成的法律在起效了
海伦认为
其实我们当前在人工智能领域面临的许多挑战
很大程度上来源于对技术能力、以及未来五年内发展程度的不确定性
专家们也对这些问题的看法分歧极大
这给政策制定带来了巨大的难度
因此，良好的政策倾向
有助于我们更加清晰地认识到技术所处的状态
比如，去年十月的一项行政命令
包含了很多内容
其中一点是要求训练特别先进的AI系统的公司
必须向政府提交有关这些系统的特定信息
这种机制既不限制模型的构建或者训练
也不要求政府审批
而是通过增强信息共享的透明度来提高应对能力
所以对于政府而言
如何跟进快速变化的技术是个巨大挑战
另一个挑战挑战在于如何判断人工智能的现状
因为我们很难确切地衡量或者比较两个AI系统
并且判断哪个系统更“聪明”，
原因有三点
第一点、人工智能的覆盖范围广泛
横跨多个行业
有许多不同的应用场景
很难全面的了解它是什么、它能做什么
以及它将产生什么影响
第二点、人工智能还处于持续的演进之中
技术能力与两年前、五年前乃至十年前相比
已经大相径庭
而政策制定者并不擅长进行快速的政策调整
没法做到像软件开发者那样敏捷
第三点、没有人能够就它们是如何变化的
或者未来将如何变化
达成一致意见
如果你询问五位专家对AI未来趋势的看法
往往会得到五种截然不同、而且常常是极其笃定、但是又相互矛盾的答案
这样就给政策制定者带来了巨大困扰
因为他们需要依赖科学共识来指导决策
但是现实中的多样性观点却难以提供明确的指引
正如Geoffery Hinton和Yann Lecun
同样作为人工智能的两大教父
却有着完全相反的观点
甚至前几天Yann Lecun还和马斯克一阵互怼
因此，这三点原因导致政策的制定者
难以确定应该听取哪一方的意见、关注哪些问题
以及这些问题又将如何随着时间变化
于是也成为了人工智能政策制定中最为棘手的难题
而对于AI行业中的那些大公司
政策制定者其实缺乏对他们深入了解的专业和时间
一个典型的参议员助手可能同时要处理技术、贸易、退伍军人事务、农业和教育等多个议题
因此大公司介入到AI治理工作
并发挥作用是一件很自然的事
同时，海伦也认为
如果政策制定者不了解技术运作的原理
而且没有与受监管的企业沟通未来的走向
他们也很容易做出错误的决策
所以
难点就在于如何在听取这些企业意见的同时
平衡来自外界的声音
因为这些声音会指出大公司实际上是自私自利的
这就需要公民社会要参与到这些对话中来
海伦是这么来形容的
大公司显然需要在AI治理中有一席之地
但是他们最好只拥有一席之地
而不是占据了100个座位中的99个
在执行方面
海伦认为没有必要搞太极端的政策
比如全面放开或者全面监管
其实在这其中存在很多中间的路径
比如Hugging Face就曾经将被认为是冒犯性或者危险的模型下架
像Meta、Instagram等公司也具备一定的机制来识别、抑制并报告儿童色情、政治误导信息等内容
在图像和音频生成领域
业界也在围绕内容来源认证
或者内容真实性验证
逐步在进行一些倡议
所以
海伦认为AI还是一个发展迅速、充满创新的领域
虽然最终可能无法实现完美的解决方案
但是通过这些技术与政策手段
能够显著提升个人和平台的辨别能力
同时，社会的逐步适应也非常关键
通过技术与政策的创新结合
才能够有效地应对挑战
接下来，在主持人的引导下
海伦畅想了一下AI世界的未来
如果未来是反乌托邦的
那么可能与现在的世界没有太大的不同
人们会直接受到算法系统和AI的严重影响
比如老人因为算法而失去了医疗保险
甚至是把AI用于战争
但是最令海伦担心
也是她直觉上认为未来最可能发生的一种走向
就是《机器人总动员》式的未来
注意，她想说的
并不是电影里那个变成垃圾堆的地球
而是电影中的人们
他们整天坐在柔软的轮椅上四处滚动
有各种内容、食物和其他东西让他们感到快乐
海伦的担忧在于，现实中的人们
往往倾向于追求即时的欲望与选择
而不是真正能够滋养心灵、构建意义深远生活的事物
在商业驱动下
我们很容易创造出只满足人们表面需求的产品
却无形中构筑了一个空洞、浅薄和缺乏内涵的世界
而且在这个世界中
大部分重要的决策
都由那些对什么是有意义的生活毫无概念的机器做出
所以在海伦的设想中
未来并不是会发生那种戏剧性的大事件
而是我们逐渐将越来越多的控制权
交给越来越复杂的计算机
而它们对于意义、美、喜悦、成就或者繁荣等等概念毫无理解
更可怕的是
我们无法将这些概念编程到机器中
因为我们自己也难以确切地把握这些概念
而如果未来是乌托邦式的
那么一个基本的出发点
就是我们能否解决世界上的一些重大问题
比如气候的变化，能源的短缺
以及农业和粮食供应问题
除此之外，应该让我们的子孙后代们
自己来决定未来应该是什么样子
而不是按照先人的遗愿前进
最后
对于网上一些关于要警惕AIGC内容的观点
海伦认为
不必对技术本身或者是技术专家感到畏惧
因为这是一项连业界顶尖专家
都还没有完全掌握工作原理的技术
我们能做的就是保持自己的好奇心
并且每个人都有权利对技术的未来发展
持有自己的见解
因为无论是监管者还是企业的CEO
都无法全面预见AI将如何影响全球亿万民众的方方面面
所以，海伦建议
我们每个人都应该依靠自己的经验去探索
去形成自己的见解，这才是最重要的
好了
以上就是海伦·托纳这次访谈的主要内容
可以看出她在AI安全方面有着很多的思考
对于海伦最后给出的建议
我想这可能也是我们这个频道存在的一个意义
就是让大家更多的去了解AI的方方面面
以更多的视角来看待这次科技浪潮的发展
从而找到自己在时代中的位置
感谢观看本期视频，我们下期再见
