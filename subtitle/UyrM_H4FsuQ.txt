大家好，这里是最佳拍档，我是大飞
不得不说，英伟达最近是真的猛啊
不光是股价，在AI创新方面
它也不断想要证明自己的领导地位
6月14号
英伟达宣布发布Nemotron-4 340B通用模型
专为生成训练大语言模型的合成数据而设计
有可能彻底改变训练大模型时、合成数据的生成方式
这个突破性的进展
可能标志着AI行业的一个重要里程碑
那就是现在无需昂贵的真实世界数据
用合成数据就可以创建出性能强大的、特定领域大模型了
而且
Nemotron-4 340B的性能已经超越Mixtral 8x22B、Claude sonnet、Llama3 70B和Qwen 2
甚至可以和GPT-4一较高下
今天我们就来聊聊这个模型
具体来说
Nemotron-4 340B包括了基础模型Base、指令模型Instruct和奖励模型Reward
并且构建了一个生成高质量合成数据的完整流程
模型除了支持4K上下文窗口、50多种自然语言和40多种编程语言以外
还采用了高达9万亿个token训练
训练数据截止到2023年6月
必须要提的是
指令模型的训练是在98%的合成数据上完成的
结果显示
Nemotron-4-340B-Base在常识推理任务
比如ARC-Challenge、MMLU和BigBench Hard基准测试中
可以和Llama-3 70B、Mixtral 8x22B和Qwen-2 72B模型相媲美
而Nemotron-4-340B-Instruct
在指令跟随和聊天能力方面
也超越了相应的指令模型
Nemotron-4-340B-Reward在发布时
在RewardBench上实现了最高的准确性
甚至超过了GPT-4o-0513和Gemini 1.5 Pro-0514这样的专有模型
说明它生成的合成训练数据质量非常高
推理方面，在BF16的精度下
模型的推理需要8块H200
或者16块H100/A100 80GB
但是在FP8精度下，则只需要8块H100
除此之外
Nemotron-4 340B的许可还对商业使用十分友好
并且还可以与英伟达开源的NeMo和TensorRT-LLM框架结合使用
接下来
我们就来详细说明一下模型的独到之处
首先，也是最重要的一点
Nemotron-4 340B指令模型
可以帮助开发者生成合成训练数据
这些多样化的合成数据
模仿了真实世界的数据特征
也因为数据质量的明显提升
提升了各个领域定制大语言模型的性能和稳定性
而且
为了进一步提高AI生成数据的质量
开发者还可以用Nemotron-4 340B 奖励模型
来筛选高质量的响应
它会根据有用性、正确性、一致性、复杂性和冗长性这5个属性
对响应进行评分
另外
研究者可以使用自己的专用数据
再结合HelpSteer2数据集
定制Nemotron-4 340B的基础模型
从而创建出自己的指令或者奖励模型
其次，在预训练方面
模型的预训练数据是基于三种不同类型的混合数据
共有9T的token
其中前8T用于正式预训练阶段
最后1T用于继续训练提高质量
数据中英语自然语言占了70%，
由不同来源和领域的精选文档组成
包括网页文档、新闻文章、科学论文、书籍等等
多语种自然语言占了15%，
包含53种自然语言
由单语语料库和平行语料库中的文档构成
代码占15%，包含43种编程语言
与Nemotron-4-15B-Base类似
Nemotron-4-340B-Base也是基于仅解码器的Transformer架构
具体来说
模型使用了因果注意力掩码
来确保序列的一致性
并采用旋转位置嵌入（RoPE）、SentencePiece分词器、分组查询注意力（GQA）
以及在MLP层中使用平方ReLU激活
此外，模型没有偏置项，丢弃率为零
输入输出嵌入不绑定
有94亿个嵌入参数和3316亿个非嵌入参数
第三
Nemotron-4-340B-Base使用了768个DGX H100节点进行训练
每个节点包含8个基于NVIDIA Hopper架构的H100 80GB SXM5 GPU
每个H100 GPU在进行16位浮点运算时
峰值吞吐量为989 teraFLOP/s
英伟达采用了8路张量并行、12路交错流水线并行
以及数据并行相结合的方法
同时使用了分布式优化器
可以将优化器状态分片到数据并行副本上
从而减少训练的内存占用
第四，在推理方面
利用开源的NVIDIA NeMo和NVIDIA TensorRT-LLM
开发者可以优化指令模型和奖励模型的效率
从而生成合成数据
并对响应进行评分
所有Nemotron-4 340B模型都利用了张量并行
经过TensorRT-LLM优化
可以将单个权重矩阵分割到多个GPU和服务器上
从而实现大规模的高效推理
其中
基础模型可以使用NeMo框架进行多种定制
包括监督微调和参数高效微调
比如说低秩适应（LoRA）
为了提高模型的质量
开发者还可以使用NeMo Aligner和由Nemotron-4 340B Reward模型所标注的数据集
来对齐模型
第五，为了开发一个强大的奖励模型
英伟达收集了一个包含10k人类偏好数据的数据集
HelpSteer2
与成对排名模型不同
多属性回归奖励模型在区分真实有用性和无关伪影方面更加有效
此外
回归模型在预测细粒度的奖励、捕捉相似回复之间有用性的细微差别方面
表现更好
因此在Nemotron-4-340B-Base模型中
回归奖励模型通过用一个新的奖励头
替换掉了模型的最终softmax层
这个头其实是一个线性投影
将最后一层的隐藏状态映射到一个包含HelpSteer属性的五维向量
分别表示有用性、正确性、一致性、复杂性和冗长性
在推理过程中
这些属性值可以通过加权求和
聚合为一个总体的奖励
第六，在整个对齐过程中
英伟达仅仅使用了大约20K的人工标注数据
而数据生成pipeline
则生成了用于监督微调和偏好微调的98%以上的数据
要生成合成数据
第一步就是要生成合成提示
这些提示在不同维度上的多样性至关重要
包括任务的多样性
比如写作、开放问答、封闭问答
主题的多样性
比如STEM、人文、日常生活
以及指令的多样性
比如JSON输出、段落数量、是否回答等等
对此
英伟达使用了Mixtral-8x7B-Instruct-v0.1作为生成器
分别对这些任务的合成提示进行了生成
为了收集多样化的主题
英伟达先是引导生成器
输出一组多样化的宏观主题
然后再为每个合成的宏观主题
生成相关的子主题
再加上人工收集的
最终得到的主题达到了3千个
接下来，为了提升指令跟随能力
需要生成合成的指令跟随提示
研究团队先是随机选择了一些合成提示
对于每个合成提示
从可验证的指令模板中随机生成一个合成指令
然后使用手动定义的模板
将提示和指令连接在一起
除了单轮指令跟随提示以外
英伟达还构建了多轮指令跟随提示
这些指令适用于所有未来的对话
此外
英伟达还构建了第二轮的指令跟随提示
可以根据给定的指令来修改之前的回答
为了在偏好微调中提高模型的多轮对话能力
英伟达构建了两轮提示来建立偏好数据集
具体来说就是
提示包含一个用户问题
一个助手回答，以及另一个用户问题
英伟达从ShareGPT中获取第一个用户提示
并使用中间指令模型
来生成助手回答和下一轮的问题
通过监督微调，模型就可以学习到
如何以对话的形式与用户互动
为了培养多轮对话的能力
英伟达把每个对话设计成包含三轮
好让对话流程更加动态和具有互动性
通过迭代角色扮演
模型会交替地模拟助手和用户的角色
在过程中英伟达发现
为了在用户回合中引导所需的行为
就需要提供明确的提示
来定义不同的用户个性
并且附上对话历史
最后
英伟达会使用Nemotron4-340B-Reward来评估对话质量
为每个样本分配一个分数
并且过滤掉那些低于预定阈值的样本
这样就提供了额外的质量控制层
保证留下来的都是高质量的数据
第七，由于在数据的合成过程中
需要一个对齐的大语言模型
来准确的遵循指令
所以英伟达开发了一种从弱到强的迭代对齐方法
结合了对齐训练与数据合成的优势
让它们能够相互增强，持续改进
具体来说，首先
英伟达使用一个初始对齐模型
来生成对话和偏好数据
然后，通过监督微调和偏好调优
让它们对更好的基础模型进行对齐
有趣的是，英伟达发现
教师模型并不会限制学生模型的上限
随着基础模型和对齐数据的改进
新对齐的模型能够显著超过初始的对齐模型
要注意的是
对齐过程与基础模型的预训练是并行进行的
因此
这个迭代过程会形成一个自我强化的飞轮效应
基础模型越强，指令模型也越强；
数据质量越高，指令模型也越强
于是在整个对齐过程中
英伟达进行了多轮数据生成和改进
从而不断提升模型的质量
除了前面介绍的这些特点以外
英伟达还结合了CantTalkAboutThis训练集
帮助模型提升了主题连贯性和细粒度指令跟随
以及采用少样本方法
帮助模型更好地处理无法完成的任务
此外，英伟达还利用FinQA数据集
提高了模型的数值推理能力
并使用wikitablequestions数据集
增强了模型对半结构化数据的理解
以及利用Glaive AI的样本
来增强模型在函数调用方面的能力
显然，Nemotron-4 340B的发布
对各行各业都有着潜在的巨大影响
比方说在医疗领域
如果能生成高质量合成数据
可能会带来药物发现、个性化医疗和医学影像方面的突破
在金融领域
基于合成数据训练的定制大语言模型
则可能会彻底改变欺诈检测、风险评估和客户服务
在制造业和零售业方面
特定领域的大模型可以实现预测性维护、供应链优化和个性化客户体验
不过，Nemotron-4 340B的发布
也提出了一些隐忧
比如数据隐私和安全怎么来保证
用合成数据来训练AI模型
是否会引发伦理问题等等
但是无论如何，越来越多的迹象表明
使用合成数据才是AI的未来
好了
以上就是对英伟达新开源模型的简单介绍
有兴趣的朋友可以去阅读技术报告
内容非常详尽
也欢迎在评论区分享试用体验
感谢大家的观看，我们下期再见
