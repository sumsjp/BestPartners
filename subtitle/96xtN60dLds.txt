大家好，这里是最佳拍档，我是大飞
这两天
三个从哈佛退学的00后本科生
开发了一款超牛逼的AI芯片
准备掀翻老黄的新闻登顶了科技圈的热搜
又是藤校生辍学创业
又是要开拓技术新路线
甚至号称要做最适合Transformer的芯片
剑锋直指英伟达
别的先不说，至少在话题度上
整个科技圈都被这两个00后给拿捏了
当地时间6月25日
Etched宣布完成1.2 亿美元的 A 轮融资
由早期投资机构Primary Venture Partners 和 Positive Sum Ventures 共同领投
其中
重量级的天使投资人包括风险投资家彼得·蒂尔Peter Thiel、GitHub 首席执行官托马斯·多姆克 Thomas Dohmke、自动驾驶公司 Cruise 的联合创始人凯尔·沃格特 Kyle Vogt
以及Quora的联合创始人查理·契弗Charlie Cheever
有头有脸的人物多得屏幕都快放不下了
称得上大佬云集
含金量拉满
尽管目前公司没有透露新一轮融资后的估值
但是根据媒体报道
Etched的生意已经顺利开张了
已经有早期客户
向Etched AI预订了数千万美元的硬件订单
今天大飞就来给大家介绍一下Etched AI这家公司
Etched AI 位于加利福尼亚
是一家由3 名大学辍学生创立、目前仅 35 名员工的小公司
三位创始人克里斯
朱Chris Zhu
加文·乌贝蒂Gavin Uberti和罗伯特·瓦亨Robert Wachen
都是在2020年左右进入哈佛
他们在学校时疯狂兼职打工
后来休学创业
这些年，英伟达的AI芯片帝国
从来不乏挑战者
比如芯片初创公司Cerebras Systems的大体积单个芯片
以及 Tenstorrent公司的RISC-V技术芯片
现在
英伟达又多了一个更年轻、更雄心勃勃的对手Etched AI
以及他们的重量级产品
号称比英伟达H100快20倍的sohu芯片
Sohu，乍一听上去挺像搜狐的
但是两者没有半毛钱关系
「Sohu」是一种 ASIC芯片
全称是应用专用集成电路（Application-Specific Integrated Circuit）
相当于把某种特定的程序“硬件化”，
并且只为一种任务优化
去掉了其他不必要的功能
从而达到比通用芯片速度更快、功耗更低的目的
比如在比特币热潮的后期
矿工们就抛弃了传统的GPU
使用挖矿专用ASIC芯片来谋求更多的利润
另一个常见的例子是手机里的视频解码芯片
通常也是一种ASIC
Etched提出
GPU在过去四年间的效率并没有变得更好
只是变得更大了
芯片每平方毫米的TFLOPS几乎持平
事实上
老黄本人也在今年GTC大会上提出
我们需要更大的GPU，如果不能更大
就得把更多GPU组合在一起
变成更大的虚拟GPU
财大气粗的老黄自然可以走大力出奇迹的路线
但是
在Etched看来，还有更加取巧的办法
既然摩尔定律放缓已经成为既定的事实
那么为什么不试试ASIC
走专用化的路线呢？
而Sohu所专注的对象就是Transformer
整个芯片的制造工艺相当于把Transformer网络架构直接“烧录”到芯片里
公司名称Etched也是取自“蚀刻”的意思
Sohu由台积电4nm工艺制造
只有1个核心
每张芯片配有144GB HBM3E高带宽内存
Etched团队表示
英伟达的H100有800亿个晶体管
却只有3.3%用于矩阵乘法这种大模型推理时最常见的运算
而只支持Tranformer的Sohu芯片
FLOPS有效利用率超过了90%，
因为他们采用了一种名为“连续批处理”（Continuous batching of prompts and completions）的创新技术
这种方法巧妙地将多个输入和输出序列组合在一起处理
充分利用了芯片的计算资源
想象一下，就像是在一个大厨房里
多个厨师同时使用相同的食材
也就是模型权重，去烹饪不同的菜肴
也就是处理不同的输入序列
这种技术的优势
在处理长输入短输出的场景中尤为明显
这恰好符合大多数AI应用的使用模式
通过这种方式
Sohu芯片能够在处理Llama-3-70B等大型模型时
达到惊人的效率，远超传统GPU的表现
简单来说
Sohu芯片就像是一个超级高效的并行处理器
能够同时处理大量的AI任务
而不会被内存的读取速度拖后腿
这个突破性的技术有望大幅提升AI应用的响应速度和处理能力
为用户带来更加流畅、更加智能的体验
此外
Sohu还能做到简化推理所用的硬件和软件
由于Sohu不运行Transformer以外的模型
Etched 团队可以去掉与Transformer无关的硬件
削减传统上用于部署和运行非Transformer的软件开销
可以说
Sohu芯片是抛弃了一切花里胡哨的额外功能
全心全意地为大模型服务
这样极致化的结构
换来的是Sohu在大模型方面的极致性能
单单一张芯片
就能够支持最高100万亿参数的大模型
这已经远远超过当前市面上的大模型规模
压根没有这么大的模型能够摸到Sohu的上限
在性能测试上
Etched使用了FP8精度的Llama-3 70B
无稀疏性，8倍模型并行
2048输入长度
128输出长度对Sohu进行了测试
与此同时
使用TensorRT-LLM 0.10.08最新版本来评估H100性能
二者对比
最终得出了一个令人惊叹的数据
Sohu在推理Llama-3 70B上
比H100快至少20倍
一些朋友可能对这个数字没有什么概念
大飞举一些应用方面的例子
方便大家理解
当下
Gemini 要花费超过 60 秒的时间
来回答有关视频的问题
AI运行代码的能力也不尽如人意
需要几个小时才能完成任务
而且成本比雇佣人类码农更高
至于视频生成模型
一秒钟才能生成一帧画面
对于普通用户也许是够用了
但是在专业领域这个生成速度还远远不够
当 ChatGPT 注册用户达到 1000 万的时候
甚至 OpenAI 也出现过GPU算力荒
即使是以多卡互联的方式堆叠显卡
以每两年 2.5 倍的速度不断制造更大的 GPU
也需要十年的时间才能实现即时的视频生成
如果大模型的推理速度能够提高20倍
视频模型生成画面就能够更加即时、迅速
甚至做到实时语音对话
几毫秒理解上千字的token并且给出回复
多少人期待的可以实时互动的AI女朋友
才终于在硬件上有了实现的可能
至于在编写代码和文本生成方面
Sohu带来的提升也堪比是氮气加速
已经有不少人准备提前开香槟
庆祝AI即将在Sohu引领下到来的另一场创新狂潮
在Sohu的强劲性能让众人惊掉下巴的同时
三位开发这款芯片的少年
克里斯
朱，加文·乌贝蒂和罗伯特·瓦亨
也是一战成名
然而，在当下无限风光的背后
是长达两年的绝命豪赌
三位创业者中
加文和克里斯率先休学创业
当时正值2022年6月
Chat-GPT还没有问世
Transformer也还没有成为主流的架构
在那时候
图像和视频生成模型使用的是U-Net
自动驾驶汽车模型使用CNN
可以说
除了风险投资人和个别极具眼光的技术大佬
没有人真敢押宝这个前途未卜的技术
但是，加文和克里斯，all in了
最初，二人是在大学暑期实习时
进入了一家芯片公司
在接触到底层硬件领域后为之吸引
加文原本只打算离开哈佛休学一年
但是最终在 OctoML 找到了一份从事 Apache TVM 开源编译器和matmul内核的工作
在为 Arm Cortex M4 和 Cortex M7 开发微内核的时候
加文注意到 Arm 的指令集中没有 8 位的 MAC SIMD 指令
只有 16 位的
尽管M4 和 M7 支持许多其他的 8 位 SIMD 操作
但是只有Helium 引入了 8 位 MAC SIMD 指令
这意味着 8 位 MAC SIMD 操作
实际上只能以一半的速度运行
这可以说是加文创办Etched的一个关键因素
他表示，这个问题永远无法解决
每次上班，我都必须处理这个疏忽
这让我和克里斯一起思考
我们必须能够做得更好
与此同时，加文和克里斯还看到
人们对基于Transformer 架构的大语言模型的兴趣正在激增
硬件的缺陷与人工智能的潜力
让两位年轻人看到了未来无限的可能
如果能有一款针对大语言模型进行强化的芯片
它将在未来的市场中占据不可忽视的重要地位
加文说
你无法通过泛化获得我们所需要的那种改进
你必须在单一架构上下大赌注
不仅仅是人工智能
还要在更具体的东西上下赌注
我们认为英伟达最终会做到这一点
这个机会太大了，不容忽视
于是，说干就干
二人当机立断，决定从哈佛大学退学
又拉上了加文的大学室友罗伯特·瓦亨
共同创立了 Etched
一家专门为大语言模型设计更高效推理架构的公司
虽然目前市场上还没有专门针对于大语言模型的加速器
但是英伟达已经宣布了针对Transformer的软件功能
其他加速器公司也纷纷宣布将支持语言和视觉转换
正面硬拼这些实力雄厚的大佬
显然不是明智之举
摆在Etched面前的路只剩下了一条
那就是通过进一步的专业化来与其他的企业竞争
三位 00 后创始人押上了无数人梦寐以求的哈佛学位
只是为了赌一个未来
那就是Transformer将席卷全球
专用 ASIC 芯片将会成为必然的趋势
现在看来，他们似乎暂时赌赢了
ChatGPT 的全球爆火
彻底颠覆了全球的芯片市场
创造了前所未有的生产需求
在 ChatGPT 之前
业内人士推测Transformer 的市场约为 5000 万美元
现在的市场已经高达数十亿美元
与此同时，AI的架构也开始逐渐趋同
自从GPT-2 以来
最先进的模型架构几乎都保持一致
OpenAI 的 GPT 系列、谷歌的 PaLM、Meta 的 LLaMa
甚至特斯拉的 FSD 都是基于 Transformer
所有大型科技公司都在使用 Transformer 模型
老黄更是借着这股东风赚得盆满钵满
英伟达一举超越微软和苹果
以3.34万亿美元的市值成为全球最有价值的公司
加文表示
当 ChatGPT 问世、英伟达股票大涨
尤其是所有即将推出的AI 模型都是 Transformer 的时候
我们才发现自己在正确的时间出现在了正确的地点
正如他所说
当模型的训练成本超过 10 亿美元
推理成本超过 100 亿美元的时候
使用专用芯片就是不可避免的了
在这种规模下
只要有 1% 的性能改进
都能证明成本为 5000 万至 1 亿美元的芯片项目是值得的
三位创业者的故事固然传奇
但是挑战英伟达的垄断地位
可不是光靠一腔热血就能搞定的
在芯片的战场上
老黄已经干倒了无数的对手
凭借A100 和 H100 芯片坐稳了业界的头把交椅
面对新的挑战者，究竟是王者迎天命
还是追梦赤子心？
Etched 能否打败英伟达呢？
对于这个问题
Etched的首席运营官罗伯特这样回应道
过去，AI计算市场是分散的
人们使用各种类型的模型
比如 CNN、DLRM、LSTM、RNN 和其他几十种跨领域的模型
每种架构的花费都在数千万到数亿美元之间
通用GPU芯片有着庞大的市场
但是现在
市场正在迅速整合为一种架构
那就是Transformer
如此一来，专用芯片就是大势所趋
我们的芯片在大多数工作负载上都无法击败 GPU
因为 Sohu 无法支持它们
但是
对于Transformer 专用芯片来说
我们将会占据这个市场
罗伯特这番想要占领市场的发言
可谓是信心十足
公司的投资人也纷纷为Etched摇旗助威
Thiel Fellowship 的主任亚历克斯·汉迪Alex Handy 在一份声明中表示
投资 Etched 是对 AI 价值的战略押注
他们的芯片解决了竞争对手害怕解决的可扩展性问题
也挑战了同行中普遍存在的性能停滞不前的现象
目前来看
Etched 受到了业界的广泛关注和许多支持
但是这场豪赌还没有结束
正如加文自己所说
如果未来 Transformer 消失或者被取代了
我们就会死，但是如果他继续存在
我们就会是有史以来最大的公司
好了以上
就是对Etched公司和Sohu芯片的简要介绍
在大飞看来
ASIC确实是一片蓝
海
也算是部分解决了现有大模型的痛点
但是光凭这个就想把老黄拉下马
还是相当困难的
资本市场也不是大学里的小组竞赛
光讲技术可还不够
也许哪天老黄大手一挥
直接收购了Etched都是有可能的
不知道大家是如何看待Etched的呢
欢迎在评论区留言
感谢大家的观看
我们下期再见
