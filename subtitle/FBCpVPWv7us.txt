大家好，这里是最佳拍档，我是大飞
今天我们要解读的这篇论文
是来自斯坦福大学、SambaNova Systems和加州大学伯克利分校联合团队的最新成果
ACE框架
全称是Agentic Context Engineering
智能体上下文工程
这项研究的核心
是为了解决大语言模型在上下文适配中最头疼的两个问题
简洁性偏差和上下文坍缩
最终让大语言模型不用更新权重
就能够通过动态演进的上下文
实现自我提升
在正式解读论文之前
我们得先搞清楚一个基础问题
什么是上下文适配？
为什么现在越来越多的AI系统都在依赖它？
简单来说
上下文适配就是不修改大模型的权重
而是通过调整输入给模型的上下文
比如系统提示词、任务策略等等方式
来提升模型的性能
这种方式和传统的模型微调相比
有三个非常关键的优势
第一是可解释性强
开发者能够直接看到上下文里的内容
知道模型是基于哪些规则或者经验做出判断的
不像微调那样是黑箱；
第二是知识更新快
比如金融领域出了新的监管政策
直接把政策要点加到上下文里
模型马上就能用，不用重新训练模型；
第三是跨模型的兼容性好
一份优化后的上下文
既能给开源模型用
也能给闭源模型用
不用为不同的模型再单独去做适配
而且现在的技术环境
也越来越支持上下文适配
比如长上下文大模型的普及
还有KV缓存的复用、压缩这些推理优化技术
都让用更长、更丰富的上下文来驱动模型这件事
变得越来越实用
可以说
上下文适配已经成了构建可扩展、能够自我提升的AI系统的一个核心范式
但是就是这么重要的技术方向
现有的方法却有两个绕不开的坑
这也是ACE框架要解决的核心问题
第一个坑是简洁性偏差（Brevity Bias）
很多现有的提示词优化工具
比如大家可能听过的GEPA
都把简洁当成核心的目标
觉得提示词越短、越通用，效果越好
但是实际的情况是
这种追求简洁的思路会漏掉大量的关键信息
比如在测试代码生成任务中
有研究者发现
迭代优化后的提示词
会反复出现生成单元测试
来确保方法按预期运行这类笼统的指令
却漏掉了如何处理边界值、如何适配特定框架这些具体的策略；
再比如做金融领域的数值推理
简洁的提示词可能会忽略XBRL文档中
数值单位的特殊标记规则
导致模型提取数据的时候出现偏差
这种偏差的本质
是把通用简洁和有效指导混为了一谈
而对于Agent和知识密集型的任务来说
恰恰是那些细节的策略才决定了最终的效果
第二个坑更加致命
叫做上下文坍缩（Context Collapse）
有很多方法会让大语言模型每次迭代时
完整重写已有的上下文
结果就是随着迭代次数的增加
上下文会越变越短、信息越来越少
最后性能断崖式的下跌
研究团队在AppWorld智能体基准测试上做了个实验
用动态备忘单（Dynamic Cheatsheet）框架进行测试
在第60次适配步骤的时候
上下文还有18282个token
模型准确率能达到66.7%；
可到了第61步
模型直接把上下文压缩到了122个token
准确率瞬间掉到了57.1%，
甚至比没有任何适配的基线模型还低
这种越迭代越差的情况
在需要保留细节的场景里尤为明显
因为模型会主动丢掉那些看似冗余、实则关键的经验
正是看到了这两个问题
论文的研究者们才提出了ACE框架
他们的核心思路很有意思
那就是不把上下文当成简洁的摘要
而是当成一个不断演进的操作手册（Playbook）
这个手册要能积累策略、细化经验、整理知识
既要全面，又要能够动态更新
而且他们还借鉴了人类学习的逻辑
先通过实践积累经验
再从经验里提炼规律
最后把规律系统化
这就构成了ACE的三大核心组件
生成器（Generator）、反思器（Reflector）和整理器（Curator）
接下来咱们就详细拆解一下ACE的工作流程
看看它是怎么解决那两个核心问题的
首先是生成器（Generator）
它的作用很明确
那就是针对新的任务查询
生成完整的推理轨迹
包括模型是怎么思考的、调用了哪些工具、中间结果是什么、最终成功还是失败了
比如在AppWorld的账单拆分任务里
生成器会输出从调用手机APP
获取室友联系人
到调用Venmo API创建付款请求的每一步代码和执行结果
哪怕中间出现了调用API时参数错误这样的失败
也会完整记录下来
这么做的目的
就是为后续的反思提供最原始、最详细的素材
毕竟只有看到完整的过程
才能准确判断哪里对、哪里错
然后是反思器（Reflector）
这是ACE和其他框架最大的区别之一
很多现有的方法
会让同一个组件既做生成又做反思
而ACE把反思单独拎了出来
让它专注于从生成器的轨迹里
提取可复用的洞察
具体来说，反思器会做三件事，第一
诊断问题
比如在刚才的账单拆分任务里
如果生成器用Venmo交易描述里的关键词来识别室友
而不是用手机APP的联系人关系
反思器会明确指出这是用不可靠的启发式方法
替代了权威的数据源；
第二，提炼正确的策略
比如总结出识别联系人关系
必须调用手机APP的search_contacts接口
不能依赖交易的描述信息；
第三，迭代优化洞察
如果一次反思不够透彻
反思器还会基于反馈多次调整
直到提炼出的策略足够具体、可以落地
举个真实的例子
研究团队在AppWorld的Spotify播放列表统计任务中
生成器用了for i in range(10)的固定循环
来处理API的分页问题
结果只获取了前10页的播放列表
漏掉了后面的13页
这时反思器就会诊断出
用固定范围循环处理分页
会导致数据不完整
同时提炼出必须用while True循环
直到API返回空时才停止的策略
甚至还会补充
循环中要加入异常处理
避免无限循环的细节，显然
这些洞察不是一些笼统的建议
而是能直接用到下次任务中的具体规则
最后是整理器（Curator）
它的核心任务是把反思器提炼的洞察
以增量更新的方式
整合到已有的上下文
或者说操作手册里
而不是像以前那样重写整个上下文
这里有两个关键的设计
第一个是结构化条目（Bullet）
整理器不会把洞察写成大段的文字
而是会拆成一个个带元数据的条目
每个条目都有唯一的ID
以及有用或者有害的计数器
内容则是一个小的知识单元
比如处理时间敏感的交易时
必须用datetime范围比较
不能用字符串匹配
认证失败的时候
要先尝试用手机号代替邮箱登录
甚至是一段可复用的代码片段
这种结构化设计的好处是
后续生成器在使用上下文的时候
能够快速定位到需要的条目
而且更新时只动对应的条目就行了
不会影响其他的内容
第二个是确定性合并
整理器会采用更轻量的逻辑来合并新的条目
比如检查新条目和已有条目是否语义重复
如果重复就更新有用计数器
如果不重复就新增条目
同时定期清理那些标记为有害
或者很少用到的条目
这种方式避免了大模型重写时的主观压缩
确保已有的知识不会被弄丢
通过生成器、反思器、整理器的配合
ACE还实现了三个核心的创新
也正是这三个创新
彻底解决了简洁性偏差和上下文坍缩的问题
第一个创新是反思器的分离设计
之前的方法要么没有专门的反思环节
要么让生成器兼顾反思
导致洞察提取不深入
而ACE的反思器只专注于从轨迹中挖掘规律
不用考虑生成任务
这样提炼出的策略会更加精准、更加详细
同时
这种细分规则恰恰是解决简洁性偏差的关键
因为它保留了领域知识的细节
而不是把知识压缩成模糊的指令
第二个创新是增量Delta更新
传统方法每次更新都要重写整个上下文
既耗时又容易丢失信息
而ACE的更新是增量的
每次只增加几个新的结构化条目
或者更新已有条目的计数器
比如在AppWorld任务中
一次适配只新增3-5个条目
每个条目几十到几百个token
相比重写动辄上万token的上下文
效率提升非常明显
研究数据显示
在AppWorld的离线适配中
ACE的延迟比GEPA低82.3%，
需要的rollout少75.1%，
这意味着开发者不用等太久
就能拿到优化后的上下文
更重要的是
增量更新不会覆盖已有知识
从根本上避免了上下文坍缩
第三个创新是生长-精炼（Grow-and-Refine）机制
ACE的上下文不是无限增长的
而是边生长边精炼
一方面
新的洞察会不断以新条目的形式生长进来
确保知识的全面性；
另一方面，整理器会定期做精炼
比如合并语义相似的条目、删除有害的条目
以及根据有用计数器来调整条目的优先级
这种机制既保证了上下文的丰富度
又避免了臃肿
让模型始终能够用到最有价值的知识
讲完了ACE的设计
我们再来说说它的实际效果到底怎么样？
团队在两类典型任务上做了全面测试
一类是需要多轮推理的Agent任务
另一类是需要领域知识的金融推理任务
还对比了目前主流的5种基线方法
包括基础大模型
上下文学习ICL、MIPROv2、GEPA和Dynamic Cheatsheet
先看Agent任务的表现
AppWorld是目前比较权威的Agent基准
包含邮件处理、账单拆分、音乐播放列表管理等真实场景
还分为测试正常集（Test-Normal）和测试挑战集（Test-Challenge）
后者的难度更高
评估指标用的是任务目标完成率（TGC）和场景目标完成率（SGC）
简单来说就是看模型能不能完成核心任务
以及能不能适配整个场景的需求
在离线适配、有真值标签的情况下
ReAct+ACE的表现非常突出
测试正常集的TGC达到76.2%，
比基础ReAct框架的63.7%提升12.5个百分点；
SGC更是从42.9%提升到了64.3%。
对比其他基线，比如ReAct+GEPA
ACE的TGC比它高11.3个百分点
SGC高19.7个百分点
这都说明ACE积累的细节策略
在多轮任务中
比GEPA的简洁提示词更有效
更关键的是
ACE在没有真值标签的情况下
依然能够实现高效适配
很多实际场景中
开发者拿不到标注好的训练数据
这时候ACE就能靠执行反馈来提炼策略
数据显示，没有真值标签时
ReAct+ACE的平均准确率
依然能够比基础ReAct提升14.8个百分点
这意味着ACE真正实现了无监督自我提升
不用人工标注就能优化
在在线适配场景下，ACE的优势更明显
对比同样支持在线更新的Dynamic Cheatsheet（DC-CU）
ReAct+ACE在测试挑战集的TGC达到66.0%，
比DC-CU的52.3%提升了13.7个百分点；
SGC达到48.9%，
比DC-CU的30.8%提升18.1个百分点
而且ACE的在线适配延迟比DC-CU低91.5%，
token成本低83.6%，
这对于需要实时响应的Agent应用来说
简直是降维打击
最让人惊喜的是ACE在AppWorld排行榜上的表现
截至2025年9月20日
排行榜上排名第一的是IBM CUGA智能体
它用的是GPT-4.1模型
平均准确率60.3%；
而ReAct+ACE用的是更小的开源模型DeepSeek-V3.1
平均准确率达到59.4%，
几乎追平了GPT-4.1的效果
更重要的是
在难度更高的测试挑战集上
ACE的TGC比IBM CUGA高8.4个百分点
SGC高0.7个百分点
这说明ACE的上下文优化
能让小模型发挥出接近大模型的能力
大大降低了Agent应用的部署成本
再看金融领域任务的表现
团队选了两个典型任务
分别是金融数值实体识别FiNER和金融数值推理Formula
前者需要识别XBRL文档中的139种细分的实体类型
后者需要根据XBRL数据做计算
比如计算净利润、资产负债率等等
都是金融领域的核心需求
在FiNER任务中
离线适配且有真值标签的情况下
ACE的准确率达到78.3%，
比基础模型提升了7.6个百分点
比GEPA（73.5%）提升4.8个百分点
要知道，FiNER的实体类型非常细分
比如这两个都是现金类实体
但是前者是无限制现金
后者是受限现金
ACE能通过上下文积累
区分这两类实体的规则
而其他方法往往会把它们归为一类
在Formula任务中
ACE的提升更为显著
离线适配有真值标签时
准确率达到85.5%，
比基础模型提升18个百分点
比Dynamic Cheatsheet（69.5%）提升16个百分点
Formula任务的难点在于计算逻辑的正确性
比如计算稀释每股收益时
需要考虑可转换债券、期权等潜在的稀释因素
ACE能从错误轨迹中
提炼出必须先计算潜在普通股加权平均数
再用净利润除以该数值的完整步骤
而其他方法往往会漏掉潜在普通股这个关键环节
不过这里也要客观的说一句
ACE的表现也依赖于高质量的反馈信号
如果没有真值标签
也没有可靠的执行反馈
ACE的性能会有所下降
比如在FiNER任务中，没有真值标签时
ACE的准确率只有71.1%，
只比基础模型高0.4个百分点
不过Dynamic Cheatsheet的准确率
甚至会下降到68.3%。
这说明上下文适配的核心还是反馈质量
如果模型不知道自己做得对不对
那么再先进的框架也难以发挥作用
除了性能以外
ACE在成本和效率上的优势也特别值得关注
对于企业来说
AI系统的部署成本往往和延迟、计算资源直接挂钩
而ACE在这两方面都做了优化
在离线适配场景下
对比目前效率较高的提示词优化器GEPA
ACE在AppWorld任务中的适配延迟
从53898秒下降到9517秒
降低了82.3%；
需要的rollout次数从1434次下降到357次
减少了75.1%。
rollout次数减少
意味着更少的任务执行
也就减少了API调用、计算资源的消耗
对于需要大量测试的企业来说
这能节省一大笔成本
在在线适配场景下
对比Dynamic Cheatsheet
ACE在FiNER任务中的延迟
从65104秒降到了5503秒
降低了91.5%；
token成本从17.7美元下降到2.9美元
降低了83.6%。
要知道，在线适配是实时进行的
延迟降低意味着用户等待的时间更短
而token成本降低
则直接减少了模型调用的费用
比如一个每天处理1000个金融文档的系统
用ACE每年能节省的token成本
可能超过1万美元
可能有朋友会问
ACE的上下文是不断生长的
会不会导致推理时的上下文窗口不够用呢？
或者说
长上下文会不会增加推理的成本？
这里要纠正一个常见的误区
那就是长上下文不等于高服务成本
现在的大模型推理基础设施
已经有了很多的优化技术
比如KV缓存复用、KV缓存压缩、缓存卸载等等
这些技术能让频繁使用的上下文片段被缓存起来
不用每次推理都重新处理
从而大幅降低计算成本
比如KV缓存复用技术
能够让重复出现的上下文片段的处理时间
减少90%以上
这意味着ACE的长上下文
在实际部署时的成本并不会比短上下文高太多
反而会因为策略更精准
减少了重复推理的次数
整体成本反而更低
另外
ACE对在线学习和持续学习也有重要的意义
现在很多AI系统都面临着分布偏移的问题
比如金融领域的会计准则更新、Agent调用的API版本变更
这时候传统的微调方法
需要重新准备数据、训练模型
成本高、周期长
而ACE只需要通过新的执行反馈
更新上下文里的策略条目
比如把旧会计准则下的收入确认规则
替换成新准则下的规则
模型马上就能适配新场景
更重要的是
ACE的上下文是可解释、可编辑的
如果发现某个条目是错误的
比如旧版本的API参数
开发者可以直接删除或者修改这个条目
实现选择性遗忘；
而微调后的模型
要删除错误知识几乎是不可能的
这对于需要遵守数据隐私法规的企业来说
是非常关键的优势
当然，ACE也不是万能的
它有两个明显的局限性
第一个局限性是依赖强反思器
如果反思器无法从生成轨迹中提炼出有用的洞察
那么ACE的上下文质量也会下降
比如在某些特殊的医疗文档分析任务中
如果反思器分不清DICOM格式和HL7格式的区别
就无法提炼出正确的文档处理策略
这时ACE的效果可能还不如简单的上下文学习
第二个局限性是
并非所有的任务都需要长上下文
对于一些简单任务
比如生成一句话总结、回答常识问题
简洁的提示词反而比长上下文更加高效
比如在多跳问答任务HotPotQA中
模型只需要知道如何检索证据、如何合成答案的通用规则
不需要积累大量的细分策略；
再比如24点游戏
只需要一个加减乘除凑24的规则
额外的上下文反而会增加推理时间
所以ACE更适合那些需要细节策略的复杂任务
比如Agent、领域推理、多轮工具调用等等
总结一下，ACE框架的核心价值在于
它重新定义了大语言模型的自我提升方式
不需要再依赖权重更新
而是通过生成-反思-整理的闭环
让上下文成为一个动态演进的知识库
它解决了现有方法的简洁性偏差和上下文坍缩问题
在Agent和领域相关任务中实现了性能、效率、成本的三重优化
甚至能够让小模型发挥出接近大模型的能力
对于开发者来说
ACE能够带来的启示是
未来再构建大模型系统的时候
与其一味的追求更大的模型参数
不如花更多的精力来优化上下文
因为好的上下文
能让模型用更少的参数，做更多的事
而对于企业来说
ACE可以显著降低复杂AI系统的部署成本
尤其是开源模型+ACE的组合
可能会成为很多场景下的性价比之选
好了，以上就是对这篇论文的解读
希望对大家有所帮助
感谢观看本期视频，我们下期再见
