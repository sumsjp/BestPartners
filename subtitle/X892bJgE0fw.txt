大家好，这里是最佳拍档，我是大飞
今天我们来聊聊一款最近备受关注的模型
Kimi K2
可能有些朋友已经听说过它的名字
但是它背后的技术细节、性能表现以及在行业中的定位
或许还有很多值得深入挖掘的地方
作为一款拥有1万亿总参数、320亿激活参数的混合专家（MoE）模型
K2在多个基准测试中都交出了亮眼的成绩单
甚至超越了不少开源和闭源的同类模型
那么，它究竟是如何做到的？
背后又有哪些创新的技术在支撑呢？
今天
我们就通过刚刚发布的32页的技术报告
来一起揭开Kimi K2的神秘面纱
首先
我们来介绍一下Kimi K2的基本架构
它采用的是混合专家MoE架构
这种架构的特点是将模型拆分成多个“专家”子网络
每次输入数据的时候
只会激活其中一部分的专家进行计算
这样既能够保证模型的规模和能力
又能够有效地控制计算成本
具体来说
Kimi K2的总参数达到了1.04万亿
而每次激活的参数为320亿
这种设计让它在处理复杂任务的时候
既能保持高效
又能维持较高的性能水平
说到模型的训练
就不得不提它所使用的优化器
MuonClip
这是Kimi团队在Muon优化器的基础上改进而来的
最大的亮点是加入了QK-Clip技术
为什么要做这样的改进呢？
原来
在使用Muon优化器进行大规模训练的时候
很容易出现注意力logits爆炸的问题
这会导致训练不稳定
甚至出现损失飙升的情况
而QK-Clip技术通过对查询（Query）和键（Key）的投影权重进行重新缩放
有效限制了注意力logits的增长
从而解决了训练不稳定的难题
具体来说
QK-Clip会监控每个注意力头的最大logit值
当这个值超过设定的阈值时
就会对查询和键的权重进行调整
由于这种调整是按头进行的
所以只会影响那些出现问题的注意力头
从而最大程度减少了对模型训练的干扰
在Kimi K2的训练过程中
研究人员设置的阈值是100
从训练结果来看，这种方法非常有效
整个训练过程没有出现一次损失飙升
最终模型在15.5万亿 tokens的数据集上完成了预训练
除了优化器的创新
Kimi K2在预训练数据的处理上
也下了不少功夫
为了提高token的利用效率
团队采用了一种合成数据生成策略
特别是在知识和数学领域进行了针对性的改写
比如在知识数据方面
他们通过多样化的提示词
让模型从不同风格和角度对原始文本进行重述
同时采用分块自回归生成的方式
保证长文档的连贯性
最后还会进行保真度验证
确保改写后的内容与原文一致
这种改写策略的效果是显著的
在SimpleQA的实验中
将原始数据重复训练10个epoch
模型的准确率为23.76%；
而将数据改写一次后重复训练10个epoch
准确率提升到了27.39%；
如果将数据改写10次后只训练1个epoch
准确率更是达到了28.94%。
这说明通过改写来增加数据的多样性
比单纯重复训练更能够提高模型的性能
同时还能避免过拟合的问题
在数学数据方面
团队则借鉴了SwallowMath的方法
将高质量的数学文档改写成“学习笔记”的风格
还把其他语言的数学材料翻译成英文
进一步丰富了数据的多样性
这些处理让Kimi K2在预训练阶段
就积累了扎实的知识和推理基础
为后续的性能表现埋下了伏笔
接下来
我们来看看Kimi K2的模型架构细节
它的隐藏维度为7168
专家隐藏维度为2048
采用了与DeepSeek-V3类似的多头潜在注意力MLA机制
与DeepSeek-V3相比
Kimi K2的专家数量从256增加到了384
而注意力头的数量则从128减少到了64
为什么要做这样的调整呢？
这源于团队对稀疏性缩放定律的研究
他们发现
在激活参数数量固定的情况下
增加专家总数，也就是提高稀疏性
可以降低训练和验证损失
提升模型的性能
例如
在达到相同验证损失1.5的情况下
稀疏性为48时的计算量
比稀疏性为8时减少了1.69倍
因此，Kimi K2选择了48的稀疏性
即每次前向传播激活384个专家中的8个
而减少注意力头的数量
则是为了提高长上下文处理的效率
随着上下文长度的增加
注意力头如何数量过多
会导致推理计算量大幅上升
实验显示，当序列长度为128k的时候
将注意力头从64增加到128
推理的FLOPs会增加83%。
而从性能来看
增加注意力头带来的提升却很有限
在不同计算预算下
验证损失的降低幅度仅为0.5%到1.2%。
因此，综合考虑效率和性能
团队最终选择了64个注意力头
在训练基础设施方面
Kimi K2是在配备NVIDIA H800 GPU的集群上进行训练的
每个节点有8块GPU
通过NVLink和NVSwitch连接
节点之间则采用8×400 Gbps的RoCE互连
为了适应动态的资源变化
团队还采用了灵活的并行策略
结合了16路管道并行（PP）、16路专家并行（EP）和ZeRO-1数据并行
让模型可以在任何32的倍数节点上进行训练
这种并行策略不仅能够有效的利用GPU内存
还可以通过重叠计算和通信来提高效率
例如，在1F1B
也就是一次前向一次后向的调度中
通过增加热身的微批次
可以让专家并行的all-to-all通信与计算重叠进行
同时，团队还对激活进行了优化
包括选择性重计算、FP8存储和CPU卸载等等
确保在有限的内存下完成训练
预训练完成后
Kimi K2还经历了多阶段的后训练过程
包括监督微调SFT和强化学习RL
在SFT阶段
团队构建了大规模的指令微调数据集
涵盖了多个领域
并且特别开发了一个大规模的智能体数据合成管道
用来训练模型的工具使用能力
这个数据合成管道分为三个阶段
首先是生成工具规范
既包括了从GitHub获取的3000多个真实的MCP工具
也包括通过领域演化生成的20000多个合成工具；
然后为每个工具集生成对应的智能体和任务；
最后生成智能体使用工具完成任务的轨迹
在轨迹生成过程中
还会模拟用户与智能体的多轮对话
并且通过工具执行环境提供反馈
最后由模型根据任务标准进行评估和筛选
这种合成数据不仅规模大
而且质量高
再加上部分真实执行环境的补充
比如代码执行沙箱
让Kimi K2在工具使用方面的能力得到了显著提升
这一点在后续的基准测试中也得到了充分体现
在强化学习阶段
团队开发了一个类似Gym的框架
结合了可验证奖励（RLVR）和自我批判奖励机制
对于数学、STEM和逻辑任务
他们收集了大量高质量的问答对
并且选择难度适中的问题进行训练；
对于需要主观判断的任务
比如创意写作
则会让模型通过 pairwise 比较来评价自己的输出
生成偏好信号
为了保证强化学习训练的效果
团队还做了一些优化
比如引入了预算控制
限制每个样本的最大token数
避免模型生成过长的响应
同时加入PTX损失
防止模型忘记预训练阶段的高质量数据
以及采用温度衰减策略
在训练初期通过高温度来鼓励探索
后期则降低温度以稳定输出
这些措施让Kimi K2在强化学习阶段
能够持续的提升性能
同时保持良好的泛化能力
接下来
我们来看看Kimi K2的性能表现
在多个基准测试中
它都展现出了领先的水平
在智能体和竞争性编码方面
Kimi K2在SWE-bench Verified的代理式单轮尝试中
得分为65.8%，
多轮尝试中可以达到71.6%；
在SWE-bench 多语言中得分为47.3%，
在LiveCodeBench v6中得分为53.7%，
在OJBench中得分为27.1%，
这些成绩不仅超越了大多数开源模型
还与像Claude 4 Sonnet这样的闭源模型
差距大幅缩小
在工具使用任务上
Kimi K2在Tau2-Bench上得分为66.1
在ACEBench（英文）上得分为76.5
表现同样出色
而在数学和STEM领域
它在AIME 2025中得分为49.5
GPQA-Diamond中得分为75.1
展示出了强大的推理能力
应该说，这些成绩的取得
与Kimi K2在预训练和后训练阶段的精心设计密不可分
值得一提的是
在2025年7月17日的LMSYS Arena排行榜上
Kimi K2成为排名第一的开源模型
在超过3000次用户投票中位列第五
这也从侧面反映了它在实际应用中的受欢迎程度
除了Kimi K2-Instruct指令模型以外
团队还发布了Kimi K2-Base基础模型
在预训练评估中
Base模型在多个基准测试中也表现优异
比如MMLU得分为87.79%，
MATH得分为70.22%，
GSM8K得分为92.12%，
在中文任务中更是达到了92.50%，
展现出强大的多语言能力
在安全评估方面
Kimi K2-Instruct在有害内容、犯罪、错误信息、隐私和安全等多个维度的测试中表现稳定
例如，在有害内容的基础策略测试中
通过率为98.04%；
在隐私保护的基础策略测试中
通过率达到100%。
不过，在面对复杂的攻击策略
比如迭代越狱的时候
模型的通过率有所下降
不过这也为后续的优化指明了方向
当然，Kimi K2也并非完美无缺的
团队在内部测试中就发现
在处理复杂推理任务或者工具定义不清晰的时候
模型可能会生成过多的token
导致输出被截断
或者工具调用不完整
此外，在构建完整软件项目的时候
一次性提示的成功率
不如在智能体编码框架下使用的效果
这些问题都需要在未来的版本中进一步改进
总的来说
Kimi K2 的技术报告不仅展示了一个性能强大的万亿参数模型
更重要的是
它为业界描绘了一条通往“开放式智能体”的可行路径
不过，就在昨天
阿里通义也推出了最新的Qwen3模型
Qwen3-235B-A22B-2507
通义千问官方表示
他们停用了混合思维模式
改为分别训练Instruct和Thinking模型
并且正式发布了性能更强的 Instruct模型及其FP8版本
根据官方的测评显示
最新版Qwen3又击败了Kimi K2模型
开源新王或许将再次易主
有机会我们再做一期视频详细介绍
感谢大家观看本期视频
我们下期再见
