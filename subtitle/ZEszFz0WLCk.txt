大家好，这里是最佳拍档，我是大飞
今天这期视频
咱们来聊聊AI对科研领域的影响
最近，OpenAI的科学家Jason Wei预测
在未来一年内
AI重点将从推广大众需求
转为促进科学发现，未来五年
AI更是会转向硬核领域
用AI加速科学和工程
甚至加速AI本身的研究
无独有偶
DeepMind刚刚发布的36页报告也揭示出
全球各地的实验室里
科学家们对AI的使用正在呈指数级增长
如今
每三位博士后研究员中就有一位
使用大语言模型来协助完成文献综述、编程和文章撰写等工作
而且今年的诺贝尔化学奖颁发给了AlphaFold 2的发明者
这也启发了大量科学家将AI应用到自己的科学领域中
以求得更多的创新性发现
过去半个世纪，科学家的人数猛增
仅美国就翻了七倍多
但是科技所带来的社会进步却放缓了
其中一个原因就是
现代科学家面临的规模和复杂性挑战越来越大
不过
深度学习不仅很擅长搞定这种复杂局面
还能大幅压缩科学发现的时间成本
比如
传统方法要花几年、烧10万美元才能搞定一个蛋白质结构
而AlphaFold直接免费给你2亿种预测
秒杀传统方法
因此，对于在不同科学研究阶段
难以突破研究瓶颈的科学家们来讲
把握住使用AI的关键机遇
或许就能促进诞生强有力的新发现
论文中指出了五个机遇
我们来分别说说
首先是知识方面
AI将会改变科学家获取和传递知识的方式
科学家要想推动新发现
必须要掌握一套越来越专业化
而且呈指数增长的知识体系
这种“知识负担”让颠覆性发现
越来越倚重年长的科学家和顶尖大学的跨学科团队
同时也导致小团队独立撰写论文的比例在持续下滑
而且
大多数科学成果仍然以晦涩难懂、英语为主的论文形式分享
限制了政策的制定者、企业和公众的关注与兴趣
在这方面
大语言模型可以帮助科学家和公众破局
比如，有团队用谷歌Gemini
一天内从20万篇论文中提炼出相关的见解
即使是普通人也可以通过AI轻松获得论文的摘要和问答
拉近与前沿科学的距离
其次是数据
AI可以帮助生成、提取和标注大型的科学数据集
尽管我们处于数据爆炸的时代
科学数据却严重匮乏
比如土壤、深海、大气层和非正式经济
而AI正有助于改变这一现状
它能够减少在DNA测序、检测样本中具体的细胞类型
或者捕捉动物发音时可能包含的噪声和错误
科学家们还可以利用大语言模型越来越强的多模态能力
从科学出版物、档案文件以及视频图像等资源中
提取非结构化的科学数据
然后转化成结构化数据集
以便后续研究
AI还可以帮助为科学数据添加科学家所需的辅助信息
比如至少三分之一的微生物蛋白质
在执行细节中都没有被可靠的标注
而经过可靠性评估验证的AI模型
也可以作为新的合成科学的数据来源
比如，AlphaProteo蛋白质设计模型
是在AlphaFold 2中超过1亿个AI生成的蛋白质结构
以及蛋白质数据库中的实验结构上进行训练的
第三个机遇是实验
AI可以模拟、加速并且指导复杂的实验
科学实验经常会因为成本高昂、复杂而且耗时难以执行
还有一些实验会因为研究人员无法获得所需要的设施、人力或者实验材料而无法进行
核聚变就是一个典型例子
它有希望能给人类提供一种几乎无限、无排放的能源来源
并且可能支持像海水淡化等高能耗的创新性大规模应用
但是控制等离子体所需的托卡马克反应堆极其复杂昂贵
而AI可通过模拟的方式来加速实验进程
其中一种方法是
利用强化学习Agent来对物理系统进行模拟
比如，研究人员与洛桑联邦理工合作
用强化学习控制了托卡马克等离子体的形状
这种方法还可用于粒子加速器、望远镜等设施
不过这些模拟的目的
主要是为了指导和优化现实的实验
而非完全替代它们
以基因研究为例
普通人平均有9000多个错义变异
大多数是无害的，但是少数会致病
在现实中
研究人员只能逐个测试蛋白质的影响
而AlphaMissense模型能够快速分类7100万个潜在变异中的89%，
帮助科学家聚焦高风险变异
加速疾病研究
再来说说模型方面
AI可以帮助建模复杂系统及其组件之间的相互作用
1960年
诺贝尔奖得主物理学家尤金·维格纳（Eugene Wigner）感叹
数学方程在模拟自然现象
比如行星运动中存在“出乎意料的有效性”。
但是在面对生物学、经济学、天气等复杂系统时
传统的方程模型就逐渐显得乏力
因为这些系统充满动态性、随机性
还经常伴随着涌现和混沌
难以预测和控制
这些方程能够提供非常有用
但是并不完美的近似
而且运行这些方法也需要高昂的计算成本
AI却能够从复杂数据中挖掘规律
比如
谷歌的深度学习系统能快速预测未来10天的天气
速度与准确性双双秒杀传统数值模型
同时，AI还能够帮助减缓气候问题
比如用AI来预测潮湿区域的出现时间和位置
帮助飞行员避开会加剧全球变暖的凝结尾迹
而且AI还能够丰富传统的复杂系统建模
比如，基于智能体的建模
通过模拟个体行为者
比如企业和消费者之间的交互
来理解这些交互如何影响更大、更复杂的社会经济系统
在传统方法中
科学家需要事先规定这些智能体的行为方式
如今
科学家可以利用大语言模型来创建更灵活的生成式智能体
这些智能体能够进行沟通和行动
比方说搜索信息或者购买商品
同时还能对这些行动进行推理和记忆
科学家还可以利用强化学习
来研究这些智能体如何在更加动态的模拟中
学习和调整它们的行为
比如对于新的能源价格或疫情响应政策的反应等等
最后一个机遇是解决方案
AI为大规模搜索空间问题提出了解决方案
很多重要的科学问题都伴随着许多几乎无法理解的潜在解决方案
比如
生物学家和化学家需要确定分子的结构、特性和功能
才能设计出用作抗体药物、降解塑料的酶
或者新型材料的一些新分子
然而，要设计一种小分子药物
科学家需要面对超过10的60次方种潜在的选择
而要设计一种由400种标准氨基酸组成的蛋白质
则需要面对20的400次方种选择
这种大规模搜索空间不仅限于分子
还广泛存在于许多的科学问题中
比如寻找数学问题的最佳证明、计算机芯片的最佳设计架构等等
传统上
科学家只能依赖于直觉、试错法、迭代或者暴力计算的某种组合
来寻找最佳分子、证明或算法
然而
这些方法难以充分遍历庞大的搜索空间
从而无法发现更优的解决方案
如今
AI能够更好地探索这些庞大的搜索空间
同时更快地聚焦在
最有可能可行、而且有效的解决方案上
今年7月
AlphaProof和AlphaGeometry 2
就成功解决了国际数学奥林匹克竞赛中六道题目中的四道
它们利用Gemini大语言模型架构
为给定的数学问题生成了大量潜在解决方案
并且结合基于数学逻辑的系统
迭代式地实现了接近最可能正确的候选解决方案
接下来
论文深入探讨了一下实现“AI for Science”的几个关键因素
将它归纳为了一个“AI for Science生产函数”的模型
展示出了如何利用AI来推动科学研究和创新的不同阶段
包括从科学研究的问题选择、模型评估开始
通过计算资源和数据这些基础设施的支持
在开展研究过程中注重组织模式设计和跨学科
形成成果，并且最终通过采纳
将研究成果转化为实际的影响
以及每个阶段需要关注的核心内容
在问题选择方面，论文认为
科学进步的关键是要找到真正值得解决的问题
在DeepMind
科学团队通常会先评估一个研究问题是否足够重要
是否值得投入大量时间和资源
DeepMind的CEO德米斯·哈萨比斯曾经提出过一个思维模型
那就是将整个科学视为一棵知识之树
那么，最重要的就是找到树的根
像蛋白质结构预测、量子化学这些基础性的“根源问题”，
它们一旦得到解决，就能开枝散叶
解锁全新的研究和应用
而在这些问题当中
要判断AI是否能带来增益效果
我们需要寻找具备特定特征的问题
比如巨大的组合搜索空间、大量数据
以及可以用来衡量性能的明确目标函数
其实许多最近的突破
就来自于重要科学问题和成熟AI方法的碰撞
比如，DeepMind在核聚变研究的进展
就得益于新发布的强化学习算法
最大后验策略优化
所以说，选对问题很重要
但是问题的难度也得刚好
一个适合AI的问题
通常是能够产生中间结果的问题
如果问题太难
就没法产生足够的反馈推动进展
而要做到这一点
需要靠直觉与实验的结合
在科学 AI 研究中
模型评估也是一个不可或缺的环节
在训练 AI 模型的时候
往往会出现模型表现良好
但是实际却无法有效解决现实问题的情况
这就凸显了评估模型的重要性
比如，DeepMind的天气预测团队
最初是基于几个关键的变量的「进展指标」来提升模型表现
但是当模型达到一定性能水平之后
他们采用了一个更加全面的评估方法
其中包括1300多个指标
这些指标的设计
受到了欧洲天气预报中心（ECMWF）评分卡的启发
团队也发现
AI模型有时会在某些指标上「作弊」，
比如存在「双重惩罚」问题
也就是「模糊」预测比「精准」预测受到的惩罚更少
为了进一步验证
团队还评估了模型在下游任务中的实用性
比如预测气旋路径的能力
以及表征可能导致洪水的「大气河流」的强度
计算资源是AI和科学发展的核心引擎
但也是节能减排的焦点之一
AI实验室和政策制定者需要从长远考虑的视角
来平衡模型需求与效率提升
比如，蛋白质设计模型是小巧高效的
而大语言模型在训练时是计算密集的
但是微调和推理时所需要的计算量则比较少；
通过优化数据
或者将大模型「蒸馏」成小模型
也可以进一步降低计算成本
同时
也需要对比AI与其他科学方法的资源消耗
比方说
AI驱动的天气预测模型尽管训练的时候很耗费资源
但是整体的效率可能会优于传统方法
因此，对实证数据的持续跟踪
可以帮助明确这些趋势
并且为未来计算需求的规划提供依据
像计算资源一样
数据也是科学AI发展的基础设施
需要持续开发、维护和更新
人们常着眼于由政策制定者推动的新数据集创建
例如
2012年奥巴马政府启动的材料项目绘制了无机晶体图谱
为DeepMind最近的GNoME项目
预测220万种新材料提供了数据支持
但是其实许多科学AI上的突破
往往来自更有机的数据涌现
这些数据得益于有远见的个人或小团队的努力
比如Broad研究所的丹尼尔·麦克阿瑟Daniel MacArthur所领导开发的gnomAD遗传变异数据集
就为DeepMind的AlphaMissense项目提供了基础
还有
数学工具Lean最初由莱昂纳多·德·莫拉Leonardo de Moura开发
如今已经AI数学模型的重要训练资源
这些案例都说明
除了自上而下的战略规划
还需要激励研究者在数据收集、整理和共享中扮演更积极的角色
在组织模式方面，学术界偏自下而上
工业界偏自上而下
但是顶尖的实验室往往能找到二者间的平衡
像贝尔实验室和施乐帕洛阿尔托研究中心的黄金年代
就以自由探索的研究模式著称
这也为DeepMind的创立提供了灵感
最近
一批新兴科学机构试图从这些例子中汲取经验
复刻这种研究模式
它们希望推动更多高风险、高回报的研究
削减官僚主义
为科学家提供更好的激励
这些机构致力于解决一些科学中规模过大、学术界无法承担
但在工业界又不够盈利的问题
比如扩展Lean证明助手
这个工具对于AI数学研究至关重要
理想状态下
机构为科学家提供清晰的目标、资源和支持
但是具体的研究方法和过程由科学家自己主导
找到这种平衡不仅能吸引顶尖研究领导者
也是成功的关键
Demis Hassabis称之为协调尖端研究的核心秘诀
跨学科合作呢
可以说是破解科学难题的一把钥匙
但是常常会被学科壁垒所卡住
AIF science的研究
往往是需要多学科起步的
但是真正的突破却来自于跨学科的深度融合
这不仅是把人凑在一起
而是让团队共同开发共享的方法和思想
比如
DeepMind的伊萨卡Ithaca项目用AI来修复受损的古希腊铭文
为了成功
AI研究负责人要钻研铭文学
而铭文学家也需要理解AI模型
培养这种团队动态需要正确的激励机制
团队能做到这一点
靠的是专注于解决问题
而不是抢论文署名
而这也是AlphaFold 2成功的关键
为了实现真正的跨学科合作
组织还需要为能够帮助融合学科的人创造角色和职业路径
在DeepMind
研究工程师推动研究与工程的良性循环
项目经理加强团队协作并连接不同项目
DeepMind还优先招募擅长发现学科交叉的人
并鼓励科学家和工程师定期更换项目
而关键还是在于打造一种好奇心驱动、尊重差异、敢于争论的文化
然而
将科学进展转化为实际的应用并不简单
例如
疾病的病原理论（germ-theory）从提出到被广泛接受
经历了漫长的时间
而科学突破所催生的下游产品
比如新型的抗生素
也常常由于缺乏合适的市场激励
而得不到充分开发
论文指出，为了促进模型的落地应用
DeepMind在科学采用与商业目标、安全风险等因素之间努力寻找平衡
并且设立了一个专门的影响力加速器
来推动研究的落地应用
并且鼓励社会公益方向的合作
除此以外
要想让科学家更容易地用上新工具
集成流程必须简单
像AlphaFold就开发了很多给科学家用的工具和扩展
科学家只有信任AI模型，才会用它
而推广关键在于明确模型的用途和局限
最后，在合作方面，论文指出
AI for Science 离不开多领域的协作
尤其是公共和私营部门的合作
从数据集创建到科研成果的共享
这种合作会贯穿项目的始终
比如，AI模型设计的新材料是否可行
需要资深的材料科学家来评估；
DeepMind设计的抗SARS-CoV-2蛋白质
能否像预期一样结合目标
也需与克里克研究所合作进行实验验证
甚至在数学领域
一些问题也需要数学家的专业指导
但是毕竟，合作不是一件简单的事情
各方需要尽早就目标和关键问题达成一致
比如研究成果的归属、是否发表论文、数据和模型是否开源、适用的许可协议等
都可能会引发争议
这些分歧通常反映了双方不同的激励
但是成功合作往往都需要建立在清晰的价值互换之上
好了
以上就是DeepMind这篇论文的大概解读了
相当完整的介绍了AI for Science的发展现状和未来趋势
也让我们可以一窥
DeepMind在通过AI推动科学研究方面的努力和成果
最后两部分关于风险和政策责任的部分
大家有兴趣可以自行阅读一下
感谢大家的观看，我们下期再见
