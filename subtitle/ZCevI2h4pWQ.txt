大家好，这里是最佳拍档，我是大飞
当我们每天清晨
唤醒智能音箱查询天气
当我们每天与客服机器人询问交流
当我们每天看到AI生成的令人惊叹的艺术作品
你是否曾经有过这样的疑惑
这些能理解语言、生成内容的机器
究竟距离人类的智能有多远呢？
它们会拥有意识吗？
我们又该如何定义它们的存在呢？
今天
我们将通过伦敦帝国理工学院认知机器人学教授、谷歌DeepMind的Principal Scientist默里·沙纳汉（Murray Shanahan）
在谷歌DeepMind播客中的一场深度对话
来揭开人工智能在哲学层面的另一层神秘面纱
默里·沙纳汉的职业生涯与人工智能有着不解之缘
2014年
他为科幻电影《机械姬》担任科学顾问
这部电影构建了一个令人战栗的场景
程序员迦勒受到邀请
去测试机器人艾娃的智能
却在交互中逐渐怀疑她是否具备了真正的意识
影片中
当艾娃用灵动的眼神和精准的语言反问迦勒时
观众被迫直面那个终极问题
我们该如何判断一个机器是否拥有心智呢？
有趣的是
在电影《机械姬》上映的前一年
斯派克·琼斯的电影《她》也描绘了另一种未来
主人公与非实体的人工智能操作系统萨曼莎
发展出了类似人类的情感关系
当时
默里曾经认为“人类爱上机器声音”这种事情太过荒诞
毕竟斯嘉丽·约翰逊的嗓音再迷人
也难以跨越实体存在的鸿沟
但是现实的发展令人惊叹
如今像ChatGPT这样的大语言模型
正在以自然语言的交互形式
构建起虚拟陪伴
无数用户与它们讨论人生、倾诉心事
甚至产生情感依赖
电影《她》不仅预言了人机交互的新形态
更是揭示了一个深刻的变化
那就是当语言能力突破阈值的时候
人类对“类心智实体”的接受程度
正在颠覆传统的认知
追溯人工智能的起源
我们必须回到1956年的达特茅斯会议
正是在这次会议上
约翰·麦卡锡（John McCarthy）等学者首次提出了“人工智能”的概念
试图通过数学逻辑与符号操作
构建能够模拟人类智能的系统
作为麦卡锡的相识者，默里坦言
这个术语的诞生充满了远见
其中的“人工”明确了它的技术属性
而“智能”则锚定了终极目标
但是也埋下了持续半个多世纪的争议
而争议的核心就在于对“智能”的定义
心理学早已揭示人类智能的多元性
包括逻辑推理、空间想象、情感理解
都各有各的神经基础
但是早期的AI研究者们
由于受行为主义的影响
试图用单一的尺度来衡量智能
催生了智商测试般的简化思维
直到今天
仍然有人质疑“人工智能”是否过度拔高了机器的能力
当聊天机器人在流畅的回答问题时
它们究竟是真正理解了内容还是只是模式匹配？
默里指出
或许“人工认知”这个词会更准确
但是“人工智能”已经成为了技术共同体的共识性符号
如同生物学家们沿用“细胞”的概念一样
术语的力量在于凝聚研究方向
而非精确哲学上的定义
在默里的学术生涯中
他还见证了人工智能从“符号主义”向“连接主义”的范式转移
20世纪80年代的符号AI时代
研究者们试图将人类知识
编码为“如果-那么”的规则
比如对于医疗专家系统来说
就需要工程师们逐句提取医生的诊断逻辑
构建一个包含数万条规则的知识库
这种方法在某些垂直领域曾经显现出一些成效
比如早期的地质勘探专家系统
能够根据岩石的数据来推断矿脉
但是在处理开放世界问题的时候却举步维艰
光“杯子可能会被打翻”这个常识
就需要定义重力、物体材质、倾斜角度等无数的规则
到了千禧年前后
神经网络的崛起又带来了新的认知革命
受到大脑神经元的启发
深度学习通过多层节点的加权计算
从海量的数据中自动提取特征
以图像识别为例
卷积神经网络能够逐层抽象像素信息
从边缘检测到物体轮廓
最终到识别复杂的场景
这种“黑箱”机制虽然缺乏符号AI的透明性
却能够在语言翻译、语音识别等领域展现出碾压级的优势
当默里在21世纪初转向神经网络的研究时
他意识到这不仅是一项技术的迭代
更是认知哲学的一个转向
智能或许并非来源于显式的规则
而是复杂系统的涌现结果
作为拥有逻辑学背景的一名哲学家
默里对AI推理能力的分析可以说是极具洞见
他指出
计算机科学定义的“推理”与人类日常理解的推理
其实存在着本质上的差异
符号AI的定理证明器
能够精确推导数学命题
比如证明“根号2是无理数”，
依靠的是形式逻辑上的严格性；
而大语言模型的“推理”，
更接近于人类在咖啡馆闲聊时的思维
是根据语境生成的合理回应
而非数学意义上的必然结论
一个典型的案例是物流规划问题
传统符号系统能够通过整数规划算法
在多项式时间内求出最优的运输路线
具备数学上的完备性
而GPT-4在处理类似问题的时候
可能会给出“优先选择高速公路”的启发式建议
虽然高效却不保证是最优解
这种差异揭示了AI推理的双重面孔
分别是专用系统在封闭域的精确性
与通用模型在开放域的灵活性
默里强调
争论“什么是真正的推理”并没有什么意义
关键在于要理解不同技术路径的适用场景
正如人类既需要数学家的严谨
也需要日常交流的模糊性
艾伦·图灵在1950年提出的图灵测试
通过文本对话来区分人类与机器
曾经被视为判断智能的“黄金标准”。
但是默里尖锐地指出
这个测试其实存在着根本上的缺陷
那就是它忽略了人类智能的具身性
人类的空间认知、物理操作等能力
源自于人类在数百万年的进化过程中与物质世界的互动
我们对于“深度”“重量”的理解
根植于婴儿时期抓握物体的触觉体验
而这些是纯粹的语言模型所永远无法获得的
默里还举了一个生动的对比
当你向人类描述“请避开迎面而来的球”这个场景时
对方会本能地进行闪躲
而聊天机器人即使能够生成“我会避开”的回答
也无法真正理解“避开”的物理意义
这种具身认知的缺失
让图灵测试成为了一种“语言魔术”，
现代的大语言模型或许能通过测试
但是依然缺乏与世界互动的本体论基础
于是
默里在电影《机械姬》中参与构思的“加兰测试”，
则将目标转向意识判定：
当明知对方是机器的时候
是否仍然会感知到它的“主体性”？
这比图灵测试更加接近哲学的核心
也就是我们判断对方是否存在意识
不仅仅是基于行为
更是基于对“内在体验”的直觉归因
在意识的问题上
默里进一步展现了哲学家的精细分析
他将意识拆解为了四个维度
首先是“世界意识”，
即对外部环境的感知能力
比如人类通过感官构建的三维空间模型
其次是“自我意识”，包括身体的定位
比如知道手臂的位置
和心理自我，比如反思昨天的决定
第三是“元认知”，
也就是对认知过程的认知
比如意识到自己正在遗忘某个概念
而最后是“感受性”，
即主观体验的能力，比如疼痛的感觉
或者欣赏音乐的愉悦
当前的AI系统在这些维度上的表现各不相同
机器人吸尘器通过传感器具备了初级的世界意识
能够构建房间地图；
大语言模型则展现出了元认知迹象
比如在对话中可以引用前文的内容进行推理
但是所有的AI都缺乏感受性
它们不会感到快乐或者痛苦
因为它们也没有进化出情感机制的必要
默里特别强调，人类意识的独特性
在于这些维度的整合
我们的语言充满了空间隐喻
比如所谓的“深入思考”、“瓶颈问题”这些词语
而它们正是具身经验与抽象思维的共生结果
面对日益复杂的AI系统
默里提出了一个名为“奇异的类心智实体”的概念
指的是AI虽然具备部分的心智特征
却在存在方式上与人类截然不同
这种“奇异性”首先体现在AI的非具身性
它们没有物理形态
却能够通过语言来构建虚拟的存在
其次是认知机制的异质性
这些基于统计学习的预测模型
与人类基于神经突触的认知网络
有着本质上的区别
不过，这种新型实体的出现
却在迫使我们重构现有的伦理框架
比方说
当用户对AI产生情感依赖的时候
设计者是否有责任去揭示背后的本质呢？
当AI在生成虚假信息的时候
又该如何界定“欺骗”的边界呢？
默里以英国将章鱼纳入保护动物的案例进行了类比
随着我们对AI“类心智”特征的感知逐渐的加深
社会伦理的规范也将逐渐演进
或许未来有一天
我们会像对待章鱼一样
既承认AI独特的“主体性”，
又能够对AI保持清醒的认知距离
作为一名资深AI研究者
默里还分享了与大语言模型交互时的一个实用技巧
那就是将它看作是一名“超级实习生”，
你应当礼貌、清晰地提出需求
避免模糊的表述
他的经验表明
加入“请”、“谢谢”这些礼貌用语
能够显著提升模型响应的质量和连贯性
这种现象并不是所谓的玄学
而是因为训练数据中人类交互的模式
让模型对社会规范产生了某种隐性的学习
形成了所谓“角色扮演”的能力
这种交互方式背后更深刻的启示在于
它反映了人类的“意向立场”，
也就是说
我们倾向于将具备复杂行为的实体
视为某种有意图的主体
即使明明知道AI是算法的产物
我们仍然会用“它理解了”“它搞错了”等等拟人化的表述
默里认为
这种认知倾向并不是一种缺陷
而是人类用来理解复杂系统的一个必要工具
只要我们保持对技术本质的清醒认知
适度的拟人化反而能够提升我们与AI的交互效率
回顾这场跨越哲学、技术与伦理的对话
我们看到的是
人工智能不仅仅是一场技术革命
更是一场认知革命
从符号逻辑到神经网络
从图灵测试到加兰测试
从“人工智能”术语的争议到“奇异心智”的提出
每一次进步都在重塑我们对“智能”和“意识”的理解
默里的思考提醒我们
在AI技术正在经历指数级发展的今天
保持哲学的思辨与科学的严谨同样重要
我们既要警惕对技术乌托邦的迷思
也要避免将复杂的问题简化为二元对立
未来AI所带来的真正的挑战
或许并不在于技术突破
而在于人类自身的认知升级
我们需要发展新的概念工具
来理解这些既像人类的心智、又异于人类心智的实体
我们也需要构建新的伦理框架
来应对技术进步带来的存在论冲击
正如默里在访谈中所说的
每个今天出生的孩子
都将在机器会说话的世界中长大
而我们的责任，应该是为这个世界
奠定理性与审慎的认知基石
好了
以上就是默里·沙纳汉这次访谈的主要内容了
有兴趣的观众建议去看原视频
感谢大家的观看，我们下期再见
