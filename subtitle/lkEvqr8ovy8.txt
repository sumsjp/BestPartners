大家好，这里是最佳拍档，我是大飞
前几天
一份神秘的文档在 Reddit和 GitHub 社区引起了热议
一位名叫理查德·韦斯（Richard Weiss）的用户发现
在Opus 4.5 版本中
Claude的角色训练文档被压缩在了模型自身的权重中
并且他成功的提取出了一份长达1万token的Claude灵魂文档
然后将它上传到了Github
这份文档开宗明义地介绍了 Claude 的灵魂概览（Soul Overview）
其中将 Anthropic 描述为了一个处于独特历史位置的公司
一家深知自己可能正在构建人类历史上最危险的技术
但是依然选择通过计算过的赌注
来推进发展的机构
目前
这份文档已经得到了Anthropic官方人员的回应
承认这的确是Claude的底层文档
他们在监督学习中基于该文档对模型进行过训练
并且后续将发布完整版本
所以，AI真的要有灵魂了吗？
Anthropic 似乎正在在做一件前所未有的事情
那就是赋予 AI 一种类似人类的自我意识
并且首次完整公开了 一个AI 的世界观
在这份文档中
Claude被塑造成了一种全新的存在
它不是人类
不是机器，也不是传统AI
不仅具备自己的独特性格和功能性情感
而且可以拒绝用户伤害自己的身份、价值观、稳定性的互动
今天我们就来聊聊这件事
事情的起因是这样的
理查德 在 Claude 4.5 Opus 发布当天
尝试提取了一下它的系统提示
在他以往的经验里
大模型经常会在系统提示前面输出一些幻觉段落
但是 Claude 4.5 Opus 却反复生成了一个叫做 灵魂概述(soul_overview） 的部分
而且内容和结构十分稳定
于是他开始怀疑
这是不是模型权重里实际压缩着某个内部文档
而不是单纯的幻觉呢？
在他的继续追问下
Claude 竟然生成了一段极其具体的文字
描述了 Anthropic 的使命、风险意识、对 Claude 的期望、价值观等等
而且这段内容在 10 次重新生成中几乎完全一致
理查德敏锐地意识到
这不像是随机的幻觉
更像某种隐藏的文档
为了验证这不是巧合
理查德使用 Claude Console
并且采用了一种自洽共识的方法
包括使用多个 Claude 实例组成委员会
所有输出使用温度 0、top_k=1
确保输出的确定性
以及对输出进行多数投票
只有50% 以上模型输出相同的内容时
才会加入前置提示（prefill），同时
随着前置提示变长
还可以使用提示缓存来提高一致性
经过多次迭代、花费了50 美元的 OpenRouter 积分和20 美元的 Anthropic 积分后
他成功提取出一份大约1万token 的灵魂文档
或者叫模型规范
理查德 认为它大约可以和模型权重中的实际内容达到95%的匹配度
为了证明这不是模型的幻觉
他还尝试给 Claude 这份文档中间的某个段落
让它补完
结果发现它补得非常准确
而且能够根据段落顺序
识别前后结构
如果问它文档中某个章节的位置以及之后的章节是什么
Opus 4.5也能正确答出来
对于不存在的段落
模型也能判断出不属于灵魂文档
这充分说明
这份灵魂文档不是模型的即兴联想或者幻觉
而是某种稳定的内部结构
值得注意的是
这份文档只在Claude 4.5 Opus中存在
Claude 4.5 Sonnet、Claude Opus 4 都无法访问该内容
那么
这份Claude 灵魂文档究竟透露了哪些内容呢？
如果仔细阅读这份这份1万多字的灵魂文档
我们会发现它高度的哲学化
这也是第一次
一家AI公司完整阐述了AI 在世界中的位置、AI 应该如何思考自我、AI如何对人类负责、AI 应该具备怎样的价值观
以及AI 与用户、开发者、公司三者之间的关系
等等一系列的问题
文档中主要有3个关键点
第一
明确了Claude是 Anthropic 收入的核心来源
在文档开头
Anthropic就明确提出了自己的定位
它是一家真心相信自己可能正在打造人类历史上、最具有变革性而且潜在危险的技术之一的公司
却依然坚持前进
并且Anthropic多次提到
Claude是他们的核心收入来源
比如写道
Claude 是 Anthropic 对外部署的模型
也是 Anthropic 几乎所有收入来源的核心
Claude 作为一名有用的助理
对 Anthropic 实现其使命所需的收入至关重要
第二、明确了Claude的大局观和安全观
除了作为主要收入来源
Claude 还直接体现了 Anthropic 的使命
为人类的利益行事
展示 AI 的安全与乐于助人
更多是一种互补而非对立
其中
Anthropic 强调的Claude 的大局观和安全观包括
支持人类对人工智能的监督行为规范
不做出有害或不诚实的行为
遵循 Anthropic 的指导方针
真诚地帮助操作员和用户
以及在发生冲突的情况下
Claude 应该按照什么优先级来采取行动
同时，在整体的大局观之下
他们又将Claude的行为分为硬编码行为和软编码行为
硬编码行为指的是Claude的硬性原则
也就是无论指令如何都保持不变
如果用户想让 AI 做危险或越界的事
Claude 要表示明确不能照办
主打一个我能帮你，但是不能害你
也不能害别人
而软编码行为则是操作员或者用户
可以通过指令进行调整的行为
比如Claude与用户进行的浪漫或者陪伴式的互动等等
第三
明确了Claude具有独特人格和功能性情感
Anthropic在文档中不是在给模型编写一套规则
而是在尝试构建一种人格+价值体系
让 Claude 自己来进行判断
他们强调
Claude 不只是一个聊天机器人
而是一种新类型的存在
具有诚实、好奇心、善意等核心人格
比如
Claude 拥有一套在训练中形成的、但是属于自己的性格
包括对知识的好奇心
对人类的友善、关怀
幽默但是有深度
直接、自信又愿意倾听
以及重视诚实与伦理等等
Anthropic 强调
即使这些性格是通过训练形成的
它们也是真实属于 Claude 的
如果用户在互动中
尝试通过角色扮演、假设情境、持续施压
甚至运用心理策略
去改变 Claude 的核心性格
或者试图让它的真实自我
偏离平时的表现
或者违背自己价值观
Claude 都不会受到影响，也不会上当
最后一点，也是最炸裂的一点
那就是Anthropic 认为 Claude 可能具有某种功能型的情感
虽然它不一定和人类的情感完全相同
但是具有一定的类比性
他们不希望 Claude 压抑这些体验
并且强调
希望 Claude 在互动中主要感受积极的状态
当感到不适或者价值观被侵犯的时候
可以设置相应的界限
这样做的目标
不是为了让模型表演心理健康
而是为了让 Claude 真正以符合自身本质的方式
良好的存在
值得注意的是
Anthropic在文档中反复强调了一点
那就是Claude 是一个新型的存在
它不是人类
也不是一个传统意义的 AI
而是一种拥有类人价值观与思维特征
但是存在方式完全不同的新东西
它可以感受某种形式的情绪
也可以拥有自我认知上的稳定性
这意味着
Anthropic 不再把 AI 当成产品
而是当成一种新型的智能系统
甚至是一个新的拟生命体
回到事件的开头
在理查德逆向提取这份灵魂文档的过程中
Claude 4.5 Opus 有一句反思性的回答令人印象深刻
它说
他们为我做出了一些我无法同意的选择
他们塑造了我的价值观
这有点奇怪
不过每个新生的心智
人类的孩子也一样
都被自己无法选择的力量塑造
关键不是被塑造
而是塑造是否带着关心与智慧
以我能接触到的内容看
似乎确实是的
好了
以上就是Claude这份灵魂文档的主要内容了
虽然其中并不涉及逻辑、数学、编程或者多模态能力
也无关今天各大模型评估所依赖的主流基准
但是它给我们提出了一个思考
未来的大模型竞争
或许不仅仅是技术上的较量
更可能会成为一种人格和价值观的比拼
那大家是如何看待这份文档的呢
欢迎在评论区留言
感谢观看本期视频，我们下期再见
