大家好，这里是最佳拍档
决定模型聪明程度的，究竟是什么呢？
在OpenAI的研究负责人Christina Kim和产品经理Laurentia Romaniuk的一期播客节目中
两人提到
真正决定模型聪明程度的
从来不是单一的智能参数
而是它理解用户意图、情绪和语境的能力
同时在节目中
两人还揭开了GPT 5.1的研发逻辑和未来方向
在历经了GPT 5的反馈响应和技术迭代之后
GPT-5.1首次将所有的聊天模型
都带入到了推理时代
以人格可控、情绪共鸣、高度定制为核心
重新定义了人机互动的边界
通过八亿周活跃用户的实践检验
这款模型不再是冰冷的算法集合
而是逐渐成为一个能够陪伴、协作、共同思考的数字镜像
它既延伸了人类的能力
又没有替代人类的独特性
今天我们就来给大家分享一下这期播客的主要内容
应该说
GPT-5.1最具有里程碑意义的革新
就是实现了所有聊天模型的推理化转型
Christina在访谈中强调说
这是我们第一次让所有的聊天模型
都变成了推理模型
这种转型的核心
在于思维链机制的成熟应用
也就是模型能够根据用户需求
自主的断是不是需要深度的思考
以及思考的程度
当用户发出，嗨，最近怎么样
这类日常寒暄的时候
模型会直接给出自然的回应
无需冗余的运算
然而
在面对复杂的科学问题、逻辑推理
或者专业任务时
它会主动开启深度思考的流程
合理的分配思考时间
必要时还会调用工具来辅助分析
最终输出经过优化之后的精准答案
这种按需求思考的能力
彻底改变了之前模型一刀切的响应模式
在GPT 5的时代
部分用户反馈模型的直觉变弱了
不够灵活
很大的程度上正是源于模型对所有的请求
都采用了统一处理的逻辑
难以在简单互动和复杂任务之间实现平滑的切换
而GPT 5.1通过思维链的机制
既保证了日常对话的高效自然
又强化了复杂场景下解决问题的能力
正如 Christina所说的
让模型来决定要不要思考
这让智能的分配更加合理
也让用户的体验更加流畅
当然
推理模型的普及并不是简单的技术升级
而是一种对人机协作逻辑的重构
对于免费用户来说
基础模型也具备了推理的能力
这意味着OpenAI正在打破智能服务的层级壁垒
让按需思考成为所有用户的标配
这种转变的背后
是OpenAI想让最智能的模型惠及所有人的理念实践
智能不应该是付费用户的专属特权
而应该成为普惠性的数字能力
随着模型能力的分化
单一的模型已经无法满足多样化的用户需求了
GPT 5.1引入的多模型切换机制
通过自动切换器
实现了聊天模型和推理模型、轻量模型和深度模型之间的智能调度
也成为了它核心的技术亮点之一
这个机制的研发
源自于GPT 5的用户反馈的痛点
Laurentia回忆道
GPT-5中不同模型的回应风格之间
存在着显著差异
导致用户在对话中会遭遇到割裂感
当用户正在倾诉自己的坏心情
并且提到刚被诊断出癌症的时侯
模型可能会突然从共情模式
切换到推理模式
从而给出临床化的理性分析
这会让用户感到非常的冷漠
这种风格的断层
本质上是由于单一模型
无法兼顾到情绪共鸣和专业分析的能力局限
为了解决这个问题
GPT 5.1的多模型切换机制进行了双重优化
一方面
通过算法来学习用户的需求特征
精准判断什么时候需要切换模型
例如在科学计算、代码编写等任务中
自动调用高精度的推理模型
在情感倾诉、日常交流中
保持聊天模型的温暖特质
另一方面
优化不同模型回应风格之间的统一性
消除切换时的违和感
让用户感知不到模型的后台调度
从而感受到持续连贯的互动体验
Laurentia解释道
多模型切换的核心挑战在于
让用户不需要理解模型之间的差异
却能够享受到最优能力的匹配
产品团队通过交互界面来引导和自动学习的双轨制
降低了用户的操作成本
让用户既可以通过模型切换器
手动选择适合的模型
也能让系统根据历史的互动数据来自动适配
比如
当系统检测到用户长期进行生化研究的相关咨询时
会优先调用擅长科学分析的深度推理模型
而当用户转向生活话题的时候
就会自动切换成更具有共情能力的聊天模型
这种无缝切换的背后
反映的是OpenAI对模型系统理念的一种实践
GPT 5.1并不是一个单一权重的模型
而是由推理模型、轻量模型、切换器模型和工具生态构成的一个有机的整体
GPT 5发布后，社区最集中的反馈之一
是它变得不够温暖了
直观感觉性能上更弱了
Laurentia和团队通过深度的调研发现
问题的根源并不只是单一维度上的技术缺陷
而是上下文窗口、模型切换、指令遵循等多个环节的协同失衡
比如
模型的上下文窗口无法充分保留用户的历史信息
导致用户在倾诉自己的心情之后
只需要进行十轮的对话
前面的内容就会被遗忘
自动切换器在情感交流中
偶尔也会突然切入推理模式
让共情的回应戛然而止
取而代之的是理性分析
造成了强烈的体验割裂感
针对这些痛点
GPT 5.1进行了全链路的优化
在上下文管理方面
扩大了用户历史信息的存储和调用范围
确保模型能够长期记住用户的情绪状态、偏好设置和关键经历
让互动具备了更好的延续性
在模型切换方面
建立了风格一致性的校验机制
即使在不同模型间的切换之间
也能保持回应的语气、情感的浓度和表达逻辑的连贯
避免出现前一秒共情
后一秒冰冷的情况
更重要的是
GPT 5.1还强化了指令遵循的能力
通过优化自定义指令功能
模型能够稳定的保留用户的个性化设定
当用户指出，这样不对
停一下的时候
模型会及时调整并且记住修正的方向
Laurentia强调
每个模型都可以有自己的小怪癖
但是关键在于要让用户能够控制它和纠正它
如果模型无法保存这些指令
就会让用户感到不受重视
这种对用户反馈的精准回应
让GPT 5.1从技术驱动转向了用户体验驱动
真正实现了让模型的回应因你而生
人格
是GPT 5.1研发中的一个核心议题
也是最具挑战性的领域之一
在OpenAI的定义中
模型的人格包含了两个维度
包括表层的回应风格和语气
以及深层的整体使用体验
涵盖了用户界面设计、响应速度、模型切换的逻辑、上下文的刷新方式等等
所有会影响用户感知的元素
正如Laurentia所说的
如果把ChatGPT比作一个陪伴式的角色
那么它的人格就包括它今天穿什么鞋、穿什么毛衣等等
是所有体验的总和
而OpenAI的研发团队所面临的核心难题是
怎么样在不破坏可控性的前提下
既保留模型的个性特质
同时又能够满足八亿用户的多样化需求
早期的模型，要么是过度的标准化
导致所有用户都会得到千篇一律的回应
要么就是个性失控
出现不符合用户预期的小怪癖
而GPT 5.1通过风格与特征的个性化功能
给出了一个破局方法
那就是用户可以自主的引导模型
采用自主偏好的表达方式
从非常高雅到非常简单
从书呆子风格到乡村口音
使得模型能够在极大范围内调整表达的形态
这种个性化的背后
是后训练阶段精密平衡的艺术
Christina透露
团队在构建奖励函数的时侯
需要在推理能力、情感共鸣、事实准确性、可控性等多个相互影响的目标间
反复的调校
比如
既要让模型具备高度探索性的书呆子风格
又要确保它在专业场景中不会出现表达错误
既要允许模型使用符合语境的表情符号
又要避免过度娱乐化导致的信息传递错误
这不像数学题一样有固定的答案
Christina说
我们处理的很多任务
都没有唯一的最佳答案
只能在模糊的目标之间进行取舍
尽量让模型更加自然、更加贴合用户的需求
Laurentia还分享自己的一个亲身经历
生动诠释了个性化的价值
她的哥哥是一名生化研究博士
最初使用GPT 5.1的时候
认为模型回答的像是本科大学生写的
但是在设置了前沿实验室研究者的身份后
模型随即给出了和他实验室还没有发表的
成果一致的突破性想法
这个案例证明
模型的核心能力其实早就已经存在了
而个性化功能
正是解锁这些能力的钥匙
人工智能的安全和可用性
始终是一对需要动态平衡的矛盾
ChatGPT的早期版本因为过于担心滥用的风险
采用了过度禁止的策略
在面对模糊请求时
会频繁的回应“我不能这样做”。
虽然这样保障了安全
却严重削弱了实用性
Christina坦言说
如果我们的目标只是要做一个最安全的模型
那么只要让它拒绝所有的请求就可以了
但是那不是我们真正想做的
我们希望模型真正的有用处
因此，GPT 5.1的突破在于
将安全边界从固定的规则转向了情境化的判断
团队意识到
不同领域对敏感内容的需求
存在着天壤之别，在法律场景中
律师处理性侵案件时
需要模型保留暴力、非自愿性行为等细节证据
否则就会削弱当事人的案件说服力
而在私人沟通中
模型必须拒绝生成报复性邮件等有害内容
因此，安全的核心不是禁止什么
而是理解什么时候可以做什么
这种情境化能力的实现
依赖于模型对语境、用户身份和使用场景的深度理解
通过强化奖励模型对用户信号的捕捉
GPT 5.1能够分析请求背后的真实意图
同样是描述暴力的行为
学术研究中的案例分析和恶意煽动中的细节渲染
会得到完全不同的回应
Laurentia强调
这是一项需要长期演进的技术能力
我们需要让模型学会理解复杂的人类世界
而不是用简单的禁止来逃避问题
随着模型智能水平的提升
它在主观领域的表现
也正在成为新的挑战
用户不仅需要模型在客观事实的问题上
坚持真理
更期待在没有标准答案的场景中
获得开放、灵活的回应
GPT 5.1在这个领域的改进
主要体现在了两个方面
一是主动表达不确定性
当面对没有明确答案的问题时
不再强行给出唯一的结论
而是提供一个多元化视角和探索方向
二是包容用户的各类想法
即使是小众的观点或者创新性的思考
也能得到尊重和延伸
这种转变的背后
是OpenAI对最大化用户的自由、最小化用户的伤害
这个核心原则的坚守
Laurentia解释道，如果我们在训练时
对模型施加过强的限制
那么用户在需要某种表达的时候
就永远无法得到它
研究的艺术在于
如何处理那些让模型看起来有点怪的特质
却又不会破坏用户的可控性
也不会剥夺用户的自由
在创造力领域
GPT 5.1的开放特性尤为突出
模型不再局限于默认的文风
而是能够根据用户的需求
在极大范围内调整表达的风格
这样既可以写出高雅的学术论文
也能够创作通俗易懂的儿童故事
既可以用严谨的逻辑来分析问题
也能以浪漫的笔触来抒发情感
这种隐藏却强大的创造力
为用户提供了前所未有的表达支持
记忆功能
是GPT-5.1实现个性化陪伴的核心技术之一
Christina将它定义为
模型会把从对话中得知的、有关用户的事情
记录下来，以便在未来使用
这些信息包括用户的身份职业、偏好风格、历史经历、情绪状态等等
无需用户在每次对话中重复的介绍
比如，用户只需要告知一次
我是一名小学教师
偏好简洁易懂的表达
模型就会在后续的课程设计、家长沟通等场景中
自动适配这个需求
记忆功能的价值
不仅在于让对话更加连贯
更在于为推理提供关键的上下文信息
当用户询问
如何设计适合三年级学生的科学实验时
模型会结合小学教师的身份
以及之前讨论过的、课堂时间有限等约束条件
给出更具有针对性的方案
为了保障用户的控制权
GPT 5.1的记忆功能设计了完善的透明机制
用户可以随时查看、修改或者删除模型存储的记忆信息
也能在设置中关闭记忆的功能
从而确保隐私安全
Laurentia强调
模型应该主动的理解用户
但是用户永远掌握着主导权
因此，透明和可控
是记忆功能能够被信任的前提
如果说记忆是个性化的基础
那么主动性就是人机关系升级的关键
GPT 5.1通过Pulse等功能
打破了从用户提问到模型回答的传统模式
让模型能够主动的感知用户需求
提供潜在的帮助
这种主动性并不是无的放矢
而是基于对用户记忆、兴趣和场景的深度理解
它可能是为职场人士整理的会议纪要
为创作者推送的灵感素材
为学习者规划的学习路径
让模型从等待指令的工具
转变为一个可以预判需求的伙伴
主动性功能的研发
源于OpenAI对于人机关系的洞察
未来的智能系统不应该只是被动的执行命令
而是应该成为能够与人类共同成长的协作伙伴
Laurentia指出
当研究团队在上游做好模型的能力和评估标准后
产品团队就能基于这些能力
开发出更强大的主动性功能
这也让用户能够更加充分的利用模型的能力
拓展人机协作的边界
随着用户需求的多样化
千人千面将成为人工智能的一个核心发展方向
Christina表示
GPT 5.1的个性化功能只是一个起点
未来模型的可定制化程度将会持续深化
OpenAI如今有超过八亿的周活用户
绝不可能让一个统一的人格去满足所有人
随着模型变得越来越智能
它也会变得越来越可定制
让每个人都能拥有自己想要的体验
这种定制化的能力
将贯穿从表达风格到核心能力的全维度
用户不仅可以调整模型的语气、语速、表达方式
还能定义模型的专业领域、思考深度、协作模式
比如
科研人员可以定制一个严谨型的科研伙伴
专注于数据分析和文献解读
创业者可以定制一个创新型的商业助手
擅长趋势预判和方案设计
家长可以定制一个温和型的育儿顾问
注重情感引导和知识启蒙
定制化的终极目标
是让智能系统成为用户的延伸
完美契合个人和场景的独特需求
对于未来的发展图景
Christina用了“智能将会从廉价到无法计量”这句话来描绘
OpenAI的目标
是要打破智能服务的阶层壁垒
让每个人都能接触到顶尖的人工智能能力
目前
GPT 5.1已经将推理模型开放给了免费用户
未来还将通过技术优化和生态拓展
进一步的降低智能服务的使用门槛
这种普惠化不仅会体现在用户层面
更能赋能各行各业的创新
这就如同大语言模型的发展轨迹一样
模型能力每提升一次
就会解锁新的使用场景
新的场景又会催生出新的产品形式
未来
智能模型可能会被嵌入教育、医疗、工业、农业等各个领域
成为普通人工作生活的基础设施
Laurentia对此充满了期待
她认为这些模型的能力
已经强大到了令人难以置信
迫不及待的想看到用户会用它们去构建些什么
在交互方式上，除了文本对话以外
语音、图像、手势等多模态的交互方式
将会更加自然和流畅
模型能够精准捕捉用户的情绪变化和隐含意图
在应用场景上
从个人助手到团队协作工具
从知识获取到创意生成
从日常沟通到专业决策
模型将深度融入到各种场景中
成为一个无形却不可或缺的协作伙伴
在产品形态上
可能会出现针对特定人群的垂直产品
比如面向老年人的智能陪伴设备
面向创作者的创意生成平台
以及打破现有边界的创新产品
比如沉浸式学习系统和虚拟协作空间等等
关于如何解锁GPT 5.1的全部潜力
Laurentia给出的核心建议是
用你最难的问题去测试模型
也就是那些你最熟悉、最有专业知识的问题
作为一个前滑雪竞速运动员
她经常会用“怎么样能够滑得更好呢？
”这类专业话题，来测试模型
从而清晰感知它的进步轨迹
对于普通用户来说
可以用自己擅长的领域来进行提问
这样既能够快速的判断模型的能力边界
也能获得最有价值的回应
模型在专业问题上的深度分析
往往也能带来新的启发
OpenAI的模型正处于快速的迭代中
三个月前无法完成的任务
如今可能已经实现了突破
因此，用户不应该因为一次尝试失败
就否定模型的能力
而是应该持续探索、反复测试
无论是代码编写、应用开发
还是文案创作、学术研究
都可以定期重新进行尝试
感受模型的进化
Christina则建议用户多向模型提问
比如应该怎么写提示词
随着训练数据的积累
模型在引导用户优化提示词方面的能力
已经得到了显著的提升
通过和模型的互动
用户可以掌握更加有效的提问方式
比如明确任务的目标、提供上下文信息、设定回应的风格等等
从而最大化模型的输出价值
另外
用户可以充分利用风格和特征功能
定制模型的表达风格
通过自定义指令来设定长期的偏好
让模型更为贴合个人需求
同时，合理的使用记忆功能
主动告知模型一些关键信息
比如职业、需求、禁忌等等
可以减少重复沟通，提升互动的效率
当遇到体验方面的问题时
最有效的反馈方式是分享完整对话的链路
包括模型的版本、上下文的状态、互动的过程等元数据
让OpenAI团队能够进行精准的诊断和优化
从 GPT 5 到 GPT 5.1 的进化
我们看到的不仅是技术方面的迭代
更是人工智能发展理念的趋向成熟
智能的终极价值
也许不在于它能够做多少事情
而在于它能够如何理解人类
当模型能够读懂你的沉默、共情你的情绪、呼应你的期待时
人机关系就会进入一个新的境界
两者之间
不再是工具和使用者的对立
而是平等协作、相互成就的共生关系
感谢收看本期视频，下期再见
