大家好，这里是最佳拍档，我是大飞
前几天
有观众在评论中留言想了解GPU租赁市场的情况
巧的是
SemiAnalysis正好发布了一篇关于GPU租赁的深度报告
今天我就来和大家详细聊聊这里面的门道
提前预警
这期节目可能过于干货
建议大家躺在床上收听，有助睡眠
最近这两年
随着人工智能应用的不断拓展
对GPU的需求呈爆发式增长
很多企业和开发者为了降低成本、提高效率
选择租赁GPU
这就催生了庞大的GPU租赁市场
不过
这个市场如今也发生了一些变化
早期，GPU租赁市场那叫一个狂热
大家都争着入局
但是如今
它已经实实在在地转向了买方市场
特别是Hopper和MI300级别的GPU
市场上的参与者越来越多
目前有超过100家新兴云服务商和超大规模云服务商Hyperscaler
都提供了GPU租赁的服务
这么多选择
却没有一个明确的“租赁指南”，
也缺乏独立的评估标准
这可让不少用户犯了难
为了解决这个问题
SemiAnalysis花了12个月的时间
构建了GPU云的一个评级系统
简称ClusterMAX
这个系统对100多家GPU云服务商
从多个维度进行了评估和分级
就像是给市场上的服务商们做了一次全面的“体检”。
它不仅独立进行测试
还收集了大量的客户反馈
目前已经覆盖了90%以上的GPU租赁市场份额
ClusterMAX评级分为五个等级
从高到低依次是铂金（Platinum）、金牌（Gold）、银牌（Silver）、铜牌（Bronze）和不合格（UnderPerform）
每个等级都有着明确的评判标准
先来说说最高等级铂金
可能会让大家想不到的是
目前只有CoreWeave一家达到了这个级别
CoreWeave是目前唯一能够可靠运营万级H100集群的非超大规模云服务商
在安全性上
它早期采用的多租户Kubernetes命名空间隔离方案
已经被淘汰
现在使用的是更加安全的单租户Kubernetes集群模式
为每个租户分配独立的集群
从而有效防范了容器逃逸漏洞所带来的风险
在集群的生命周期管理方面
它的操作也非常严格
在部署阶段
所有节点都要经过高温环境下的NCCL测试和ib_write_bw带宽验证等烧机测试
不符合标准的节点会被自动隔离检修
在运行期间
会同步进行全面的被动健康检查和每周自动执行的主动健康检查
这些检查的结果会实时反映在可视化仪表板上
客户能够清楚看到节点的健康状态
在调度系统上
它提供开箱即用的托管Slurm和Kubernetes解决方案
尤其是SUNK架构能让客户在统一的环境中调度训练和推理任务
还可以自动生成拓扑配置
优化NCCL的集体通信性能
在网络性能方面
它是全球少数几家正确配置了InfiniBand SHARP协议的服务商
能够实现网络内聚合计算
目前只有少数客户能够充分利用这个功能
像Meta、Jane Street等技术密集型企业
都把CoreWeave作为首选
就是因为它能让企业专注于模型的开发
而不用操心底层基础设施的问题
不过
CoreWeave主要面向长期租赁的大规模集群客户
如果是短期的租赁需求
可能需要考虑其他灵活性更高的服务商
金牌级别的服务商也各有优势
比如Crusoe
在过去七个月的表现十分亮眼
它的控制台UI简洁易用
让资源管理和部署都变得更加简单
当遇到GPU总线错误的时候
它能自动检测问题
预留备用节点
还会指导用户完成迁移
极大地提升了用户体验
之前Crusoe由于缺乏完全托管的Slurm解决方案
用户需要通过Terraform脚本
手动设置Slurm集群
但它的白手套服务弥补了这个不足
工程师会亲自处理Slurm部署
最近在GTC上
Crusoe还宣布了全新的托管Slurm产品“Auto Clusters”，
承诺将进一步简化用户的工作流
还会自动生成Slurm拓扑配置
优化NCCL性能
检测到不健康节点的时候也能自动替换
同时
Crusoe已经提供完全托管的Kubernetes服务
方便用户部署和扩展容器化的工作负载
不过，在监控和可靠性方面
它目前只实施了基本的被动健康检查
还没有引入自动化的每周主动健康检查
不过他们表示正在积极开发
很快就会集成到产品中
目标是达到CoreWeave的健康检查水平
在定价和合同条款方面
Crusoe提供的中短期合同很有竞争力
比较适合初创企业和部分企业客户
虽然价格和条款不如Nebius优惠
但是对于那些追求简化UI和良好用户体验的、快速发展的初创公司来说
Crusoe还是很有吸引力的
Nebius则以市场最低价格著称
它之所以能做到这一点
得益于其强大的财务优势
不仅拥有数十亿美元的资产负债表
而且没有债务负担
Nebius采用定制化的ODM机箱
选择直接与ODM合作
绕过了传统的OEM供应商
将毛利率从行业主流的10-15%降低到了大约2%，
大大降低了初始的硬件投资和持续的运营成本
它还创新性地提供将H100无缝过渡到B200部署的服务
不过，Nebius也有自己的短板
它的前身为俄罗斯的云服务商
虽然技术团队实力很强
但是在用户体验方面有所欠缺
它的按需H100 SXM GPU的价格
虽然低至每小时1.50美元
但是很多用户还是更倾向于Lambda Labs
就是因为Nebius的UI和用户体验过于复杂
不够直观
目前
Nebius提供完全托管的Kubernetes解决方案
但是还没有推出完全自动化的托管Slurm产品
他们也正在开发名为“Soperator”的Slurm解决方案
里面包含基础的被动和主动健康检查
但是还没有达到行业领先标准的水平
为了提升竞争力
Nebius还需要进一步投资
完善每周计划健康检查
推出更高级的Grafana仪表盘
Oracle Cloud Infrastructure
简称OCI
在测试中的GPU体验也很不错
被广泛认为是四大Hyperscaler中性价比最高的选择
它的GPU服务通过OCI市场
提供一键部署的“OCI HPC Stack”，
涵盖Slurm和监控功能
不过
OCI的Slurm解决方案目前还不是完全托管的
需要一到两名OCI解决方案架构师提供支持
在监控和可靠性方面，OCI表现良好
它的Slurm HPC Stack市场产品包含DCGM、Grafana监控和被动健康检查
但是缺乏高级的主动健康检查和自动化节点的生命周期管理功能
不过OCI已经确认这些功能正在开发中
预计在今年第二季度完成
OCI的自动化拓扑配置（topology
conf）支持拓扑感知调度
能够提升网络性能
这是很多新兴GPU云提供商都没有重视的功能
它的RoCE网络性能经过优化之后
可以与Spectrum-X以太网竞争
但是在某些NCCL版本上仍然存在性能回归的问题
另外
OCI的支持和服务团队以技术专业性和以客户为中心的态度著称
作为Hyperscaler
它还提供数据库、对象存储和CPU虚拟机等全套服务
用户不用在不同的云平台间迁移数据
而且
长期租赁OCI的计算资源通常还会附带市场合作机会
帮助客户扩展业务
在安全性方面，OCI也表现出色
提供企业级标准的安全措施
包括强大的租户网络隔离、基于RoCEv2结构的VLAN隔离
以及基于InfiniBand结构的PKEY隔离
TogetherAI在GPU云市场中也表现突出
它的集群服务本身达到了ClusterMAX 银牌的水平
但是凭借卓越的支持和技术专长
最终被评为金牌级
TogetherAI的团队由Flash Attention的发明者特里·道领导
它们的Together Kernel Collection（TKC）可以显著提升客户的性能
此外
它还提供直观的托管Slurm和Kubernetes解决方案
用户通过仪表盘就能够轻松的部署
作为英伟达的合作伙伴
TogetherAI能在早期获取到新的硬件
还与英伟达在合作开发优化内核
不过
TogetherAI目前缺少Slurm环境中进行容器管理的Pyxis插件
也缺乏全面的被动健康检查和每周计划的主动健康检查
默认的Grafana仪表盘也比较基础
目前
TogetherAI由于依赖于其他GPU云提供商的基础设施
导致问题解决可能会略有延迟
但是他们计划在今年内部署自有的硬件
摆脱对外部供应商的依赖
LeptonAI由PyTorch的联合创始人创建
它并不直接拥有GPU
而是提供机器学习平台软件层
来管理GPU和进行健康检查
用户可以选择通过LeptonAI租赁GPU
也可以直接从Nebius等服务商租用GPU
再购买LeptonAI的平台支持
LeptonAI为训练任务提供了类似Slurm的作业提交方式
用户稍作调整就能够适配
它的控制台仪表盘能够可视化节点的生命周期
功能仅次于CoreWeave的仪表盘
在被动健康检查方面
LeptonAI会运行自身的开源解决方案“gpud”，
覆盖了大多数的被动检查项目
还支持手动主动健康检查
但是没有提供每周自动计划检查和参考性能数据
LeptonAI的Beta功能包括零影响NCCL分析器
用户只需勾选复选框就能启用
从而帮助可视化集群操作瓶颈
优化网络性能
接下来我们看看银牌级别的GPU云提供商
这些服务商在性能、安全和价值方面表现尚可
但是和金级、铂金级比起来
还是有明显差距
AWS的GPU云基础设施的可靠性不错
但是网络性能长期落后于InfiniBand和Spectrum-X以太网
尽管AWS通过EFAv3网络改进缩小了差距
但是在实际NCCL测试中
还是比不上顶级方案
AWS提供名为Hyperpod的托管Slurm和Kubernetes解决方案
简化了集群部署
但是缺乏自动化的主动健康检查
比如NCCL测试、TinyMeg2检测等等
监控仪表板的功能也比较基础
Lambda Labs以按需GPU实例受到开发者欢迎
但是用户体验存在着不少问题
比如，实例启动时间长达10分钟
而Crusoe只需30秒
而且它的默认CUDA工具路径设置错误
Lambda提供托管Kubernetes服务
但是Slurm解决方案还不完善
缺乏Pyxis插件等关键功能
虽然其技术团队承诺改进
但是目前仍缺乏自动化健康检查和高级监控仪表板
Firmus/Sustainable Metal Cloud（SMC）
专注于可持续的AI创新
采用了浸没式冷却技术
宣称H100的功耗低于风冷方案
在MLPerf训练中表现优异
但是在实际测试中发现
其GPU的温度比标准风冷高了10°C
导致性能降低了1-2%。
SMC是少数支持InfiniBand SHARP的提供商之一
但是由于技术门槛较高
客户没有充分利用这项功能
它的主要问题包括缺少自助部署选项和自动化健康检查
也没有提供基础的Grafana仪表板
Scaleway的Slurm和Kubernetes解决方案
结合了VAST Data高性能文件系统
适合AI和HPC工作负载
其技术团队对英伟达Pyxis等插件支持良好
但是由于使用了镀金DGX Hopper机箱
导致总拥有成本（TCO）较高
Scaleway需要改进的地方
也包括缺少自助部署工具和自动化健康检查
以及基础监控功能不足
还有一些银牌提供商，像DataCrunch
它的单节点按需实例适合开发
但是生产集群不适合训练和推理；
TensorWave的托管Slurm和Kubernetes还处于测试阶段
正在开发健康检查功能
未来有可能升到银牌
铜牌级别的GPU云服务提供商
满足了基本的要求
但是在多个关键评估领域存在明显的不足
Google Cloud就是一个典型的例子
长期以来
它提供的GPU服务在网络性能和开箱即用功能方面
表现不佳
2024（口误）年4月起
Google Cloud就一直在努力“追赶”。
2023年8月推出的H100产品“a3-high”，
每节点网络带宽只有800Gbit/s
而当时其他竞争对手大多都能提供3.2Tbit/s的网络速度
这让很多使用a3-high的客户非常不满
这个阶段可以称为“完全不合格阶段”。
意识到问题后
Google Cloud推出了“a3-mega”，
将每节点网络带宽提升到了1.6Tbit/s
但还是比竞争对手慢50%。
根据NCCL的测试结果
在实际消息大小上
Google Cloud的性能比竞争对手慢两倍
在端到端训练性能上也受到影响
比如在Llama 70B训练中MFU降低了10%，
在8x7B混合专家稀疏模型中
MFU降低了15-20%。
而且，这个产品长期不支持LL128协议
导致实际NCCL网络的性能更差
用户需要设置复杂的环境变量
才能让NCCL网络和插件正常工作
而且它的Slurm方案也存在漏洞
难以设置
这个时期可以称为“追赶阶段”。
2025年1月
Google Cloud推出了a3-ultra实例
每个节点提供3.2Tbit/s的RDMA以太网网络与ConnectX-7网卡
终于让网络带宽接近了竞争对手
不过
在实际NCCL的集体网络性能上还是略逊一筹
而且a3-ultra的每个rail组大小仅为4个节点
而其他很多提供商为32个节点
这导致进行集体操作时需要更多跳数
产生更多拥塞，性能下降
目前
大多数GCP客户和GPU资源仍在使用A3-Mega
意味着大多数客户仍然面临网络性能不佳的问题
使用A3-Mega时性能会降低10-20%。
到2025年中期
GCP将推出最新的A4 B200和A4X GB200实例
纸面规格将与其他竞争对手竞争
还会继续改进并推出新的软件功能
SemiAnalysis预计到2025年中期
GCP将完成“追赶”阶段
有望为行业树立标杆
重新赢得客户信任
达到ClusterMAX金牌或者铂金级别
虽然Google Cloud目前好存在一些问题
但是它的安全性是一流的
包括正确实施了租户网络隔离和传输中加密
而且它作为完整的云服务
还具有Bigtable、数据库、对象存储和并行文件系统等产品
方便进行数据处理
其他铜牌级别的提供商
有的没有非测试版的Slurm或Kubernetes产品
有的提供的产品存在漏洞或者没有正确设置
一些提供商直到上个月才获得SOC2合规认证
经过测试
DataCrunch的按需单节点产品很适合开发工作
TensorWave的测试版托管Slurm和托管Kubernetes产品正在开发被动和主动健康检查
未来有可能达到银牌级别
最后是不合格级别的GPU云服务提供商
这部分的服务商主要是没能满足基本得行业标准和关键评估指标
普遍存在严重问题
包括安全措施不足、可靠性差、技术支持有限
以及误导性营销
很多这一级的提供商甚至缺乏基本的安全认证
比如SOC2或ISO 27001
一些不合规的服务商在数据存储和传输过程中
甚至没有采取有效的加密措施
租户的敏感数据如同在“裸奔”，
极易受到黑客攻击和恶意窃取
在可靠性方面
这些不合格的服务商也表现糟糕
服务器频繁出现故障
缺乏有效的故障预警和快速修复机制
客户提交的作业常常无故中断
却没有得到及时通知和妥善处理
有用户反馈
在使用某不合格服务商的GPU进行重要模型的训练时
训练到一半突然中断，而且无法恢复
之前投入的大量时间和计算资源付诸东流
严重影响了项目进度
在技术支持方面，几乎处于缺失状态
客户遇到问题的时候
很难找到专业人员进行咨询和解决
邮件回复不及时
在线客服要么无人响应
要么对技术问题一问三不知
此外
还有些服务商还存在误导性营销行为
宣传时声称拥有高性能的GPU集群
但是实际提供的设备性能远低于承诺标准
网络带宽也严重缩水
用户满怀期待地租用
却发现根本无法满足自己的业务需求
造成了经济损失
了解完这些不同等级的GPU云服务提供商
我们再把目光转回到市场价格趋势上
自2024年10月以来
H100的租赁价格持续下降
目前已经从每小时3.5美元
降到了1.5美元左右
这背后有多方面的原因
一方面，英伟达的产能不断提升
市场上的GPU供应越来越充足
另一方面
很多大型买家的战略发生了转移
像Meta之前大规模采购GPU
现在更倾向于将资金投入到软件和模型的研发上
对租赁市场的需求减少
这就使得租赁市场的竞争更加激烈
同时
大量新进入者带着新的硬件进入市场
进一步加剧了价格战
比如GB200，虽然它的价格相对较高
但是性能比H100有了显著提升
在相同计算任务下
GB200能节省更多时间和成本
这也促使H100不得不降低价格来维持竞争力
在租赁模式上
市场上主要有按需租赁、抢占式租赁和合约租赁三种方式
按需租赁灵活性高
用户可以根据实际需求随时租用和退还GPU
适合一些短期的、对时间要求不高的项目
但是价格相对较高
通常会比合约租赁高出30%-50%。
抢占式租赁的价格最低
不过稳定性较差
服务商可能会随时收回资源
适合一些容错性较强的任务
比如数据预处理等等
合约租赁则介于两者之间
用户通过签订长期合同
能获得相对较低的价格
适合长期、稳定的项目
除了价格和租赁模式
在选择GPU云服务时
还有很多关键要素需要考虑
安全性是重中之重
必须确保服务商具备完善的安全措施
比如数据加密、网络隔离等
防止数据泄露和恶意攻击
生命周期管理也很重要
从硬件的部署、运行到维护
都要有严格的流程和标准
调度系统要高效，能够合理分配资源
提高GPU的利用率
存储性能和网络性能也不容忽视
高速的存储和网络能加快数据传输和处理速度
提升训练效率
可靠性方面
要选择那些服务器故障率低、能提供及时故障修复的服务商
技术合作伙伴关系也很关键
与NVIDIA、AMD等芯片巨头有紧密合作的服务商
往往能更早获得新硬件
并且在技术支持和优化方面更有优势
对于AMD和英伟达
SemiAnalysis也给出了一些建议
认为AMD应该加强对合作伙伴的审核
确保他们提供的GPU云服务质量
同时应该改进对Slurm的支持
提升用户体验
而英伟达则可以公开更多的配置文档
让用户更好地了解和优化硬件性能
此外，还可以进一步优化SHARP等技术
提高网络性能
总的来说
当前的GPU租赁市场正处于一个变革期
价格下降、服务质量参差不齐
SemiAnalysis推出的ClusterMAX GPU云评级系统
为市场提供了一个重要的参考标准
无论是对服务商提升自身服务水平
还是对用户选择合适的租赁服务
都有着极大的帮助
如果有想了解更多细节的观众
建议去阅读SemiAnalysis的原文
感谢大家观看本期视频
我们下期再见
