大家好，这里是最佳拍档，我是大飞
半个月前
Meta发布了他们的开源大模型Llama3.1
在社区中引起广泛关注和讨论
现在一周的时间过去了
热度逐渐退潮
舆论逐渐降温
整个Llama3家族的技术报告也公开出来
报告数据更新到了Llama 3.1
正是理性地来审视一下这款大模型的好时候
经常有人问我怎么去学习大语言模型
有哪些相关技术
我觉得模型的技术报告就是一个很好的索引
因此
虽然网上已经有很多关于Llama 3.1技术报告的解读
我决定还是从另一个视角去看它
把它当作是一次梳理大语言模型相关技术的机会
基于这篇 LLama 3.1的技术报告
今天我们将从模型参数、基础设施、预训练、后训练这四个方面
来详细的剖析Llama3系列模型
希望大家能够耐心看完
相信一定能有所收获
之前各路媒体，也包括大飞自己
在报道Llama3.1的时候
都喜欢强调模型高达405B的庞大参数
这个数字固然抢眼，但是
我们有没有想过
为什么Llama 3.1要堆如此庞大的参数呢？
要知道
如今已经不再是纯粹的规模为王的时代了
如果考略经济效益和便携性
小模型的市场表现也并不会差多少
405B的庞大参数让很多的个人开发者望而却步
即便这样
Llama3.1还是折腾了一个巨无霸出来
而这次的技术报告就为我们揭露了这背后的原因
那就是Meta希望通过Scaling Law
来确定旗舰模型的最佳大小
但是存在两个挑战
一是现有的Scaling Law通常只能预测下一个词的损失
而不能预测特定基准的性能；
二是Scaling Law可能会因为小计算量的预训练
而变得嘈杂和不可靠
为了解决这些挑战
Meta 希望通过一个两阶段的方法
来实现能够准确预测下游基准性能的Scaling Law
首先
他们需要找到最优模型在下游任务上
负对数似然和训练FLOPs之间的相关性
然后再利用Scaling Law模型和使用更高计算FLOPs训练的旧模型
将下游任务上的负对数似然
与基准任务的准确率相关联
具体做法是这样的
首先保证6 × 10^18 FLOPs到10^22 FLOPs之间的计算预算
然后在这个预算下
通过预训练模型来构建Scaling Law
在训练过程中
Meta还使用了余弦学习率计划
预热了2000个训练步骤
峰值学习率根据模型的大小
设置在了2 × 10^-4到4 × 10^-4范围之间
此外，还将余弦衰减设置为峰值的0.1
将每一步的权重衰减
设置为该步骤学习率的0.1倍
范围在250K到4M之间
实验结果产生了如图所示的IsoFLOPs曲线
并且这些曲线中的损失是在单独的验证集上测量的
Meta 还使用了二度多项式来拟合测量的损失值
并且以此来确定每个抛物线的最小值
再将这个最小值
称为对应预训练计算预算下的计算最优模型
通过这种方法
Meta 就可以利用计算最优模型
来预测指定计算预算下
最佳的训练token数量
实验结果显示，随着计算预算的增加
IsoFLOPs曲线在最小值附近变得逐渐平坦
这意味着旗舰模型的性能
对于模型大小和训练token 之间的权衡
变得相对稳健
基于这个观察结果
Meta 最终决定训练一个具有405B参数的旗舰模型
然而
405B的庞大参数不是说训练就能训练的
Meta还必须找到能够稳定运转这个庞然大物的硬件架构和基础设施
Llama 1 和 2 模型
是在 Meta 之前的 AI 超级集群上训练的
但是眼下这个超级集群还远远达不到405B的预期目标
最终，Meta整合了24000多块H100
重新搭建了生产集群
其中16000个用于Llama 3的预训练
所有这些GPU 都运行在 700W 热功耗TDP下
配备了 80GB 的HBM3
使用 Meta 的 Grand Teton AI 服务器平台
每个服务器配备了八个 GPU 和两个 CPU
在服务器内部
八个 GPU 通过 NVLink 连接
模型的训练还使用了Arista 7800 交换机和 Minipack2 OCP交换机
采用RoCE网络拓扑结构
通过三层 CLOS 网络连接
在底层，每个机架托管着 16 个 GPU
分布在两台服务器上
并且通过一个 Minipack2 机架顶部交换机连接
在中间层
192 个这样的机架通过集群交换机连接
形成了一个拥有 3072 个 GPU 的 pod
具有完整的双向带宽，确保不会过载
在顶层
同一座数据中心大楼内的八个 pod
通过聚合交换机连接
最终形成了24000个 GPU 的集群
虽然目前还比不上马斯克的十万卡集群
但是Meta的这个生产集群也算的上是世界上最贵的集群之一了
GPU还只是这个集群的底子
为了保证大模型能够老老实实地把学到的知识记到脑子里
Meta 的研究人员还采用了分布式文件系统
构建了 Llama 3 预训练的存储网络
它可以提供高达 240PB 的存储空间
由配备了 SSD 的 7500 台服务器支持
并且支持每秒2TB的持续吞吐量和每秒7TB的峰值吞吐量
通过这一系列的设置
Meta希望能够将检查点期间的 GPU 暂停时间最小化
同时增加检查点的频率
从而减少恢复后丢失的工作量
现在这个集群算是搭得差不多了
但是庞大的规模也带来了其他挑战
比如说负载均衡
由于大语言模型的训练会产生大量的网络流量
而这些流量很难使用传统的方法
比如说 等价多路径路由ECMP来进行负载均衡
为了解决这一挑战
Meta采用了两种技术
首先
Meta的集合库会在两个 GPU 之间创建 16 个网络流
而不是仅仅一个
从而减少每个网络流的传输量
并且提供更多的网络流进行负载均衡
其次
通过采用增强等价多路径路由E-ECMP协议
对 RoCE 数据包头中额外的字段进行哈希
从而有效地在不同的网络路径上平衡这 16 个网络流
另外，拥塞控制也是一个大麻烦
在训练的过程中
运行速度慢的服务器会引起持续的拥塞和网络压力
这些现象都会导致训练效率上的损耗
对此
Meta采用了深缓冲deep buffer交换机
在骨干网络上进行了部署
从而降低由于集合通信模式引发的瞬间拥塞和缓冲
避免了使用像数据中心量化拥塞通知DCQCN
这样传统的拥塞控制方法
现在
基础设施和解决方案都准备齐了
对于405B这个巨无霸的训练
Meta可以说是势在必行
然而，意料之外的情况还是发生了
16000个 GPU训练的复杂性和潜在故障
远远超过了之前更大规模的CPU集群
由于AI模型训练的同步性质
导致整个集群对于故障的容忍度很低
单个GPU的故障可能就需要重启整个作业
在54天的预训练期间
集群总共经历了466次作业中断
其中，47次是计划内的中断
主要是自动化的维护操作
比如升级固件、启动作业
或者更新配置和数据集等等
其余419次是意外的中断
其中大约78%都出于确认的硬件问题
比如GPU或主机组件故障
以及疑似与硬件相关的问题
比如静默数据损坏和计划外的主机维护
而GPU的问题又是最多
占所有意外问题的58.7%。
不过，尽管经历了大量的故障
在整个训练期间
只有三次故障需要显著的手动干预处理
其余问题都被自动化处理给解决了
为了增加有效训练时间
Meta还使用了几套用来快速诊断和解决问题的工具
首先是Pytorch 内置的 NCCL飞行记录器
这项技术可以将集合通信的元数据以及堆栈信息
捕获到环形缓冲区中
从而允许维护人员快速诊断系统挂起以及性能的相关问题
尤其是与 NCCLX 相关的问题
利用这个功能
Meta可以有效地记录每个通信事件
以及每个集合通信操作的持续时间
并且可以在 NCCLX 看门狗或者心跳检测超时的时候
自动导出跟踪数据
通过在线配置更改技术
Meta还可以在不需要代码重新部署或者任务重启的情况下
实时并且选择性地启用
更复杂的跟踪操作和元数据收集
此外
由于网络中混合使用了 NVLink 和 RoCE
使得大规模训练的调试变得很复杂
通过 NVLink 传输的数据
通常会通过 CUDA 内核发出 加载和存储操作
而远程 GPU 或 NVLink 连接中的故障
通常会表现为 CUDA内核的加载和存储操作停滞
但是并不会返回明确的错误代码
而通过 NCCLX 与 PyTorch 紧密的集成设计
使得 PyTorch 能够访问 NCCLX 的内部状态
追踪相关信息
从而提高了故障检测和定位的速度和准确性
虽然无法完全防止由于 NVLink 故障导致的停顿
但是系统会监控通信库的状态
并且在检测到这类停顿的时候自动超时
此外
NCCLX 还会跟踪每个 NCCLX 通信的内核以及网络活动
并且提供失败的集合通信内部状态快照
包括所有等级之间已完成和待处理的数据传输
通过分析这些数据
就可以来调试 NCCLX 的扩展问题
有些时候
硬件问题也会导致训练任务变慢
但是不会失败
这是由于采用了同步训练模式
所以单个异常节点会导致所有节点都变慢
为了解决这个问题
Meta还开发了相关的工具
可以从选定的进程组中
筛选出有问题的通信
再通过重点调查几个主要的可疑对象
有效地识别出慢节点
同时
Meta的训练人员也发现了一个有趣的现象
那就是环境因素对大规模训练性能的影响
在训练405B 模型的过程中，每天中午
吞吐量都会有 1%到2% 的变化
研究人员认为
这大概是由于中午温度升高的原因
此外，在训练的过程中
当同时启停任务
或者所有 GPU 都在等待 检查点保存或者集合通信完成的时候
可能会导致数以万计的 GPU 同时增加或减少功耗
这就会让整个数据中心的电力消耗
瞬间波动数十兆瓦
逼近电网的承载极限
而随着模型和集群规模的扩大
这也将是一个持续的挑战
尽管集群的运行麻烦不断
但是Meta最终还是完成了训练
在全新的生产集群上
Meta训练了一系列的基础模型
统称为 LLaMA 3
这个系列的大模型天然支持多语言、代码、推理和工具使用
其中最大的模型是一个稠密的 Transformer 模型
包含 405B 参数量
最大可以支持 128K 的上下文长度
这个系列的模型一共包含 8B、70B 和 405B 3 种规模
以及 LLaMA 3 和 LLaMA 3.1 两个版本
每个版本都了提供 Base 模型和 Instruct 模型
相比于Llama 2
LLaMA 3 系列模型也使用了GQA
都是 8 个 KV头
其中8B 模型是4个注意力头共享1个 KV头
70B 模型是 8 个注意力头共享 1 个 KV 头
而405B 模型是 16 个注意力头共享 1 个 KV Head
可见GQA 可以明显的减少 KV缓存
熟悉大模型的观众应该清楚
大语言模型的训练一般会包含两个关键的阶段
一个是预训练Pre-Training
主要处理下一个token的预测
一个是后训练Post-Training
主要是训练模型在SFT、DPO方面的能力
以及集成新的能力
我们先来谈一下llama 3的预训练阶段
在这个阶段
训练用的数据可谓是重中之重
Llama3.1的预训练数据包含了截至 2023 年末的各种数据源
然后针对每个数据源进行了多次去重和数据清洗
这样不仅可以保证获得高质量的 Token
同时也会删除大量个人身份信息和成人内容
预训练数据中不同数据源的数据混合比例
也是影响模型质量非常关键的因素
为此，论文作者开发了一个分类器
用来对网络数据进行分类
为了确定最佳的数据混合方案
作者还进行了Scaling Law实验
具体来说
就是在数据混合上训练几个小模型
然后使用它们来预测大模型在这个混合比例上的性能
经过对不同的数据的多次混合测试
选择出新的数据混合比例
最后
在这个数据混合上训练一个更大的模型
评估这个模型在几个关键基准上的性能
最终
混合数据集中包含大约 50% 的一般知识token
25% 的数学和推理 Token
17% 的代码 Token
以及 8% 的多语言Token
为了提升Llama3的多语言能力
Meta团队还训练了一个专门处理多语言数据的专家模型
同时收集和生成了高质量的多语言指令调优数据
涵盖德语、法语、意大利语、葡萄牙语、印地语、西班牙语和泰语
并且尽量避免使用机器翻译的数据来微调模型
从而防止翻译腔、可能的名称偏见、性别偏见以及文化偏见
论文作者还发现
通过对数据混合进行退火
也就是在选定域中对高质量数据进行上采样
可以将预训练的 LLaMA 3.1 8B
在 GSM8K 和 MATH 评估集上的性能提高 24.0% 和 6.4%。
但是，这对 405B 模型的改进很小
说明405B 模型已经具备了强大的上下文学习能力和推理能力
与此同时，作者还发现
退火可以帮助判断小型特定领域数据集的价值
这比对每个小数据集进行缩放实验更加有效
确定好了预训练数据
就可以准备正式开始预训练了
405B 模型的预训练
采用了余弦学习率计划
峰值学习率为 8 × 10^-5
线性预热 8000 步
然后在 1200000 个训练步骤内
衰减到 8 × 10^-7
研究人员发现在训练初期
使用较小的批量大小可以提高训练得稳定性
随后再增加批量大小，从而提高效率
具体来说
Meta最初使用了4M个token 的批量大小和 4
096 的序列长度
然后在预训练了 252M 个token之后后
翻倍到 8M 个toekn和 8
192 的序列长度
在预训练了 2.87T 个token之后
再次将批量大小加倍到 16M
Meta 发现这种训练方法非常稳定
损失峰值很少
并且不需要干预来纠正模型训练发散的问题
与预训练阶段数据为主不同
后训练阶段的基础则是奖励和微调模型
比如使用人类标注偏好数据训练的 奖励模型
以及监督式微调 SFT和直接偏好优化DPO
最后的 DPO 模型再用于下一轮的训练
llama3 的后训练总共进行了 6 轮迭代
其中每一轮都会进行SFT和DPO
最终获得了与人类反馈一致的模型
基于最后 405B 的检查点
Meta训练了一个涵盖不同能力的奖励模型
并且使用偏好数据进行了奖励建模
其中标注被划分成了4个偏好等级
分别是明显更好（significantly better）、更好（better）、略好（slightly better）和勉强更好（marginally better）
具体的数据分布如图所示
接下来
研究人员使用奖励模型对人工标注的提示进行了拒绝采样（Rejection Sampling）
然后将拒绝采样数据和其他数据源合并
再使用标准的交叉熵损失
对预训练语言模型进行了监督式微调
其中405B模型是在8.5K到9K步的过程中
以10^-5的学习率进行微调
在 SFT 之后
Meta进一步使用 DPO 对 SFT 模型进行训练
以便与人类的偏好对齐
相比于PPO
DPO 针对大参数模型的计算量更少
并且性能更好
此外，为了提高 DPO 训练的稳定性
研究人员还对 DPO 做了一些修改
比如在 DPO损失中
屏蔽特殊格式的 Token
并且添加了一个额外的负对数似然损失项
对被选择的序列进行正则化
缩放系数为0.2
在后训练结束后
我们再介绍一些关于Llama3模型推理的内容
405B 模型如果想要使用 FP16 推理
至少需要 810GB 的显存
至少要两台装有8个H100的服务器
如果服务器之间有 NVLink 和 NVSwitch 高速互联
可以使用张量并行
而如果服务器之间的带宽比较低
时延比较长，则需要使用流水线并行
然后再使用微批处理来提高吞吐量
而405B的FP8 推理
使用 1台服务器即可部署
因此完全可以采用张量并行的方案
经过测试
FP8推理不仅能够让预填充阶段的吞吐量提高50%，
而且在解码阶段
也能够获得更好的的吞吐量-延迟权衡
好了
以上就是llama3.1技术报告里一些关键部分的内容啦
由于时间关系
大飞对报告的内容进行了一定的取舍
原文链接我会放到视频简介里
感兴趣的朋友可以自行阅读
感谢大家的观看，我们下期节目再见
