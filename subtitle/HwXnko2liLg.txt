大家好，这里是最佳拍档，我是大飞
在当前的 GPU 市场格局中
NVIDIA 一直处于领先地位
而 AMD 则在不断努力追赶
近期
SemiAnalysis 发布了一篇极具深度的分析文章
对 AMD 和 NVIDIA 的 GPU 进行了全方位的实测性能对比
这为我们揭示了许多不为人知的细节
而且AMD 的苏妈也跟文章作者谈了一个半小时
认为作者给的反馈很重要
足以说明这篇文章的含金量
今天我们就来给大家分享一下
我们先来看看这两家的三款备受瞩目的 GPU
分别是AMD MI300X、NVIDIA H100 和 H200 的基本参数
从参数表中可以清晰地发现
AMD MI300X 在某些方面似乎更具优势
它的功耗（TDP）为 750 瓦特
略高于 NVIDIA H100 和 H200 的 700 瓦特
但是在系统整体功耗方面
三者均为每 GPU 1275 瓦特
在内存容量上，MI300X 拥有 192GB
远超 H100 的 80GB 和 H200 的 141GB
内存带宽方面
MI300X 达到了每秒 5300GB
也高于 H200 的 4800GB 和 H100 的 3352GB
在浮点运算性能上
无论是半精度浮点数（FP16/BF16）还是 8 位浮点数（FP8/FP6/Int8）
MI300X 的理论 TFLOPS 都高于 NVIDIA 的这两款产品
然而
实际的性能表现却并不是完全与参数成正比
接下来我们进入到通用矩阵乘法（GEMM）性能的测试环节
通用矩阵乘法在训练像 ChatGPT、Llama 和 Claude 等大型模型的时候
占据了绝大部分的浮点运算次数
它的性能的高低
对 GPU 处理前沿AI模型训练工作负载的能力
有着关键的指示作用
在这次基准测试中
测试人员采用了Llama 70B 的生产训练通用矩阵乘法
涵盖了融合的（Q）、（K）、（V）投影
注意力输出投影
以及前馈网络等多种复杂的运算形状
并且使用了来自OpenAI 的业界标准“do_bench”函数
确保在每次运行之间清理缓存
从而在多次重复之后获取可靠的中间结果
在BF16性能测试中
NVIDIA 的 H100/H200 官方标称的是 989 TFLOP/s
实际达到了大约 720 TFLOP/s
而 AMD 的 MI300X 的标称高达 1307 TFLOP/s
但是实际只能达到大约 620 TFLOP/s
这使得 MI300X 在半精度浮点数工作负载方面
比英伟达的 GPU 慢了 14%。
在 FP8性能测试中
NVIDIA 的 H100/H200 标称的是 1979 TFLOP/s
实际能达到大约 1280 TFLOP/s
而（口误：AMD） 的 MI300X 却仅能达到约 990 TFLOP/s
比英伟达的 GPU 慢了 22%。
这背后的软件难题不容忽视
为了在 MI300X 上取得较好的测试结果
用户必须依赖 AMD 工程师特制的自定义 Docker 镜像
并且要设置许多复杂的环境参数
在开箱即用的情况下
AMD 芯片的性能表现与经过精心调优后的结果相差甚远
在测试过程中
作者还发现了 AMD GPU 存在一些严重的 bug
比如，“torch.matmul”和“F.Linear”的API之间
由于底层库（“hipBLASLt”与“rocBLAS”）的差异
导致性能出现明显的不一致
不过
在 SemiAnalysis 报告了这个问题后
AMD 迅速采取行动修复了这个bug
此外
像“PYTORCH_TUNABLE_OPS”这类实验性的功能特性
虽然在一定程度上有助于提升性能
但是也极大增加了用户操作的复杂性
用户往往需要花费几个小时
手动调整通用矩阵乘法
才能获得相对合理的性能
而且 AMD 的 hipBLASLt/rocBLAS 启发式模型
经常会错误地选择算法
这与英伟达的cuBLASLt 库能够自动为大多数矩阵形状
选择最优的开箱即用算法
形成了鲜明的对比
同时，在 AMD 上进行FP8训练
最初还会引发段错误和其他一系列的问题
即便在修复之后
在公开的发行版本中
FP8的性能在某些情况下仍然比BF16要慢
这里SemiAnalysis 还对斯塔斯·贝克曼（Stas Bekman）所做的基准测试提出了批评
斯塔斯·贝克曼声称 MI300X 的性能接近 H100
但是SemiAnalysis 指出他的测试存在着严重的缺陷
主要包括在各次迭代之间
没有清理二级缓存
以及报告的是最大性能而非多次运行后的中间值或平均值
这些因素导致测试结果严重偏离了实际情况
接下来
我们再来看看 HBM 内存带宽方面的测试
AMD 的 MI300X 凭借192GB的 HBM3 内存
提供了每秒 5.3 TB/s的内存带宽
高于英伟达 H200 的每秒 4.8TB/s
以及 H100 的每秒 3.35 TB/s
内存带宽的提升对于推理任务非常关键
在某些情况下对训练也有一定的帮助
特别是在处理大规模批量数据的时候
但是，在实际的训练工作负载中
虽然 MI300X 理论上拥有更高的内存带宽
应该能让用户设置更大的批量规模
但是实际上当全局批量规模超过一定阈值的时候
可能会对模型的收敛时间产生负面影响
因为更大的批量往往需要更多的迭代次数
才能实现最优的模型性能
尽管 MI300X 在基准测试中展现出了更好的原始内存带宽
但是由于存在软件效率低下和计算能力受限等其他瓶颈
所以这个优势在训练过程中
并不总是能转化为更快的训练时间
不过在推理工作负载中
由于模型需要快速访问和处理存储在内存中的数据
MI300X 的高带宽内存确实更具有优势
在单节点训练方面
英伟达的 GPU 表现出了强大的实力
开箱即用就能提供出色的性能
而 AMD 的 MI300X 则需要大量的调优和漏洞修复工作
才能在性能上具备一定的竞争力
在测试中
作者使用了包括 GPT-1.5B、Llama3 8B、Llama3 70B 4层代理以及 Mistral 7B v0.1 等基准模型
在使用公开的稳定版本时
英伟达的 H100 和 H200 在所有模型上的性能
都显著优于 AMD 的 MI300X
比如在 GPT-1.5B 这个相对简单的模型上
英伟达的 GPU 性能比 MI300X 高出 2.5 倍以上
即便使用 AMD 12 月 21 日的构建版本
MI300X 的性能也难以与 H100 和 H200 相媲美
在 Mistral 7B（非因果注意力模型）上
由于 MI300X 缺乏对FlexAttention机制的支持
所以表现得非常吃力
而英伟达GPU 所提供的性能几乎是 MI300X 的两倍
不过
在 Llama3 8B 和 Llama3 70B 代理模型上
使用12月21日的构建版本
MI300X 展现出了一定的竞争力
在 Llama3 70B 代理模型上甚至略微优于 H100
但是这是通过一个公众无法获取的实验性开发分支来实现的
在 FP8训练方面
起初在 MI300X 上进行FP8训练
会遇到段错误和其他问题
而且在某些情况下速度比BF16还慢
经过修复之后，虽然性能有所提升
但是仍然只局限于特定的定制镜像
在多节点训练场景中
AMD 的 MI300X 面临着更为严峻的挑战
与英伟达的 H100 相比
由于网络硬件、软件库以及垂直整合方面的差异
MI300X 在有效扩展方面困难重重
在这次的基准测试中
作者针对 AMD 的 MI300X 和英伟达的 H100 GPU 进行了双节点配置的测试
在网络配置方面
英伟达采用了InfiniBand网络的 NDR（400G）
或者搭配 BlueField-3 网卡的 Spectrum-X 以太网；
AMD 则采用带有博通 Thor-2 网卡的 RoCEv2 以太网
在单网络集合操作中
英伟达在所有对分布式训练至关重要的集合操作
比如all_reduce、all_gather、reduce_scatter等方面
都表现出了明显的优势
H100更是凭借着每秒 450GB 的 NVLink 交换拓扑结构
以及NVLink SHARP特性
展现出了卓越的性能
而 AMD 的 MI300X 因为xGMI 点对点拓扑结构
单个 GPU 对之间仅能提供每秒 64GB 的带宽
表现欠佳
在横向扩展网络方面
英伟达的InfiniBand SHARP通过在交换机内部执行 Reduction操作
有效减少了网络流量
极大地提升了可扩展性
相比之下，AMD 缺乏类似的能力
随着 GPU 数量的增加
性能会迅速下降
对于实际应用中的消息大小
比如16 MiB到256MiB
英伟达的 H100 始终比 AMD 的 MI300X 性能高出 2 倍或者更多
而对于更大的消息大小
比如8 GiB和16GiB
AMD 虽然能接近峰值带宽
但是仍落后于英伟达
在扩展方面
MI300X 所采用的 RoCEv2 以太网与英伟达的InfiniBand和 Spectrum-X 方案相比
扩展性较差，随着 GPU 数量的增加
性能明显下降
这使得 AMD 在大规模训练集群应用中处于劣势
此外
AMD 在软件方面还面临着许多的挑战
在 RCCL 与 NCCL 的对比中
由于 AMD 工程师缺少可用的计算资源
只有不到32个MI300X用来研发
而相比之下
英伟达的 NCCL 团队能够使用拥有11000 个 GPU 的集群进行研发
这使得他们在软件优化方面具有巨大的优势
在垂直整合方面
英伟达在硬件和软件库方面做到了紧密整合
而 AMD 缺乏类似的垂直整合
只能依赖像博通 Thor-2 这样的第三方网卡
除此以外
在早期版本的 PyTorch 实现中
AMD 在注意力层存在着重大漏洞
导致反向传播的运算速度极其缓慢
低于每秒 20 万亿次TFLOP/s
甚至比CPU 还慢
经过好几个月的艰苦努力
包括漏洞报告和反复修复
这些问题才得以解决
在FlexAttention的支持方面
英伟达的 GPU 从 2024 年 8 月起
就已经支持这个机制
而截至 2024 年 12 月
AMD 的产品上还只是部分可用
这使得AMD 在处理使用非因果注意力机制的模型上
处于明显的劣势
为了让AMD的训练正常工作
用户必须依赖“PYTORCH_TUNABLE_OPS”参数
对通用矩阵乘法内核进行长时间的手动调优
这极大地拖慢了研究人员的迭代周期
与英伟达开箱即用而且运行流畅的 cuBLASLt
形成了巨大的反差
此外
要想让 MI300X 达到合理的性能
还需要手动设置众多复杂的环境参数
严重影响了易用性
在派生库方面
AMD 使用了一种名为“Hipify”的工具
用来将英伟达的 CUDA源代码
转换为AMD 的 HIP 代码
从而将英伟达的软件库适配到自己的硬件上
虽然这样做能让 AMD 迅速构建起一个可用的软件栈
但是也带来了许多的限制
在性能上，AMD 的派生库
比如Rocm和RCCL的优化程度远不如英伟达的对应库
还有就是AMD 依赖英伟达TransformerEngine 的派生版本
来进行FP8的训练
但是 AMD 的 GPU 对FP8的支持并不完善
导致单元测试无法通过
而且也没有建立起CI/CD的管道
来确保功能的稳定性
在兼容性方面
派生库常常会面临兼容性的问题
比方说
由于支持不完善而且缺乏测试
PyTorch 原生的 FP8训练方案
在 AMD 硬件上无法很好地运行
同时
在英伟达 GPU 上已经可用的功能
往往需要几个月时间
才能在 AMD 的硬件上正常运行
在原生开发方面
AMD 没有大力投入原生开发
而是严重依赖对英伟达开源库的适配
这限制了AMD独立创新的能力
并且对英伟达的生态系统产生了依赖
面对这些问题
Semianalysis也为AMD提出了一系列的改进建议
首先是增加内部计算资源
由于AMD 的工程师用来测试和开发的内部 GPU 集群资源有限
阻碍了他们有效识别和解决软件漏洞的能力
报告建议 AMD 应当在内部
为 PyTorch 的CI/CD管道部署数千个
甚至更多的 MI300X和MI325X GPU
同时为工程师提供访问大规模集群的权限
以便测试多节点训练和提升 RCCL的性能
此外
报告还建议引入严格的Regression 测试和功能测试
以便在公开版本发布前发现问题
同时可以创建一个公开的仪表盘
用来跟踪每日的性能基准测试情况
来保证系统的透明度
在增强易用性方面
建议将最优的环境参数设为默认值
从而简化开箱即用的体验
同时消除对像“PYTORCH_TUNABLE_OPS”这类
需要花费几个小时来手动调优的prototype功能
并且提供包含所有必要的库和工具的预构建 Docker 镜像
类似于英伟达的 NGC 镜像
同时对公开镜像进行标准化处理
与工程师内部使用的VIP镜像保持一致
此外，与 Meta的合作也不容忽视
Meta 现在还没有将 MI300X GPU 用来训练生产环境的工作负载
这导致在PyTorch 的 ROCm 中
存在一些未经测试、漏洞百出的代码路径
而且AMD 到现在
还没有提交任何 MLPerf 训练基准测试结果
另外，由于薪酬普遍低于英伟达
AMD 很难吸引顶尖的软件工程人才
所以报告建议 AMD 应该提供有竞争力的薪资和福利
来吸引世界级的工程师
最后，AMD 应当投入精力
去构建专门针对自身硬件的原生解决方案
而不是完全依赖对英伟达生态系统的适配
彻底解决不尽如人意的性能以及兼容性问题
总结来说
通过SemiAnalysis这次深入的分析和对比
我们可以清晰地看到 AMD 目前在 GPU 领域
与 NVIDIA还存在着较大的差距
而且主要问题集中在（口误：软件）层面
包括功能性、性能和易用性等各个方面
当然
NVIDIA 在这个领域已经深耕多年
积累了深厚的技术底蕴和生态优势
而 AMD 发力时间较短
想要在短时间内与之抗衡
确实困难重重
不过，相信随着时间的推移
AMD 有可能会逐步地解决这些问题
提升自身产品的竞争力
在这里，大飞我想多说两句的是
相比之下，国内的GPU 发展时间更短
技术水平在现阶段
可能连AMD都还不如
但是在网上
我们时常能看到一些夸大其词的言论
声称某些国产 GPU 已经能与英伟达比肩
甚至遥遥领先，显然是不客观的
更何况，软件的护城河
其实比硬件还要高
所以希望国内的相关厂商
能够保持清醒的头脑
正确认识到我们与国际先进水平的差距
脚踏实地地推动技术进步
也建议大家在做相关投资的时候
尽量擦亮眼睛
不要被诱导性的文字所迷惑
最后人财两失
好了，大飞我能力有限
建议大家还是去看原文
感谢大家观看，我们下期再见
