大家好，这里是最佳拍档，我是大飞
今天的视频包含两部分内容
一个是o3-mini模型的发布
一个是Sam Altman罕见忏悔
承认自己在开源AI上站错了队
我们一一来说
2月1日凌晨，在DeepSeek的压力之下
OpenAI发布了全新的推理模型o3-mini
并且号称这是OpenAI最具成本效益的推理模型
不仅复杂推理和对话的能力显著提升
在科学、数学、编程等领域的性能表现超过前代o1模型
同时保持了o1-mini的低成本和低延迟
并且可以与联网搜索功能搭配使用
目前o3-mini已经在ChatGPT和API中可以使用
并且向所有ChatGPT免费用户提供
在ChatGPT中选择“Reason”按钮即可使用
企业版的访问权限将在一周内推出
ChatGPT Pro用户可以无限制的访问o3-mini
而Plus和Team用户的速率限制
从原来o1-mini的每天50条消息
增加到了每天150条消息
付费用户还可以选择更为智能的版本“o3-mini-high”，
不过需要更长的时间才能生成响应
和o1模型一样
o3-mini模型的知识截止日期为2023年10月
上下文窗口为20万个token
比DeepSeek R1的13万token略多
每个输出最多10万个 token
跟满血版o1相同
并且提供了低（low）、中（medium）、高（high）三个版本
可供开发者针对特定的场景进行优化
美中不足的是
o3-mini还不支持视觉功能
因此开发者仍然需要使用o1进行视觉推理任务
在API方面
现在o3-mini已经在Chat Completions API、Assistants API、Batch API中推出
每百万输入token为1.10美元
每百万输出token为4.40美元
让OpenAI比较尴尬的是
虽然这个价格比GPT-4已经降低了95%，
但是还是要比DeepSeek R1模型
高出一倍以上
在发布o3-mini的同时
OpenAI还发布了37页的技术报告
涵盖了模型介绍、数据训练、测试范围、安全挑战和评估、外部红队测试、准备框架评估、多语言性能以及结论等多个方面
我们这里简单来解读一下
首先，在性能上
o3-mini针对科学、数学、编程推理进行了优化
同时响应速度更快
在GPQA Diamond、AIME 2022-2024、Codeforces ELO基准测试中
o3-mini的分数分别为0.77、0.80、2036
比肩或者超过o1推理模型
在14种语言的MMLU测试集上
o3-mini的表现显著优于o1-mini
展示了在多语言理解方面的进步
外部专家测试人员的评估表明
与o1-mini相比
o3-mini的答案更准确、更清晰
推理能力更强
在人类偏好评估中
测试人员在56%的时间里
更喜欢o3-mini的回答
并且观察到在困难的现实问题上
重大错误减少了39%，
并且在中推理能力下
o3-mini在一些最具挑战性的推理和智力评估上
表现与o1相当
在A/B测试中
o3-mini的响应速度比o1-mini快24%，
平均响应时间为7.7秒
而o1-mini为10.16秒
数学方面，在低推理能力下
o3-mini在数学方面的表现与o1-mini相当
在中推理能力下
o3-mini的表现与o1相当
而在高推理能力下
o3-mini的表现优于o1-mini和o1
在FrontierMath测试上
具有高推理能力的o3-mini在第一次尝试时
解决了超过32%的问题
其中包括超过28%的T3高难度问题
随着推理能力的增加
o3-mini逐渐能获得更高的Elo分数
优于o1-mini
而且在中推理能力下，表现与o1相当
编程方面，在SWE-bench测试中
o3-mini是OpenAI表现最好的模型
其中o3-mini (tools) 性能最好
为61%。
o1是表现第二好的模型，得分为48%。
而在LiveBench编程测试中
高推理能力的o3-mini得分全面超过了o1-high
相信一定有朋友想知道
o3-mini和DeepSeek R1相比如何
不过已经有国外网友进行了对比
总的来说
o3-mini在整体性能方面只比DeepSeek R1具有微小的优势
其中在2024 AIME基准测试中
o3-mini仅在高推理强度下表现优于R1
在以编程为重点的SWE-bench Verified基准测试中
o3-mini同样仅在高推理强度下
以0.1分的微弱优势领先R1
不过，在低推理强度下
o3-mini在博士级科学问题GPQA Diamond基准测试中
落后于R1
最关键的是，o3-mini是闭源的
而DeepSeek R1是开源的
此外，OpenAI还在技术报告中
详细介绍了o3-mini在多个安全评估中的表现
称o3-mini在具有挑战性的安全性和越狱评估方面明显超越了GPT-4o
其中，在不允许的内容评估中
o3-mini在标准拒绝评估和挑战性拒绝评估中
与GPT-4o表现相似
但是在XSTest中略逊一筹
在越狱评估中
o3-mini在生产越狱、越狱增强示例、StrongReject和人类来源的越狱评估中
与o1-mini表现相当
在幻觉评估中，使用PersonQA数据集
o3-mini的准确率为21.7%，
幻觉率为14.8%，
与GPT-4o、o1-mini相比
表现相当或者更好
在公平性和偏见评估中
o3-mini在BBQ评估中的表现与o1-mini相似
但是在处理模糊问题时的准确性略有下降
此外，外部红队测试显示
o3-mini在与o1的比较中表现相当
两者都显著优于GPT-4o
在灰天鹅竞技场（Gray Swan Arena）的越狱测试中
o3-mini的平均用户攻击成功率为3.6%，
比o1-mini和GPT-4o略高
在网络安全方面
o3-mini被评为“低风险”，
在CBRN
也就是化学、生物、放射性、核
以及说服力和模型自主性方面
o3-mini被评为“中等风险”。
按照评级
只有缓解后得分为“中等”或以下的模型才可以部署
得分为“高等”或以下的模型才可以进一步开发
总的来说
o3-mini的发布并没有让大家感到任何兴奋
反倒像是对DeepSeek的仓促应战
而就在o3-mini上线几小时后
OpenAI官方开启了Reddit AMA大约1小时左右的在线问答
Altman本人也上线
回答了网友们的很多问题
这里我挑一些精华的回答跟大家分享下
首先是大家最关心的关于DeepSeek的焦点问题
有用户表示显然这是一个非常令人印象深刻的模型
这会如何改变OpenAI对未来模型的计划
Sam Altman此前对于DeepSeek评价很高
这次也给出了类似的评价
他回复称，这是一个非常好的模型！
我们将生产出更好的模型
但是领先优势将比前几年有所减弱
鉴于DeepSeek在开源领域取得的成功
有人问OpenAI是否考虑发布一些模型权重并发表一些研究？
Sam Altman对此回应称，是的
我们正在讨论
我个人认为
我们在这里站在了历史的错误一边
需要找出一个不同的开源策略
OpenAI中并非所有人都认同这一观点
这也不是我们当前的最高优先事项
这似乎是Sam Altman首次正面承认
OpenAI的闭源“是一个错误”。
但是OpenAI是否会真正开源？
这恐怕将是一个艰难的选择
第二个话题集中在关于o3 mini的产品功能
首先是价格问题
有人对比发现
o3 mini的价格与Deepseek和Gemini相比仍然没有竞争力
OpenAI API研究主管米歇尔·波克拉斯Michelle Pokrass对此回应
我们发现o3-mini与美国托管的Deepseek版本相比具有竞争力
我们认为对于这种级别的智能来说
这是一个真正实惠的选择
对于OpenAI会计划提高plus会员的价格的问题
Sam Altman回应称
实际上我想随着时间的推移减少它
其次是思维链的展示问题
o3 mini并不像DeepSeek R1那样
会给出非常详细的思维链过程
而是非常简洁
于是有用户提问
我们能看看所有的思考标记吗？
首席产品官凯文·韦尔Kevin Weil回复称
我们正在努力展示比今天更多的内容
而且很快就会实现
所有内容都有待确定
展示所有CoT会导致竞争对手提取数据
但是我们也知道很多高级用户想要这个功能
所以我们会找到正确的方法来平衡它
关于o3 mini知识库的时间更新问题
有用户表示不理解
GPT-4o拥有的知识都截止到2024年6月
但是现在o3 mini知识截止时间又改回了2023年10月
为什么会这样？
Sam Altman对此回应称
现在我们已经启用了搜索功能
这一点就不再那么重要了
就我自己的使用而言
我再也没有考虑过知识截止的问题了
由于OpenAI这次发布的是o3 mini
于是有人问完整版本o3何时首次亮相？
Sam Altman一如既往开始画饼
我猜会是几周以上
几个月以下
第三个话题集中在其他产品的更新
也就是OpenAI曾经发布的“期货”产品何时兑现
有用户关心4o的图像生成器是否还会发布
这是大约一年前OpenAI宣布的功能
凯文·韦尔对此回复称，是的
我们正在努力
我认为等待是值得的
有人继续追问有没有大概的时间表
Kevin Weil先是开玩笑地说
你想给我找麻烦
随后又补充说，可能要几个月
此外
关于图像生成模型DALL-3的后续版本
凯文·韦尔也是一模一样的回复
是的，我们正在努力
我认为等待是值得的
有用户对此“千篇一律”的回复表示不满意
并且调侃道
这是GPT-3在回应吗？
有用户关注长上下文窗口的问题
询问能否很快实现1M上下文
对此
工程副总裁斯里尼瓦斯·纳拉亚南Srinivas Narayanan回复道
正在努力，但没有明确的日期表
关于很多人都关心的GPT-5
Sam Altman表示还没有时间表
凯文·韦尔则回应称
会在“o-17 micro和 GPT-(π+1) 之后不久”。
换句话说，遥遥无期
不过Sam Altman表示会有一些即将发布的更新
比如高级语音模式
最后是关于算力以及AGI相关的问题
有人问，假设现在是2030年
你刚刚创建了一个大多数人称之为AGI的系统
它在你提出的每一个基准测试中都表现出色
并且在速度和性能上都击败了你最好的工程师和研究人员
现在怎么办？
除了“在网站上提供”之外
还有其他计划吗？
工程副总裁斯里尼瓦斯回复道
我们与人工智能的交互界面将发生根本性的变化
更加Agentic
人工智能将在后台为我们持续工作
完成复杂的任务并且实现我们的目标
而Sam Altman则认为
最重要的影响是加速科学发现的速度
这是对改善生活质量的最大贡献
有人提到了芯片
问OpenAI如何看待trillium、cerebras等更为专用的芯片或者TPU？
OpenAI是否正在研究这些芯片
Sam Altman的回应很简洁
GB200现在很难被击败
还有人问
星际之门对 OpenAI 的未来有多重要？
凯文·韦尔回应称，非常重要
我们看到的一切都表明
我们拥有的计算能力越多
我们构建的模型就越好
我们制造的产品就越有价值
我们现在同时在两个维度上扩展模型
分别是更大的预训练和更多的强化学习和草莓训练
两者都需要计算
为数亿用户提供服务和更多的Agent也需要计算
所以可以把星际之门想象成OpenAI的工厂
它会将电力和GPU 转化为酷炫的产品
好了
以上就是这次OpenAI发布o3-mini的相关内容了
看上去
DeepSeek与OpenAI已经形成了两种不同的技术路线
DeepSeek代表了以低计算成本来实现高计算性能的路线
而OpenAI仍然坚持“大力出奇迹”的Scaling Laws
不知道这两种不同路线的选择
是否会成为实现AGI的分水岭
感谢大家的观看，我们下期再见
