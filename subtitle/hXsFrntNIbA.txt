大家好，这里是最佳拍档
如果你能记住你读过的一切
生活会不会变的不一样呢？
当你打开手机的收藏夹
里面躺着几十篇AI教程
上百个工具技巧
从ChatGPT 进阶玩法
到NotebookLM 全功能解析
每一篇都标注着有空一定要学
可真正回头去看
去用的，却寥寥无几
我们总觉得，收藏了就是拥有了
转发了就是学会了
仿佛只要把这些信息存在手机电脑里
它们就会自动钻进我们的大脑
等到需要的时候随时提取
可现实往往是，等到真要解决问题
比如想用AI生成一段播客
或者用无代码工具，做个简单的App时
我们翻遍收藏夹
却发现自己对那些教程的记忆
只剩下了模糊的碎片
连基本步骤都想不起来
这时候我们难免会困惑
为什么我们花了那么多的时间阅读和收藏
却还是记不住读过的内容呢？
这个问题，不仅困扰着我们普通人
也引发了全球网友的热烈讨论
在YouTube上
有一个标题为《How to Remember Everything You Read》的视频
至今已经斩获了863万的播放量
在推特上更是掀起了千万级别的热议
有网友留言说
这是他看过最实用的阅读指南
26分钟的内容
却能改变一生的学习方式
还有一位30岁的外科医生评论道
真希望他在10岁的时候
就能看到这个视频
这帮他节省了太多的时间
那这个视频到底有什么神奇之处呢？
贾斯汀・宋在视频一开头
就抛出了一个直击灵魂的问题
你为什么想要记住一切？
是为了像硬盘一样存储
还是为了像CPU一样处理呢？
我们从小到大接受的教育
似乎都是在传递一种记忆至上的观念
考试要背诵知识点
面试要记住专业术语，就连日常聊天
能引经据典出口成章的人
也总会被贴上厉害的标签
于是我们养成了一种习惯
看到有用的信息就收藏
遇到重要的内容就摘抄
总觉得记住的越多
自己就越有竞争力
但是，这种全盘接收的记忆方式
其实是在给我们的大脑增加负担
就像贾斯汀在视频里做的一个比喻
阅读信息的过程，其实分为两个阶段
分别是消费和消化
我们现在的大多数人
都只停留在消费阶段
比如快速刷完一篇文章
匆匆看完一个教程
就像在自助餐里狼吞虎咽
吃得越快
摄入的越多，就越有满足感
可是我们忘了
身体的消化能力是有限的
大脑的记忆容量也是有限的
那些没有被消化的信息
就像没有被吸收的食物一样
最终只会被排出体外
留不下任何的营养
我们疯狂地消费着网络上的各类信息
却从来没有花时间去消化它们
所以才会出现收藏了很多
却什么都记不住的尴尬局面
而更可怕的是
这种盲目记忆一切的执念
不仅不会让我们变得更聪明
反而可能会阻碍我们的思考
贾斯汀在视频里举了一个极端却真实的例子
世界上真的有能记住一切的人
他就是电影《雨人》的原型
金・皮克
他是一位罕见的学者症候群患者
他的记忆力堪称人肉百科全书
能够完整背诵1.2万本书的内容
从正文到标点符号，无一差错
他还能记住美国所有城市的高速公路编号
航班时刻表
甚至能准确说出任何一个历史事件的具体日期
这样的记忆力
恐怕是我们每个人都梦寐以求的吧
但是在处理复杂问题的时候
金・皮克的表现却还不如普通人
因为他的大脑里塞满了各种各样的死数据
这些数据占据了他全部的认知空间
让他没有办法进行逻辑推理
批判性思考和创造性联想
他能记住书本上的所有公式
却不知道如何运用这些公式
来解决实际的问题
他能背诵历史事件的时间线
却无法分析事件背后的因果关系
因此，所谓的记住一切
并不是要把我们的脑子变成一本百科全书
更不是要让我们成为一个只会存储信息的硬盘
真正有价值的记忆
从来都不是全盘接收
而是择优录取
只要记住那些能帮我们解决问题
提升认知的核心信息
而不是被无关紧要的细节所拖累
尤其是在AI时代
我们更不需要执着于记住一切
因为你的记性再好
也比不过模型的长文本记忆能力
你的反应再快
也赶不上GPU的实时运算速度
AI工具已经成为了我们的外部大脑
它们可以帮助我们存储海量的信息
随时供我们调用
在这样的背景下
人类大脑的核心竞争力
已经从存储信息转向了处理信息
也就是如何筛选
消化和运用，那些真正有价值的信息
而贾斯汀・宋提出的PACER系统
正是一套帮助我们的大脑
实现精准消化的信息处理工具
它就像一个智能的过滤器
能够帮我们把杂乱无章的信息分门别类
用最适合的方式去吸收
让每一份阅读都能产生实际的价值
那么，PACER系统到底是什么？
它是五个英文单词的首字母缩写
分别对应五种不同类型的信息
而且每种信息都有专属的消化方式
贾斯汀说
这就像我们处理不同的食材一样
肉类需要腌制炖煮才能入味
蔬菜需要清炒凉拌才能保持鲜嫩
主食需要蒸煮焖炸才能饱腹
不同的食材有不同的烹饪方法
不同类型的信息也有不同的记忆逻辑
首先是P类信息，也就是程序性信息
这类信息的核心是如何做
它告诉我们完成一件事的具体步骤和操作流程
比如编程教程，软件使用指南
临床检查步骤
还有我们平时看的AI工具实操教程
都属于这一类
这类信息具有极强的实操性和时效性
软件会更新
流程会优化
单纯的抄写和记忆，根本跟不上变化
因此，贾斯汀给出的消化方式是
实践，而且是越早应用越好
看到这类教程，千万不要犹豫
也不要想着先收藏起来，以后再学
现在
立刻，马上打开对应的软件
跟着教程一步步试玩一把
比如你看到一篇用 ChatGPT 生成短视频脚本的教程
那就立刻打开 ChatGPT
输入教程里的提示词
跟着步骤调整参数
优化内容，直到生成一个完整的脚本
你可能会说，我现在没时间
等有空了再弄不行吗？
可是，等到有空
永远是一个模糊的概念
而且人的记忆是有衰减周期的
你现在看完教程不实践
过几天就会忘记大半
到时候再想捡起来
反而要花更多的时间
而当你亲手去实践的时候
情况就完全不一样了
你的手指在键盘上敲击的动作
眼睛看到的界面反馈
大脑对每一个步骤的理解和调整
都会形成一种肌肉记忆和场景记忆
这种记忆比你抄在笔记本上的文字
要牢固得多，哪怕过了很久
你可能忘记了具体的步骤
但是只要打开软件
那种操作的感觉就会回来
你能凭着记忆，快速找回正确的方法
所以对于程序性的信息，只看不练
等于白看，实践才是最好的记忆方式
接下来是A类信息，类比性信息
这类信息的核心是与你已知的事物相关联
它是用我们熟悉的概念和经验
去解释新的知识
帮助我们快速理解陌生的领域
比如我们在学习AI的相关知识时
经常会遇到一些抽象的概念
如果直接去看技术定义
很容易一头雾水
但是如果用一个熟悉的类比
就能瞬间豁然开朗
比如
DeepSeek 推出深度思考模式的时候
很多人不理解深度思考到底是什么意思
有人做了一个类比
这就像学生在做数学题时
不再是凭直觉口算
而是会拿出草稿纸一步步的演算
虽然过程变慢了
但是计算的准确性大大提高了
这种类比性信息的消化方式
贾斯汀称之为审辩
也就是批判性地审视这个类比
它们在哪些方面相似？
又有哪些不同？
为什么要用这个类比来解释呢？
很多人在看到一个好的类比时
只会觉得
哦，原来是这样
然后就把类比当成了知识本身
却没有深入思考类比背后的逻辑
可实际上，类比只是一种桥梁
它的作用是帮我们从已知领域
走到未知领域
但是桥梁本身并不是目的地
比方说
如果把AI的联网功能比作一个会用百度的实习生
这个类比在查找资料和验证信息方面
是相似的
但是我们也要看到不同之处
实习生可能会偷懒
会错误的理解需求
而AI的联网搜索是基于算法的
效率更高，也更加客观
此外，实习生可能需要有人指导
才能筛选出有效的信息
而AI可以通过自身的模型
对搜索结果进行初步的甄别
只有我们批判性地去分析
这个类比的相似点和不同点
才能真正理解AI联网功能的本质
而不是仅仅记住一个表面的比喻
所以，遇到类比性信息的时候
不要只停留在听懂了的层面
要多问自己几个为什么
这样才能把类比背后的知识
真正内化为自己的东西
然后是C类信息，也就是概念性的信息
这类信息的核心是，是什么和为什么
它包括各种理论，原理
概念之间的关系
是帮助我们理解事物底层逻辑的知识
比如
为什么AI会出现一本正经地胡说八道的情况？
为什么AI生成的图片里
有时候会出现六根手指？
为什么大语言模型能理解人类的自然语言呢？
这些都属于概念性的信息
这类信息的特点是抽象，难懂
但是一旦理解了
就能帮我们看透很多现象的本质
是构建我们认知体系的核心
也正是因为它们很抽象
所以这类信息也是最容易被忘记的
很多人学习概念性信息的时候
喜欢做一种线性的笔记
把书本上的定义和原理
一条条抄下来，然后反复背诵
可是这种方法的效果，其实并不好
因为概念之间是相互关联的
线性的笔记会割裂它们之间的联系
让我们只能记住孤立的知识点
而无法形成一个完整的知识网络
贾斯汀建议
学习概念性信息的消化方式是利用构图
也就是用思维导图
逻辑图等方式，重构这个知识网络
比如我们要理解AI 幻觉这个概念
单纯去背诵它的定义
其实并没有什么用
过不了多久就会忘记
但是如果我们用构图的方式来理解
情况就不一样了
我们可以在脑子里画一张图
把AI比作一个超级版的手机输入法
它的工作原理不是理解语言
而是预测语言
它会根据之前训练过的海量文本
预测下一个最可能出现的字
词，或是句子
就像我们用手机输入法打字的时候
它会根据我们输入的前几个字
给出后续的联想词
AI生成内容的过程
其实就是一个不断预测的过程
它并不知道自己说的是不是事实
只是在根据概率预测下一个的内容
让整个文本看起来连贯，合理
而当AI的训练数据中存在矛盾信息
或者它遇到了自己没有学过的内容时
它依然会按照概率去预测
这时候就会出现胡说八道的情况
也就是 AI 幻觉
我们还可以在这张图上补充
AI没有真实的意识
它无法像人类一样去验证信息的真实性
它只是一个纯粹的预测机器
当我们用这样一张逻辑图
来理解AI 幻觉的概念时
不仅能记住是什么，还能理解为什么
而且各个知识点之间的联系也会非常清晰
就像一张网一样，印在我们的脑子里
下次再遇到AI生成错误信息的情况
我们就能立刻用这个逻辑图去分析原因
而不是仅仅觉得AI 又出错了
这就是构图的力量
它能帮我们把抽象的概念具象化
把孤立的知识点网络化
让记忆变得更加牢固，理解更为深刻
接下来是E类信息，也就是证据性信息
这类信息是支撑某个概念或观点的具体案例
数据
事实，比如新闻里提到的
DeepSeek V3.2在数学考试中考了多少分
Sora生成的视频达到了多少的分辨率
这些都属于证据性的信息
这类信息的特点是具体，直观
能够让观点更有说服力
但是同时也具有很强的时效性和局限性
因为新的模型不断出现
旧的数据很快就会被刷新
所以具体的数字其实并没有那么重要
贾斯汀给出的消化方式是
储存与复述
但是这里的储存
并不是要储存具体的数字
而是储存数字背后的核心结论
以及复述这个结论对我们的意义
这些核心的结论
才是证据性信息真正有价值的部分
它们能指导我们的实际行动
而具体的数字
只是支撑这个结论的临时证据
最后是R类信息，也就是参考性的信息
这类信息是那些琐碎的
在需要时能快速找到的工具性的信息
比如某个AI画图工具的具体指令
某个网站的网址
软件的参数设置，快捷键列表等等
这类信息的特点是
不需要我们理解背后的原理
只需要在需要的时候能够快速调用即可
而且它们数量多，更新快
用大脑去记忆完全是一种浪费
所以
处理参考性信息的消化方式很简单
那就是把它们丢进收藏夹
看到有用的参考性信息时
不要想着我要记住它，而是要想着
我要把它放在一个容易找到的地方
你可以把AI工具的指令大全
存进手机的备忘录中
把常用的网站链接
添加到浏览器的书签里
关键是要建立一个属于自己的信息检索系统
让这些参考性信息有固定的存放位置
等到需要用的时候
能在一分钟内快速找到
这比你花几个小时去背诵它们
然后用的时候还要冥思苦想
显然会高效得多
贾斯汀在视频的最后说道
学习是有生理极限的
你刷得信息越快，如果不消化
最后留下的就越少
在这个信息爆炸的时代
我们最缺的不是新的资讯
而是信息的留存率
PACER 系统看似很慢
实则是一种更为高效的慢
它让我们把时间花在消化信息上
而不是消费信息上
当我们用实践去消化程序性的信息
用审辩去消化类比性的信息
用构图去消化概念性的信息
用提取结论去消化证据性的信息
用整理收藏去消化参考性的信息时
我们虽然花了更多的时间在每一条信息上
但是每一条信息都能真正被我们吸收和利用
成为我们认知体系的一部分
这才是信息最重要的意义所在
感谢收看本期视频，我们下期再见
