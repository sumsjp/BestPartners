大家好，这里是最佳拍档，我是大飞
最近
在第六届国际分布式人工智能会议DAI 2024（Distributed Artificial Intelligence Conference）上
现代强化学习的奠基人Rich Sutton教授
发表了题为《去中心化神经网络》（Decentralized Neural Networks）的主旨演讲
直击当前人工智能发展的瓶颈
那就是深度学习的局限性
他认为，这种局限性所带来的问题
包括灾难性遗忘、可塑性丧失以及模型坍塌等现象
已经严重影响了人工智能的持续学习能力
成为了深度学习迈向更高阶段的巨大障碍
我们之前做过一期视频
萨顿也提到了深度学习的问题
认为未来的发展方向是持续学习
为了应对这些棘手的问题
这次演讲中萨顿教授提出了“去中心化神经网络”的全新概念
它的核心思想是赋予每个神经元独立的目标
比如向其他神经元传递有效信息、保持自身活跃等等
通过在保持“骨干”神经元稳定性的同时
鼓励“边缘”神经元进行积极地探索
从而增强整个网络的适应性和持续学习能力
最终实现一种动态平衡
萨顿教授还分享了他的创新算法
持续反向传播
在每轮反向传播过程中
这个算法会依据神经元的活跃度
选择性地重新初始化部分神经元
从而有效提升模型的灵活性和学习效果
实验数据表明
在多个持续学习任务中
持续反向传播算法的表现优于传统反向传播方法
为持续学习领域开辟了一条新的路径
接下来
今天大飞就来给大家分享一下这次演讲的核心内容
我们先来了解一下当前深度学习和人工神经网络所面临的具体问题
通常情况下
我们在深度学习中进行训练的时候
往往只是训练一段时间之后
就停止并且冻结系统
所以可能不会遇到一些与延长训练相关的问题
但是如果我们的目标是打造一个能够持续学习、不断适应新环境的Agent
那么这些问题显然就无法回避
首先
根据萨顿教授团队在《Nature》杂志上发表的论文内容
深度学习在持续监督学习中会失去可塑性
以经典的 ImageNet 数据库为例
它包含数百万张、涵盖了一千个类别的名词图片
每个类别至少有 700 张图片
因此在这个数据库上进行的实验
可以清晰地揭示出问题所在
研究人员做了这样一个实验
要求神经网络区分鳄鱼和吉他这两个类别
当区分任务接近完成的时候
又让网络忘记之前学习到的知识
转而区分另外两个类别
如此循环往复
在这个过程中
研究人员通过测试集和训练集来衡量网络的性能
也就是计算测试集中正确分类的百分比
并且在多次运行中取平均值
同时不断改变测试集中的配对组合
实验结果显示，在测试集上
当步长设置为 100 的时候
正确率大约为 89%。
如果减小步长
初始性能虽然会稍微差一点
但是在后续任务中能展现出一定的改进空间
然而，随着任务数量的增加
学习率和可塑性在早期任务中虽然有时会提高
但是长期来看
却会呈现出明显的下降趋势
到第 2000 个任务的时候
性能表现已经相当糟糕
甚至比直接从像素到类别进行简单线性处理的基线方法还差
尽管通过一些算法
比如对大权重进行惩罚的 L2 正则化
以及在权重中加入随机变化并结合 L2 正则化的方法
在某些情况下能取得一定的积极效果
但是深度学习在持续学习过程中的可塑性丧失问题依然严峻
其次，除了在持续监督学习中的问题
深度学习在长时间的强化学习中
也可能会出现崩溃的现象
以控制蚂蚁运动的任务为例
研究人员试图让模拟蚂蚁通过控制八个关节实现向前行走
并且根据蚂蚁的前进速度给予奖励
向后滑动则给予惩罚
在数百万个时间步长的训练过程中
使用标准的 PPO 强化学习算法时
起初蚂蚁还能够很好地学习并且快速向前移动
但是随着训练的持续进行
它的移动能力开始逐渐退化
最终甚至不再快速行走
表现笨拙
奖励值也大幅下降，甚至跌到零以下
虽然通过调整权重
能在一定程度上延长较好表现的时间
但是继续进行长时间训练
仍然会出现同样的问题
不过，采用 LT 正则化的方法时
性能能够保持稳定，不出现退化
而持续反向传播算法则在一定程度上能够缓解这种崩溃现象
并且随着时间推移
表现相对会更好
那么
萨顿教授提出的去中心化神经网络具体是什么
又是如何运作的呢？
首先
我们要明确去中心化神经网络的定义
它是一个神经元所追求的目标与整个网络目标有所不同的网络架构
不存在中央控制器
由多个执行任务的Agent或神经元组成
最终期望形成一个强大的智能网络
比方说，整个网络在强化学习系统中
可能会致力于最大化奖励
或者在监督学习系统中
会按照训练集指示对图像进行分类
但是单个神经元可能有着不同的局部目标
比如为其他神经元提供有用的信号
或者进行自我规范化
并且在一定时间内保持活跃等等
从历史发展的角度来看
现代强化学习最初的构想
与去中心化神经网络有着紧密的联系
如果说安迪·巴托（Andrew Bartow）和萨顿教授是现代强化学习之父
那么 A·哈里·克洛普夫（A.Harry Klopf）则可以称为祖父
克洛普夫在其著作《享乐主义神经元》（The Hedonistic Neuron）中
提出了单个神经元是一个寻求目标的实体的观点
他将大脑中的神经元类比为社会中的人
认为神经元会通过寻求获得兴奋
来避免自己被抑制
这种从寻求目标的组件来构建目标寻求系统的思想
在当时极为具有开创性，应该说
克洛普夫的这个科学贡献为现代强化学习奠定了重要的基础
尽管强化学习的概念由来已久
比如马文·明斯基（Marvin Minsky）在其博士论文中就有所涉及
但是后来由于学术界对代理寻求事物的想法接受度不高
所以逐渐被监督学习所掩盖
但是克洛普夫的工作让强化学习的思想重新受到了关注
在实际的神经网络中
神经元的活动也为去中心化神经网络的构想
提供了一定的启发
通过对培养中的真实神经元
进行时间延迟摄影观察可以发现
神经元会伸出纤维
神经元的树突和轴突末端的生长锥也表明
它们在积极地尝试寻找与其他神经元的连接
并且参与到网络的构建中
这与我们设想中的神经元工作方式是相契合的
进一步支持了去中心化神经网络的理念
在去中心化神经网络中
适应是一个关键的环节
主要体现在三个层面
分别是连接线、权重和步长参数
神经元会主动伸出连接线与其他神经元建立连接
这是网络结构形成和变化的基础；
权重的调整则会直接影响神经元之间的信息传递强度；
而步长参数则决定了学习的速度
对网络的学习过程起着重要的调控作用
在传统的深度学习中
网络结构通常是一个固定的预设计分层结构
每个层具有特定的功能
与之不同的是
去中心化神经网络更倾向于自然生长的方式
从简单的输出单元和少量传感器、输入开始
随着不断添加进新的特征
逐渐积累神经元
让网络变得更加复杂和强大
在去中心化神经网络中
还存在着骨干网络和边缘部分的区分
骨干网络由那些权重不是零
而且可以通过连接影响网络输出的神经元组成
它们代表了网络已经学习到的知识；
而边缘部分则是那些在网络中看似没有发挥直接作用
但是实际上在边缘会不断尝试形成
对网络有用的功能或信号的神经元
在传统的反向传播过程中
如果神经元不影响输出
那么它的梯度就为零，权重不会改变
而在去中心化的神经网络中
我们希望边缘部分的神经元更加具有探索性
能够持续地学习和改变
因为它们可能蕴含着提升网络性能的潜力
为了实现边缘部分的有效学习
萨顿教授提出了一些新的算法思路
由于边缘神经元的梯度在反向传播中通常为零
无法直接使用传统的反向传播方法来学习权重
所以需要新的策略
其中一个基本理念是让每个神经元控制传入的权重
当一个神经元处于边缘部分的时候
虽然它不能直接影响误差
但是可以尝试改变传入的连接
期望下游的神经元能够选择接收它提供的信息
并且，在与骨干网络连接的过程中
需要经过两个步骤
首先骨干网络对新的边缘神经元会保持一定的谨慎态度
给予较小的步长
即使它提供了有用的信息
权重也不会快速增加；
但是如果经过一段时间的观察
发现这个神经元确实对网络有积极贡献
那么它的步长就会逐渐增加
权重也会相应提升
从而实现与骨干网络的有效连接
在步长优化方面
对于骨干网络和边缘单元需要采取不同的策略
因为骨干网络已经承担了网络的主要功能
并且已经在做着有用的工作
所以为了保护骨干网络的稳定性
需要让它的步长变小
避免被轻易地改变；
而对于边缘单元
如果它创造了有用的东西
那么在与骨干网络连接的初期
要经历骨干网络的谨慎考察阶段
随着神经元价值的逐渐显现
步长和权重才会逐步增加
另外萨顿教授还介绍了团队在未充分利用的人工神经元中
增加额外变化源方面的研究
正如我们刚刚提到的
深度学习要实现全部潜力
就需要在未充分利用的人工神经元中引入更多的变化
同时保护和保留那些被证明有用的变化神经元
此外
阿尔伯塔大学的研究人员在流算法方面取得的重要突破
也与去中心化神经网络的理念相关
在强化学习中
传统的深度学习方法在流式在线设置中表现不佳
存在着流障碍
而新的流算法研究成果
使得在各种标准深度强化学习任务上的性能得到了显著提升
能够与基于回放的深度学习方法相竞争
这个成果进一步支持了去中心化神经网络的论点
表明从去中心化的视角出发
能够为解决深度学习的问题提供有效的途径
总的来说
当前的深度学习方法虽然取得了巨大的成就
但是确实也存在着不容忽视的局限性
萨顿教授提出的去中心化神经网络和持续反向传播算法等理念和方法
为解决这些问题提供了新的方向和希望
当下，我们试图充分理解智能
以便创造出比当前人类更智能的生物
接下来就是试图理解我们自己
并且为此来构建工具
萨顿认为
我们必须以谦逊的态度来面对这个问题
这是一个如此巨大、重要的问题
而我们在面对它的时候显得如此的渺小
这个进程正在发生，而且将会发生
认识到它将会发生并且尝试成为其中的一部分
并不是一种傲慢
好了
以上就是对萨顿教授演讲的概括介绍了
感谢观看本期视频，我们下期再见
