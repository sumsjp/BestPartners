大家好，这里是最佳拍档
对于人工智能领域来说
二零二五年绝对是一个值得被深刻铭记的转折之年
硅谷的资本狂热仍在延续
大模型参数竞赛进入了千亿级后的瓶颈期
而曾经被奉为行业终极目标的通用人工智能
却悄然从主流舆论视野中淡去
在这样的行业迷局中
一位教父级人物的动向
直接牵动了全球AI研究的脉搏
他就是图灵奖得主、深度学习三巨头之一的杨立昆
二零二五年底
六十五岁的杨立昆宣布了一个震惊行业的决定
告别效力十二年的Meta核心管理层
从零创办一家名为AMI的新公司
要知道，他一手打造的Meta FAIR
早已是全球顶级的AI实验室
手握充足的算力资源和顶尖的研究团队
为何还要在花甲之年选择从零创业呢？
今天
我们就结合杨立昆二零二五年全年的公开演讲和访谈实录
完整拆解一下他对于AI的核心洞见
从对A·G·I的彻底否定
到对大语言模型的尖锐批判
再到他眼中
能够真正突破AI瓶颈的世界模型与Jepa架构
要想理解杨立昆的创业选择
首先要读懂二零二五年AI行业的微妙处境
在多个公开场合，杨立昆都提到
这一年行业正站在范式转移的临界点
过去三年，大语言模型的爆发
让整个行业陷入到参数堆得越大
智能就越强的路径依赖
从GPT 4到Llama 3
参数规模从万亿级向更高维度突破
但是在实际应用中
幻觉无法根除
物理世界理解缺失
复杂任务规划能力不足等核心问题
始终无解
更让杨立昆担忧的是
主流AI实验室的研究氛围正在发生质变
他在接受一次专访时直言
FAIR曾经坚持全公开的策略
发表所有的研究成果
开源包括PyTorch在内的核心工具和研究原型
这种开放姿态极大推动了全球AI生态的发展
也倒逼谷歌等实验室变得更加开放
但是过去几年
以OpenAI、谷歌为代表的头部机构
开始转向封闭和保密
将研究成果与商业利益深度绑定
不发表成果的研究等同于自我陶醉
杨立昆认为
这种封闭环境会扼杀长期主义的基础研究
而他一直深耕的世界模型相关研究
已经无法在巨头体系内
获得足够的自由空间
这正是A·M·I诞生的核心动因
杨立昆希望复刻当年贝尔实验室、施乐帕克研究中心的模式
打造一个不追求短期产品KPI、专注解决AI根本问题的科研净土
根据媒体披露的信息
A·M·I全称为先进机器智能公司
杨立昆担任执行董事长，并未出任CEO
而是聘请了AI初创企业Nabla的联合创始人
亚历克斯·勒布伦担任这个职务
更值得关注的是
这家公司在还没有正式启动之际
就计划以三十亿欧元的估值进行首轮融资
目标募资五亿欧元
如此高额的融资规模
也从侧面印证了
资本市场对杨立昆世界模型路线的认可
杨立昆在领英的简短帖子中明确表示
AMI的核心方向是世界模型与规划能力的研发
目标是构建一个能像人类一样
理解物理世界、进行复杂推理的智能系统
而非继续优化现有的大语言模型
而支撑这次创业选择的
是他对当前AI行业核心路线的彻底反思
首当其冲的
就是对AGI概念的全盘否定
在二零二五年英伟达GTC大会的炉边对话中
面对英伟达首席科学家比尔·达利关于AGI是否即将到来的提问
杨立昆给出了毫不含糊的答案
他认为
AGI即将到来这种说法完全是无稽之谈
在他看来，AGI之所以是伪命题
核心原因在于通用智能本身就是对人类智能的误读
杨立昆的论证逻辑是这样的
人类智能的本质是高度的专业化
而非通用
我们进化出的核心能力
是适应现实世界的具身交互
比如行走、抓取物体、理解他人的情绪等等
这些看似简单的能力
其实是千万年进化的结果
但是在很多领域
人类智能其实存在着明显的短板
比如计算速度不如计算器、记忆容量不如普通的存储设备、导航能力不如候鸟
强行要求机器具备与人类同等的通用智能
本质上是违背生物进化规律和数学逻辑的
因为智能的核心价值
在于解决特定的领域问题
而非全知全能
正是基于这个认知
杨立昆提出了用AMI来替代AGI
作为AI研究的新目标
他在相关访谈中明确了AMI的四大核心能力
一是从感官输入中自主学习物理常识
比如通过观察来理解重力、惯性等基本规律
二是具备持久记忆能力
能够存储和调用长期积累的知识
三是拥有复杂推理与层次化规划的能力
能从宏观的目标拆解到微观的动作
四是内置安全机制与可控性
避免出现不可预测的风险行为
杨立昆对AMI的实现时间线
也给出了相对明确的预判
最乐观的情况下
三到五年内可以在小范围内
实现某种形式的高级机器智能
但要达到与人类相当的智能水平
还需要更长时间的系统性优化
大概率会遇到目前未知的理论障碍
时间线可能拉长到二十年甚至更久
他特别强调
AI的进步是渐进式的，而非突变式的
过去七十年里
每一代研究者都宣称五到十年内实现人类水平的智能
但是这些预测都没能兑现
本质上就是对智能本质的理解存在偏差
而杨立昆对现有AI路线的批判
最尖锐的部分集中在当前行业的主流
大语言模型上
他甚至在二零二五年美国联合数学会议上直言
用预测下一个词的方法来创造AGI
就像是想用算盘登陆火星一样
这种激烈的批判
背后其实是三个层面的底层逻辑支撑
第一个是数学层面的自回归死结
这也是幻觉无法根除的本质原因
大语言模型的核心机制是自回归生成
也就是根据前文的Token
来预测下一个Token
杨立昆在数学会议上给出了一组精准的计算
假设模型单步预测的错误率仅为0.1%，
词表大小按照一万个Token来计算
那么生成一百个Token后
整个序列保持逻辑正确的概率
就会暴跌到37%。
如果生成一千个Token
这个概率会进一步降至几乎可以忽略的0.004%。
这不是可以通过优化算法、增加数据就能解决的Bug
而是自回归机制的内生属性
每一步Token预测都是一次概率赌博
只要有一个Token出现偏差
后续的预测就会像多米诺骨牌一样
产生连锁错误
最终形成一本正经地胡说八道的幻觉
杨立昆用了一个形象的比喻
戳破了大语言模型的本质
它不是在规划思考路径
而是在每一步都掷骰子
这种机制注定无法处理需要长程逻辑连贯的任务
比如复杂数学证明、精密的物理模拟
更不可能支撑起对现实世界的理解
第二个是信息论层面的带宽不对称
因为文本数据永远无法替代具身经验
很多人认为
只要给大语言模型投喂足够多的文本数据
就能让它掌握人类的知识
杨立昆用一组对比数据打破了这个认知
Meta的Llama 3预训练数据量
大约为三十万亿Token
换算成字节大约是十的十四次方
而一个四岁儿童
清醒时间大约为1.6乘以十的四次方个小时
人类视觉系统的总带宽是每秒二十兆B
仅通过视觉摄入的数据总量
就达到了十的十四次方个字节
和Llama 3的训练数据量完全相当
但是，这两者的认知差距却天差地别
四岁儿童用四年时间就能理解物理世界的基本规律
他知道物体是不可穿透的
松开的杯子会下落
物体消失后仍然存在
而Llama 3学完了一百T·B的文本
却连倒水时水流会往下流
这种最基础的常识都不具备
杨立昆解释
核心问题在于数据质量的本质差异
文本是低维的离散信号
每个Token仅包含两到三个字节的信息熵
是对现实世界的高度抽象和简化
丢失了物理世界的底层约束
而视觉、触觉等具身感官数据
是高维的连续信号
其中的冗余信息恰恰是学习世界模型的关键
这种样本效率的极度差异
决定了仅靠文本训练的大语言模型
永远无法触及现实世界的本质
第三个是在认知科学层面
系统一和系统二之间的差距
使得大语言模型缺乏真正的推理能力
心理学家丹尼尔·卡尼曼提出的双系统理论
是杨立昆批判大语言模型的重要理论依据
系统一是直觉式、反应式的快思考
比如熟练的司机在空旷道路上开车
无需刻意去思考
系统二是需要集中注意力、分步规划的慢思考
比如初学者在拥堵的路段驾驶
需要不断的判断和调整策略
杨立昆指出
当前所有的大语言模型都只是属于系统1的智能
无论面对的问题是简单的2+2=4
还是复杂的证明，P=NP
它们消耗的算力和处理逻辑完全相同
都是预测下一个Token
不会根据问题的复杂程度
动态调整思考时间和资源分配
所谓的思维链
本质上只是生成更多的Token来模拟思考的过程
就像一个人解题时
必须把所有念头大声说出来一样
一旦某个念头出错
后续的推导就会全部偏离方向
而人类真正的推理
是在抽象表征空间里进行的迭代优化
比如规划一次从纽约到巴黎的行程
我们会在脑海中构建，从去机场
到办理登机
再到起飞，最终降落的抽象步骤
而不是逐字逐句地生成详细指令
这种能力是大语言模型所完全缺失的
为了让这个观点更加容易理解
杨立昆多次引用了莫拉维克悖论的概念
机器擅长人类认为困难的任务
比如下棋、微积分
却难以完成人类认为简单的任务
比如收拾餐桌、开矿泉水瓶
他举了一个让人深思的例子
十岁的孩童第一次就能正确的收拾餐桌
十七岁的少年经过二十小时就能学会开车
但是耗费万亿Token训练的大模型加机器人系统
至今仍然无法稳定的完成这些简单任务
核心原因就在于，人类的这些能力
依赖于对物理世界的直觉理解
而大语言模型只能进行文本层面的统计拟合
无法建立与现实世界的连接
这一点在自动驾驶领域表现得尤为明显
行业喊了多年的L5级自动驾驶
始终停滞不前
杨立昆认为根本原因不是数据不足
因为当前自动驾驶系统已经积累了数百万小时的训练数据
而是采用的感知映射
模仿学习等方法
本质上还是基于统计拟合
没有构建真正的世界模型
一个青少年能够快速学会开车
是因为他知道
不减速会撞到护栏，视线被遮挡时
行人可能仍在移动
而AI只能靠穷举过往的边缘案例
这种方式在数学上是发散的
也就是你永远无法覆盖所有可能的场景
除非它能像人一样构建出
如果这样做会怎样的内部模拟
也就是世界模型
既然大语言模型的路线走不通
那AI的正确发展方向应该是什么呢？
杨立昆给出的答案是联合嵌入预测架构
Jepa
以及基于Jepa构建的世界模型
这也是AMI公司的核心研究方向
为了让大家深入的理解Jepa
杨立昆首先澄清了一个关键认知
为什么像Sora这样的视频生成模型
也无法构建世界模型呢？
他认为，生成式模型的核心问题
是在像素级别重现细节
但是在现实世界中
很多细节其实都是随机噪声
比如树叶的随机摆动、地毯的纹理变化
强迫模型预测这些不可预测的细节
只会让它要么拟合噪声
要么输出模糊的平均值
无法学到背后的因果规律
而世界模型的核心目标
不是重现细节
而是要学习抽象层面的因果结构
比如笔离开支撑会下落
物体无法穿透固体
这些才是智能的核心
Jepa架构的设计
正是为了实现这个目标
它的核心逻辑可以概括为
放弃像素级的预测
专注抽象表征的因果学习
具体分为三个关键的步骤
第一步是双路编码
将输入数据
比如视频的前半段，和目标数据
比如视频的后半段
分别通过两个独立的编码器
映射到同一个抽象表征空间中
第二步是潜空间预测
模型不直接预测目标数据的像素或者Token
而是在抽象表征空间中
根据输入的表征来预测目标的表征
第三步是信息过滤
目标编码器会主动丢弃那些不可预测的细节噪声
只保留具有语义价值的核心信息
比如物体的类别、位置、运动趋势等等
我们可以用一个具体例子来理解
用Jepa处理杯子从桌子上掉下来的视频
输入是杯子刚离开桌面的画面
目标是杯子落地的画面
JEPA不会去预测杯子掉下来时
每一个像素的变化
比如杯子上的花纹如何晃动、光影如何变化
而是在表征空间中学习
杯子从失去支撑，到受到重力下落
再到接触地面的因果关系
这样一来
模型学到的就不再是像素纹理的统计规律
而是物理世界的基本法则
这正是从文本拟合到具备智能的质变
但是这里存在一个关键的技术难题
那就是放弃像素级重建后
模型很容易出现偷懒行为
不管输入什么内容
都输出同一个表征
也就是模型坍塌
为了解决这个问题
杨立昆团队提出了方差、不变性、协方差正则化方法
简称VICReg
通过三个约束项来撑开表征空间
确保模型能够学到有价值的信息
第一个约束项是方差项
强制表征向量在每个维度的方差
保持在阈值以上
避免所有样本的表征都缩成一个点
确保信息能够有效存储
第二个是不变性项
对同一个物体的不同视图
比如从正面和侧面看杯子
要求它们的表征预测误差最小化
确保模型能够识别不同视角下的同一物体
保持信息的一致性
第三个是协方差项
强制表征向量各维度的协方差趋近于零
让每个维度都独立承载不同的信息
最大化表征空间的信息熵
避免出现信息冗余
这种设计的优势非常明显
不需要像对比学习那样
构造海量的负样本
仅通过数学约束就能让模型学到丰富、独立的语义特征
极大提升了学习效率
杨立昆团队用基于Jepa的视频模型V·Jepa做过一个极具说服力的实验
给模型输入，球凭空消失
物体穿墙而过
这种违反物理常识的视频时
模型的预测误差会瞬间飙升
这和婴儿看到反重力现象时
会盯着看更久的反应完全一致
这证明V·Jepa确实学到了物理世界的基本规律
而不是在记忆视频的纹理细节
除了Jepa架构
杨立昆还强调了能量基模型的重要性
他认为
能量基模型可以通过能量函数
来衡量输入与输出的兼容性
允许系统根据问题的复杂度
动态调整推理时间
更接近人类系统二的思考模式
能够有效弥补当前模型在推理能力上的不足
与需要进行概率归一化的生成式模型不同
能量基模型不需要计算复杂的配分函数
通过简单的能量高低判断
就能做出决策
在处理不确定性问题时更具优势
在讨论AI的未来方向时
杨立昆不仅关注算法架构
也对硬件发展和基础学科的重要性提出了独到见解
其中最具颠覆性的观点
是对模拟计算和神经形态芯片的批判
随着摩尔定律逐渐放缓
行业开始探索模拟计算和神经形态芯片
认为这些技术能大幅提升AI算力的能效比
但是杨立昆用生物学证据反驳了这一观点
他以秀丽隐杆线虫为研究对象
这种一毫米长的线虫只有三百零二个神经元
神经元之间采用模拟信号通讯
因为体型小，信号传输距离短
噪声可以控制
但是当生物体型变大
比如长颈鹿的大脑到腿部、人类视网膜到视觉皮层
就进化出了动作电位
本质上是二进制的数字信号，零或一
杨立昆由此提炼出生物计算的核心法则
那就是模拟计算、数字通讯
模拟信号在长距离传输时
信噪比会呈指数级衰减
无法保证信息的准确性
而数字信号可以通过中继器无损再生
适合长距离、大规模的信息传输
对应到AI硬件
模拟芯片的缺陷非常明显
一是通讯瓶颈
现代CMOS芯片需要跨芯片传输海量数据
模拟信号长距离传输时的衰减问题无法解决
必须进行模数和数模之间的转换
这会消耗大量能量
抵消模拟计算的能效优势
二是复用性缺失
数字芯片的乘法器等核心单元
一秒能复用几十亿次
可以处理不同层的计算任务
而模拟芯片往往需要神经元与电路一一对应
要运行千亿参数的模型
就需要制造千亿个物理单元
成本和体积都不可行
因此，杨立昆判定
通用AI硬件的未来
仍然会以数字逻辑CMOS为核心
模拟计算和神经形态芯片
只能用于边缘端的特定场景中
无法成为通用AI的主流硬件方案
他同时提到
Meta正在探索核能作为低排放能源
来支持大规模的AI计算
同时推动模型小型化与硬件优化
从而降低AI发展的能源消耗
除了硬件，杨立昆多次强调
基础学科对AI突破的关键作用
他认为，当前AI行业的很多问题
根源在于对基础理论的忽视
未来的研究者需要回归到概率论、控制理论、认知科学等基础学科
才能解决机器的物理世界理解、持久记忆、复杂规划等核心难题
比如
控制理论中的状态估计、最优控制等思想
可以为世界模型的规划能力提供理论支撑
概率论中的不确定性建模
能够帮助AI更好地处理现实世界中的随机事件
认知科学的研究成果
可以为AI架构的设计
提供生物智能的参考范式
杨立昆还回顾了深度学习工具链的演进历史
从一九八七年的SN模拟器
到后来的Caffe、Torch
再到如今的PyTorch
每一次工具链的进步
都推动了研究的爆发
而这些工具的研发
都离不开基础学科的支撑
他以二零一二年ImageNet竞赛的突破为例
当时他团队提出的卷积神经网络
之所以能取得历史性成绩
不仅是因为数据量和算力的提升
更关键的是对高维几何直觉的修正
通过卷积、池化等操作
有效提取到了图像的层级特征
这个设计思路就融合了信号处理、几何学等基础学科的知识
在技术路线之外
杨立昆对AI行业的生态建设
也有着自己深刻的思考
其中开源是他反复强调的一个核心主张
这个主张的背后
是他对二零二二年Meta Galactica模型下架事件的深刻反思
以及对行业信息垄断风险的担忧
二零二二年
Meta发布了专注于科学领域的大语言模型Galactica
该模型在超过四千八百万篇论文、教科书、讲义等科学语料上进行训练
能够总结学术文献、解决数学问题、生成科学代码
甚至处理化学公式和蛋白质序列等多模态任务
然而，由于模型存在严重的幻觉问题
生成了一些不严谨的内容
上线不到三天就被舆论猛烈批评
最终被迫下架
杨立昆当时就发布推文表达遗憾
再也不能用它来找乐子了
你们都开心了吗？
让杨立昆感到不公的是
就在Galactica下架后不久
OpenAI发布的ChatGPT也被发现存在严重的幻觉问题
但是OpenAI在发布的博客中
明确指出了这个弱点
却没有受到类似的猛烈批判
反而迅速成为了行业顶流
两个月内月活用户就突破了一亿
杨立昆认为，这是典型的舆论双标
Galactica被定位为科学研究工具
用户对它的准确性的期待极高
一旦出现错误就被全盘否定
而ChatGPT被包装成聊天玩具
用户对错误的容忍度大幅提升
但是更深层的问题是
这种舆论差异的背后
反映了行业对封闭模型和开源模型的不同态度
OpenAI的封闭模式让它获得了更多商业话语权
而Meta的开源尝试
却面临更严苛的审视
杨立昆多次在公开场合为Galactica鸣不平
他表示
Galactica的幻觉水平实际上低于当时的其他模型
因为它是在科学文献上进行的微调
对科学家来说是非常有价值的工具
而以人工智能道德为幌子的误导性批评
最终毁掉了这个有潜力的研究项目
这次事件也让他更加坚定了
开源是AI生态健康发展的核心的信念
在他看来，未来人类获取信息的入口
很可能都会被AI助手垄断
如果这个入口被少数几家美国的西海岸公司控制
就会带来严重的信息主权和文化安全问题
这些模型自带的文化偏见
会同化非英语文化圈的价值观
各国的核心数据也会被外国公司所掌控
最终导致文化多样性的丧失
因此，杨立昆明确表示
AMI将延续开源策略
坚持公开发表研究成果
开源核心的研究原型和工具
他认为，创新不是封闭的过程
而是跨学科、跨地域合作的成果
只有保持开放，才能让全球的研究者
共同参与到AI的基础研究中
避免少数公司的技术垄断
同时，开源也能让不同国家和地区
基于开源基座
训练符合本土语言、文化、法律的专用AI
构建分布式的AI生态
保障各国的信息主权和文化安全
杨立昆以Meta的Llama模型为例
说明开源的价值
Llama发布时
Meta吸取了Galactica的教训
采取了相对谨慎的开源策略
在GPL v3许可证下向研究社区发布
要求研究者填写表格才能访问
而Llama的成功
直接推动了开源AI生态的爆发
让更多中小企业和研究者
能够参与到大模型的研发中
打破了头部公司的算力和数据垄断
他强调，开源的核心原则是尽早发布
经常发布，通过快速迭代和社区反馈
不断优化模型
同时让研究成果更快地转化为实际价值
在批判现有路线、提出新的技术方案的同时
杨立昆也描绘了他眼中AI的未来愿景
AI不是要替代人类
而是会成为人类智能的放大器
推动一场超越印刷术的新文艺复兴
他预言
未来十年将是机器人的黄金十年
当前机器人的硬件技术已经相当成熟
无论是机械臂的精度、移动平台的稳定性
还是传感器的感知能力
都已经达到了商业化应用的水平
但是机器人的大脑，也就是智能系统
始终存在着短板
无法理解物理世界、进行灵活规划
这也是制约机器人普及的核心瓶颈
而随着世界模型和Jepa架构的突破
AI将具备真正的物理世界理解和规划能力
为机器人提供通用大脑
让机器人能够像人类一样
灵活处理各种物理交互任务
广泛应用于家庭服务、工业生产、医疗护理等领域
在杨立昆看来
AI的终极角色不是替代人类
而是放大人类的智能
就像工业革命用机械放大了人类的体力一样
AI将放大人类的智力
他构想了一个虚拟幕僚团的场景
科学家的AI助手能快速阅读全球所有的相关文献
提炼核心观点，提出新的研究假设
帮助科学家突破知识的边界
艺术家的AI助手能将模糊的创意具象化
生成多种创作方案
激发创作灵感
普通人的AI助手能处理日常琐事
提供个性化的医疗建议、教育指导
让每个人都能享受到专业级的服务
这种智能放大的价值
在科学和医学领域将表现得尤为突出
杨立昆认为
AI未来在蛋白质折叠、药物设计、理解生命过程等研究中
将发挥不可替代的作用
比如AlphaFold已经在蛋白质结构预测领域
取得了突破性进展
未来基于世界模型的AI系统
将能够更精准地模拟生物过程
加速药物研发和疾病治疗方案的探索
他强调
AI的发展最终是为了给人类文明增加智能供给
因为智能的稀缺性制约着人类社会的发展
而提升服务于人类的智能总量
是一项具有根本性积极意义的事业
杨立昆也提到
AI的发展必然会带来安全和伦理问题
比如就业结构变化、隐私保护、算法偏见等等
但这些问题并非无法克服
他主张以工程思维解决这些挑战
通过内置安全机制、完善法律法规、加强行业自律等等方式
确保AI的发展方向符合人类的整体利益
他不认同AI威胁论
认为只要引导恰当
AI将成为推动人类社会进步的核心力量
就像历史上的蒸汽机、电力、互联网一样
彻底改变人类的生产和生活方式
回顾AI发展的历史
每一代研究者都有自己的技术范式和终极愿景
而杨立昆的思考
无疑为当前陷入参数竞赛迷局的行业
提供了一种清醒的纠偏
AI不应该困在文本的概率游戏中
而应该回归到对现实世界的理解和交互中
不应该追求虚无缥缈的AGI
而应该专注于构建能解决实际问题的AMI
不应该走向封闭的商业垄断
而应该保持开放的生态合作
或者，二零二五年AGI的消失
不是AI的失败
而是行业从狂热回归理性的开始
从堆参数到学因果
从文本拟合到物理理解
从封闭垄断到开源协作
AI正在走向一条更扎实、更可持续的发展道路
而杨立昆创办的AMI
以及他提出的Jepa架构和世界模型
无疑将成为这条新道路上的重要探索者
感谢观看本期视频，我们下期再见
