大家好，这里是最佳拍档，我是大飞
随着这两年AI技术的蓬勃发展
AI在科研领域的应用也越来越广泛深入
包括前两天我们也报道了AlphaFold 3的发布
这无疑让许多人开始抱有乐观的态度
但是
人工智能最终可以彻底替代人类科学家
帮人类解决所有科学问题吗？
对此
Wolfram语言之父、美国计算机科学家Stephen Wolfram给出的答案是
NO
在近期的Imagination In Action峰会中
Wolfram与德国著名计算机科学家与认知科学家约沙·巴赫Joscha Bach进行了一场对谈
发表了他关于这一问题的观点
并且他还在Wolfram网站发表了一篇文章详细进行了解释
翻译过来超过3万字
大家有精力可以去仔细阅读一下
出于时间原因
大飞我结合视频和文章内容
尽量总结了Wolfram的核心观点
在这里跟大家分享一下
如果有不准确的地方欢迎大家指正
首先，我们要回答一个核心的问题
人工智能能预测未来吗？
从历史上看
一种科学是否成功的决定性特征
往往是它能够预测未来会发生什么
或者说
它能够找到某个系统运行的基本规则
而目前的人工智能
似乎还并不能完全做到这一点
Wolfram认为，这个问题的核心就在于
在科学研究中
许多系统运行的规则体现着计算不可约性（Computational irreducibility）
也就是指某些系统或者过程
无法通过简化的计算步骤
提前得到预测
而目前的人工智能，就它的构造而言
本质上只是在做相当浅层的计算
那么
该如何理解这种计算不可约性呢？
我们的科学理论核心之一在于
可以把一切过程视为计算
系统通过计算来确定它的行为
而人类以及我们创造的任何AI
也必须通过计算
试图来预测或者“解决”这种行为
不过，计算等价原则指出
如果任何两个问题或者函数
具有相同的解决方法或者计算结果
那么这些运算在复杂度上是等价的
这意味着我们无法跳跃式的预测或者“解决”系统
要想准确地理解这个系统的行为
总是需要一定的运算输入
所以，不管人工智能是否能够被应用
“科学力”都受限于行为的计算不可约的本质
但是为什么计算不可约性的存在
不妨碍科学取得进展呢？
关键就在于，在全局不可约中
即系统总有可以经过有限计算描述的方面
这恰恰是科学的关注点所在
不过
即使我们将计算局限在可约的范围内
自然界出现的现象与问题
也总会迫使我们去面对不可约性的计算
AI或许能提供一些途径
来揭示某些可简化的计算
但是总有一些还没有被计算简化的未知
等待着被我们发现
它始终制约着我们全面攻克科学
而AI在处理这些计算时就显得力不从心
举个例子
假设我们已有的“数据”是这里的蓝色曲线
也许代表的是悬挂在弹簧上的重物的运动
而“物理学”则能让我们知道
如何延续出来红色的曲线部分
再举个例子
假设这是一个非常简单的神经网络
如果使用上面的蓝色曲线数据对它进行训练
会得到一个具有特定权重集合的网络
现在
让我们用这个训练过的网络来重现原始数据
并对它进行扩展，我们看到
这个网络基本重现出了训练数据
但是却没能做到“预测未来”。
那这是因为我们训练的时间不够长吗？
这是逐步增加训练回合后的结果
可以看到，似乎并没有什么用
所以问题的原因可能在于
我们的神经网络规模太小了
于是我们对它进行进一步的调整
更大的神经网络或许会起到一定的作用
但它们并不能解决我们的预测是否成功的问题
神经网络的一个特点就在于它的激活函数
也就是我们可以如何根据输入的加权和
来确定每个节点的输出
下面是一些使用各种常用激活函数的结果
可以发现
不同的激活函数导致了不同的预测结果
不过似乎这种预测的结果
也只是激活函数形式的直接反映
我们当然可以继续对它加以训练
不只限于某个单一函数
而是训练整个函数系列
比如三角函数集合
或者Wolfram语言中的所有内置数学函数
这样
我们当然可以预测出上面的正弦函数
就像我们使用以正弦曲线为基础的传统傅里叶分析一样
但是，这称得上是“做科学”吗？
从本质上说
它只是自动化了人类在某一特定领域的典型经验
所以，Wolfram认为
人工智能在“预测”这方面的表现“出乎意料地糟糕”。
他认为
大语言模型等人工智能表现出色的地方
从某种意义上说
应该是那些计算量比我们所知
要少的方面
比如
我们能够从ChatGPT的成功中了解到的一点
或许就是语言比我们想象的要简单
语言中的规律性比我们所发现的要多得多
这也是人工智能能够在科学领域的这类问题上
能够取得成功的原因
但是在这些问题中
有一些计算从根本上来说也是不可约的
在这一方面
人工智能的表现并不比我们人类更好
它也无法取得更大的进步
如果我们要求大语言模型给出一些
没有那么精确的回答
比方说对某个主题的文献
或者对某些事情的看法
那么它们可以答得很好
Wolfram认为
这是因为大语言模型拥有一种我们未曾有过的、分析文本的能力
过去，我们可以运用统计学工具
得出一大堆数字中的异常值
以及计算平均值或是方差
现在，有了大语言模型
我们可以对大量文本进行同样的处理
我们以前从来没有过这种能力
它不能被归为统计
而是一种还没有被命名的新事物
人工智能现在可以衡量
像“这些作品的相似程度如何”，
“这些神话有多大不同？
”等等这类
人们之前只能通过写文章来解决的问题
而且在某种意义上可以量化
或许，我们可以期待人工智能领域
能够出现一个新的词来命名这种能力
人们可能还会比较关心一个问题
那就是人工智能是否具有原创性与创造力呢？
实际上
想要做出原创性的工作是非常简单的
你只需要选择一堆随机数
那些随机数序列非常出人意料、有创意、也很有独创性
但是这对我们来说
并没有太大意义
我们真正感兴趣的是那些既有原创性
而且“有趣”的东西
举个例子
假设我们正在进行艺术创作
那么随机去画一些像素排列当然是原创
但是它们并没有太大意义
如果我们让AI制作一张
戴着派对帽的猫的图片
那张图片的含义会被转换成一组数字
而这组数字就是生成那张猫的图片的来源
如果我们想了解嵌入向量在潜在空间中的不同可能值
尝试去随机更改这些数字，这时
在那个可能代表事物含义的数字空间里会出现什么？
我们会看到各种各样的图片
但是其中大部分是我们无法解读的
或许这些图片大部分看起来有点意思
但是我们无法用语言来表达它的含义
因此
人工智能有能力发现一些我们意想不到的、新奇的事物
这其实并不难
不过，我们通常不会这么做
一般来说，我们在编写程序的时候
都是有明确的目标的
我们会按部就班地设计和编写代码
去实现我们想要的功能
但是如果我们不按常理出牌
随意地编写程序
那会出现什么情况呢？
结果可能会出乎你的意料
那就是即便是非常简单的程序
也可能执行一些非常复杂的任务
当我们观察到这些程序的效果时
我们可能会惊喜地发现它们非常有用
可以被用来完成某些特定的工作
这就有点像我们在自然界的探索中
发现了新的矿物质
意识到这些新材料对我们有实际的用途
在技术领域，尤其是计算世界里
也同样如此
某种意义上，科学也是一种数据压缩
我们观察了宇宙的所有动态
然后用几条定律、几个微分方程来表征它们
我们就能理解发生了什么
但是在这个过程中
还有一个方面超越了数据压缩
也就是当我们在发挥创造力的时候
我们自身也被改变了
这一点类似于艺术
艺术的特点在于
你在感知到某个事物的时候
它也改变了你
如果我们是富有创造力的
那么无论做什么
我们都能提出新的想法
重要的是观察者或者创造者本身
正在通过这个创造过程发生变化
但是在现在的模型中
似乎还具有一些局限性
它们在创造、或者说“生成”的时候
还无法根据自身发现的内容进行更新
而这正是人类目前优越于AI的地方
Wolfram提到，需要明确的一点是
关于这个世界的想法是异常丰富的
人类的典型语言中可能有5万个单词
而这些词语所表达的
往往都是在我们看起来足够重要的概念
除此之外
需要用文字来表达、但是还没有被言明的东西还有很多
关键就在于，我们如何去探索
如何去明确我们所感兴趣的方向
如何去扩展自己，并从中获得发展
举个例子
如果我们从数学的公理出发
通过逻辑推理来探索可能的数学定理
那么这个过程通常会涉及到两个步骤
首先
这里有许多看起来可能看起来非常“无趣”的定理
但是，在这些定理中
有时会发现一些特别有趣的定理
它们足够重要
于是在教科书中被特别的命名
比方说“幂等律”。
那么，我们是否有可能预测出
哪些定理会被特别命名呢？
虽然这可能看起来像是一个历史问题
但是在逻辑学中
似乎有一个系统的模式存在
比方说，当我们列举逻辑定理的时候
可以从最简单的定理开始
按词典的顺序依次排列
列表中的大多数定理
都可以从前面的定理推导出来
但也有少数定理是不可推导的
而这些定理
基本上就是那些通常得到命名、在图上被高亮显示的定理
换句话说
至少在基本逻辑相当受限的情况下
那些被认为足够有趣并被命名的定理
是那些给我们能带来新的信息、并引起惊喜的定理
如果我们在更广泛的“元数学空间”（metamathematical space）中考虑
就可以根据经验
来识别那些被认为有趣的定理的位置
那么人工智能能预测这一点吗？
理论上
我们可以使用现有的数学文献和其中的数百万条定理
来训练一个神经网络
然后
我们可以将通过系统枚举得到的定理
输入到这个神经网络
让它评估这些定理
作为可能出现在数学文献中的对象的可信度
在这个过程中
神经网络甚至可以被用来预测
哪些数学探索的“方向”可能是有趣的
如果任由人工智能发展
我们可以期待它去探索这个可能的计算世界
但是在寻找“真正的新的科学”的时候
上面的方法可能就有问题了
因为从现有文献中训练出来的神经网络
基本上会寻找“更多相同的东西”，
它所“接受”的是“主流”和“不太令人惊讶”的东西
而计算不可约性意味着
在探索过程中总会有出人意料的发现
这些发现不容易被归纳到已知的模式中
虽然它们可能会提供新的信息
甚至可能具有实际应用价值
然而
这些新的概念最初可能并没有直观的解释
需要人类逐渐来理解和接受
不过
我们选择内化哪些新事实或新方向
这个过程有一定的主观性
虽然特定的方向可能引导我们发现新的思想或技术
但是在没有深入探索之前
我们还无法确定哪个方向是正确的
而这通常是由人类的选择来决定的
此外，还有一个潜在的问题
即使人工智能对人类心理和社会有足够的了解
能够预测我们可能感兴趣的内容
但是计算的不可约性仍然意味着
我们无法事先完全知道我们最终会喜欢什么
因为直到我们真正的感受到
我们才能真正了解我们对某个发现的反应
这意味着
尽管人工智能可以提供指导和建议
但是人类对于决定哪些新概念值得追求
仍然扮演着关键角色
因此，在我们的选择之前
人工智能或者其他任何东西
都无法去发现“有趣”的抽象概念
实际上，寻找“有趣”的方向
也就意味着我们如何探索这种具有计算可能性的空间
而我们所关心的计算可能性的集合是非常小的
但是对于我们文明的未来来说
这才是最重要的
相比AI，人类要做的事情
就是在这个充满可能性的计算宇宙中
选择他们认为“有趣”的方向
科学的作用是什么？
Wolfram认为其中一点就在于计算宇宙的可能性
虽然我们可以用人类的叙述来解释某些片段
但是很多事情是无法理解的
我们没有办法把它简化成我们可以描述的东西
因此
Wolfram才致力于构建一种计算语言
也就是Wolfram Language
这种语言的理念
就是让世界上的事物通过计算实现形式化
它的构建与人类文明进程的演进相呼应
从原始的指物交流
到语言的诞生
再到逻辑学与数学的形成
每一步都是对世界的进一步形式化
他希望Wolfram Language
能够以一种简洁的方式来代表世界中的各种事物
为探索未知领域提供工具和符号
从而促进新发现和发明的产生
他的目标是让这种语言能够描述尽可能高级的计算过程
这就有点类似于500多年前的数学发展
当时数学符号如加号和等号的发明
对代数和微积分的发展起到了关键作用
进而推动了现代数学科学和工程学的进步
最后我们回到最初的问题上来
人工智能能够代替人类
解决所有的科学问题吗
Wolfram认为
从某种意义上来说
人工智能的预测往往非常的人性化
在我们看来通常只是大致正确的
从根本上来说
他们依赖于计算的可约性
而当存在计算不可约性的时候
他们或多或少就会不可避免的失败
而这个时候
人们就需要不可约的深度计算来计算出会发生什么
所以人工智能目前更像是人类思维的延伸工具
来帮助完成大脑并不擅长的事情
不过或许
把人工智能与计算范式的优势结合起来
才是推动科学向前发展的最大机会
好了以上就是Wolfram对于人工智能
是否会代替人类来解决科学问题的观点
希望对大家能有所启发
也欢迎大家在评论区发表自己的看法
感谢大家观看本期视频
我们下期再见
