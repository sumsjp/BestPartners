大家好，这里是最佳拍档，我是大飞
前几天呢
我们做了一期有关Etched Sohu芯片的介绍视频
评论区里就有观众提出
前几个月不是才出了个groq号称超越英伟达吗？
怎么这会儿又来一个
很好奇Groq和Sohu之间的差异
今天大飞就来简单的讲解一下二者的区别
首先
两款产品从设计上就是完全不同的两个思路
Sohu芯片的设计理念基本就是抱紧了Transformer的大腿
一荣俱荣
一损俱损
它是专门为Transformer模型设计的ASIC芯片
在处理Transformer有关的任务上
Sohu的表现非常牛逼
ETCHED公司给芯片塞上了大量的硬件加速器
来优化Transformer模型中的关键计算步骤
这些加速器针对NLP任务的特性进行了定制设计
凭借着专门为Transformer模型设计的ASIC架构
Sohu芯片每秒可以处理高达50万个tokens
支持最高100万亿参数的大模型
Sohu在推理Llama-3 70B上
比H100快至少20倍
在Transformer模型的推理性能上
Sohu确实彪悍
ETCHED能拿到1.2亿的融资
手里还是有两把刷子的
但是代价是什么呢？
代价就是Sohu较窄的应用范围
作为一款ASIC芯片
Sohu除了跑大模型几乎做不了其他任何事情
而且还必须得是基于Transformer的大模型
像什么U-Net、CNN这些
Sohu都跑不了
相当于Etched公司把宝全压在了Transformer上
希望通过专业化芯片带来的性能提升
来大幅提高Transformer模型的各项指标
从而在硬件层面卷死其他对手
只要Transformer仍然是最流行的大模型架构
Sohu就有无限潜力
这也是为什么众多投资人看好Etched的原因
但是，换个角度来说
一但Transformer被更强的大模型架构取代
那么Sohu基本也就跟着完蛋了
而Groq的LPU芯片则跑通了一条不同的赛道
Groq的团队从头设计了一个张量流处理器（Tensor Streaming Processor）
简称TSP的微架构
这个架构没有采用开发小型可编程内核、并且进行数百次复制的传统思路
而是直接构建了一个可以容纳数百个功能单元的处理器
为了组织多个TSP
Groq 还设计了一个名为 Dragonfly 的网络
它采用多级层次化结构
通过几个层次的路由器连接不同的子组
从而提供高带宽容量和低通信延迟
这对于机器学习任务来说十分的重要
简单来说
Groq 的 TSP 技术就像是一个交通系统
通过软件来控制红绿灯
让同一方向的所有车辆在一条路上快速前进
从而大大提高了效率和速度
在这个基础上，虽然同为ASIC架构
但是LPU和sohu的核心玩法却不同
Groq玩了一个用空间换时间的把戏
把模型权重和中间数据都放在了 SRAM 里面
而不是 HBM 或者 DRAM
不同于英伟达GPU需要依赖高速的数据传输
TSP架构允许Groq在系统中不采用高带宽存储器（HBM）
而是使用SRAM
因此LPU不必像使用HBM的 GPU 那样
频繁地从内存中重新加载数据
这个做法在大幅度提高推理速度的同时
还有助于避免 HBM 短缺的问题
想象一下，假设你有两个工人
一个是来自Groq的“LPU”，
另一个来自英伟达的GPU
两人的任务都是尽快地整理完一大堆的文件
GPU就像一个速度很快的工人
但是要依赖于高速的传送系统
比如说HBM或者其他的高带宽存储器
不停的把文件快速传送到他的桌子上
这个工人虽然干活能力不错
但是因为HBM的产能有限
所以你很难招到他
而Groq的LPU就像一群高效组织任务的工人
他们不需要那么快地交付文件
所以利用了一张他们身边的小桌子
比如SRAM
或者其他更快、更小的存储器
因为小桌子上的东西只要伸手就能够到
所以他们几乎可以立即获得所需的东西
这意味着他们可以在不依赖快速交付系统的情况下快速工作
这就是LPU的特点，小内存和大算力
它适合需要频繁搬运数据的场景
不过，LPU的速度虽然很快
但是单卡的吞吐能力有限
这也就意味着LPU用户需要购买更多的卡
来保证同等的吞吐量
因此速度对于LPU而言
既是优势也是劣势
贾扬清就曾经在推特上算过一笔账
因为LPU只有小的可怜的230MB内存容量
在运行Llama-2 70b模型时
需要305张卡才能把模型塞进去
而用H100则只需要8张卡
从目前的价格来看
这意味着在同等吞吐量下
LPU的硬件成本是H100的40倍
能耗成本是H100的10倍
与此同时，同为AISC芯片
LPU也面临和Sohu类似的麻烦
它也需要解决应用范围较窄的问题
Groq 目前只能为少数的大型模型提供服务
不过
LPU并没有针对Transformer进行专业化
因此没有像Sohu那样被Transformer“绑架”，
这意味着LPU在未来还有机会被应用到新的大模型架构上
因此被模型迭代淘汰的风险相对小一些
好了
以上就是两款芯片的简单介绍和对比
希望能帮助大家理解他们的不同之处
这期视频时间比较短
主要还是想对Sohu的视频做一个补充
就目前的市场而言
无论是Sohu还是LPU
都很难在短时间内和英伟达硬碰硬
说实话
老黄靠着提前十年布局AI的眼光
才换来了今天的回报
又因为英伟达在这次AI浪潮中的绝对领先地位
让全球都在翘首以盼英伟达的挑战者
不过，这些后起之秀在宣传时
总是会在单一的维度来比较，实际上
这两款芯片主打的都是纯推理的场景
如果比拼综合性能
英伟达的H100依然是无可撼动的业内第一
那么大家是怎么看的呢？
欢迎将自己的想法打在评论区里
感谢大家的观看，我们下期再见
