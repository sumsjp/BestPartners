大家好，这里是最佳拍档，我是大飞
相信昨天晚上Llama3的发布
让无数AI从业者无眠
而和Llama3同时发布的
还有一个扎克伯格关于Llama3的访谈视频
可以说
这就是Meta和小扎向全世界的宣言
在这个长达80分钟2万字的访谈里
基本所有内容都围绕着Llama3展开
可想而知，包含了多少干货内容
为什么一定要开源最强的大模型？
Meta如何从开源模型中赚钱？
小扎做出这些重大开源决定的初心是什么？
如何考虑开源模型的风险问题？
有太多值得关注的问题在这个访谈里得到了详细的解答
今天大飞就来跟大家分享一下对话的精华内容
推荐大家有时间去看一下原视频
在这个采访里
扎克伯格首先介绍了Llama3和Meta AI的最新进展
包括模型升级、新的创作功能以及对实时知识的整合
Llama3一共有三个不同参数规模的模型
分别是80亿参数、700亿参数以及4050亿参数版本
前两个版本已经准备就绪
而4050亿参数的模型仍在训练中
目前占用了Meta几乎所有的GPU资源
此外
Llama3后续还会发布多模态、更多语言的支持以及更长的上下文窗口等等功能
4050亿参数的版本大概会在今年晚些时候发布
根据目前的训练进展
它的MMLU
也就是跨模态学习理解的得分
已经接近85
700亿参数的模型已经正式发布
它的MMLU得分约为82
即使是80亿参数的模型
它的性能也几乎与Llama-2 700亿参数相媲美
这意味着，即使是“最小”的Llama3
在功能上也几乎与最大的Llama 2一样强大
而今天的这一切
都可以追溯到小扎在2022年所做的决定
在2022年
Meta面临着股价的大幅下滑
人们对大笔采购英伟达H100芯片的投资充满了疑惑
元宇宙的概念也没有得到市场的广泛认可
当时Meta正在开发Reels项目
他们发现
为了训练模型需要更多的GPU
这其实是一个巨大的转变
因为Meta的服务不再仅仅基于用户所关注的人或者页面来排列内容
而是开始大力推荐所谓的“未连接的内容”，
也就是那些来自于你没有关注的人或页面的内容
因此，可能需要展示的候选内容数据
一下子就从几千个激增到了几亿个
这就需要一个全新的基础设施来支撑
但是为了追赶TikTok的步伐
Meta遇到了瓶颈
小扎意识到
不能再陷入这种被动的局面了
所以不仅订购了开发Reels所需的GPU
还将订购量翻了一倍
他认为有一个始终坚守的原则是
未来总会有我们无法预见的新事物出现
所以我们必须为此做好准备
经营公司，就像打游戏一样
总会有新的挑战出现
如今回过头来看
这个决定无疑是明智的
它让Instagram和Facebook的内容推荐有了一个巨大的飞跃
但是实际上
它源自于Meta曾经落后的教训
实际上
很多决定之所以现在看起来正确
正是因为曾经犯过错误
并且从中汲取了教训
再往前推
2006年小扎拒绝了10亿美元的收购提议
当时并不是因为各种财务方面的原因
而是因为他与自己内心进行了一次深入的对话
如果自己不做Facebook了
会去做什么？
他发现自己很喜欢创造新的东西
喜欢帮助人们进行沟通
喜欢了解人们的动态以及人与人之间的互动
如果把这个公司卖了
他很可能又会去创造另一个类似的公司
那既然对现在的公司还挺满意的
又何必要卖呢？
因此他认为
人们做出的很多重大决定
其实都是基于我们的信念和价值观
实际上
通过分析来准确预测未来是非常困难的
接下来
小扎深入探讨了他对于通用人工智能AGI的看法
大约10年前
Meta创立了Facebook人工智能研究所
FAIR
当时的初衷是
在迈向通用人工智能的道路上
会有许多创新涌现
而这些创新将不断推动公司各项业务的进步
因此
当时并没有将FAIR作为一个独立的产品来构思
而是当成是一个研究团队来组建的
但是，随着ChatGPT的崛起
以及文生图领域和扩散模型的涌现
所有人都明显感受到了一股巨大的变革之风
于是，Meta决定组建第二个团队
也就是通用人工智能团队
目的是将这些前沿技术融入到Meta的产品中
同时构建能够支撑所有不同产品的、领先的基础模型
由于Meta的很多产品都有很强的社交属性
因此在不断的产品迭代过程中
团队发现
通用人工智能的支持是必不可少的
以两个能力为例
第一个是编码能力
Llama-2在开发的时候并没有优先考虑编码功能
但是编码实际上在很多领域中都扮演着重要的角色
而不仅仅局限于编程行业
即使用户并没有直接提出编码相关的问题
对模型进行编码训练
也有助于它们更为精确地回答问题
同时在不同领域的推理中展现出卓越的能力
因此，Meta就在Llama-3中
通过大量的编码训练进行了优化
另一个是推理能力，很多时候
客户并不清楚自己真正需要什么
或者如何准确地提出问题
因此
仅仅回答问题并不是人工智能的全部工作
我们需要更全面、更深入地思考
这实际上已转化为一个推理问题
基础阶段的聊天机器人并不能满足用户的需求
会被竞争对手很快超过
因此
Meta最终决定全力解决通用人工智能的问题
于是加大了赌注和投资
确保能够取得突破
不过，现在Meta所做的这些努力
并不是在试图取代人类
而是希望通过这些工具
赋予人们更强大的能力
让他们能够完成更多以前难以想象的工作
也许在未来某个时刻
人工智能可能会在某些方面超越大多数人类的能力
但是
小扎认为这是一个逐步演进的过程
AGI也并非能一蹴而就
需要逐步地为模型增加不同的能力
除了多模态、元宇宙、3D技术以外
小扎特别关注的一个模态是情感理解
因为人类大脑的大部分功能
都在致力于理解他人、解读表情和情感
所以小扎坚信
如果能够在这方面取得突破
让人工智能能够真正理解并表达情感
那么人与机器之间的互动
将会变得前所未有的自然和深入
根据Meta的预测
智能推理将深刻改变今后几乎所有的产品形态
比方说可能会有一种Meta AI通用助手
它从传统的聊天机器人演变而来
不仅能够回答问题
还能够接收并且执行更复杂的任务
此外
与其他智能体Agent的互动也很重要
人类不会只与一个通用的人工智能互动
每个企业都将拥有代表自身利益的人工智能
通过独特的方式与企业、创作者和消费者互动
需要特别值得一提的是
创作者将成为这项技术受益的重要群体
如果能让创作者训练自己的人工智能
并且借助它与社区保持互动
那将是一个非常强大的功能
在这个方面
Llama模型可能会与其他工具进行协作
这在Llama-2中主要还是通过手工的方式
工具使用功能相对具体和有限
Llama-3已经内嵌了不少功能
能够独立完成搜索等任务
而Llama-4的目标是将更多这类功能
自然而然地融入到模型中
总体的目标是让模型能够自我学习、自我进化
从而适应各种复杂多变的场景
目前
Meta已经建立了两个大型的GPU集群
每个集群拥有大约22000到24000个GPU
主要用来训练大语言模型
不过，由于Meta的用户规模极其庞大
所以需要的推理计算量比训练要大得多
在训练Llama3 700亿的时候
原本以为随着数据量的增加
模型的性能提升会逐渐趋于饱和
但是在训练了大约15万亿个token后
发现模型仍然在不断学习
即使在训练的最后阶段
它仍然展现出了强大的学习能力
如果继续输入更多的token
模型的性能可能还能进一步提高
谁都没想到
目前的模型架构竟然能够容纳如此庞大的数据量
大飞我看到这里
不禁想起前几天做的几期节目
看来苦涩的教训说的是一点没错啊
不相信Scaling Law的人终会被打脸
未来模型究竟会如何发展
没人能够准确预测
因为世界上最难预测的事情之一就是指数级增长的趋势
没人知道到底它会持续多久
唯一能相信的只有继续前进
从历史上看
我们总会在某个时刻遇到发展的瓶颈
但是如今这些瓶颈可能会很快被克服
比如过去几年里的GPU生产
还有资本投入
在什么时候
投入更多的资本就不再具有性价比了
以及能源问题
目前还没人能够建造出一个千兆瓦特的单一训练集群
也没人能建造1吉瓦的数据中心
所以能源会是要面临的一个主要限制
此外
像Meta这样的大公司还会面临严格的监管问题
不过，小扎也认为
模型架构本身还存在某些根本的局限性
以Llama-3为例
尽管已经取得了显著的进步
但是架构仍有进一步优化的空间
人们基于现有模型架构构建出的东西
并不是可以无限可扩展的
在达到下一个技术飞跃之前
我们可能只能在现有的基础上
进行一些优化和改进
从更宏观的角度来看
人工智能其实是一种非常底层的技术
它更像是计算机的发明
将会催生一系列全新的应用
就像网络和手机的出现
让许多以前不可能的事情变得可能
人们开始重新思考新的体验
因此，人工智能将会带来类似的变革
但是它是一种更深层次的创新
就像是从没有计算机到有计算机的转变
由于存在许多物理限制
人工智能不会一夜失控
人类有足够的时间去适应
但是人工智能将真正改变我们的工作方式
为人们提供创新的工具
让人们能够更自由地追求他们真正想做的事情
人们经常会存在另一种偏见
就是认为智能与生命在某种程度上有着紧密的联系
但是事实并非如此
我们还没有对意识或生命有足够清晰的定义来全面理解这个问题
AI可能会发展成为一个与意识和行为完全分离的工具
接下来
小扎重点聊了下开源方面的观点
他目前还是非常支持开源的
但是这并不意味着会公开所有的成果
开源对于社区和Meta来说都是有益的
因为这将促进创新
但是
如果哪天Meta觉得开源是不负责任的
也会选择不公开
这种不确定性是存在的
在开发Llama-2的时候
Meta已经投入了大量资源
来确保它不会被用于不良目的
比如暴力行为等等
但是根本的问题在于如何识别并缓解潜在的不良行为
而非行为本身
评估事物的好坏涉及多个维度
很难事先列举所有可能性
需要时间来细化和识别危害行为
大多数的人会选择直接使用现成的模型
但是也会有一些心怀不轨的人
可能会试图利用这些模型进行不良行为
但是，开源的风险不仅如此
如果未来人工智能过度的集中化
那么它的潜在风险可能不亚于广泛传播
这时候，开源软件就扮演了重要角色
它使得软件的改进不再局限于单一企业的范围
而是能够广泛应用于各种系统
包括银行、医院和政府机构
随着软件的不断完善
更多的人可以参与查看和测试
关于这些软件如何工作的标准也会逐渐建立
当需要升级的时候
全世界可以迅速共同行动
在他看来
这种分布式、广泛部署的方式
比集中化的方式更为健康
虽然确实存在着人工智能系统被用于不良行为的风险
但是如果一个不可信的实体
拥有超级强大的人工智能系统
这可能是一个更大的风险
把人工智能系统开源
有助于建立一个更公平、更平衡的竞技场
其实Meta有着悠久的开源软件传统
虽然并不会将产品直接开源
但是会开源很多底层的基础设施
比如
Meta历史上最大的开源项目之一
就是开放计算项目（Open Compute Project）
将服务器、网络交换机和数据中心的设计全部开源
这带来了的巨大好处是
现在整个行业基本上都以Meta的设计为标准
这意味着整个供应链都是围绕这个设计建立起来的
从而提高了生产效率，降低了成本
为Meta节省了数十亿美元
如果通过开源
人们找到了更加经济高效地运行模型的方法
那么这对Meta来说将是一个巨大的利好
毕竟他们在这上面的投入已经达到了数百亿美元
如果能够通过开源提高10%的效率
那么就能够节省数十亿
而且对于整个市场来说
开源还可以促进整个行业的进步和发展
对于模型训练来说
其中一个趋势就是走向商品化
这将意味着训练的成本大大降低
以及微调质量的提升
拿移动生态系统举例
苹果和谷歌最为封闭
不光是收取高额费用
还会拒绝你发布某些功能
因此，Meta构建自己的模型
是为了确保不会被其他公司限制自己的创新能力
而选择开源
也是希望开发者不要受到这些公司的限制
同时
开源模型社区的发展
会最终为Meta贡献宝贵的价值
让产品变得更加出色
除此之外
通过向云服务商授权模型使用
Meta还可以从中获得可观的收入
Llama采取了非常宽容的开源许可
为社区和开发者提供了广泛的使用权限
但是对于使用它的最大公司则设置了限制
这样做的目的呢
并不是想要阻止他们使用模型
而是希望他们在打算直接转售模型并且从中获利的时候
能够与Meta进行沟通和协商
说白了就是Meta想从像微软Azure
以及亚马逊AWS这样的云服务厂商手中分一杯羹
大飞我觉得呢
这在商业社会中也无可厚非
另外小扎认为
开源正在成为一种全新的强大的构建方式
很多开源项目
像PyTorch、React、Open Compute等等
都将对人类的进步产生持久而深远的影响
虽然具体的产品会随着时间的推移
不断的发展出现和消失
但是技术对于人类社会的贡献却是持久的
最后小扎还是不死心地聊了一下元宇宙
他认为元宇宙是一个让人类从物理束缚中解脱出来的理想平台
它提供了一个全新的维度
让人们能够更加便捷高效的进行社交
建立联系完成工作
并且在工业医学等众多领域发挥巨大的作用
小扎对于元宇宙的信心
来自于他内心想要不断创造新东西的驱动力
他认为自己无法停止创造
而且不仅是在科技领域
在生活方面也是如此
比如说他在考艾岛建了一个牧场养牛
并且亲自参与了所有建筑的设计工作
在高中和大学期间
年仅19岁的他就阅读了大量的古代和古典书籍
尤其对于凯撒奥古斯都如何成为皇帝的故事深感着迷
从那个时候他就意识到
人们都是有自己的思想边界的
很多时候
人们难以理解构建事物的模型
难以理解为什么这件事情会有价值
或者为什么这是一个合理的状态
就像很多的投资人难以理解
为什么Meta要开源这些技术一样
他们认为Meta迟早会把这些开源再变回闭源
但实际上合理的事情比人们想象的要多得多
大飞我觉得
小扎内心里可能就是一个
想要成为像凯撒一样的人
年纪轻轻就创建自己的帝国
毕竟他自己也说
他最喜欢毕加索说的一句话
那就是所有孩子都是艺术家
挑战在于长大后如何保持艺术家的身份
好了
以上就是小扎这次对话的主要内容了
总体而言
他在这次访谈中全面阐述了自己对于AI发展的看法
以及Meta在AI领域的布局和规划
他既看到了AI的巨大潜力
也意识到了其中的风险和挑战
在强调开源和创新重要性的同时
也提出了一些应对于AI风险的策略
此外呢
他还分享了自己的感悟和管理心得
全面展现了一位科技领袖的深度思考
大飞我也希望能够尽早看到Llama 4的发布
以及开源模型在AI领域的百花齐放
感谢大家观看本期视频
我们下期再见
