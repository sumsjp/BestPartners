大家好，这里是最佳拍档，我是大飞
在科技产业的版图上
从来不乏巨头之间的博弈与转型
但像Meta这样在2025年展开的ASI攻坚战
其规模与决心依然令人惊叹
如今
Meta正以一种近乎破釜沉舟的姿态
在算力基建、人才争夺和技术路线上展开全方位的重塑
而这场变革的导火索
或许还要从今年那个震惊行业的收购说起
Meta以约300亿美元的估值
收购了Scale AI 49%的股份
而支撑这一动作的
是Meta每年高达1000亿美元的广告现金流
今天
就让我们跟随SemiAnalysis的最新文章
看看Meta在扎克伯格的亲自操盘下
一个关于超级智能的宏大计划
正在如何浮出水面
在生成式人工智能发展的早期阶段
Meta与谷歌等科技巨头遵循着"人工智能渐进主义"的策略
这种策略的核心是将AI技术作为现有业务的延伸
而非一种颠覆性创新
比方说
它们通过优化推荐系统来提升广告投放的精准度
利用自然语言处理技术来改进内容的审核效率
或者是通过大模型来辅助用户生成内容
这种稳扎稳打的投入在财务上取得了显著成效
尤其是在应对苹果公司的应用追踪透明度（ATT）政策时
Meta通过AI驱动的广告算法优化
成功抵消了用户数据获取受限所带来的冲击
确保了核心广告业务的增长
然而，这种渐进式的策略
也导致了Meta在基础研究领域逐渐落后
当OpenAI的ChatGPT在2023年掀起大语言模型浪潮时
Meta的Llama系列模型虽然在开源领域占据了一席之地
但是在模型性能和用户生态上始终未能形成突破
2025年
当中国的DeepSeek在开源大语言模型的关键评测中超越Meta时
这个曾经的AI巨头终于感受到了危机
那就是在通用人工智能的竞赛中
渐进主义正在让位于激进的战略调整
面对技术领先地位的流失
马克·扎克伯格重新开启了"创始人模式"。
作为少数仍然在一线领导科技巨头的创业者
他敏锐地指出Meta的两大核心短板
分别是算力规模与顶尖人才
在2025年第一季度的财报电话会议上
扎克伯格罕见地将战略重心
从股东回报转向了长期的技术投入
明确表示ASI是公司未来十年的核心使命
为了弥补算力方面的缺口
Meta打破了延续十年的"数据中心建设哲学"。
早期的"H"形数据中心设计
注重稳定性和能源效率
但是面对AI训练对算力的爆发式需求
这种模式在部署速度上显得力不从心
受特斯拉AI团队和xAI快速落地的启发
Meta决定采用一种近乎颠覆的"帐篷式"数据中心架构
放弃传统建筑的永久性结构
转而使用预制化的电力模块、轻量化的冷却系统和快速组装的机架布局
这种设计牺牲了部分的冗余性
但是将算力集群的建设周期从传统的18-24个月
缩短到了6-9个月
为快速扩大算力规模奠定了基础
在人才争夺上
扎克伯格也展现出了惊人的魄力
他亲自参与核心团队的组建
向OpenAI、Anthropic等竞争对手的顶尖科学家抛出天价合约
一位资深AI研究员的典型报价是4年2亿美元
这个数字达到了行业平均水平的100倍
甚至还有传闻称
Meta曾向伊利亚·苏茨克弗（Ilya Sutskever）的SSI团队
提出10亿美元级别的邀约
尽管最终未能达成
但是这种"搅局式"的招聘策略
显著抬高了行业的人才成本
迫使竞争对手不得不跟进投入
在算力方面
位于俄亥俄州的Prometheus 1GW AI训练集群
是Meta算力战略的关键落子
这个庞大的项目采用了"全栈整合"的建设思路
既有自建的核心算力园区
配备了定制化的AI服务器集群
也通过租赁第三方的数据中心来快速扩充容量
仅2024年下半年就预租了超过任何一家 hyperscaler 的算力空间
为了应对当地电网的负荷限制
Meta还与能源公司Williams合作
建设了两座总功率400MW的现场天然气发电厂
配备了3台Solar Turbines的Titan 250燃气轮机、9台PGM 130涡轮机
以及15台卡特彼勒3520往复式发动机
确保在极端用电需求下的稳定供电
在网络架构上
Prometheus采用了Arista 7808交换机
与博通Jericho/Ramon ASIC组成的超高带宽网络
实现了跨数据中心的低延迟通信
这种设计使得分布在不同物理位置的算力单元能够协同工作
形成一个逻辑上统一的超级计算集群
为大规模分布式训练提供了基础设施保障
如果说Prometheus是快速响应的先锋
那么路易斯安那州的Hyperion 2GW集群
则是Meta的"算力旗舰"。
这个规划中的超级园区预计在2027年建成
仅第一阶段就将具备1.5GW的IT电力容量
成为全球最大的单体AI训练基地之一
Hyperion的设计理念更加激进
放弃了传统的数据中心建筑形式
采用模块化的"帐篷式"结构
将服务器集群部署在可快速组装的轻量化设施中
这种设计的核心是"速度优先"，
将从破土动工到算力上线的周期压缩到极限
确保Meta能够在最短时间内
缩小与OpenAI等对手的算力差距
为了支撑Hyperion的电力需求
Meta不仅接入了区域电网
还规划了分布式储能系统和可再生能源补充方案
尽管这种设计在能源效率上略逊于传统数据中心
但是在AI训练的"算力军备竞赛"中
速度与规模成为更优先的考量因素
在技术方面
Llama 4的研发失败是Meta技术路线上的一次深刻教训
这款被寄予厚望的大语言模型
在多个关键评测中表现不及预期
核心问题出在架构设计与数据质量的双重缺陷上
在注意力机制的选择上
Meta为了实现长上下文处理
采用了"分块注意力"（Chunked Attention）技术
这种方法将输入文本分割成固定大小的块
每个块内独立计算注意力
虽然节省了内存资源
但是导致模型在处理跨块逻辑时
会出现"上下文断层"的问题
也就是当推理过程需要跨越块边界时
模型的连贯性和逻辑能力会显著地下降
相比之下
竞争对手采用的滑动窗口注意力或全局注意力机制
虽然在计算成本上更高
但是能够提供更完整的上下文关联
在混合专家路由（MoE）架构的实现中
Meta中途从"专家选择路由"切换为"Token选择路由"，
这个决策带来了严重的训练不均衡问题
前者是由专家主动选择处理的token
确保每个专家模块的负载均衡；
后者则由token来选择专家
导致部分专家过度使用而其他则训练不足
这种架构调整不仅增加了工程的复杂度
还导致模型的部分专家模块未能有效的专业化
最终影响了整体的性能
Llama 4的另一个痛点在于数据质量的控制
在从Common Crawl转向内部网络爬虫数据的过程中
Meta的清洗与去重系统没能应对大规模数据的挑战
新获取的网页数据中包含了大量重复的内容、低质量文本和格式错误
导致训练语料的纯净度下降
更关键的是
与OpenAI、DeepSeek等团队不同
Meta在训练数据中没有纳入YouTube视频的字幕、arXiv论文等优质的多模态数据源
错失了提升模型跨模态理解能力的机会
这种数据策略上的保守
使得Llama 4在处理复杂语义和专业领域任务时
明显落后
为了弥补技术团队的短板
扎克伯格亲自担任了首席招聘官
打造了一支星光熠熠的核心团队
前GitHub CEO纳特·弗里德曼（Nat Friedman）带来了开源生态建设的丰富经验
他的加入标志着Meta将重新聚焦开源模型的领导地位
Scale AI的前CEO亚历克斯·王（Alex Wang）则带来了团队在数据标注与模型评估领域的核心技术
尤其是Scale AI的SEAL实验室开发的"人类终极考试HLE"评测体系
填补了Meta在模型推理能力评估上的空白
此外
来自SSI公司的丹尼尔·格罗斯（Daniel Gross）等顶尖工程师的加入
为团队注入了分布式训练与模型优化的前沿技术
Meta的招聘策略在依靠高薪之外
还尝试去构建一个"算力+数据+应用"的生态吸引力
每位研究员将获得前所未有的算力资源
人均可用GPU数量从行业平均的数十块
提升到了数千块
同时能够接触到Meta旗下20亿日活用户的真实应用场景
这种理论与实践的结合对科研人员具有极强的吸引力
为了避免大公司的官僚化弊端
Meta的超级智能团队还采用了独立于传统业务的敏捷管理模式
他们拥有专属的研发预算、自主的技术决策权限
甚至在数据中心建设上享有优先级保障
这种"创业公司式"的运作机制
使得团队能够快速迭代算法、部署实验
将传统大厂需要几个月的研发周期压缩到几周
例如，在Llama 4失败后
团队迅速启动了Llama 5的预研
摒弃了分块注意力等争议性技术
回归了经过验证的架构
并且融入最新的稀疏注意力研究成果
在财务与政策方面
2025年7月通过的《大漂亮法案》为Meta的算力投资提供了关键的助力
这项法案恢复了100%的奖金折旧政策
允许企业在数据中心设备
比如GPU、服务器投入使用的第一年
即可抵扣全部成本
同时恢复了全额研发费用的税前扣除
而且可以追溯到2022年
这两项政策直接降低了Meta的资本开支压力
根据SemiAnalysis估算
Meta的税务支出就可能因此减少超过50%，
释放出数十亿美元的现金流用于再投资
此外
法案还扩大了利息支出的抵扣范围
允许企业以EBITDA为基础
计算可抵扣利息
这对于依赖债务融资的大型数据中心项目尤为有利
尽管法案逐步取消了清洁能源的税收抵免
但是对"算力基础设施自主可控"的政策倾斜
明确支持了Meta这种重资产投入的技术路线
回顾Meta在虚拟现实领域的Reality Labs
它的早期烧钱式的投入曾经引发股东不满
而如今的超级智能计划吸取了这一教训
更加注重技术投入与现有业务的协同效应
比如
Prometheus集群的算力在支撑AI训练的同时
也被用来优化Facebook和Instagram的广告推荐系统
提升核心业务的变现效率；
Scale AI的数据标注技术
也被整合到内容审核流程中
降低人工成本的同时提高审核精度
这种"技术反哺业务"的模式
使得超级智能计划不再是孤立的研发项目
而是与核心商业体系形成更加良性的互动
不过呢
Meta的超级智能战略也并非没有隐忧
首先是算力投资的回报周期
Hyperion等集群的建设
需要数百亿美元的资本开支
而AI训练的效率提升速度
是否能够匹配投入
仍然是一个未知数
其次是人才竞争的可持续性
天价薪资虽然短期内吸引了顶尖的人才
但是也导致团队薪资结构失衡
长期可能会引发内部公平性的问题
此外，在技术路线上
如何平衡创新与稳健
既要避免Llama 4式的激进冒险
又要防止回到渐进主义的老路
也时刻考验着管理层的技术判断力
而就在这两天
前Meta研究科学家蒂曼·布兰克沃特Tijmen Blankevoort的一封离职控诉信被广泛流传
毫不留情的指出许多离开的员工都对Meta恨之入骨
背后的原因是因为Meta有一种「恐惧文化」，
部分根源在于它的绩效评估体系
以及「末位淘汰制」裁员
今年二月份
Meta就毫不留情地裁掉了5%，
大约3600人的员工
而裁员的依据就是绩效
而且
未来这种绩效的末位淘汰制还会一直持续
布兰克沃特还揭露道
Meta的很多员工
工作的动力都不是AGI使命
或者是什么创造伟业的抱负
而完完全全是源于被解雇的恐惧
这种心态如同癌症一般
已经侵蚀了整个公司
全公司上下人人自危
并且引发了一系列乱象
比如抢地盘、截胡项目、窃取他人的成果等等
而Meta AI业务的另一大问题
则是愿景缺失与各部门的明争暗斗
比如说Meta生成式AI部门的老大
是首席产品官克里斯·考克斯Chris Cox
而搞可穿戴设备的
则是CTO安德鲁·博斯沃思Andrew Bosworth掌管的Reality Labs
两个部门，两个山头
说好听点是分工明确
说难听点就是互不搭理
更雷人的是，Meta最新爆款雷朋眼镜
搭载的就是Meta AI助手，结果呢
这背后的AI团队和眼镜团队却压根没怎么合作
布兰克沃特不得不在控诉信中沉痛总结道
任何一家愿景清晰、心智正常的公司
都会毫不犹豫地拥抱这种合作
但是可惜，我们不是这样的公司
而Meta这种内部复杂的组织架构
其实早已经存在多年
就连Meta的首席科学家LeCun最近也说
在Meta
产品开发的周期在3个月到一年
技术开发则在1到2年，相比之下
研究的跨度为2到10年，甚至更长
而LeCun领导的Meta FAIR实验室
从事的就是基础性的研究工作
因此他关注的领域也会比当前AI流行的东西领先3到5年
也正是因为这个原因
FAIR相对于Meta其他部门能分到的GPU资源
也要少得多
总之
从Llama 3的开源辉煌到Llama 4的折戟沉沙
再到GenAI 2.0的全面转型
Meta的超级智能之路充满了科技巨头转型的典型矛盾
既要突破创新的桎梏
又要承受股东短期回报的压力；
既要在技术前沿冲锋陷阵
又要确保核心业务的稳定现金流
这场始于算力与人才的攻坚战
最终将考验的是一个企业在技术理想与商业现实之间的平衡能力
无论结果如何
Meta的实践也都将为行业提供宝贵的参考
在通用人工智能的竞赛中
没有永远的领跑者
只有持续的颠覆者
当算力成为新的"工业革命燃料"，
当人才成为核心生产力
科技巨头的竞争本质上已演变为战略远见、资源整合与组织韧性的综合比拼
而这
或许正是我们这个时代最激动人心的科技叙事
感谢大家收看本期视频
我们下期再见
