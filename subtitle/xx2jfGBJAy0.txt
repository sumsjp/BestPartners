大家好，这里是最佳拍档，我是大飞
2025年11月27日，西方传统的感恩节
本应是家人团聚、表达感谢的日子
但是对于全球数万名向AI顶级会议ICLR 2026提交论文的研究者来说
这一天却成了学术信仰的崩塌日
一场史无前例的泄露门突然爆发
短短61分钟
整个同行评审体系的双盲遮羞布被撕得粉碎
从审稿人身份裸奔到AI代笔审稿曝光
再到金钱贿赂、人身威胁
AI学术圈最荒诞、最黑暗的一面
被赤裸裸地展现在所有人面前
今天
我们就来从头到尾拆解这场AI学术史上最魔幻的61分钟
看看这场事故到底如何发生
又暴露了学术圈哪些积重难返的问题
在聊漏洞之前
我们需要先介绍一个平台
OpenReview
如果你是AI领域的研究者
对这个平台一定不陌生
它是承载了全球绝大多数AI顶级会议论文评审的核心基础设施
像我们常说的AI三大顶会ICLR、NeurIPS、ICML
还有自然语言处理领域的ACL、计算机视觉领域的CVPR部分评审流程
都依赖OpenReview来实现
OpenReview的初衷其实很好
它想打破传统学术评审的黑箱
以前审稿人是谁、评审意见怎么来
作者往往只能被动接受
而OpenReview希望通过开放评审让过程更加透明
甚至允许社区参与讨论
但是谁也没想到，11月27日这天
它的开放变成了毫无底线的门户大开
问题就出在一个叫profiles/search的API接口上
可能有观众会问
API漏洞不是很常见吗？
但是这次的漏洞低级到让人震惊
在正常的软件工程逻辑里
涉及用户身份、评审信息这种敏感数据的接口
必须经过严格的权限验证
比如，我作为作者
登录后只能看到自己的论文投稿状态
我作为审稿人
只能看到分配给我的那几篇论文
而且在双盲评审阶段
绝对不能看到作者的名字和机构
但是OpenReview的后端
偏偏忘了加这道锁
这种漏洞在技术上有个专业名词
叫BOLA（Broken Object Level Authorization）
对象级授权失效
它是OWASP列出的API安全漏洞里排名第一的类型
也是最容易被忽略、但是破坏力极强的低级错误
简单说
就是系统判断你能不能访问某个数据
只看你输入的URL参数对不对
而不看你是谁、有没有权限
具体怎么操作呢？
你不需要黑客技术
不需要复杂的渗透工具
甚至不用破解数据库密码
你只要拿到某篇论文的投稿ID
然后修改API请求里的参数
想查作者
就把参数改成Submission{论文ID}/Authors
系统会直接返回所有作者的姓名、个人邮箱、所属机构
甚至连他们的个人履历、ORCID
也就是学者唯一标识
还有DBLP论文数据库的链接都能调出来
想查审稿人
就改成Submission{论文ID}/Reviewer_{k}，
其中k是审稿人的序号
这样审稿人的身份信息、还没正式发出的拒稿理由
就全都会暴露
想查负责统筹的领域主席
改成Submission{论文ID}/Area_Chair_{k}就行
这就像你住酒店
发现只要把房卡上的房间号101用马克笔改成102
就能直接刷开隔壁的门，显然
这不是技术多高明
而是系统的基础安全逻辑根本就没有设防
而就是这样一个低级漏洞
给整个AI学术圈埋下了一颗定时炸弹
根据ICLR组委会后来发布的官方报告
我们能精准还原这场61分钟惊魂的每一个节点
而这短短的一个多小时
足以让ICLR 2026的评审体系彻底失控
一切始于2025年11月27日美东时间上午10:
09
北京时间晚上23:09
ICLR的工作流主席首先发现了OpenReview的这个漏洞
意识到它会泄露作者、审稿人和AC的核心信息
于是第一时间通知了OpenReview团队
OpenReview的反应不算慢
在美东时间11:
10，也就是1小时1分钟后
就修复了这个漏洞
看起来
从发现到修复只用了一个小时
算是快速响应了吧
但是在互联网时代
一个小时足以让所有敏感数据飞遍全网
就在漏洞存在的这61分钟里
已经有人写出了简单的爬虫脚本
疯狂抓取平台上的评审数据
到了美东时间12:09
也就是漏洞修复后不到20分钟
ICLR团队就收到消息
一份包含10000篇ICLR投稿论文的详细数据集
已经开始在互联网上流传
从Telegram的私密群组
到Reddit的机器学习板块
甚至有人把数据片段发到了X上
这份数据集还不是简单的论文标题+作者列表
它更像一张庞大的学术关系网
每篇论文的作者是谁、来自哪个机构
分配了3位还是4位审稿人
每位审稿人给了多少分
审稿人的评论里哪些是表扬、哪些是尖锐批评
甚至哪些是阴阳怪气的暗示
负责最终决策的AC是谁
有没有在后台留下初步的判断意见
所有这些本应严格保密的信息
全被扒了出来，摊在阳光下
而另一边
很多被不负责任的审稿人折磨过的作者
却陷入了一种狂欢
有位博士生投稿的论文
被审稿人以缺乏创新为由打了低分
他一直怀疑审稿人根本没看懂自己的工作
结果通过泄露数据查到
这位审稿人自己连一篇AI顶会论文都没发表过
他发帖吐槽
终于知道是谁在胡说八道了！
这就是现世报！
很快
一个调侃ICLR的梗在学术圈传开了
ICLR不再是国际表征学习大会的缩写
而是变成了I Can Locate Reviewer
我能定位审稿人
这个梗背后
藏着的是整个学术圈对现有评审机制积压已久的愤怒与无奈
双盲评审本应是公平的底线
却因为一个低级漏洞，彻底失效了
如果事情只停留在大家知道了彼此是谁
或许最多只是尴尬一阵子
但是当顶会论文和毕业、找工作、拿绿卡、升职加薪这些切身利益挂钩时
人性的弱点被无限放大
学术圈很快陷入了黑暗森林
每个人都可能是猎人，也可能是猎物
ICLR组委会在后续的声明里
披露了很多让人不寒而栗的细节
漏洞爆发后的24小时内
大规模的串通行为开始浮出水面
手段直白到粗暴
第一种是直接公关
有作者拿到审稿人名单后，不再掩饰
直接发邮件给审稿人
李博士或者王教授，您好
看到您是我这篇论文的审稿人
我对您之前的某篇研究非常敬佩
不知道您对我论文里的某个细节有没有疑问？
我可以补充说明
看似客气，实则是暗示对方高抬贵手
更直接的
甚至会说如果您这次能支持我的论文
下次您的工作如果落到我手里
我一定认真对待
这本质上是互保的默契
第二种更恶劣，是金钱贿赂
ICLR的调查发现，有第三方人员
既不是作者也不是审稿人主动介入
他们像学术掮客一样
拿着泄露的审稿人名单
联系审稿人开出条件
只要你把这篇论文的评分从3分提到7分
我可以给你5000美元的咨询费
这种行为已经不是学术不端了
而是赤裸裸的腐败
甚至可能触犯法律
比贿赂更可怕的是报复
有作者通过泄露数据发现
给自己论文打低分的审稿人
竟然来自竞争对手的实验室
而且这位审稿人自己也投了一篇主题相似的论文
很明显，对方是故意打低分
想压低竞争对手的论文
以前这种恶意差评因为双盲
只能靠猜测
没有实锤，但是现在
审稿人的IP、名字、机构全在数据里
证据确凿
更极端的情况发生在美东时间11月28日凌晨5:
30
ICLR团队发现有个恶意用户用自动化脚本
在600多篇论文的公开评论区里
直接点名曝光审稿人身份
这种行为无异于网络开盒
很多审稿人因为给了热门论文差评
被作者的粉丝或利益相关者骚扰
有人收到辱骂邮件
有人的社交账号被网暴
甚至有人的家庭住址被扒出来
收到威胁信息
学术圈本该是追求真理、理性讨论的地方
但是在利益和情绪的裹挟下
却变成了互相攻击的角斗场
为了保住ICLR的公信力
组委会在短短几天内推出了一套组合拳
每一步都很痛苦，但别无选择
第一步是冻结讨论
美东时间11月27日下午4:30
ICLR宣布冻结所有评审表格的编辑功能
同时关闭论文的公开评论区
因为当时每一句讨论
都可能带着场外的威胁或利诱
继续开放只会让混乱加剧
冻结讨论虽然能遏制恶意行为
但是也让很多有价值的学术辩论被迫中断
第二步是分数回滚
组委会决定，将所有审稿意见和评分
回滚到漏洞爆发前的状态
也就是美东时间11月27日10:09之前
这意味着
任何在漏洞泄露期间修改的分数
全部作废
这么做是为了确保评审意见的纯净性
但是也带来了问题
有些审稿人在泄露前已经开始修改意见
补充了更多细节
回滚后这些工作全白费了
只能重新来
第三步是重新分配AC
领域主席（AC）是评审的核心角色
他们负责汇总审稿意见
给出最终的录用建议
但是漏洞泄露后
原来的AC身份已经暴露
可能会被作者或利益方干扰
无法保持中立
所以ICLR决定
给所有论文重新分配新的AC
这意味着之前AC对论文的了解、和审稿人的沟通
全要归零
新的AC需要在极短的时间内重新阅读几十篇论文
工作量直接翻倍
很多AC在私下抱怨，本来年底就忙
现在还要额外处理这么多工作
根本来不及
第四步是严厉惩罚
对于那些利用泄露数据串通、贿赂、骚扰他人的人
ICLR祭出了最狠的手段
涉事的论文直接desk reject
也就是无需经过完整评审，直接拒稿
而且涉事人员会被ICLR永久或多学年封杀
未来3-5年不能投稿，也不能参与评审
同时，传播泄露数据的始作俑者
已经被OpenReview和ICLR联合封禁
组委会还表示会联系多国执法机构
追究相关人员的法律责任
这套措施确实暂时稳住了局面
但是也让ICLR 2026的评审进度严重滞后
组委会原本计划在2026年1月26日前发布录用通知
为了赶上这个时间
新AC的metareview期限被延长到1月6日
而且AC被分成三人一组
遇到难判断的案例要集体讨论
即便如此，很多AC还是坦言压力巨大
只能牺牲休息时间赶进度
ICLR的无奈在于，不这么做
整个会议的公信力会彻底崩塌
这么做
又会给无辜的作者和审稿人带来巨大的麻烦
但是这场危机还没结束
就在大家忙着处理身份泄露的混乱时
一家AI检测公司的报告
又给了学术圈一记更响亮的耳光
这家公司叫Pangram Labs
专注于AI文本检测
CEO是麦克斯·斯佩罗（Max Spero）
在ICLR数据泄露后
麦克斯·斯佩罗团队做了一个大胆的决定
既然泄露的数据已经在流传
不如用它来分析一下AI在学术评审中的渗透情况
他们花了12个小时
扫描了ICLR 2026的19490篇投稿论文
以及75800条同行评审意见
结果让整个学术圈头皮发麻
这可能是AI历史上最讽刺的一幕
根据Pangram Labs发布的报告
核心发现有三个
第一
21%的审稿意见是完全由AI生成的
也就是审稿人没写一个字
全靠ChatGPT、Claude这些工具生成
第二
超过50%的审稿意见有AI参与的痕迹
比如用AI润色语言、补充逻辑
或者直接借鉴AI生成的框架
第三，1%的投稿论文
也就是199篇是完全AI生成的
作者可能只是把想法输入给大模型
让AI写完整篇论文
自己连实验数据都没验证
更让人心惊的是
Pangram Labs为了验证数据准确性
还拿ICLR 2022的评审意见做了基线测试
因为2022年ChatGPT还没推出
理论上不会有AI生成的审稿意见
结果显示，ICLR 2022的审稿意见里
完全AI生成的比例是0
轻度AI编辑的误报率只有千分之一
中度是五千分之一，重度是万分之一
这说明，2026年的21%AI审稿率
不是检测工具的误判
而是真实存在的情况
那么
这些AI生成的审稿意见有什么特征呢
pangram Labs总结了几个典型的表现
第一种是毫无意义的漂亮话
比如开篇就说本文结构清晰
研究方向有价值
具有一定的创新性
但是后面完全没说结构怎么清晰、创新点在哪里
全是万金油式的夸赞
第二种是幻觉引用
AI会一本正经地建议作者
引用某某教授2024年在NeurIPS上发表的论文
认为该研究在相似问题上提出了更优的解决方案
甚至会给出论文的页码
但是作者去Google Scholar或DBLP上一搜
根本没有这篇论文
第三种是车轱辘话
AI会把论文摘要里的内容换个说法重复一遍
第四种是奇怪的详细程度
比如AI会花几百字批评论文里一个标点符号的错误
或者纠结参考文献的格式不对
但是对论文核心算法的逻辑漏洞、实验数据的真实性视而不见
最讽刺的案例来自哥本哈根大学的德斯蒙德·埃利奥特（Desmond Elliott）教授
他的学生收到了一条AI生成的评审意见
意见里不仅对论文的核心贡献理解错误
还编造了两个不存在的前人研究让学生引用
最后给了一个模棱两可的分数
这种分数最折磨人
既不拒稿也不录用
却会消耗AC大量的精力去判断
看到这里，可能有观众会问
这些审稿人为什么要用AI写评审意见？
是他们没有职业道德吗？
其实不完全是个人问题
而是整个学术评审系统产能过剩的必然结果
我们看一组数据
ICLR 2024年收到大约7000篇投稿
2025年涨到11000篇
2026年直接飙升到19490篇
投稿量几乎是指数级增长
但是合格的审稿人数量并没有同步增加
甚至因为AI领域竞争激烈
很多审稿人自己还要写论文、做实验、跑项目
时间根本不够用
这时候，ChatGPT就成了救命稻草
把论文PDF上传
输入提示词帮我写一篇500字的评审意见
语气专业，指出3个潜在问题
几秒钟就能完成任务
21%的AI审稿率
反映的不是审稿人的懒惰
而是整个同行评审系统在AI时代的崩溃前兆
我们生产论文的速度
已经远远超过了我们阅读、评估论文的速度
而更可怕的是
这次泄露事件还顺藤摸瓜
暴露了学术圈另一个长期存在的阴暗面
审稿人圈子
在ICLR的泄露数据里
有一个更扎心的发现
很多论文的评审结果
不是看论文质量，而是看作者是谁
这背后其实是审稿人圈子（Reviewer Rings）和引文联盟（Citation Cartels）的操作
简单说，就是一群研究者结成同盟
如果你是圈子里的人
不管你的论文写得怎么样
我作为审稿人都会给的高分；
如果是圈子外的人，尤其是竞争对手
就鸡蛋里挑骨头，直接拒稿
更隐蔽的操作是引文交换
我给你过稿
但你必须在论文里引用我指定的5篇论文
要知道
学术圈衡量学者水平的核心指标
就是引用量（Citation）和顶会发表量
通过这种方式
一群平庸的研究者能人为制造出学术明星的假象
这种抱团行为不是第一次出现
也不是AI圈独有
比如计算机体系结构领域的SIGARCH会议
曾经爆发过著名的引文联盟丑闻
计算机视觉顶会CVPR也出过类似问题
但是以前这些抱团行为，大多是怀疑
缺乏实锤
而ICLR这次的泄露数据，给了铁证
比如有一篇论文
实验设计有明显的漏洞
结果三位审稿人全给了8分以上的高分
再看审稿人信息
发现他们和作者都是同一个导师带出来的同门
OpenReview的漏洞
无意间充当了揭穿皇帝新衣的小孩
它让我们看到
在公平、公正、双盲的学术规则下
藏着多少人情世故和利益交换
这也让所有人不得不面对一个更尖锐的问题
我们花这么多时间、精力做评审
到底是在评估论文的质量
还是在评估作者的圈子？
这场ICLR泄露门
本质上不是一个简单的技术事故
而是AI学术圈长期积累的矛盾的总爆发
双盲评审机制的脆弱性、审稿人资源的不足、AI对学术诚信的冲击、学术圈的利益抱团
每一个问题都在挑战着学术研究的初心
现在回头看，其实早有预兆
比如在2025年8月的NeurIPS审稿期间
有位审稿人在评审意见里忘了删除给AI的提示词
直接留下了Who is Adam?
的评语
后来大家才知道
他在让AI帮忙写评审时
遇到了Adam优化器的术语
不知道怎么解释，就问了AI一句
结果把问题和答案一起复制进了评审意见
当时大家只是当笑话看
但是现在结合ICLR的事件才发现
AI审稿可能早就不是个别现象了
应该说，AI学术圈的发展
离不开信任二字
包括作者信任评审的公平
审稿人信任匿名的保护
以及整个社区信任学术的纯粹
这场ICLR泄露门虽然惨痛
但是也给了我们一个刮骨疗毒的机会
只有正视问题，解决问题
才能让AI研究回归追求真理、推动技术进步的初心
最后，我想说
学术研究不是一场比赛
不是谁发表的论文多、谁的引用高
谁就赢了
真正的赢，是你做的研究
能让这个世界变得更好一点
希望这场风波之后
AI学术圈能少一些浮躁
多一些踏实
少一些利益，多一些纯粹
好了，今天的内容就到这里
感谢收看本期视频，我们下期再见
