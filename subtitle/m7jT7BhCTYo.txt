大家好，这里是最佳拍档，我是大飞
在ChatGPT横空出世之后
许多人都在讨论
AI到底还需要多久才能完全取代程序员
AI在代码方面超越人类的临界点究竟会在哪里？
此前
大飞我也曾经与一些软件行业从业者讨论过这个话题
不少人都觉得，AI取代程序员的关键
在于AI是否能够进行自我批判
换句话来说
就是AI能否自己修改自己的代码
没想到，这一天会来得这么快
北京时间 6 月 28 日凌晨
紧随 Google 发布 Gemma 2 之后
OpenAI 公开了一篇名为《大语言模型评价帮助发现模型漏洞》（LLM Critics Help Catch LLM Bugs）的论文
详细描述了一款基于 GPT-4 的模型
CriticGPT
这个模型的主要功能
就是帮助人类评估和检测大语言模型生成的代码输出中的错误
CriticGPT通过训练生成自然语言反馈
可以指出代码中的问题
并且在检测自然发生的模型错误时
它生成的评审比人类评审更受欢迎
准确率可以达到63%。
一句话总结就是
OpenAI 实现了让 GPT-4 给 GPT-4 自己改Bug的功能
而且AI在大部分时候表现得比人类更好
今天我们就来聊聊这个CriticGPT
看看这个模型是不是真的要优化掉人类程序员了
之所以说CriticGPT是GPT自己批自己
是因为二者其实师出同门
CriticGPT 也是通过 RLHF 训练的
类似于 ChatGPT
RLHF全称为基于人类反馈的强化学习
Reinforcement Learning from Human Feedback
是包括ChatGPT在内的很多大语言模型常用的对齐方法
指的是AI训练人员会收集模型对同一个问题的不同响应
然后进行评分
以此来改进模型的性能
然而
随着ChatGPT的响应变得越来越准确
它犯的错误也会越来越微妙
让人类训练人员更难以觉察
从而会降低RLHF的有效性
事实上，这也是RLHF的根本限制
随着模型逐渐进化到
比任何提供反馈的专家都更有知识
基于人类的评价来调整模型就会变得越来越困难
因此
OpenAI的「可扩展监督」团队希望能够跳出RLHF的框架
既然人类已经跟不上AI犯的错误了
那就干脆训练一个模型来评价ChatGPT
纠正输出结果中不准确的地方
让英雄来论英雄，好汉去评好汉
因此，研究团队的核心思想非常简单
他们不需要搞一个彻底颠覆以往研究成果的大新闻
只需要在原来的基础上改进就可以了
CriticGPT和其他GPT一样
依旧是一个自回归模型
标注人员先向ChatGPT的响应输出中
人为地注入一些微妙的错误
然后让CriticGPT针对这些有错误的答案生成评价意见
之后再由训练人员为评价意见进行打分排名
这就是CriticGPT与ChatGPT 最大的不同
它有点像是一个用来辨识毒品的缉毒犬
针对AI的错误输出进行了强化训练
学习到如何对这些错误提出评价
此外
OpenAI的训练人员会手动将这些错误
插入到 ChatGPT 编写的代码中
然后撰写示例反馈
就像他们刚刚发现了自己插入的错误一样
然后让同一个人比较多种修改后的代码评价
看看哪个能轻易评判出插入的错误
而CriticGPT的详细训练过程则与ChatGPT类似
首先
训练人员会篡改模型生成的答案
引入细微的错误，并且特别标注出来
这种篡改是对抗性收集的，也就是说
在访问生成评价的大模型时
他们会在三次样本中有意地漏掉篡改的错误
让研究团队和 CriticGPT 都更难以发现这些错误
之所以采用「篡改」这种方法
是因为论文作者想为没有真实奖励函数的长期和开放式任务
找到一种方法
可以简单地在没有修改的答案上训练评价模型
「篡改」的优势在于它提供了质量高、难度大的参考错误
一方面让训练人员更容易区分
模型是否抓住了回答中的错误
巩固排名任务，另一方面
能够确保大部分数据是在与模型分布相似的有错误代码上收集的
而不是来自于现有的错误数据集
人类评估CriticGPT的评价意见时
会从几个不同的维度给出评分和排名
比如是否全面
有没有遗漏任何明显或者严重的问题
是否捕获到了之前插入的特定bug
即CBI（critique-bug inclusion）
有没有出现幻觉或者挑剔现象
有没有指出不存在的问题等等
训练人员会根据 1-7 的等级
来给这些评价打分
前两个特征，也就是CBI和全面性
类似于召回率
如果模型撰写了包括多个错误点的长篇评价
通常评分会提高
然而，评价变长的同时
也可能会包含更多臆想的问题甚至是吹毛求疵
所以训练人员在总体评分时倾向于给准确、全面、简洁而且避免吹毛求疵的评价高分
在人类打分的过程中
训练人员将同时看到对同一问题的四个评价
这样，研究人员可以通过比较
得出特定属性的偏好率
例如
如果评价 A 在全面性的得分为1分
而评价 B 的得分为2分
那么 B 就比 A 更全面
随后
根据训练人员评估的结果来训练奖励模型
并且使用PPO来优化奖励模型
论文作者发现
通过在测试时对评价奖励模型进行额外的搜索
可以生成更长、更全面的评价
这个搜索过程允许研究人员来平衡在代码中查找问题的积极性
并且配置幻觉和所检测错误数量之间的精度
即召回权衡
这意味着 CriticGPT 可以生成对 RLHF 尽可能有帮助的评价
在训练CriticGPT的过程中
除了RLHF的方法
团队还将奖励模型与搜索结合
提出了一种名为强制采样束搜索FSBS（Forced Sampling Beam Seach）的新方法
一般来说，模型产生的评价意见越长
它们就更容易出现幻觉
这有点类似于准确率和召回率之间的权衡
AI其实吃不准人类到底想要更长的回复
还是更加详细的描述
有时为了多写几个字
它们就会开始胡编乱造
或者把一些无伤大雅的问题放大
导致输出的信息又臭又长
而FSBS的作用
就在于激励CriticGPT在产生更长、更全面评价的同时
减少无中生有或者鸡蛋里挑骨头的概率
当然
OpenAI还是忘不了他们最喜欢的Scaling Law
他们用RLHF训练并且评估了一系列的模型
用来探索模型规模对bug检测效果的直观影响
从他们披露的实验结果来看
想要达到不使用FSBS的CriticGPT的同等水平
在没有额外数据或者修改pipeline的情况下
需要将ChatGPT的预训练计算量
扩大30倍以上
要知道
OpenAI 在GPT-4 的训练中就已经使用了大约1.76万亿的参数
2.15乘以e25 的FLOPS了
这如果是还要往上翻30倍
恐怕OpenAI自己也吃不消
所以这足以证明CriticGPT的必要性
而采取了FSBS的CriticGPT也没有辜负开发人员的期待
在结果评估阶段表现优异
检查bug的能力超过了大部分的人类程序员
具体的评估流程是这样的
首先
团队把人类和CriticGPT撰写的评价意见
混杂在一起，再交给人类来进行评估
看看人类自己更喜欢哪一方的批改结果
根据论文中公布的测试结果来看
63%的情况下
CriticGPT撰写的评价意见都比人类的更受青睐
要知道
研究团队招来写评价意见的不是编程的门外汉
而是有着平均5年Python开发经验的技术人员
然而
老到的经验并没有能够帮助人类战胜AI
即使在能够执行代码以及允许查找参考手册的情况下
这些程序员在每个错误案例上依然需要花费大约50分钟的时间
结果也只能发现25%左右的、人为插入的bug
论文认为
这次人类一败涂地的原因在于
这些评估人员可能缺乏所需要的领域知识
毕竟
再资深的程序员也不可能掌握世界上每个Python库的用法
在这种情况下
大模型的通用性优势就发挥得淋漓尽致了
CriticGPT的检测错误能力相当全面
可以针对各种特定的python库
而且无论是对于人为篡改的错误
还是原始输出中本来就存在的错误
都达到了最高的全面性百分比
更令人惊讶的是
ChatGPT在这两个方面的表现
也都超过人类独立撰写的评价意见
评估人员需要借助CriticGPT
才能达到与ChatGPT相当的水平
不过
AI这队也还没有到可以开香槟庆祝的时候
即使采用了FSBS
幻觉和评估意见准确度等问题依然在困扰着GPT
团队发现，虽然人类容易遗漏错误
但是人类也最不容易产生幻觉或者「鸡蛋里挑骨头」的问题
在产生幻觉这方面
ChatGPT的表现最不如人意
而采用FSBS的CriticGPT稍有提升
但是总体而言依然不及人类
考虑到评价意见的全面性与减少幻觉之间的权衡
OpenAI的开发人员提出了「人机合作」的模式
根据他们的实验结果
人类+CriticGPT的团队表现
能够超越模型或人类单独工作时的帕累托边界
这个结果也符合OpenA一贯的立场
那就是强调人类与AI的合作
而不是互相竞争取代
在论文的最后，开发者也强调
CriticGPT的终极目标是帮助人类评估模型
训练出更好、更安全的策略
从长期来看
人类应该找到一种泛化性更强的评价模型训练方法
适用于没有groung truth和奖励函数的长期和开放式任务
从短期来看
CriticGPT依旧存在着幻觉问题
如果编码任务或者原模型的输出过于复杂
即使是有模型协助的专家
也可能无法做出很好的评估
不过
这篇文章的方法也为今后的RLHF训练带来了一种新鲜思路
那就是将RLHF应用到GPT-4中
训练出CriticGPT这样的模型
可以合成出更多的高质量RLHF数据
这次CriticGPT公开
应该说给最近的OpenAI挽回了一些面子
不仅GPT-5遥遥无期
前几天还宣布GPT-4o的语音功能将推迟一个月发布
与此同时
友商追赶的脚步也越来越快
Anthropic发布的Claude 3.5 sonnet和GPT4o相比
在性能上可以说相差无几甚至略微超过
也许因为强大的外部压力
OpenAI才选择在28号放出了新模型CriticGPT
试图稳住自己的支持者和投资人
不过，有意思的是
CriticGPT的作者之一
其实是已经离职的超级团队的负责人
简·雷克 Jan Leike
尽管简在离开的时候还与老东家OpenAI 上演了一出撕逼大战
不过这次 CriticGPT 的发布
简还是在X上发了篇推文宣传了一下
只是在X推文的最后
他又附上了Anthropic 的招聘信息
所以呢
你很难说他到底是来给open i站台的
还是来拆台的
实在是呢
让人哭笑不得
好了
以上就是对CriticGPT的简单介绍
总的来看
CriticGPT虽然在GPT4的基础上
取得了一定的突破
实现了有限的自我批判能力
但是由于幻觉等原因
依然不能完全脱离人类单独工作
屏幕前的码农们可以暂时松一口气了
不过未来谁又说的准呢？
那么大家是如何看待CriticGPT的
欢迎在评论区留言
感谢大家的观看，我们下期再见
