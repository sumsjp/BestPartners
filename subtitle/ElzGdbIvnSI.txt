大家好，这里是最佳拍档，我是大飞
2025年5月19日
英伟达CEO黄仁勋在台北流行音乐中心的Computex大会上
发表了一场主题演讲
可能又将预示着未来十年的产业走向
这场长达两小时的演讲
不仅勾勒出了英伟达从芯片公司向AI基础设施巨头的转型路径
更是首次系统性地阐述了智能革命时代的技术框架与产业逻辑
今天
我们就来深入拆解这场演讲背后
英伟达的技术脉络与战略野心
黄仁勋的演讲以英伟达30年发展历程为切入点
揭示了这家公司如何通过三次关键转型
成为全球AI革命的核心引擎
1993年成立之初
英伟达还只是一家专注于图形芯片的技术公司
目标是打造“让计算机能够实时渲染3D图形的芯片”。
但是真正改变命运的转折点出现在2006年
当CUDA并行计算架构诞生后
英伟达首次将GPU的通用计算能力展现在了世人面前
黄仁勋在演讲中回忆
当时我们突然意识到
GPU的并行计算特性可能会开启一个全新的计算时代
这种前瞻性的判断
在十年后也迎来了爆发式的验证
2016年，深度学习的浪潮初现
英伟达敏锐捕捉到了AI对计算架构的颠覆性需求
同时黄仁勋也做出一个关键决策
那就是将公司技术栈全面转向AI优化
他亲自推动开发的DGX-1系统
虽然在发布时遭遇市场冷遇
既没有人理解他在说什么
也没有人下订单
但是当第一台DGX-1捐赠给OpenAI后
这个举动无意间却点燃了AI革命的导火索
随着GPT系列模型的爆发
人们才意识到
专门为AI设计的计算系统
才是这场革命的底层基石
到了2025年
英伟达又完成第三次战略升级
从“AI技术的供应商”转型为了“智能基础设施的构建者”。
黄仁勋将这个转变类比为电力革命中的GE与西门子
他说道
当我们意识到AI正在成为像电力、互联网一样的基础设施时
英伟达的使命就从制造芯片
转变为构建支撑全球智能经济的底层架构
这种定位的转变
直接催生了“AI工厂”这个全新的概念
传统的数据中心被重新定义为了“输入能源、输出高价值token的智能工厂”，
而英伟达的目标
就是成为这些工厂的“基建总承包商”。
在技术层面
英伟达的核心竞争力源自于两大支柱
分别是CUDA构建的软件生态
以及与NVLink打造的硬件互联体系
黄仁勋在演讲中多次强调
库（Libraries）是我们一切技术的起点
从1999年推出首款支持CUDA的GeForce 256显卡开始
英伟达用了二十多年的时间
构建起了庞大的CUDA-X库生态
这些针对不同领域优化的库
如今构成了加速计算的核心竞争力
比如
在图形领域，DLSS技术通过AI渲染
实现了渲染1/10像素
生成9/10像素的效果
使得GeForce RTX 5060的实时光线追踪性能
提升了10倍
在科学计算领域
cuQuantum库为量子-经典混合计算提供了架构支持
预计2030年全球超算将普遍配备“QPU+GPU+CPU”的混合架构
在生物医学领域
Monai库推动了医学影像分析效率提升300%，
助力癌症早期筛查技术的突破
而在硬件层面
NVLink技术的开放战略成为了本次演讲的关键转折点
作为英伟达独家的高速互连技术
NVLink曾是其系统性能的核心壁垒
带宽可达7.2TB/s，是PCIe 5.0的18倍
但是通过NVLink Fusion计划
英伟达首次向第三方开放了技术授权
其中，芯片组方案允许第三方加速器
比如联发科的定制ASIC
直接接入英伟达的生态
而IP授权模式则支持合作伙伴在自研芯片
比如富士通、高通的下一代CPU中
集成NVLink接口
应该说，这种“半开放的生态”策略
既保持了英伟达技术栈的兼容性
又可以吸引更多玩家加入到生态体系中
堪称“用技术标准收割行业红利”的经典案例
谈到AI
黄仁勋用“十二年前从感知起步
未来十年向物理世界进军”来概括了AI的进化路径
他将AI的发展划分为三个阶段
第一个是感知AI阶段
从2010年2020年
以图像识别、语音理解为核心
代表技术包括ResNet卷积神经网络、WaveNet语音合成等等
第二个是生成与推理AI阶段
从2020年到2030年
从ChatGPT的文本生成
到思维链、思维树的推理能力突破
AI开始具备分解问题、模拟决策的能力
第三个是2030年后开始进入物理AI阶段
要求AI理解现实世界的物理规律
比如物体的持久性、摩擦力建模等等
典型的应用包括自动驾驶模拟、工业机器人训练
为了推动这个进化过程
英伟达推出了两大关键技术
分别是Newton物理引擎和Isaac Gr00t平台
其中
Newton物理引擎是与DeepMind、迪士尼合作开发的
支持刚体与软体的高保真模拟
今年7月开源后将成为机器人训练的基础设施；
而Isaac Gr00t平台是基于Jetson Thor芯片的机器人开发平台
集成了从训练到部署的全流程工具
其N1.5版本已经开源
并且已经获得了6000次的下载
黄仁勋还特别强调了Agentic AI的概念
他说，未来的AI一定会像人类一样
具备从理解到思考到行动的完整能力
因此，一个由Agent组成的AI员工群体
可能会在2030年承担企业中30%的重复性工作
目前，英伟达内部所有的软件工程师
都已经在使用AI Agent来辅助开发
代码生成的效率提升了40%。
在计算架构方面
黄仁勋详细介绍了为AI推理时扩展而设计的Grace Blackwell
它有两个关键的能力
分别是scale up和扩展scale out
黄仁勋解释了这两个概念的区别
scale up意味着将一台计算机变成一台巨型计算机
而scale out是将一台计算机连接到多台计算机
让工作在多台不同的计算机上完成
scale out很容易，scale up却很困难
建造超越半导体物理极限的大型计算机
更是极其困难的
而这正是Grace Blackwell所做的
他宣布Grace Blackwell系统已经全面投产
以及将在今年第三季度
升级到Grace Blackwell GB300
GB300将保持相同的架构、相同的物理占用空间、相同的电气机械
但是内部会配备新的Blackwell芯片
推理性能可以提高1.5倍
HBM内存增加1.5倍，网络能力提高2倍
从而带来更高的整体系统性能
接着
黄仁勋详细展示了Grace Blackwell的内部构造
相比于B200
B300在计算中央采用了100%液冷
他指出
单个节点的性能大约为40 petaflops
相当于2018年Sierra超级计算机
当时
这台超级计算机有18000个Voltage GPU
而如今
一个Blackwell节点就可以取代整个超级计算机
6年内将性能提高了4
000倍，这就是摩尔定律的极限
在算力民主化（democratization）方面
英伟达通过DGX系列的新产品
试图复制PC革命的成功路径
其中，DGX Spark定位为“个人AI云”，
提供1 Peta FLOPS的算力与128GB的HBM内存
相当于2016年DGX-1的性能
但是体积缩小了80%，
可以直接放置在办公桌面上
这款产品的合作伙伴包括戴尔、惠普等传统PC巨头
目标是让中小企业与开发者不需要依赖云端
就可以运行十亿级参数的模型
而DGX Station的定位则是终极个人超级计算机
支持运行1万亿参数规模的模型
采用与数据中心相同的编程模型
实现一次开发，多端部署
黄仁勋还戏称，你可以把它放在厨房
但是要小心微波炉启动时的电力波动
应该说
英伟达正在试图通过这种“从数据中心到桌面”的一致性架构
来降低AI的开发门槛
正如黄仁勋所言，1980年代
PC让普通人拥有了计算能力
而从2025年起
DGX系列将让普通人拥有AI开发能力
除了个人产品以外
针对传统企业IT的转型需求
英伟达这次提出了“AI原生架构”的理念
主张重构计算、存储、网络的三层架构
首先
在计算层推出RTX Pro Enterprise服务器
支持x86虚拟化与Kubernetes集群管理
同时集成AI Agent运行环境
实测数据显示
该服务器运行Llama 70B模型的性能
是上一代Hopper H100的1.7倍
而DeepSeek R1模型在优化后
性能更是可以提升4倍
其次
在存储层开发AI-Q智能查询系统
将传统SQL的结构化查询升级为语义检索
查询速度可以提升15倍
结果相关性可以提高50%。
这个系统的关键创新在于
将GPU引入了存储机架
实现了非结构化数据的实时嵌入计算
最后
在网络层通过NVLink spine来构建“机架级主板”，
单个机架内让72颗GPU通过每秒130TB的带宽互联
数据传输量甚至超过了全球互联网大约每秒112.5TB的峰值流量
这种架构让AI工厂能够实现“跨芯片的无缝协作”，
从而破解传统分布式计算的通信瓶颈
黄仁勋还特别指出
未来企业的IT部门将成为‘数字员工的人力资源部’，
负责管理、评估、优化AI Agent的工作流
目前
英伟达已经与埃森哲、德勤等咨询公司合作
推出了企业AI转型的解决方案
帮助客户在现有IT架构中集成AI Agent
在演讲的工业应用板块
黄仁勋展示了台湾地区企业的一些数字化实践案例
其中台积电正在为自己的下一代晶圆厂构建数字孪生
通过Omniverse来模拟光刻机调试、晶圆传输等精密流程
预计可以将设备的调试时间缩短40%；
而鸿海精密则利用Isaac Sim来训练协作机器人
通过在模拟环境中完成数万次的抓取、装配测试
让物理机器人的部署周期从6个月缩短到了2周
高雄市政府也在积极构建城市级的数字孪生
涵盖了数十万栋建筑与数百万公里道路
用于交通流量优化、灾害模拟等场景
这些案例背后
体现了英伟达“模拟优先”的技术策略
因为在物理世界试错的成本太高
所以AI必须先在虚拟世界里
学会如何与现实互动
在演讲的尾声
黄仁勋宣布将在台北北投士林科技园区
建设“英伟达Constellation”海外总部
这个选址背后蕴含了多重战略考量
首先在技术生态方面
台湾聚集了全球60%的半导体封测产能、40%的PCB制造能力
英伟达在此设立总部
可就近与台积电、联电等合作伙伴深化技术协作
其次是市场辐射
作为亚太地区的科技枢纽
台北能够有效覆盖中国大陆、日本、韩国等关键市场
尤其在AI服务器需求爆发的背景下
地缘优势显著
预计2025年全球AI服务器市场规模将突破300亿美元
第三是人才储备方面
台湾拥有超过10万名的半导体从业人员
英伟达更是计划未来三年在台扩招50%工程师
重点布局AI芯片设计、机器人算法等领域
黄仁勋还以幽默方式呼吁支持
市长想知道市民是否欢迎我们建设新总部
我相信大家知道该怎么做
请立即给他打电话
应该说，这个提议背后
不仅体现了英伟达对台湾地区技术生态的高度依赖
也是英伟达“智能基础设施全球化”战略的一步重要落子
回顾整场演讲
黄仁勋反复在强调一个核心的观点
那就是AI不是工具
而是重构一切的底层架构
从电力革命到互联网革命
历史已经证明
基础设施的变革将催生出全新的产业形态
英伟达正在试图通过“开放生态+垂直整合”的双重策略
来构建一个横跨芯片、系统、软件、服务的AI基础设施帝国
正如黄仁勋在演讲开篇所说的
GeForce把AI带给世界
现在AI回来改变一切
当英伟达的技术栈逐渐渗透到计算、存储、网络、机器人、数字孪生等各个领域后
我们看到的不仅是一家公司的转型
更是整个科技产业的底层逻辑重构
未来十年
这场由AI基础设施引发的变革
将会如何重塑全球经济格局呢？
或许
黄仁勋在演讲结尾的提问更值得我们深思
当AI成为像电力一样的基础设施后
人类社会的下一个奇点会在哪里出现呢？
好了以上就是黄仁勋这次Computex大会演讲的核心内容了
希望对大家有所帮助
感谢大家观看本期视频
我们下期再见
