大家好，这里是最佳拍档，我是大飞
2017年
谷歌在开创性论文《Attention Is All You Need》中提出的Transformer
如今已经成为了大模型的主流架构
然而刚刚
一家由 MIT 计算机科学与人工智能实验室 (CSAIL) 的前研究人员
共同创立的初创公司 Liquid AI
却走出了一条不一样的路线
Liquid AI 的目标是要探索出一条
构建超越Transformer 基础模型架构的方法
为了实现这个目标
Liquid AI推出了首批的多模态 AI 模型
Liquid Foundation Models，简称LFM
根据Liquid AI的说法
这是基于第一性原理构建的、新一代的生成式AI模型
不仅在各个模型规模上都能实现SOTA性能
同时还保持了更小的内存占用和更高效的推理能力
Liquid AI的后训练主管马克西姆·拉博内Maxime Labonne 更是发推文表示
LFM是他职业生涯中最自豪的工作成果
LFM的核心优势不仅在于性能上胜过了基于Transformer的模型
而且还占用更少的内存
敢夸下这样的海口
看来Liquid AI对于他们的新架构是信心十足
今天大飞就来带大家看看
这位Transformer的新晋挑战者
到底有什么本事
咱们先来简单介绍一下LFM的性能
这次Liquid AI 公布的LFM 系列模型
拥有三种不同的尺寸和变体
首先是密集型LFM 1.3B
也是参数规模最小的一款模型
非常适合资源高度受限的环境
在与同等规模模型的比较中
LFM-1.3B在各项基准测试中都取得了最高分
包括优于Meta的Llama 3.2-1.2B 和微软的Phi-1
这也是非Transformer架构的模型
首次显著优于基于 Transformer的模型
其次是密集型 LFM 3B
这个模型不仅适合部署在边缘设备端
而且在与 3B Transformer 模型、混合模型和 RNN 模型的性能比较中
名列第一
此外，LFM 3B在多个基准测试中
不仅可以做到与 Phi-3.5-mini 相当
同时规模还比后者小了18.4%，
可以看出
LFM-3B 是移动端和其他边缘端文本应用的理想选择
最后是LFM 40.3B MoE 模型
这是目前LFM 系列中最大的一个模型
为了专门处理更为复杂的任务
Liquid AI特意打造了这个类似于 Mixtral 的专家混合模型
那我们为什么不去用Mixtral或者同样规模的Llama呢？
根据Liquid AI 自己的说法
LFM-40B 在模型大小和输出质量之间
实现了一个新的平衡
它在运行的时候
可以激活 12B的 参数
让自己的性能可以媲美更大的模型
而MoE架构不仅可以实现更高的吞吐量
还可以在更具有成本效益的硬件上进行部署
不难看出
对比市面上现有的模型来说
LFM的第一优势就是精简
与使用Transformer 的传统模型相比
LFM占用的内存相对更少
尤其是对于长输入场景
因为在基于 Transformer 的模型中
KV 缓存会随着序列的长度而线性增长
但是通过高效的压缩输入
LFM可以在相同硬件上
处理更长的序列
因此在与其他3B模型的对比中
LFM占用的内存最少
举例来说，LFM-3B只需要16 GB的内存
而Meta的Llama-3.2-3B 则需要超过48 GB的内存
除了内存以外
LFM架构还拥有更强的上下文能力
对于开发者来说
可以在这个基础上打造更长的上下文窗口
借助于这个优势
LFM首次在边缘设备上实现了长上下文任务
解锁了新的应用场景
包括文档分析和摘要、允许用户与可以感知上下文的聊天机器人
进行更有意义的交互
以及提高检索增强生成 RAG 的性能
这样一来
模型不仅在原始的性能基准方面
具有很强的竞争力
而且在运营效率方面也颇有优势
让它成为了各种场景下的理想选择
比如从金融服务、生物技术到企业级应用和边缘设备部署
好了
对模型的评测我们先简单介绍到这里
下面进入今天视频的重点
也就是LFM所使用的特殊架构
液体神经网络 Liquid Neural Networks
简称LNN
简单来说
液体神经网络LNN是Liquid团队提出的一种全新架构
与需要数千个神经元来执行复杂任务的传统深度学习模型不同
LNN只需要更少的神经元
就可以实现相同的结果
具体来说
LNN的设计空间主要由两个维度定义
分别是核心运算符的特征化和计算复杂度
所谓的特征化是指将输入的数据
比如说文本、音频、图像和视频
转换为结构化特征集或者向量的过程
这些特征或者向量的作用
就是以自适应的方式来调节模型内部的计算过程
比方说，与语言和多模态数据相比
音频和时间序列数据通常信息密度较低
在运算符中需要较少的特征化处理
另一个关键的维度
就是运算符的计算复杂度
也就是完成操作所需要的计算资源
通过探索和完善设计空间
团队能够在控制计算需求的同时
最大化模型的性能
为了实现这两个维度的架构
Liquid AI根植于动态系统理论、信号处理和线性代数理论
设计了一种混合的计算单元
并且在此之上开发出了一些通用的AI模型
能够用来模拟任何类型的序列数据
包括视频、音频、文本和时间序列信号
从而进一步用来训练更强的LFM
因此
LFM模型不仅保留了LNN的核心优势
同时还允许模型在推理过程中进行实时的调整
这样就不会带来传统模型相关的计算开销
这个优化使得LFM可以高效地处理多达100万个 token
同时将内存使用量降到最低
也让基于Liquid架构开发的模型
非常适合需要大量顺序数据处理的应用程序
比方说文档分析或者聊天机器人
有意思的是
LNN的灵感竟然来自于仿生学
也就是线虫的神经结构
LiquidAI的研究人员发现
在生物学上
秀丽隐杆线虫虽然体长仅为1毫米、只有 302 个神经元、96 块肌肉
但是却具备了感知、逃逸、觅食、交配等复杂的智能行为
可以说，它既是最简单的生命智能体
也是通过生物神经机理
模拟实现通用人工智能的最小载体
受到秀丽隐杆线虫的神经结构启发
Liquid AI的研究人员
设计出了一种「液态时间常数网络」（ Liquid Time-constant Networks）
这是什么什么意思呢？
如果说
标准的神经网络像是一层层间隔均匀的水坝
每层水坝上安装了许多阀门
代表权重
而计算的洪流每流经一层水坝
都要透过这些阀门
汇总以后再奔向下一层
相比之下
液态神经网络则不需要水坝
因为每个神经元都由微分方程ODE控制
这种网络的特点就是时间常数可变
而输出可以通过求解微分方程得到
研究表明
它在稳定性、表达能力和时间序列预测方面
都要优于传统模型
后来
Liquid AI又提出了一种近似的方法
可以用闭式解来高效地模拟神经元和突触之间的相互作用
不仅大大提高了模型的计算速度
也表现出了更好的可扩展性
尤其在时间序列建模方面表现出色
优于许多先进的循环神经网络模型
适合分析任何随时间波动的现象
包括视频处理、自动驾驶、大脑和心脏监测、金融交易和天气预报等等
目前
Liquid AI已经将自家的基础模型
构建成了跨多种数据模态的通用模型
希望凭借着这种多模态能力
能够解决各种行业所面临的挑战
与此同时
Liquid AI 也正在为多家硬件制造商的产品
进行模型方面的优化
包括 NVIDIA、AMD、Apple、Qualcomm 和 Cerebras
Liquid AI 还邀请了很多早期用户和开发者
测试他们的新模型
提供反馈并且改进模型
虽然现在模型还不够完美
但是Liquid AI计划将于2024 年 10 月 23 日在麻省理工学院举行正式的发布会
并且为了保持研究的透明度和推动科学进步
还会在发布会前
发表一系列的技术博客文章
如果到时候还有相关新技术公布的话
大飞也会持续跟踪报道的
就目前来看
Liquid AI 推出的LFM以及Liquid架构
结合了高性能和高效的内存使用
为传统基于Transformer的模型提供了一个强有力的替代选择
有望成为基础模型领域的重要玩家
不过
这家有能力做出如此突破性进展的公司
相信大部分人却没有听说过他们的名号
那Liquid AI到底是什么来头呢？
实际上
Liquid AI是由 MIT 计算机科学和人工智能实验室 CSAIL 孵化出来的
成立于 2023 年 3 月
公司一共有四位联合创始人
拉明·哈萨尼Ramin Hasani是Liquid AI的首席执行官
同时也是MIT CSAIL的机器学习研究合作伙伴
在此之前
他以优异的成绩获得了维也纳工业大学（TU Wien）的计算机科学博士学位
后来到MIT CSAIL进行博士后研究
与丹尼尔·罗斯Daniela Rus教授一起负责
有关智能建模和序列决策的研究
他的研究主要集中在复杂动态系统中的鲁棒性决策算法
另一位联合创始人是马蒂亚斯·莱希纳Mathias Lechner
他也是Liquid AI的首席技术官
是哈萨尼在MIT CSAIL的研究合作伙伴
他分别于2017年和2016年在维也纳工业大学（TU Wien）获得了计算机科学硕士和学士学位
并且于2022年在奥地利科学技术研究所（ISTA）获得了博士学位
在MIT的研究工作期间
他专注于开发具有鲁棒性而且可信的机器学习模型
MIT CSAIL的主任丹尼尔·罗斯
也是公司的创始人之一
这位著名的机器人学家和计算机科学家
也是CSAIL实验室的首位女性主管
最后的一名联合创始人、首席科学官亚历山大·阿米尼Alexander Amini
也曾经是丹尼尔·罗斯的博士生
2023年12月
Liquid AI拿到了种子轮融资3750万美元
估值达到 3 个亿
投资人包括 GitHub 的联合创始人 汤姆·普雷斯顿·韦恩Tom Preston Werner、Shopify 的联合创始人托比亚斯·吕特克 Tobias Lütke 以及Red Hat 的联合创始人鲍勃杨等人
目前 Liquid AI 还没有计划为消费者开发像 ChatGPT 这样的应用程序
公司首先关注在为金融和医学研究建模的企业客户
好了
以上就是对Liquid AI 及其全新架构的介绍了
对于这款基于虫脑而非人脑的模型架构
大家会考虑使用吗？
欢迎在评论区留言，感谢大家的观看
我们下期再见
