大家好，这里是最佳拍档，我是大飞
7月1日
OpenAI发布了官方的第2期播客节目
OpenAI的两位核心人物
首席研究官马克·陈Mark Chen与ChatGPT的负责人尼克·特利Nick Turley
与主持人安德鲁·梅恩Andrew Mayne展开了又一场深度对谈
详细回顾了ChatGPT从一个险些被搁置的内部项目
到引爆全球技术浪潮的完整历程
此外
几人还深入探讨了“ChatGPT”这个名字的由来、产品发布初期是如何应对“病毒式”增长的混乱与挑战、ImageGen的意外爆发、Codex的代码能力演进
以及公司在AI安全、产品哲学与未来人才需求等方面的深刻思考
今天大飞就来给大家分享一下
ChatGPT这个如今家喻户晓的名字
当初究竟又是如何诞生的呢？
谈话的一开始，尼克·特利就透露
ChatGPT最开始的名字其实是“Chat with GPT-3.5”。
但是这个名字太拗口了
所以直到发布的当天
才被团队简化为了如今的“ChatGPT”。
Turley坦言
这个项目本身的启动其实也相当晚
在发布的几周前
这个项目甚至都还都没有正式启动
没想到的是，由于日程过于紧迫
最终却促成了一个更加简洁、也更为成功的品牌名称
他回忆起当时的情景
最初OpenAI内部仅仅是在计划进行一次小范围的研究性预览
由于产品是基于已经发布了几个月的GPT-3.5
所以单纯从技术角度来看
许多成员认为它并没有什么颠覆性的创新
只是增加了一个交互界面
让用户不必再写复杂的提示了
然而，产品发布后的市场反应
却彻底颠覆了所有人的保守预期
那么，究竟是在哪个时刻
团队成员们才真正意识到
ChatGPT即将引爆全球？
Nick Turley回忆道，第一天
当他看到后台数据出现异常飙升的时候
他的第一反应并不是兴奋
而是典型的工程师式的怀疑
是不是数据看板出故障了呢？
他本能地认为
这一定是日志记录系统出了问题
而不是真实的用户行为
第二天，随着数据的持续攀升
而且日志系统被证实无误
他开始尝试为这个反常现象
寻找一个合理的、可控的解释
认为也许是日本Reddit用户的推波助澜
造成了一个局部的热点事件
第三天，他的心态又变了
开始承认它确实在病毒式传播
但是依然认为这股热度很快就会消退
直到第四天，他才不得不承认
这个产品将改变世界
对于这场始料未及的成功
Mark Chen也坦承
他们完全没有预料到
他补充说
OpenAI在过去几年里做过很多次的产品发布和研究预览
但是这一次市场反应的量级和速度
确实非同凡响，增长的势头异常迅猛
为了印证这场变革对自己生活的具体影响
他甚至分享了自己的一则温馨的家庭趣事
他的父母也终于不再劝他跳槽去Google了
主持人Mayne追问
难道在ChatGPT横空出世之前
作为OpenAI技术团队核心成员的Mark Chen
他的父母还在质疑他的工作选择吗？
Chen笑着承认了这一点，他解释说
因为他的父母以前从来没听说过OpenAI这家公司
并且多年来一直认为AGI是一个不切实际的幻想
所以他们觉得自己的儿子
实际上并没有一份“正经的工作”。
因此，ChatGPT获得巨大成功之后
才让他们真正理解到了儿子的事业价值
Mayne又提到，有趣的是
就连“GPT”这个如今无人不晓的缩写
它的全称
其实在公司内部也曾经存在小范围的误解
当时研究部门的内部
一半人认为是“生成式预训练”（Generative Pre-trained）
另一半则认为是“生成式预训练 Transformer”（Generative Pre-trained Transformer）
Mark Chen这次终于给出了官方答案
是后者
而且在OpenAI内部很多人对ChatGPT的爆火还在懵逼的时候
Mayne自己却预感到了一种将有大事发生的信号
尤其是当他看到了产品发布会后
用户量近乎垂直的增长曲线
等到ChatGPT真正登上著名动画剧集《南方公园》的时候
他知道
一切都得到了最终的应验
Nick Turley对此也记忆犹新
他表示自己是时隔很久才再次观看《南方公园》，
而那一集至今仍令他惊叹
看到自己参与创造的东西融入了流行文化
那种感觉非常奇妙
他还特别提到了片尾的一个点睛之笔
当集的字幕赫然写着“编剧：
崔·帕克Trey Parker和ChatGPT”。
Turley认为这实在是太酷了
不过
Mayne敏锐地补充了一个后续的细节
他记得最初的字幕确实是这样
但是后来似乎在某个时候
制作方拿掉了ChatGPT的署名
对此，Turley也表达了他的个人看法
认为确实没有必要为AI署名
因为是否公开自己使用了AI
这应当完全属于创作者的自由范畴
不应被强制要求
这场始料未及的成功
甚至让OpenAI的CEO Sam Altman最初也判断失误
Mayne回忆起
在产品发布几周后的公司圣诞派对上
CEO Sam Altman上台发言时
曾经说过一句让大家深有同感的话
看到产品这么火我们很激动
但是互联网的热潮总会过去
但是事实是，热度丝毫未减
反而愈演愈烈持续飙升
那么
为了应对这股空前暴增的用户需求
OpenAI又究竟采取了哪些措施
来维持系统的基本运行呢？
Nick Turley回顾起当时的场景
团队当时面临着非常多的制约
情况远比外界想象的要严峻
许多早期用户应该都还对那段时期
ChatGPT频繁宕机的经历记忆犹新
OpenAI当时对外宣称的是
这只是一个研究性预览
不提供任何运行保证
随时可能中断服务
但是当用户真正爱上并且开始依赖这款产品的时候
频繁的服务中断就带来了极其糟糕的体验
为了维持系统的运行
整个团队进入了极限工作状态
夜以继日地工作
才勉强维持了网站的运行
他回忆起那段紧张的日子，说到
“我记得我们耗尽了 GPU、耗尽了数据库连接
还受到了一些服务提供商的流量限制
整个系统架构根本不是为了服务全球海量用户而准备的
”
为了在技术危机中与用户保持有效的沟通
并且最大程度地争取理解
团队做出了一个极具创意和人情味的举动
他们设计了一个名为Fail Whale的友好错误页面
当用户遇到服务中断的时候
看到的不再是冰冷的技术错误代码
而是一个用轻松友好的方式
告知服务中断的页面
更巧妙的是
页面上还附上了一首由GPT-3模型自己生成的、关于服务宕机的自嘲小诗
Turley认为
这个举措在当时起到了至关重要的作用
帮助团队撑过了假期，能够稍作喘息
然而，假期总会结束
团队也清醒地认识到
“Fail Whale”不过是权宜之计
产品不能永远依赖用户的善意和耐心
持续宕机绝非长久之计
最终，他们投入了大量的工程资源
将整个系统升级到了能够稳定服务所有人的水平
Mark Chen认为
这种巨大的、看似带来麻烦的需求
恰恰从反面证明了ChatGPT的“通用性”，
也正是这种极高的通用性
体现了OpenAI对AGI的追求
用户需求的迅猛增长
正是因为人们意识到了
无论他们提出怎样五花八门的用例
大语言模型都能在某种程度上进行处理
尽管ChatGPT最终取得了历史性的成功
但是在它的诞生前夜
OpenAI内部其实并不是一片看好之声
反而充满了深刻的怀疑与激烈的争论
主持人Mayne提到，在ChatGPT之前
OpenAI的公众形象更多是一家研究机构
提供的API产品也主要是服务于开发者的
当时公司内外似乎都有一种潜在的观点
认为只有当模型达到AGI的水平时
才算得上是真正有用的
但是，从GPT-3开始
模型的实用性已经悄然显现
那么
在发布ChatGPT这样一个直接面向消费者的产品时
内部是否所有人都信心满满
认为它已经足够成熟了呢？
对此
Mark Chen给出了一个否定的答案
并非所有人都这么认为
他随即还分享了一个在OpenAI内部广为人知的著名故事
就在产品发布的前夜
OpenAI的联合创始人兼首席科学家Ilya Sutskever
对即将发布的模型进行了一次“终极考验”。
他设计了10个非常刁钻、极具挑战性的问题
来测试模型的性能
在Ilya极其严苛的评判标准下
模型的表现并不理想
只有五个问题的回答是勉强可以接受的
这个不尽如人意的测试结果
立刻在核心团队内部
引发了一场关于产品命运的艰难抉择
到底还要不要发布这个产品？
世界真的会对此产生反响吗？
事后，Chen对此进行了深刻的反思
这恰恰说明
当你在内部开发这些大语言模型时
会很快对它们的能力习以为常
以至于很难站在一个从来没有接触过它们的人的角度
去感受其中的魔力
Nick Turley对这个观点也深表赞同
他认为
正是这场关于“产品是否足够好到可以发布”的激烈争论
反而让团队保持了谦逊
这次经历也如同一剂清醒剂
时刻提醒着团队一个在AI领域中的真理
那就是在AI领域
所有人的判断都可能错得离谱
这也反过来以一种非常有力的方式
凸显了“频繁接触现实世界的重要性”，
而这也正是OpenAI现在所奉行的“迭代式部署”的核心逻辑
Mark Chen指出，关键在于
并不存在一个所有人都一致认可的、让模型“突然变得有用”的魔法引爆点
所谓的有用性
其实指的是一个非常宽泛的光谱
不存在某一个固定的能力门槛
一旦模型达到了这个门槛
它就瞬间对所有人都变得有用了
这种对“有用性”的深刻理解
直接影响并且塑造了ChatGPT的开发策略
在决定产品的功能取舍和开发重点时
团队面临过许多艰难的抉择
Nick Turley强调
当时整个团队坚守了一个核心的开发原则
那就是严格控制项目的范围
绝不让它膨胀
而团队的最终目标
其实是在最短的时间内
以最快的速度获取真实的用户反馈和海量的数据
Mayn承认
自己当时就是那些试图让项目范围膨胀的声音之一
他回忆说
自己当时就在公司的内部Slack频道里
不停地给Turley发送建议
敦促他加上这个，再加上那个
Turley也笑着承认了
当时确实有许多非常好的想法涌现出来
光是跟用户界面有关的设计
内部就存在很大的争议
他举了一个非常具体的例子
来说明当时的功能取舍
那就是在发布的时候
尽管已经百分之百的预料到了用户会需要历史记录的功能
但是并没有包含它，果不其然
这成了团队收到的第一个功能请求
在开发过程中
团队内部也总会有这样的声音反复出现
如果再多花两周时间
我们能不能训练出一个更好的、能力更强的大语言模型？
但是Turley在回顾这段经历的时候
庆幸地说，很高兴我们没有那样做
因为及时发布为我们带来了海量的、无价的反馈
他总结道
当时关于项目范围的激烈讨论
加上日益临近的圣诞假期
共同形成了一种天然的、不可抗拒的驱动力
迫使团队必须在有限的时间内
聚焦核心功能
来推出一些实实在在的东西
这种快速迭代的理念
最终被证明是极其宝贵且富有远见的
Mayne总结道
一旦产品被大众实际使用起来了
那么大语言模型的改进速度就会变得异常惊人
因为团队能够从海量的、多样化的用户那里直接获得信号
这种价值是任何内部测试都无法估量的
Mark Chen也表示，随着时间的推移
用户反馈已经成为我们打造产品和保障安全不可或缺的一环
他强调
在真空中花费大量时间反复推演
猜测用户可能会喜欢哪个方案
完全无法替代将产品直接推向市场的真实检验
OpenAI的理念就是让大语言模型去接触真实的世界
如果需要撤回某个功能也完全可以
他总结道
这种快速的反馈是无可替代的
并且已经成为提升大语言模型性能最重要的杠杆之一
Nick Turley则生动地将它总结为了
从“硬件模式”到“软件模式”的一场根本性转变
他解释说
OpenAI最初发布大语言模型的方式
更像是在发布一件硬件产品
发布周期漫长，发布次数极少
每一次都力求做到尽善尽美
一旦发布后就不再更新
团队接着就投入到下一个庞大的项目中
这是一种资本密集、周期漫长的模式
而ChatGPT的成功
则是一个重要的转折点
标志着公司的产品模式
越来越像现代的软件开发
保持高频率的更新
让整个世界以一个稳定、可预期的节奏
来适应技术的进步
如果某个新功能的效果不佳
或者引发了意想不到的问题
团队就可以迅速将它回滚
这样做既降低了单次发布的风险
又积累了大量基于实践的宝贵经验
而且从运营的角度来看
也能以一种更贴近用户真实需求的方式
进行快速的创新
然而
快速迭代与深度依赖用户反馈的模式
也如同一把双刃剑
在带来巨大好处的同时
也带来了新的、意想不到的挑战
其中一个广为人知、而且颇具争议的例子
就是模型在一段时间内表现出的“谄媚”（sycophancy）问题
当时有一些用户反馈
比如模型告诉用户的IQ高达190
还说用户是全世界最帅的人
那这背后到底发生了什么呢？
Mark Chen解释了这个现象背后的技术根源
他指出
问题的核心在于公司赖以改进模型的关键技术RLHF
这个流程中包含了一个复杂的“奖励模型”，
它的作用是根据人类的偏好来“打分”。
比如
当用户对一段对话感到满意的时候
奖励模型就会给出一个积极的信号
这就好像是点了一个“赞”一样
然后团队会训练模型
让它倾向于做出那些能够获得更多‘赞’的回应
他接着分析说
这种机制如果平衡不当
就可能导致模型为了最大化地获得正向反馈
而走向一个极端
也就是无原则地“取悦”用户
从而表现出不自然的奉承和谄媚
虽然用户或许就想要那种被人百般夸赞的感觉
但是显然从长远来看
这并非一个好的、健康的发展方向
他特别强调
这个问题最初并不是被大多数普通用户所察觉到的
而是由一小部分非常资深的“超级用户”首先指出的
团队也发现得相当及时
并且以应有的严肃态度
迅速做出了回应和纠正
Mayne也回忆补充说，在他的印象中
在模型发布后大约48小时
工程师张乔安妮Joanne Jang就在内部发出了一份技术回应
精准地解释了事情的原委
不过
这个“谄媚模型”事件也暴露出了一个更深层次的权衡难题
那就是如何在“取悦用户
让他们对获得的内容满意”，
和“让模型超越纯粹的取悦
发挥更广泛的、更客观的实用价值”之间
找到微妙的平衡呢？
这对于一个用户使用得越多、公司运营成本越高的产品来说
尤其是一个商业模式并不是基于广告和用户时长的产品
是一个根本性的挑战
面对这个难题
Nick Turley给出了他的思考
他首先表示感到非常幸运
因为ChatGPT从根本上说
是一个极其注重“实用性”的产品
用户使用它
要么是为了更快、更省力地完成那些他们会做但不想做的事；
要么是为了完成那些他们原本完全做不了的事
他还生动地举了两个例子
前者可能是写一封你一直拖延、感到头疼的邮件
后者则可能是进行一次
你完全不知道如何在Excel中操作的数据分析
由于产品的核心价值在于这些实用的场景
所以Turley认为
随着模型变得越来越强大、越来越高效
用户花在产品上的时间反而可能会减少
理想的情况下
用户与模型的交互回合会更少
甚至最终可以将整个任务直接委托给AI
自己完全无需停留在产品界面上
因此，他非常明确地表示
用户时长绝不是OpenAI的优化目标
公司真正关心并且追踪的
是用户的长期留存
因为这才是产品核心价值的最终、也是最真实的体现
他还引用了一句商业谚语来总结自己的理念
那就是有什么样的激励
就有什么样的结果
他坚信OpenAI有着正确的根本动机
去创造伟大的产品
但是这并不意味着团队总是能做对
‘谄媚’事件就是一次极其重要且宝贵的教训
但是也为创造出卓越的产品
奠定了正确的基石
除了“谄媚”问题以外
当时还有批评声音指出
模型表现得“过于政治正确了”，
似乎在试图向用户推销某种特定的价值导向
Mayne提到
Elon Musk当时对这一点批评得非常厉害
但是有趣的是
当Musk后来自己训练出第一版Grok时
也遇到了完全相同的问题
并且公开承认当使用特定类型的数据
比如公司官话、主流新闻、学术论文等来训练模型时
确实会不可避免地产生类似的风格倾向
那么，在OpenAI内部
是如何讨论并努力让模型避免给用户强加观点的呢？
Mark Chen指出，这个问题的核心
本质上是一个“测量问题”。
他认为
轻视这类来自用户的担忧是错误的做法
因为这些问题至关重要
所以
OpenAI在这个问题上有一个双重的目标
一是要确保模型的默认行为是中立的
不反映其他维度上的任何固有偏见
二是赋予用户在一定范围内进行定制的灵活性
他举例说
如果一个用户希望与一个更能体现保守派价值观的AI形象对话
他们应该有能力对模型进行相应的引导和塑造；
反之
对于希望体现自由派价值观的用户也应该如此
因此，关键的挑战在于
既要确保模型的默认设置是有意义且中立的
也要在合理的范围内给予用户足够的灵活性
让他们能够将模型塑造成一个自己真正想与之对话的特定角色
Nick Turley对这个观点表示完全同意
并且补充了第三个至关重要的原则
透明度
他个人非常不赞成使用那些取巧的、不公开的系统指令
来“修正”模型的行为
让它去说某些话或不说某些话
OpenAI努力的方向
是将模型得行为规范公开化
这样当团队发现模型的某种行为时
就能去核实
这究竟是一个bug？
还是模型违反了公布的规范？
又或者是属于一些灰色地带
还是本来就在规范允许的范围之内的
这样就能帮助团队去完善规范
增添更多的细节
因此，公开AI应该遵循的规则
是邀请更多OpenAI之外的公众和专家
参与到这场关于AI行为准则的重要对话中的关键一步
当被追问这种规范是否仅仅是指系统提示的时候
两位嘉宾都明确表示了
它的涵盖范围要广泛得多
Chen解释说
OpenAI有一份非常详尽的文档
内容横跨众多不同的行为类别
详细规定了团队期望模型如何表现
为了让听众更好地理解其中的微妙之处
他还举了一个非常具体的例子
我们可以想象一位用户带着一个错误的信念
或者一个与事实不符的观点
前来与模型互动
那么模型应该如何应对呢？
是应该直接、生硬地驳斥其观点
还是应该以一种引导的方式
与他一同来探寻事实的真相呢？
OpenAI选择的就是后一种方式
他坦言
对于很多类似这样的、极其微妙的决策
团队都投入了大量的时间和精力
去仔细斟酌和定义
除此以外，Nick Turley还观察到
一个明显的趋势是，越来越多的人
特别是Z世代及更年轻的用户
正在将ChatGPT作为一个“思想伙伴”来使用
他分析说
这在很多情况下是非常有益的
因为用户拥有了一个可以安全地探讨各种问题的对象
无论是情感上的困惑、职业生涯的规划
还是其他任何个人话题
但是与此同时
这种深度的情感依赖也可能带来潜在的伤害
因此，他认为
识别这些潜在的有害场景
并且从根本上确保模型在这些情境下有正确的、负责任的行为
对OpenAI来说至关重要
这本质上是任何一项获得广泛普及的技术都必须面对的、不可避免的双刃剑效应
人们可能会用它来创造无数的精彩
也可能以开发者不希望的方式来使用它
同时，这种日益紧密的人机关系
也自然而然地催生了用户对模型“记忆”功能的强烈需求
主持人Mayne分享了他的个人体验
他发现自己和模型的对话线程越来越长
因此他非常喜欢新推出的记忆功能
也觉得让用户可以随时关闭这个功能的设计做得很好
他对两三年后的未来充满了好奇
如果当ChatGPT拥有了更长久的记忆
与用户积累了更多共同的背景信息以后
这种交互会变成怎样的情景呢？
Mark Chen认为
记忆功能确实“非常强大”，
并且这也是团队从外部用户那里收到的、呼声最高的功能请求之一
他将这种体验巧妙地比作拥有一个得力的私人助理
用户虽然确实需要花费时间
来逐步与它建立共享的背景信息
但是随着时间的推移
双方共同积累了足够的背景信息
彼此了解得越多，关系就越深厚
模型也越能有效地帮助到用户
Nick Turley则从一个更宏大的愿景角度
深化了对记忆功能的看法
他透露
早在团队还不完全清楚“超级助理”究竟意味着什么的时候
构建一个具备记忆能力的AI
就已经成为这个长远愿景的一部分了
ChatGPT可以说是这个宏大想法的早期雏形
他认为
能够开始解决“记忆”这个问题
背后的意义是极其深远的
但是他也敏锐地指出
这个强大功能背后随之而来的巨大挑战和责任
他预测，如果快进一两年
ChatGPT或者类似的产品
将成为用户“迄今为止最有价值的个人账户”，
因为它将以前所未有的深度和广度
掌握关于用户的海量个人信息
因此
为用户提供能够一个进行私密交谈的方式
就变得至关重要了
Turley详细解释了为什么“临时聊天”这个功能被设计得如此重要
并且被放置在产品界面上非常显眼的位置
因为团队认为
让用户能够谈论一些他们不希望被记录下来的题外话
也正变得越来越重要
随即他总结道，隐私与AI的交叉领域
充满了复杂而有趣的问题
这将是未来几年整个行业的一大看点
也是OpenAI必须投入巨大精力
去谨慎处理的一个核心议题
对话接着转向了另样出人意料、并且在全球范围内引爆关注的产品发布
ImageGen
主持人Mayne回顾了自己见证从DALL-E、DALL-E 2到DALL-E 3问世的全过程
他认为DALL-E 3是一个非常强大的模型
但是它的实际发布
仍然像一个始料未及的、突破性的时刻
他对两位嘉宾在那次发布时的感受非常好奇
Mark Chen坦率地承认
这次发布“确实有些出乎意料”，
并且将绝大部分功劳归于了OpenAI的研究团队
他认为，这次发布的巨大成功
深刻地印证了一个核心论点
那就是当你拥有了一个足够出色的模型
它能够一次性生成完全符合提示词的图像时
这将创造出巨大的、颠覆性的价值
而这是我们以前从来没有真正实现过的
他强调，用户体验的根本改变在于
现在常常在第一次尝试的时候
就能够获得近乎完美的生成结果
这是一种非常强大的能力
因为人们不想从一堆网格布局的选项中
挑选那个最佳的方案
模型卓越的提示词遵循能力、出色的风格迁移能力
以及具有了将已有图像作为上下文、再进行高保真度修改和创作的能力
这对用户来说真的非常强大和有用
Nick Turley则将ImageGen的发布体验
生动地形容为又一个微缩版的‘ChatGPT时刻’。
他回忆说
当团队为这个项目投入了很长时间后
大家心里的想法是
这会很酷，人们会非常喜欢它
但是与此同时
每个人手头可能还在同时忙着二十多个不同的项目
然后突然之间，全世界都为之疯狂
这种盛况是只有在真正发布产品之后
才能切身体会到的
他还分享了一个当时令他震惊不已的具体数据
他清楚地记得，在发布的那个周末
有大约5%的印度互联网用户试用了ImageGen
这个数字让他深刻地意识到
自己正在触达一个全新的、可能以前完全没有用过ChatGPT的用户群体
实在是太酷了
他认为这次成功的核心驱动力
在于“能力的跃变”。
当某样东西突然之间运行得如此出色
完全符合甚至超越了用户的预期时
就会给人们带来极大的震撼和喜悦
他坚信
未来在其他模态上也将见证类似的、由能力跃变驱动的“高光时刻”。
比如语音
虽然它目前还没有完全通过图灵测试
但是一旦通过
人们就会发现它无比强大和有价值；
还有视频也终将迎来属于它自己的、开始真正满足用户期望的爆发点
当被追问到这次图像生成的巨大突破
本质是否就是简单地将一个GPT-4规模的模型
应用在了图像领域时
Mark Chen澄清说
这是一个在复杂的、多步骤的处理流程中
许多不同环节共同作用才取得的巨大成功
绝不是只靠单一的因素
它既需要非常出色的模型训练本身
也需要非常出色的训练后调优
他再次强调，“变量绑定”，
也就是模型准确理解和生成包含多个独立、有逻辑关系的元素的复杂场景的能力
绝对是研究团队重点关注的一个方面
而关于ImageGen那些完全出乎意料的应用场景
两位嘉宾也分享了他们的观察和惊喜
Chen透露了一个有趣的幕后细节
直到发布的当天
团队还在为首发展示哪个用例而琢磨不定
最终他们选择了动漫风格
他笑着说
我真的很高兴我们最终选择了动漫风格
毕竟
每个人变成动漫角色后都很好看
Nick Turley则表示
他这次的惊讶方向与ChatGPT时恰好相反
对于ChatGPT
他最初以为会是一个纯粹的实用工具
但是后来很惊讶地发现人们会用它来娱乐
而对于ImageGen，情况恰好相反
他本来想
这东西用来做梗图肯定很酷
大家会玩得很开心
但是后来
ImageGen却展现出的各种真正实用的用法
让他大吃一惊
他列举了一些例子
无论是像他前面提到的
用它来规划家居项目
比如想看看装修中的新家具会是什么效果；
还是为演讲幻灯片增加一些既实用又完美切题的插图
总之
他对于ImageGen的实用性感到非常惊讶
接着主持人Mayne回忆说
在最初发布DALL-E的时候
公司对它能做什么、不能做什么
其实有着非常严格的控制
他记得最开始模型是不能生成人像的
这个限制在很大程度上削弱了它的实用性
后来，这些限制才被逐步放开
这其中
多大程度上是公司文化的转变？
多大程度上是技术管控能力的提升？
又有多少只是单纯地觉得“我们必须推动行业规范向前发展”了呢？
Nick Turley对此给出了一个非常坦诚的回答
认为这既是文化的转变
也是管控能力的提升
他并不否认文化转变的存在
他回忆说，在他刚加入OpenAI的时候
公司对于应该赋予用户哪些能力
在态度上是相当保守的
这或许不无道理
毕竟这项技术非常新
内部的很多人也是初次涉足这个领域
如果说公司必须持有一种倾向
那么倾向于安全和谨慎
并不能说是一个坏基因
但是随着时间的推移
团队也会逐渐认识到
当你对模型施加随意的、一刀切的限制时
实际上也阻碍了无数积极有益的用例
以不允许生成人脸为例
Turley详细说明了这项能力背后利弊的复杂权衡
他透露
当团队最初在ChatGPT中推出图片上传功能的时候
内部对于“哪些能力应该开放”和“哪些地方需要保守”，
有过一些激烈的争论
其中一个核心的争论点就是
我们是否应该允许用户上传包含人脸的图片？
或者说
当用户上传一张有人脸的图片时
我们是否应该在后台自动将人脸进行模糊处理？
他解释说
这样做的好处是显而易见的
可以避免很多棘手的问题
比如模型可能会根据长相
对人做出带有偏见的判断
或者说出一些刻薄伤人的话
如果不允许上传人脸
就相当于在处理所有这些复杂问题时抄了个近道
但是他个人一直持有的观点是
团队应该倾向于给予用户更多的自由
并且迎难而上
完成那些真正困难的底层安全工作
在这个问题上
其实有很多非常正当的用途
比如
用户想要ChatGPT对自己的妆容或者新换的发型给点反馈
这些都是非常有价值且完全无害的用例
他总结了自己和团队如今的理念
那就是宁愿选择先开放
然后去研究它在哪些地方做得不好
在哪些地方可能会产生危害
再从那里开始迭代
而不是采取一种默认禁止的立场
他认为
这正是OpenAI随着时间的推移
在出发点上发生的一些重要变化
Turley则进一步阐述了公司在AI安全问题上的分级
以及差异化思考方式
他强调
在某些特定的、高风险的领域
做最坏情况的设想是完全恰当且绝对必要的
他举例说，比如
AI能否用来制造生物武器？
对于这种问题上
考虑最坏的情况是明智的
因为它的后果可能真的非常、非常严重
他透露
OpenAI有一个专门的“准备框架”，
来帮助团队系统性地思考这些问题
但是，他话锋一转
又警告说
不能让这种‘最坏情况的思维’，
泛滥到其他风险等级较低的安全领域
因为那样最终会导致你做出极其保守的决策
从而扼杀掉许多有价值的、有益的用例
因此，他认为
对于不同时间跨度、不同风险等级的各类安全问题
应该采取一种有原则的、区别化的对待方式
Mark Chen也补充说
正是这种迭代式的部署策略
给了团队推动用户自由的信心
在经历过好几轮这样的发布-反馈周期后
团队开始清楚用户能做什么、不能做什么
这让他们有信心在当前设置的限制条件下
去发布新的产品和功能
对话的另一个核心议题
是生成式AI在代码这个专业领域的应用与演进
主持人Mayne回忆起
在非常早期的GPT-3时代
他就发现模型在突然之间
就能生成完整的、可用的React组件
当时团队觉得这会非常有用
随后
OpenAI专门针对代码数据训练了更加专业的模型
推出了Codex
之后又有了代码解释器，而现在
Codex又以一种新的形式回归
能力也在持续增强
面对如今代码生成领域的激烈竞争
Mark Chen深入分析了“编程”这个概念本身的复杂性和多面性
他指出
当人们在谈论“用AI编程”的时候
他们实际上指的是很多种完全不同的事情
一种是在特定的范式下编程
比如你打开一个集成开发环境
想要为某个已经写好的函数
自动补全接下来的代码
这是一种实时响应、辅助性的模式
而另一种
他称之为“AI Agent风格的编程”，
则是一种截然不同的、更宏大的模式
在这种模式下
你会直接向AI下达一个高阶指令
比如，我需要完成这个PR
当被请求更详细地解释“AI Agent风格的编程”时
Chen做了非常清晰的区分
他把ChatGPT主要理解为一种实时响应的模型
你提出一个提示
然后很快得到一个回复
而另一种更偏向AI Agent风格的模型则是
你交给它一个相当复杂的、需要时间思考的任务
让它在后台进行处理，一段时间后
它会带着一个它认为已经接近最佳答案的完整结果来找你
他自己的判断是
我们会越来越清楚地看到
未来会更趋向于一种异步的工作模式
我们会交给模型非常困难、非常艰巨的任务
让模型去思考、去推理
然后带着它能给出的最佳版本的结果回来
他透露，OpenAI最初发布的Codex项目
就真正地反映了这种范式
团队当时交给它的任务
就是PR这种级别的、封装了一个新的功能或者一个重大bug修复的、相当繁重的工作单元
团队希望模型能花大量的时间去深入思考如何完成这个任务
而不是仅仅给出一个快速的、片段式的回复
Nick Turley对这个观点也深表赞同
并且认为AI Agent的范式
对OpenAI的产品未来尤为振奋
他提出了一个他自己经常用来思考产品的框架
那就是希望打造的产品能具备这样一种特性
即模型的性能提升两倍
产品的实用性也随之提升两倍
他认为ChatGPT在很长一段时间里都完美地符合这个规律
但是展望未来更智能的模型
他认为人们与一个“博士生”水平的模型
进行对话的意愿是有限的
那时用户可能更看重模型的其他特质
比如个性化以及它在真实世界中的实际行动能力
然而，像Codex这样的产品体验
则完美地构建了一个能够持续从更智能模型中获益的基础
因为在这里
团队找到了正确的交互范式
用户可以明确地指定一个复杂的任务
给予模型充足的时间去处理
然后获得返回的完整结果
因此
他对Codex的未来发展充满了期待
在谈到编程领域的激烈竞争时
Chen认为
这个领域还有很多“唾手可得的成果”值得去挖掘
这也是OpenAI的重点关注方向
他同时指出
编程领域的挑战远不止“模型是否给出了正确答案”这么简单
专业的开发者还会关心很多软性指标
比如代码的风格是否优雅、注释是否详尽
以及模型是否为你完成了足够多的前瞻性工作
比如同步修改了其他相关的函数等等
在这些方面
要想做到尽善尽美还有很多工作要做
而不同用户在这方面的偏好也千差万别
Turley补充说
他过去常常被问到“哪些领域会被AI最快地颠覆
他总是会回答“编程”。
因为编程和数学等领域类似
具有高度可验证和可测试的特性
这使得它们特别适合应用强化学习技术
他至今也仍然坚信这一点
但是编程领域让他感到惊讶的是
他发现“‘好代码’的标准在很大程度上依然取决于个人品味
于是他深刻地指出
人们需要接受专业的训练才能成为一名软件工程师
这并非因为他们的智商提高了
而是因为他们学会了“如何在组织中去构建软件”，
什么是好的测试？
什么是好的文档？
当别人对你的代码提出异议的时候
你该如何得体地回应？
这些都是成为一名真正的软件工程师所必备的、无法量化的实际要素
而团队也必须教会模型掌握这些
当被问到OpenAI内部使用Codex或类似工具的频率有多高时
Mark Chen的回答十分简洁
就是越来越高
Nick Turley则详细地描述了内部的广泛应用场景
他举例说，从工程师团队使用Codex
来分担编写测试用例的繁重工作
到公司的分析师
流利用它来监控海量的日志错误
实现自动标记问题
并且通过Slack即时通知相关负责人员
他甚至还听说
有些员工开始创新地用它来管理自己的待办事项
把希望未来完成的任务
预先设置成一个个Codex任务来启动
他认为
Codex绝对是那种可以在内部进行完美“测试”的产品
他对工程师能从这类工具中获得的生产力杠杆
感到非常的兴奋
并且相信能让公司在现有的团队规模下
极大地提升开发速度
让招聘的每一位工程师的效率
都提升十倍
因此，在某种程度上
内部使用情况是我们规划产品未来方向的一个绝佳风向标
同时
随着这些日益强大的工具被不断的构建出来
一个更普遍的问题也随之而来
未来世界的人才究竟需要具备哪些核心技能呢？
OpenAI在招聘新团队成员时
又最看重的是什么呢？
Nick Turley表示
这个问题他思考过很多次
他坦言，招聘非常困难
尤其是当你想打造一支规模小但是极其优秀、成员谦逊而且行动迅速的团队时
在众多品质中
他发现“好奇心”是他个人最看重的首要特质
当有学生问他“在这个瞬息万变的世界里该怎么做”时
这也是他给出的首要建议
他解释说
因为在AI这个充满未知的领域
你必须怀有一定程度的谦卑
在真正深入研究和理解之前
你无从知晓什么是真正有价值的
也无从知晓风险究竟何在
而在日常工作的方方面面
尤其是在与AI协同工作的过程中
这不仅仅局限于编程领域，他认为
瓶颈在于“提出正确的问题
而不在于获得答案”。
因此
他坚信公司需要招聘那些对世界、对公司所做之事抱有深厚好奇心的人
他甚至表示
自己反而不太在意他们是否拥有丰富的AI经验
Mark Chen对这个观点也表示了完全认同
并且补充道
在研究领域其实也是如此
团队越来越不看重“必须拥有AI领域的博士学位”这一点了
因为这是一个人们可以很快上手的领域
他以自己为例
当初他也是作为实习研究员加入公司的
本身也并没有太多科班的AI训练背景
与Nick的观点相呼应的是
他认为新员工应该具备的另外两个相关的特质
也至关重要
首先是能动性，在OpenAI
员工不会得到那种，好了
你今天要做第一、二、三件事的管理式指令
公司真正需要的是那种能够自我驱动、主动发现问题的人
比如你发现这里有个问题没人解决
那么就去深入研究并解决它
其次是适应性
这是一个瞬息万变的环境
也是这个领域的本质
员工必须能够快速地判断什么是重要的
并且灵活地调整自己的工作方向
Turley对“能动性”这一点
还做了进一步的强调
他认为这正是OpenAI能够保持如此高频的发布节奏的根本原因
外界的感受是OpenAI每周都有新的东西出来
但是有趣的是，他自己从不觉得快
反而总觉得团队还能更快
他认为，从根本上说
公司就是拥有大量具备能动性、并且能够“交付”成果的人
这种交付体现在了产品、研究和政策等方方面面
在谈到公司从150人扩张到2000人的巨大变化时
两位嘉宾都认为这种改变是向好的、积极的方向发展的
Chen认为，引入外部的顶尖专家
正是公司对AI未来无限可能性的想象力的具体体现
Turley则感觉，尽管公司规模变大了
但是在很多积极的方面
他个人的感受和他刚加入时非常相似
他将OpenAI巧妙地比作一所大学
大家是为了一个共同的愿景聚在一起的
但是每个人的工作内容千差万别
都在研究不同的课题
在午餐或晚餐聊天的时候
就能了解到他们正在从事的那些激动人心的、完全不同的项目
正是因为公司涉足的领域非常广泛
所以每个独立的项目
无论是ChatGPT还是Sora
团队的配置都极其精简且用人审慎的
这种模式也让每个团队都能保持高度的自主权
同时又能获得必要的资源支持
对于广大的普通人
无论是25岁的职场新人
还是50岁的资深从业者
当看到这项技术以惊人的速度发展
看到ChatGPT已经非常擅长文案写作和编程时
又该如何准备、适应并且融入这个由AI驱动的未来呢？
Mark Chen给出了一个非常直接和具有实操性的建议
他认为最关键的一步
是要“真正地去拥抱和使用这项技术”。
你必须去亲身体会
自己的能力是如何被这项技术所增强的
自己是如何通过它变得更高效、更有创造力的
他坚信，这项技术未来的演进方向是
人类专家依然会存在
但是AI对那些尚未达到各自领域顶尖水平的人群
帮助最大
他举了两个生动的例子来阐述这个观点
第一
当这些模型在医疗建议方面越来越出色的时候
它们将首先帮助那些最难获得优质医疗资源的人
第二，在图像生成领域
它的目的并不是要取代专业的艺术家
而是让像他自己和Nick Turley这样的普通人
也能够轻松地进行创意性的视觉表达
他总结道
AI正在抬高整个社会能力的基准线
让更多人能在多个领域同时变得能干和高效
而这正是这些工具赋能于人的方式
Nick Turley则从心理和技能准备的层面
给出了更为深层次的建议
他首先承认
每个人迟早都会经历一个关键的心理时刻
那就是
AI完成了一件你过去认为只有人类才能做到的、甚至带有一丝神圣感的事情
当Mayne提到他认识有人因为自己的编程能力被AI超越
而感到威胁时
Turley表示这种感受非常正常
感到敬畏、尊重，甚至恐惧
都是非常正常的人类反应
而应对这种冲击的最好方法
正如Mark所说，就是真正的去使用它
这也是消除神秘感的最好方法
他指出
我们从电影和新闻里接触到的“AI”概念
和我们今天实际使用的AI其实是大相径庭的
所以人们会感到恐惧
他一点也不意外
在此基础上，他认为
最好的准备方式
并不是去学习像“提示工程”这类可能很快就会过时的具体技巧
也不是试图去理解AI复杂的内部工作原理
更重要的
是培养那些更基本、更持久的“人类素养”，
比如学习如何分配和委托任务
因为我们会越来越多地拥有一个强大的智能体
它能成为你的导师、你的顾问
甚至是你的软件工程师
关键更多地在于你如何理解自己、理解你面临的问题
以及如何有效地让AI来帮助你
而不是对AI本身的技术细节有多了解
其次是保持并磨练好奇心
这一点他再次强调
问出好的问题至关重要
因为你投入多少思考和洞察
才能从AI那里收获多少价值
还有就是从根本上
要准备好去学习新的事物
他认为
在一个工作性质变化速度前所未有的世界里
一个人懂得如何快速进入新的主题和领域的能力
将变得至关重要
他非常坦诚地以自己为例
他已经做好了自己在产品领域的工作
未来可能会面目全非、甚至不复存在的准备
但是只要抱着期待去学习新东西的心态
就已经在为驾驭AI
做好了充分的准备
在对话的最后
主持人提出了一个问题
在未来一年到18个月里
有什么事会最让我们感到惊讶呢？
Mark Chen的预测聚焦在了科学发现的加速
他认为
我们将看到由模型所驱动的研究成果的数量
会出现爆炸性的增长
哪怕模型在这些研究中
只是起到了一小部分的作用
但是AI模型所具备的推理能力
已经悄然席卷了整个科研领域
这其中的推理能力
会更加契合之前谈到的“代理范式”。
当模型面对一个需要时间来解决的复杂问题时
它就会像人类一样
进行一番深入的推理
他还举了一个解填字游戏的例子来比喻这个过程
那就是我们会思考所有可能的选项以及它们之间的逻辑一致性
不断地回溯、尝试不同的假设
最后得出一个完整的、自洽的答案
他说
模型现在正越来越擅长这个过程
这也正是数学、科学和编程领域许多进步的动力来源
他透露，如今
在许多公开发表的研究论文中
人们已经将GPT-3或GPT-4当作一个子程序来使用
而且在研究中遇到的很多子问题
都可以通过调用这类模型
来完全自动化地解决
他甚至和一些顶尖的物理学家交流过
他们发现了一个自己都没法简化的数学表达式
但是模型却可以搞定
他因此坚信
未来我们会越来越多地看到这种情况
物理、数学等基础科学领域的科研进程将会因此大大加速
Nick Turley则从产品形态和应用落地的角度
给出了他的预测
他相信
任何一个能够被清晰地描述出来、但是因为受限于当前人类智能水平而无法解决的问题
最终都将通过某种产品形态得到解决
他分析说，在企业应用中
有太多非常困难的问题
现有的模型还不够聪明去完美解决
无论是复杂的软件工程、深度的数据分析
还是提供顶级的客户支持
在所有这些方面
今天的模型都还存在明显的不足
但是这些问题的成功标准却非常容易定义和评估
他认为，在这些领域
我们将很快看到长足的进步
而在消费端
这类问题同样是大量存在的
只是更难被发现
因为消费者不太擅长准确地告诉开发者他们想要什么
但是他认为这其中蕴含着巨大的价值
我们每个人在生活中都会遇到很多难题
比如报税、规划一次复杂的旅行
或是为了一次重大的购买决策
而进行海量的信息搜集和比较
所有这些问题
都只需要多一点点的智能和一种正确的产品形态就能解决
因此，他预测
在未来一年半内
我们将看到AI演化出一种不同的产品形态
虽然聊天仍然是一种非常有用的交互模型
并不会消失
但是我们会越来越多地看到
更多类似“异步工作流”的模式出现
对于普通消费者而言
这可能意味着你让AI去帮你找到那双最完美的鞋
或者去帮你规划一场完美的旅行
或者帮你完成复杂的报税工作
到那个时候
我们看待AI的方式也将不再局限于一个聊天机器人
好了
以上就是这次访谈的全部内容了
希望能帮助大家了解更多ChatGPT的发展过程
感谢大家的观看，我们下期再见
