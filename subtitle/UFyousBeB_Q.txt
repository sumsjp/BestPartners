不知道大家对World Labs新发布的3D生成模型有什么看法
欢迎在评论区留言
感谢大家的观看，我们下期再见
大家好，这里是最佳拍档，我是大飞
12月3日
由“AI教母”李飞飞联合创立并担任CEO的AI初创公司World Labs
对外公布了他们的首个成果
3D世界生成模型
一个可以让用户从单张图片生成3D世界的AI系统
和市面上大多数将图片转化为3D的产品不同
World Labs的3D世界生成模型
通过预测3D场景
实现了更高的可控性和一致性
而且用户还可以与模型生成的3D场景进行互动
比如
用户可以模拟相机进行对焦或者滑动变焦
还可以在浏览器中进行实时交互
并且能够为场景添加交互效果和动画
今天我们就来介绍一下这个3D世界生成模型
根据World Labs的博客介绍
用户只需要提交一张图片
不论是由AI生成的图像
还是日常生活中拍摄的照片
3D世界生成模型都能够根据这张图片
生成一个3D的场景
而且风格和原始图片保持一致
同时
和市面上将图片转化为3D建模或环境的产品不同
World Labs模型生成的3D场景
更像是一个开放世界游戏里的画面
它允许用户通过操作键盘、鼠标和场景进行交互
比如按下键盘上的“WASD”键
可以向前向左向右向后移动
点击并且划动鼠标，还可以转换视角
生成3D场景之后
模型还会使用虚拟相机在浏览器中实时渲染
用户在使用的时候
可以通过拖动滑块来精准地控制虚拟相机
从而实现艺术摄影效果
比如
用户可以通过拖动滑块来模拟拍照时候的对焦
从而渲染出更清晰
或者更加模糊的画面
另外，在World Labs生成的3D场景中
用户还可以使用滑动变焦
来调整虚拟相机的视野范围
从而获得不一样的视觉效果
World Labs还在博客中介绍
与大多数模型预测像素的方式不同
他们是预测3D场景
这么做有三个明显的优势
首先是连续性（Persistent Reality）
也就是模型生成的3D场景将一直存在
转换视角和移动都不会对已经生成的场景产生影响
其次是实时控制（Real-Time Control）
用户可以在场景中自由、实时移动
不仅能凑近去看花的经络
也能抬头远望太空星云
第三是正确的几何结构（Correct Geometry）
模型生成的3D场景遵循了3D几何的基本物理规律
有立体感和纵深感
也正是因为这些优势
用户可以在生成的3D场景中构建交互式的效果
比如选择声呐（Sonar）效果后
再点击场景中的任一区域
这个区域会出现对应效果
用户还可以为场景制作动画效果
比如选择波纹动态效果
整个画面就会像波纹一样动起来
World Labs团队认为
3D世界生成模型将改变电影、游戏、模拟器和其他数字媒体的制作方式
他们展示了两个应用案例
第一个是像戴上VR眼镜一样
游览世界名画
比如World Labs的模型可以根据凡·高等世界知名画家的画作
生成一个画中世界
让用户以全新的方式感受艺术作品
第二个是让3D世界生成模型与现有的AI工具结合使用
加速内容创作的过程
比如
用户可以先使用文生图模型生成图像
再从生成的图像来创建3D世界
虽然不同的文生图模型有不同的风格
但是生成的3D场景依然可以适配这些风格
World Labs给出了一个示例
他们给四个不同的文生图模型输入了同一组提示词
具体内容为
一间充满活力的卡通风格青少年卧室
床上铺着五颜六色的毯子
杂乱的书桌上放着一台电脑
墙上贴着海报，运动装备散落
一把吉他靠在墙上
中间是一块舒适的图案地毯
窗外的光线为房间增添了温暖、年轻的氛围
随后
再根据文生图模型生成的不同风格的图像
创建出对应风格的3D场景
在模型发布之后，有网友激动地表示
太疯狂了
我们即将迎来一个像80年代、90年代那样的革命
这将让许多人实现他们的创意
有望降低开发成本
帮助工作室的新IP实现更大胆冒险
也有网友表示
这就是视频游戏、电影的未来
不过
目前这个模型还存在着一些不足
比如在生成的3D场景中
可探索的区域比较有限
在移动一小段距离后
它就会提示已经达到边界
另外在某些场景中会出现渲染错误
不同的物体会以不自然的方式融合
成为一团色块
World Labs表示，以上成果还偏早期
他们正在努力提高生成世界的大小和拟真度
也正在试验用户与它们交互的新方式
当下
2D的图片或视频生成模型比比皆是
比如国外的Midjourney
Stable Diffusion、国产的可灵、Vidu、清影等等
而视频生成模型始终有一个痛点挥之不去
那就是AI视频的稳定性、一致性得不到控制
于是3D模型生成的视频可控性和一致性
就成为新的着眼点
从2023年开始
许多厂商开始专攻3D生成模型或者升维
也就是2D转3D模型
但是就现状来说，直到现在
效果好一点
或者能满足基本需求的3D生成模型
实在是屈指可数
而李飞飞团队的World Labs公司
为我们打了个样
早在李飞飞在斯坦福大学实验室的时候
她就已经开始试图教会计算机“如何在3D 世界中行动”了
例如
通过使用大语言模型让机械臂执行诸如打开门、制作三明治等任务
后来，她在今年4月开始计划创业
并于9月正式创立World Labs
探索“空间智能”。
根据《福布斯》报道
成立还不到一个星期
World Labs就已经筹集了2.3亿美元的风投资金
估值超过10亿美元
投资方不仅包括Andreessen Horowitz（a16z）、NEA和Radical Ventures等在内的美国知名风投机构
还有杰弗里辛顿Jeffery Hinton、杰夫迪恩Jeff Dean、安德烈卡帕西Andrej Karpathy、Salesforce公司的创始人兼CEO马克·贝尼奥夫Marc Benioff等个人投资者
我们频道在第一时间也做了报道
大家有兴趣可以去回看一下
而关于公司的愿景
李飞飞在温哥华的一次TED会议的演讲中提到过
那就是要训练一个能够理解复杂的物理世界
及其内部物体相互关系的AI系统
在李飞飞看来
这是“解决人工智能难题的关键拼图”。
而至于什么是“空间智能”，她说到
视觉化为洞察
看见成为理解，理解导致行动
在李飞飞看来
人类智能可以分为许多种
其中之一是语言智能
它让我们能够通过语言进行交流和与他人联系
但是更为基础的或许是空间智能
它不仅让我们能够理解和与周围世界互动
还能帮我们将脑海中的画面带入现实世界
在三维空间和时间中对世界进行建模
并对物体、场所和交互进行推理
在之前斯坦福大学的一场闭门论坛上
李飞飞也曾经公开diss过Sora
她指出
尽管 OpenAI 的 Sora 模型能够生成视频
但是它的核心仍然是二维的
缺乏对三维空间的深入理解
在她看来，二维是表象
三维是本质
空间智能才是 AI 通向 AGI 的钥匙
当时
她以 Sora 模型生成的「日本女性走过霓虹闪烁东京街头视频」举例称
如果你希望算法换个角度
来展现这个女子走过街头的视频
比如把摄像机放在女子背后
那Sora是无法做到的
因为这个模型对于三维世界并没有真正的深刻理解
而人类可以在脑海中想象女子背后的情景
人类可以理解在复杂的环境下如何活动
我们知道如何抓取，如何控制
如何打造工具，如何建造城市
根本而言，空间智能是几何形状
是物体间的关系，是三维空间
正如英伟达的高级计算机科学家Jim Fan所说
生成式AI正在创建越来越高维度的人类体验快照
Stable Diffusion是2D快照
Sora是一个带有时间维度的2D+快照
现在
World Labs是一个完全身临其境的3D快照
也许对于如今的生成式AI来说
一张照片只是起点
一个真正立体、可交互的、富有生命力的虚拟世界
才是终点，而 World Labs 的出现
正在弥合这道鸿沟
