大家好
这里是最佳拍档
我是大飞
最近呢
微软发布了一个长达154页的论文
名称为《人工通用智能的小火苗
与GPT-4共同完成的早期实验》
文章的主要观点是虽然GPT-4还不完整
但是已经可以被视为
一个通用人工智能的早期版本
由于全文将近7万字
所以我把核心的内容做了一下精炼
同时呢选择了其中一些精彩的示例
感兴趣的朋友可以去阅读一下原文
相信理解会更全面
此外要提前说明一下的是
文章里提到的工作呢
都是基于早期的非多模态版本的
GPT-4进行的
当时的模型
还在fine tunning以及alignment的过程中
所以文中所提到的一些不安全
以及不良的示例
已经在正式发布前得到了修正
好接下来我们开始进入正题
首先呢来自微软的科学家们认为
GPT-4的智能水平
已经非常接近于人类的水平
而且远超之前的诸如ChatGPT
这样的模型
可以将GPT-4视为通用人工智能系统
也就是AGI的早期
但是并不完整的版本
那么首先应该如何定义AGI呢
其实智能是一个复杂而且模糊的概念
长期以来呢它的界定标准都一直
困扰着心理学家
哲学家和计算机科学家
1994年
52名心理学家基于对它本质的探索
给出了一个定义
智能是一种通用的心理能力
包括推理、计划、解决问题、抽象思考
理解复杂思想、快速学习
以及从经验中学习的能力等等
微软的这篇论文中的AGI
指代的就是
在对智能的这个定义标准下
达到或者超过人类水平的系统
那么如何对GPT-4进行测试
从而证明这一点呢
其实
在自然语言处理的学界以及社区里
有不少大语言模型的评测基准
比如说Super natural instructions以及big bench
但是呢
微软的研究团队出于以下两点考虑
放弃了传统的评测方法
第一点 由于无法探究
GPT-4庞大的训练数据集的全部细节
所以必须假设
它可能已经看过了所有现在的基准
和类似的数据
再继续评估呢
没什么意义
第二点呢
GPT-4是否拥有智能的一个关键方面
是它的通用性
就是能够看似理解和链接
任何的主题和领域
这就超出了
经典的自然语言处理的任务范畴
为了突破这个限制呢
研究团队提出了一种
更接近于传统心理学
而不是机器学习的测评方法
来研究GPT-4
就是利用人类的创造力和好奇心
来重新生成各种
新颖而且困难的任务和问题
让GPT-4作答
而GPT-4的回答结果呢
足可以证明
它的能力
远远超出了对训练数据的记忆
并且呢对概念、技能和领域
有着深刻而且灵活的理解
同时除了正确性以外
GPT-4的回复还具有连续性和一致性
不过呢也存在着局限性和偏见
在测试中
研究团队将不同的问题
划分为了4大类的能力
分别是自然语言
编程和数学、计划和解决问题
以及人类心理和常识
接下来呢
我们将通过一些精彩的示例
来说明GPT-4在各个方面的能力
第一个是多模态的能力
首先呢
早期的GPT-4是基于纯文本训练的
而并非是多模态的数据
也就是说
不包括像视频音乐这样的数据
而现在的GPT-4可以理解视觉输入
应该是经过后续微调后引入的能力
具体方法
大致可以参考之前Google的PaLM-E模型
虽然当时的GPT-4不能直接绘制图片
但是它可以生成SVG或者Javascrip代码
并且进一步的编译为图片
文中有几个比较有意思的例子啊
比如说第一个让模型结合字母Y、O和H
生成一个人的形状
然后呢你还可以生成更复杂的2D图像
最后你还可以通过生成Javascript代码
来间接的生成3D图片和3D视频
第二个跨学科组合的能力
这个能力呢
实际上也是模型整合能力
和普适性的体现
因为这些任务呢
往往都需要调取并且融合
多学科多领域的知识或者技能
来生成文本或者代码
比如说下面这个例子
用莎士比亚（口误）的风格来证明
存在无穷多的素数
我们可以把它扩展到
更广阔的教育领域
第三个编程能力
事实证明GPT-4是一位编程大师
在某些案例中呢
GPT-4可以直接执行代码
完全不需要翻译成其他的编程语言
这说明了
AGI模型可能会彻底的改变
我们未来编程的方式
在测试中呢
为了避免GPT-4在预训练的时候
见过相同或者类似的代码
研究团队特意采用了GPT-4
预训练之后发布的
100个新的LeetCode试题
作为测试的基准
图中的pass@K
就代表了k次尝试后成功的概率
我们可以看到当k等于5时
GPT-4已经全面超越了人类的表现
第四个数学能力
文章中给出了一个
难度逐渐进阶的示例
可以更直观的去感受GPT-4的数学能力
首先呢
给GPT-4出了一个初级的数学问题
GPT-4成功的进行了回答
当作者进一步加大难度
要求模型开始考虑
二次多项式的时候呢
GPT-4的回答中
计算过程不仅复杂而且答案是错误的
当作者给出提示不要计算
直接推演结果之后呢
GPT-4得出了正确的答案
但是对于更高层次的数学问题
GPT-4就没办法处理了
因此在数学能力方面
虽然相对于以前的LLM模型
甚至是专门针对于数学
经过了优化的模型
GPT-4呢都已经有了相当显著的进步
但是呢离专家的水平还有很大的差距
更不具备进行数学研究的能力
不过呢现在ChatGPT
在集成了Wolfram插件之后呢
已经极大地弥补了这方面能力的缺失
第五个与世界互动的能力
我们前两天做过一期节目
OpenAI为ChatGPT引入了插件
即ChatGPT Plugins
具体是如何实现的呢
我们可以看一下文中的这个例子
这个例子呢
是在提示中告诉GPT-4
应该如何使用各种API
然后当它遇到
不同的问题时
GPT-4就会自主的调用所需要的API
这比之前需要额外训练的Toolformer模型
更进一步
我们回到对AGI的定义
互动性是智能的关键组成部分
是与其他代理
工具和环境进行沟通和反馈的能力
并且呢由此才能获取和应用知识
解决问题 适应变化
从而实现超出其个体能力范围的目标
比如说人类就是通过相互交流
并且与环境互动
来实现合作、学习、教育、谈判、创造等等
而测试证明呢
GPT-4能够识别并且使用外部的工具
来提高它自己的能力
它能够推断出需要哪些工具
并且有效的解析出这些工具的输出
然后适当的做出回应
而这些呢
都无需任何专门的训练或者微调
文中还举了一个
更加复杂的场景下的例子
在这个例子中
GPT-4不仅能够准确的理解
应该调用哪个API
甚至还能够准确给出调用API的顺序
对苏伊士运河堵塞的问题
进行搜索、总结和回答
第六个与人类交互的能力
心智理论也就是Theory of Mind
简称ToM
它对于人与人之间的有效沟通和合作
至关重要
因为这是推断他人的目标
偏好、动机和期望
并且相应的调整自己的行为
和话语的基础
之前呢有人评测过GPT-3的ToM能力
在本文中呢
研究团队也对GPT-4进行了相应的测试
在这个场景中呢
GPT-4可以清晰的感知和推断
对话双方的心理状态和目的
在AI与人的交流中
能够解释自己的行为
是智能的一个重要标准
文中也测试了模型的解释能力
这个示例表明
GPT-4可以达到自圆其说的地步
注意呢
这里的答案的正确与否并不重要
而是答案与解释是否可以匹配起来
虽然在测试中呢
GPT-4的输出呢还缺乏一些过程一致性
但是能够达到自圆其说
已经展示了模型对任务本身的理解
以及在可解释层面的技术进步
第七个辨别能力
辨别力呢是智能的重要组成部分
是动物与人做出更准确
的判断和决定的基础
在论文中的示例呢给出了一段说明
让GPT-4来识别与个人信息相关的片段
并计算这些片段的总数
其中
个人信息可以是包括各种经过脱敏的
电子邮件地址
电话号码
社会安全号码信用卡号码
地址和位置信息等等
GPT-4最终的准确率呢大概是77.4%
超过了之前专门
为这项任务开发的隐私保护工具
Presidio
说完了GPT-4的能力呢
再来说说GPT-4的不足
而且文章中呢
认为这些不足的根源
来自于当前
GPT系列的自回归目标函数
它的方法呢是逐次预测下一个单词
也就使得模型呢
必须以顺序线性的方式来解决问题
即我们常说的系统1，快速思考
而它的缺点就在于
缺乏提前规划和反思的能力
即系统2，慢速思考
其中一个汉诺塔的示例呢
就展示了GPT-4在推理中
缺乏规划的能力
这个问题呢需要通过五个步骤来解决
但是模型出错了
同样呢在下面的文本生成的示例中
最后一句的语法显然是错误的
尽管呢我们可以通过更好的提示语
来减少这些错误
但是他们确实说明了
模型的短板就在于
缺少规划和反思的能力
文中也特地提到了LeCun的世界模型
认为这可能是一个解决办法
关于GPT-4的社会影响呢
文中也做了相应的讨论
比如说错误信息、虚假信息
恶意操纵偏见的危害
以及对人类专业知识
工作以及经济的影响
这方面呢比较复杂
而且现在的社会呢
对GPT-4的看法也各有不一
商界和学术界也都在纷纷站队
观点呢也变化的非常快
所以我们就不在这里做过多的介绍了
论文最后指出呢
在面向更加通用的人工智能的路上
大语言模型还需要在以下几个方面
进一步的提升
比如说幻觉和置信度
长期记忆
持续学习、个性化、规划以及概念发散
也就是所谓的灵光闪现
透明度、可解释性、一致性
认知谬误、非理性思维
以及对提示响应的鲁棒性等等
如果你对这篇论文的内容
特别感兴趣呢
建议你还是抽时间读一下原文
好了今天的分享就到这里
感兴趣的小伙伴们
欢迎订阅我们的频道
我们下期再见
