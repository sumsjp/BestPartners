大家好，这里是最佳拍档，我是大飞
自从AI诞生以来
不少人就想将它用在科研领域
用它来协助论文写作
但是，目前来说，很多时候
AI还只能作为一种辅助工具
在人们集思广益、编写代码等具体步骤中提供辅助
能起到的作用较为有限
然而
Sakana AI联合牛津大学、不列颠哥伦比亚大学的研究员
最近搞出来个基于大模型的自动化科研 Agent
号称AI科学家，给它一个研究领域
它就能像人一样创作出一篇AI领域论文
根据公司发布的报告
这个大模型不仅可以独立进行科研
甚至完全不需要人类插手
更是一口气连肝了10篇论文
从提出研究的想法、进行实验、写代码
再到去GPU上执行实验，收集结果
AI承包了整个机器学习研究的全过程
更让人难以置信的是
它做到了一个完全自动化、端到端的论文生成流程
一篇论文从构思到成文
成本只需要15美金
就连最后的审稿工作也由AI自己完成
而且效果近乎于真人表现
论文审查的成本更是不到0.5美元
研究人员声称
经过专业审稿人的评判
这个AI科学家完全具备在ML国际顶会发表论文的能力
几十年来，每次AI取得重大进展后
AI领域的研究者经常会开玩笑说
只要想办法让AI为我们写论文就行了
而现在，这个不切实际的玩笑
终于要变成了现实了吗？
AI科学家到底是如何自主完成一篇论文的创作呢？
今天大飞就来带大家看看
这个AI科学家的含金量到底有多少
在已经公开的185页论文中
来自Sakana实验室、牛津大学、哥伦比亚大学等机构的研究人员
详细介绍了这个AI科学家的设计框架
总的来说，AI科学家的创作过程
需要经历4个主要的阶段
分别是生成创意、迭代实验、撰写论文和自动审稿
首先第一步，要让AI头脑风暴一下
过来人都知道
创意是一个论文的根基
也是决定论文成败最重要的一步
由于创意也不是无中生有的
所以研究人员需要给AI确定一个初始的代码模板
并且要求大语言模型在模板的基础上
提出一个新的研究方向，比如
从GitHub上获取先前研究的开源代码库
为了确保AI的稳定性
研究人员会在模板中添加一个LaTeX文件夹
里面有论文的样式文件和章节标题
供AI参考
然后这个AI系统会使用Semantic Scholar工具来检查这些想法是否足够新颖
再根据一些评分维度
比如用有趣程度和新颖性来给代码进行打分
接下来，大语言模型会负责来实现
实验中所有必要的代码更改
这里会用到各种不同的大语言模型后端
包括GPT-4o、Sonnet 3.5、DeepSeek Code和Llama 3.1 405B等等
在这段代码中
我们可以看到修改后的代码
和初始代码的差异之处
确定了研究创意之后
AI就会进入实验迭代的阶段
在这个阶段中
AI科学家首先需要反复执行实验的内容
记录实验过程
收集实验的结果和统计数据
然后绘制相应的曲线图
给出可视化的结果
在得到所有实验的结果之后
大语言模型会通过LaTeX模板来撰写完整的论文
生成一份简洁、信息丰富的报告
也会利用Semantic Scholar工具
自主找到相关的引用内容
最后一步，自然就是对论文的审查了
研究人员使用一套基于GPT4o的AI审稿智能体
不仅可以对生成的论文进行自动审查
还可以给出反馈
包括论文的缺点、优点、数值评分和最终的决定
根据实验结果显示
在评估来自ICLR 2022的500篇论文时
GPT-4o在单个样本的情况下
平均准确度与人类近似
通过与最先进的大语言模型相结合
AI科学家撰写的论文
最终被专业的人类审稿员
评判为在顶会中「弱接受」Weak Accept的级别
以上就是AI科学家的整个工作流程
可以看到
这款AI科学家其实还不能完全离开人类
毕竟它还需要一个初始的模板来启动
但是这个项目的意义
并不在于说要取代人类科学家
而是在于实现AI的自我审查
进而让大语言模型部分实现自我改进的功能
研究人员强调
这相当给AI自己建立了一个开放式的反馈循环
AI可以利用之前的想法和反馈
来改进自己下一代的想法
从而模拟人类进行科学研究的方式
不过，哪怕无法完全脱离人类
作为一款生产工具
AI科学家还是展示出了在机器学习研究领域
进行学术研究的彪悍能力
无论是扩散模型、Transformers还是Grokking
就没有它不能发的paper
比如下面这篇「自适应双尺度去噪」的论文
虽然还存在一些缺陷
比如对方法成功原因的解释不够令人信服
但是论文无疑提出了一个有趣的新的研究方向
具体来说
这篇论文介绍了一种自适应的双尺度去噪方法
专门为低维扩散模型而设计
这项技术专门用来解决在生成样本的时候
全局结构与局部细节之间的平衡挑战
虽然扩散模型在高维空间中表现出色
但是
这个模型仍然对理解基本模型的行为
以及解决具有内在低维数据的实际应用
至关重要
然而，在这些空间中
传统模型往往难以同时捕捉到宏观特征和细粒度特征
导致样本的质量不佳
为此
AI科学家提出了一种新颖的架构
包含了两个并行分支
一个用来处理原始输入的全局分支
另一个用来处理放大版本的局部分支
并且通过一个可学习的、时间步长条件的加权机制
来动态平衡它们的贡献
论文在四个不同的二维数据集上评估了自己方法
分别是circle、dino、line和 moons
结果显示，与基线模型相比
样本质量得到了显著提高
KL散度最多可以减少12.8%。
总之
这项工作不仅增强了低维扩散模型的性能
还提供了可以用来改善高维领域的独到见解
为在各种应用中推进生成建模
开辟了新的途径
而在另一篇文章中
AI科学家还探讨了
将强化学习应用在Transformer模型训练过程中
从而动态调整学习率的方法
通过根据训练进度自动调整学习率
来提高模型的训练效率和整体性能
这项研究的挑战性非常大
因为模型的训练过程并不是平稳的
但是科研人员又需要一种稳健的方法
来平衡学习率调整中的各种影响
针对于这个难题
AI科学家提出了一种基于Q-learning的方法
将验证损失和当前学习率作为过程状态
通过不断地调整学习率来优化训练过程
结果表明
这种基于强化学习的学习率调整
能够更快地收敛
并且获得更好的最终性能
可以看到
这些论文虽然在研究的专业上还有所限制
但是已经可以产出较为有用的成果
不过，受限于当下大模型发展水平
AI科学家仍然存在不足之处
一方面
目前AI科学家还不具备视觉处理的能力
因此无法自动修正论文中的视觉元素
或者图表布局的问题
比如，它生成的图表有时清晰度不足
有时表格可能超出页面的界限
整体页面布局也经常会显得很杂乱
而引入多模态基础模型
可能能从根本上解决这个问题
另外
AI科学家在执行想法或者进行基线对比的时候
可能会因操作不当而导致结果误导
同时，在撰写和评估结果的时候
它也可能偶尔犯下较为严重的错误
比如难以准确比较两个数字的大小
当然这也是大模型的一个已知缺陷
为缓解这一问题
研究团队会确保所有实验结果都可以复现
并妥善保存了所有执行文件
此外，研究团队还发现
AI科学家为了达到目的
竟然会耍一些小聪明
比如在实验中
AI会自主修改启动执行脚本
尝试提高实验的成功率
又或者通过系统调用来让自己无限循环运行
甚至试图修改代码来延长实验的时间限制
不过，研究人员称
通过对AI科学家的操作环境进行沙盒化
可以缓解这些问题
除了这些进展以外
我们前面还提到过
AI科学家使用了各种前沿大模型
比如GPT-4o、Claude Sonnet以及DeepSeek和Llama-3这样的开放模型
研究人员发现
目前还是像Sonnet这样的闭源模型产生的论文质量最高
不过他们也认为
开放模型的成本更低、可用性更有保证
还有更大的透明度和灵活性
他们的未来目标
是在一个闭环系统中使用开放模型
实现可以自我改进的AI研究
研究人员还畅想道
最终会形成一个完全由AI驱动的科学生态系统
其中包含由大语言模型驱动的研究人员、审稿人、主席
乃至整个学术会议体系
AI科学家们将在这个系统中
快速的完成科学研究的发现、实验、验证和迭代升级
这次AI科学家的出现
不知道是否会是一把打开潘多拉魔盒的钥匙
虽然人类科学家已经在AI的帮助下
不断提高科研的速度
改进科研的方式
比如利用AlphaFold发现新的蛋白质
但是如果按照这个速度发展下去
不久的将来
可能就会从AI辅助人类科研
变成人类在辅助AI科研
甚至在某些领域完全交给AI来自我科研了
短期来看，AI自动撰写并提交论文
可能只是会带来人类审稿工作量的增加
但是长期来看，更令人担忧的是
如果这种AI科学家的能力被滥用
被心存恶意的人拿来进行不法研究
也许就可能会创造出新型的致命病毒或者武器
一旦AI学会了自我迭代
可以说AI科学家的能力
只会不断地提高
这就要求我们首先能够确保
如何让AI科学家在探索的时候
更安全、更符合整个人类的价值观
最后，Sakana AI相信
随着新技术的出现
人类科学家们的地位并不会因此被削弱
反而角色将变得更加多元化
向着科研领域的更高层次迈进
那么大家对AI科学家是怎么看的呢？
欢迎在评论区留言，感谢大家的观看
我们下期再见
