大家好，这里是最佳拍档，我是大飞
相信最近关注AI圈的朋友
都被OpenAI的动静刷屏了
前几天，Sora 2刚登顶App榜
那种细腻到发丝、流畅到自然的视频生成效果
让不少人直呼“AI视频时代真的来了”。
但是如果说Sora 2是OpenAI在“秀技术肌肉”，
那美国时间10月6日举办的OpenAI DevDay
就是它真正亮出“战略蓝图”的时刻
这场发布会没有太多颠覆性的“黑科技”，
却把过去两年AI技术的演进
整合成了一套系统化、平台化的生态方案
目标很明确
那就是要构建一个以AI为绝对核心的全新软件生态体系
今天咱们就来回顾一下这场发布会的内容
看看OpenAI的“商业帝国”到底在如何布局
首先
咱们得先明确这场发布会的整体框架
除了常规的API更新
核心内容其实是三个板块
Apps SDK、AgentKit、Codex
这三者共同撑起了OpenAI的未来生态
而第一个要聊的
就是能让“大语言模型成为所有软件唯一入口”的Apps SDK
可能有朋友还记得，2024年的时候
“把大语言模型当软件入口”，
还只是个模糊的概念
大家觉得AI能帮着调用工具
但总觉得差点意思
可到了2025年
这个概念已经成了行业共识
而OpenAI的Apps SDK
就是把这个共识落地的关键工具
它不是一个简单的“插件集合”，
而是一套完整的开发堆栈
开发者用它
能在ChatGPT内部直接构建真实、可交互的应用程序
通过连接自己的数据、触发具体的操作
甚至可以渲染出交互式的用户界面
这和之前的工具不一样的地方在于
像Claude和GitHub Copilot这些
它们虽然也能调用外部服务
但是最终只能把结果以文本的形式返回
缺乏真正的上下文理解和自然的交互界面
简单来说
过去的工具是“告诉你结果”，
而Apps SDK是“帮你完成操作”，
让用户在大语言模型里像在电脑上一样来使用App
发布会现场有个非常生动的案例
我给大家还原一下
假设你正在为宠物狗业务做头脑风暴
聊到一半想做海报
这时候你不用退出ChatGPT
直接“@”出Canva
重点来了
这个Canva能完全理解你之前和ChatGPT聊的所有点子
比如你说，要色彩丰富、异想天开
它不用你再重复解释
直接就能生成一系列符合要求的精美海报
如果这时候你灵感来了，说
请把这张海报扩展成商业计划书
它也能无缝衔接
直接帮你把商业计划书的框架搭好
等你想扩张业务，需要找场地的时候
ChatGPT还会根据你之前聊的“宠物狗业务”上下文
主动建议你考虑“匹兹堡”这个城市
然后直接唤起房产平台Zillow
全屏展示
你在ChatGPT里说“要带院子的三居室”，
它就会帮你进行筛选
筛选完你再问“这个房子离狗狗公园有多远”，
它还能基于Zillow的数据直接回答
整个过程没有一次软件切换
所有操作都在ChatGPT的对话框里完成
工具在最需要的时候自动出现
还能协同工作
这背后就是Apps SDK的核心能力
打破应用之间的壁垒
让不同工具在统一的入口里形成“协作流”。
而支撑这一切的，是OpenAI的MCP体系
开发者依靠MCP能设计应用的逻辑和界面
再结合GPT本身的图像识别能力
让App不是“硬塞进”对话
而是“自然的融入”对话
更关键的是上下文记忆能力
发布会里还有个细节
ChatGPT在另一个新对话里
还能延续上一个对话的宠物狗业务话题
这种跨对话的记忆
正是大语言模型能够作为软件入口的核心竞争力
以前的App是“功能孤岛”，
你打开才能用；
现在有了Apps SDK
App成了“可随时唤醒的插件”，
还能理解你的对话背景
真正做到了万物在大语言模型内
聊完Apps SDK，我们自然要问
怎么让这些App更好地适应用户需求
和对话更紧密地连接呢？
这就轮到发布会的第二个核心
AgentKit了
行业里其实早就把2025年称作“Agent元年”，
但是直到10月
市场上都没出现足够引发行业震荡的现象级Agent产品
显然，大家都觉得Agent是未来
但是开发门槛太高、落地太难
而OpenAI这次推出AgentKit
就是想“推一把”Agent时代
它号称是“最简便、快捷”的Agent开发工具包
核心思路就是让一切回归可视化
AgentKit的核心是“Agent Builder”，
这是一个可视化的画布
以前开发者做Agent，得从零写代码
逻辑错一点就得从头改
而现在用Agent Builder，不用写代码
通过直接拖拽、连接不同的功能节点
就能直观地设计复杂的业务流程
除了画布，它还有两个关键的功能
一个是“ChatKit”，
这是一个可嵌入的聊天组件
开发者能轻松把带品牌定制能力的聊天界面
集成到自己的应用里
不用自己再来做界面设计了；
另一个是“Connector”，
能够直接把AgentKit里构建的Agent工具
和企业内部的数据、工具连起来
比如企业的客户数据库、内部办公系统等等
这样就不用再去做复杂的接口开发了
直接和企业已有的系统打通
发布会现场
产品经理克里斯蒂娜（Christina）做了个演示
从零开始，只用了8分钟
就为一个静态的DevDay活动官网
搭建并且上线了一个智能问答Agent
从演示里能看到
AgentKit的功能节点特别精简
只有三个核心
分别是Agent、End和Note
不同Agent之间的逻辑关系
也只用三个点就能控制
分别是条件触发
比如用户问时间就调用A Agent
问地点就调用B Agent，还有同时进行
让多个Agent并行处理任务
以及用户许可
也就是需要用户确认后才继续
每个Agent内部，还能添加三个工具
包括文件搜索、安全防护和MCP应用
当然
你也能把这些工具作为独立的功能点
加在流程外部
整个设计逻辑十分清晰
哪怕是没做过Agent开发的人
看一眼也能明白个大概
不过，客观地说，单从设计逻辑上看
AgentKit并没有比现在市场上的Dify、Coze这些工具领先太多
但是它胜在“精简”和“易用”。
为了让习惯了Dify的用户转用AgentKit
OpenAI还提供了两个“杀手锏”。
第一个是RFT定制
现在第三方工具用GPT
都只能把它当做“黑箱”一样来调用API
你不知道模型内部是怎么推理的
也没法优化
但是AgentKit能深入模型的内部
目前OpenAI已经在实验GPT-5的RFT功能
开发者通过RFT
不仅能定制GPT-5的推理模型
还能专门训练模型在最恰当的时机、用最优的方式来调用工具
比如你想做一个客服Agent
用RFT能让模型学会
用户问售后问题的时候
先调用订单数据库查询信息
再调用售后流程工具提交申请
而不是乱调用工具
这对想基于GPT来开发Agent的企业来说
吸引力非常的大
第二个是AgentKit的“Evals评估板块”。
做Agent开发
最头疼的就是“不知道问题在哪”。
比如流程跑不通，到底是节点错了
还是工具调用时机不对呢？
Evals就直接解决了这个问题
它提供了“数据集构建”、“跟踪评估”、“自动化提示优化”这些能力
能让开发者对Agent工作流进行端到端的评估
精准定位和修复问题
这对需要快速迭代Agent的团队来说
确实能省不少事
不过这里我也得客观说一句
看到AgentKit
不禁让人容易想到当年OpenAI发布的GPT Store
那时候的模型主要靠上下文
没法有效的调用工具和数据
应用场景特别窄
现在AgentKit虽然解决了开发门槛问题
但是Agent落地的核心难题
比如复杂任务的逻辑拆解、多工具协同的容错性
以及真实场景的数据安全等等
这套框架能不能解决，目前还不好说
不过，至少OpenAI已经开始行动了
也许就会有找到解法的可能
聊完Agent，咱们再往底层看
不管是开发Agent
还是部署App，最基础的支撑都是编程
而发布会的第三个核心
就是可能会让Claude“编程王者”地位受到威胁的Codex
根据Sam Altman在发布会上的介绍
Codex从今年8月上线到现在
已经处理了40T的token数量
成了OpenAI增长最快的产品之一
从程序员社群的反馈来看
Codex的出现确实冲击了Anthropic Claude
现在有越来越多的程序员开始用Codex
认为它生成的代码更贴合实际的开发需求
这次发布会
Codex正式从“研究预览版”转为了“正式版”，
更新的重点是对企业和工程团队的深度支持
具体分为三个方面
第一个是Slack集成
这是程序员社群呼吁了很久的功能
以前团队用Codex
得在Codex界面和Slack之间来回切
现在不用了
直接可以在Slack频道里调用Codex
它能在对话流里直接回答相关的技术问题
比如“Python怎么实现批量处理Excel”，
或者直接生成代码片段
甚至能帮忙查看代码里的bug
整个流程都在团队日常沟通的场景里完成
不用再切换应用，效率提升十分明显
第二个是全新的Codex SDK
以前企业用Codex，大多是“单点使用”，
比如团队里的某个程序员用它来写代码；
现在有了Codex SDK
企业能够把Codex的能力作为一个“模块”，
集成到自己内部的开发工作流里
拿企业的代码审查系统举例
现在就可以通过Codex SDK来调用Codex的能力
自动检查代码规范；
或者让内部的开发文档工具
通过Codex来自动生成API文档
这样一来
Codex就不再是“单个程序员的工具”了
而是“整个团队的开发助手”，
能更好地融入企业现有的开发体系
第三个是新的后台管理与报告工具
对于企业管理者来说，以前用Codex
不知道团队里谁在用、用它做了什么、有没有安全风险
现在有了这套工具，能做“环境控制”，
比如限制某些团队只能使用特定的代码库、“实时监控”，
查看Codex的调用频率、处理时长
以及“分析仪表盘”，
统计Codex帮团队节省了多少开发时间、减少了多少bug
这些功能能让管理者清晰地掌握Codex在企业内的使用情况
也能更好地管控风险
但是这些更新
都不如发布会最后的那段演示令人印象深刻
演示者拉曼（Raman）当时说
我们来试试
只用对话，让语音助手调用Codex SDK
做一个滚动的开发者名单
然后他对着语音助手说
我需要在当前的前端应用里
加一个滚动展示的开发者名单
名单数据用DevDay的参会开发者信息
滚动速度要平缓
样式和现有界面保持一致
话音刚落
后台的Codex就开始实时修改前端的React代码
屏幕上能看到代码一行行的变化
没过几秒
页面上就出现了一个流畅滚动的开发者名单
和拉曼描述的完全一致
这个场景
就是OpenAI预想的“未来软件开发”，
你不用打开代码编辑器
不用手动敲一行代码，只用和AI对话
说出你的需求
软件就能在后台实时修改代码、自我迭代、完成功能更新
以前咱们说“代码生成”，
主要是AI帮你写代码
而现在OpenAI想做的
是“无代码编程”。
让AI直接帮你完成软件的修改和进化
开发者只需要负责提出需求就行了
这一步现在来看虽然还很初级
但是方向已经很明确了，未来的编程
可能真的会从写代码变成聊需求
除了APPS SDK AgentKit Codex这三个生态核心
发布会还有第四部分的内容
那就是相对传统的API更新
不过它们的重要性依然不容小觑
因为它直接降低了开发者使用OpenAI模型的门槛
首先是GPT-5 Pro的API开放
GPT-5 Pro是OpenAI目前最强大的模型
之前只对少数企业开放
这次正式向所有开发者开放API
这意味着不管是小团队还是个人开发者
都能用GPT-5 Pro的能力来做产品
实现更复杂的自然语言理解、更精准的多模态处理等等
这对整个开发者生态来说
这无疑是个重大利好
其次是新的语音模型“GPT Real-time mini”。
其实OpenAI做语音模型也有段时间了
但是之前的模型成本太高
很多开发者想做一些语音应用
都因为成本问题望而却步
而这次的GPT Real-time mini
成本比之前的版本降低了70%，
但是音质和情感表现力没打折扣
比如它能听出用户说话时的情绪
用对应的语气回应
也能清晰识别带有口音的语音
成本降了，能力没减
这就会大大降低语音应用的开发门槛
未来我们可能也会在更多场景里看到OpenAI的语音技术
而最重要的，是Sora 2 API的开放
之前Sora 2是作为独立App上线的
大家只能在App里生成视频
现在开放了API
意味着开发者能够把Sora 2的视频生成能力
集成到自己的产品里
比如内容创作平台
能让用户直接在平台里生成AI视频素材；
电商平台
能让商家用Sora 2快速生成产品的宣传视频；
甚至对于教育平台来说
也能让老师用Sora 2来生成教学动画
可以说Sora 2 API的开放
标志着OpenAI的顶级视频生成技术
正式从“自用”转向“生态共享”，
未来我们在各种应用里
可能都能够看到用Sora 2生成的视频
聊完所有技术细节，我们再跳出来
看看OpenAI这次DevDay背后的“野心”。
它的商业帝国轮廓
其实已经越来越清晰
甚至隐隐盖住了AGI的远景图景
先看模型迭代，今年的GPT-5 Pro
确实强大
但是已经没有GPT-4发布时那种“跨时代的惊艳感”了
GPT-4当时让大家觉得
AI居然能做到这个程度
而GPT-5 Pro更像是在GPT-4的基础上
做了稳健的优化
比如处理速度更快、上下文窗口更大、多模态能力更协调
但是没有突破大家的预期
Sora 2也是一样，它的惊艳之处
不是视频生成技术比更早它发布的Veo 3强多少
而是产品团队精准抓住了社交媒体的爆点
把真实人物无缝的融入到了AI生成的视频中
这是个天才的商业构想
能够快速吸引用户、占领市场
但是它更多是“商业嗅觉”的胜利
而非底层技术的革命
再看这次DevDay的核心
Apps SDK、AgentKit、Codex
这三者其实都是在“搭建生态”。
Apps SDK把所有应用拉进ChatGPT
让ChatGPT成为唯一入口；
AgentKit统一了Agent的开发标准
让开发者都来用OpenAI的工具做Agent；
Codex深入到企业的开发流程中
让企业离不开OpenAI的编程支持
OpenAI的整个逻辑很清晰
那就是想要以自家大模型为核心
搭建一个封闭而且具有强掌控力的软件生态
开发者们在这个生态里开发
用户们在这个生态里使用
所有数据和流量都留在OpenAI的体系内
这时候咱们再回过头来看看OpenAI早年的气质
那时候它带着一种“神秘感”，
总在探索未知领域
比如最早的GPT-3、DALL-E
每次发布都让大家觉得
离AGI又近了一步
那种对技术边界的突破
能让人肾上腺素飙升
但是现在的OpenAI
更像一个“成熟的商业公司”，
它不再追求“惊艳感”，
而是追求“生态掌控力”；
不再强调“探索AGI”，
而是强调“商业落地”。
它的商业帝国轮廓也越来越清晰
但是曾经那种“为了AGI而探索未知”的气质
却在慢慢的褪色
当然，这并不是说OpenAI做错了
企业要发展，必然要考虑商业落地
要搭建生态壁垒
但是作为关注AI行业的人
我们难免会有些感慨
当OpenAI把更多精力放在“掌控生态”上
它还能像以前那样
为AGI的突破投入足够的资源吗？
AGI的远景
会不会慢慢变成“商业帝国”的附属品？
这个问题，可能需要时间来回答
不过不管怎么说
这次DevDay都给整个AI行业指明了一个方向
AI的下一个阶段
不再是“单点技术突破”，
而是“生态整合”。
谁能把应用、Agent、编程工具都整合在自己的体系内
谁就能在未来的竞争中占据优势
对开发者来说，这是机遇，也是挑战；
对用户来说
未来我们可能真的会进入
一个对话框解决所有问题的时代
但同时也要接受所有需求都在一个生态里完成的现状
最后，我想问问
大家觉得OpenAI的这个生态蓝图
会让AI变得更加实用
还是会让行业陷入到“生态垄断”中呢？
你会用Apps SDK来做自己的应用
还是继续用独立工具呢？
欢迎在评论区留言交流
好了
今天对OpenAI DevDay的解析就到这里
感谢收看，我们下期再见
