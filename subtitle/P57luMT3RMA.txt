大家好，这里是最佳拍档，我是大飞
前两天做纳瓦尔的节目时
提到了大卫·多伊奇的一些著作和思想
有很多朋友说想了解更多
所以今天大飞我呢
就先给大家分享一下，他在2012年
也就是将近12年前发表的一篇与人工智能有关的文章
标题叫做《哲学将成为开启人工智能的钥匙》，
如今读起来，依然是振聋发聩
在这篇文章中他认为
人工智能是可以实现的
但是要想开发出像人一样思考的机器
仅靠计算机科学和神经科学是不行的
无论是人还是机器
对智能生物的定义属性
是创造力
这也是在纳瓦尔那期节目中
他反复在提到的
那究竟如何才能实现通用人工智能呢
我们看看大卫·多伊奇究竟是如何说的
人类大脑所具有的能力
在某些方面要比任何宇宙中已知的事物
都更为强大，这一点毫无争议
大脑是唯一一个事物
能够理解为什么宇宙会存在
为什么会有无穷多质数
为什么苹果坠落是因为时空曲率
为什么遵循自身的生物本能在道德上可能是错误的
或者为什么大脑自己的存在
等等所有这些现象
大脑的独特之处还体现在一个冷冰冰的物理事实上
那就是它是唯一能将自己送入太空
然后完好返回的事物
它能预测或者预防陨石砸到自己
或者将物体冷冻到绝对零度之上
数十亿分之一度
也只有大脑能够在银河系的远端寻找同类
但是
对于以上所有被实现的事实和功能
这个星球上却没有一个大脑能够知道
自己到底是怎么做出来的
那些想要通过人工方式去实现它的努力
也就是所谓的AGI
artificial general intelligence
实际上六十年来没有任何的进展
尽管如此，AGI肯定是有可能的
这源于物理定律的一个深刻特性
就是计算的通用性
universality of computation
也就是通过计算过程来模拟自然过程的普遍可行性
这个特性意味着
只要时间和储存能力允许
通用计算机上的某个程序
是能够模拟出物体遵循物理定律所做的每件事的所有细节的
那么
为什么这个领域却一直没有进展呢？
在多伊奇看来
引起困惑的不是我们不知道的东西
而是我们以为知道
实际上并非如此的东西
没有任何其他重要的知识领域会像这个领域一样
社会和专家中的主流智慧
会如此根深蒂固地受到根本性错误的困扰
但是这个领域也是最具有自信的
有人预言AGI很快就会实现终极的突破
1950年，艾伦·图灵预测
到2000年
人们能够谈论机器思考而毫无违和感
1968年
阿瑟·C·克拉克预测这一情形会发生在2001年
直到今天，在对AGI的编程方面
仍然没有人能够超越图灵本人
对AGI可能性持反对态度的人数在不断减少
这并不令人感到意外
但是，另一个阵营
认为AGI即将到来的那群人也承认
这段失败的历史迫切需要得到解释
至少需要合理化
而AGI这个词就是一个合理化解释的例子
这个领域曾经被称为AI
即人工智能
但是
AI逐渐被用来描述各种不相关的计算机程序
比如
游戏玩家，搜索引擎和聊天机器人
直到字母G所代表的「通用（general）」被加上去
人们才有可能再次用这个单词
来指代真实的事物，不过
现在的AGI不过是指那些更加聪明的聊天机器人
另一类合理化解释的思路是
AGI并没有想象的那么好
现在的软件已经越来越智能了
只不过是以非人类的方式
而且我们太虚荣、太过秉持文化上的偏见
以至于无法给它应有的认可
这种解释获得了一定的支持
因为它让人想起
文化相对主义中持续流行的非理性
以及相关的比喻，那就是
我们人类以身为动物的典范而骄傲
但是这种骄傲却被放错了地方
因为动物也有着语言、工具、以及自我意识
还记得电影《终结者》中的计算机系统天网么
它正是因为变得具有「自我意识」而被大家如此关注
不过
这只是另一种哲学上的错误观念
本身就足以屏蔽通往AGI的任何道路
事实上
现在的软件开发人员可以直接对计算机编程
让它具有行为意义上的「自我意识」，
比方说
他们可以让计算机通过「镜子测试」（mirror test）
利用镜子来推测关于自己的事实
不过据我们所知，还没有人这么做
很可能是因为这实在没什么用
而且微不足道
自我意识之所以因为AGI而获得了不该有的名声
原因可能在于任何形式的自我参照都已经变成了一种迷信
这还要感谢哥德尔定律和二十世纪各种形式逻辑的争议
为我们揭示出了这个真相
意识也是如此
而且对于意识
我们又很难用术语来描述清楚
因为意识这个术语的含义太广泛了
一方面是主观感觉的本质
即「感受性（qualia）」的哲学问题
这与AGI的问题紧密相连
另一方面
「意识」不过是我们在麻醉状态时所失去的东西
当然许多动物也有这种东西
未来，AGI一定会有自我意识，但是
那是因为他们具有了通用性（General）
他们能够意识到各种深刻而且微妙的事物
包括它们自己
不过，这并不意味着
如果通过镜子测试的黑猩猩被暗示具有「通用智能（general intelligence）」的特征
那么AGI就是这种「通用智能」的人工版本
确实
理查德·伯恩Richard Byrne对大猩猩模因（memes)的精彩研究已经揭示出
黑猩猩如何能在不了解用途的情况下
相互学习有用的行为，也就是说
对黑猩猩认知原理的解释实际上是行为主义的
讽刺的是，这组合理化的解释
观点正是源于那些「AGI不可能」阵营观点的镜像
针对「做不出AGI
是因为我们永远无法对人类的灵魂编程
因为灵魂是超自然的」这种形式的观点
认为「AGI很容易实现」的阵营
都能找到合理化的解释
那就是「如果你认为人类认知与黑猩猩有着本质的不同
那么你必须相信有超自然的灵魂」。
另外一种合理化的解释是
任何我们还不知道如何编程的东西
都可以被称为‘人类智能’。
这是来自哲学家约翰·塞尔John Searle提出的论点的镜像
他属于“AGI不可能实现”的阵营
他认为在计算机诞生之前
蒸汽发动机和后来的电报系统
都曾经被用来隐喻人类心智的工作方式
他认为
AGI可能仅仅存在于类似的、非实质性的隐喻上
也就是心智本质上是一个计算机程序
但是
计算的通用性遵循已知的物理定律
这句话并不是一个隐喻
有些人认为，大脑使用了量子计算
甚至使用了以量子理论无法解释的物理现象为基础的超量子计算（hyper-quantum computation）
这就解释了为什么在现有计算机上创造AGI失败的原因
不过
多伊奇和量子理论领域的绝大多数研究人员都无法苟同
那就是人类大脑拥有独特功能的原因之一
从一开始，AGI的概念中就隐含了
AGI是人的意思
哪怕缺少一个人类特有的认知能力
那么
从定义上说，它就不是AGI
如果使用非认知性的属性
比如碳含量的百分比来定义人格
那这属于种族主义的做法
认为有机大脑优于硅基大脑
但是实际上，创造新的解释
是人、包括人类和AGI所特有的功能
在道德和智力上具有重要的意义
他们通过推测和批判可以做出新的解释
这一事实改变了一切
如今
人格（personhood）更加具有象征的意义
而非真实的意义，它被作为一种荣誉
作为证实某个实体
比如黑猩猩、胎儿、公司是一个人的承诺
从而来实现某种哲学或者实践中的目的
但是这并不是正确的做法
因为那个在客观标准定义下的
真实的人类与其他实体之间的区别
具有重大的道德和实践意义
对包括AGI在内的文明运作也至关重要
比如，如果说人类不是计算机
而是一个运行的程序
那么这个事实就会引发一个未解的哲学难题
那就是一旦AGI存在
这个难题就会变成一个现实的政治争议
因为一旦AGI在计算机上运行起来
再想从计算机上剥离它
就无异于等同谋杀
或者至少会是一种错误的监禁
就像是剥夺一个人的思想和肉体一样
但是，和人体不同的是
你只需要轻轻按一下按钮
一个AGI程序就能够被复制到许多台计算机上
虽然他们的运行步骤相同，但是
这个程序是同一个人还是多个不同的人呢？
它们应该享有一个投票权还是多个投票权呢？
删除其中一个程序是属于谋杀
还是属于较轻的袭击呢？
如果一个不讲武德的程序员
在一台或者多台电脑上
创建出了成千上万个不同的AGI分身
那么会发生什么呢？
他们都是人，享有人权
但是他们都能拥有选举权吗？
而且，我们对AGI
就像对其他任何具有创造力的实体一样
必须忘掉“编程”这个词几乎所有的现有的含义
把AGI看作是任何一个其他的计算机程序
都将构成类似于洗脑、奴役、暴虐的效果
从儿童的角度说也是同样的残酷
因为和其他编程行为不同
对一个已经处在运行中的AGI「编程」，
就意味着教育
这会引发道德和事实层面的争议
忽视AGI的权利与人格不仅代表着邪恶
也会成为制造灾难的根源
因为任何有创造力的存在不能永远被奴役
有些人想知道
我们是否应该欢迎这些新的机器人
并且如何操纵他们的程序
让他们本质上无法伤害人类
就像阿西莫夫的「机器人三定律」一样
同时防止他们将宇宙变为回形针
大飞我这里稍微解释一下
宇宙回形针Universal Paperclips
是瑞典哲学家尼克·博斯特罗姆（Nick Bostrom）在讨论AGI风险时
提出的一种思想实验，简单来说
就是如果一个超级AI被设计成生产尽可能多的回形针
而不考虑其他任何的因素
那么它有可能会消耗地球上所有的资源来生产回形针
甚至包括把人类转化为生产回形针的原料
导致人类的灭绝
后来纽约大学游戏中心的总监弗兰克蓝兹（Frank Lantz）还专门以此为题材
开发了一款游戏，关于这个哲学问题
回头我们专门做一期视频来讲讲
回到多伊奇的文章
他认为这都不是什么问题
因为事实一直是
无论从生产力、经济能力、智力哪个方面来看
一个特别有创造力的人
他的能力都会是普通人的成千上万倍
而这种人如果将自己的能力用来作恶
那么就会祸害无穷
不过，这些现象与AGI没有什么关系
善恶之间的思想斗争和人类这个物种一样古老
而且无论智能在什么硬件上运行
都还会持续斗争下去
问题在于
我们总是希望善的智能总是能击败恶的智能
无论是这个智能是生物的还是人工的
但是我们也会犯错
我们自己对于「善」这个概念的理解
也需要不断的发展
同时社会的组织结构也需要不断的发展来适应
如果我们认为
想要「控制所有的智能」是一个灾难性的错误答案
那么想要「控制所有看起来与我们不同的智能」，
也好不到哪里去
有一个我们现在必须停止的事情
就是将对人类或者类似AGI的教育
视为一种指令
用一种不加改变、填鸭式灌输知识的手段
让它们遵从现有的价值观
正如卡尔·波普尔（Karl Popper）在《框架的神话（The Myth of the Framework）》一书中所写的
不存在来自于认知框架以外的指令
我们不是通过复制来发现新的事实或者影响
也不是从观察中归纳推导出它们
更不是依靠环境的指导来发现新的事物
直接点说，我们的办法是试错
也就是推测和批判
学习必须是新创造出的智能为自己所做的事
而且必须是自己能够控制的
多伊奇并不是在强调所有这些哲学问题
因为他担心在人类发展出复杂的哲学来理解AGI
并将它融入到人类文明的哲学解释之前
AGI就已经被开发出来了
出于几乎完全相反的原因，他确信
开发AGI的全部问题
其实就是一个哲学问题
而不是计算机科学或者神经生理学
并且哲学的研究进展是AGI未来融合的关键
它也是开发AGI的先决条件
错误的观念阻碍了AGI的发展
没有了波普尔的认识论
我们甚至没有办法开始猜测
开发AGI必须实现哪些细节的功能
但是
波普尔的认识论并不被大众所熟悉
更别说充分地理解并加以运用了
把AGI看做是一个把经验、奖励与惩罚翻译成思想
或者更糟糕的是翻译成行为的机器
就如同体液学说用平衡身体的体液
来治愈传染病一样可笑
因为它源自于一个古老而且错得离谱的世界观
如果你不能理解AGI和其他任何一种计算机程序
有什么本质的不同
那么你实际上并没有在这个领域中工作
如果一个人努力制作出一个「思维」上
天生就无法违背先决约束的程序
那么
这个人就是在试图消除智能生物
以及人的定义属性，也就是创造力
清除这个障碍本身并不会得出结论
但是
想要得到答案也并不难
既然人类能够设定目标
而黑猩猩没有这个能力
那么理解这个能力的本质区别
就为我们提供了线索
如何获取这一能力
答案肯定被编码进了人和黑猩猩DNA的少量差异中
因此一方面
多伊奇赞同AGI即将来临阵营的观点
那就是似乎我们和突破之间仅隔着一个想法
但是另一方面
他认为这个想法必须是有史以来最好的那一个
好了以上就是这篇文章的内容了
不知道大家听完有什么理解和感悟呢
欢迎在评论区留言
关于多伊奇的其他思想和著作
我们后续会逐渐一一介绍
感谢大家观看本期视频
我们下期再见
