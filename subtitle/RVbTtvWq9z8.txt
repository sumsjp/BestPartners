大家好，这里是最佳拍档，我是大飞
每年到初夏的时候
科技圈总会迎来一波“新品大秀”，
尤其是 5 月和 6 月这段时间
几乎成了开发者的“小春晚”，
微软、谷歌、苹果轮番登场
给大家带来一大波新的技术和工具
我们刚刚做完英伟达的ComputeX大会
今天要带来的是5月20日的微软Build 2025 大会
后面还会有谷歌IO和其他大会的报道
敬请大家期待
在微软的这场大会上
微软 CEO 纳德拉和 CTO Kevin Scott 亲自上阵
令人意外的是
一直不太对付的Sam Altman 和马斯克
还有黄仁勋
也都以线上视频接入的形式
出现在了这场大会上
分别与纳德拉进行了几段关于合作、大模型、芯片等维度的简短对话
整体来看
AI 无疑是微软现在最重要的战略方向
不过
今年开源也成了另一个贯穿全场的关键词
微软这次不仅将 VS Code Copilot 的核心功能开放了出来
还开源了适用于 Linux 的 Windows 子系统（WSL）
实属令人意外
当然，除了这些重磅发布
微软在这场大会上还有不少值得关注的技术创新
从产品体验到底层工具
接下来我们就来看看
微软又为AI行业带来了哪些新的变化
有个小插曲的是
纳德拉刚刚登台没几分钟
现场就出现了一名抗议者
后来了解到是微软硬件团队的一名工程师
名叫乔·洛佩兹Joe Lopez
主要是抗议微软与以色列政府签订的云服务和AI合同
对加沙人民造成了伤害
好在大会很快回归正轨
我们也言归正传
纳德拉在开场时
是这样描述当下的技术浪潮的
他说
我们正处在一轮变革的中局阶段
一切开始迅速扩展、加速演进
这有点像 1990 年代初
Web 技术刚起步时的情形
或者像 2000 年代云计算和移动互联网的快速崛起
而2025年的关键词则是open agentic web
他指出，在开发者工具方面
数据显示
Visual Studio 系列产品目前的用户已经超过了 1500 万
GitHub 拥有超过 1.5 亿开发者
而 GitHub Copilot 的用户数也突破了 1500 万
纳德拉对此信心十足
认为这一切才刚刚开始
而微软也正在不断地升级这些工具
比如
Visual Studio 将迎来多项功能更新
包括支持
NET 10、引入实时预览和更流畅的设计时体验、强化 Git 工具链
以及为跨平台开发打造的新调试器
更新节奏也将调整为每月发布一个稳定版
让开发者能够更及时地获取新的功能
VS Code 也刚刚发布了第 100 个开源版本
新增了多窗口支持
开发者现在可以直接在编辑器中查看和管理暂存区内容
在 GitHub 方面
微软正在推动 AI 与开源的深度结合
纳德拉宣布
将在 VS Code 中开源 Copilot 扩展
并且将这些 AI 驱动的功能
直接集成到 VS Code 的核心代码库中
让 AI 成为开发体验的一部分
也为 GitHub Copilot 的持续演进打下基础
针对 GitHub Copilot，纳德拉表示
现在它已能够帮助开发者完成从 Java 8 升级到 Java 21
或者将
NET Framework 升级到
NET 9 等版本的迁移工作
Copilot 会自动处理依赖项的更新、给出修复方案建议
并且从开发者的修改中学习
从而让整个迁移过程更加顺畅和自动化
微软还宣布推出一款专门为站点可靠性工程SRE打造的自主Agent
Azure SRE Agent
这款 SRE Agent能够在发生线上故障的时候自动启动
执行初步的排查、定位故障原因并且尝试缓解问题
随后会将事件报告记录为 GitHub Issue
并且附带完整的修复建议项
开发者可以进一步将这些修复任务
分配给 GitHub Copilot 继续处理
从而实现自动化运维的闭环
值得一提的是
微软首次推出了完整意义上的 Coding Agent
让 Copilot 从对话式的编程助手
向着真正的协作式开发伙伴迈进
新版 Coding Agent 的使用操作非常简单
只需要像分配任务一样
把一个或多个 GitHub Issue 分配给 Copilot即可
你可以在 GitHub 网站、移动端或者命令行中完成操作
也可以直接通过 Copilot Chat
在 GitHub 或者 VS Code 中发出指令
一旦接收到任务
Coding Agent 会在后台启动一个工作流程
包括启动虚拟机、克隆代码库、配置环境
并且通过基于GitHub Code Search 的RAG技术来分析代码
在工作过程中
这个Agent会持续将修改内容
以 Git 提交的形式推送到Pull Request 中
并且更新描述
同时
你可以在会话日志中看到它的推理和验证步骤
方便梳理思路与识别问题
借助MCP协议
开发者现在还能将外部数据和能力接入Agent
你可以在代码库设置中配置 MCP 服务器
也可以直接调用 GitHub 官方的MCP Server 来获取数据
不仅如此，得益于视觉模型的加持
Agent还能看懂 GitHub Issue 中的图片
包括 bug 截图或者功能草图
任务完成后
Copilot 会提醒你进行审核
并且会结合相关的 Issue 或 PR 内容
以及项目中的自定义说明
确保理解开发者的意图和遵循项目规范
大会现场，纳德拉自己还进行了实操
深度体验了这款 Coding Agent
目前已经面向 Copilot Enterprise 和 Copilot Pro Plus 用户开放
在这次 Build 大会上
微软还对 Microsoft 365 平台进行了全面升级
重点是对聊天、搜索、笔记本、创作工具和Agent界面进行了优化设计
看起来更加简洁
其中最引人注目的新功能
是 Microsoft 365 Copilot Tuning 的推出
它支持企业根据自身的数据、流程和语言风格
对Agent进行定制
构建符合业务需求的 Copilot
换句话说，微软的目标
似乎不是让消费者依赖 OpenAI 的 ChatGPT 模型
而是想让每家企业都能拥有“自己的 Copilot”，
用这些定制化的Agent来学习公司惯用的表达方式、沟通语气
甚至逐步掌握行业特有的专业知识
像以往
构建这种个性化的模型往往需要专业的数据科学团队、复杂的部署和很长周期的开发
而现在，企业只需要配置基础的环境
提供少量的参考资料
就可以快速启动定制流程
模型会自动继承现有的数据权限设置
确保内容只对授权用户可见
定制完成后
模型可以直接集成到 Copilot 中
按需分发给特定的用户组
纳德拉强调，这些模型和Agent
都是运行在 Microsoft 365 的服务边界内的
不会使用客户的数据来训练基础模型
从而确保数据的安全和合规
目前
Copilot Tuning 的早期体验计划将于 6 月启动
纳德拉还特别提到
借助 Copilot Studio 与Agent的推理能力
未来每一个业务应用
都可能会被多Agent工作流重新定义
当然了，想要构建出色的Agent和应用
不仅需要优秀的模型
还需要完整的系统支持
Azure AI Foundry 就是一个统一的平台
供开发者设计、定制和管理 AI 应用程序和Agent
这次大会上
微软带来了这个系统的多项创新
首先是扩充了模型库
包括xAI 的 Grok 3
还将推出Flux Pro 1.1
以及OpenAI的预览版Sora
其次，面对日益丰富的模型生态
模型的选择也变得越来越复杂
为此
微软推出了全新的 Model Router
可以根据任务自动选择最合适的 OpenAI 模型
简化开发者的使用流程
过去
一个应用或Agent只能绑定一个模型
而现在真正实现了对多模型的支持
第三
正式发布了Foundry Agent Service
允许开发者用极少量的代码
来构建可以协同工作的多个 AI Agent
比如在处理一个复杂的流程时
让多个子Agent通过分工协作来完成任务
第四
Azure AI Foundry 支持了多Agent的编排
这个功能不仅适用于 Azure
也支持 AWS、Google Cloud 以及本地部署
开发者可以让多个Agent像一个团队一样
相互协作、彼此调用
还能通过 A2A和 MCP 等开放标准
实现跨平台协同
这套机制还引入了状态管理、错误处理和长流程支持
非常适合金融审批、供应链等复杂的场景
同时
微软也在整合 Semantic Kernel 与 AutoGen 框架
为多Agent编排提供统一的支持
第五，在 AI 落地的过程中
性能、安全性和成本
常常是企业最关心的事情
为此
微软在 Azure AI Foundry 中引入了新一代的可观察性功能
开发者可以在统一的仪表板中查看Agent的质量、响应时间、费用开销
甚至可以详细追踪内部的执行逻辑
此外
微软还推出了全新的 Foundry Observability 功能预览版
为Agent提供从开发到生产的全链路可观测性
开发者可以实时监控延迟、吞吐量、使用情况与输出质量
并且查看每个Agent的推理过程和工具调用的详细日志
谈到微软
我们不得不提Windows 操作系统了
在这次Build 2025 大会上
微软再次强调了 Windows 在 AI 时代的重要角色
并且进一步推出了一项新的计划
Windows AI Foundry
目标是把 Windows 打造成最适合构建 AI 应用的平台
简单来说
Windows AI Foundry 是微软内部用来开发 Windows Copilot、Recall等 AI 功能的一整套工具和平台
现在
微软首次将这些工具向开发者们开放
而且覆盖范围不限于特定设备或芯片
无论你使用 CPU、GPU、NPU
甚至是在云端运行
都可以开发并且部署自己的 AI 应用
这其中
有一个名为Foundry Local的重要组件
它内置了一个已经优化好的模型库
开发者可以直接在本地运行这些开源模型
完全不依赖云端
比如微软自己的 Phi-Silica 小语言模型
未来将会直接内嵌在 Windows 操作系统中
如果你想让它做一些定制任务
只需加入一个 LoRA
就能快速完成“微调”，
而不需要再重新训练整套模型
纳德拉认为
Phi-Silica 有望改变 PC 上 AI 推理的格局
让本地运行 AI 模型变得像调用普通系统功能一样简单
而开发者也将能构建出更贴近用户、响应更快的智能体验
除了模型本身
微软还提供了一系列新的 API
让开发者可以将用户的本地数据转化成向量
嵌入到模型中
并且构建带有上下文理解的 AI 应用
而所有这一切都在用户的设备上完成
不依赖云端，数据也不会上传
更符合隐私保护的需求
为了让AI应用更好地与系统打通
微软还宣布 Windows 将原生支持 MCP协议
这意味着 Windows 将内置多个 MCP 服务
比如文件系统、设置、窗口管理等等
开发者可以构建兼容 MCP 的应用
并且通过官方注册表来连接这些服务
微软也会对这些接口进行性能和安全审查
保障用户体验和数据安全
与此同时
令不少开发者颇为兴奋的是
Windows 正在深度拥抱开源
并且在会上官宣了WSL 的完全开源
WSL全称是Windows子系统
最早于 2016 年亮相
起初通过 Windows 内核中的 lxcore
sys ，实现了对 Linux 程序的支持
被称为 WSL 1
随着对兼容性的更高要求
微软在 2019 年推出 WSL 2
引入了完整的 Linux 内核
并且陆续支持了 GPU、图形界面和 systemd 等功能
为了加快开发的节奏
微软在 2021 年将 WSL 从 Windows 中剥离
作为独立包发布到了 Microsoft Store上
并且在 2022 年推出了稳定版 1.0
此后，微软持续迭代
推动用户全面转向新的版本
并且在 WSL 2.0.0 中带来了重大更新
包括网络镜像、代理支持和防火墙兼容等
纳德拉在会上透露
其实早在项目刚启动的时候
社区就有人提出希望开源 WSL 的请求
但是当时由于 WSL 深度绑定在了 Windows 系统镜像中
没法单独分离出来
如今，随着架构演进
微软终于实现了代码的“松耦合”，
WSL已经具备了独立运作的能力
如今，微软终于翻出了当年的老帖子”，
正式把它标记为了已解决
除了这些以外，这次大会上
微软 CTO Kevin Scott 也推出了一个开源项目
NLWeb
目的是为了让网站更容易接入 AI 聊天机器人
简单来说，开发者只需要几行代码
就能在自己的网站上添加一个对话框和发送按钮
接入自己选择的 AI 模型
并且结合自己的数据
快速实现AI 聊天的能力
比方说
一个零售网站可以用 NLWeb 搭建一个推荐穿搭的机器人
帮助顾客挑选适合出行的衣服
而一个美食网站则可以创建一个聊天机器人
告诉用户某道菜应该搭配其他什么菜
更进一步，如果网站愿意
还可以通过 NLWeb 把内容开放给支持 MCP 标准的 AI 平台使用
Scott希望 NLWeb 能够成为Agentic Web里的 HTML
也就是说
就像 HTML 定义了网页的结构一样
微软希望NLWeb 能够成为 AI 模型理解和使用网页内容的新的基础
我们都知道
如今AI 技术的发展离不开大量数据的支撑
正如纳德拉所强调的
数据层是每一个 AI 应用的核心
围绕这一点
微软正式宣布了多个重磅数据产品的更新
最受关注的是即将推出的 SQL Server 2025
目前处于公开预览阶段
这是微软数据库系统的一次重要升级版本
不仅提供了内置的可扩展 AI 功能
还可以与 Microsoft Azure 和 Microsoft Fabric 无缝集成
而所有这些都可以在 SQL Server 引擎中使用T-SQL 语言实现
更值得注意的是
微软正在将数据能力与智能能力
以前所未有的方式打通
比如
微软已经将分布式数据库服务 Azure Cosmos DB和Azure Databricks
直接集成进了 Foundry 平台
这意味着开发者可以让Agent更自然地“记住”对话历史
也让数据更高效地服务于 AI Agent
作为整个数据栈的核心
微软在两年前推出的 Fabric 平台也在持续的演进
今年
Cosmos DB 也被纳入了 Fabric 体系
考虑到 AI 模型处理的内容
越来越多是文本、图像、音频等非结构化数据
这个整合就显得尤为关键了
用户现在可以在同一个平台上
统一管理结构化和非结构化数据
为 AI 应用做好准备
更进一步的是
微软还将数字孪生构建器接入了 Fabric
用户可以通过可视化界面、甚至无代码的方式
快速构建一个数字孪生系统
与此同时
微软还在OneLake 中推出了基于AI的快捷转换功能（Shortcut Transformations）
本质上就是一种智能的 ETL工具
借助预先构建好的 AI 模块
比如语音转文本、情绪分析或者摘要提取
用户只需要几次点击
就可以完成复杂的数据预处理操作
最后
微软还宣布了一项面向所有数据消费者的重磅功能
Copilot in Power BI
这个新功能允许用户直接通过对话的形式
与 Power BI 的报告进行交互
你可以用自然语言提出问题
Agent会跨多个报表、多个模型
帮你提取出数据并且生成可视化的分析
这项功能也将在 Microsoft 365 Copilot 中推出
进一步打通办公应用与数据分析的边界
在基础设施方面，纳德拉表示
现在的重点不只是让 AI“跑起来”，
而是要在性能、能效和成本之间找到最佳平衡点
这意味着，不只是要单点突破
而是要从芯片、系统软件到应用服务器
全链路地进行协同优化
于是
微软以每美元每瓦特可以处理的 token 数量
作为衡量指标
正在推进多个方向的技术跃迁
包括芯片工艺的演进、系统软件的调度优化、以及模型本身的架构革新
纳德拉称
今年的 Azure将成为首个大规模上线 NVIDIA GB200 Grace Blackwell 芯片的云平台
通过将 72 个 NVLink 互联机架连接成集群
Azure 的单套系统每秒能够处理多达 86.5 万个 token
创下当前所有公有云平台中的最高吞吐纪录
不过，AI 的底层基础
不只是部署几个 GPU 这么简单
每个 AI 应用除了需要算力
还需要高速的存储和网络
微软也正在从网络、存储到计算资源
全方位提升 AI 系统的效率曲线
在算力资源方面
微软去年推出了基于 Arm 架构的处理器 Cobalt
并且迅速在内部产品中广泛使用
比如 Microsoft Teams 和 Defender 安全系统
现在都跑在这上面
当然，对于那些对延迟非常敏感
或者对数据控制要求极高的场景
就需要“离用户更近”的计算资源
为此
我们之前提到过的 Foundry Local 服务
让用户在本地也能运行和云上相同的 AI 能力
从而构建可以离线运行的跨平台 AI 应用
同时将敏感数据存储在本地
降低带宽的成本
在大会的最后
纳德拉还特别提到的另一个重点领域
科学研究
这或许才是未来几年最令人期待的方向之一
他认为，AI 带来的下一个重大飞跃
可能正是在科学本身的流程上
未来我们有望加快新材料、新药物、新分子的研发速度
而这一切的背后
是对科学发现方式的根本性重塑
为了实现这一目标
微软现在推出了名为 Microsoft Discovery 的全新平台
这是一个利用 Agentic AI来改变科学发现流程的平台
你可以把它看作是科学界的“Copilot”，
就像 GitHub Copilot 重塑了软件开发、Microsoft 365 Copilot 改变了知识工作一样
Discovery 的目的是为科学研究者们
打造一个专属的 AI 助手
这个平台背后的核心
是微软最新的 Graph RAG 知识引擎
它不仅能够查找信息
还能理解科学领域中那些复杂、细致的知识结构
目前
这款系统已经在微软内部的研究中
展示了一定的潜力，官方数据显示
它帮助研究者们在大约 200 个小时内
发现了一种用于数据中心浸入式冷却的新型冷却剂
而传统上这个过程至少需要几个月或者几年的时间
好了
以上就是本次 Build 2025 大会的亮点内容了
不知道大家最感兴趣的技术点是什么呢？
欢迎在评论区留言
感谢大家的观看，我们下期再见
