大家好，这里是最佳拍档
关注AI行业发展的朋友们
一定能感受到一个明显的变化
从2023年的大语言模型爆发
到2024年的工具集成热潮
再到2025年的今天，整个行业的焦点
已经彻底转向了AI Agent
曾经，企业们还在纠结要不要做Agent
而现在，所有人都在问
怎么才能可靠、高效、大规模地部署Agent
为了搞清楚这个问题的答案
LangChain团队最近做了一次行业调查
覆盖了1340名来自工程师、产品经理、业务领袖到高管的专业人士
横跨科技、金融、医疗等多个行业
从小型的初创公司到万人规模的大企业
都有涉及
今天，我们就来拆解一下这份报告
看看AI Agent的真实应用现状、企业面临的核心痛点
以及未来的发展趋势
相信无论是行业从业者还是AI的爱好者
都能从这份数据中
获得一些有价值的洞察
在解读报告之前
我们首先要明确一个核心概念
什么是代理工程，Agent Engineering？
根据LangChain的定义
代理工程是一个迭代式的过程
核心是将大语言模型转化为可靠的系统
这里有一个关键的前提是
AI Agent是非确定性的
这和我们传统的软件系统完全不同
传统软件的输出是可预测的
输入A就一定会得到结果B
但是AI Agent会根据上下文、工具的调用结果
动态调整决策路径
同样的输入可能会产生不同的输出
正因为这种不确定性
工程师们必须通过快速迭代
来持续优化Agent的质量
这也是代理工程最核心的工作逻辑
简单来说
代理工程不是一次性的开发
而是一个持续打磨的过程
它要求团队不仅要懂大语言模型的原理
还要具备系统设计、工具集成、故障排查等多方面的能力
最终目标
是让AI Agent能够自主完成复杂任务
并且输出的结果稳定可控
这也是为什么
可靠性会成为企业部署Agent的核心诉求
接下来，我们来看报告的内容
首先来看一组核心数据
在2025年的调查中
有57.3%的受访者表示
他们的企业已经将AI Agent投入了生产环境
另外还有30.4%的企业正在积极开发
并且有明确的部署计划
这个数据对比2024年有明显的提升
2024年时
只有51.2%的企业实现了生产部署
仅在探索阶段的企业比例为10.7%，
2025年上升到了12.3%。
这个变化背后传递出了一个明确的信号
AI Agent已经度过了概念验证的阶段
开始进入规模化落地的初期
现在
绝大多数企业已经不再犹豫要不要做了
而是开始专注于怎么做好
而在这场落地的浪潮中
大型企业无疑是引领者
数据显示
员工规模在10000人以上的大企业中
有67%已经将Agent投入生产
24%正在积极开发并且计划部署
而员工规模不足100人的初创企业中
这两个比例分别是50%和36%。
为什么大企业的生产部署比例会更高呢？
报告给出了一个合理的解释
大企业往往在平台团队、安全基础设施和可靠性建设上
有更大的投入
这让他们能够更快地从试点项目
推进到稳定的生产系统
相比之下
初创企业虽然开发的意愿强烈
但是受限于资源
在规模化部署的基础设施准备上会慢一些
除了企业规模
行业分布也能反映出Agent的接受情况
在所有的受访者中
科技行业占比最高
达到了63%，这并不意外
因为科技企业本身对新技术的接受度更高
也有更强的技术研发能力
其次是金融服务行业10%、医疗行业6%、教育行业4%，
以及消费品和制造业各3%。
这说明AI Agent的应用
已经从科技行业渗透到了传统行业
只是不同行业的推进速度有所差异
了解了整体的部署情况后
我们自然会问
这些企业都把AI Agent用在了哪里呢？
调查结果显示
客户服务是最常见的核心应用场景
占比26.5%。
紧随其后的是研究与数据分析
占比24.4%。
这两个场景加起来
占据了所有核心部署场景的一半以上
成为AI Agent落地的主力军
先看客户服务场景
这个结果其实反映了一个重要的行业转变
AI Agent已经从企业内部的辅助工具
开始走向直接面向客户的前端工具
在过去，很多企业的AI应用
还停留在内部的办公自动化、员工辅助等场景
但是现在，越来越多的企业
敢于将Agent直接部署在客户服务一线
这背后的原因也很简单
那就是客户服务场景的需求
标准化程度较高
而且能够快速带来肉眼可见的价值
比如降低人工客服成本、提升响应速度、减少客户等待时间等等
尤其是对于电商、SaaS等客户量大的行业
AI Agent客服已经成为标配
再来看研究与数据分析场景
这个场景的火爆
恰恰击中了AI Agent的核心优势
擅长处理海量信息、跨源推理
以及加速知识密集型任务
在当今的商业环境中
企业需要处理的数据量
呈指数级的增长
从市场报告、行业动态到内部业务数据
人工处理不仅耗时耗力
还容易遗漏关键的信息
而AI Agent能够快速抓取、整合、分析这些数据
生成结构化的报告或洞察
帮助决策者节省大量的时间
除此之外
内部生产力提升占17.7%、代码生成占9.8%、内容生成占9.0%、销售和营销自动化占6.0%，
这些也都是重要的应用场景
还有6.7%的受访者选择了其他
说明AI Agent的应用正在逐渐多元化
不再局限于几个核心的场景
值得注意的是，不同规模的企业
应用场景的优先级也存在明显的差异
在员工规模10000人以上的大企业中
内部生产力提升是最核心的应用场景
占比为26.8%，
超过了客户服务和研究与数据分析
这背后的逻辑不难理解
大企业的内部组织架构复杂
部门众多，流程繁琐
通过AI Agent来优化内部的工作流、提升员工效率
能够带来巨大的规模化收益
比如大企业的HR部门
可以用Agent自动化简历筛选和员工入职流程
财务部门可以用Agent处理报销审核、发票整理
这些内部场景虽然不直接面向客户
但是能够显著降低企业的运营成本
而小企业则更倾向于将Agent用在直接产生营收
或者能获客的一些场景
因为这些场景的投入产出比更加直接
更符合小企业的生存需求
尽管AI Agent的部署势头正猛
但是企业在落地过程中
依然面临着诸多挑战
报告显示，输出质量是最大的障碍
有32.9%的受访者将它列为首要问题
这个结果和去年的调查保持一致
说明质量问题
是AI Agent规模化落地的长期痛点
注意
这里的质量是一个综合性的概念
不仅仅指输出结果的准确性
还包括相关性、一致性
以及Agent能否保持合适的语气、遵守品牌准则或者政策要求
比如在客户服务场景中
Agent可能会给出不准确的产品信息
在合规要求严格的金融行业
Agent可能会输出不符合监管政策的内容
甚至同一个问题，不同时间询问Agent
可能会得到相互矛盾的答案
这些都是质量问题的具体表现
而对于大企业来说
质量问题还多了一个维度
幻觉和输出一致性
很多万人规模的大企业在反馈中提到
如何避免Agent产生幻觉、确保在不同场景下输出一致的信息
是他们在质量优化上的核心难题
此外
上下文工程以及大规模场景下的上下文管理
也是大企业面临的重要挑战之一
当Agent需要处理超长对话、多源信息的时候
如何有效的管理上下文
避免信息丢失或者混淆
直接会影响输出的质量
排在质量之后的第二大障碍
是延迟和响应时间
占比为20.1%。
这个问题在客户服务、代码生成等面向用户的场景中
尤为突出
想象一下，当你在咨询客服时
AI Agent需要十几秒才能给出回复
你大概率会失去耐心
同样，开发者在使用代码生成Agent时
响应速度也会直接影响开发效率
这里面其实存在一个核心权衡
那就是质量和速度
更强大的AI Agent往往需要多步骤推理、多次工具调用
虽然能够提升输出的质量
但是必然会增加响应时间
如何在两者之间找到一个平衡点
是企业需要解决的关键问题
接下来是安全与合规占16.0%、部署基础设施占13.9%和成本管理占12.8%，
还有4.2%的受访者选择了其他
值得注意的是，成本管理的关注度
相比去年有了明显下降
这背后的原因
可能主要是因为模型价格的下降和效率的提升
让企业不再将原始支出作为首要的顾虑因素
转而更关注Agent的实际效果和用户体验
报告还指出，不同规模的企业
面临的核心障碍也各不相同
对于员工规模在2000人以上的大企业来说
安全与合规已经上升为第二大障碍
占比24.9%，超过了延迟问题
这很好理解
大企业的业务范围更广、涉及的用户数据更多
而且往往面临更严格的行业监管
Agent的安全漏洞
可能会导致严重的合规风险、数据泄露问题
甚至影响企业声誉
而对于员工不足100人的小企业来说
延迟问题则更为突出
因为小企业往往没有足够的基础设施投入
来优化Agent的响应速度
而他们的用户对体验的敏感度又很高
所以延迟问题会直接影响用户的留存
如果说质量是AI Agent落地的核心目标
那么可观测性就是实现这个目标的关键支撑
报告用 table stakes
必备条件来形容可观测性的重要性
简单来说，现在部署AI Agent
如果没有可观测性
就相当于盲人摸象
数据显示
89%的组织已经为他们的AI Agent
实施了某种形式的可观测性
其中62.4%的组织
拥有详细的追踪能力
能够检查Agent的每个步骤和工具调用
26.4%的组织只有基础的日志和指标数据
而没有实施可观测性的组织仅占11.2%。
更值得注意的是
在已经将Agent投入生产的企业中
可观测性的采用度更高
94%的生产级企业都实施了可观测性
其中71.5%拥有完整的追踪能力
只有6.0%的企业没有设置可观测性
为什么可观测性如此重要呢？
因为AI Agent的决策过程是黑盒式的
它不像传统软件那样
有明确的逻辑流程图
你无法直接知道它为什么会做出某个决策、调用某个工具
或者为什么会输出错误的结果
而可观测性的核心作用
就是把这个黑盒打开
让团队能够追踪Agent的多步骤推理链和工具的调用过程
想象一下
当一个客户服务Agent给出了一个错误的回复
通过可观测性工具
你可以一步步回溯
它究竟在哪个环节理解错了用户意图？
调用了哪个不合适的工具？
推理过程中哪里出现了偏差等等？
只有找到了问题的根源
才能针对性地优化Agent
提升质量
反之，如果没有可观测性
团队只能靠猜来排查问题
既低效，又无法保证优化的效果
可以说
可观测性已经成为AI代理工程的基础能力
没有它
企业就无法可靠地调试故障、优化性能
更无法建立内部和外部利益相关者
对于Agent的信任
这也是为什么
生产级企业的可观测性采用度如此之高
当Agent直接面向客户或者支撑核心业务时
任何故障都可能带来实际损失
而可观测性正是风险控制的关键所在
如果说可观测性是监控工具
那么评估与测试就是一本优化指南
但是与可观测性的高采用度相比
AI Agent的评估与测试还处于追赶阶段
数据显示，只有52.4%的组织
会在测试集上进行离线评估
37.3%的组织会基于生产数据
进行在线评估，还有29.4%的组织
目前尚未进行任何形式的评估
不过
评估实践的成熟度与Agent的部署阶段密切相关
在已经将Agent投入生产的企业中
评估的采用度明显更高
尚未评估的比例从29.4%下降到了22.8%，
而进行在线评估的比例上升到了44.8%。
这说明
当Agent开始面对真实用户、支撑实际业务时
企业才会真正开始重视评估工作
因为只有通过评估
才能及时发现生产环境中的问题
避免造成更大的损失
从评估方法来看
大多数团队会从离线评估开始
这主要是因为离线评估的门槛更低、设置更为清晰
不需要依赖生产数据
适合在开发阶段
验证Agent的基本行为
比如是否符合业务逻辑、是否能够正确的调用工具、是否存在明显的错误等等
但是随着Agent的落地
越来越多的团队开始采用离线+在线的混合评估方式
在开发阶段，用离线评估做初步验证
在生产阶段用在线评估
监控真实的表现
数据显示，在进行评估的组织中
有近四分之一的团队会同时使用两种评估方法
这种混合模式既能保证开发阶段的效率
又能兼顾生产阶段的实际效果
在评估指标的选择上
呈现出了明显的人机结合趋势
内部的人工审核和标注是最常用的方式
占比为59.8%。
这是因为AI Agent的很多交互是开放式的
不存在唯一的正确答案
比如客户服务中的语气适配、内容生成中的创意性
都需要人类来进行细致入微的判断
尤其是在高风险场景中
人工审核是必不可少的
排在第二位的
是大语言模型作为裁判的方式
占比为53.3%，
这种方式的优势在于规模化
能够快速处理大量的评估样本
适合检查事实准确性、是否遵守品牌准则等标准化的评估维度
值得注意的是
传统的机器学习和数据科学指标的采用率非常低
仅为16.9%。
这背后的原因很简单
那就是这些指标
主要是用来评估文本生成的相似度的
适合机器翻译、摘要生成等
有明确参考文本的场景
但是AI Agent的交互是开放式的
同一个问题可能有多个合理的回答
这个时候
再用相似度指标来评估，显然不合适
这也反映出AI Agent的评估体系
已经脱离了传统NLP的框架
正在形成自己独特的标准
在AI Agent的技术栈中
模型和工具的选择是核心决策之一
而这份报告也揭示了当前行业的选择偏好
首先是模型选择
OpenAI的GPT模型占据了主导地位
有67.8%的组织在使用
但是对单模型的依赖已经成为了过去
有超过四分之三的组织
会在生产或开发中使用多个模型
除了GPT模型以外
谷歌的Gemini的采用率为37.4%，
Anthropic的Claude为36.6%，
开源模型为34.2%，
还有5.9%的组织使用了其他的模型
这种多模型趋势的背后
反映出的是企业的理性决策
不同的模型在性能、成本、延迟、合规性等方面
各有优劣
团队会根据具体任务的需求来分配模型
对于复杂的推理任务
可能会选择GPT或者Claude等能力更强的闭源模型
而对于简单的信息查询、成本敏感等场景
可能会选择开源模型或轻量级的闭源模型
对于有数据驻留要求的行业
比如金融和医疗来说
可能会选择能够本地部署的开源模型
从而满足数据主权和监管要求
这种不把鸡蛋放在一个篮子里的策略
不仅能够优化成本和性能
还能避免被平台锁定
降低供应链的风险
其次是模型的部署方式
尽管商业API非常便捷
但是仍有三分之一的组织
在投入基础设施和专业知识
部署自己的模型
这种自建模型的需求
主要来自三个方面
一是成本优化，对于高使用量的场景
自建模型能够降低长期的API调用成本
二是数据合规
很多行业对数据的出境有严格限制
商业API的云端部署无法满足需求
三是定制化需求
部分企业需要针对特定的业务场景来优化模型
而开源模型提供了更多的定制空间
不过，与多模型部署形成对比的是
模型微调并没有被广泛的采用
数据显示
55.7%的组织不会对模型进行任何微调
30.5%的组织只是在实验阶段进行微调
仅有13.8%的组织
会在生产中大量使用微调后的模型
这主要是因为微调的门槛太高
需要大量高质量的标注数据、专业的训练基础设施
以及持续的维护成本
对于大多数企业来说
投入产出比并不高
因此，当前行业的主流做法是
基于基础模型
结合提示工程和检索增强生成等技术
来优化Agent的性能
这种方式不需要大规模的训练投入
却能够快速的适配具体场景
性价比更高
前面我们聊的都是企业层面的部署情况
那从个人视角来看
专业人士日常使用最多的AI Agent是什么呢？
报告中揭示了三个清晰的趋势
第一个趋势
Coding Agent正在主导日常的工作流
这是受访者提到最多的一类Agent
相关工具的提及次数都非常高
其中Claude Code被提到120多次
Cursor110多次
GitHub Copilot80多次
还有Amazon Q、Windsurf、Antigravity等工具
也被频繁的提到
这些Coding Agent已经深度融入了开发者的日常工作
从代码生成、调试排错
到测试用例的编写、大型代码库的导航
都能看到它们的身影
可以说
Coding Agent已经成为开发者的必备助手
显著提升了开发效率
第二个趋势，研究与深度研究Agent
是第二大高频使用场景
这类Agent主要基于ChatGPT、Claude、Gemini、Perplexity等工具
核心用途是探索新的领域、总结长文档、跨来源整合信息等等
值得注意的是
这类Agent常常和Coding Agent配合使用
比如开发者在开发一个新的功能时
会先用研究Agent查找相关的技术文档、了解行业的最佳实践
然后再用Coding Agent编写代码
形成从研究到开发的完整工作流
第三个趋势
基于LangChain和LangGraph的自定义Agent
越来越受欢迎
很多受访者提到
他们会根据自身工作需求
构建个性化的内部Agent
比如QA工程师会构建自动化的测试Agent
客服人员会构建内部知识库的查询Agent
这些自定义Agent虽然不像商业工具那样通用
但是能够精准匹配特定场景的需求
解决实际工作中的痛点
不过，也有一部分受访者表示
他们目前使用的Agent
还仅限于大语言模型聊天或编码辅助
尚未拓展到更广泛的场景
这说明
虽然AI Agent的使用已经很普遍
但是Agentic Everything
代理化一切的时代，还处于早期阶段
未来还有很大的拓展空间
最后
我们来了解一下这份报告的数据来源
这能帮助我们更好地理解数据的代表性
这份报告的洞察来自于2025年11月18日
到12月2日期间进行的一项公开调查
为期两周
共收集到了1340份有效回复
受访者的行业分布前面已经提到
主要集中在科技
金融服务、医疗等行业
企业规模分布方面
员工不足100人的小企业占比最高
为49%，100-500人的企业占18%，
500-2000人的企业占15%，
2000-10000人的企业占9%，
10000人以上的大企业占9%。
从样本结构来看
虽然小企业和科技行业的受访者占比较高
但是样本覆盖了不同规模、不同行业的专业人士
能够在一定程度上
反映出行业的整体趋势
不过需要注意的是
由于受访者多来自LangChain的生态用户
可能对代理工程的认知度和接受度
高于行业的平均水平
因此部分数据可能存在一定的偏差
尤其是对LangChain和LangGraph工具的采用度方面
希望大家理性看待
感谢收看本期视频，我们下期再见
