大家好，这里是最佳拍档，我是大飞
提到谷歌，大家应该都很熟悉了
毕竟它的产品很多人天天都在用
但是如果提到谷歌内部的技术人员
大家可能相对来说了解的并没有那么多
虽然我们都知道谷歌有很多相当厉害的技术大佬
但是到底到什么程度
以及他们日常工作的内容和思考的题目都是什么
我们就更不清楚了
所以今天
我们将跟着谷歌的首席科学家杰夫·迪恩（Jeff Dean）一起
回顾他最近在DeepMind的一期播客节目
深入了解他在谷歌的工作经历
并且在他的引导下
更多地了解谷歌Gemini大模型的前世今生
并且一同展望AI发展的未来
首先我们还是按照惯例
来简单介绍一下今天的主角
杰夫·迪恩
网上有这么一个开玩笑的说法是
杰夫在写自己的简历的时候
他只会列出他没有做过的事情
因为这样比较短
不过这其实也不完全是夸张
因为他在许多研究领域都是一座几乎不可逾越的高山
在上世纪九十年代末
是杰夫编写的代码
将谷歌从一家小型创业公司转变为今天的科技巨头；
他领导了TensorFlow的推出
使得机器学习的普及成为现实
特别是通过扩展计算能力和网络规模
推动了搜索引擎和神经网络的发展
除此之外
他还参与创立了Google Brain
也是最早推动Transformers的先驱之一
关于杰夫迪恩其实完全可以做一期视频来介绍
所以我们今天还是先来看看他在播客中的观点是怎样的
在访谈中
主持人首先把大家带回到了25年前
询问杰夫他刚进入谷歌时候的状态
杰夫回忆到
他加入谷歌的时候还是二十世纪九十年代末
那时的谷歌还不是一个成熟的组织
不过，尽管还是一个初创的小公司
谷歌流量的增长速度却是非常快的
因为他们所提供的高质量服务
所以每天、每周
流量都在创造新高
为了应对这些日益增长的需要
他们也不得不时刻优化
编写出更多更新的代码
以此来满足更多的用户需要
渐渐的
从公共搜索网页到电子邮件Gmail
谷歌的产品和业务开始扩展到了其他的领域
从一个只有搜索软件的单一产品
逐渐扩展出了如今一系列的生态
谷歌也从一个纯粹的搜索公司变成了大型的科技公司
不过在杰夫看来，谷歌所做的事情
其实一直都没有偏离过初衷
即便是到现在已经创立二十五年了
谷歌在做的事情
仍然是组织全球的信息
让它们可以被普遍访问并且有用
在这一点上
谷歌如今的Gemini大模型已经提供了很多帮助
让人们可以流畅的接收和解析文字图片、数据表格等等各种信息
并且可以方便地进行对外输出
所以杰夫他们也在尝试着
构建一个能够接收和生成所有模态的统一模型
只不过会在合适的时候使用对应的不同能力
不过目前看来
在这个方向上还有很长的路要走
虽然外人看上去
谷歌现在研究的大模型好像是一个新鲜事物
但是其实对于人工智能的研究
从上世纪五十年代就开始了
上世纪70年代，神经网络开始出现
直到90年代
研究人工智能的浪潮才正式兴起
换句话说，早在谷歌成立之前
人工智能的研究领域早已经是热闹非常了
在1990年
杰夫还是明尼苏达大学的一名本科生
当时他所修习的课程
就讲述了如何将一个问题
拆分成可以在不同计算机上完成的多个步骤
然后让这些计算机共同合作来完成
事到如今
这项技术已经成为了人工智能的底层技术
也早已不再需要多台电脑进行串联合作了
在学校里听了两场关于神经网络的讲座之后
杰夫对这个领域产生了浓厚的兴趣
于是他花了三个月的时间
做了一个比当时研究更大的系统
只不过这个系统还是太小了
起码需要数据处理能力提高一百万倍
才能够真正开始解决实际的问题
好在到了2010年
杰夫真的拥有了足够的计算能力
新设备的处理能力是当年那台计算机的一百万倍
于是
杰夫曾经的兴趣又再一次被激发
恰好
当时的斯坦福大学教授吴恩达（Andrew Ng）正在谷歌工作
与杰夫也是一拍即合
促成了谷歌神经网络工作的开始
2011年，他们组建了一个小团队
称为Google Brain Team
开始研究如何利用谷歌的计算资源
来训练一个非常大的神经网络
到了2012年初
他们开始着力于神经网络任务的分解
为的是解决如何在两千台计算机上训练出一个神经网络
在BrainTeam进行的如火如荼的同时
大西洋彼岸的英国
Deep Mind也开始崭露头角
经过相互的深入了解之后
杰夫发现他们两方
其实是在用不同的方式去接近同一个问题
那就是如何使用强化学习
从一个非常小的问题开始
并逐步建立神经网络
然后在非常大的模型规模上拥有丰富的理解
去年，谷歌在面对OpenAI的压力下
将Deep Mind、Google Brain和Google研究的其他部分
整合在了一起
重新组建成立了谷歌Deep Mind
随即推出了大模型Gemini
之所以命名为Gemini，双子星
不仅因为它代表了之前Deep Mind和Brain这两个团队“遗产”的结合
也意味着原本独立的两组成员
真正开始在一个雄心勃勃的多模态项目上一起工作
那什么是多模态呢？
杰夫做了一番解释
简单来说
模态（modal）就是事情经历发生和表现的方式
我们生活在一个由多种模态（Multimodal）信息所构成的世界里
包括视觉信息、听觉信息、文本信息、嗅觉信息等等
当要研究的问题或者数据集
包含多种模态信息的时候
就把它称之为多模态问题
之所以要研究多模态问题
是因为它是推动人工智能更好的了解和认知我们周围世界的关键
正如我们之前提到的
人类是可以流畅接收和解析文字、图片、数据表格等各种信息
并且进行对外输出的
当我们看到一头牛的时候
我们的大脑中就会想到“牛”这个词的读法
或者在脑海中听到牛叫声
这对于人类来说是很稀松平常的事情
但是对AI来说
却需要大量、广泛的训练
在理想状态下
如果模型看到一段牛在田间行走的视频
应该会立刻触发模型中与之相关的一大堆联系
基于神经网络激活来建立起来这些关联事物
这并不是说在这里有单词的部分
在那里有像素的部分
然后在两者之间进行有先后顺序的转换
而是需要非常深层次的训练和校准
这在开始设置网络参数的时候会更加困难
也会导致网络更加难以执行
不过
这些麻烦对于如今的技术发展而言
都是必须要去克服的难题
在多模态领域
Google公开的Transformer技术
已经让很多人改变了原本的想法
这项技术所带来的革命性和突破性
以及通过对训练方法的改进
让AI的训练效率和效果都更上了一层
杰夫解释道
在语言和其他许多领域的问题中
本质上其实都是序列问题
在Transformer架构出现之前
成功的模型指的就是所谓的循环网络模型
它们具有一些自己的内部状态
每次看到一个词的时候
它们都会进行一些处理
来更新自己的内部状态
然后它们继续处理下一个词
再这样循环一次
这样，每多处理一个词
就会让他们更能准确了解问题的含义
也就更能给出较好的答案
但是这也就意味着它很难运行得很快
一个12个词的句子
就需要处理十二次
每一步都要依赖于上一步的结果
对于顺序的严重依赖导致它的速度不可能提升太多
因此研究人员们提出了一个非常有趣的想法
与其在每个词上更新单一的状态
还不如一次性处理所有的词
并且记住处理每个词时得到的状态
虽然在我们人类看来
这似乎和原本的方法没有什么区别
都是要把一句话全部看完
但是对于像Gemini这样的大语言模型来说
这就意味着它可以同时处理所有的单词
单词之间都是并行计算
这就在性能方面提高了几十倍甚至一百倍
而人类因为一次只能处理少数的单词所以看不出什么差距
更高的效率和更准确的理解
也就使得大模型在实践中开始变得更加方便和实用
说到 Gemini
杰夫提到目前它已经在教育领域
得到了比较明显的成果
比如帮助人们进行理解和学习各种东西
相当于让每个用户都得到了一个非常专业的私人老师
而且它还可以帮助人们跨过语言的障碍
除了天生支持英语之外
Gemini还可以使用成百上千种语言
几乎世界上所有的人都可以无障碍地使用它
不过，杰夫也指出
这个设计看似是为了让更多的人可以接受到更好的教育
可是实际上
也会造成更显著的马太效应
如果有人可以用更多的时间去接受AI老师的指导
那么对于那些无法接触到这类AI工具的人
就会面临比现在更大的困境
当然，虽然说存在着这种风险
但是我们也不能因噎废食
拒接接受这一科技成果
杰夫说道
他们正在努力让这些技术可以更广泛、更普遍地被每个人使用
让人们在教育和医疗领域
可以负担得起、或者可以免费使用这些工具
如果能够做到这一点
杰夫觉得就算是真正利用了自己的科技优势
为社会做出了一些自己的贡献
不过话又说回来
无论是用于教育还是医疗
或者是任何其他领域
AI目前仍然存在一个比较致命的问题
那就是可靠性，或者说真实性
尽管目前AI在专业领域的实用性和准确性
已经提高了很多
但是仍然免不了会在一些地方“胡编乱造”，
凭空生成一些不符合事实的话
杰夫和他的团队们也正在努力解决这些问题
不仅试图提高Gemini的准确性
也在推动Gemini的使用优化
比如让Gemini拥有一个容量巨大的上下文窗口
现在Gemini的阅读量大约是两百万token
可以阅读1200页的文字
40篇以上的普通文章
或者两个小时的视频
差不多相当于一场完整的电影
不过
杰夫和团队并没有打算止步于此
仍然在想通过改进算法
来提高它的“阅读能力”。
但是在AI产品的发布态度上
杰夫依然是谨慎和克制的
他对观众们解释道
也许人们必须调整他们对于AI的期望
他认为这些模型就是工具
人们需要理解它们的能力
但是也要知道
在什么情况下可能不应该使用这些工具
就像我们如今使用网络一样
网络上的信息真真假假
很多事情并不是看到的那么简单
人们需要对真实信息进行一定的查阅和推理
才有可能发现谎言的漏洞
有些事情哪怕靠我们人力无法去查证
也不一定说明那是真的
同样的，AI的回答也是这样
或许在未来，AI会再一次教育人类
不要立刻相信任何一个AI所说的每一句话
你需要对它进行一些起码的审查
当然，随着模型的改进
回答的真实性肯定会逐步上升
但是用户最好还是要抱着怀疑和审慎的态度
因为很有可能一些回答是不符合事实的
就目前来看
包括Gemini在内的这些大语言模型
都只能算是增强人类的一种方式
那它们是否可以再更进一步
帮助我们来理解整个世界呢？
杰夫认为，这仍然有些困难
因为那是一种相当复杂的集成
涉及到模型自己的推理能力、它向你解释时所需要的知识
以及如何理解并分解执行任务等等一系列的能力
不过，杰夫也相信未来指日可待
因为在过去的五年十年里
模型已经有了长足的进步
而在未来的五到十年里
实现真正可以帮助人们学习知识
理解世界的“大模型老师”，
或许也并不只是幻想
好了
以上就是今天关于杰夫迪恩分享的全部内容了
那大家对AI大模型的未来是如何看的呢？
是觉得会像杰夫所言
AI能帮人们更好的理解世界
还是觉得幻觉问题无法解决
对AI要始终保持怀疑态度呢？
欢迎大家在评论区留言
感谢大家的观看
我们下期再见
