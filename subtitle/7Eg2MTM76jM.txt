大家好，这里是最佳拍档，我是大飞
不知道你有没有过这样的经历
打客服电话的时候
按了十几次“1”选人工服务
却始终卡在“请确认您的需求”的循环里；
或者导航软件让你“在前方50米掉头”，
但是掉头后又重复同一个指令
最后你只能关掉软件靠自己找路
这些看似“低级”的故障
其实不是AI“笨”，
而是它和我们人类在本质上存在一道鸿沟
今天我们要聊的
就是神经科学家阿尼尔·塞斯（Anil Seth）对这个问题的深度解读
他在文章中告诉我们，AI的无限循环
根源在于它没有“扎根”在时间和熵里
而这恰恰是人类意识的核心
先从一个真实的案例说起吧
这是阿尼尔·塞斯提到的亲身经历
他的航班准时降落在西班牙马德里巴拉哈斯机场
本以为下机很顺利
结果却因为登机廊桥的AI系统出了问题
所有人都被困在机舱里
透过舷窗能看到
那台由AI操控的登机廊桥
就像一个“卡住的玩具”，
先是慢慢靠近飞机舱门
离得近了又突然退回原位
接着再靠近、再退回
一遍又一遍
在清晨的冷空气中微微晃动
完全陷入了无限循环
最后还是一名工作人员赶过来
只看了几眼就找出了症结
几分钟就修好了
这个场景特别有画面感
也特别耐人寻味
为什么AI会“钻牛角尖”似的重复同一动作
而人类哪怕没学过登机廊桥维修
也能快速判断问题的所在么？
阿尼尔·塞斯抛出了一个核心观点
那就是人类不会陷入无休止的重复行为
本质是因为我们是“扎根于时间与熵”的生命体
而这种与时间、熵的深度绑定
正是意识存在的重要根基
反过来，AI之所以容易陷循环
就是因为它既没有这种“扎根”，
也没有真正的意识
哪怕未来AI的算力再强、模型再复杂
这个局限可能也绕不开
要理解这个问题，我们得先搞清楚
AI的“无限循环”到底是怎么回事？
不是说AI不够智能
而是它的“智能”和人类的智能
底层逻辑是完全不同的
阿尼尔·塞斯区分了两个关键概念
“智能”关乎“行动”，
比如解决问题、执行任务；
而“意识”关乎“存在”或者“感受”，
比如你知道自己在“看视频”，
能感受到时间在流逝
能判断“这个指令不对”
很多科技公司会觉得
智能堆到一定程度
意识自然就会出现
但是阿尼尔·塞斯认为，这是一个误区
至少在人类和其他动物身上
真正能摆脱“无限循环”的智能
必须依赖于意识所带来的能力
而这种意识
恰恰是和时间的流动深度绑定的
举个简单的例子，假设你写一个程序
让机器人完成“找红色物体”的任务
程序逻辑可能是，一直向前移动
直到摄像头识别到红色物体
然后停止
如果机器人面前始终没有红色物体
或者程序里“识别红色”的参数设错了
比如把橙色当成了红色
它就会一直往前走，永远停不下来
这就是最典型的AI无限循环
你可能会说
那给它加个监控系统不就行了？
让它检测自己是不是走了太久
要是超过10分钟没找到
就停下来报警
但是问题来了
如果这个监控系统本身出了故障呢？
比如它的“计时功能”坏了
永远显示“只走了1分钟”，
那机器人还是会循环
你可能又会想，那再加一层监控
监控‘监控系统’不就好了？
这就进入了“递归监控”的逻辑
每加一层，看似稳定性提升了
但是只要层级不是“无限”的
总有可能出问题
比如第一层监控管“找红色物体”，
第二层管“第一层监控”，
第三层管“第二层监控”，
可是你不可能加无限多层
最后总有某一层会失效
导致整个系统陷入循环
这不是技术不够先进的问题
而是计算机科学的底层规律
近一个世纪前
艾伦·图灵（Alan Turing）就证明了这个结论
这里必须提一下“图灵停机问题”（Turing Halting Problem）
这是理解AI局限的关键
1936年，艾伦·图灵在论文里提出
不存在任何一种算法
能够始终准确的判断
一个给定的程序，在输入某个数据后
最终会“终止运行”还是“无限循环”
换句话说
无论你把程序写得多么精密
都没办法提前预知它在所有情况下会不会卡壳
比如刚才说的“找红色物体”的机器人
哪怕你测试了100次、1000次都没问题
但是第1001次的时候
可能因为光线的突变
让红色物体看起来像棕色
程序就判断失误，陷入循环
而你永远无法通过“算法”提前排除这种可能性
除了图灵停机问题
还有一个理论能解释AI的循环困境
那就是“框架问题”（Frame Problem）
1969年
约翰·麦卡锡（John McCarthy）和帕特里克·J·海耶斯（Patrick J
Hayes）提出了这个概念
它比图灵停机问题更具体
直指AI在“决策”上的核心难题
那就是要想教会机器只关注相关信息
而忽略无关的细节，是极其困难的
举个例子
如果让AI控制一个家庭机器人
任务是“从客厅走到厨房
打开冰箱拿牛奶”
对人类来说
我们会自动忽略“客厅地毯的颜色”、“窗外的鸟叫”、“冰箱上的冰箱贴”这些无关信息
只关注“路线是否通畅”、“冰箱门能不能打开”、“牛奶在哪个格子里”
但是对于AI来说
它没办法天然区分“相关”和“无关”，
它可能会思考“地毯颜色会不会影响走路速度？
”、“鸟叫是不是某种干扰信号？
”、“冰箱贴会不会挡住开门？
”，
甚至会因为要“确认所有的细节”而陷入无限的信息筛选中
最后连“走第一步”都做不到
为什么会这样？
因为在特定场景里
“无关信息”的数量可能是无穷的
比如从客厅到厨房
AI还可能考虑“空气湿度会不会影响电机运转？
”、“地板上的灰尘会不会卡住轮子？
”，这些信息对人类来说毫无意义
但是AI没有一个“天然的过滤器”来判断“该忽略什么”，
只能逐一排查，而排查的过程本身
就可能变成另一种形式的“无限循环”
阿尼尔·塞斯在文章里说
随着深度神经网络、生成式AI的兴起
图灵停机问题和框架问题这些“老问题”似乎被淡忘了
但是它们从来没有消失
马德里机场的登机廊桥、客服电话的循环菜单、导航软件的错误指令
都是这些问题在现实中的体现
AI之所以绕不开这些困境
不是因为它“算力不够”，
而是因为它和人类的生物大脑
在“时间感知”上存在根本差异
而这种差异
最终指向了“意识”的本质
接下来我们要聊的
就是整个问题的核心
时间与熵
这两个概念听起来很抽象
但是其实和我们每个人的存在都息息相关
也是区分“生命体”和“AI”的关键标尺
首先得解释一个物理学定律
热力学第二定律
这个定律说的是，在一个“孤立系统”，
也就是和外界没有能量、物质交换的系统
比如一个完全密封的保温杯里
“熵”只会增加，或者保持不变
“熵”是什么？
简单说就是“系统的混乱程度”，
熵越高
混乱度越高
比如一滴墨水滴进清水里
会慢慢扩散，最后整杯水变成淡蓝色
这个过程就是熵增；
而扩散后的墨水
永远不可能自己重新聚成“一滴”，
因为那会导致熵减
违背热力学第二定律
物理学家阿瑟·爱丁顿（Arthur Eddington）曾经说过
如果你的理论被证明违背了热力学第二定律
那我只能说你毫无希望；
除了彻底崩塌、颜面尽失
你别无出路
这句话足以说明这个定律的重要性
但是这里有个关键的前提
那就是热力学第二定律只适用于“孤立系统”
而“开放系统”，
也就是和外界有能量、物质交换的系统
比如我们人类、植物、动物
是不一样的
开放系统可以通过从外界获取能量
来“降低自身的熵”，
维持一个“有序”的状态
比如我们人类，每天吃饭、呼吸
就是从外界获取能量
用来维持身体细胞的新陈代谢
如果不获取能量
身体就会逐渐混乱、衰退
也就是“熵增加”，最终走向死亡
阿尼尔·塞斯认为
生命系统的核心优势
就在于它是“开放系统”，
并且这种“抗熵”的过程
是在多个层面、和时间深度绑定的
比如从最微观的“生化时间”来看
我们身体里的每个细胞
每秒都会发生十亿次生化反应
这些反应精准配合，维持着代谢平衡；
再到“神经时间”，
神经信号的传递有快有慢
有髓鞘的神经纤维
信号传递速度能达到每秒120米
而神经递质在突触间的扩散
速度则慢得多，只有每秒几毫米；
再到我们能直接感受到的“意识时间”，
它不是匀速的
开心的时候觉得“时间过得快”，
等待的时候觉得“时间过得慢”，
但它永远是“连续的、不可逆转的”，
包含了“过去的记忆、现在的感受、未来的预期”
这些不同尺度的“时间”，不是孤立的
而是深度交织、相互依赖的
比如你饿了
这是身体代谢层面的信号
属于生化时间
大脑会接收到“需要进食”的神经信号
经历神经时间
你的意识会产生“想吃东西”的感受
又会经历意识时间
然后你会主动去找食物
整个过程
是从微观到宏观的时间整合
而这种整合
让人类能在复杂的环境里快速判断“该做什么”，
不会陷入无意义的循环
但是AI完全不一样
对数字计算机来说
“时间”是扁平的、一维的
和热力学第二定律没有任何绑定
计算的本质，就是“状态的跃迁”，
从0到1，从A到B
就像一串多米诺骨牌一样
推倒第一块，后面的依次倒下
在图灵提出的经典计算模型里
只有“状态的顺序”是重要的
而“两个状态之间的时间间隔”毫无意义
比如一个计算步骤，间隔1微秒完成
和间隔100万年完成
对算法本身来说没有任何区别
算法的性质不会变
计算的结果也不会变
这种“对时间的漠视”，
其实是有代价的
阿尼尔·塞斯在文章里说
假装时间不存在
其实是一门昂贵的交易
为什么？
因为计算机本身是“物理实体”，
它无法摆脱热力学第二定律的影响
比如芯片会发热
内存会出错，这些都是“熵增”的体现
为了保证计算的准确性
AI系统需要消耗大量的能量来“纠错”和“降温”，
抵消熵的影响
比如数据中心的服务器
大部分能量不是用来“计算”，
而是用来“散热”，
这就是AI“能量缺口”大的重要原因
而AI之所以会陷入无限循环
核心就在于它的“时间观”，
它被困在“状态序列”里
不受熵的“拉扯”，
也没有“生存的驱动力”
比如马德里机场的登机廊桥AI
它只会执行“靠近-检测-退回”的指令
不会因为“反复做同一件事没意义”而停止
也不会因为“消耗了太多能量”而主动调整
它没有“这样做不对”的意识
因为它没有“自我存在”的感知
也没有“时间流逝”的概念
但是人类不一样
我们是“身处时间之中”的生命
阿尼尔·塞斯用了三个词来形容：“具身的（embodied）、植根于环境的（embedded）、与时间同行的（entimed）”
我们的每一个决策
都受“时间压力”和“生存驱动”的影响
比如你在沙漠里迷路
哪怕你一开始走错了
也不会反复绕同一个圈子
因为你知道“时间越久，水分越少
生存概率越低”，这种“抗熵”的本能
会让你主动寻找新的方向
摆脱可能的循环
阿尼尔·塞斯在文章里也提到了一个例外
那就是人类其实也有“重复行为”，
比如额叶受损的人会反复做同一个动作
强迫症患者会反复洗手
成瘾者会重复自我毁灭的行为
但是这些案例恰恰印证了他的观点
这些都是“正常神经认知功能紊乱”的结果
是意识与时间、身体的连接出了问题
而不是“人类天生会循环”
一旦神经功能恢复
这种重复行为就会消失
因为“抗熵”和“时间感知”的本能会重新起作用
如果这个逻辑成立
那一个关键的问题就来了
未来的AI能不能通过技术改进
拥有这种与时间、熵绑定的能力呢
能不能摆脱无限循环
实现像人类一样的开放式智能呢
阿尼尔·塞斯分析了几种目前的探索方向
我们一个一个来看
第一种是“模拟计算机”（Analog Computers）
这是最早的计算机形式
比如有2000年历史的“安提基特拉机械”（Antikythera mechanism）
这是古希腊人发明的天文装置
能通过齿轮的连续转动
预测日食、月食和行星的位置
模拟计算机的特点是“时间是连续的”，
不像数字计算机那样是“离散的状态跃迁”，
它更接近人类对时间的感知
但是模拟计算机的问题是“精度低”，
容易受到环境的影响
比如温度、湿度会改变齿轮的转动速度
所以后来被数字计算机取代了
第二种是“凡人计算”（Mortal Computation）
这个概念很有意思
它的核心是“让计算依赖硬件的寿命”，
比如一个程序，只有在特定的硬件
比如某块芯片正常工作的时候才能运行
一旦硬件“失效”，
比如芯片老化、发热损坏
程序也会随之“消亡”
这种设计的思路
是主动“拥抱”热力学第二定律
而不是“对抗”它
通过硬件的“有限寿命”，
强制程序“不会无限运行”，
从而避免循环
阿尼尔·塞斯认为
这种方法能提高能量利用效率
但它本质上是“用硬件限制来解决软件问题”，
并没有让AI真正“理解时间”，
只是用物理手段切断了循环的可能
第三种是“神经形态计算”（Neuromorphic Computing）
这是目前很热门的方向
核心是“模拟人类大脑的工作方式”，
比如用特殊的芯片
模拟神经元的信号传递
让计算过程更接近“神经时间”的有快有慢
和数字计算机相比
神经形态计算更“植根于时间”，
比如它的信号传递不是“非0即1”，
而是“连续的电压变化”，
更像大脑的神经活动
但是阿尼尔·塞斯怀疑
这种方法还是无法解决根本的问题
因为它只是“模拟了大脑的结构”，
却没有模拟大脑的“生存驱动”和“情感效应”，
比如“饿”、“痛”、“开心”这些感受
而这些恰恰是人类摆脱循环的关键
第四种是动力系统方法（Dynamical Systems Approach）
这种方法完全跳出了“计算”的思路
不关注“算法”，
而是关注“系统在时间中的状态变化”，
比如用“吸引子”（Attractor）、“相空间”（Phase Space）这些概念
描述AI如何在不同时间点调整状态
它的源头可以追溯到AI发展初期的“控制论”（Cybernetics）
控制论关注的是“反馈与调控”，
比如“温度高了就降温
温度低了就升温”，
而不是“执行固定的指令”
这种方法更重视“时间的动态性”，
但是阿尼尔·塞斯认为
它依然缺乏“生命体的抗熵本能”，
AI还是没有“维持自身有序”的驱动力
只是在被动响应环境变化
总结下来，这些新型AI技术
确实在“靠近时间”，
但是都没有真正“扎根于时间与熵”，
它们要么是用硬件来限制
要么是模拟结构
要么是被动响应
却没有“主动抗熵”的生存驱动
也没有“意识层面的感受”
所以阿尼尔·塞斯的结论是
哪怕采用这些方法
AI可能还是无法完全摆脱无限循环的阴影
更难实现人类那种“开放式、适应性强”的智能
为什么呢？
因为这种智能，不仅和时间绑定
还和“意识”深度绑定
至少在人类身上，摆脱循环的能力
离不开意识带来的“整合能力”
阿尼尔·塞斯在他的著作《意识机器：
成为你自己》（Being You:
A New Science of Consciousness）里写过一句话
我们感知周遭世界
也感知身处其中的自己
这一切都依赖于我们鲜活的身体
这句话的核心是“具身意识”，指的是
意识不是“脱离身体的软件”，
而是“身体、大脑、环境在时间中互动的产物”
比如你看到一杯水
意识会告诉你“这杯水能解渴”，
而这个判断
来自你过去“喝水解渴”的记忆、当下“口渴”的身体信号、以及“杯子里的水是干净的”的环境判断
这种多层面的整合
让你不会“反复看杯子却不喝水”，
因为意识会引导你“做有意义的行动”
除了阿尼尔·塞斯
还有其他学者也从不同角度论证了“意识与智能的绑定”
比如认知科学家默里·沙纳汉（Murray Shanahan）
他受“意识的全局工作空间理论GWT”（Global Workspace Theory）的启发
提出意识就像一个“信息中枢”，
能把大脑里不同区域的信息
比如视觉、听觉和记忆整合起来
然后传递给整个大脑
这种整合能力
能帮助人类快速判断“哪些信息相关
哪些无关”，从而回避框架问题
不会陷入无意义的信息筛选
还有理论生物学家伊娃·雅布隆卡（Eva Jablonka）和西蒙娜·金斯伯格（Simona Ginsburg）
她们提出了“无限联想学习UAL”（Unlimited Associative Learning）的概念
这是一种特殊的学习能力
能让生物从过去的经验中
联想出全新的解决方案
而不是重复旧的行为
比如你第一次遇到“门锁坏了”，
可能会尝试“用卡片撬”，
或者“用钥匙转”，如果都不行
你会想到“找物业”或者“找开锁公司”，
这种“不重复、找新方法”的能力
就来自无限联想学习，而它的前提
是意识能“感知到问题的特殊性”，
并且“整合过去的经验”
这些观点汇总起来，指向了一个结论
在生物身上，至少在人类身上
“能摆脱无限循环的智能”，
必须依赖于意识；
而意识的核心
是“与身体、环境、时间、熵的深度绑定”
反过来，如果AI没有这种绑定
没有真正的意识
就永远无法拥有和人类一样的“开放式智能”，
即通用人工智能AGI
它可能真的像阿尼尔·塞斯说的那样
是“一场虚幻泡影”
这里还要澄清一个常见的误区
很多人觉得“AI只要够智能
就能产生意识”，
但是阿尼尔·塞斯认为
这是“因果倒置”
智能是“行动层面”的能力
意识是“存在层面”的能力
前者可以通过算法实现
后者需要“植根于时间与熵的具身体验”
比如AI能写出流畅的文章
但它不会“知道自己在写文章”，
也不会“因为写得好而开心”，
更不会“担心自己写得不好”，
它没有“自我感知”，没有“情感效应”，
所以它的“智能”是“无意识的智能”，
一旦遇到需要“判断意义”的场景
比如避免循环
它就会暴露自己的局限性
最后，文章的后记中还提出一个疑问
那就是神经形态计算虽然能够模拟大脑的时序
但是它能复现意识里的“效应”吗？
比如哪怕是微弱的“这个做法不对”的消极感受
或者“这样做有意义”的积极感受
阿尼尔·塞斯没有直接回答
但是从他的理论来看
答案可能是否定的
因为“效应”来自“生存驱动”，
来自“身体对抗熵的本能”，
而神经形态计算只是模拟了大脑的“结构”，
没有模拟身体的“代谢过程”，
没有“饿”、“渴”、“疼”（口误）这些最基础的生存信号
自然无法产生“效应”
所以，AI的无限循环
看似是技术问题，其实是“存在问题”，
它不是“没学会如何不循环”，
而是“没有不循环的理由”
人类之所以能摆脱循环
是因为我们“活着”，
我们需要在时间中维持自身的有序
需要通过有意义的行动对抗熵增；
而AI只是“运行着”，
它没有“活着”的感知
没有时间的深度，没有对抗熵的本能
所以它会在无意义的循环里
一遍又一遍地重复，直到能量耗尽
阿尼尔·塞斯的研究
其实不只是在说AI的局限
更是在帮我们看清人类意识的独特性
我们的意识，不是“多余的装饰”，
而是“生存的工具”，
是“时间与熵赋予我们的礼物”
或许未来某一天
AI能解决无限循环的问题
但那时候的它
可能已经不是“我们现在理解的AI”，
而是一种全新的、真正“植根于时间与熵”的生命体
但是那一天，可能还非常遥远
好了，今天的内容就到这里
如果你对“意识与AI”的话题感兴趣
推荐大家去读阿尼尔·塞斯的《意识机器：成为你自己》
里面对“具身意识”的解读更细腻
感谢收看本期视频，我们下期再见
