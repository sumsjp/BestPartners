大家好，这里是最佳拍档，我是大飞
今天要和大家聊的
堪称AI行业与投资圈的“双重反转剧”，
一个23岁的德国年轻人
曾经是OpenAI核心人物伊利亚·苏茨克维尔（Ilya Sutskever）的信徒
因为坚持提醒公司关注AGI安全隐患被开除
却在离开OpenAI后
用一份165页的论文当“投资指南”，
在完全没有金融背景的情况下
6个月内做出了47%的投资回报
还筹集到15亿美元的基金
战绩远超一众华尔街的资深投资者
这个名叫利奥波德·阿申布伦纳（Leopold Aschenbrenner）的年轻人
到底凭什么能做到这一切？
他那篇引发热议的论文里
又藏着怎样的关于AI的未来预言呢？
今天我们就来拆解一下这个故事
首先
我们得从利奥波德进入OpenAI的经历说起
因为他后来的所有选择
都和这段经历里的“理想与冲突”紧密相关
时间回到2023年
当时刚满21岁的利奥波德
怀揣着“守护AGI安全”的理想
踏入了旧金山OpenAI总部的大门
加入了由伊利亚·苏茨克维尔（Ilya Sutskever）和扬·莱克（Jan Leike）共同领导的“超级对齐（Superalignment）团队”。
这个团队的核心目标非常明确
就是在四年内解决“超级智能对齐”的问题
简单说就是确保未来比人类更聪明的AI
能始终遵循人类的利益和价值观
不出现失控风险
对利奥波德来说，这不仅是一份工作
更是实现他“AGI守护者”理想的途径
所以他很快就全身心投入到工作中
也因为对AI安全的深刻理解和对伊利亚理念的认同
成为了伊利亚身边的核心成员之一
但是这份理想没过多久
就遇到了现实的冲击
随着OpenAI在山姆·奥特曼（Sam Altman）的主导下
产品迭代节奏越来越快
从GPT-3.5到GPT-4
再到各类商业化应用的推出
公司的重心逐渐向“快速落地”倾斜
而利奥波德关注的“安全防护”却被慢慢挤压
最让他担忧的是
他发现公司的安全体系存在明显的薄弱环节
甚至发生过一次黑客入侵事件
但是这件事没有被公开披露
这让他更加担心OpenAI的关键算法
可能存在被竞争对手窃取的风险
作为一个把“AGI安全”刻在骨子里的人
利奥波德无法坐视不理
他很快写下了一份措辞非常严厉的“安全备忘录”，
在里面直言不讳地指出
OpenAI的安全防护“极度不足”，
甚至用“形同虚设”来形容部分环节
更关键的是
他没有按照常规流程先交给上级
而是直接绕过层级
把这份备忘录递交给了OpenAI董事会
这个举动直接引发了公司高层和董事会之间的紧张关系
也让利奥波德成为了一名“特殊分子”。
雪上加霜的是
在后来山姆·奥特曼被临时罢免又复职的风波中
大部分员工都签署了支持奥特曼复职的请愿书
但是利奥波德没有签，这在公司看来
这就是“不够忠诚”的表现
HR很快就找他进行了警告
如果说这只是“职场站队”的问题
或许事情还能有转圜的余地
但是接下来的一件事
彻底让利奥波德和OpenAI走向了决裂
2024年初
利奥波德整理了一份关于AGI安全措施的“头脑风暴文档”，
里面收录的都是他对行业公开信息的分析和思考
没有任何OpenAI的内部机密
他还特地邀请了三位外部学者帮忙提反馈意见
可就是这份文档
被公司认定为“泄露内部资料”，
并以此为理由展开调查
调查过程中还翻出了他之前“越级向董事会提交备忘录”的旧账
最终在2024年4月
OpenAI以“泄密且不配合调查”为由
正式解雇了利奥波德
有意思的是
就在利奥波德被解雇后不久
他曾经的直属领导、超级对齐团队的负责人伊利亚·苏茨克维尔（Ilya Sutskever）和扬·莱克（Jan Leike）
也相继离开了OpenAI
虽然没有直接证据表明
两人的离职和利奥波德有关
但是熟悉OpenAI内部运作的人都知道
这背后大概率和“安全理念与商业化节奏的冲突”脱不开关系
而利奥波德的遭遇
或许只是这个冲突的一个“缩影”。
被解雇后的利奥波德没有沉寂
反而把自己所有的思考和观察
写成了一份长达165页的论文
标题叫做《态势感知：
未来十年》（Situational Awareness:
The Decade Ahead）
这份论文发表于2024年6月
也就是他被解雇后的两个月
在论文的开篇部分
利奥波德特地注明了“本论文献给伊利亚·苏茨克维尔（Ilya Sutskever）”，
这份敬意
也让外界更清楚地看到他作为“伊利亚信徒”的立场
而这份论文里的核心观点
不仅奠定了他“AI趋势预言家”的地位
更成为了他后来进入投资圈的“核心武器”。
那么这份165页的论文里
到底说了些什么呢？
最核心的观点
就是利奥波德预测“2027年前后
人类或将迎来AGI
到2030年则会迈向超级智能”，
而且他还在论文里强烈呼吁
全球需要联合起来建立“AI曼哈顿计划”，
以此应对AGI可能带来的安全风险
这个预测
是利奥波德用了大量的数据和逻辑推导出来的
我们大概可以从三个维度来理解他的论证
分别是“AI模型能力的进化速度”、“算力投入的爆发式增长”，
以及“算法效率的突破与解开收益”。
先看第一个维度
AI模型能力的进化速度
利奥波德在论文里做了一个非常直观的类比
如果把AI模型的能力和人类的智能水平对应起来
他指出，2019年推出的GPT-2
能力大概相当于“学龄前儿童”，
当时的GPT-2只能写出一个还不太连贯的段落
在文本总结任务中
生成的结果甚至只比“随机从原文里选3个句子”，
稍微好一点，更别说复杂任务了
就连从1数到5这样的基础操作
都可能出现逻辑断裂
而到了2023年GPT-4推出的时候
模型能力已经达到了“聪明的高中生”的水平
在理科方面
GPT-4能深入思考并且推理复杂的数学问题
还能胜任从编写复杂代码到迭代调试的高级编程任务；
在文科方面
它能在几万字的长篇文本中
保持逻辑和内容的一致性
甚至能和人类深入探讨哲学、历史等复杂话题
更关键的是
在包括美国大学预修课程AP和美国高考SAT在内的几乎所有标准化测试中
GPT-4的得分已经超越了绝大多数高中生
从2019年到2023年，短短4年时间
GPT系列模型就从“学龄前”跃升到了“高中生”水平
而人类完成这个智力发展阶段需要至少12年
利奥波德据此计算
AI模型的能力进化速度
是人类自然智力发展速度的3倍还多
这个速度如果持续下去，到2027年
也就是从GPT-4推出后再经过4年
模型能力达到“AGI水平”，
似乎就有了逻辑支撑
再看第二个维度
算力投入的爆发式增长
利奥波德在论文里对比了“摩尔定律时代”和“AI时代”的算力增长差异
在摩尔定律的鼎盛期
算力每10年才增长1到1.5个数量级；
但是到了AI时代
AI硬件的算力年增长率
已经达到0.6个数量级
也就是每年增长大约4倍
速度是过去的5倍还多
用GPT系列模型举例可能会更加直观一些
从GPT-2到GPT-3
模型的训练设备完成了从“小型实验设备”到“大型数据中心”的过渡
一年内算力就增长了2个数量级
即100倍；
而GPT-4的训练算力在这个基础上
又实现了大幅提升
更重要的是
从OpenAI持续囤积GPU芯片的动作来看
这种算力增长速度并不是短期爆发
而是会逐渐演变为一种长期趋势
利奥波德在论文里做了一个更激进的预测
那就是在这个十年结束之前
也就是2030年前
全球将有数万亿美元投入到GPU、数据中心和电力建设中
仅美国就需要将电力生产提高数十个百分点
才能支撑AI的发展需求
他还结合AI企业的收入趋势做了推导
随着AI产品收入的快速增长
像谷歌、微软这样的科技巨头
在2026年左右的AI相关年收入
可能达到1000亿美元；
而这种收入增长会进一步刺激资本投入
到2027年
全球每年的AI投资总额可能会超过1万亿美元
如果把时间线再拉远一点
到了2028年
单个AI模型的训练集群成本
可能会达到千亿美元级别
比国际空间站大约1500亿美元的造价还要高；
而到本世纪末
一个超大型训练集群的成本
甚至会达到1万亿美元，到那时
AI所需要的电力占美国总发电量的比例
将从现在的不到5%上升到20%。
这些预测虽然听起来夸张
但是从近几年AI算力投入的增长趋势来看
并非完全没有依据
第三个维度
也是利奥波德认为最容易被低估的一点
算法效率的突破
以及由此带来的“解开收益”（Unhobbling Gains）
首先说算法效率
利奥波德在论文里用了两个具体案例
来证明算法进步的速度
第一个案例是MATH基准测试
这是一个衡量AI数学推理能力的标准测试
从早期的Minerva模型到后来的Gemini 1.5 Flash模型
在准确率达到50%的前提下
推理效率提高了将近3个数量级
也就是1000倍
虽然推理效率不等于训练效率
但是这个趋势足以说明
算法层面的大幅进步是切实可行的
而且正在快速发生
第二个案例是ImageNet图像识别任务
回顾2012年到2021年期间的公开算法研究
研究人员发现
要训练出性能相同的模型
计算成本以近乎一致的速度下降
每年减少大约0.5个数量级
即每年成本降低大约2/3
而且这种下降趋势适用于所有主流的模型架构
虽然大模型的研发团队很少会公开算法效率数据
但是根据EpochAI的估算
2012年到2023年期间
大模型的算法效率每年也能带来大约0.5个数量级的提升
也就是说
8年时间里算法效率总共提升了1万倍
这个数据足以打破“AI进步全靠堆算力”的刻板印象
而“解开收益”则是利奥波德提出的一个更有意思的概念
简单来说就是在某些情况下
AI模型的原始能力其实被‘束缚’了
通过简单的算法改进或者技术调整
就能解锁这些潜在能力
带来远超常规算法优化的收益
虽然它本质上也是一种算法改进
但是和常规的优化不同的是
“解开收益”能跳出现有的训练范式
直接带来模型能力和实用价值的阶梯式跃升
利奥波德在论文里举了四个典型的例子
第一个是RLHF
基于人类反馈的强化学习
通过让人类对AI生成的结果进行打分和反馈
再用这些反馈训练模型
能让一个小模型达到“百倍于其原始模型”的效果
比如一个100亿参数的模型经过RLHF优化后
在某些任务上的表现能媲美1万亿参数的未经过优化的模型
第二个是CoT（思维链
Chain of Thought）
让AI在解决问题的时候“一步步说出思考过程”，
而不是直接给出答案
这种简单的提示方式
能为推理任务带来超过10倍的“有效算力提升”，
相当于用同样的算力
模型能解决更复杂的问题
第三个是增加上下文长度
通过把AI能处理的文本长度
从早期的2048个token提升到100万个token以上
直接解锁了大量的全新应用
比如一次性处理整本图书、分析超长的代码库、总结几十小时的会议录音文字稿等等
这种能力的扩展不是“量变”，
而是一种“质变”。
第四个是后训练（Post-training）
在模型正式发布后
通过持续输入新的数据、优化训练策略进行二次训练
这也是GPT-4发布后性能不断提升的主要原因
比如GPT-4在发布半年后的数学推理能力
比刚发布的时候提升了将近30%，
这背后就是后训练的作用
根据EpochAI的研究
这类“解开收益”技术普遍能为AI模型带来5到30倍的“等效算力收益”；
而另一家研究机构METR的测试也显示
在Agent任务中
GPT-4基础模型的性能只有5%，
经过后训练后能提升到20%，
再结合工具使用和框架优化
性能能直接跃升到接近40%，
这种提升幅度
是单纯增加算力所无法实现的
当算力增长
算法效率提升解开收益
这三个因素叠加在一起的时候
利奥波德得出了他最核心的结论
那就是到2027年
AI将能够自动化所有的认知工作
或者说所有可以远程进行的工作
他在论文里做了一个更具体的推导
从GPT-2到GPT-4
模型大致经历了4.5到6个数量级的有效计算扩展
而从基础模型到能实际使用的聊天机器人
又相当于获得了大约2个数量级的“解开收益”。
按照这个速度，未来4年
也就是到2027年
计算效率的提升会让模型迭代速度大幅加快
假设GPT-4的训练花了3个月
那么到2027年
领先的AI实验室将能在“一分钟内”训练出一个GPT-4级别的模型；
其次
“解开收益”会让AI不再是单纯的“聊天工具”，
而是进化成“能够独立完成复杂任务的Agent”，
它能够自己使用电脑、管理长期记忆、针对一个问题进行几个小时甚至几天的持续思考
甚至能像人类员工一样
快速适应新公司的工作流程和业务逻辑
不过利奥波德也在论文里强调
这个预测存在“很大的误差范围”。
如果“解开收益”逐渐停滞
或者算法进步无法解决“数据耗尽”的问题
那么AGI的到来时间会推迟
但是反过来
如果“解开收益”能释放出模型更大的潜能
或者出现新的技术突破
那么AGI可能会比2027年更早到来
这份充满前瞻性的论文
不仅让利奥波德在AI安全领域获得了更多关注
更意外地成为了他“跨界”进入投资圈的敲门砖
2024年下半年
利奥波德成立了自己的对冲基金
核心投资逻辑就是他在论文里提出的“态势感知”，
简单来说就是“通过精准判断AI行业的技术趋势和市场需求
提前布局相关企业”。
虽然他之前没有任何的金融行业经历
但是凭借着在AI领域的KOL地位
以及论文里详实的数据支撑
他成功说服了一大批顶级投资者
根据公开信息
他的基金支持者包括支付公司Stripe的创始人帕特里克·科里森（Patrick Collison）和约翰·科里森（John Collison）兄弟
这两位本身就是科技圈的知名创业者
对AI趋势有着深刻理解；
还有近期被Meta（原Facebook）招募负责AI业务的丹尼尔·格罗斯（Daniel Gross）和纳特·弗里德曼（Nat Friedman）
前者是著名的AI投资人
后者曾担任GitHub CEO
同样深耕科技领域
这些支持者的背书
不仅给基金带来了资金
更带来了行业资源和可信度
而基金的业绩也没有让人失望
在2025年上半年，扣除各项费用后
利奥波德的基金获得了47%的收益
这个成绩是什么概念呢？
同期全球顶级对冲基金的平均收益大约为12%，
即使是专注于科技领域的对冲基金
平均收益也只有25%左右
利奥波德的47%几乎是行业平均水平的两倍
更关键的是
他的基金规模在短短6个月内就从初始的几千万美元增长到15亿美元
成为了“有史以来增长最快的对冲基金之一”。
利奥波德的投资能力
在他对英伟达的判断上体现得淋漓尽致
早在2024年的一次采访中
他就预测“英伟达的数据中心收入
将从每季度几十亿美元增长到每季度250亿美元”。
当时很多金融分析师还认为这个预测过于激进
但现实却比他的预测的更为夸张
英伟达2025财年第二季度的数据中心收入
就达到了262亿美元
超过了他预测的250亿；
而到了2026财年第二季度
这个数字更是直逼411亿美元
几乎是他当初预测的1.6倍
这种对行业趋势的精准判断
也让更多投资者相信
这个“没学过金融的AI专家”，
确实掌握了别人没有的“态势感知”能力
利奥波德的成功
其实也是当下AI行业热度的一个缩影
根据CNBC引用Pitchbook的数据
2025年上半年
全球AI初创企业总共筹集了1043亿美元的资金
而基于风险投资的退出总额超过了360亿美元
其中最大的几笔投资包括
OpenAI在2025年3月筹集的400亿美元
AI数据标注公司Scale AI从Meta获得的143亿美元投资
以及Anthropic筹集的35亿美元
这些数据说明
AI行业已经从“概念炒作”，
进入了“资本密集型发展”阶段
一方面
大型科技公司和投资机构在持续砸钱
推动技术突破；
另一方面
像利奥波德这样的“行业内行人”，
正在从二级市场攫取属于他们的财富
这种“技术驱动资本
资本反哺技术”的循环
让整个AI行业呈现出一种“疯狂生长”的态势
而利奥波德的故事
就是这种疯狂最生动的注脚
一个因为坚持安全理念被开除的AI研究员
靠一篇论文成为投资圈新贵
这种跨界的成功
在其他行业几乎是不可想象的
但在AI时代，却真实发生了
不过最后我们也要客观看待这个故事
利奥波德的成功有它的特殊性
他既身处AI技术的核心圈
能够第一时间掌握行业动态
又具备将技术趋势转化为投资逻辑的能力
这种“双重优势”不是所有人都能拥有
而且他的基金业绩只持续了半年
未来是否能保持这种高增长
还有待时间检验
但是不可否认的是
他的经历也给我们提了一个醒
在AI快速发展的时代
“理解技术趋势”正在成为一种核心竞争力
无论是做技术研发、产品落地
还是投资决策
谁能更早、更准地看懂AI的发展方向
谁就更有可能在这个时代抓住机会
好了
关于利奥波德和他的AI投资故事
今天就和大家分享到这里
如果你对他的论文《态势感知》感兴趣
欢迎去阅读原文
感谢观看本期视频，我们下期再见
