大家好，这里是最佳拍档，我是大飞
11月10日，李飞飞亲自撰文
认为生成AI的下一个战场是空间智能（Spatial Intelligence）
在文章中
她首次系统性地解释了什么是空间智能？
它为什么如此重要？
以及如何构建能够解锁空间智能的世界模型
李飞飞还指出了当前AI存在的致命缺陷
虽然AI掌握了海量的抽象知识
但是对于物理世界的常识和空间规律
它几乎一无所知
这种缺陷
直接卡死了AI升级的大动脉
她敲响警钟
提出AI的下一个十年的真正突破
不再是堆砌文字
而是要解锁空间智能
这才是连接感知、想象和行动的终极能力
文章发布之后
立即在社交平台引发了热议
今天我们就来看看她具体都说了什么
1950年
当计算机还只是用来做自动运算和简单的逻辑判断时
艾伦·图灵（Alan Turing）在《计算机器与智能》一文中
就提出了一个影响深远的问题
机器能思考吗？
在那个时代
这个问题显得有些天马行空
但是图灵凭借着非凡的想象力洞察到
智能或许不必天生
而是可以通过技术构建出来
正是这个想法
催生了后来被称为人工智能的科学领域
75年过去
AI确实取得了翻天覆地的进步
尤其是最近几年
以大语言模型为代表的生成式AI
已经从实验室走进了我们的日常生活
这些AI展现出了曾经被认为不可能的能力
但是如果我们冷静下来审视
就会发现当前的AI依然存在巨大的局限
李飞飞在文章中提到了几个关键问题
首先，自主机器人的愿景还远未实现
我们在科幻电影里看到的机器人场景
至今还停留在实验室或者高度受限的场景中
其次，AI在加速科学研究方面的潜力
还没有完全释放出来
很多研究的关键步骤
依然需要人类手动完成
最后
AI还无法真正理解并且赋能人类的创作者
无论是在分子化学、建筑设计还是电影建模等领域
AI都没能成为真正的帮手
因为它缺乏对空间的理解
为什么会出现这些问题？
李飞飞认为，核心原因在于
当前的AI没有掌握空间智能
而这种能力恰恰是人类认知的基础
要搞清楚这一点
我们得先回到智能是如何进化的这个根本问题上
提到智能
很多人会首先想到语言、逻辑、数学这些能力
但是实际上
空间智能才是更基础、更古老的智能形式
李飞飞在文章中把空间智能
称为人类认知的脚手架
它就像建筑施工时的脚手架一样
支撑着我们对世界的感知、理解、推理和创造
从进化的角度来看
动物们通过感官感知世界的简单行为
就已经开启了空间智能的进化之路
随着进化
动物的神经系统越来越复杂
逐渐形成了从感知到行动的核心循环
许多科学家推测
正是这种循环驱动了智能的进化
最终让人类成为了既能感知、又能学习、还能思考和创造的物种
而空间智能，就是这个循环的核心
对于我们每个人来说
空间智能其实是一种我们每天都在用
但是却不自觉的能力
比如我们对空间布局的认知、对空间关系的实时判断、基于长期经验形成的空间直觉
以及最基础的空间推理
它们背后是对复杂的空间感知、推理和预测
而这正是当前AI所最缺乏的
更重要的是
空间智能还是人类文明进步的关键驱动力
李飞飞在文章中举了三个极具代表性的例子
第一个例子是古希腊学者埃拉托色尼（Eratosthenes）测量地球周长
公元前3世纪
埃拉托色尼发现了一个有趣的现象
在夏至这天，埃及的赛伊尼地区
太阳会直射到深井的底部
这时的物体是没有影子的
而同一时间，在北方的亚历山大港
一根竖杆的影子会形成7度的夹角
凭借空间智能
埃拉托色尼把这两个看似无关的现象
转化成了一个几何问题，他认为
这7度的夹角，其实是因为地球是球形
两个地点在地球表面的纬度差异导致的
于是
他通过测量亚历山大港到赛伊尼的距离
再乘以50
最终计算出地球的周长约为4万公里
这个结果和现代科技测量的实际值惊人地接近
第二个例子是詹姆斯·哈格里夫斯（James Hargreaves）发明珍妮纺纱机
18世纪中期
英国的纺织业还是手工操作
一个工人用传统纺纱机一次只能纺一根线
效率很低
哈格里夫斯在观察妻子纺纱的时候
突然有了一个空间层面的灵感
如果把多个纺锤并排排列在同一个框架里
是不是就能让一个工人同时纺多根线呢？
基于这个想法，他发明了珍妮纺纱机
把纺纱效率提高了8倍
这个发明也直接推动了工业革命的爆发
让人类从手工生产进入了机器生产的时代
第三个例子是詹姆斯·沃森（James Watson）和弗朗西斯·克里克（Francis Crick）发现DNA双螺旋结构
20世纪50年代
科学家们已经知道DNA是遗传物质
但是不知道它的结构是什么样的
沃森和克里克没有依赖复杂的仪器
而是通过构建3D分子模型来寻找答案
他们用金属板代表DNA的碱基
用金属丝代表连接它们的化学键
不断调整这些组件的空间排列
直到找到符合所有实验数据的结构
最终
他们发现DNA是由两条反向平行的链组成的双螺旋结构
这个发现揭开了生命遗传的奥秘
为现代分子生物学奠定了基础
这三个例子跨越了几千年的历史
但是都指向了同一个结论
空间智能是人类理解世界、改造世界的核心能力
无论是探索自然规律、发明新工具
还是推动科学革命
都离不开对空间关系的感知、推理和创造
而当前的AI之所以无法在这些领域发挥作用
正是因为它缺乏这种能力
那么，要想让AI拥有空间智能
我们需要做什么？
李飞飞和她的团队提出了一个关键的解决方案
构建世界模型（World Models）
这种模型的核心能力
是能够理解、推理、生成
并且与语义、物理、几何和动态上都极为复杂的世界进行交互
这远远超出了当前大语言模型的能力范围
那么，一个真正的世界模型
需要具备哪些核心能力？
李飞飞在文章中明确提出了三点
第一个核心能力是生成式（Generative）
它能根据语义或者感知指令
生成无穷无尽、多样化的模拟世界
而且这些世界必须满足感知一致性、几何一致性和物理一致性
在这个方面
目前学术界正在探索的一个关键问题是
世界模型应该如何表示这些空间信息？
是用隐式表示
通过神经网络的参数间接存储空间信息
还是用显式表示
直接存储物体的3D坐标、形状、物理属性呢？
李飞飞对此的观点是，两者都需要
第二个核心能力是多模态（Multimodal）
我们人类在理解世界的时候
会同时使用视觉、嗅觉、触觉、听觉等多种感官
这种多模态融合的能力
是我们理解世界的关键
同样，世界模型也需要具备这种能力
当前的多模态模型虽然也能处理多种输入
但是它的核心还是语言模型
图像、视频等模态只是辅助输入
并没有真正与语言模态深度融合
而世界模型的设计理念是原生多模态
也就是说
各种模态在模型中是平等的
它们共同服务于理解和构建世界这个核心目标
第三个核心能力是交互性（Interactive）
如果我们向模型输入动作或目标
它应该能输出世界的下一个状态
而且这个状态必须符合世界的历史状态、物理规律和语义逻辑
这是世界模型最关键的能力之一
因为它直接对应人类的行动能力
而更高级的交互性能力
还包括目标驱动的动作规划
也就是说
世界模型不仅要能预测目标的状态
还能规划出需要做哪些动作才能达到这个目标
这也是未来机器人自主行动的核心基础
如果机器人能够通过世界模型规划动作
那么它就能在复杂环境中自主完成任务
而不需要人类重新编程
李飞飞认为
构建具备这三大能力的世界模型
是AI下一个十年的决定性挑战
因为这个挑战的难度
远远超过了构建大语言模型
因为语言是一维的、序列式的信号
而世界是三维的、动态的、多模态的系统
要模拟这样的系统
需要解决一系列技术难题
李飞飞创立的World Labs
就是专注于世界模型研究的机构
在文章中
她分享了当前世界模型研究面临的三大核心挑战
以及团队的一些探索成果
挑战一，设计通用的训练任务函数
我们知道
大语言模型之所以能取得成功
一个关键原因是它有一个简单、优雅且通用的训练任务
预测下一个token
而世界模型的训练
目前还没有这样一个通用的任务函数
为什么设计这个任务函数这么难？
因为世界模型需要处理的是空间+时间+多模态的复杂系统
而不是一维文本
这涉及到的连续性的维度更多
也更复杂
李飞飞认为
世界模型的训练任务函数
必须反映几何和物理规律
因为这是世界的本质属性
一个可能的任务函数
也许是预测下一个世界的状态预测
但是这个任务函数的具体设计
还需要进一步的探索
如何定义世界状态？
如何衡量预测的准确性？
这些都需要研究人员不断尝试和优化
挑战二
如何获取大规模、高质量的训练数据
大语言模型的训练数据
主要是互联网上的文本数据
这些数据数量庞大、获取成本低
而世界模型的训练数据
需要包含空间、物理、多模态的信息
获取难度要大得多
当前的训练数据来源主要有三个
第一个是互联网上的图像和视频数据
比如
YouTube、Instagram上有大量的视频
这些视频包含了丰富的空间和动态信息
但问题是，这些数据大多是二维的
而且缺乏深度、触觉、物理属性等关键信息
所以
研究的关键是如何从二维图像/视频中提取三维空间信息
第二个是合成数据
也就是通过计算机模拟生成的、带有精确标注的空间数据
比如，用3D引擎生成大量的虚拟场景
并且标注出每个物体的3D坐标、物理属性、动态规律
这种数据的优点是标注精确、可控性强
可以弥补真实数据的不足
但是合成数据也有缺点
它可能与真实世界存在着差距
导致模型在真实场景中表现不佳
第三个是多模态的补充数据
比如
通过深度相机获取的深度图、通过触觉传感器获取的触觉数据、通过运动捕捉设备获取的动作数据
这些数据能为世界模型提供更丰富的空间信息
但是获取的成本很高
李飞飞认为
未来世界模型的训练数据
必然是真实数据+合成数据+多模态数据的融合
而研究的关键
是如何构建能高效利用这些数据的模型架构
如何让模型从真实数据中学习世界的多样性
从合成数据中学习精确的空间和物理规律
以及从多模态数据中学习跨模态的关联关系
挑战三
需要研发新的模型架构和表示学习方法
当前的多模态和视频生成模型
大多是基于Transformer架构
并且把图像、视频转化为一维或二维的token序列来处理
这种方法有一个致命的缺点
它破坏了空间的三维结构和时间的动态连续性
导致模型无法真正理解空间关系
因此
世界模型需要研发超越当前范式的新型架构
李飞飞提到了两种可能的方向
第一种是3D/4D感知的tokenization方法
也就是说
不再把图像、视频转化为2D token
而是转化为3D空间token或者4D时空token
这样
模型就能直接处理空间的三维结构和时间的动态变化
而不是间接通过2D像素来推测
第二种是空间记忆机制
也就是说
模型需要有专门的记忆模块
用来存储世界的空间信息，比如
房间里有哪些物体
这些物体的位置、形状、物理属性是什么
这样，当模型处理动态场景时
能通过调用空间记忆
保持场景的一致性
World Labs的团队已经在这方面做了一些探索
比如他们最近研发的实时生成帧模型（Real-Time Generative Frame-based Model
RTFM）
这个模型的核心创新
是用基于空间的帧作为空间记忆
也就是说，模型会把生成的世界场景
存储为一系列带有空间坐标的帧
当需要生成下一个状态时
模型会调用这些帧
确保空间的一致性
目前
RTFM已经能实现高效的实时生成
并且保持生成世界的空间一致性
这是世界模型研究的一个重要进展
除了技术挑战
World Labs还展示了世界模型的第一个应用产品
Marble平台
这是一个面向创作者的世界模型工具
能通过多模态的输入生成并且维护一致的3D环境
目前
Marble已经向部分用户开放测试
李飞飞博士表示，团队正在努力优化
争取尽快向公众开放
聊了这么多技术细节
可能有朋友会问
空间智能和世界模型
最终能给我们的生活带来什么改变呢？
李飞飞在文章中
从短期、中期、长期三个时间维度
描绘了空间智能的应用前景
空间智能的第一个重要应用领域
是创造力领域
李飞飞认为
空间智能将彻底改变我们创造和体验叙事的方式
从传统二维的叙事方式
到轻松生成可探索的3D叙事世界
设计流程也将迎来效率革命
有了空间智能工具
设计师可以通过文本+草图的方式
快速生成3D模型，进行实时调整
沉浸式体验也会更加普及
打破空间的限制
让人与人之间的连接更加紧密
空间智能的第二个重要应用领域
是机器人领域
李飞飞认为
机器人要成为人类的协作伙伴
必须具备空间智能
因为机器人需要在物理世界中移动、操作物体、与人类互动
这些都离不开对空间的理解
当前的机器人技术
最大的瓶颈就是缺乏空间智能
而世界模型的出现
会从三个方面推动机器人技术的突破
第一个突破是解决机器人训练数据稀缺的问题
世界模型可以模拟无数个虚拟训练场景
让机器人在虚拟环境中快速学习
第二个突破是让机器人成为懂人类的协作伙伴
未来的机器人
需要具备空间智能+语义理解的能力
才能理解人类的需求和意图
第三个突破是拓展机器人的形态和应用场景
当前的机器人
大多还是人形机器人或工业机械臂
形态比较单一
而未来会根据应用场景的需求
呈现出多样化的形态
除了创造力和机器人领域
空间智能在科学研究、医疗健康、教育等长期领域
也将产生深远的影响
在科学研究领域
空间智能将成为加速发现的工具
比如科学家可以用世界模型
模拟全球气候系统的三维动态变化
或者模拟原子的空间排列与材料性能的关系
甚至是模拟星系的三维结构和演化过程
这些模拟的核心
都是空间关系和动态规律
而这正是世界模型的优势所在
通过空间智能
科学家可以突破实验条件的限制
探索那些无法在实验室中复现的现象
在医疗健康领域
空间智能将成为提升诊疗水平的助手
李飞飞在斯坦福大学的团队
已经在这个领域做了多年研究
比如加速药物的研发
提升诊断的准确性
以及优化患者的照顾
在教育领域
空间智能将成为革新学习方式的工具
空间智能可以让学习变得更加沉浸式、交互式
让学习不再是死记硬背
而是亲身体验、主动探索
大大提高学习的效率和兴趣
在文章的最后，李飞飞提到
她投身AI领域25年
始终被图灵的愿景所激励着
而空间智能的研究
正是基于这个愿景
它不是要让AI取代人类的创造力
而是要让AI成为人类的伙伴
帮助我们突破自身的局限
实现以前无法实现的目标
最后
我想引用李飞飞的一句话作为结尾
她说
从自然界赋予远古动物空间智能的第一缕曙光开始
已经过去了将近5亿年
我们有幸成为这样一代的技术人员
不仅可能很快就能赋予机器同样的能力
并且有幸利用这些能力
为世界各地的人们带来福祉
好了
以上就是这篇文章的主要内容了
如果你对空间智能、世界模型有什么想法
欢迎在评论区留言
感谢大家的观看，我们下期再见
