大家好，这里是最佳拍档，我是大飞
今天聊一个比较敏感的话题
谈谈中国大模型产业到底有没有问题
存在哪些问题
这个话题一说
估计又有很多人要跳出来喷我了
又要扣上外宣、公知这样的帽子了
说实在
那真是高看大飞我这一个屁民了
你说国内的老百姓
现在除了吃瓜吐槽
现在还能干点啥呢？
所以我今天要给大家分享的
是国内知名媒体《财经十一人》的一篇文章
题目就叫《中国大模型产业的五个真问题》，
所以如果你觉得今天视频的内容
让你小小的自尊心感觉不舒服了
别喷我，去找财经十一人哈
文章内容比较长
我大概总结一下核心内容
大家听听看是不是这么回事
对错与否自己去判断
先简单说一些我们都已经知道了的事
2023年
在OpenAI发布ChatGPT的几个月里
中国公司密集发布自己的大模型
整个2023年
中国公司发布的大模型数量已经超过130个
可是在ChatGPT发布之前的很长一段时间里
产业界和投资界大多不看好OpenAI
但是并未动摇它的方向，直到2023年
几乎所有人都认可了大模型的方向
大家认为
OpenAI已经把结果摆出来了
其他公司要做的就是尽快跟进
不断优化，确保能参与未来
有些人把过去没有大规模投入大模型的原因
归咎于结果的不确定性
但是现在已经确定了
算力、数据、人才都可以加大投入
按理说
中国公司最擅长的就是工程优化
当时很多人觉得
做出能实际应用的大模型产品已经指日可待了
但是事实真的如此吗？
对于OpenAI来说
大模型从来都是确定的方向
OpenAI的大部分资金都花在了算力上
当时英伟达的A100价格比今天低很多
根据第三方数据机构SemiAnalysis估计
OpenAI使用了大约3617台HGX A100服务器
包含近3万块英伟达GPU
当然光有GPU还不够
投资方微软还帮助OpenAI搭建了大模型定制化的算力集群
能够进一步提升这些GPU的效率
在数据方面
OpenAI从数据收集、数据标注、数据清洗、数据整理、数据优化等每个环节都有持续得投入
而在人才方面
OpenAI团队中大部分人
都来自顶尖的科研机构或科技巨头
也就是说
在这种财力、实力和投入的力度之下
OpenAI依然用了超过八年的时间
才打造出突破性的产品GPT4
而且还存在无法彻底解决的“幻觉”问题
那么为什么中国公司在几个月的时间里
就能做出号称匹敌GPT4的大模型？
这又是谁的幻觉呢？
从2023年的下半年开始
陆续有部分大模型被指出是“套壳”，
直接套用了国外的开源大模型
在一些检验大模型能力的榜单上排名靠前
不少指标都接近GPT4
甚至榜单表现越好，套壳比例越高
略有调整表现就会变差
而“套壳”还只是中国大模型产业现状的冰山一角
这背后折射出了产业发展的五个问题
分别是模型本身、算力、数据、资本和商业化
它们之间互为因果
每个问题都无法独立解决
而在2024年
这五个问题会进一步的暴露
首先来说一下模型本身的问题
2023年11月
李开复创办的“零一万物”被国外开发者质疑套壳LLaMA
只是重命名了两个张量
很不巧我也做了一期相关节目
随后，李开复和零一万物均做出回应
称在训练过程中沿用了开源架构
出发点是充分测试模型
执行对比实验
这样能快速起步
但是发布的Yi-34B和Yi-6B模型都是从0开始训练
并做了大量原创性优化和突破工作
2023年12月
字节跳动被爆出秘密研发的大模型项目中
调用了OpenAI的API
并使用ChatGPT输出的数据进行自己的模型训练
而这是OpenAI的使用协议中明确禁止的行为
随后，OpenAI暂停了字节的账号
表示会进一步调查
如果属实将要求更改或终止账户
字节对此的回应是，2023年初
技术团队在大模型探索初期
有部分工程师将GPT的API服务应用于较小模型的实验性项目研究中
该模型仅为测试，没有计划上线
也从未对外使用
在2023年4月公司引入GPT API调用规范检查后
这种做法已经停止
目前国产大模型中，主要分为三类
一是原创大模型；
二是套壳国外的开源大模型；
三是拼装大模型
也就是把过去的小模型们拼在一起
变成参数量看起来很大的“大模型”。
其中，原创大模型数量最少
做原创大模型需要有很强的技术积累
且要有持续的高投入，风险很大
因为一旦模型没有足够强的竞争力
这些大规模投入就打了水漂
大模型的价值需要商业化来证明
当市场上已经出现足够好的基础大模型
其他公司应该去挖掘新的价值点
比如大模型在不同领域的应用
或是中间层
比如帮大模型训练、数据处理、算力服务等
但是现状是
大部分参与者都在“卷”所谓的“原创大模型”，
又担心风险太高
于是有了大量套壳、拼装的大模型
其实无论是直接使用开源模型或是拼装模型
只要符合相关规范
都没有问题
等到商业化落地阶段
客户也不太会在意你是否原创
有用就行
甚至不少客户会因为成本更低
更愿意选择非原创的技术
问题在于，即使是拼装和套壳
现在大家也要不断强调“原创”，
为了证明自己是“原创”的
就需要不断的调整修改
而这又会影响大模型的迭代能力
逐渐陷入到内耗、刷榜、作假的境地
其次是算力方面的问题
大模型的基础之一是海量算力
而且是先进算力
因此大模型也被称为暴力美学
英伟达的A100此前被认为是最适合训练大模型的
近期英伟达又推出了更先进的算力芯片H100
但是还没有在中国市场开售
2023年，A100的售价涨了约1倍
但是在2023年
密集购买A100的中国公司主要还是那些自身有业务需求的大厂
包括阿里巴巴、腾讯、字节跳动、百度等
创业公司其实很少
有一些知名的大模型创业公司
会主动要求和英伟达建立所谓的战略合作关系
以此来对外证明自己在投入算力
但是是“不给钱的那种”。
尽管有美国政府的“出口管制规则”，
中国公司想要获得英伟达的算力
也并非不可能
目前有很多方式可以选择
除了直接购买
还可以通过英伟达在中国的合作伙伴购买
不过，除了GPU本身很贵以外
买来之后的部署、运营、调试、使用
都是一笔不小的成本
此前业内流传的一句话是
中国不少科研机构连A100的电费都付不起
我们可以简单来算一下
由八张A100组成的DGX服务器最大功率是6.5kW
也就是运行一小时需要6.5度电
同时要搭配大约同等电量的散热设备
按照平均工业用电每度0.63元计算
一台服务器开一天24小时的电费
就大概200元
如果是1000台服务器
一天的电费就是大概20万元
因此，除了大厂以外
其实创业公司很难大规模的购买、部署GPU
不过，好歹GPU资源还可以租用
在阿里云、腾讯云或是亚马逊AWS等云服务平台上
都可以直接租用A100算力服务
虽然租金同样在过去一年涨了不少
但是实际情况是
不少大模型公司其实并不想在算力上做大规模投入
很多AI方向的投资人都知道
一旦创业公司开始部署算力
会出现两个“问题”，
一是这个投入没有上限，没有终点
谁也不知道要烧到什么程度
哪怕是OpenAI
到今天还会因为算力跟不上而出现宕机
二是公司会因此变成重资产公司
这对于公司未来的估值有不利影响
会直接影响到投资人的收益
2023年
中国不少投资人会直接告诉大模型创业者
先招一些名校背景的人
抓紧开发布会
发布大模型产品，然后做下一轮融资
不要去买算力
于是创业公司们都想在在风口期拿到大量融资
高薪招人，高调发布产品，推高估值
一旦风口过去
继续融资或是上市就需要收入
到时候再通过此前融到的钱
去低价甚至亏本竞标项目
或是直接对外投资来并表收入
当然，随之而来的是
创业公司不愿意承担算力高投入的风险
就很难在大模型领域有突破性发展
也就难以和那些真正在这个方向上大规模投入的巨头们竞争
所以
我们平时总是会对外强调被卡了脖子
但究竟是被别人卡脖子
还是自己不想买呢？
再次是数据方面，现在我们都很清楚
数据和算力都是大模型的基础
在数据方面
中国大模型产业其实面临和算力同样的问题
那就是是否值得大规模投入？
在中国，一般的数据获取门槛很低
过去主要是用爬虫工具来收集数据
现在可以直接用开源的数据集
中国大模型以中文数据为主
而业内普遍认为中文互联网数据的质量较低
我相信，绝大部分国内的AI从业人员
当他需要在互联网上搜索专业信息时
他首先会使用谷歌搜索、像arxiv这样的专业论文网站
或者是上YouTube
我很难想象他会从百度上面快速找到自己所需的资料
虽然
OpenAI用来训练大模型的中文数据
同样来源于中国互联网平台
但是它额外做了很多工作来提升数据质量
这不是普通的数据标注工作能完成的
而是需要专业团队对数据进行清洗、整理
有AI创业者曾表示
在中国很难找到相对标准化的数据服务商
大多是定制化服务
但是定制服务又很贵
这就和是否要大规模投资算力的逻辑有些类似
这笔投入对于很多公司
尤其是创业公司来说
看起来并不划算
如果大规模投入
一旦最后的模型效果不理想
同样是“打水漂”，
还不如用开源数据训练
直接开发布会
此外
中国市场缺乏有效的数据保护手段
有一位大厂的AI负责人说
在中国，你能拿到的数据
别人也能拿到
如果你花很多钱去做高质量数据
别人可以用很低的成本拿到
反过来也一样
相比于算力
如果中国的大模型产业想发展
数据可能是个更加绕不过去的槛
国外在这个领域能诞生像scale
ai这样的独角兽企业，但是在中国
数据加工、清洗的工作通常被认可度较低
创业公司很难在获得高质量数据和低成本投入之间达到平衡
因此模型调优
往往成了一件可望而不可及的事情
也就不足奇怪了
第四，资本的问题
其实上面的这三个问题
背后都指向一个共同的方向
那就是资本短视
尽管OpenAI已经蹚出一条明确的道路
对于绝大部分公司来说
想从零开始做出成熟的大模型
需要耗费的成本和时间并不会短很多
对于大部分投资人来说
每笔投资的目的很明确
退出、赚钱
OpenAI火了，估值一路攀升
未来还会继续增长
2023年4月，OpenAI估值约280亿美元
到了现在
OpenAI最新一轮估值已经达到1000亿美元
这在投资人眼里是一个非常确定的信号
如果以合适的价格投资中国大模型创业公司
也能在很短时间内做到估值成倍增长
可惜的是
中国投资人的耐心只有三五年
这是资本运作模式所决定的
投资人从LP手里募资
需要在一定年限内退出并拿到可观的收益
投资人退出的渠道包括项目并购、上市
或是在后续融资中把自己手里的股份卖给新投资方
早期的融资可以靠风口和讲故事
但是走到中后期甚至上市
就必须有一定规模的商业化能力
投资人们发现，拖得越久
项目上市或被并购的难度就越高
因为AI领域主要的商业模式是做B端的定制化项目
这条路径就决定了创业公司很难做出高增长的收入
投资人只能趁风口还在
迅速推动公司完成多轮融资
抬高估值
之后哪怕打折出售手里的股份
也是划算的
这也是为什么2023年大模型相关的发布会层出不穷
各种大模型榜单百花齐放且排名各不相同
这些都是有助于融资的“故事”。
类似的路径在几年前的AI产业已经出现过一次
那个阶段的代表公司是AI四小龙
2023年的大模型创业只是把过去三年走完的路在一年时间里加速完成
但是，话说回来
只有资本是短视的吗？
要知道
现在中国绝大部分专业投资机构
都已经是人民币基金
美元基金几乎已经全军覆没
而人民币基金大部分拿到的都是地方政府投资
募资的时候都会有行业限制、返投招商、预期回报等条款
在这种情况下
像OpenAI那样默默前期沉淀7-8年的情况
现今几乎已经不敢想象了
创业公司从拿到钱的那一刻开始
就要开始疲于向挣钱奔跑
终点在出发的那一刻其实已经决定了
第五，商业化，究竟谁才会为AI买单
2023年
中国大模型产业迅速从比拼大模型参数
进入到了比拼商业化的阶段
2024年1月的CES上
两位著名的AI科学家李飞飞和吴恩达均表示
接下来AI商业化会有明显发展
会深入到更多行业
目前看来
大模型的主要应用方向有两个
一是通过大模型技术为C端用户提供新的工具
比如付费版的GPT4、百度文心一言等等
但是C端付费短期内很难有大规模增长
对于大模型工具有刚需的人群相对较少
是更有希望的商业化方向的
是b端的服务
在中国的市场
做b端软件服务
其实一直是一个老大难的生意
大飞我就做了十几年
深知这里边的苦楚
跟美国市场不一样的是啊
中国市场最大的B端客户呢
其实是政府和国企
大模型作为一个先进的生产力工具
会有一个直接影响就是减少人力
而在政府和国企
减少人力呢
在很多的时候反而会变成一种阻力
如果退而求其次
我们去选择做中小b的客户
那么在2024年
恐怕也很难
有一位AI大模型的创业者曾经说过
他近期呢询问了不少的企业客户
得到的回应都是大模型能够做什么
能帮我裁员
还是能帮我赚钱
直到今天
即使是最先进的大模型
也依然存在着幻觉的问题
这个呢在c端的应用上呢
还可以忍受
但是在一些专业的b端场景上
有幻觉就意味着难以真正的落地
过去呢中国大量发展的是对比式的AI
比如说人脸识别
如果识别出现错误
还可以通过较低的人工辅助的手段来调整
但是
大模型很擅长一本正经的胡说八道
这种迷惑性呢
有时候是很难发掘和判断的
在2024年呢
AI大模型的发展呢会有几个相对确定的趋势
一个是融资热度会下滑
2023年出现的一家公司完成多轮数亿美元的融资呢
这种情况会明显的减少
大模型创业公司需要找到新的出路
第二个呢
是大模型的应用会持续的深入
但是这主要会集中在数字化程度很高
而且业务体量非常大的领域
大模型也许会在c端呢
大模型也会进一步的普及
不过对于中国的公司来说
不能只是依赖于c端用户的付费
c端应用场景中呢
必须要加入其他的变现模式啊
比如说广告
第三个呢
是国产的算力呢会得到进一步的重视
但是得到重视
并不意味着在短期内会有明显的进步
这是一个很漫长的过程
当然了国产算力能力提升的同时呢
也会出现更多趁机炒作造势圈钱的现象
最近迅速翻车的AI割韭菜第一人
李一舟以及鹤老师这些人呢
就是最好的例子
风口会刺激产业迅速扩张
泡沫也随之而升
机会越大泡沫就越大
只有撇开了泡沫
才能够看清产业发展的新机会
好了以上就是这篇文章的核心内容
其实大飞
我觉得还有一点问题没有提出
那就是人才的问题
但这个问题背后呢
是更为深远的教育
社会体制等等更大的话题
正如84年著名的钱学森之问一样
为什么我们的学校总是培养不出杰出的人才呢
我觉得放到现在呢依然没有过时
以后呢有机会我们会再展开聊
最后呢
对于那些总是幻想着遥遥领先
总是无端给我扣帽子的键盘侠呢
我也找了个嘴替
感谢小崔老师
好了本期视频内容就到这里
感谢大家观看
我们下期再见
