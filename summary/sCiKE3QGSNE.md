好的，這是整理後的文稿：

**MiniMax 开源模型：AI Agent 元年基石？**

大家好，這裡是最佳拍檔，我是大飛。

2024年底，許多 AI 領域的領軍人物都預測 2025 年將是 AI Agent 的元年。隨著 Agent 應用場景的擴大，無論是單個 Agent 工作時產生的記憶，還是多個 Agent 協作產生的上下文，都對模型的上下文長度提出了更高的要求。

1 月 15 日，MiniMax 開源了最新的基礎語言模型 MiniMax-Text-01 和視覺多模態模型 MiniMax-VL-01。這兩個模型在業界首次大規模實現了線性注意力機制，大大增加了上下文窗口長度，甚至一次可以處理 400 萬的 token，是其他模型的 20 到 32 倍。MiniMax 相信這些模型能夠為接下來一年 Agent 的應用爆發做出貢獻，並斷言傳統 Transformer 架構不再是唯一選擇。

在此之前，MiniMax 一直以閉源模型的身份示人，外界對底層模型的細節知之甚少。這次不僅是 MiniMax 首次將模型開源，也是 MiniMax 首次公開技術細節。

**MiniMax-Text-01：線性注意力與混合專家架構**

目前大多數領先的大語言模型都是基於 Transformer 架構的，其核心機制是自注意力機制 (Self-Attention)。自注意力機制允許模型在處理文本時關注到文本中不同位置的信息，從而捕捉到更複雜的語義關係。然而，自注意力機制的計算複雜度與輸入序列長度呈平方關係 (O(n²))，導致處理長文本時計算速度慢，訓練時需要消耗大量計算資源和電力。

為了應對這個挑戰，MiniMax 在 MiniMax-Text-01 模型中引入了一種名為 Lightning Attention 的線性注意力機制。Lightning Attention 是 TransNormer 架構的改進版本，透過將計算複雜度降低到線性 (O(n))，使得模型能夠更高效地處理長序列數據。雖然線性注意力機制並非 MiniMax 首創，但這次是首次實現線性注意力模型的大規模訓練。

為了在保持效率的同時提升模型性能，MiniMax 還提出了 Hybrid-lightning 策略：每七個使用 Lightning Attention 的 transnormer 塊後，會跟隨一個使用 softmax 注意力的 transformer 塊。這種混合策略既能顯著提升計算速度，又能利用傳統 softmax 注意力機制捕捉更複雜的語義關係，保證模型的整體性能。

此外，MiniMax 還採用了混合專家 (MoE) 架構。MoE 架構的核心思想是將模型劃分為多個「專家」，每個專家擅長處理特定類型的任務，並根據輸入數據的不同動態選擇最合適的專家來處理。與傳統的密集模型相比，MoE 架構不僅效率更高，性能也更加優秀。MiniMax 的實驗表明，在相同的計算負載下，MoE 模型的表現要大幅優於密集模型。

**訓練策略與優化**

為了訓練 MiniMax-Text-01，MiniMax 先通過小規模實驗驗證技術改進的有效性以及 Scaling Laws，然後開始著手大規模訓練。MiniMax 採用了 1500 到 2500 台 H800 GPU，並在訓練過程中動態調整 GPU 的數量。

在訓練中，MiniMax 面臨的最大挑戰是長上下文的訓練。針對 MoE 架構，MiniMax 採用了一種基於 token 分組的重疊方案，通過對專家權重和數據並行的精細劃分，設計了專家張量並行 (ETP) 和專家數據並行 (EDP) 兩個進程組，實現了存储和计算的最佳平衡。對於長上下文訓練，MiniMax 的解決思路是進行數據格式化，將不同的樣本沿著序列的維度首尾相連，命名為 data-packing，以降低計算過程中的浪費。

為了提高訓練效率，MiniMax 還採用了 token-drop 的策略，為每個專家分配一個容量限制，一旦達到這個容量，任何額外路由到該專家的 token 都會被丟棄。

此外，為了實現大規模的 Lightning Attention 訓練，MiniMax 還採用了四項優化策略：分批內核融合、分離式的預填充與解碼執行、多級填充、跨步分批矩陣乘法擴展。這些優化策略使得模型能够在GPU集群上高效运行，在英伟达H20上达到超过75%的MFU，同时保持模型的性能和推理效率。

最終，MiniMax 打造出了擁有 4560 億參數的 MiniMax-Text-01 模型，總共有 32 個專家，每個 token 都會激活其中 459 億個參數。模型的訓練上下文窗口可以達到 100 萬 token，而在執行推理的時候，上下文長度最高可以外推到 400 萬 token，是其他模型的 20 到 32 倍。

**性能評估**

在常見的學術測試集上，MiniMax-Text-01 的表現可以與 GPT-4o、Claude 3.5 Sonnet 等頂尖閉源模型，以及 Qwen2.5、DeepSeek v3、Llama 3.1 等頂尖開源模型相媲美，甚至在某些方面更勝一籌。例如，在 GPQA Diamond 數據集上，MiniMax-Text-01 取得了 54.4 的成績，超過了大多數開源指令微調的大模型以及最新版本的 GPT-4o。而在 MMLU、IFEval 和 Arena-Hard 這些測試中，MiniMax-Text-01 也取得了前三名的成績，展示了強大的知識應用能力和對人類偏好的理解能力。

在長上下文理解任務上，MiniMax-Text-01 的表現更為突出。當上下文長度超過 128k 時，MiniMax-Text-01 的優勢就明顯體現出來了。在長文本學習能力方面，MiniMax-Text-01 也達到了 SOTA 水平。

在實際應用案例中，MiniMax-Text-01 能夠根據提供的指令、語法書、單詞表和對照例句，翻譯一門新幾內亞的小眾語言 Kalamang，並給出與標準答案基本一致的翻譯結果。在長對話記憶任務中，MiniMax-Text-01 能夠準確地記住對話中的細節，並且做出相應的回應。

**MiniMax-VL-01：多模態拓展**

MiniMax 基於 MiniMax-Text-01 開發了一個多模態版本 MiniMax-VL-01，其思路是在文本模型的基礎上整合一個圖像編碼器和一個圖像適配器，將圖像轉換為大語言模型能夠理解的 token 形式。MiniMax-VL-01 的整體架構符合 ViT-MLP-LLM 的範式，並設計了一個專有數據集和一個多階段的訓練策略，確保模型的視覺理解能力。最終，MiniMax-VL-01 在各個基準上的表現可以與其它 SOTA 模型媲美，並且在某些指標上達到最佳。

**局限性與未來展望**

MiniMax 也提出了 01 模型的局限性：

*   **長上下文評估：** 目前長上下文檢索任務的評估數據集主要為人工或簡化場景設計，實際應用中對長文本推理能力的評估仍然有限。
*   **模型架構：** 模型目前仍然保留了 1/8 的組件使用傳統的 softmax 注意力。
*   **複雜的編程任務：** 模型在高級編程任務上的性能仍有待改進，因為預訓練階段的編碼數據集仍然有限。

除了這些以外，MiniMax 還在探索如何將長上下文能力應用到多模態任務中。MiniMax 的創始人閆俊傑曾表示，下一代人工智能將是無限接近通過圖靈測試的 Agent，交互自然、觸手可及、無處不在。

**總結**

MiniMax-01 系列的兩個模型展示了處理長上下文方面的卓越性能以及處理更長上下文的潛力。

最後，提供一个 MiniMax-01 和 DeepSeek v3 的对比表格（大家可以暂停观看）。

MiniMax 尚未发布推理模型，期待他们接下来的动作。

感謝大家的觀看，我們下期再見！

[model=gemini-2.0-flash,0]
