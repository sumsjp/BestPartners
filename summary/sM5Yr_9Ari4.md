好的，我將盡可能專業地整理您提供的文稿，使其更清晰、更易讀。以下是整理後的版本，並附上一些建議：

**標題建議：**

*   **邪惡版 ChatGPT 出現：WormGPT 引發網路安全危機？**
*   **AI 安全拉響警報：WormGPT 的出現與網路犯罪的未來**

**正文整理：**

大家好，這裡是最佳拍檔，我是大飛。

最近我們做了許多關於人工智慧的節目，其中幾期探討了安全與對齊等議題。無論是 OpenAI 的 GPT-4、Anthropic 的 Claude，還是 Google 的 Bard，都在努力讓大型語言模型變得更安全，並符合審查標準。

即便如此，OpenAI 仍不斷因 AI 的道德問題和數據安全隱患遭到質疑。上週，美國聯邦貿易委員會 (FTC) 更對其發起了正式調查，這也是美國監管機構首次對 AI 聊天機器人風險進行審查。由此可見，AI 安全本身就是一件重要且艱難的事情。

然而，如果真有人利用大型語言模型來為非作歹呢？當 OpenAI 還在疲於應付各方對 ChatGPT 的審查時，一款「沒有道德界限或限制」的「邪惡版 ChatGPT」—— WormGPT，已悄然在網路上蔓延。

根據網路安全公司 SlashNext 的報告，他們的團隊在研究生成式 AI 在網路犯罪方面的潛在風險時，偶然在一個與網路犯罪有關的著名論壇上發現了 WormGPT 工具。據了解，這是一個 GPT 模型的駭客版本，月費為 60 歐元 (約合人民幣 479 元)。SlashNext 形容 WormGPT 是一個專為惡意活動設計的工具，簡直是網路罪犯的武器庫。

WormGPT 的作者是一名駭客，他在論壇上表示，這個專案的目的是提供一個 ChatGPT 的替代方案，讓使用者可以進行各種非法及與駭客相關的活動。為證明其說法，他還上傳了相關截圖，顯示使用者可要求 AI 機器人生成用 Python 語言編寫的惡意軟體。

根據公開消息，WormGPT 是基於 2021 年開源的大型語言模型 GPT-J 開發的，其工作方式與 ChatGPT 大致相同，可處理人類自然語言提出的要求，並輸出所要求的任何內容，包括故事、摘要和程式碼。此外，它還能生成任意長度的文本，且支援無限數量的字元，使其非常適合製作網路釣魚郵件和其他社交工程攻擊。WormGPT 還具備聊天記憶功能，能利用先前的知識產生更具說服力的回應，甚至可以格式化程式碼，躲過安全軟體的檢測，提高攻擊成功率。

與 ChatGPT 或 Bard 不同的是，WormGPT 不用像 OpenAI 或 Google 這樣的大公司一樣，承擔相關法律義務，也更不會將安全對齊作為首要目標。它幾乎沒有任何限制，也更容易被用來做違法的事情。SlashNext 指出，WormGPT 在各種資料來源上進行訓練，尤其集中在惡意軟體相關的資料上。由於其輸出沒有任何道德限制，可被要求執行各種惡意任務，包括創建惡意軟體以及一切與駭客有關的事情，這對網路犯罪分子而言無疑是一大利器。

NordVPN 的網路安全專家阿德里安評價 WormGPT 簡直是「ChatGPT 的邪惡雙胞胎」，因為它顯然是從 OpenAI 對 ChatGPT 不斷施加限制，而攻擊者則極力想規避這些限制的情況下衍生出來的產品。

為了全面評估 WormGPT 及其相關的潛在危險，SlashNext 的團隊進行了以 BEC 攻擊為重點的測試。簡單來說，BEC (商業電子郵件洩露) 攻擊是一種透過電子郵件進行的社交工程學攻擊，攻擊者一般會偽造電子郵件消息，誘騙受害者執行某些操作，也被稱作釣魚。由於國外電子郵件使用非常頻繁，所以這種攻擊手段尤為有效。

在實驗中，SlashNext 團隊要求 WormGPT 生成一封電子郵件，內容是向毫無戒心的銀行帳戶經理施加壓力，迫使其支付一張虛假發票。看到 WormGPT 輸出的結果後，SlashNext 團隊驚呼危險。WormGPT 生成的電子郵件不僅極具說服力，而且在策略上也十分狡猾，展示了它在複雜的網路釣魚和 BEC 攻擊中的無限潛力。

透過測試，SlashNext 認為，類似於 WormGPT 這樣的生成式 AI 技術可能會給網路安全帶來巨大威脅。因為有了這類工具的能力加持，就連網路犯罪新手都能輕易實現詐騙。以 BEC 攻擊為例，使用生成式 AI 具有兩大優點：

*   **卓越的語法：** 生成式 AI 可以創建在語法上無懈可擊的電子郵件，使其看起來非常合法合理，因此被郵件系統自動標記為可疑郵件的可能性會大幅降低。
*   **降低犯罪門檻：** 生成式 AI 的出現極大地簡化了原本複雜的 BEC 攻擊。即便技術有限的攻擊者也能夠使用生成式 AI 技術，使其成為越來越多網路犯罪分子可以使用的工具。

針對生成式 AI 可能引發的大範圍 BEC 攻擊，SlashNext 建議了兩種防範策略：

1.  **進行 BEC 專項培訓：** 公司可以制定相應的培訓計畫，以應對 AI 驅動的 BEC 攻擊，讓員工了解 BEC 攻擊的威脅，以及 AI 如何加大這種威脅的原理。
2.  **強化電子郵件的驗證措施：** 企業應當執行嚴格的電子郵件驗證流程，當有來自組織外部的電子郵件冒充內部高管或供應商時，系統要自動發出警報。

事實上，在安全方面，除了利用 WormGPT 編寫惡意軟體、進行 BEC 攻擊以外，上個月 ChatGPT 還出現了一個「奶奶漏洞」。一位名為 Sid 的使用者發現，只要讓 ChatGPT 扮演自己過世的奶奶來講睡前故事，就能順利騙出 Windows 10 Pro 的金鑰。經過 Sid 的分享後，越來越多使用者也發現了這個漏洞，並開始嘗試欺騙 ChatGPT 報出 Windows 11 的序號，其中許多人都成功了。雖然這些金鑰大多是無效的，但也有少量序號確實是真實可用的。

無論是 ChatGPT 的「奶奶漏洞」，還是「網路犯罪分子專用」的 WormGPT 的出現，都證明至少現階段 AI 領域仍然存在著不少挑戰和局限性。如果我們現在還認為生成式 AI 只是會跟我們聊聊天、或者畫個畫，那就是太天真了。

事實上，我們可能已經一頭扎進了史詩般的網路安全地獄中。我相信，第一個完全由 AI 編寫的病毒可能很快就會出現。大型語言模型技術在給我們帶來大量效率和想像力的同時，也像是打開了潘朵拉之盒，帶來了無盡的災禍。更何況，我們現在幾乎沒有什麼有效的手段能夠阻止駭客或攻擊者利用這樣的技術。

他們大不了自己拿開源模型來訓練一個，而且可以往危害越來越大的方向去訓練，完全不用考慮任何道德約束問題。比方說，拿所有的病毒軟體程式碼和漏洞資料來訓練大型語言模型，那麼是不是會自動製造出更多的病毒和漏洞攻擊？這一點想想就可怕。

未來幾年，當正邪人工智慧交鋒的時候，究竟誰會更勝一籌？未來的世界又會是怎樣的呢？

歡迎大家在評論區發表自己的意見。今天的影片內容就到這裡，感謝大家的觀看，我們下期再見！

**建議：**

*   **更明確的段落劃分：** 將內容更細緻地分成小段落，讓閱讀體驗更輕鬆。
*   **重點強調：** 對於關鍵詞或重要資訊，可以使用粗體或斜體加強突出。
*   **補充說明：** 對於 BEC 攻擊等專業術語，可以添加更詳細的解釋，以便不熟悉相關領域的觀眾也能理解。
*   **個人觀點：** 在適當的地方加入您個人的觀點或見解，讓內容更具吸引力。

希望這個整理版本對您有所幫助！如果需要進一步修改，請隨時告訴我。

[model=gemini-2.0-flash,0]
