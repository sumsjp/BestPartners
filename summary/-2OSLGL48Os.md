好的，這是整理後的文稿：

**標題：MiniGPT4：搶先體驗 GPT-4 的圖像理解與對話能力**

**引言：**

大家好，這裡是最佳拍檔，我是大飛。距離 GPT-4 首次公開問世已一個月。GPT-4 作為多模態大語言模型，不僅能生成文字內容，還能理解圖像輸入，讓使用者直接與圖片對話。OpenAI 曾演示 GPT-4 如何透過手繪草圖生成網站，令人印象深刻。圖像對話功能是 GPT-4 最令人期待之處，但目前尚未對外開放。

**MiniGPT4：實現圖像理解與對話**

今天介紹一個名為 MiniGPT4 的項目，由阿布杜拉國王科技大學的博士開發，提供類似 GPT-4 的圖像理解與對話能力，讓您搶先一步感受圖像對話的強大之處。

**MiniGPT4 的特點：**

1.  **多模態：** 能夠讀懂圖片，回答圖片內容、顏色，甚至風格。
2.  **中國團隊：** 5 位作者中有 4 位是中國人。
3.  **低成本：** 僅用 4 塊 A100 訓練 10 小時。
4.  **開源：** 項目 GitHub 地址在影片評論區。
5.  **提供演示地址：** 提供 7 個演示地址供大家體驗。

**MiniGPT4 的訓練方式：**

MiniGPT4 將 BLIP-2 的凍結視覺編碼器與凍結 LLM Vicuna 對齊，僅使用一個投影層。訓練分為兩個階段：

*   **第一階段（預訓練）：** 使用 4 塊 A100 在 10 小時內訓練約 500 萬對對齊的圖像和文本數據。
*   **第二階段（微調）：** 透過模型本身和 ChatGPT 一起創建高質量圖像文本對 (3,500 對)，並在對話模板中訓練，顯著提高模型生成的可靠性和整體可用性。此階段計算效率高，用一台 A100 僅需 7 分鐘左右。

**MiniGPT4 的能力：**

MiniGPT4 產生了許多新興的視覺語言能力，與 GPT-4 類似。例如，詢問 MiniGPT4 對粉紅色火烈鳥標誌的看法，它能詳細描述其設計、風格和適用場合。

**MiniGPT4 的應用前景：**

MiniGPT4 算法模型可以進行本地化部署。GPT-4 的先進能力可能歸因於其使用了更先進的大模型語言。未來基於大模型所製造的應用，在圖像、聲音、影片等領域的效果應該都不會太差。MiniGPT4 項目驗證了大語言模型在圖像領域的可行性，相信將有更多開發者投入，將 GPT-4 的能力延伸至音訊、影片等領域，帶來更多有趣的 AI 應用。

**結語：**

今天的分享就到這裡，感興趣的小伙伴們歡迎訂閱我們的頻道，我們下期再見！

**建議：**

*   建議先體驗線上演示環境。
*   有興趣本地部署 MiniGPT4 的朋友，可以在評論區回復，我們會錄製安裝和使用的教程。

[model=gemini-2.0-flash,0]
