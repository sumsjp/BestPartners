好的，以下是對文稿的整理，使其更具結構性、更易於理解和參考：

**標題：徹底搞懂AI Agent的「上下文工程」（Context Engineering）：概念、意義與實踐**

**引言：**

*   當前許多AI Agent看似先進，但實際使用時常出現問題。
*   問題根源並非模型能力不足，而是「上下文工程」（Context Engineering）的缺失。
*   本影片旨在徹底搞懂上下文工程的概念，以及它與提示詞工程（Prompt Engineering）、檢索增強生成（RAG）、模型上下文協議（MCP）之間的關係。

**一、 什麼是上下文（Context）？**

*   **定義：** 提供給大語言模型，用於完成下一步推理或生成任務的全部資訊集合。
*   **三種類型：**
    *   **1. 指導性上下文（Guiding Context）：**
        *   **功能：** 指導模型該做什麼，以及如何去做。設定框架、目標和規則。
        *   **包含：** 系統提示詞（System Prompt）、任務描述（Task Description）、少樣本示例（Few-shot Examples）、輸出格式定義（Output Schema）。
        *   **與提示詞工程的關係：** 提示詞工程主要優化此類上下文。
    *   **2. 信息性上下文（Informational Context）：**
        *   **功能：** 告訴模型需要知道什麼知識，提供解決問題所需的知識、事實與數據。
        *   **包含：** RAG、記憶（Memory）。
            *   **記憶（Memory）：** 分短期記憶、長期記憶，以及狀態（State）和草稿本（Scratchpad）。
    *   **3. 行動性上下文（Actionable Context）：**
        *   **功能：** 告訴模型能做什麼，以及做了之後的結果。提供與外部世界交互的能力。
        *   **包含：** 工具定義（Tool Definition）、工具調用和結果（Tool Calls & Results）、工具追蹤（Tool Traces）。
*   **總結：** 上下文是多維、動態、服務於特定任務的系統性概念，遠不止聊天記錄。

**二、 什麼是上下文工程（Context Engineering）？**

*   **定義：**
    *   **托比·盧特克（Tobi Lütke）：** 提供所有上下文的藝術，讓大語言模型能夠合理地解決任務。
    *   **安德烈·卡帕西（Andrej Karpathy）：** 在工業級大模型應用中，是一門微妙的藝術與科學，目的是在上下文窗口中填入恰到好處的資訊，為下一步的推理做準備。
*   **總結：** 上下文工程是一門系統性的學科，專注於設計、構建和維護一個動態系統，負責為Agent執行任務的每一步智能地組裝出最優的上下文組合，從而確保任務能夠被可靠、高效地完成。
*   **類比：** 卡帕西將Agent視為新型操作系統，模型是CPU，上下文窗口是記憶體，上下文工程則是記憶體管理器。
*   **意義：** 標誌著與大語言模型交互模式的升級，從提示詞工程優化指導性上下文，轉向構建最高效的資訊供給系統。

**三、 上下文工程與提示詞工程、RAG的區別？**

*   **關係：** 並非互相排斥，而是處於不同層級，互相協作。
*   **提示詞工程：** 優化單次交互的指令部分，更細粒度的、面向具體問題、單輪交互的工程實踐。
*   **RAG：** 從外部知識庫檢索相關資訊，作為信息性上下文的一部分，填充到上下文窗口中。
*   **上下文工程：** 範疇遠大於RAG，不僅要負責「檢索什麼」，還要考慮如何將得到的信息性上下文與另外兩類上下文進行動態組合，甚至在RAG失敗之後考慮使用其他工具。

**四、 為什麼需要上下文工程？**

*   **問題：** 當Agent輸出不及預期時，可能的原因：
    *   1. 模型能力局限（較少見）。
    *   2. 上下文資訊缺失（更常見）。
*   **重點：** 現在基礎模型智能水平提升後，輸出不及預期的原因更多指向上下文工程的缺失。
*   **例子一：**
    *   **貧乏上下文的Agent：** 收到「明天有空聚一下嗎？」的回覆是機械式的。
    *   **充足上下文的Agent：** 會檢索日曆、識別發件人、分析過往郵件，並提供日曆邀請工具，生成高效的回應。
*   **例子二：**
    *   **長期任務：** 線性Agent為了無所不知，將每一次交互都記錄下來，並作為上下文傳遞。
    *   **問題：**
        *   性能下降：早期任務的細節干擾當前步驟。
        *   成本與延遲激增：Token數量急劇膨脹。
        *   架構限制：上下文溢出，API調用失敗。
*   **總結：** 隨著基礎模型能力普遍越過關鍵閾值，上下文工程成為提升系統表現的更高優先級選項，甚至在許多場景下是唯一可行的路徑。

**五、 上下文工程的系統性應對框架：**

*   **四個部分（參考蘭斯（Lance）的博客）：**
    *   **1. 寫入（Write）：**
        *   **目的：** 將上下文持續久化，超越上下文窗口限制，未來按需取用。
        *   **類型：**
            *   **會話內寫入（Session-level Write）：** 將思考、計畫或臨時數據寫入會話內的草稿紙（Scratchpads）。
            *   **持久化寫入（Persistent Write）：** 將長期價值資訊寫入外部記憶（Memory）系統，如向量資料庫或知識圖譜。
    *   **2. 選取（Select）：**
        *   **目的：** 從所有可用資訊源中，動態拉取與當前子任務最相關的資訊，保證上下文信噪比。
        *   **類型：**
            *   **確定性選取（Deterministic Select）：** 根據預設規則加載上下文。
            *   **模型驅動選取（Model-driven Select）：** 利用模型自身能力進行篩選。
            *   **檢索式選取（Retrieval-based Select）：** 通過相似度檢索選取資訊。
    *   **3. 壓縮（Compress）：**
        *   **目的：** 在資訊進入上下文窗口之前，對資訊進行有損或無損的壓縮，用更少的Token承載最核心的信號。
        *   **策略：**
            *   **自動壓縮（Auto-compact）：** 自動總結上下文，保留最重要的部分。
            *   **修剪策略：** 硬截斷超過限度的歷史。
    *   **4. 隔離（Isolate）：**
        *   **目的：** 在多資訊流之間設置邊界，由子流程先行消化，僅上交要點資訊，視為跨流層面的一種壓縮。
        *   **例子：** 多Agent架構。
        *   **區別於壓縮：** 壓縮主要作用於單一信息流的內容，而隔離作用在多條信息流上，目的都是提升上下文中的資訊密度。

**六、 結論：**

*   上下文工程是AI應用開發從演示階段走向工業級應用階段自然產生的開發哲學與準則。
*   重心將轉向設計能夠為模型在每一步都動態組裝出完美上下文的、健壯可靠的系統。
*   理解並熟練運用寫入、選取、壓縮、隔離這四大最佳實踐，是區分AI系統究竟是演示還是可靠應用程序的關鍵要素。

**七、 模型上下文協議（MCP）：**

*   面向工具與數據的標準化接口/上下文交換協議。
*   本質上是為行動性上下文和部分信息性上下文的標準化交互所做出的努力。
*   是實現穩健的上下文工程所需的基礎設施之一。

**八、 總結：**

*   多数AI Agent的失败，并不是模型能力上的失败，而是上下文工程的失败。
*   無論是精巧的提示詞、RAG、或是MCP，它們都指向同一個目標：在模型做出決策之前，為它準備好一份恰到好處的上下文。

**九、 結束語**

這個結構化的文稿更方便閱讀和理解，也更容易提取關鍵信息和重點。您可以將其用於學習、分享或作為參考資料。

[model=gemini-2.0-flash,0]
