好的，我來幫你整理這份文稿。以下整理後的文稿更注重結構清晰、重點突出，並針對口語化的部分進行潤飾，使其更適合書面閱讀：

**標題：AI發展的「苦澀的教訓」：算力至上與通用方法的勝利**

大家好，這裡是最佳拍檔，我是大飛。

前段時間，Sora 的出現引發了廣泛關注。當時我在節目中提出一個問題：為什麼又是 OpenAI？是什麼樣的信念支持他們不斷突破？後來我發現，這並非我個人的疑問，在社交媒體上也引發了熱烈的討論。

在一篇知乎文章中，加州大學伯克利分校計算機科學博士 @SIY Z 分析了 OpenAI 成功的方法論，認為這就是通往 AGI（通用人工智慧）的方法論。此方法論建立在幾個重要的「公理」之上，包括：

*   **The Bitter Lesson (苦澀的教訓)**
*   **Scaling Law (縮放法則)**
*   **Emerging Properties (湧現性質)**

**The Bitter Lesson：算力才是王道**

「苦澀的教訓」源自機器學習先驅 Rich Sutton 於 2019 年發表的經典文章。Sutton 透過回顧人工智慧數十年來的發展歷程，提出核心觀點：**人工智慧若要長期發展，強大的算力才是關鍵。** 這裡的算力包含大量的訓練數據和大型模型。

@SIY Z 認為，在某種意義上，**強大算力加持的通用 AI 算法才是 AGI 的正道，也是 AI 技術真正進步的方向。** 大模型、大算力和大數據構成了 AGI 的必要條件，再加上 Scaling Law 這一充分條件，透過算法使它們獲得更好的結果。

值得一提的是，在 OpenAI 研究人員 Jason Wei 的每日工作時間線中，也提到了 Rich Sutton 的「苦澀的教訓」。他甚至每天早上背誦 OpenAI 章程，向優化之神祈禱，並學習《The Bitter Lesson》。

**對結果驗證的反思：來自二十年前的預見**

在關於「大語言模型是否可以作為自身結果的驗證者」的討論中，有人認為大語言模型驗證自身結果時不夠準確，甚至會導致性能下降。

有推特網友發現，Rich Sutton 在二十多年前的一篇博客中就已預見了這個問題。他指出，如果 AI 系統需要人類干預來驗證知識、檢測誤差和糾正，那麼我們永遠無法建立真正龐大的知識系統，其規模將受限於人類的監控和理解能力。

Sutton 後來回覆稱，這篇未完成的博客正是「苦澀的教訓」的原型。

**回顾《苦涩的教训》**

The bitter lesson 的核心观点是，过去70年来对人工智能研究给我们带来的最深刻的教训是，那些能够发挥计算力的通用方法终将大获成功。 这背后的根本原因就是摩尔定律，也就是计算单位成本会持续呈指数型下降这一普遍现象规律。

绝大多数的AI研究都会基于一种假设，那就是智能体可使用的计算资源是不变的，在这种情况下，发挥人类的知识就成了提升性能的主要手段。

然而，随着时间的推移，一旦放到更长的时间尺度上来看，我们将不可避免地需要大量的计算资源。虽然研究人员希望在短时间内依靠人类在某些领域的知识来取得突破，但是从长远来看，真正重要的还是计算能力的发挥。

这两种方法不是对立的，但是在实践中它们往往是此消彼长的。在一个上的投入就意味着要牺牲另一个，因为人们对某种方法的投入，往往会让他在心理上选择不断地坚持。 基于人类知识的方法通常会使程序变得复杂化，所以不能够很好地发挥计算能力。

*   **国际象棋领域：** 1997年战胜世界冠军卡斯帕罗夫的方法依靠的是大量的深度搜索。

*   **围棋领域：** 最初研究者试图利用人类对围棋特殊性的认知。但是所有这些努力一旦在大规模搜索得到有效应用之后，就显得无关紧要，甚至是错误的。
*   **语音识别领域：** 20世纪70年代采用统计方法隐马尔可夫模型 HMMs胜出。深度学习更是沿这一方向迈出的最新步伐。

以上案例证明，人类知识可能会阻碍AI算法发挥计算能力。

**「苦澀的教訓」的啟示**

The bitter lesson 带来的最重要的启示是，从长远来看，试图构建一个符合人类思维方式的系统是行不通的，基于以大规模计算为基础的搜索和学习的方法才会有突破性的进展。

通用方法具有强大的力量，而且会随着算力的增加继续扩展，只有搜索和学习这两种方法能够做到如此无限的扩展。

The bitter lesson带来的第二个重要启示是：意识的真实内容是极其复杂和深邃的，我们应当停止寻找想要简化理解意识思考的方法。相反，我们应该只构建那些能够发现并捕捉这些任意复杂性的元方法，而不是仅仅包含我们所发现的东西。

**總結**

建議所有從事 AI 行業的朋友們可以經常回顧「苦澀的教訓」，時刻清晰地認識到，人工智慧並不是要按照人類的思考方式去構建系統，而是要透過發揮海量的計算能力，讓它自己學會發現新的知識。這也是 Scaling Law 縮放法則的由來吧。

感謝收看本期節目，我們下期再見！

**改進說明：**

*   **更明確的標題：** 突顯主題，吸引讀者。
*   **更清晰的結構：** 使用標題和子標題，將內容分成邏輯段落。
*   **重點突出：** 使用粗體字強調關鍵概念和結論。
*   **潤飾口語化表達：** 替換一些口語化的詞語和句子，使其更符合書面語規範。
*   **補充說明：** 針對部分概念進行更詳細的解釋，例如 AGI。
*   **案例簡潔化：** 将案例用更简洁的文字表达出来。

希望這個整理後的版本更符合您的需求！

[model=gemini-2.0-flash,0]
