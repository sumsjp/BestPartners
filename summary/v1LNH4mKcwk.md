好的，這是我根據您提供的文稿整理後的版本。我力求保留原文的信息，並使其更易於閱讀和理解。主要改進包括：

*   **分段更清晰：** 將內容按照主題和邏輯關係進行分段，使結構更清晰。
*   **標題和小標題：** 添加了標題和小標題，幫助讀者快速了解每個部分的主要內容。
*   **重點詞加粗：** 重要的概念和術語進行加粗，方便快速瀏覽。
*   **語言更流暢：** 稍微調整了部分語句，使表達更自然流暢。
*   **移除口語化詞語：** 將一些口語化的詞語替換成更書面化的表達。

**整理後的文稿：**

# Scaling Laws：人工智能發展的核心引擎 (基於 Jason Wei 的演講)

大家好，這裡是最佳拍檔，我是大飛。今天想和大家分享 OpenAI 研究員 Jason Wei 在 CIS 7000 上的演講，主題是 **Scaling Laws (縮放法則/擴展定律)**。

Jason Wei 畢業於史丹佛，曾在 Google Brain 工作三年，是 **CoT (思維鏈)** 的作者，也為 o1 模型做出了很大貢獻，在社交媒體上也比較活躍。他的演講深入淺出，值得分享。

在過去幾年，人工智能能取得如此矚目的突破，**Scaling Laws** 扮演了核心引擎的角色。那麼，它究竟如何推動了人工智能的發展？又是否將繼續推動向前發展呢？讓我們一起看看 Jason Wei 的觀點。

## 1. Scaling Laws 的演進

在 2010 年到 2017 年，也就是 **Transformer 架構**和 **深度學習** 尚未得到廣泛應用之前，人工智能的進步主要依賴於針對特定評估基準的優化，例如 **ImageNet**。研究人員會嘗試各種方法，比如構建更優的架構、引入歸納偏差、改進優化器以及精心調整超參數等等，目標是在基準測試中超越基線性能。

然而，**Transformer 的出現改變了這個局面**，它為學習多種類型的關係提供了強大的工具，使得 **Scaling** 成為人工智能發展的新方向。

### 什麼是 Scaling？

在人工智能領域，**Scaling 並非指的是簡單地增加計算資源、數據量或者模型大小。** 更準確地說，它是將自身置於一種沿着連續軸移動，並且期望持續獲得性能改進的情境之中。通常情況下，這個連續軸會涉及計算量、數據量或者模型大小等關鍵的因素。以大語言模型的發展為例，可以看到 Scaling 無處不在。

在許多相關研究論文中，都有關於 **Scaling Laws** 的圖表展示。這些圖表清晰地呈現了隨著模型參數數量、訓練數據量以及計算資源的增加，模型性能的變化趨勢。

## 2. Scaling 面臨的挑戰

早期，Scaling 面臨著許多巨大的挑戰：

*   **技術和運營層面：** 分布式訓練需要深厚的專業知識，構建一個高效的分布式訓練系統，需要聘請大量的專業工程師來應對複雜的技術難題。同時，機器學習的研究人員也需要時刻警惕可能出現的損失發散和硬件故障問題，確保訓練過程的穩定。
*   **計算成本高昂：** 大規模的 Scaling 需要投入大量的計算資源，這對於許多研究機構和企業來說是一個沉重的負擔。
*   **心理層面：** 研究人員長期以來習慣於利用歸納偏差來改進算法，他們從提出假設並驗證性能提升的過程中獲得樂趣，因此對於單純的 Scaling 工作可能缺乏足夠的熱情。而且，人類學習的高效性也讓人們對於讓機器通過大規模數據進行學習的必要性產生了質疑。
*   **科研激勵機制：** 學術會議更傾向於接受具有新穎算法的研究成果，而只是擴大數據集和計算資源的工作往往難以得到足夠的認可。

## 3. 堅持 Scaling 的理由

既然 Scaling 面臨著如此多的困難，為什麼我們仍然要堅持走這條路呢？因為在非 Scaling 的範式下，模型的每一次改進都需要全新的獨創性思維，這就需要投入大量的研究精力，而且成功並不是必然的，具有很大的不確定性。

相比之下，以 Scaling 為中心的人工智能雖然成本高昂，卻提供了一種相對可靠地提升模型能力的方法。特別是當我們衡量模型能力的标准具有较高的通用性时，這種大規模的投資往往是值得的。比如，我們希望模型能夠在多個領域和任務中表現出色，那麼通過 Scaling 來提升模型的通用能力，就是一個合理的選擇。

## 4. Scaling 的兩種範式

Jason Wei 深入探討了兩個 Scaling 範式：

### 4.1 Scaling 下一個詞的預測

這個範式始於 2018 年，至今仍然在發揮著重要的作用。這個範式的核心原理就是通過大規模的多任務學習，來實現對下一個詞的精準預測。

想像一下，語言模型面對一個句子，比如“在週末，達特茅斯的學生喜歡”，它會對詞彙表中的每個單詞（從 A 到 Z 打頭）計算出一個出現的概率，然後根據實際的下一個詞來調整這些概率，從而不斷地進行學習和優化。

通過這種方式，語言模型能夠學習到多種能力，例如：

*   **語法學習：** 例如，在預訓練過程中遇到“在我的空閒時間，我喜歡去｛編碼，香蕉｝”這樣的句子，模型會逐漸認識到在這個語境下動詞“編碼”的可能性更高，從而學習到相應的語法規則。
*   **世界知識的獲取：** 當遇到“阿塞拜疆的首都是｛巴庫，倫敦｝”這樣的句子時，模型會提高“巴庫”的權重，進而積累關於世界地理的知識。
*   **電影評論的情感分析：** 比如“我一直全神貫注，非常投入，這部電影真的是｛好，壞｝”，模型可以學習到如何判斷情感傾向。
*   **翻譯任務：** “神經網絡在俄語中的單詞是 {нейронная, сетьпривет}”，模型能夠掌握不同語言之間詞彙的對應關係。
*   **空間推理：** 通過“艾洛去廚房泡茶，祖克站在艾洛旁邊，思考他的命運，然後祖克離開了 ｛廚房，商店｝”這樣的句子，模型可以學習到空間位置的推理能力。
*   **數學運算：** 對於“三加四加八等於 {15, 11}”這樣的例子，模型也能逐漸學會正確的計算結果。

**卡普蘭等人於 2020 年發表的論文推廣了下一個詞預測中的 Scaling 範式，提出了 Scaling Laws**。這個定律表明，隨著模型大小、數據集大小以及訓練計算資源的增加，下一個詞的預測能力（也就是語言模型的性能）會平穩地提升。研究人員通過使用七個數量級的計算量進行訓練驗證，發現這個趨勢非常穩定，而且沒有出現性能飽和的現象。這個發現極大地增強了研究人員繼續擴大規模的信心。

**為什麼 Scaling 能夠取得如此好的效果呢？** 對於小型的語言模型而言，由於參數有限，記憶成本非常高，所以在知識編碼方面必須非常謹慎。而大型的語言模型擁有大量的參數，在學習尾部知識和記憶大量事實方面具有更大的優勢。此外，小型模型在單次前向傳遞中的計算容量較低，主要學習一階相關性，而大型模型在擁有更多計算資源的情況下，可以學習複雜的啟發式方法，從而更好地處理各種任務。

**湧現能力 (Emergent Abilities) 或相變 (Phase Transition)：**

儘管 Scaling Laws 具有一定的可預測性，但是 ChatGPT 的成功仍然讓許多人感到驚訝，因為對下一個詞的預測實際上是一種大規模的多任務學習，不同任務的能力提升速度並不相同。我們可以將下一個詞的預測準確性看作是多個子任務準確性的加權總和。

例如，GPT-3.5 的語法已經近乎完美，在後續訓練 GPT-4 的時候，語法方面的性能提升可能微乎其微；而在數學能力方面，GPT-3 和 GPT-2 表現較差，但是 GPT-4 卻有了巨大的飛躍。

以翻譯任務為例，當給定提示“我喜歡踢足球和網球”，並要求翻譯成西班牙語的時候，較小的模型 Adam 和 Babbage 可能只是重複答案，無法正確完成翻譯，而最大的模型 Curie 卻能夠突然學會並且完美地執行這項任務。這表明在模型規模達到一定程度後，一些原本難以完成的任務會突然變得可行，模型的能力出現了質的提升。

**局限性：**

僅僅通過 Scaling 下一個詞的預測，就想要實現 AGI 的想法可能會面臨巨大的挑戰，因為對某些詞的預測非常困難，需要進行大量的計算和複雜的推理。

比方說，在面對一個數學問題“什麼是 ((8 - 2) * 3 + 4) ^ 3 / 8 的平方？”時，為了預測下一個詞（也就是正確答案 A、B 或 C），模型實際上需要完成整個數學計算過程，這對於單純的下一個詞預測來說是一個巨大的瓶頸。

**思維鏈提示 (Chain-of-Thought Prompting)：**

為了解决這個問題，研究人員提出了 **思維鏈提示** 的方法。這種方法類似於我們在解決數學問題時向老師展示解題的過程，要求語言模型在給出最終答案之前輸出推理鏈。實踐證明，這種方法在數學應用題基準測試中效果顯著，能夠大幅提升模型的性能，並且隨著模型規模的擴大，性能提升效果更加明顯。

不過，思維鏈提示也存在一定的局限性。在互聯網上的大部分數據中，模型訓練所依據的推理過程往往是事後總結的，而不是真實的思維過程。我們真正希望模型能夠模擬人類的內心獨白或者思想流。但是目前的訓練數據還難以完全滿足這一要求。

### 4.2 在思維鏈上去 Scaling 強化學習

這就引出了第二個 Scaling 範式，那就是 **在思維鏈上去 Scaling 強化學習**。這個範式的核心思想是訓練語言模型在給出答案之前進行思考。除了像傳統的擴展訓練計算量之外，還增加了一個新的維度，也就是擴展語言模型在推理時可以思考的時間長度。

**o1 模型：**

OpenAI 发布的 **o1 模型** 就是這個範式的典型代表。在解决化学问题的时候，o1 模型会首先明确问题，比如“首先，让我们理解一下问题是什么”，然后逐步分析问题，确定存在哪些离子，考虑不同的计算策略，不断回溯和调整思路，最终得出正确答案。

**驗證不對稱性問題 (Asymmetric Verification Problems)：**

在填字遊戲、數獨等具有驗證不對稱性的問題上，o1 模型也表現出色。所謂驗證不對稱性問題，就是驗證一個解決方案比生成一個解決方案要容易得多。

在需要大量思考才能够获得良好表现的问题上，o1 模型相比 GPT-4o 有了巨大的提升。這表明在思維鏈上 Scaling 強化學習的範式，為模型處理複雜問題提供了更强大的能力。

**未来展望：**

從長遠來看，我們希望人工智能能夠幫助我們解決人類面臨的一些最具挑戰性的問題，比如聽力疾病、環境保護等等。在未來，我們可以想像為一個非常具有挑戰性的問題提供一個提示，例如撰寫一篇關於讓 AI 更安全的最佳方法的研究論文，語言模型可以在推理時分配大量的計算資源，經過長時間的思考和分析，最終返回一個全面的答案和研究成果。

## 5. Scaling Laws 對 AI 文化的影响

隨著 Scaling Laws 在人工智能領域的廣泛應用，它也深刻地改變了 AI 文化。

*   **數據方面：** 過去研究人員主要致力於改進神經網絡來學習特定的 XY 關係，而現在的重點更多地轉向了收集更好的 X 和 Y 集合。
*   **評估方法上：** 目前行業中存在一個急需解決的問題，那就是缺乏能夠準確捕捉語言模型能力邊界的評估方法。我們需要更加完善和多樣化的評估方法，來準確評估模型的性能和進步。
*   **模型類型上：** 出現了從單一任務模型向高度多任務模型的轉變。過去，每個自然語言處理任務都需要單獨的模型，而現在一個模型可以嘗試完成多種不同的任務。
*   **團隊規模上：** 构建像 o1 或者 Gemini 这样的大型模型则需要一个庞大的团队。

## 6. 人工智能的未来展望

Jason Wei 展望了一下人工智能的未来，認為 AI 在多個方向上有着巨大的發展潛力，比如在科學和醫療保健領域、減少模型的幻覺方面、多模態，以及 AI 對工具的使用。

另外，未來要重點關注的一個點在於人工智能的應用落地。我們需要進一步縮小技術前沿與實際應用之間的差距，讓人工智能真正造福人類社會。

好了，以上就是 Jason Wei 這次演講的主要內容了，希望能讓大家更好地理解 Scaling Laws 的歷史和發展。

感謝大家的觀看，我們下期再見！

**說明：**

這個版本已經盡可能地做了優化，希望能符合您的需求。如果您對某些部分有具體的修改意見，請隨時提出，我會盡力調整。

[model=gemini-2.0-flash,0]
