好的，作為您的專業文件整理員，我已將這份深度訪談文稿進行了結構化整理，提煉出核心要點，並以清晰的中文呈現。

---

## 訪談摘要：約翰·舒爾曼（John Schulman）深度訪談——揭秘OpenAI崛起之路與AI未來洞察

**受訪者：** 約翰·舒爾曼 (John Schulman)
*   OpenAI 創始元老
*   PPO 算法之父
*   RLHF 架構靈魂人物
*   現任新公司 Thinking Machines 創辦人

**核心主題：** OpenAI 崛起、AI 研究本質、強化學習趨勢、AGI 時間線、新公司 Thinking Machines 重磅產品 Tinker。

### 一、 顛覆性觀點：算力並非AI發展的唯一瓶頸

**1. 算力迷思的挑戰：**
*   **普遍共識：** 大模型成功依賴海量算力堆砌，算力是衡量AI實力的唯一標準和創業門檻。
*   **舒爾曼觀點：** 算力從來不是唯一的瓶頸。
    *   **驚人預言：** 若回到2018年，只需2-3人，幾台V100顯卡，一年內可達成接近GPT-3.5水平的模型。
    *   **案例支持：** Nanochat項目（一人獨立開發半年，單台H100顯卡運行，接近GPT-3.5效果）。即使是2018年的V100，通過聯網幾台GPU、結合成熟的後訓練與微調技術，小團隊也能實現類似效果。

**2. 技術巧思彌補算力：**
*   **關鍵洞察：** 很多人誤以為只有超大模型才能打造優秀的少樣本聊天模型。
*   **實際路徑：** 優化後訓練流程能大幅提升計算資源利用效率；投入大量精力微調並巧妙構建數據集，小規模模型也能達到不錯效果。
*   **OpenAI 的啟示：** 當年OpenAI未能更早推出ChatGPT，並非算力不足，而是缺乏成熟的後訓練與微調技巧，只能訴諸於「堆算力」這種更粗暴的方式。
*   **成功前提：** 需預見最終技術路徑和目標方向，並利用前人已完成的預訓練數據集。
*   **未來展望：** 演示級的ChatGPT訓練流程可能只需一個文件，自動爬取網絡數據，一天內完成訓練。
*   **結論：** AI的進步不僅是算力的獨角戲，技術創新和方法優化同樣重要，為初創公司和研究者帶來希望。

### 二、 OpenAI早期發展：從非正式小組到巨頭的蛻變

**1. 草創時期（2016年）：**
*   **組織形態：** 鬆散的學術研究小組，成員基於個人興趣工作，壓力不大。
*   **工作模式：** 一到三人小團隊，成果多為論文或博客，無明確商業化目標。
*   **遠大抱負：** 堅信透過專業工程實踐和大規模項目團隊能取得更大突破。
*   **主要影響：** 深受DeepMind AlphaGo 項目中研究人員與工程師協同工作模式的啟發。
*   **發展策略：** 小型研究與大型項目並存，整合研究人員與工程師力量。

**2. 探索與失敗的積累：**
*   **普遍現象：** 大多數研究項目未能成為主流，部分大型項目以失敗告終。
*   **典型案例——Universe項目：**
    *   **目標：** 創建大量強化學習環境，構建通用數據集，期望模型具備泛化能力，打造卓越AGI。
    *   **失敗原因：** 「生不逢時」，超前十年，必要前提條件不具備（系統難操作、模型從零訓練泛化能力差）。
    *   **價值：** 雖未成功，但為後續強化學習研究積累經驗，啟發團隊專注於簡化後的模擬遊戲任務。
*   **其他項目：** 機器人相關研究等死胡同項目。
*   **長期價值：** 這些項目為OpenAI積累了寶貴的大型工程與研究經驗，培養了人才，為ChatGPT等產品的成功奠定了基礎。

**3. 首個成功案例——Dota項目：**
*   **特點：** 投入大量計算資源，涉及機器學習系統開發、大型代碼庫、特定場景強化學習。
*   **工程挑戰：** 環境基礎設施搭建（接入Dota、構建訓練環境）與訓練系統開發（大規模部署、并行訓練、異步強化學習）。兩者需緊密配合。

### 三、 研究管理：平衡自主與目標導向

**1. 研究管理者模型：**
*   **挑戰：** 管理性格各異、能力突出的專業人才。
*   **舒爾曼觀點：** 理想管理者無統一模板，領域不斷變化，早期成功經驗現已不適用。
*   **兩種成功模式：**
    *   **親力親為型：** 撰寫代碼、審閱代碼、提供詳細技術反饋。
    *   **放手型：** 智囊團角色，提供職業發展建議，保持團隊積極性與滿意度，賦予自主權。
*   **適用場景：**
    *   **放手型：** 探索性研究、經驗豐富的獨立貢獻者。
    *   **親力親為型：** 目標導向項目、經驗不足團隊、需執行明確任務。

**2. OpenAI的管理靈感來源：**
*   **非傳統：** 並非刻意借鑒貝爾實驗室、施樂帕洛阿爾托研究中心等歷史機構。
*   **主要影響：** 成員過去的工作經驗（研究生階段、Google Brain、DeepMind），谷歌和DeepMind的工作方式影響最大。
*   **借鑒：** 曾討論過曼哈頓計劃等大型項目，但更多在實踐中摸索。

### 四、 Thinking Machines 與 OpenAI 的異同

**1. 相似之處：**
*   多個項目同時推進。
*   公司願景在不斷成型中。

**2. 核心差異（行業發展階段）：**
*   **OpenAI早期：** 處於「和平時期」，行業缺乏一致競爭方向和發展路徑，更多探索性工作。
*   **Thinking Machines（當前）：** 行業發展迅速，競爭激烈，面臨「追趕模式」壓力，需先複製現有技術再創新。
*   **舒爾曼策略：** 確保 Thinking Machines 兼顧追趕與探索性研究能力的積累，避免日後難以培養創新文化。

### 五、 強化學習（RL）未來趨勢洞察

**1. 價值函數的命運：**
*   **現狀：** 在許多RL研究中不再流行，引發「過時」質疑。
*   **舒爾曼：** 否認過時。其主要作用是減少方差且效果顯著，預計未來會重新流行。

**2. 持續學習的難題：**
*   **重要性：** AI走向實用化的關鍵，需模型不斷學習新知而不遺忘。
*   **舒爾曼：** 學習有多種含義（情景記憶、新知學習、程序性記憶），需不同方法支持。
    *   **趨勢：** 上下文相關方法、上下文管理技術將持續發展；長上下文處理能力更重要。
    *   **LoRA技術：** 作為補充或參數微調基礎，對特定類型記憶更有效（需大量容量、吸收大量知識）。
    *   **解決方案：** 可能非單一。儘管擴大模型規模可持續改善，但舒爾曼更傾向於新思路能更快解決問題，帶來不同縮放定律，或更有效率的持續學習能力。
    *   **應用場景：** 上下文學習對短時跨度有效；權重更新對長時跨度優勢；參數微調處於中間。

**3. 泛化能力的脆弱性：**
*   **問題：** 模型在預訓練階段表現好，但在RL應用中受限於特定領域，跨領域遷移差，是否阻礙AGI？
*   **舒爾曼：** 難以明確結論。上下文學習樣本效率可能比人類高，但某些訓練需遠超人類數據量。
    *   **人類優勢：** 進化使其適應長時跨度，具備自我糾正機制，目標激發後足智多謀。
    *   **模型不足：** 處理大量工作時易陷入困境。
    *   **解決方案：** 利用模型推理與指令遵循能力，為生成模型提供學習信號，形成「良性循環」（模型越好，驗證器越好）。

**4. 協同訓練與博弈前景：**
*   **舒爾曼偏好：** 多智能體訓練或博弈相關理念（零和博弈、多人博弈）。
*   **優點：** 帶來良好屬性（如自動課程學習——與自身複製體對抗時，對手同步變強）。
*   **理論基礎：** 從理論計算機科學角度，設計博弈可解決複雜問題（如雙人零和博弈的均衡點）。
*   **應用：** 對齊相關文獻（辯論博弈），舒爾曼認為非常有說服力，預計其重要性日益增加。

### 六、 AGI時間線：持續低估與加速發展的權衡

**1. 時間線低估的偏見：**
*   **觀察：** 工程師和研究人員普遍低估小型項目完成時間（需乘以3倍）。AGI是否也存在？
*   **舒爾曼：** 完全認同存在「持續低估時間線」的偏見（可能需乘以2-3倍）。類比自動駕駛汽車，實際完成時間遠超預期。

**2. AI加速發展的影響：**
*   **另一面：** AI本身會加速發展，可能超出人們直覺。考慮此效應者會給出較短時間線。
*   **舒爾曼立場：** 對於AI發展帶來的提升存在不確定性，對人類理解能力等瓶頸也不確定。故不對任何預測過於自信。

### 七、 Thinking Machines 與 重磅產品 Tinker

**1. Tinker 的核心定位與功能：**
*   **公司：** 舒爾曼創辦的新公司 Thinking Machines。
*   **產品：** Tinker，定位為「底層微調API」。
*   **目標：** 徹底改變AI模型微調規則。
*   **功能：** 提供一套小型底層原語，用於執行訓練和採樣任務。
    *   用戶幾乎可實現所有後訓練算法，無需擔心GPU/加速器問題，也無需處理複雜的分佈式系統。
    *   將「值得抽象的良好層級」構建為一項服務（類似OpenAI/Anthropic的採樣API）。
    *   用戶可編寫Python腳本完成大量訓練代碼，無需安裝大量GPU相關依賴。

**2. 目標用戶與發展願景：**
*   **初期用戶：** 適合想深入了解細節的研究者/開發者（提供大量開源代碼）。
*   **未來願景：** 變得更容易使用，構建更多工具和高層級組件，成為全棧解決方案。
    *   用戶只需明確業務問題或模型規格，Tinker軟件即可實現。
    *   讓初創公司無需開發自身基礎設施，直接在Tinker之上構建複雜定制模型並規模化。
    *   大幅降低AI創業門檻，讓更多人專注模型創新與應用落地。
*   **公司規劃：** 明年推出自家模型，持續改進Tinker，添加多模態訓練、輸入輸出等功能，大幅提升任務規模。

**3. 設計理念：**
*   **初心：** 讓AI研究與開發更高效、普惠。
*   **核心理念：** 「算力不是唯一的瓶頸，技術方法的優化同樣重要」——Tinker通過優化微調流程和工具，賦能更多人參與AI創新。

### 八、 舒爾曼的個人習慣與研究洞察

**1. AI工具輔助研究：**
*   **日常使用：** 頻繁使用 Cursor、Claude Code 等AI工具。每天打開多個模型聊天窗口，提問多次。
*   **用途：** 輔助編程、查找答案、充實模糊想法、文獻檢索（大幅提升效率）、查找開源庫。
*   **輔助寫作：** 作為第一輪反饋來源（但主要思考工作仍由自己完成）。

**2. 工作日常：**
*   **思考階段：** 經常去咖啡館思考，喜歡周圍有活動的氛圍，攜帶筆記本，遠離干擾，記錄想法。
*   **執行階段：** 親自參與時編程，或大量閱讀文檔、消息、圖表和代碼。
*   **當前職責：** 花費大量時間進行研究指導，審閱他人研究成果。

**3. AI研究進步速度的思考：**
*   **現象：** 自2020年縮放定律出現以來，研究人員數量增長數十甚至百倍，但重大突破性想法產生速度似乎穩定。
*   **舒爾曼觀點：**
    *   量化科學進步速度困難，難以輕易下結論。
    *   **觀察：** 70-90年代論文實驗嚴謹性較低，如今標準已提高（基準方法、大量實驗）。
    *   **結論：** 想法產生速度實際已大幅提升，某些方面標準與質量也有提高。
    *   **人才分佈變化：** 準入門檻提高（競爭激烈）。工程技能重要性更高，研究品味重要性相對下降（規模化帶來進步，簡單想法高效執行即有成果）。
    *   **協作趨勢：** 更多在他人代碼庫和優質基礎設施上開發，軟件工程背景者更具優勢。

### 九、 總結：技術方法與研究品味的勝利

**1. 核心論點：** AI的未來是技術方法和研究品味的勝利，而非單純的算力堆砌。
**2. 支撐依據：**
    *   **ChatGPT 案例：** 算力非唯一瓶頸，成熟後訓練與巧妙微調數據同樣重要。
    *   **OpenAI 早期失敗：** AI進步非一帆風順，超前想法需合適時機與前提。
    *   **強化學習趨勢：** 被遺忘的經典理念（如價值函數、博弈）將回歸，因其堅實的理論基礎。
    *   **Tinker 產品願景：** 技術創新核心在於降低門檻、提升效率，普惠AI創新。
**3. 舒爾曼的期望：** 透過技術創新，讓AI研究與開發更高效、普惠，激發更多人參與AI創新，這將是AI行業發展的新增長點。

---

[model=gemini-2.5-flash,0]
