好的，我為您整理了這篇文稿：

**主旨：蘋果公司低調佈局AI，或將於2024年有所動作**

**引言：**

*   科技圈公認五巨頭：蘋果、微軟、Google、Meta、亞馬遜。
*   在OpenAI和微軟帶起的AI風潮下，Google、Meta、亞馬遜紛紛推出AI技術，唯獨蘋果看似置身事外。

**蘋果的AI佈局：**

*   **檯面下的準備：** 彭博社記者爆料，蘋果內部早已組建AI研究團隊，準備投入AI領域。
*   **「Apple GPT」：** 蘋果內部創建了類似ChatGPT、Bard的聊天機器人服務，內部工程師稱之為「Apple GPT」，基於蘋果自主構建的Ajax架構開發。Ajax是蘋果去年為了統一機器學習而創建的系統框架，底層基於Google Jax。
*   **現有服務的AI應用：** 蘋果的搜索、Siri、地圖等服務已經基於Ajax做出了一些與人工智能相關的改進。
*   **未來方向：** 蘋果的下一步是用Ajax來開發大語言模型。
*   **庫克的表態：** 庫克表示不會評論產品路線圖，但承認生成式AI的潛力巨大，同時認為AI目前還有不少問題有待解決。
*   **團隊發展：** 該團隊在去年年底就已經成立，且規模不斷擴大。
*   **安全考量：** 「Apple GPT」一度因安全問題被叫停，後續仍允許推展。內部使用需經特殊審批，並嚴格警告不能用於開發面向用戶的功能。
*   **目前功能：** 「Apple GPT」經過訓練後，可以總結文本和回答問題，協助工程師開發產品原型，功能上與ChatGPT、Bard沒有太大區別。
*   **發布計畫：** 蘋果目前沒有向消費者公布該產品的計畫，但內部人士透露稱，蘋果可能會在2024年發布與AI相關的重要說明。
*   **合作計畫：** 蘋果還計劃與OpenAI合作，簽訂大合同，具體內容未知。

**蘋果AI的現狀：**

*   **低調宣傳：** 蘋果很少公開提及AI概念，常用「機器學習」代替。
*   **AI已融入生態：** AI已融入蘋果生態的每個角落，在WWDC 2023後的新版系統中尤其明顯。
*   **具體應用：**
    *   iOS 17：蘋果輸入法獲得AI加持，具有自動糾正功能，能預測用戶想要打出的文字，並學習用戶的輸入習慣。
    *   AirPods Pro：通過機器學習實現自適應音訊模式，在識別到外部特定聲音時，自動切換降噪模式和通透模式。
    *   iPadOS 17：利用機器學習模型識別PDF中的字段，快速填寫相關信息。
    *   Journal：利用機器學習技術，根據用戶近期的活動智能記錄生活瞬間，並自動添加詳細信息。
    *   Vision Pro：使用基於「編碼器-解碼器」的神经网络。
    *   iOS 17和iPadOS 17：動畫效果使用AI技術，通過機器學習模型合成額外的動畫幀。
    *   iOS 17 Public Beta：「聲音克隆」功能，可以學習用戶的聲音，生成與音色相近的AI聲音（目前僅支持英語）。

**未來展望與挑戰：**

*   **AI策略：** 蘋果對機器學習的宣傳重點是「基於本地運行」和「保護隱私」。
*   **內部意見：** 蘋果在押注大語言模型之後，是否會像微軟和Google那樣激進地部署AI功能，內部尚未達成共識。
*   **領導者：** 與機器學習相關的項目由約翰·詹南德雷亞 (John Giannandrea)和克雷格·費德里吉 (Craig Federighi)共同領導。約翰·詹南德雷亞希望先觀望AI的演變，用更保守的方式發展。
*   **Siri的可能升級：** Siri可能成為整合大語言模型的落腳點，提升其智能水平。
*   **競爭壓力：** 如果Google完善AI安全限制措施，將Bard率先應用於Google Assistant，將對Siri形成降維打擊。
*   **刻不容緩：** 蘋果部署大語言模型不僅十分必要，而且刻不容緩。
*   **未來應用：** 或許我們很快就能看到在手機上部署大語言模型的應用。

**結語：**

*   蘋果的AI聊天機器人最終會是什麼樣子，值得期待。

**整體而言，整理後的文稿更具條理，重點突出，方便讀者快速了解蘋果公司在AI領域的動態和未來發展方向。**

[model=gemini-2.0-flash,0]
