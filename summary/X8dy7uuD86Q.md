好的，以下是經過整理的文稿：

**主題：南洋理工大學團隊解決AI影片「閃爍」問題**

**簡介：**

*   大飛（最佳拍檔）介紹南洋理工大學團隊如何解決AI生成影片的「閃爍」問題，該問題是目前AI生成影片的最大瓶頸之一。

**問題描述：**

*   AI影片的「閃爍」是由於前後幀不連貫所導致。
*   AI對每一幀圖片的處理結果都不一樣，導致影片中的物體、人物變換不同，細節差異大。
*   現有AI影片技術依賴關鍵幀，幀與幀之間的聯繫不緊密。

**解決方案（南洋理工大學團隊提出的框架）：**

*   **核心目標：** 提升AI生成影片時，幀與幀之間的連貫性。
*   **框架組成：**
    *   **關鍵幀翻譯 (Key Frame Translation)：**
        *   基於擴散模型生成關鍵幀。
        *   利用跨幀約束，加強關鍵幀之間的一致性。
    *   **完整影片翻譯 (Full Video Translation)：**
        *   通過基於時間感知的匹配算法，將其他幀與關鍵幀「連接」起來。
*   **核心方法：** 分層跨幀一致性約束
    *   利用光流約束幀與幀之間的關係。
    *   第一幀作為整個影片的「錨點」，控制整體走向。
    *   後續每一幀以前一幀作為參考，防止偏離最初的風格、形狀、紋理和顏色。
*   **生成模型：** 經過改進的 Stable Diffusion + ControlNet 的組合。
    *   調整了Stable Diffusion等擴散模型採樣過程。
    *   在不同採樣階段，採用不同的跨幀約束 (例如：形狀感知、像素感知)。

**框架優勢：**

*   **零樣本學習：** 輸入新影片時，無需重新訓練。只需提示詞 + 影片，即可自動將影片「翻譯」成想要的效果。
*   **效率高：** 關鍵幀生成速度約 14.23 秒，非關鍵幀約 1.49 秒/幀。
*   **效果好：** 影片流暢，鬼影少。

**影片控制：**

*   可以通過更改提示詞中的關鍵字，在幾乎不改動其他元素的情況下，生成新的影片（例如：換髮型、換風格、換頭）。

**效果評估：**

*   由 23 名志願者對生成影片的質量進行綜合評分，結果良好。評估指標包括：
    *   提示詞和輸入幀的關聯度
    *   時間一致性
    *   影片整體質量

**研究團隊：**

*   **楊帥：** 南洋理工大學助理教授，研究方向為人像編輯、文本風格化、圖像翻譯等。北京大學本科、博士。
*   **周弈帆：** 南洋理工大學研究工程師，北京理工大學本科，ACM-ICPC 金牌，研究方向包括文本挖掘、基於機器學習重建入射光場等。
*   **劉子緯：** 南洋理工大學助理教授，香港中文大學博士，研究方向是計算機視覺、機器學習和計算機圖形學等。
*   **呂健勤 (Chen Change Loy)：** 南洋理工大學和香港中文大學副教授，研究興趣集中在計算機視覺和深度學習方向，包括圖像、影片恢復和生成以及表徵學習等。

**總結與展望：**

*   該技術朝製作影片、生成電影邁出了一大步。
*   持續穩定的圖像畫面，將提供更好的觀影體驗。
*   期待未來能有完全由AI生成的，接近我們現在觀影效果的影片。

**補充說明：**

*   該項目的程式碼尚未開源，但論文表示「會有的」。

**結尾：**

*   歡迎訂閱頻道，下期再見。

**整理說明：**

*   我將文稿分段整理，使其更有結構性。
*   提煉出關鍵資訊，並以更簡潔的語言表達。
*   使用粗體和項目符號，以突顯重點。
*   更正了一些語法錯誤和表達方式。
*   修改了少量語句，使其更易於理解。

希望這個整理版本對您有幫助！如果您有其他需求，請隨時提出。

[model=gemini-2.0-flash,0]
