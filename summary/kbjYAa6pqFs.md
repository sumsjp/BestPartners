好的，這是我整理後的文稿。我著重在讓文章結構更清晰、重點更突出，並且修改了一些口語化的表達方式，使其更適合閱讀：

**標題：Google Gemma 2：新一代開源大語言模型的突破與解析**

大家好，這裡是最佳拍檔，我是大飛。

繼上週介紹 Claude 3.5 Sonnet 後，Google 又在 AI 領域投下震撼彈。Google DeepMind 的研究副總裁 Clement Farabet 和主管 Tris Warkentin 聯袂發文，正式宣布 Gemma 2 向所有研究人員和開發者開放。讓我們一同深入了解 Gemma 2 的突破性進展。

**一、Gemma 2 簡介**

Gemma 2 是 Google 最新的開放大語言模型，提供兩種規模：9B 參數和 27B 參數，各有預訓練基礎和指令調優版本，共計四個版本。

*   **性能提升，部署要求降低：** 與上一代 Gemma 相比，Gemma 2 的性能大幅提升，但部署要求顯著降低，只需一塊 NVIDIA H100 Tensor Core GPU 或 TPU 主機即可使用。
*   **易於使用：** 即使硬體不達標，也能在 Google AI Studio 中使用 Gemma 2，測試 27B 參數版本的全部功能。Kaggle 和 Hugging Face Models 也提供 Gemma 2 模型下載。
*   **免費使用：** Google 強調 Gemma 2 提供免費的使用方式，用戶可透過 Kaggle 或 Colab 筆記本免費使用。學術研究人員可申請 Gemma 2 的學術研究計畫，獲得 Google Cloud 的信用額度，加速研究。申請至 8 月 9 日截止。
*   **寬鬆的授權許可：** Gemma 2 沿用第一代授權許可，幾乎沒有限制，允許用戶進行分發、微調、商業用途和創作衍生作品。

(大飛會把4個模型的地址都放在視頻簡介中， 感興趣的朋友可以去下載試試了)

**二、Gemma 2 的技術創新**

Gemma 2 在架構和訓練數據量方面都進行了全面改良。

*   **架構改良：**
    *   **局部滑動窗口注意力 + 全局注意力：** 使用局部滑動窗口注意力 (4096 token) 減少記憶體和時間消耗，並結合全局二次注意力 (8192 token) ，在保持長上下文長度的前提下，提高輸出品質。即使 token 數量過半，模型仍能有效關注所有 token。
    *   **軟上限 (Soft Cap)：** 在最終層和每個注意力層使用軟上限，防止 logits 過度增長而無法截斷，穩定訓練。雖然軟上限與 Flash Attention / SDPA 不相容，但仍可用於推理，且即使不使用軟上限，輸出結果差異也很小。
*   **訓練數據迭代：**
    *   **數據量翻倍：** 27B 版本使用 13 萬億 token，9B 版本使用 8 萬億 token 的網頁數據。
    *   **數據構成：** 主要由英語語料、程式碼和數學數據構成。
    *   **訓練策略：** 在預訓練階段，Gemma 2 在文本合成、英語合成和人類生成的提示、響應對上應用監督式微調 (SFT)，再基於偏好數據訓練獎勵模型，並進行基於相同提示的 RLHF 強化訓練。
    *   **知識蒸餾 (Knowledge Distillation)：** 9B 參數模型採用知識蒸餾進行預訓練，27B 參數模型則從頭開始預訓練。後期訓練中，團隊生成來自教師模型的多樣化補全集，並使用這些合成數據透過 SFT 訓練學生模型。

**三、知識蒸餾的優勢與挑戰**

*   **優勢：** 知識蒸餾是一種常用於訓練較小學生模型、模仿較大教師模型的策略。它能提供更豐富的學習信號，加速模型訓練。
*   **挑戰：** 學生和教師模型容量不一致可能導致訓練和推理過程中文本的不匹配。
*   **解決方案：** Gemma 2 團隊採用「線上蒸餾」方式，學生模型從 SFT 提示中生成補全，用於計算教師和學生 logits 之間的 KL 散度。透過最小化 KL 散度，學生能準確模擬教師行為，同時最小化訓練和推理之間的不一致性。
*   **重要利好：** 線上蒸餾只需教師的 logits，開發者即可開班帶學生，無需再依賴獎勵模型或大型語言模型作為評審員，對開源社群的開發者而言是重大利好。

**四、Gemma 2 效能評估**

*   **Google 內部評估：** 在 HuggingFace 的評估套件上，與 Qwen1.5 34B 和 LLaMA-3 70B 相比，Gemma 2 模型在同規模類型中表現最佳，甚至與訓練時間更長的大型模型相比也具有競爭力。
*   **綜合評測：** 在 MBPP、MMLU、ARC-C、GSM8K、BBQ Disambig 等基準測試上，Gemma 2 表現出色，例如在 MMLU 5-shot 測試中，27B 模型的得分達到 75.2%，相較於 Gemma-1 的 42.3% 有顯著增長。
*   **同類最佳：** 在同類小參數模型中，Gemma 2 超過了 Llama-3 8B 等知名模型，性能逼近 Qwen1.5，成為同類中的最佳模型之一。
*   **社群評估：** Hugging Face 目前正在評估 Gemma 2，結果將在稍後更新。

(大飛會把他們的測試結果，同步到視頻的評論區裡)

**五、安全保障**

Google 在訓練 Gemma 2 時遵循嚴格的內部安全程序，篩選預訓練數據，並對一系列綜合指標進行嚴格測試和評估，以識別和緩解潛在的偏見和風險。Google 也致力於為開發者和研究人員提供構建和部署安全 AI 所需的資源，包括負責的生成式 AI 工具包和最近開源的 LLM Comparator，以及基於 Gemma 模型開發的文本水印技術 SynthID。

**六、總結**

以上就是 Gemma 2 目前已知的情況。 鼓勵大家親自測試 Gemma 2，並在評論區分享使用心得和體驗。感謝大家的觀看，我們下期再見。

**修改說明：**

*   **調整語氣：** 去除一些口語化的詞語，例如 “搞了個大新聞”、“真是永遠也追不完”、“相當的平民”、“吃掉了”。
*   **精簡表達：** 避免重複敘述，將相似的資訊合併。
*   **結構化資訊：** 使用標題、副標題和項目符號，讓內容更易於閱讀和理解。
*   **專業化術語：** 保留了必要的專業術語，並在第一次出現時進行解釋。
*   **重點強調：** 使用粗體字標示重點。

希望這樣的整理能更好地呈現文稿內容！ 如果需要更多修改，請隨時告訴我。

[model=gemini-2.0-flash,0]
