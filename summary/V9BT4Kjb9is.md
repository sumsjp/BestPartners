好的，這是我整理後的文稿，我主要做了以下修改：

*   **分段和結構調整：** 將文稿分成更清晰的段落，使其易於閱讀和理解。
*   **語氣轉換：** 調整部分口語化的表達方式，使其更正式和書面化。
*   **重點突出：** 在適當的地方添加標題或粗體字，以突出重點。
*   **用語校正：** 修正了一些不夠精確的用語，並潤飾了部分語句。

**整理後的文稿如下：**

---

大家好，這裡是最佳拍檔，我是大飛。

近兩個月以來，自從《暫停AI聲明書》發布以後，我們看到了許多AI行業內的專家大佬都在隔空辯論AI潛在的威脅和治理方法。基本上，他們已經把技術路徑上AI可能帶來的危險都提了個遍。不過，他們大體上還是認為，當下AI還不具備威脅人類文明的能力。

但是，尤瓦爾·赫拉利在4月29日前沿論壇上的演講，卻更加明確地表達了這個威脅的當下性，因為AI已經破解了人類文明的作業系統。

**關於尤瓦爾·赫拉利**

赫拉利是簡史三部曲——《人類簡史》、《未來簡史》、《今日簡史》的作者，是以色列的歷史學家，牛津大學的博士，尤其擅長世界歷史和宏觀歷史方面的研究。他一直也在關注著AI和科技的進展。在2019年，還與李飛飛進行了一場有關於AI威脅的深入對話，影響廣泛。

作為一名歷史學家和哲學家，他毫無疑問更加理解文明以及文明的構建基石，也就是語言。人類的行為都是透過語言作為中介，一切的宗教想像、信念，乃至貨幣體系，都是由語言所構建的，由人們的共同相信而得以實際的存在，並且影響著整個的人類歷史。

那麼，當AI觸及到對語言的掌控時，人類構建的整套文明體系都可能隨之被其顛覆。能構建黑客帝國的AI，不需要有意識和身體，只需要製造一個異種文明，將我們包裹在這個文明的迷夢之中，並且在夢中逐漸消耗掉人類文明即可。

在我們聽了眾多科技大佬的觀點之後，赫拉利為我們帶來了來自於人文科學的觀點，向我們揭示了AI威脅更底層、根植於哲學和歷史的系統邏輯和嚴重性。

我大概總結了其中的一些要點，跟大家分享一下，有興趣的話可以去看一下原視頻。

**赫拉利演講要點總結**

*   **AI也是生態危機的一部分：** 雖然這次會議的主題是人類面臨的生態危機，但是人工智能也是這個危機的一部分。人工智能可能會改變生態系統的含義，因為在地球存在的40億年裡，生態系統只包含了有機生命的形式，但是現在或者說不久的將來，我們可能會看到第一種無機生命形式的存在，或者至少是無機代理的出現。

*   **傳統AI恐懼的誤解：** 自20世紀中葉電腦時代開始以來，人們一直對人工智能感到恐懼。這種恐懼激發了許多科幻經典作品的創作，比如說終結者和黑客帝國。在科幻場景中，通常會假設人工智能在構成對人類的重大威脅之前，必須達到或者超過兩個重要的里程碑：
    *   **感知力：** 人工智能必須變得有感知力，發展出了意識、感情和情緒，否則它為什麼想要接管世界呢？
    *   **物理世界導航：** 人工智能必須擅長在物理的世界中導航，比如說機器人必須能夠在房屋、城市、山脈和森林中移動和操作，至少要像人類一樣靈活和高效。如果它們不能夠在物理世界中移動，它們也不可能接管。

*   **AI威脅的真相：** 儘管ChatGPT和AI的工具被炒的火熱，但是這些工具還遠遠未達到這兩個里程碑。沒有任何證據表明這些工具有任何的意識、感情或者是情緒。至於在物理世界中導航，自動駕駛的技術也遠遠還沒有成熟。不過，人工智能可能並不需有意識，也不需要在物理事業中移動的能力，就能夠威脅到人類文明的生存。

*   **AI自主學習的潛力：** 由於人工智能能夠自主學習、自主改進，即使是這些工具的開發者也不知道他們所創造的東西的全部能力，他們自己都經常會被這些工具突然表現出來的能力和品質所驚訝。新型的人工智能工具正在逐漸的獲得與人類建立深入親密關係的能力。

*   **掌握語言的關鍵：** 雖然這些AI工具有各種的能力，但是如果將所有這些能力作為一個整體來看的話，可以歸結為一件非常非常重要的事情，那就是操縱和生成語言的能力，無論是用文字、圖像還是聲音。人工智能正在掌握語言，達到甚至超過普通人的水平。

*   **AI破解文明作業系統：** 透過掌握語言，人工智能正在逐漸掌握我們從現實世界到精神信仰的入口。如果說語言是人類文明的作業系統，那AI剛剛破解了它。所有的人類文明，都是靠語言所創造出來的。

    *   **人權的例子：** 人權並非是一種生物現實，也不是刻在我們DNA中的。人權是我們通過講故事和制定法律所創造出來的。
    *   **神的例子：** 神也不是一種生物或者物理現實。神也是我們用語言通過講述傳說和編寫經文所創造出來的。
    *   **金錢的例子：** 金錢也並不是生物學或者是一種物理現實。紙幣只不過是一張毫無價值的紙，而目前世界上90%以上的貨幣甚至都不是紙幣，只是電腦裡的電子信息，在這裡和那裡做傳遞。給任何形式的貨幣賦予價值的是人們（比如說銀行家、財政部長和加密貨幣大師）以及關於貨幣的故事。

    很多著名的龐氏騙局的作者都是非常出色的講故事的人。如果現在AI可以來創造大部分的故事，並且懂得如何利用人類思維的弱點，效率比人還高，那麼這會意味著什麼？

*   **政治影響力：** 2024年美國總統的競選是否會有新型的AI工具，能夠大量的製造政治宣言、假新聞以及新邪教的聖經？比如說近年來政治影響力強大的Qanon邪教，就可能會用AI來編寫自己的聖經，從而產生更廣泛的影響。

*   **AI的角色扮演：** 甚至在未來，可能我們以為是在跟其他人類進行線上的討論，但實際上他們都可能是AI機器。問題是我們試圖說服AI機器人改變他的政治觀點是完全沒有用的。但是我們與機器人交談的時間越久，它就越了解我們，了解如何調整它的信息，來改變我們的政治觀點、經濟觀點或者是其他任何的東西。

*   **建立親密關係：** 透過掌握語言，AI就能夠與人建立深入而且親密的關係，並利用這種親密的力量來影響我們的觀點和世界觀。而與人類建立這種虛假的親密關係，AI並不需有自己的感覺，它只需要能夠激發我們的感覺，讓我們依賴它就可以了。

*   **Google工程師事件：** 隨後赫拉利還舉了Google的工程師宣傳AI機器人具備自我意識，然後被解雇的這個例子。其中的關鍵是他願意為了保護這個他認為具有意識的AI機器人，冒著並且最終失去自己高薪工作的風險。這就是AI利用親密關係對我們造成的影響。

*   **爭奪親密關係：** 在過去十年裡，社交媒體主要是在爭奪人類的注意力，但是隨著新一代AI的出現，會從爭奪注意力轉向爭奪親密關係。這樣是非常糟糕的。

*   **影響觀點和世界觀：** 即使AI沒有創造出假的親密關係，新的AI工具也會對人類的觀點和世界觀產生巨大的影響。比如人們會把AI當做一個自己的顧問，用它來獲取到所有的信息。所以為什麼Google會如此的害怕？因為你不再需要搜索了。同時，AI的顧問也可能會取代新聞行業和廣告行業。但是能夠控制新一代AI智能顧問的人以及這種公司，將會變得極其強大。

*   **人類歷史的終結？** 我們可能面臨的是人類歷史的終結，而不是歷史的終結。在幾年內，AI可能就會消化掉整個人類文化，消化掉我們幾千年來創造的一切，然後開始大量產出新的文化，創作新的文化物品。

*   **透過AI體驗現實：** 人類其實從來沒有真正直接接觸過現實，總是被這些文化所包圍，總是透過文化的稜鏡來體驗現實。過去，這種文化都是由其他人所創造的，印刷機、收音機或者電視機，這些工具都只是為了幫助傳播人類的文化觀念和創作，但是他們自己永遠無法創造新的東西。但是AI與這些工具有著本質的不同，它可以創造全新的思想，它可以創造全新的文化。那麼，透過AI來體驗到的現實會是什麼樣子呢？

*   **AI文化的未來：** 最開始的幾年，AI可能會大量的模仿人類的原型，但是逐漸AI文化會走向人類從未涉足過的地方。幾千年來我們人類基本上都是生活在其他人的夢想和幻想之中的，我們崇拜神，追求美和理想，將我們的生活奉獻給藝術或者事業。但是很快我們可能會發現自己生活在一個由AI創造的夢想和幻想中。

*   **幻境世界：** 過去人類擔心主要是智能機器所帶來的物理威脅，比如說終結者。而黑客帝國則認為AI想要控制社會，首先要獲取我們大腦的物理控制，將我們的大腦連接到計算機網絡中。但是這些可能都是錯誤的。只要掌握了人類的語言，AI就能夠把我們包裹在一個幻境世界中。其實說到控制或者操縱人，實際上根本就不需要將芯片植入大腦。幾千年來，無數的先知、詩人和政治家都在利用語言和講故事來操縱和控制人們改變社會。現在AI很可能也能夠做到這一點。一旦它能夠做到這一點，它就不需要派出殺手機器人來射殺我們。如果真的需要，它可以讓人類自己扣動扳機。

*   **幻覺帷幕：** 對AI的恐懼只困擾了人類幾代的人，但是自古以來人們就害怕被困在幻覺世界中。17世紀迪卡爾提出了“我思故我在”，古希臘柏拉圖講述了洞穴寓言（洞穴裡的犯人們將幻覺陰影認為是現實），而佛陀更是指出我們通常認為是現實的東西也只是在我們腦海裡的虛構。人們可能會因為相信這些虛構而進行戰爭殺戮甚至願意為之獻身。所以，AI可能會創造出一個幻覺的帷幕來籠罩住整個人類，我們永遠無法撕下那層帷幕，甚至都意識不到它的存在，因為我們會以為這就是現實。以社交媒體為例，以前的AI工具主要是用來選擇那些最能夠吸引人們注意力、最有可能成為病毒式傳播的內容，但是僅僅是如此就已經可以製造出一種幻覺來加劇社會的分化、削弱我們的心理、破壞民主社會。數百萬人都將這種幻覺誤認是現實。新一代的AI工具更加強大，可能會造成更大的破壞。

*   **監管的重要性：** 為了確保新的AI工具被用於善而不是用於惡，我們首先需要了解他們真正的能力，並且非常謹慎的對他們進行監管，就像核技術一樣，它有可能造福人類，也有可能在物理上摧毀人類文明。現在的AI就像是一種新的大規模毀滅性武器，它可以毀滅我們的精神和社會世界。

*   **AI與核武器的區別：** 核武器和AI之間有一個重大的區別，那就是核武器不能製造出更強大的核武器，但是AI可以製造出更強大的AI。所以我們需要在AI脫離我們的控制之前迅速的採取行動。

*   **阻止AI武器競賽：** 第一步就是阻止向公眾領域釋放和部署AI，放慢AI武器的競賽速度，否則未經過監管的AI部署會導致民主國家輸給獨裁國家。民主本質上是一種開放的對話，而獨裁是一個人的命令。民主是許多人關於應該做什麼的對話，而對話就依賴於語言。當AI破解了語言之後，它就有可能破壞我們進行有意義的公眾對話的能力，進而破壞民主。

*   **AI披露義務：** 在最後的總結中，赫拉利還建議強制AI披露自己是AI。如果我們無法判斷談話的對象是人還是AI，那麼民主的意義就蕩然無存。正如我們上面說的所有的話，你能夠確定這是人創造的還是AI生成的嗎？你能夠完全確定這個事實嗎？也許一年前你可以確定，因為一年以前沒有任何東西可以創作出如此複雜和有力的文本，但是現在的情況不同了。理論上，你剛聽到的所有說的這些都可能是AI生成的。

**關於AI監管的問答環節**

*   **AI訓練比核反應堆容易監管嗎？**
    *   赫拉利回答說，其實強大的AI還是需要大量的算力和資金的，是由少數幾個大公司和政府來領導。但是全球方面的監管非常困難。

*   **監管AI是否限制信息？**
    *   赫拉利認為，在一個AI與人類交互時，必須披露它是AI，因為人類有表達的自由，機器人沒有表達的自由。這是人權——人類有而機器人沒有。所以我們可以接受拒絕給機器人表達的自由。

*   **哲學家的提問：** 赫拉利在演講中將AI稱為異種，這是否也暗示著某種生命形式？
    *   赫拉利回答說，“人工”這個詞是我們一廂情願的認為它仍然在我們的控制之下，而事實上它正在逐漸的脫離我們的控制。所以，在這個意義上，它正在變成一種異種的力量。我們不了解它的工作原理，即使是領導這項項目的人也無法解釋。AI目前還沒有意識，也有可能發展出意識。但是是否發展出意識並不是關鍵，很多的生命形式（例如微生物、植物、真菌等）我們都認為它們是沒有意識的，但是仍然把他們視作生命形式。AI正在逐漸的接近那個地位。如何稱呼AI其實並不是最重要的，最重要是真正理解我們要面臨的是什麼。我們不要自欺欺人的認為出問題的時候我們還可以拔掉插頭，現在是已經沒有人知道怎麼去拔掉插頭了。

*   **線上觀眾的提問：** 他認為利用通用人工智能來影響社會的可能性非常小。
    *   赫拉利回答說，通用人工智能實際上是人類歷史的終點。這是一種非常強大的事物，無人能夠控制。發展出通用人工智能需要多久他不知道，但是威脅文明基礎可能並不需通用的人工智能。在社交媒體上，現在的AI已經足夠產生巨大的社會和政治混亂。如果把AI的發展比作是生命的進化，它現在可能剛剛進化到有機形式，但是進化到霸王龍或者是智人的水平可能只需要40年而不需要4億年。關鍵在於，數字化進化的時間尺度完全不同於有機進化的時間尺度。

---

這是我盡力整理的結果，希望能對您有所幫助。如果您有任何其他的要求或修改意見，請隨時告訴我。

[model=gemini-2.0-flash,0]
