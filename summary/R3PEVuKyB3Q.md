好的，我為你整理了這篇文稿，使其更清晰、更結構化：

**標題：OpenAI GPT-4o Mini 與 Mistral NeMo 12B：AI 大模型的新一輪「內卷」**

**引言：**

大家好，這裡是最佳拍檔，我是大飛。本期為大家帶來 AI 大模型領域的最新資訊，OpenAI 和 MistralAI 相繼推出小型模型，掀起新一輪「內卷」。

**一、OpenAI GPT-4o Mini：更經濟高效的迷你版 GPT-4o**

*   **發布與特性：**
    *   OpenAI 突然宣布推出 GPT-4o Mini 模型，並立即上線，取代 GPT-3.5 Turbo，免費使用者即可使用。
    *   GPT-4o Mini 在 MMLU 上得分 82%，在 LMSYS 排行榜上的聊天方面分數優於 GPT-4。
    *   商用價格極具競爭力：每百萬輸入 token 15 美分，每百萬輸出 token 60 美分，比 GPT-3.5 Turbo 便宜 60% 以上，比 GPT-4o 便宜 96%-97%。
*   **技術細節：**
    *   128K token 的上下文窗口，知識截至 2023 年 10 月。
    *   使用 GPT-4o 的改進版 tokenizer，處理非英語文本的能力更經濟高效。
    *   API 目前僅支援文本和視覺，預計 7 月底推出語音等模態的測試版，後續將支持文本、圖像、視頻和音訊輸入和輸出。
*   **性能表現：**
    *   在文本智能和多模態推理方面超越 GPT-3.5 Turbo 和其他小型模型，支持與 GPT-4o 相同範圍的語言，函數調用方面表現出色。
    *   各項基准測試數據：
        *   MMLU (文本智能和推理)：82.0% (優於 Gemini Flash 和 Claude Haiku)
        *   MGSM (數學推理)：87.0% (優於 Gemini Flash 和 Claude Haiku)
        *   HumanEval (編碼性能)：87.2% (優於 Gemini Flash 和 Claude Haiku)
        *   MMMU (多模態推理)：59.4% (優於 Gemini Flash 和 Claude Haiku)
        *   Artificial Analysis 質量指數：85 (與 Gemini 1.5 Flash、Llama 3 70B 接近，優於 Mixtral 系列)
        *   推理效率：每秒 183 個 token (領先於 Gemini 1.5 Flash)
*   **實際應用：**
    *   在從收據文件中提取結構化數據、生成高質量電子郵件回覆等任務上表現優異。
*   **商業應用：**
    *   可在 Assistant API、Chat Completions API 和 Batch API 中作為文本和視覺模型使用。
*   **安全性：**
    *   從模型開發初期就內置安全措施，並在開發過程中的每一步都加以強化，過濾掉不希望模型學習或輸出的信息，使用 RLHF 等技術提高模型響應的準確性和可靠性。
    *   應用指令分層方法，提高模型抵禦越獄、提示注入和系統提示提取的能力。
*   **可用性：**
    *   ChatGPT 的 Free、Plus 和 Team 使用者已可使用 GPT-4o Mini 代替 GPT-3.5 Turbo，企業使用者也將很快可以訪問。

**二、Mistral NeMo 12B：可客製化部署的多語言小模型**

*   **發布與特性：**
    *   MistralAI 和 NVIDIA 聯合發布 Mistral NeMo 12B，開發人員可以輕鬆定制和部署，支援聊天機器人、多語言任務、編程和摘要等任務。
    *   支援 128k Tokens 的上下文窗口，可以直接替代任何使用 Mistral 7B 的系統。
    *   訓練時考慮了量化，能夠在不降低性能的情況下進行 FP8 推理。
*   **性能表現：**
    *   在多項基准測試任務上，Mistral NeMo 相比 Gemma 2 9B 和 Llama 3 8B 都有較大幅度的提升。
*   **多語言應用：**
    *   使用新的分詞器 Tekken，訓練了超過 100 種語言，非常適用於全球多語言應用。
    *   Tekken 基於 Tiktoken 分詞器，相比之前 Mistral 模型中使用的 SentencePiece 分詞器，可以更加高效地壓縮自然語言文本和源代碼。
    *   在壓縮源代碼、中文、意大利語、法語、德語、西班牙語和俄語的時候，效率提高了約 30%，壓縮韓語和阿拉伯語的時候，效率分別提高了 2 倍和 3 倍。
*   **指令遵循：**
    *   由於 Nemo 模型經過了更先進的微調和對齊過程，因此與 Mistral 7B 相比，它在遵循精確指令、推理、處理多輪對話和生成代碼方面也有更佳的表現。

**三、專家觀點：小型模型趨勢與訓練方式的變革**

*   Andrej Karpathy 認為，大模型的參數規模競爭正在加劇，但未來趨勢是小型但「思考」得非常好、且可靠的模型。
*   他預測，目前大語言模型如此龐大的原因是訓練過程浪費，模型必須先變大才能變小，因為需要自動化的幫助才能將訓練數據重構並塑造成理想的格式。
*   HuggingFace 的創始人也表示這個星期是小模型的一周。

**四、價格戰：AI 推理成本大幅下降**

*   OpenAI 和 MistralAI 的小模型價格大幅下降，推動 AI 推理成本降低。
*   有網友表示，現在只需要花費不到 20 萬美元，就可以對美國 24 小時內所說或所聽到的每一個單詞進行推理。

**五、總結與展望**

*   Meta 下週也將發布 400B 參數的 Llama 3 模型。
*   OpenAI 雖然又一次採用了搶先發布的營銷策略，但總讓人感覺有些擠牙膏。
*   大家最期待的肯定還是 GPT-5，估計很快其他 AI 公司也會有相應的發布動作。我們會持續關注和報導。

**結束語：**

感謝大家的觀看，我們下期再見！

**整理說明：**

*   **結構化：** 將內容分章節整理，每個章節都有明確的標題和小標題，方便閱讀。
*   **重點突出：** 強調了 GPT-4o Mini 和 Mistral NeMo 12B 的關鍵特性、性能表現和應用場景。
*   **數據呈現：** 將各項基准測試數據以列表形式呈現，更直觀易懂。
*   **觀點提煉：** 提煉了專家對小型模型趨勢的觀點，增強內容的深度。
*   **語言精簡：** 刪除了一些口語化的表達，使語言更加簡潔專業。

這個整理後的版本更適合作為一篇資訊報導或技術分析文章。 希望對您有幫助！

[model=gemini-2.0-flash,0]
