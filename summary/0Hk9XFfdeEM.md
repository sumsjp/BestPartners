好的，這是我整理後的文稿，重點歸納、條列分明，並針對部分地方進行了潤飾，使其更易讀：

**文稿主題：OpenAI 是否秘密訓練 GPT-5？穆斯塔法·蘇萊曼訪談重點整理**

**核心內容：**

*   **OpenAI 是否秘密訓練 GPT-5？**

    *   OpenAI CEO 薩姆·奧特曼否認正在訓練 GPT-5。
    *   Inflection AI CEO 穆斯塔法·蘇萊曼懷疑 OpenAI 秘密訓練 GPT-5，認為 OpenAI 可能只是換了個名字。
*   **蘇萊曼訪談重點：**
    *   **蘇萊曼背景：**
        *   Inflection AI 聯合創辦人兼 CEO。
        *   DeepMind 聯合創辦人。
        *   曾任 DeepMind 應用人工智能負責人、Google 政策職務。
    *   **Inflection AI 的發展：**
        *   未來 18 個月內訓練的模型比當前前沿模型大 100 倍。
        *   未來 3 年內訓練的模型比現在大 1000 倍。
        *   目標是打造一個非常好用的個人助理，提供高度客製化的 AI 服務。
    *   **對開源模型的看法：**
        *   未來 5 年內，開源模型始終會落後於最前沿的閉源模型。
        *   開源模型會增加 AI 帶來的社會風險，讓力量快速擴散。
        *   AI 技術可能會降低潛在危險化合物或武器的開發門檻。
        *   並非攻擊開源社群，但仍要堅持表達開源的風險。
    *   **在 Google 和 DeepMind 的經歷：**
        *   花費大量時間試圖將更多外部監督融入到 AI 技術的建構過程中，但過程痛苦。
        *   原本 DeepMind 被收購時提出要設立倫理和安全委員會，但 Alphabet 變得膽怯。
        *   DeepMind 從未獨立過，現在也完全從屬於 Google。
    *   **AI 訓練成本：**
        *   算力成本隨著晶片算力的迭代在不斷下降。
        *   未來可能會出現訓練某个模型的成本相当于在 2022 年花费了 100 亿美元来训练。
    *   **AI 模型的軍備競賽：**
        *   Inflection AI 正在建造世界上最大的超級電腦之一，可能運行比 GPT-4 大 10 倍或 100 倍的訓練。
        *   但因缺乏自主性，模型本身不具有危險性。
        *   擁有大規模算力的公司，應該盡可能保持公開透明。
        *   Google DeepMind 也應該披露 Gemini 接受了多少 FLOPS 訓練。
*   **蘇萊曼新書《即將到來的浪潮》：**
    *   思考人工智能所帶來的社會變化和風險，以及應對措施。
    *   內容包括對人工智能模型進行能力審核、讓批評者參與直接設計人工智能模型、及极大提高政府对人工智能的理解及合理监管的能力等等。

**總結：**

蘇萊曼的訪談內容涵蓋了對 OpenAI、開源模型、AI 安全性等議題的看法，以及他在 Google 和 DeepMind 的經歷。他認為 AI 發展的風險不容忽視，並呼籲保持透明和謹慎。

**大飛觀點：**

大飛將會持續關注 GPT-5 的發展，期待其能夠再次提升大模型 AI 的能力，並解決人們對於 AI 浪潮是否能持續的懷疑。

**建議：**

1.  **分段標題加強：** 每個段落可以加上更具體的標題，例如「蘇萊曼對開源風險的詳細說明」等，讓讀者更容易掌握內容。
2.  **資料佐證：** 針對蘇萊曼的觀點，可以加入一些數據或案例來支持，增加說服力。
3.  **用語調整：** 可以將部分口語化的用語調整為更書面化的表達方式，例如將「大家都在猜測」改為「普遍認為」。

希望以上整理對您有幫助！

[model=gemini-2.0-flash,0]
