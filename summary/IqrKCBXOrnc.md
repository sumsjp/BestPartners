好的，這是經過整理後的文稿，主要做了以下修改：

*   **簡化語句：** 將部分過於口語化的表達方式改為更書面化的語句。
*   **調整段落：** 將內容重新分段，使邏輯更清晰。
*   **統一術語：** 確保關鍵詞彙使用的一致性，例如 "Agent"。
*   **刪除重複：** 刪除不必要的重複語句。
*   **潤飾語氣：** 調整部分語氣，使其更正式、更專業。

**整理後文稿：**

大家好，這裡是最佳拍檔，我是大飛。

近年來，受益於人類生成的數據，人工智能（AI）取得了顯著的突破。然而，僅僅依賴現有的數據和方法，是否還能支撐AI的持續進步？AI的下一個階段又將朝哪個方向發展呢？

日前，谷歌強化學習副總裁大衛·西爾弗（David Silver）與圖靈獎得主、強化學習之父理查德·薩頓（Richard Sutton）共同撰寫了一篇最新論文《歡迎來到經驗時代（Welcome to the Era of Experience）》。這篇論文或將如《苦澀的教訓（The Bitter Lesson）》一般，為我們指明未來的發展方向。

西爾弗和薩頓在論文中指出，人類數據正在達到頂峰，經驗才是下一個超級數據源。真正能夠推動AI躍升的數據，必須是可以隨著模型變強而自動增長的，而唯一的途徑便是經驗本身。薩頓的主張明確指出，未來的AI不會是提示詞+知識庫的組合，而是行動+反饋的循環體。正如論文所說，經驗時代將是AI範式的一個重大轉折，我們正在從人類數據時代跨入經驗時代。這不僅僅是模型的升級，也不是強化學習算法的迭代，而是一種更根本的範式轉變。AI將從模仿人類到超越人類，從靜態數據到動態經驗，從監督學習到主動試錯。這篇論文仿佛是對整個AI的宣言：經驗才是通往真正智能的鑰匙。

今天，我將為大家翻譯這篇很可能成為又一里程碑式經典的論文。

首先，我們來回顧一下AI的發展歷程，特別是人類數據在其中扮演的角色。近年來，AI通過對海量的人類生成數據進行訓練，並借助專家的人工標註和偏好進行微調，取得了顯著的進步。大語言模型就是這種方法的典型代表，它已經達到了廣泛的通用性，也讓我們看到了AI巨大的潛力。

然而，我們也要清醒地認識到，這種主要依賴人類數據的發展模式逐漸暴露出了一些問題。雖然模仿人類能夠讓AI在一定程度上復現人類的能力，但要想在許多重要領域實現超人類的智能，僅僅依靠這一點是遠遠不夠的。在數學、程式設計和科學等關鍵領域，從人類數據中提取的知識已經接近極限。這就好比我們開採礦產資源，優質的礦脈越來越少，開採難度也越來越大。高品質數據來源，要么已被大量使用，要么很快就會被消耗殆盡。而且，僅靠人類數據的監督學習來推動AI進步的速度也明顯減緩。更重要的是，有很多有價值的新見解，例如新的定理、技術或者科學突破，都超出了當前人類的理解範圍，現有的人類數據根本無法捕捉到這些信息。這意味著，如果我們想要讓AI取得更大的突破，必須尋找新的數據來源和發展模式。

那麼，新的數據到底應該從哪裡來呢？薩頓認為，這個數據正是Agent與環境互動所產生的數據。只有這樣，才能讓Agent不斷地從自身的經驗中學習，來持續改進數據。在下一個時代，經驗將成為AI發展的主要數據來源，並且完全取代如今以人類為主導的數據。

這種轉變可能已經開始。例如在數學領域中，AlphaProof在接觸了約十萬個由人類數學家多年創建的形式化證明後，其強化學習算法隨後通過與形式化證明系統的持續互動，生成了數億個新的證明。這種對互動經驗的關注，使得AlphaProof能夠探索超越形式化證明的數學可能性，從而發現更加新穎的解決方案。薩頓認為，一旦充分發揮經驗學習的潛力，不可思議的新能力將會湧現。

經驗時代的特征是：Agent和環境不僅能從海量的經驗數據中學習，還將在以下幾個方面突破以人類為中心的AI系統的局限性：

1.  Agent將棲息於經驗流之中，而不是短暫的互動片段。
2.  它們的行動和觀察將深深紮根於環境之中，而不是僅僅通過人類對話進行互動。
3.  它們的獎勵將來自於對環境的體驗，而不是來自人類先入為主的判斷。
4.  它們將根據經驗計劃和推理，而不是僅僅用人類的術語進行推理。

接下來，論文詳細解釋了經驗時代的這幾個關鍵特征。

首先是經驗流。它指的是一個經驗型的Agent，可以在它的一生中持續學習。在人類數據時代，基於語言的AI主要關注的是短期互動片段。比如說，我們向ChatGPT提出一個問題，它回答之後，這次互動就基本上結束了，很少有信息會傳遞到下一次互動中，Agent也無法根據長期的經驗來調整自己的行為。但是，人類和其他動物不同，我們的生活其實是一個持續很多年的行動和觀察流。就像我們學習一門外語一樣，都是今天學一點，明天學一點，隨著時間的推移，我們會不斷積累經驗，根據之前的學習情況調整學習方法，從而提高學習效果。而強大的Agent也應該擁有類似人類的經驗流，這樣它們就能在較長時間尺度上推進自己的學習和行動，從而實現未來的目標，並且適應新的行為模式。例如，一個連接到用戶可穿戴設備的健康和保健Agent，它可以持續監測用戶數月的睡眠模式、活動水平和飲食習慣。通過對這些數據的分析，它能夠提供個性化的建議，比如根據用戶的睡眠質量建議調整作息時間，又或者根據活動水平來推薦合適的運動計劃。而且，它還能根據長期趨勢和用戶的具體健康目標，不斷調整自己的指導。同樣，一個個性化的教育Agent可以跟踪用戶學習新語言的進展，發現用戶在哪些知識點上存在不足，然後根據用戶的學習風格來調整教學方法，在幾個月甚至幾年的時間裡持續地幫助用戶提高語言能力。還有科學Agent，它可以追求一些宏大的目標，比如發現一種新的材料或者減少二氧化碳排放。它能夠在較長的時間範圍內分析真實世界的觀察結果，進行模擬實驗，提出並且實施在真實世界的實驗或者干預措施。這些Agent在實現目標的過程中，可能單個步驟不會立刻帶來明顯的好處，甚至在短期內還可能產生一些負面影響，但是從長遠來看，這些步驟有助於實現更長期的成功。這和當前那些只是追求即時響應的AI系統有著很大的區別。

其次是行動和觀察方面的變化。在人類數據時代，大語言模型主要關注的是人類特殊的行動和觀察，它和用戶之間的互動主要通過文本輸出和輸入來完成的。但是在自然界的智能中，動物是通過運動控制和傳感器與環境進行互動的。比如小狗通過奔跑、聞嗅來探索周圍的世界，而不是僅僅通過對話。雖然大語言模型也可以在數字世界中調用行動能力，比如API，但是最初這些能力大多數都是來自於人類使用工具的例子，而不是Agent自身的經驗。不過現在情況正在發生變化，有很多Agent開始自己運行程式碼並且觀察結果。它們就像是擁有了自己的“雙手”，可以更加自主地探索數字世界。這些變化預示著Agent將從完全依賴人類的交流轉向更加自主的互動。在經驗時代，Agent將能夠積極地探索世界，根據環境的變化來調整自己的行為，從而發現一些人類可能從來沒有想到的策略。而且，Agent不僅可以使用“人類友好的”行動和觀察方式，還可以採取“機器友好的”行動方式，更好地實現自己的目標。此外，Agent還能夠通過數字接口與真實的世界進行互動，比如監測環境傳感器的數據、遠程操作望遠鏡觀察天體，或者控制實驗室中的機械臂進行自主實驗。

獎勵機制在經驗時代也會發生很大的變革。大語言模型通常是根據人類先入為主的判斷來優化獎勵的。比如說，專家們會觀察Agent的行動，判斷這個行動好不好，或者在多個備選方案中選擇最佳的行動。但是這種獎勵方式存在一些問題，因為它是人類在不考慮行動對環境實際影響的情況下決定的，沒有真正地紮根於現實世界。這就好比一個人在評判一幅畫的時候，只看顏色好不好看，卻不考慮這幅畫所表達的內涵和對觀看者的影響。這樣一來，Agent就很難發現那些人類評估者沒有注意到的、更好的策略，從而導致性能達到瓶頸。在經驗時代，為了發現更多超越人類現有知識的新想法，Agent的獎勵應該來自環境本身。比如，一個健康助手可以根據用戶休息時的心率、睡眠時長和活動水平等信號來設置獎勵，以此來給出更合適的健康建議。教育助手可以用學生的考試成績作為獎勵信號，優化自己的教學策略。獎勵還可以來自作為Agent環境中一部分的人類。比如，人類用戶可以反饋自己吃了某個蛋糕後的感受、運動後的疲勞程度，或者頭痛時的疼痛程度。這些反饋可以幫助助手Agent提供更好的食譜、改進健身建議、調整推薦的藥物。這種獎勵因為衡量了Agent在環境中的實際行動後果，所以往往比人類專家預先判斷的效果更好。那麼，獎勵信號應該從哪裡獲取呢？其實，當Agent通過豐富的行動和觀察空間與世界連接後，就會有無數的基礎信號可以作為獎勵。我們的世界充滿了各種各樣的量化指標，比如成本、錯誤率、生產力、健康指標、氣候指標等等。還有很多信號來自於特定事件的發生，或者從原始觀察和行動序列中提取的特征。有人可能會問，只優化一個基礎的信號作為獎勵，就能夠滿足通用AI的要求嗎？畢竟通用AI需要能夠可靠地朝著任意用戶期望的行為發展。雖然追求單一獎勵信號表面上看起來不符合要求，但是我們可以根據用戶的引導，靈活地調整基於基礎信號的獎勵。比如，我們可以用一個神經網路將Agent與用戶和環境的互動作為輸入來輸出一個標量獎勵。這樣，獎勵就能根據用戶的目標進行選擇，或者組合來自環境的信號。當用戶說想要“改善我的健康狀況”，獎勵函數就會返回一個與用戶心率、睡眠時長和步數相關的函數；如果用戶的目標是“幫助我學習西班牙語”，獎勵函數則可以返回用戶的西班牙語考試成績。而且，用戶在學習過程中還可以提供反饋，比如滿意度，來微調獎勵函數，讓獎勵函數可以隨著時間不斷的優化。這就像是一個雙層優化過程，把用戶反饋作為頂層目標進行優化，把來自環境的基礎信號在底層進行優化。通過這種方式，只需要少量的人類數據，就能夠產生大量的自主學習。

在計劃和推理方面，經驗時代也帶來了新的變化。最近，大語言模型在進行推理或“思考”方面取得了一些進展，比如通過思維鏈讓模型在輸出響應之前進行一定的推理。從概念上講，大語言模型就像一個通用電腦，它可以通过将token添加到自己的上下文中来执行各种算法。但是在人類數據時代，這些推理方法大多是模仿人類的思維過程，比如讓大語言模型發出像人類一樣的思維鏈，模仿人類思維的痕跡，或者加強與人類相匹配的思維步驟。而且，推理過程還會根據人類專家給出的正確答案進行微調。但是大家想一想，人類語言真的是通用電腦的最佳實例嗎？其實不然，肯定存在著更加有效的思維機制，只是這些機制可能使用的不是人類語言，比如符號、分佈式、連續或者可微分的計算。原則上，自主學習系統可以通過從經驗中學習，發現或改進這些方法。就像AlphaProof在學習證明複雜定理時採用的方式與人類數學家是截然不同的。另外，通用電腦只是為了解決了Agent的內部計算問題，沒有將它與外部世界的現實聯繫起來。如果一個Agent只是被訓練用來模仿人類思想，甚至只是匹配人類專家的答案，它可能就會繼承數據中存在的錯誤思維方法。就像如果一個Agent接受了5000年前人類思想和專家答案的訓練，那麼它在推理物理問題的時候可能會採用萬物有靈論的方式；如果是1000年前，可能會採用有神論的方式；如果是300年前，可能是牛頓力學的方式；50年前，則可能是量子力學的方式。要想超越這些思維方法，Agent必須與現實世界進行互動，做出假設、進行實驗、觀察結果，然後根據結果來更新自己的原則。這就像科學家在探索真理的過程中不斷通過實驗來驗證自己的理論一樣，Agent也必須紮根於真實世界的數據，才能夠推翻那些錯誤的思維方法，形成自己的、不受當前主流人類思維模式限制的新原則。否則，無論Agent多么複雜，都只是在重複現有的人類知識，無法取得真正的突破。怎樣才能讓Agent的思維紮根於外部世界呢？一種可行的方法是構建一個世界模型，這個模型可以預測Agent的行動對世界的影響，包括預測獎勵。比如，一個健康助手在為用戶推薦當地健身房或者健康播客的時候，它的世界模型可以預測用戶採取這個行動後，心率、睡眠模式可能會發生怎樣的變化，以及可能會與用戶進行怎樣的未來對話。這樣，Agent就能根據自己的行動以及它對世界的因果效應來進行計劃。隨著Agent在經驗流中不斷與世界互動，這個動態模型會不斷更新，糾正預測中的錯誤。有了世界模型，Agent還可以用一些可擴展的計劃方法來提高自己的預測性能。而且，計劃和推理這兩個方法並不是相互排斥的，Agent可以在計劃過程中，使用內部的大語言模型來選擇行動，或者模擬、評估這些行動的後果。

可能有人會問，從經驗中學習並不是什麼新鮮事，為什麼現在才說進入了經驗時代呢？這就不得不回顧一下AI的發展歷程了。在此之前，強化學習系統已經在模擬環境中取得了很大的成功，在很多複雜任務上達到甚至超過了人類水平，比如在圍棋、國際象棋、撲克，甚至在星際爭霸II等電子遊戲和機器人導航等方面，強化學習都展現出了強大的能力。但是，從模擬環境到現實世界的跨越一直是個難題，如同一道難以逾越的鴻溝，因為現實世界太複雜了，有無數的變量和不確定性，這使得Agent很難在現實中發揮出在模擬環境中的水平。在人類數據的時代，基於人類數據訓練的大語言模型雖然實現了廣泛的能力，能夠完成各種各樣的任務，但是過於依賴人類的知識和數據，從而減弱了Agent自我發現知識的能力，就像是被圈養在人類知識圍欄里的動物，很難突破這個界限去探索新的領域。而經驗時代的到來，正是為了調和這兩者的優勢。當前，自主Agent和強化學習方法的不斷發展也表明向經驗時代的過渡即將來臨。隨著以人為中心的大語言模型興起，人們的焦點從如何自主學習轉移到了如何利用人類知識上。像RLHF之類的技術，雖然功能強大，但是往往繞過了強化學習的核心概念，比如用人類專家來代替機器計算，從而繞過對價值函數的需求，用來自人類數據的強先驗知識來減少對探索的依賴，以及用以人為中心的推理來減少對世界模型和時間抽象的需求。經驗時代的到來正好為我們重新審視和改進這些概念提供了機會。通過對這些經典概念和算法的深入研究和優化，我們可以更好地釋放自主學習的潛力，讓Agent在經驗流中更加高效地學習和成長。

西爾弗和薩頓在論文中也指出，經驗時代的到來無疑會帶來巨大的影響，既有令人期待的潛力，也伴隨著諸多挑戰。從潛力方面來看，它有望帶來更加個性化的助手，比如在個人生活、健康、教育、科學研究、藥物研發等領域。但是，經驗時代也帶來了一系列挑戰。首當其衝的就是工作崗位流失的問題。隨著Agent在各個領域的能力不斷提升，一些重複性、規律性強的工作可能會被Agent取代，這將對就業市場產生巨大衝擊。其次，安全風險也會增加。如果Agent的行為不受控制或者可能被惡意利用，就會給個人、社會甚至國家帶來嚴重的安全威脅。另外，經驗時代的Agent往往是通過複雜的算法和大量的經驗數據進行學習和決策的，這個決策的過程和結果的可解釋性可能會變得更低，這使得我們很難理解Agent為什麼會做出這樣的決策，一旦出現問題也難以進行追溯和糾正。不過，經驗學習也並非只有風險，它同樣具有一些安全方面的優點，因為Agent在經驗流中可以不斷適應環境的變化，所以能夠及時調整自己的行為策略。而且，獎勵函數可以根據用戶的需求和環境的變化靈活地調整，避免Agent出現一些不符合預期的行為。此外，Agent在現實世界中的行動由於受到時間的製約，不會像在模擬環境中那樣進行無限次的嘗試，這在一定程度上也限制了潛在的風險。

總的來說，經驗時代將是AI發展的下一個關鍵時期。在這個時代，Agent將不再局限於從人類衍生的數據中學習，而是能夠從自身與世界的互動中獲取經驗，不斷地學習和成長，從而超越人類數據的局限，釋放出全新的能力。

以上就是這篇論文的主要內容了。不知道大家是否認同經驗時代將會是AI的下一個發展方向？歡迎在評論區留言。感謝觀看本期視頻，我們下期再見。

[model=gemini-2.0-flash,0]
