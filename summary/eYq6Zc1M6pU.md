好的，我幫你整理了這篇文稿，並將它分成更易於閱讀和理解的部分。

**標題：揭秘大模型推理「失控」真相：為何相同輸入得到不同輸出？**

**開場白 (大飛)：**

*   大家好，這裡是最佳拍檔，我是大飛。
*   今天要和大家聊的是大模型開發、應用中一個繞不開的難題：為什麼輸入完全一樣的內容，大模型的輸出卻不一樣？
*   即使固定了隨機種子，結果還是會「失控」。

**背景：Thinking Machines Lab 的研究成果**

*   **公司介紹：**
    *   由 OpenAI 前 CTO 米拉·穆拉蒂（Mira Murati）創立。
    *   成立之初就備受矚目。
    *   今年 7 月完成 20 億美元的種子輪融資，估值 120 億美元（「未出產品先獲重投」在 AI 行業極為罕見）。
    *   投資方包括 A16z、英偉達、AMD、思科等科技巨頭。
*   **研究博客 Connectionism (聯結主義)：**
    *   9 月 11 日正式推出。
    *   第一篇文章針對大模型推理中最讓人頭疼的「非確定性」問題。
    *   標題：《擊敗大語言模型推理中的非確定性》。
    *   點破了許多人對大模型非確定性的誤解，並給出了可落地的解決方案和完整實驗數據。

**大模型推理非確定性的問題**

*   **現象：**
    *   輸入相同的提示詞（如「請介紹一下理查德·費曼」），並固定隨機種子。
    *   理想情況下，模型輸出應該完全一致。
    *   但實際情況是，運行多次可能會得到不同的結果。
    *   即使使用 vLLM、SGLang 等開源推理庫，在自己的硬體上跑，情況依然存在。
*   **常見解釋（錯誤）：**
    *   GPU 並發執行導致計算順序不同。
    *   浮點數運算本身有誤差，疊加後導致輸出不一樣。
    *   **問題：** 這些說法並未觸及問題核心。

**真正的原因：批次不變性缺失**

*   **核心問題：** 大模型推理過程中的「批次不變性缺失」。
*   **批次處理：**
    *   伺服器不會每次只處理一個請求，而是將請求打包成「批次」（batch）來處理。
    *   低峰期可能將你的請求與另外 2 個請求打包成「批次大小 3」的任務。
    *   高峰期可能與另外 15 個請求打包成「批次大小 16」的任務。
*   **問題：** 相同的輸入，在不同批次大小下，會產生不同的輸出。
*   **類比：** 你去餐廳點一道番茄炒蛋，廚房同時要炒 3 道菜，你的番茄炒蛋就會偏鹹；同時炒 10 道菜，你的番茄炒蛋就會偏甜。
*   **根本原因：** 浮點數的非結合性。
    *   **(a+b)+c 的結果並不等於 a+(b+c)**。
    *   **例子：** (0.1 + 1e20) - 1e20 = 0，但 0.1 + (1e20 - 1e20) = 0.1。
    *   **原因：** 浮點數的設計初衷是「動態精度」，但當兩個數值尺度差異過大時，小數的精度會被大數「吞噬」。
*   **放大效應：**
    *   矩陣乘法、RMSNorm（均方根歸一化）和注意力機制等關鍵步驟，本質上都涉及大量的浮點數加法和乘法。
    *   當伺服器處理不同批次大小的請求時，這些操作的歸約化（Reduction）順序，也就是浮點數相加的順序，會發生變化。
    *   批次大的時候，内核會採用“分割歸約”的策略；批次小的時候，可能会用“單核心完整歸約”的策略。
*   **重要澄清：**
    *   不是「GPU 並發執行」是關鍵，而是内核的歸約策略會隨著批次大小而變化。
    *   即使在 GPU 上，只要歸約的順序是固定，相同的計算任務重複執行 1000 次，結果也會完全一致。
    *   **實驗：** 用 PyTorch 定義兩個 2048×2048 的隨機矩陣 A 和 B，計算它們的乘積，然後重複 1000 次，每次的結果都完全相同。

**解決方案：批次不變的内核**

*   **核心思想：** 讓大模型的核心操作（RMSNorm、矩陣乘法和注意力機制）在任何批次大小下，都採用相同的歸約順序。
*   **三類操作的具體實現：**
    *   **RMSNorm：**
        *   強制採用數據並行的策略，無論批次大小如何，都要保證每個批次元素的歸約在單個核心內完成。
    *   **矩陣乘法：**
        *   固定内核配置：禁用 Split-K 策略，固定張量核心指令的尺寸（如統一使用 128×128×32 的塊大小）。
        *   **(說明：** 雖然會損失一定的性能，但在批次較大的場景下，性能損耗只有 20% 左右，完全在可接受的範圍以內。)
    *   **注意力機制：**
        *   固定分割大小：不按照分割數量來拆分 KV 缓存，而是按照固定分割大小來拆分（如不管 KV 缓存的總長度是 1000 還是 2000，都按照每個分割 256 個元素的大小來拆分）。
        *   在注意力内核之前統一更新 KV 缓存的布局，確保預填充和解碼階段的 KV 數據格式一致。

**實驗結果和意義**

*   **實驗：**
    *   模型：Qwen/Qwen3-235B-A22B-Instruct-2507
    *   提示詞：「介紹一下理查德·費曼（Tell me about Richard Feynman）」，溫度設置為 0。
    *   **結果：**
        *   使用常規内核：1000 次採樣產生了 80 個不同的完成結果。
        *   啟用「批次不變内核」：1000 次採樣的結果完全一致。
*   **意義：**
    *   徹底消除大模型推理的非確定性。
    *   為大模型的「可重複性」和「可靠性」提供了科學的解決方案。
    *   讓大模型的「在線策略強化學習」（On-Policy RL）成為可能。
        *   沒有批次不變内核的時候：不使用離線策略校正，訓練會在 318 步左右出現獎勵崩潰。
        *   啟用了批次不變内核後：即使不使用校正，訓練也能順利進行，獎勵的穩定性大幅上升。
*   **性能損耗：**
    *   未經優化的批次不變内核：推理的速度下降大約 2 倍。
    *   經過優化：性能損耗已經控制在可接受的範圍內。

**總結**

*   Thinking Machines Lab 的研究：
    *   不僅解決了大模型推理非確定性的一個技術難題。
    *   更重要的是：它為大模型的「可重複性」和「可靠性」提供了科學的解決方案。
*   它不是對現有技術的小修小補，而是從底層邏輯上解決了大模型落地的一個關鍵障礙。
*   未來 AI 產品會變得更加可靠。
*   AI 從業者在追求模型性能的同時，也要關注底層計算的確定性。

**聯結主義 (Connectionism) 的含義**

*   1980 年代 AI 領域的一個重要子領域，核心研究方向是「神經網路與生物大腦的相似性」。
*   Thinking Machines Lab 的使命之一：提高人們對 AI 的科學理解，與更廣泛的研究社區合作。
*   Thinking Machines Lab 的第一代旗艦產品就叫「Connection Machine」。

**結尾 (大飛)：**

*   感谢收看本期视频，我们下期再见

**備註：**

*   此整理版本更側重於結構化地呈現原文的重點信息。
*   一些口語化的表達被略微調整，以使其更適合閱讀。
*   關鍵概念和結論被突出顯示。

希望這個版本對您有所幫助！

[model=gemini-2.0-flash,0]
