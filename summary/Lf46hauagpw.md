好的，这是一份对Sebastian Borgeaud访谈的专业整理稿。我已将文稿中的核心信息进行提炼、归纳和结构化，以便您快速理解和查阅。

---

**【深度解析】Google Gemini 3模型幕后：与预训练负责人Sebastian Borgeaud的对话**

**引言**
本整理稿将深入探讨Google Gemini 3模型背后的故事，以及由其预训练负责人、全球顶尖AI研究者Sebastian Borgeaud（亦是Metis名单成员）分享的深度见解。这是他首次参与播客录制，对话内容涵盖了Gemini 3的底层构建逻辑、行业趋势、未来展望及团队管理等多个维度，提供了许多具有深度和启发性的观点。

**一、Gemini 3的成功密码：极致的集体与微小改进的合力**

1.  **非单一突破，乃系统性优化：** 很多人认为Gemini 3的跨代飞跃源于某个惊天动地的核心技术突破。然而，布尔若引用Gemini联合负责人奥雷尔·维尼的观点指出，其成功秘诀在于“更优质的预训练和后训练”。
2.  **庞大团队的像素级改进：** 成功并非源于一两个天才灵感，而是由一个两百多人的庞大团队，在模型、数据、基础设施、评估等多个维度进行了无数次“像素级微小改进”的集体成果。
3.  **整合与协调是关键：** 作为预训练负责人，布尔若的工作不仅是提升模型性能，更包括协调近两百人的团队，使其在数据筛选、模型架构优化、基础设施搭建、评估体系完善等各环节发挥所长。
4.  **“极致的集体让卓越平庸化”：** 成功的关键在于整合众多人的工作成果，而非依赖少数人的领先。这里的“平庸化”并非指能力普通，而是强调每个微小改进的积累，最终汇聚成不可阻挡的创新力量。

**二、行业范式转变：从“数据无限”到“数据有限”**

1.  **规模不再是唯一驱动力：** 过去普遍认为堆砌算力和扩大数据规模能持续提升模型性能。但布尔若指出，尽管缩放定律仍未触顶，规模仍重要，但其作用可能被高估。
2.  **架构与数据创新超越单纯规模：** 在“数据有限”的新范式下，架构创新和数据创新的重要性甚至超过了单纯的规模扩大。真正的胜负关键在于如何在有限数据池中，通过架构优化挤压出更多智能。
3.  **DeepMind的实践项目：**
    *   **Chinchilla项目：** 研究在固定训练计算资源下，模型规模和数据规模的最佳调整。发现数据规模应更快扩展，而非一味扩大模型规模，这影响了模型部署和使用成本。
    *   **Retro项目：** 侧重架构创新，通过让模型从大型文本语料库中检索信息来提升性能，无需将所有知识存储在参数中。

**三、研究品味：决策与取舍的智慧**

1.  **难以量化但至关重要：** 布尔若强调“研究品味”是决定模型生死的关键，它虽难量化，但包含以下要素：
    *   **协同整合性：** 研究不能是孤立的，必须能与其他研究配合、整合。
    *   **对复杂性的警惕：** 承受的复杂性是有限的，团队常放弃性能最优但复杂度过高的方案，以利未来进展。
    *   **直觉判断：** 在计算资源有限下，判断哪些研究方向可行。研究者需判断投入多少精力后转向或坚持。负面结果不代表方法行不通，而往往是还未找到让其可行的方法。
2.  **“决定不做什么”：** 在资源极其昂贵的预训练阶段，最难的不是决定做什么，而是决定不做什么，这正是研究品味的体现。

**四、短期与长期目标的平衡**

1.  **兼顾改进与探索：** 总有一些关键路径上的问题需要解决（短期目标，安全赌注，避免未来隐患），同时也需要进行更具探索性的研究（长期目标，可能应用于未来版本，影响更大但未充分验证）。
2.  **周期性：** 模型规模扩张阶段，探索性研究多；临近新架构/模型发布前，重点转向降低风险和执行层面。
3.  **DeepMind的优势：** 研究与产品之间张力较小，因所有领导层都有研究背景，理解研究进展才是最关键的，从而专注长期价值创造。

**五、DeepMind的组织架构与Gemini 3的多模态特性**

1.  **高效的研发体系：** DeepMind组织架构分为预训练和后训练团队。预训练团队细分模型、数据、基础设施、评估（被低估但极其重要），各团队紧密协作。
2.  **Gemini 3架构：** 基于Transformer的混合专家架构，与前版变化不大。
3.  **原生多模态：** Gemini 3的核心特性，指由同一个神经网络同时处理图像、音频、文本等所有不同模态，而非独立模型。
4.  **多模态的成本与收益：**
    *   **成本：** 复杂性成本、研究成本（处理更多任务及模态互动）、计算成本（图像输入规模更大）。
    *   **收益：** 带来的显著性能优势在很大程度上超过了成本。

**六、预训练的未来方向与挑战**

1.  **数据枯竭？范式转变！** 布尔若认为数据枯竭不会发生，而是从“数据无限”转向“数据有限”模式，这将催生新的创新（如同ImageNet基准测试曾催生大量技术）。
2.  **合成数据：** 有趣但需谨慎，关键在于能否生成合成数据来训练一个未来模型，使其性能超越生成合成数据的原始模型。
3.  **长上下文能力：** 极具潜力，预计未来1-2年内将有更多创新，提升效率并扩展上下文长度。
4.  **注意力机制：** 近期的一些有趣发现将塑造未来几个月的研究方向。
5.  **评估的挑战与重要性：** 评估在预训练中非常困难，需弥合两大差距：
    *   **小模型预测大模型：** 日常训练的小模型评估方法需能预测大模型性能。
    *   **预训练预测后训练：** 预训练评估需反映模型在后续训练中的表现。
    *   **内部构建评估体系：** DeepMind倾向于内部构建评估体系，以避免外部基准测试很快被“污染”（内容在网络传播，难以检测训练数据是否包含）。
6.  **对齐问题：** 大部分对齐工作在后续训练阶段进行。预训练阶段，模型需要接触一部分不良信息，才能识别并学会远离它们，避免在用户提及时一无所知。
7.  **DeepThink：思考模型的工作原理：** 与仅在模型内部计算不同，这类模型会在序列长度层面进行计算，提供更多思考空间，进行假设、测试、工具调用、搜索、回顾，最终提供明确答案。
8.  **Gravity项目（Agent）与持续学习：**
    *   **Agent：** 在执行层面影响最大（如监控实验），视觉感知（屏幕理解）对Agent与计算机屏幕交互至关重要。
    *   **持续学习：** 用新知识持续更新模型。过去几年在后训练和搜索（如Retro通过检索将知识语料库与推理分离）方面取得进展。长上下文能力也相关。未来可能需要更大的范式转变，如改变训练算法，让模型从现实世界数据流中持续学习。

**七、AI行业展望与Sebastian Borgeaud的个人成长**

1.  **AI过度投资已好转：** 两年前很多人试图用专门模型解决通用模型半年内就能解决的任务，但现在人们意识到通用模型能完成多数任务。研究重心转向“如何使用模型”和“构建稳健的应用框架”。
2.  **布尔若的个人成长轨迹：**
    *   **多元背景：** 在欧洲多地长大（荷兰、瑞士、意大利），掌握多语（法语、德语）。
    *   **早期启蒙：** 十岁左右随父亲学习编程，热爱数学与科学。
    *   **求学与机遇：** 剑桥大学计算机实验室本硕毕业。通过硕士讲师推荐，于2018年加入DeepMind任研究工程师。
    *   **职业转向：** 最初从事强化学习（Atari游戏），因不喜欢其合成性质，转向与真实世界数据相关的表征学习。
    *   **Gopher项目：** DeepMind首篇大语言模型论文，意识到团队协作是关键，自此专注于大规模预训练。
    *   **持续发展：** 从研究工程师到百人预训练团队负责人，展现了技术追求、团队管理和研究型工程能力。
3.  **对未来的展望：** 享受与优秀同事合作学习，AI领域仍有巨大提升空间，对未来充满好奇。认为至少未来一年AI行业快速发展趋势不会放缓。
4.  **总结：** AI的“下半场”将属于“全栈研究员”——能整合技术栈、注重团队协作、兼具研究品味和工程能力的从业者。Gemini 3的成功仅仅是未来序幕的开端。

---

[model=gemini-2.5-flash,0]
