好的，這是對您提供的文稿的整理：

**主題：NVIDIA Cosmos 世界模型平台解讀**

**引言：**

*   大家好，這裡是最佳拍檔，我是大飛。
*   本期將解讀 NVIDIA 在 CES 上發布的 Cosmos 世界模型平台及其技術報告。

**Cosmos 簡介：**

*   Cosmos 是一個世界模型平台，包含一系列開源、開放權重的視頻世界模型（參數量 4B 到 14B）。
*   **用途：** 為機器人、自動駕駛等需要在物理世界運行的 AI 系統，生成大量照片級真實、基於物理的合成數據，解決數據不足的問題。
*   NVIDIA 一次發布了 8 個模型，在 2000 萬小時的視頻數據上訓練。
*   **模型類型：** 擴散連續 token 和自回歸離散 token。
*   **生成方式：** 文本生成視頻、文本+視頻生成視頻。
*   **模型規格：** Nano、Super、Ultra。
*   **優勢：** 幾何準確性更優，視覺一致性持續超越 VLDM，姿態估計成功率最高可達 14 倍。
*   **NVIDIA 的願景：** 讓物理 AI 普及化，讓每個開發者都能用上通用機器人技術。

**Cosmos 工作原理 (WFM - 世界基礎模型)：**

*   英偉達公開的技術報告主要介紹 WFM 的工作原理。
*   **四大功能模塊：** 擴散模型、自回歸模型、視頻分詞器、視頻處理與編輯流程。
*   **研究重點：** 視覺世界基礎模型，觀察結果以視頻形式呈現，擾動以各種形式存在。
*   **範式：** 預訓練 + 後訓練。
    *   **預訓練 WFM：** 利用大規模視頻訓練數據集，生成高品質、具有一致性的 3D 視頻，得到通用的世界模型。
    *   **後訓練 WFM：** 使用特定物理 AI 環境收集的提示-視頻對數據集，對預訓練 WFM 進行微調，得到用於特定目的的 WFM。
*   **WFM 模型：**
    *   根據過去的視覺观测序列 (x_0:t) 和当前扰动 (c_t)，預測時間 t+1 的未來观测值。
    *   视频 x_0:t 可以是 RGB 视频。
    *   扰动 c_t 可以是物理AI的动作、随机扰动、或描述扰动的文本。

**视频数据处理流程（基于 Ray 框架）：**

*   目的是提取具有丰富动态效果和高视觉质量的视频部分，促进模型学习编码在视觉内容中的物理知识。
*   **五個主要步驟：** 分割、過濾、標註、去重、分片。
*   從 2000 萬小時的原始視頻集合中，提取了約 1 億個視頻片段（2 秒到 60 秒不等）。
*   **主要类别：**自然动态、空间意识和导航、手部动作和物体操作、驾驶、人体动作和活动
*   **视频描述：** 使用视觉语言模型VLM为每256个帧提供一个视频描述。
*   **硬體加速：** 利用 GPU 上的 H.264 視頻編碼器和解碼器進行解碼和轉碼。

**預訓練 WFM 的可擴展方法：**

*   **兩種方法：** 基於 Transformer 的擴散模型和自回歸模型。
    *   **擴散模型：** 通過逐步去除高斯噪聲視頻中的噪聲來生成視頻。
    *   **自回歸模型：** 基於之前的生成內容，按照預設順序來逐段生成視頻。
*   **訓練步驟：**
    *   扩散模型：文本到世界生成预训练，视频到世界生成预训练
    *   自回归模型：基本的下一个token生成，文本条件的视频到世界生成
*   **Token：** 兩者都使用 token 來表示視頻，前者使用向量形式的連續 token，後者使用整數形式的離散 token。

**Cosmos 分詞器：**

*   **目的：** 將視頻壓縮為緊湊的 token 序列，同時最大限度地保留視頻中的原始内容。
*   **特点：** 轻量化、计算高效、结合时间因果机制
*   **架构：** 因果时间卷积层和因果时间注意力层
*   **优势：** 卓越的視覺重建質量和推理效率，提供一系列壓縮率，適應不同的計算限制和應用需求。
*   **性能：** 性能上显著超越了现有的分词器，质量更高，而且运行速度最快可达12 倍，可處理長時视频分词。

**後訓練 WFM：**

*   對預訓練的 WFM 進行微調，使其適用於各種物理 AI 任務。
*   **案例：**
    *   以相机姿态作为输入提示词，創建可導航的虛擬世界。
    *   在机器人任务中，预测机器人采取行动后世界的未来状态。
*   **任務示例：**
    *   **基于指令的视频预测：** 輸入當前視頻幀和文本指令，輸出預測視頻（数据集：Cosmos-1X）。
    *   **基于动作的下一帧预测：** 輸入當前視頻幀和動作向量，輸出預測的下一幀（数据集：Bridge）。
*   **自动驾驶：** 使用RDS数据集对Cosmos-1.0-Diffusion-7B-Text2World模型进行微调，打造多视角世界模型

**安全防护系统：**

*   为了更好地保护开发人员。
*   **前置防护系统：** 阻止有害输入。
*   **后置防护系统：** 通过视频内容安全分类器和面部模糊过滤器来阻止有害输出。

**總結：**

*   世界基礎模型 WFM 是一種能夠模擬物理世界的強大神經網絡。
*   **能力：** 從文本/圖像輸入數據生成詳細的視頻，並通過將當前狀態與動作相結合來預測場景的演變。
*   **優勢：**
    *   帮助开发人员想象不同的环境，模拟未来，做出更好的决策
    *   通過生成合成數據來增強訓練的過程。
    *   在受控的環境中訓練和測試物理 AI 系統，降低物理測試的風險。
*   **NVIDIA 的願景：** 未來會需要三台計算機：DGX (训练AI)、AGX (部署AI)、Omniverse+Cosmos (生成未来场景)。
*   未來，每個工廠都可能擁有數字孿生，通過將 Omniverse 和 Cosmos 結合，生成一大批的未來場景。

**結尾：**

*   以上是對這篇論文的大概解讀。
*   感謝大家的收看，我們下期再見。

**整理說明：**

*   **結構化：** 將文稿整理成清晰的章節，每個章節都有明確的主題。
*   **重點突出：** 使用粗體標記關鍵詞和短語，方便快速理解。
*   **簡潔明瞭：** 避免過多的口語化表達，使用更精煉的語言。
*   **補充信息：** 在一些地方補充了更具體的解釋，例如 WFM 的四大功能模塊。

希望這個整理對您有所幫助！

[model=gemini-2.0-flash,0]
