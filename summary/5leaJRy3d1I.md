好的，我为您整理了这篇文稿，使其更清晰、更有条理，并突出了重点。

**整理後文稿：**

**主题：尤瓦尔·赫拉利：AI风险高于核战和生物威胁**

**引言：**

*   大家好，这里是最佳拍档，我是大飞。
*   本期分享《人类简史》作者尤瓦尔·赫拉利在东京庆应义塾大学讲座的最新观点，主持人为庆应义塾大学校长伊藤公平。
*   赫拉利曾在《今日简史》中指出核战、生物技术和AI失控是三大全球威胁。

**核心观点：AI风险优先级更高**

*   赫拉利认为，相较于核战和生物威胁，AI的风险更高。
*   行业内更多人关注AI机遇，而忽略了其潜在风险。

**具体论证：**

1.  **AI vs 生物技术：发展速度差异**
    *   伊藤公平提问：为何新书《智人之上》将火力集中在AI之上？
    *   赫拉利认为AI发展速度远超生物技术。生物技术的变革周期漫长（20-30年），而AI的迭代速度可能只需几天。
    *   数字进化比有机进化快数百万倍，AI风险更紧迫。

2.  **AI vs 核威胁：复杂性和积极潜力**
    *   核战无任何积极意义，各方都明白其危险性。
    *   AI拥有巨大积极潜力，使得人们难以充分理解其潜在威胁。
    *   核技术的危险性显而易见，而AI的危险难以把握，是一种“异类性”的威胁。

3.  **AI的核心问题：能动性 (Agent)**
    *   AI 不只是工具，而是具有能动性，是人类创造的第一项能动性技术。
    *   AI可以自行决策、自行发明，甚至无需人类指令就能决定轰炸目标。

**对AI发展速度和监管的担忧：**

*   十年前，讨论AI更像是讨论数百年后的事情，但现在AI无处不在，发展速度惊人。
*   监管AI、达成全球协议的希望正在破灭。

**AI革命的信任悖论：**

*   赫拉利与AI公司负责人和政治家交流时，总是会问：
    *   “你们为什么发展得这么快？” -> “我们理解有风险，但其他竞争者不放慢，我们也不能。”
    *   “你们认为自己能够信任正在开发的超级智能AI吗？” -> “是的。”
*   赫拉利认为这是在“濒临疯狂的边缘”，我们对AI毫无经验，不知道它们可能发展出什么样的目标和伎俩。
*   AI就像一场席卷全球的移民浪潮，可能会夺走人们的工作、接管国家。
*   核心问题：如何在开发出超级智能AI之前，在人类之间建立信任？

**精英与大众的信任鸿沟：**

*   “精英”和“人民”是一种错误的二分法。
*   问题不在于精英的存在与否，而在于精英是服务型还是自私自利型。
*   大学的目的是培养服务型的精英。

**教育在AI时代的角色：**

*   过去教育机构的核心任务是提供信息，而现在人们被海量信息淹没。
*   教育的关键是需要理解信息并不是真相。真相是信息中一个非常罕见的子集。
*   真相昂贵、复杂且痛苦，而虚构廉价、简单且诱人，因此世界充斥着虚构。
*   教育机构的任务是帮助人们在信息的海洋中找到那些罕见的真理宝石，区分可靠和不可靠的信息来源。

**跨尊严中心（Cross Dignity Center）的研究方向：**

*   赫拉利认为“最为紧迫的”课题是如何在人类之间建立信任。
*   当前世界最大的危险不是AI，而是人类之间的不信任。
*   需要多学科的投入，包括生物学、心理学、经济学、计算机科学。
*   要重新学习如何在信息技术的调解下，在广大民众之间建立信任。

**全球局势的担忧：**

*   二战后建立的国际秩序正在瓦解，强国可以随意入侵和征服弱国。
*   军事预算上升，医疗和教育预算下降。
*   任何监管AI的机会都将不复存在，每个国家都会说必须赢得AI竞赛。

**关于社交媒体的虚假新闻：**

*   需要区分讲话的自由（freedom of speech）和信息的自由（freedom of information）。
*   讲话自由应该受到保护，但信息自由不应赋予AI、算法和机器人。
*   社交媒体的问题不在于人类编造谎言，而在于平台算法故意传播谎言和仇恨。
*   社交媒体公司有责任确保传播内容的真实性。

**AI对战争形态的影响：**

*   AI不会废除物理世界，而是在其之上构建了新的层面。
*   战争的本质仍然是杀伤，但实现方式正在改变。
*   AI越来越多地在战争中做出关键决策，例如选择目标。
*   我们需要考虑是否能够相信AI的判断，以及它是否可能犯错。

**总结：**

*   强调AI的积极潜力同时，也要指出潜在的危险，寻求平衡。
*   安全发展AI的关键再次回到了如何在人类之间建立信任的问题上来。
*   信任是生命的基础，我们需要信任他人和外界。

**结尾：**

*   以上就是尤瓦尔赫拉利这次讲座的主要内容，希望能给大家带来一些启发和思考。
*   感谢大家的观看，我们下期再见。

**改进说明：**

*   **结构化：** 使用了标题、副标题和编号，使内容更易于理解。
*   **提炼核心：** 突出赫拉利的核心观点：AI风险高于其他，以及信任的重要性。
*   **总结要点：** 针对每个论点，提炼出最重要的信息。
*   **强调关键词：** 使用粗体字强调关键概念和术语。
*   **简化语言：** 在不改变原意的前提下，精简了部分句子。

希望这个整理对您有帮助！

[model=gemini-2.0-flash,0]
