好的，我將會把您的文稿整理如下，主要著重於：

*   **分段清晰：** 增加或調整分段，使內容邏輯更易於理解。
*   **重點突出：** 使用粗體標記關鍵詞和重要觀點。
*   **精簡語句：** 在不影響原意的基礎上，盡可能簡化冗長的語句。
*   **用詞一致性：** 統一使用一些翻譯詞彙，例如"Data Curation" 使用 "數據策展"。
*   **結構化呈現：** 將一些內容以列表形式呈現，方便閱讀。

整理後的文稿如下：

---

大家好，這裡是最佳拍檔，我是大飛。

**AI 產業過去兩年因為大模型而高速發展，參數量和算力預算都大幅提升。** 然而，近期新模型的能力增長卻逐漸放緩，簡單堆砌算力和數據的邊際效益正在遞減。許多人開始懷疑大模型的 **Scaling Laws** 是否已經失效，是否真的遇到了數據牆？

**DatologyAI 的創辦人阿里·莫科斯 (Ari Morcos) 認為，數據是 AI 研究中影響最大，但投入最少的領域。** 他強調：**「模型吃進什麼，就會成為什麼。」** 與其無休止地堆砌算力、陷入規模化收益遞減的陷阱，不如回歸本源，透過極致的 **數據策展 (Data Curation)**，讓模型能吃得更好，學得更聰明。

今天，我們來回顧一下這期訪談的內容，看看對於如今的大模型來說，**數據究竟有多重要**。

**阿里押注於數據的原因：神經科學背景與經驗科學思維**

阿里擁有神經科學的博士背景。他訓練小鼠「數數」，記錄神經元活動，研究智能的生物學基礎。這段經歷讓他習慣用經驗科學來思考問題：先透過實驗去理解系統，再利用這種理解去改進系統。

為了處理高維度資料，他開始深入機器學習領域。在經歷了 AlexNet、DQN 等里程碑事件後，他下定決心轉向 AI，並希望為深度學習建立一套「可解釋的科學框架」。

然而，他很快發現，弄清楚「為什麼有效」並不難，真正難的是用這種理解去把系統做得更好。許多看似與性能相關的可解釋指標，一旦直接去優化，往往優化的只是相關性，而非因果性。

**2020年，阿里意識到數據才是決定性因素。** 當時他研究的是歸納偏置，也就是如何透過改動模型架構或目標，把先驗知識注入模型，讓模型在小數據場景下能夠學得更好。

結果顯示，在小數據場景下，軟性歸納偏置很有用。但是當數據量超過百萬級別時，精心設計的偏置甚至開始拖後腿。相反，Transformer 雖然自帶較少的歸納偏置，卻在超大數據上表現亮眼。

這正是 **苦澀的教訓 (The Bitter Lesson)** 在他身上的真實寫照：**能更好利用算力與數據的通用方法，最終會勝過依賴人類專家知識的特定技巧。**

冷靜之後，他選擇研究數據。數據研究最吸引他的一點是，科學上有趣的問題往往和實踐中有用的問題高度重合。理解一個數據點為什麼有用，幾乎可以立刻指導數據集的改造，提升模型性能。

**數據在 AI 研究中長期投入不足的原因**

阿里發現，相對於數據的影響力而言，數據在 AI 研究中長期投入不足，這背後是科研文化、激勵機制和歷史慣性共同作用的結果。

*   **文化偏見：** 數據工作往往被視為二等工作，缺乏研究的荣耀感。
*   **研究激勵的錯位：** 長期以來，機器學習的範式都是給定一個資料集，然後去優化測試集的表現，創新自然集中在模型與算法方面。
*   **時代背景的變化：** 2019 年前，主流是監督學習，數據稀缺。自監督學習崛起後，遊戲規則被徹底改寫，數據規模從百萬級躍遷到萬億級，AI 的核心矛盾從數據稀缺轉為數據過多。

**數據過多帶來的問題：**

*   模型更容易欠擬合。
*   抓取來的網路資料充滿了冗餘、低品質甚至有害的資訊。
*   過去的 Scaling Laws 基於所有數據點價值相等的假設，但這一點已經失效。

**在數據過多的時代，如何去除冗餘數據，度量資訊的增益，成了頭號難題。** **數據策展 (Data Curation) 的重要性被推到前所未有的高度。**

**數據策展 (Data Curation) 的概念與步驟**

阿里認為，數據策展不只是數據的篩選或清洗，而是一個更系統的工程，包含以下步驟：

1.  **過濾 (Filtering)：** 剔除低質量、低資訊增益的數據。
2.  **重均衡 (Rebalancing)：** 對於長尾數據進行上/下採樣，讓模型學到完整的分布。
3.  **序列化 (Sequencing)：** 合理編排數據的先後次序，用更少算力達成同等效果。
4.  **合成數據 (Synthetic Data) 的使用：** 用模型生成高品質的合成樣本，增強原始數據集。
5.  **批處理 (Batching)：** 如何組織和處理批次，影響學習速度。

**數據策展 (Data Curation) 的兩個重要概念：冗餘與自動化**

*   **冗餘：** 需要在無監督的條件下，自動發現類似大象和狗的概念，評估各自的複雜度，再決定每個概念應該保留多少冗餘。
*   **自動化：** 數據點的價值由它與訓練集中所有其他數據點的關係決定。人類無法在腦中裝著整個數據集進行全局判斷，但算法可以。因此，數據策展必須是自動化的，甚至要刻意排除人的干預。

**合成數據的兩種範式：**

1.  **「從無到有」：** 讓大模型憑空生成新的知識，容易導致模型崩塌。
2.  **「轉述或重寫」：** 知識來源於原始數據，模型只是將原始數據中的資訊重新組織。

**Datology AI 近期的 Beyond Web 論文總結了合成數據的七點體會：**

1.  合成數據不等於知識蒸餾。
2.  要想真正的破牆，得靠好的數據。
3.  高品質的種子很重要，但不是全部。
4.  風格匹配雖然有用，但是天花板很快出現。
5.  數據的多樣性決定了持續收益。
6.  改寫模型本身的影响不大。
7.  小模型其實也夠用。

**基於這些經驗，BeyondWeb 在 8B 模型實驗中給出了亮眼結果。**

*   用 BeyondWeb 數據訓練，速度比普通網路數據快 7.7 倍。
*   在 BeyondWeb 上訓練的 3B 模型，表現超過在其他數據集上訓練的 8B 模型。

這展示了數據策展的槓桿效應。

**DatologyAI 的價值：更快、更好、更小 (Faster/Better/Smaller)**

*   **更快：** 訓練速度提升，實驗迭代次數呈指數級上升。
*   **更好：** 好的數據如同算力的倍增器，效果更好。
*   **更小：** 推理成本降低，更具商業優勢。

**Datology 的使命：推倒數據的屏障**

Datology 與 RC 基礎模型的合作，從 25 萬億 token 的原始池子起步，經過數據策展，篩選到 7 萬億 token 的高品質集合，不僅模型性能更強，訓練速度也顯著提升。這說明數據策展的收益是可以疊加的。

**結論：AI 的盡頭，一定是更好的數據**

當行業還在模型和算力上內捲時，真正能夠改寫遊戲規則的，或許正是對數據的重新認識。AI 的盡頭未必是更大的模型，但一定是更好的數據。一個屬於數據策展的時代，也許正在到來。

感謝大家收看本期視頻，我們下期再見。

[model=gemini-2.0-flash,0]
