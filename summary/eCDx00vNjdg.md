好的，以下是整理后的文稿，使其更清晰、更具条理性：

**标题：Meta 开源 Llama 4 系列模型：参数规模达 2 万亿，性能超越多项竞品**

**引言：**

大家好，我是最佳拍档的大飞。Meta 突然宣布开源 Llama 4 系列模型，包括支持原生多模态，最大参数规模高达 2 万亿，本期视频将详细介绍。

**Llama 4 系列模型介绍：**

Llama 4 系列包含三个参数规模的模型：

*   **Llama 4 Scout:**
    *   小型且快速模型，170 亿激活参数、16 个专家、1090 亿总参数。
    *   亮点：支持 1000 万 token 上下文窗口，可处理 20 多小时视频，适合多文档摘要、大规模用户活动解析、大型代码库推理等应用。
    *   Int 4 量化后可在单个 H100 GPU 上运行。
    *   性能超越 Gemma 3、Gemini 2.0 Flash-Lite、Mistral 3.1 等模型。
        *   MMMU 图像推理：69.4 分 (高于 Gemini 2.0 Flash-Lite 68.0, Gemma 3 64.9, Mistral 3.1 62.8)
        *   MathVista 数学测试：70.7 分 (优于部分对比模型)
*   **Llama 4 Maverick:**
    *   主打多模态能力模型，170 亿激活参数、128 个专家、4000 亿总参数。
    *   在多个主流基准测试中击败 GPT-4o 和 Gemini 2.0 Flash 等模型。
    *   推理和编码能力与 DeepSeek v3 相当，但激活参数量不到 v3 的一半，性价比高。
    *   实验性质的聊天版本 LMArena ELO 评分 1417，排名第二，成为第四个突破 1400 分的大模型。在困难提示、编程、数学、创意写作等任务中排名第一。
        *   Chart QA 图像理解：90.0 分 (高于 Gemini 2.0 Flash 88.3, DeepSeek v3.1 85.7)
        *   Coding LiveCodeBench 编码测试：43.4 分 (优于部分对比模型)
*   **Llama 4 Behemoth:**
    *   仍在训练中，2880 亿激活参数、16 个专家、近 2 万亿总参数，Meta 迄今为止最强大的模型之一。
    *   在多个 STEM 基准测试中优于 GPT-4.5、Claude Sonnet 3.7、Gemini 2.0 Pro。
        *   MATH-500 推理：95.0 分 (高于 Claude Sonnet 3.7 82.2, Gemini 2.0 Pro 91.8)
        *   MMLU 多语言：85.8 分，展现强大的多语言处理能力。
    *   作为教师模型，通过蒸馏为 Llama 4 Maverick 等较小模型提供知识传递。

**Llama 4 系列的技术突破：**

*   **架构：** 混合专家 MoE 架构。每个 token 只激活总参数的一小部分，训练和推理效率更高。
    *   例如 Maverick，通过交替使用密集层和 MoE 层，提升推理效率。MoE 层有 128 个路由专家和 1 个共享专家。每个 token 被送到共享专家和 128 个路由专家中的一个，降低服务成本和延迟。
*   **多模态能力：** 早期融合技术，将文本和视觉 token 无缝整合到统一的模型框架中。
    *   利用海量无标签文本、图片和视频数据进行联合预训练。
    *   升级基于 MetaCLIP 的视觉编码器，与冻结的 Llama 模型分开训练，更好地适配大语言模型。
    *   在复杂场景下的表现超越部分竞争对手，无论是视觉处理任务还是语音对话任务。
*   **训练数据：** 来源广泛，包含公开的网络数据和 Meta 生态系统内的许可数据（Instagram、Facebook 公开帖子、用户与 Meta AI 交互记录）。
    *   提升了模型在多语言支持和现实场景中的适应性。
    *   在 200 种语言上预训练，实现了开源的微调支持。超过 10 亿个 token 的语言就有 100 多种，多语言 token 数量比 Llama 3 多 10 倍。
    *   预训练的整体数据量超过 30 万亿个 token，是 Llama 3 预训练的两倍多。
*   **上下文窗口长度：** 重大突破。
    *   Llama 4 Scout 支持高达 1000 万 token 的上下文窗口，Llama 4 Maverick 达到 100 万 token。
    *   Llama 3 的最大上下文仅为 128k token。
    *   超大上下文窗口使得 Llama 4 在处理长文档、复杂对话和多轮推理任务时有明显优势。
    *   采用创新的 iRoPE 架构，通过交错注意力层结合旋转位置嵌入，去除部分位置编码，推理时对注意力进行温度缩放，增强模型长度泛化能力。

**训练和优化：**

*   **预训练阶段：** 采用 MoE 架构、早期融合多模态数据、MetaP 技术设置超参数，进行新的中期训练方法，利用专门的数据集进行长上下文扩展。
*   **后训练阶段：** 全新训练流程：从轻量级监督微调到在线强化学习，再到轻量级直接偏好优化 DPO。
    *   训练 Llama 4 Maverick 时，使用 Llama 模型作为评判工具，剔除超过 50% 被标记为“简单”的数据，只留下较难的数据集进行监督微调。
    *   在线强化学习阶段，精心挑选更具挑战性的提示，采用持续在线强化学习策略，交替进行模型训练和数据过滤。
    *   通过 DPO 处理模型响应质量的边缘情况。
*   **Llama 4 Behemoth 的后训练：**
    *   精简 95% 的监督微调数据，确保模型质量和效率。
    *   通过 pass@k 分析和采样高难度的提示，设计了逐渐增加提示难度的训练课程。动态过滤掉没有优势的提示，混合多种能力的提示来构建训练批次。
    *   优化 MoE 并行设计，开发了完全异步的在线强化学习训练框架，训练效率提升 10 倍。

**下载与实测效果：**

*   Llama 4 Scout 和 Llama 4 Maverick 已可在 llama.com 和 Hugging Face 上下载。后续将上线更多云平台和集成服务商。
*   网友实测效果略微差强人意，在特定问题上表现不佳。
*   但 Llama 4 的发布为开源模型领域注入了活力。

**未来展望：**

*   Meta 的推理模型即将到来。
*   有传言称 Meta 提前发布 Llama 4 是因为下周有更强大的模型要发布。
*   Sam Altman 也在预热 OpenAI 的大招。

**结尾：**

感谢收看本期视频，我们下期再见。

**改进说明:**

*   **标题明确：** 概括了主要内容。
*   **结构清晰：** 分为引言、模型介绍、技术突破、训练优化、下载与实测、未来展望和结尾，更易于阅读和理解。
*   **重点突出：** 使用粗体字突出关键信息，例如模型名称、参数、性能等。
*   **数据呈现：** 使用列表和表格更清晰地展示数据和对比结果。
*   **语言精炼：** 删除了冗余的语句，使表达更简洁。
*   **术语解释：** 适当解释了 MoE 等专业术语。
*   **归纳总结：** 将模型和技术突破的要点进行了总结归纳，方便读者快速掌握信息。

希望这个整理后的文稿对您有帮助！

[model=gemini-2.0-flash,0]
