好的，作為您的專業文件整理員，我已將這篇關於楊立昆（Yann LeCun）AI觀點的長篇文稿進行了整理，提煉出核心要點，並以清晰的結構呈現，方便您快速掌握。

---

### **楊立昆：AI下一場革命——從語言模仿到世界理解**

---

**引言：當前AI的困境與楊立昆的洞見**

當前大語言模型（LLMs）在考試、編程、解方程等領域表現非凡，但可靠的家務機器人、L5級自動駕駛依然遙不可及，AI能耗也居高不下。這些問題的答案，可能正藏在卷積神經網絡（CNN）奠基人之一楊立昆與計算機視覺專家馬克·波萊菲斯（Marc Pollefeys）在達沃斯論壇的深度對話中。楊立昆的見解直擊行業痛點，預示著下一場AI革命的方向。

---

**一、具身智能的重新定義：超越機器人**

*   **誤區糾正：** 具身智能不僅限於「機器人」。
*   **廣闊範疇：**
    *   **實體AI：** 如自動駕駛汽車、人形機器人，能在現實世界感知、理解、推理並行動。
    *   **非具身物理AI：** 雖無實體，但處理現實世界數據，如製造流程優化、渦輪機控制等。
*   **核心判斷標準：** 數據形態為「高維、連續、帶噪聲的信號序列」（如視頻、傳感器數據），即屬於具身智能範疇。
*   **本質差異：** 具身智能面對的是充滿不確定性的「物理世界」，與大語言模型所處的「語言世界」截然不同。

---

**二、大語言模型與當前主流路徑的局限**

1.  **大語言模型的成功與失敗：**
    *   **成功原因：** 語言是離散、符號化、有明確規則的。
    *   **失敗原因：** 物理世界複雜多變，大語言模型缺乏處理現實世界複雜問題的能力，因此無法實現可靠的家務機器人及消費端L5級自動駕駛。
2.  **L5級自動駕駛的困境：**
    *   **現狀：** Waymo等公司的L4級方案「取巧」，高度依賴高精度地圖，並嚴格限制運營時間和空間，成本高昂，難以普及。
    *   **效率問題：** 人類只需數十小時練習即可學會開車，AI卻需數百萬小時訓練仍無法企及。核心差異在於人類擁有「世界模型」。
3.  **人形機器人的現狀：**
    *   **表象：** 高難度動作演示多為「預先計算好」。
    *   **本質：** 機器人缺乏常識，甚至「不如一隻家貓」，遇到未訓練過的場景會「宕機」。
4.  **視覺語言動作模型的缺陷（VLA）：**
    *   **思路：** 將大語言模型擴展為視覺語言模型、視覺語言動作模型，試圖以「文本優先」處理視覺、語言、動作。
    *   **楊立昆批判：** 這種方法存在重大缺陷，難以奏效。它們本質上是「腳本式自動化」，極其脆弱，無法應對新情境。與80年代「專家系統」的失敗宿命相似，缺乏預測後果、規劃和推理的核心能力。
5.  **生成式AI的誤區：**
    *   **楊立昆觀點：** 生成式AI（如擴散模型）是理解物理世界的「錯誤路徑」。
    *   **原因：** 試圖在像素層級重現每一個細節是「徒勞」且無法幫助AI理解世界結構的。現實世界細節無限且不可預測，生成式模型難以精確預測。
    *   **違背智能本質：** 智能的核心在於「忽略無關且不可預測的細節」，進行長期有效預測。生成式模型恰恰相反，導致只能在短期局部發揮作用。

---

**三、楊立昆提出的正確路徑：非生成式聯合嵌入預測架構（JEPA）**

1.  **核心思想：**
    *   讓AI在「抽象表示空間」中進行預測，而非原始像素空間。
    *   抓住事物「本質特徵」，忽略無關細節，構建「世界模型」。
2.  **分層世界模型：**
    *   **人類範例：** 人類規劃（如紐約到巴黎旅行）是分層次的，從高抽象層級（去機場）逐步分解到低層級（肌肉控制）。
    *   **AI需求：** 智能AI需具備多層級世界模型，低層級負責高細節短期動作，高層級負責抽象長期規劃。
3.  **JEPA的工作原理：**
    *   **訓練方式：** 自監督學習。讀取視頻，遮掩部分，通過兩個編碼器，訓練預測器從損壞部分預測「完整視頻的抽象表示」。
    *   **關鍵特性：** 預測可基於「預想的動作」進行調節，形成「預測-規劃-行動」的閉環。
    *   **抽象層級與時間跨度：** 學習到的抽象層級取決於訓練時設定的預測時間跨度。預測跨度越長，系統學習到的抽象特徵層級越高。
4.  **數據與物理常識：**
    *   **視頻數據為關鍵：** 相比文本，視頻數據是訓練物理常識的最佳選擇（如嬰兒觀察世界學習重力）。
    *   **V-JEPA 2實驗：** 在相當於百年時長的視頻數據（約10^17-10^18字節，比最大LLM文本數據多百倍）上訓練。
    *   **成果：** 模型能識別違背物理規律的視頻（如小球空中停住），表明其已具備「基本的物理常識」。
    *   **超越文本：** 文本數據只能傳遞人類總結知識，視頻數據則蘊含物理規律與因果關係。

---

**四、蛋糕類比：學習方式的效率差異**

楊立昆用「蛋糕類比」闡述自監督學習、有監督學習和強化學習的角色：

*   **自監督學習（蛋糕主體）：** 讓AI了解世界、學習抽象表示、建立世界模型、進行預測。這是智能的核心，無需專家行為或他人指導，只需觀察世界自然流逝。人類和動物大部分知識由此獲得。
*   **有監督學習（薄層奶油）：** 模仿人類或專家行為，快速掌握特定技能。在整個智能系統中佔比很小。
*   **強化學習（櫻桃）：** 僅用於AI行為的微小「微調」。樣本效率極低，無法支撐複雜系統。例如，自動駕駛汽車需沖下懸崖數千次才能學會躲避，且經驗難以遷移。在遊戲中成功因環境可控、數據海量，但在現實世界不適用。
*   **高效學習方式：** 以自監督學習為基礎構建世界模型，再用有監督學習快速掌握技能，最後用強化學習微調。
*   **系統一與系統二：** 當前AI多實現「系統一」的自動化任務；JEPA目標是讓AI具備「系統二」的規劃和推理能力（通過調用心理世界模型規劃行動）。

---

**五、AI硬件的挑戰與未來**

1.  **能耗問題：**
    *   **人類大腦：** 僅20瓦，原地存儲與計算，能耗極低。
    *   **當前AI硬件：** 數據需在內存和計算引擎間頻繁搬運（硬件多路復用），能耗幾乎全消耗在數據存取與傳輸上。
    *   **解決方案：** 需要全新硬件技術（如自旋電子學、碳納米管、光學器件），實現納米尺度的「模擬存儲」與「原位計算」。
    *   **速度與並行：** 低功耗AI系統不需超快，而需「超大規模並行」（如人腦運行頻率低，但反應足夠應對現實）。
2.  **硬件架構偏置：**
    *   **實時視覺AI：** 目前所有實時視覺AI系統均採用卷積網絡（CNN），而非Transformer，因CNN更高效且實時性強。
    *   **優化潛力：** 若將Transformer優化技巧應用於CNN，兩者表現幾乎難分伯仲，架構本身無本質優劣。

---

**六、具身智能落地的“最後一公里”：行動適配**

1.  **當前問題：** 模型遷移到新設備需從頭訓練，高度依賴特定相機位置和機械臂配置，缺乏位移不變性等核心歸納偏置。
2.  **V-JEPA 2.1的兩階段方案：**
    *   **第一階段（通用世界模型構建）：** 在長達百年的自然視頻數據上預訓練模型，學習視頻特徵表示及填補畫面空白，不關聯特定動作或具身。純粹為構建對物理現實的「高階抽象表示和預測能力」。
    *   **第二階段（具身動作適配）：** 固定預訓練編碼器，微調預測器，引入動作作為輸入。訓練機器人機械動力學模型、環境模型和交互模型。
    *   **效果：** 微調數據量少，通過模擬系統動力學即可獲得，模型通用性強，能快速適應不同設備和環境。
    *   **核心創新：** 將「世界模型的通用構建」與「具身動作的專門適配」分離。

---

**七、未來AI的願景：一場全新的革命**

1.  **楊立昆的十年願景：** 構建能理解物理世界、處理任何模態數據的AI系統。具備分層世界模型、基於模型進行規劃和推理、能預測行為後果。其性能將「遠超當前的大語言模型」。
2.  **範式轉變：** 從當前基於自回歸Token預測的「大語言模型範式」，轉向「基於規劃的非生成式範式」。這將使AI從「鸚鵡學舌式」的語言模仿，升級為「洞察本質式」的世界理解。
3.  **非生成式AI：** 並非不生成內容，而是指不在原始輸入信號層級重現，而是在抽象表示層進行預測，捕捉世界核心規律，忽略無關信息，實現長期有效預測，具備真正智能。
4.  **可行性：** 概念上無巨大挑戰，人類一直在進行類似的在線自適應。實驗結果已證明通過視頻數據的自監督學習可獲得基本物理常識，分層規劃路徑清晰。
5.  **潛在影響：** 帶來可靠的家務機器人、L5級自動駕駛的落地，人形機器人進入實際應用，AI系統能耗大幅降低。
6.  **挑戰：** 需解決視頻訓練數據規模與質量、JEPA訓練效率、低功耗硬件研發等工程問題。

---

**結語：**

楊立昆始終質疑主流、探索真相。他提出的「非生成式AI範式」為AI的未來發展指明了新方向，預示著一場將徹底改變AI應用場景的全新革命。讓我們拭目以待。

[model=gemini-2.5-flash,0]
