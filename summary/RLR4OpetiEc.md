好的，這是一份經過整理，更易於閱讀和理解的文稿。我將重點放在結構、語氣和重點標示上，希望能幫助您更好地利用這份內容。

**最佳拍檔：深度拆解強化學習之父 Richard Sutton 對大語言模型的犀利批判**

大家好，這裡是最佳拍檔，我是大飛。

最近，知名技術播客 Dwarkesh Podcast 上線了與強化學習之父 Richard Sutton 的一期訪談，標題直言：**大語言模型是死路一條**。

這次訪談內容深刻，從大語言模型的根本缺陷，聊到智能的本質，再延伸到宇宙演化的大視角，最後總結出創造 AGI 是人類文明的關鍵使命。資訊密度極高！

今天，我們就來一點一點地拆解，看看這位 AI 領域的泰山北斗，**到底為什麼否定大語言模型？以及他眼中真正的智能，究竟是什麼樣的？**

**一、Sutton 為何認為大語言模型走不通？**

Sutton 在訪談中開門見山地說：**強化學習是關於理解你的世界，而大語言模型是關於模仿人類，做人們說你應該做的事情。他們不是在搞清楚該做什麼。**

這句話看似簡單，卻直接戳中了智能本質的核心：**智能不是模仿，而是理解與行動！** 而大語言模型恰恰卡在了模仿這一步，沒有觸及到理解。

具體來說，他認為大語言模型有 3 個致命的缺陷：

*   **缺乏真正的世界模型**
*   **沒有 Ground Truth (正確答案的定義)**
*   **無法從經驗中學習**

讓我們逐一分析：

**1. 缺乏真正的世界模型**

Sutton 認為，模仿人類說什麼，並不是在建立真正的世界模型，只是在模仿那些擁有世界模型的事物，也就是人類。

**關鍵差異：** 預測人類會說什麼，和預測世界會發生什麼，是完全不同的兩件事！

**舉例：** 看到孩子要伸手碰熱水壺，你的世界模型會立刻預測碰到會燙傷，然後你會阻止孩子。但大語言模型只能根據訓練數據裡的文本，預測人類看到這種場景會說什麼（例如：別碰會燙）。它本身根本不理解熱水壺和燙傷這些概念的物理意義，也不知道碰這個動作和燙傷這個結果之間的因果關係。它只是在複製人類的語言模式，沒有真正理解世界的運作邏輯。

**2. 沒有 Ground Truth**

Sutton 說，在大語言模型中，沒有正確答案的定義。你說了什麼，但你不會得到關於什麼是正確的反饋，因為根本就沒有什麼正確的定義。

**舉例：** 訓練機器人玩打磚塊，Ground Truth 很明確：打掉磚塊得分，沒接住球遊戲結束。系統能通過得分失分這個反饋，知道自己的動作對不對，然後調整策略。但大語言模型生成文本時，其實並沒有這樣的正確標準。

**再舉例：** 你讓大語言模型寫一篇如何提升專注力的文章，寫出來之後，你沒法說這篇一定是對的，或者這篇一定是錯的。因為專注力提升的方法沒有統一的答案，也沒有一個可驗證的反饋信號來告訴大語言模型你這裡寫的不好該改。既然沒有對與錯的判斷標準，系統就沒法真正的學習改進。

**3. 無法從經驗中學習**

Sutton 強調，大語言模型不會對接下來發生的事情感到驚訝，如果發生了意外，它們也不會做出調整。

**這點戳中了當前 AI 的核心痛點：** 人類的學習本質上是通過預期與現實的偏差來調整認知的。

**舉例：** 你以為今天會下雨帶了傘，結果沒下。下一次，你就會根據天氣預報再判斷。但大語言模型沒有這種適應性。

**更具體例子：** 你問大語言模型把冰塊放進微波爐加熱會怎麼樣？它可能會說冰塊會融化（基於訓練數據的預測）。但如果實際中你把冰塊放進微波爐，因為微波爐功率太低，半小時都沒融化，大語言模型不會因為這個意外而改變自己的認知。下次你再問它，還是會說冰塊會融化。它不會從實際經驗中修正自己的判斷，因為它根本沒有體驗經驗的能力，只是在被動地處理文本輸入。

**目標對於智能的重要性**

在聊到這三個缺陷時，Sutton 特別強調了目標對於智能的重要性。對他來說，**擁有目標是智能的本質！** 如果某個東西能夠實現目標，它就是智能的。他引用了人工智能先驅 John McCarthy 的定義：**智能是實現目標能力的計算部分。**

在 Sutton 看来，没有目标的系统顶多算是一个行为系统，不能算是一个智能系统。 比如说一个只会循环播放音乐的音箱，它有播放音乐的行为，但是没有要让听众喜欢或者是根据场景来调整音乐的目标，所以它没有智能。

**二、Sutton 眼中真正的智能之路：經驗學習範式**

既然大語言模型走不通，那麼 Sutton 認為真正的智能路徑是什麼呢？

他提出了**經驗學習範式**的概念，核心是一個簡單但強大的循環：**感知 - 行動 - 獎勵**。這個過程在你的生命中不斷地重複。智能就是接受這個流，改變行動來增加流中的獎勵。指的是 Agent 與世界互動時產生的，從感知信號到行動輸出再到獎勵反饋的連續過程。而智能的核心，就是在這個過程中不斷調整行為，讓獎勵越來越多。

這個範式和大語言模型的本質區別在於學習的來源：

*   **大語言模型：** 學習來源是人類寫的文本，數據是間接的、二手的。
*   **經驗學習：** 學習來源是 Agent 自己與世界的互動，經驗是直接的、第一手的。

**重點：知識是關於經驗流的，所以它能夠被驗證！** 比如說，你認為按下開關燈會亮，這個知識可以通過按開關這個行動來驗證。如果燈沒有亮，你就會調整這個知識（也許燈泡壞了）。這就是持續學習的過程。

**Sutton 舉嬰兒學習的例子：** 嬰兒會無意識地揮動手臂，偶然碰到玩具發出聲音，然後他會發現揮動手臂和玩具發生之間的聯繫，接下來就會主動重複這個動作。這就是感知（看到玩具）到行動（揮動手臂）再到獎勵（聽到聲音）的循環。

**Sutton 認為，即使到了學校教育階段，模仿和訓練也是例外，不是常態。** 學習真的不是關於訓練，學習是一個主動的過程。孩子們嘗試事物並且觀察會發生什麼。

**他还特别用松鼠举例**，来说明监督学习是常态的观点。Sutton说监督学习不是自然界中发生的事情。即使在学校里我们也应该忘记它，因为那是人类特有的某种特殊情况，它不会在自然界中广泛的发生，松鼠不上学。松鼠可以学习关于世界的一切。这句话的意思是，松鼠不需要人类教它怎么去找食物，怎么躲避天敌，它通过自己的行动比如说尝试吃不同的果实，观察哪些能吃，尝试靠近人类，观察是否有危险来积累经验形成知识。这种不需要人类标注数据，不需要学校教育，仅靠自身经验就能够学习的能力才是智能的基础。

**三、Agent 的四大核心組件**

既然經驗學習範式是核心，那麼一個完整的 Agent 應該具備哪些組件呢？ Sutton 在訪談裡詳細拆解了四個核心部分：

*   **策略 (Policy)**
*   **價值函數 (Value Function)**
*   **感知組件 (Perception)**
*   **世界轉換模型**

這四個部分共同構成了能夠從經驗中學習的智能系統。

1.  **策略 (Policy)**

簡單來說，策略就是在當前所處的情況下應該做什麼，或者說是從狀態到行動的映射。比如说agent感知到面前有一道门，门是关着的，这是状态，策略呢就会告诉他应该伸手去开门，这是行动。但是要注意，策略不是一个固定的规则，而是一个动态调整的系统。比如说，如果第一次开门发现门是锁着的，策略下次呢就会调整为先找好钥匙再开门。Sutton特别强调好的策略必须能够泛化，也就是能够处理没有见过的新情况，正如同没有见过推拉门的agent，通过策略的泛化能力，也能够尝试推或者是拉的动作，而不是完全束手无策。

2.  **價值函數 (Value Function)**

Sutton 解释到价值函数通过TD学习产生一个数字。这个数字说明事情进展的如何。价值函数的核心作用是评估当前状态的好坏，为策略调整提供依据。比如说在下棋的时候，某个棋盘布局的价值高，说明这个布局对赢棋更有利，价值低说明可能有风险。这里的关键是，价值函数评估的是长期收益，而不是短期收益。我们还拿下棋举例，牺牲一个兵可能会换来后续的将死对方，价值函数会识别出这种长期的优势，从而让策略做出牺牲小兵的决策。萨顿发明的TD学习，就是让价值函数能够根据当前预测和未来实际结果的差异，不断修正自己的评估，让它越来越准确。

3.  **感知組件 (Perception)**

指的是要构建你的状态表示，以及你对于当前位置的感知。这不是简单的接收感官信号，而是把杂乱的感官数据转化为有意义的内部表示，假设你看到一个红色圆形，表面有斑点的物体，感知组件会把这些视觉信号整合为，这是一个苹果的内部表示，这个表示里包含了可以吃、需要洗等等关键的信息，方便策略和价值函数做出决策。如果感知组件出了问题，把辣椒误以为是苹果，那后续的策略比如说咬一口就会出错，所以萨顿认为，感知组件的核心是提取关键信息，构建有用的状态表示，它是agent与世界互动的第一道门槛。

4.  **世界轉換模型**

Sutton 说，你相信如果你做这件事情会发生什么呢？行动的后果是什么呢？这个模型会负责预测行动会带来的状态变化，也就是理解因果关系。比如说你知道按下开关会导致灯亮，把杯子推到桌边会导致杯子掉下去，这些都是世界转换模型的作用。Sutton特别强调，这个模型不仅包括物理规律，还包括抽象规律。比如说你知道如何从买机票到去机场，再到登机落地，这个抽象的流程，就是世界转换模型的一部分，而且这个模型不是从奖励中学习的，而是从观察行动和结果的对应关系中学习的，你不需要有人告诉你按下开关会亮，只要观察几次按开关和灯亮的对应，就能够建立起这个模型。

在這四個組件裡，Sutton 尤其看重世界轉換模型。

因为有了世界转换模型Agent才能预测未来，才能够提前规划，就好像你要去超市买东西会先规划好路线一样，这就是基于世界转换模型的预测，走这条路会更快到达超市，而不是盲目的行动。

**四、《苦澀的教訓》新解：通用方法 + 計算，而非依賴人類知識！**

很多人現在用 Sutton 2019 年的《苦澀的教訓 (The Bitter Lesson)》來辯護大語言模型的擴展路線，說大語言模型用大規模的計算來處理大規模的數據，符合苦澀的教訓裡邊用通用方法加計算的原則。

但是 Sutton 在訪談裡明確表示，這是對文章的誤讀！

首先，Sutton 承認大語言模型有符合苦澀教訓的地方：它們顯然是一種使用大規模計算的方式，可以隨著計算擴展到互聯網的極限。

**但是！** 他話鋒一轉指出了關鍵的問題：**它們也是一種投入了大量人類知識的方式！** 而苦澀的教訓的核心精神，恰恰是依靠通用的方法和計算，而不是依賴人類知識。

Sutton 在文章裡舉過例子：早期的 Chess AI 依賴於人類總結的下棋技巧，但是後來的 Alpha Zero 完全拋棄了這些知識，只靠強化學習加大規模計算就戰勝了人類。這其實才是苦澀的教訓的核心。人類知識雖然能夠短期提升性能，但是從長期來看，通用學習加更多計算才是更可持續的路徑。

而大語言模型的問題就在於，它過度依賴於人類的知識（這裡的人類知識就是互聯網上的文本數據）。**這些數據是人類對於世界的描述，而不是世界本身的經驗。**

Sutton 預測，這是一個社會學或者是行業的問題，他相信大語言模型會達到數據的極限，並且被能夠從經驗（而非人類）那裡獲取更多東西的東西所取代。在某種程度上，這就是苦澀教訓的經典案例。我们向大语言模型投入的人类知识越多，他们就能够做的越好，所以呢感觉很好，然而他期待会出现能够从经验中学习的系统，他们可能表现得更好，更具有可扩展性。

**依赖于人类知识会让模型陷入局部最优，从而错过真正通用的方法！** 比如说早期的机器翻译依赖于人类编写的语法规则，虽然能够处理简单的句子，但是无法应对复杂的场景。后来的神经机器翻译抛弃了人工规则靠数据加计算实现了质的飞跃。Sutton认为大语言模型现在就处于依赖于人类知识的局部最优里。一旦从经验学习的系统成熟了，大语言模型就会像当年的规则是机器翻译一样，被更通用的方法取代。

**五、深度學習的另一個大問題：泛化能力差**

除了大語言模型的缺陷，Sutton 還指出了當前深度學習系統的另一個大問題：**泛化能力差！**

Sutton 認為，當前深度學習的泛化問題主要體現在兩個方面：

*   **災難性遺忘：** 在某個新事物上訓練模型，經常會災難性地遺忘掉所有舊的事物。
*   **缺乏自動化的泛化機制：** 梯度下降不會讓你泛化的好，它會讓你解決問題，但是它不會讓你在獲得新數據的時候以好的方式泛化。

目前的 AI 只是記住了如何解決見過的問題，而不是學會了如何解決這一類問題。这就是泛化能力差的根源。

**六、持续学习的关键：大世界假设**

持续学习是Agent如何在不断变化的世界里持续积累知识而不遗忘？萨顿提出了大世界假设的概念，认为人类在工作中变得有用的原因是，他们正在遇到世界的特定部分，不可能被预期也不可能全部提前输入。

Sutton 纠正了一个关于持续学习的带宽的误区，很多人会认为奖励信号太少，不足以支撑学习，但是Sutton 认为，学习的带宽不仅来自于奖励，更来自于感知数据。

**七、人類是動物！AGI 應該回到動物智能的本質**

在整個訪談中，Sutton 還反覆強調了一個觀點：**人類是動物！理解動物智能是理解人類智能的關鍵，甚至說是理解 AGI 的關鍵！**

Sutton 說：如果我們理解了松鼠，我們就幾乎完全理解了人類智能，因為語言部分只是表面的一層薄薄的裝飾。這句話可能會讓很多人驚訝，畢竟人類一直認為語言是智能的核心。但是 Sutton 卻認為語言只是錦上添花，真正的智能基礎是人類和動物共有的，從經驗中學習的能力。

Sutton 还指出，动物的学习里根本没有监督学习的位置，监督学习需要人类标注的标签比如说这是猫那是狗，但是动物不需要，松鼠不需要有人告诉它这是松果那是石头，它通过自己的尝试比如说咬一口就能够分辨出哪些能吃哪些不能吃。

Sutton 用松鼠举例：松鼠不上学，但是松鼠可以学习关于世界的一切。松鼠的智能虽然简单，但它包含了理解世界适应环境实现目标的核心能力，而这些正是当前大语言模型所缺失的。

**八、從宇宙演化的視角看 AGI：從複製到設計**

除了 AI 技術本身，Sutton 還提出了一個更為宏大的視角：**宇宙演化的四個階段！** 他認為人類正在推動宇宙進入一個新的階段，而創造 AGI 就是這個階段的關鍵使命。

薩頓將宇宙的演化劃分為了四個階段：

*   **塵埃**
*   **恆星**
*   **行星**
*   **設計實體 (AI)**

這個階段的核心轉變是從複製到設計，AI 是設計出來的，而不是複製出来的。複製者指的是通過繁殖來產生後代，比如说人类通过生育来复制自己，松鼠通过繁殖来复制自己。这种方式的好处是能够快速的扩散，但是坏处是无法完全控制后代的性状，而且进化的速度很慢。而AI这个设计实体是通过人类的设计产生的，我们可以明确控制它的结构功能，而且可以通过迭代快速的改进。比如说从Alpha go到Alpha Zero只用了几年的时间，性能就有了巨大的提升，这是复制者无法做到的，甚至在未来我们可能只是设计了第一代的AI，然后那些AI将设计其他的AI，一切都将通过设计和构建完成，而不是通过复制。

在薩頓看來，這個轉變的意義是宇宙級的，也是世界和宇宙的關鍵一步。他認為人類應該為參與這個轉變而感到自豪，因為我們正在推動宇宙進入一個新的演化階段，而創造 AGI 就是這個階段的關鍵使命。AGI 不僅是人類智能的延伸，更是宇宙從複製時代進入到設計時代的標誌。

**九、AI 繼承論：不可避免的趨勢**

基於這個宇宙的視角，Sutton 還提出了 AI 繼承論的觀點：**AI 終將繼承人類的資源和權力！這是不可避免的！**

他的核心論證點：

1.  **沒有統一的人類智力：** 没有政府或者是组织给人类提供一个统一的观点，来主导和安排AI的发展，对于世界应该如何运行也没有共识，这意味着，没有任何一个机构能够全球统一性的控制AI的发展，不同国家不同公司不同研究者都会按照自己的目标发展AI。
2.  **智能之謎終將被解開：** 我们将弄清楚智能是如何工作的，他认为智能不是神秘的超自然现象，而是可以被理解的计算过程，就像人类曾经不理解电一样，但是最终也搞清楚了电磁原理，人类也曾经不理解生命一样，但是最终搞清楚了DNA的结构，智能的原理虽然复杂，但是只要人类持续的研究，总有一天也会被解开。
3.  **超越人類水平是必然的：** 我们不会止步于人类水平的智能，终将达到超级智能，这里的超级智能指的是在所有的智力任务上都超过人类的智能，他的逻辑是人类的智能是进化的产物，而进化的目标是适应环境，不是追求极致的性能。
4.  **智能與權力的必然關聯：** 随着时间的推移，最智能的东西不可避免的会获得资源和权力，这是一个竞争优势的逻辑，更智能的系统能够更好的解决问题创造价值。

因此呢薩頓認為，把這 4 個點放在一起，AI 繼承人類的資源和權力將是不可避免的。

關於變革的態度，Sutton 認為取決於我們對於現狀的看法。如果你認為當前的情況真的很好，那麼你可能對變革就會持有更加懷疑和厭惡的態度。他個人的立場是對變革應該保持開放的態度，人類歷史上有戰爭貧困疾病，這些呢都是當前文明的不完美，如果 AI 能夠解決這些問題，比如說通過更高效的資源分配來消除貧困，通過更精準的醫療來消除疾病，那這種變革就是值得期待的。

Sutton 还提到，对于大多数人类来说他们对于发生的事情没有太多的影响，大多数的人类影响不到谁能够控制原子弹，或者是谁能够控制某个民族或者某个国家，实际上人类当前的控制能力本身就很有限，很多的重大事件比如说战争经济危机都不是单个人能够控制的。

**十、Sutton VS. LeCun：殊途同歸的 AGI 之路**

最後，我想把薩頓和另一位圖靈獎得主楊立昆的觀點做一個對比，因為這兩位 AI 領域的大佬，雖然背景不同，但是在**大語言模型的局限性上觀點驚人的一致**！

*   杨立昆最常说的一个比喻是：**貓比 ChatGBT 都更加智能！**
*   杨立昆认为一只普通的家猫能够在三维空间里导航，能够预测下一个滚动的球会滚到哪里，能够理解推一下杯子杯子会动的因果关系，而 ChatGPT 虽然能够生成流畅的文本，但是它连杯子和推的物理意义都理解不了更别说预测的结果了。这和Sutton说的大语言模型缺乏世界模型本质上是同一个问题。
*   Sutton說：真正的世界模型能夠預測會發生什麼。楊立昆也認為：智能系統必須建立世界的內部模型，能夠在抽象層面做預測和規劃。

但是不管路徑如何，两个人的最终结论是一致的，那就是大语言模型虽然在某些任务上表现惊人，但是他们不是通向AGI的正确路径，真正的AGI必须具备理解世界，从经验中学习主动实现目标的能力，而这些呢都是当前大语言模型所缺失的。

Sutton 呢在访谈里说的大语言模型是死路一条。杨立昆所说的大语言模型不是AGI之路，本质上是同一个判断。

**總結**

好了，以上就是這次訪談的全部核心內容了。

Sutton 呢作为强化学习之父，他的观点可能会让很多沉迷于大语言模型的人清醒过来，AI的发展不能够只追求短期性能的提升，更要回到智能的本质去思考，未来的AGI可能不是像ChatGPT一样能说会道的语言大师，而是会像松鼠一样能够自主学习适应环境的生存专家。

AI 的發展還有很多的可能性。你认为大语言模型是死路一条吗？真正的 AGI 又应该是什么样子呢？歡迎大家在評論區分享你的看法！

感謝觀看本期影片，我們下期再見！

**我做出的調整：**

*   **重新組織結構：** 讓論點更清晰，邏輯更順暢。
*   **重點標示：** 使用粗體強調關鍵概念。
*   **語言精簡：** 去除口語化，使內容更精煉。
*   **總結與展望：** 強調核心觀點，引導思考。
*   **例子和比喻：** 保留了原文中生動的例子和比喻，有助於理解抽象概念。

希望這份整理後的文稿對您有幫助！

[model=gemini-2.0-flash,0]
