好的，我來將這篇文稿整理成更清晰易讀的格式，並針對一些細節提出建議。

**整理後的文稿：**

**标题：神经科学与人工智能的融合：AI如何帮助我们理解大脑？**

**引言：**

*   最佳拍档 - 大飞
*   时间：2023年3月
*   一个纽约大学的人工智能研讨会，讨论的不是算力或模型，而是神经系统和心理学与AI的关系。
*   最先进的AI系统在规模和复杂性上已可比肩人脑。研究人员借鉴心理学、语言学、心灵哲学等学科来理解大模型。
*   纽约大学教授格雷斯·林赛（Grace Lindsay）认为，这些学科目标和方法接近，可合并为“神经系统理解”。

**正文：**

1.  **AI如何颠覆神经科学的研究方法：**
    *   多层人工神经网络成为大脑建模的最先进方法（重现外部行为）。
    *   颠覆传统科学方法论：过去无法在人体上进行的实验，现在可以在模型中进行。
    *   将模型内部活动与活体大脑数据直接比较。
    *   例子：人工神经网络可以识别披头士乐队成员，但无法分辨鼓和吉他（人脑不会出现此现象）。
    *   结论：虽然AI机制与大脑不同，但相似的智能输出表明细节不重要。计算任务的要求会塑造低级别的组件。
    *   谷歌DeepMind的安德鲁·兰皮宁（Andrew Lampinen）认为，只要架构足够优秀，表征会更容易受到数据和训练过程的影响。
    *   林赛等人认为，应利用神经网络架构和学习算法来解释大脑功能。
    *   机器学习先驱约书亚·本吉奥（Yoshua Bengio）认为，神经科学适合描述，机器学习思维更利于解释“为什么”。

2.  **视觉神经科学：AI与神经生物学结合的领域**
    *   第一个硬件神经网络模仿自然视觉感知（20世纪50年代）。
    *   2010年代，图像识别网络媲美人类水平，但生物仿真性未知。
    *   麻省理工学院神经科学家开发实验范式：
        *   向猴子展示视觉刺激，测量大脑反应。
        *   用相同刺激训练人工神经网络，提取AI“表征”。
        *   比较猴子大脑数据和AI数据输出。
    *   科学家构建“映射模型”以还原大脑。
    *   研究发现，猴子大脑和人工神经网络对相同视觉刺激的反应类似。
    *   麻省理工学院教授南希·坎威舍尔（Nancy Kanwisher）认为，模型和大脑对类似问题有类似解法。
    *   AI网络改变了计算神经科学家研究的规模。
    *   Brain-Score.org网站对视觉模型进行排名（基于模型是否犯大脑犯的同样错误、反应时间是否相似）。
    *   研究人员可以直接访问人工神经元（机器中的变量）。
    *   林赛团队搞了一个人工神经网络，探索“祖母神经元”。发现基于图像训练的人工网络也有类似的神经元，但与网络识别人物或物体的整体能力无关。
    *   结论：神经元对图像的响应方式不一定能说明其对物体的分类作用。
    *   人工神经网络让深入研究视觉的处理层次成为可能。
    *   AI模型可以识别蓝色咖啡杯和蓝色花朵（像素层面相似，早期层次反应相似，后期层次差异明显）。
    *   林赛表示，机器发展出来的高级表征应与大脑的表征相匹配。

3.  **“生态有效实验”：在现实环境中观察大脑运作**
    *   传统刺激-反应实验需麻醉小鼠以消除噪音。
    *   人工神经网络可以让人研究自由活动的动物，通过收集眼动追踪和其他行为数据，然后再输入神经网络，从而发现不太明显的模式。
    *   降低对实验控制条件的需求。

4.  **大语言模型对神经科学的影响**
    *   理解语言比理解视觉更困难。
    *   动物模型只能捕捉语言的狭窄特征。
    *   GPT等大语言模型填补空白。
    *   虽然结构不同（大脑语言区是反馈回路，语言模型是前馈系统），但transformer层可以像人脑一样进行语言反馈（跟踪单词的上下文）。
    *   Transformer层与大脑海马体的运作相似。
    *   2021年，麻省理工学院教授叶夫利娜·费多连科（Evelina Fedorenko）等人采用AI技术，收集人们阅读和聆听句子时的大脑反应，并用相同句子训练语言模型，创建人类和机器神经活动之间的映射模型。
    *   实验发现，这些网络不仅生成了与人类近似的文本，而且是以大致上类似于人类的方式生成的。GPT-2尤其擅长模仿人类。
    *   费多连科认为，人类大脑的语言区域也可能如此（高级的自动更正算法）。
    *   大语言模型训练大约1亿个单词后，对语言的熟练程度可以达到人类水平。
    *   当我们理解一个句子时，大脑主要依赖的是语法结构还是单词的含义？
    *   费多连科的研究生通过调整句子，发现对句子的轻微改变（去掉“the”，交换连续的单词）几乎对AI没有影响，因为没有触及单词的含义。
    *   当研究人员破坏句子结构（改变名词和动词），模型就受到了很大影响。
    *   例子：“The quick brown fox jumped over the lazy dogs”的不同变体。
    *   费多连科认为，这在某种程度上与乔姆斯基学派的观点是相反的，因为他们长期以来强调的是句法是语言的核心，而含义是次要的。

**总结与展望：**

*   目前面临的挑战：将视觉语言与其他认知分离（逻辑、社会认知、创造力、运动控制等）。
*   南希·坎威舍尔认为，大语言模型在这些方面还无能为力，只能模拟大脑的语言区域或视觉区域。
*   当ChatGPT等大语言模型产生“幻觉”时，是因为我们在强迫它们回答超出能力范围的问题。
*   过去20年的认知神经科学告诉我们，语言和思维在大脑中是分开的，这对于大语言模型也是一样。
*   AI系统虽不能提供完全可靠的答案，但可以帮助人类理解大脑和神经科学。
*   AI系统与人脑足够接近，可以进行比较；又足够不同，可以寻找感知和智能的普遍原则。
*   AI系统表明，智能是普遍的，不仅限于人类和哺乳动物。

**结尾：**

*   如何看待神经科学与AI的结合？
*   AI能否帮助我们理解大脑的运作？
*   欢迎在评论区留言，感谢观看，下期再见。

**修改建议：**

*   **结构化：** 將文稿分成更清晰的章節，例如引言、正文（分成幾個小點）、總結與展望。
*   **提炼主题：** 每个小点都应有明确的主题，方便读者快速抓住重点。
*   **精简内容：** 在不损失关键信息的前提下，尽量精简语句，去除冗余内容。例如，可以將一些重複的結論放在段落開頭。
*   **突出重点：** 使用粗体或其他方式突出关键词、人名、机构名等。
*   **增加过渡语：** 在不同部分之间增加过渡语，使文稿更流畅。
*   **润色语言：** 润色一些表达，使其更符合书面语的习惯。
*   **检查错别字：** 仔细检查文稿，修正错别字和标点符号错误。
*   **添加图片/图表（可选）：** 如果可能，可以添加一些相关的图片或图表，以增强文稿的视觉效果。
*   **参考文献（可选）：** 如果文稿引用了其他资料，建议在文末添加参考文献。

希望这个整理后的文稿对您有所帮助!

[model=gemini-2.0-flash,0]
