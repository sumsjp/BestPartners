好的，我為您整理了這段文稿，使其更易讀且更具結構性：

**主題：OmniMotion：新型視頻運動追蹤技術**

**引言：**

*   Meta 之前發布的 SAM 模型，可以分割圖像和視頻中的物體。
*   許多後續研究在此基礎上結合了目標檢測和圖像生成等功能。
*   然而，大部分研究主要集中在靜態圖像上。

**OmniMotion 技術介紹：**

*   康奈爾大學、Google 研究院和 UC 伯克利的研究人員共同提出了一種完整且全局一致的運動表徵方法，稱為 OmniMotion。
*   OmniMotion 提出了一種新的測試時優化方法，可以對視頻中的每個像素進行準確完整的運動估計，追蹤視頻中任意物體的運動軌跡。
*   演示效果顯示，OmniMotion 在運動追蹤方面表現出色。例如：跳躍袋鼠、盪鞦韆的女孩、跳躍的人物、轉彎的火車、運動的馬術選手和馬、蝴蝶煽動翅膀等。
*   即使物體被遮擋，OmniMotion 也能夠追蹤到其運動軌跡，例如：狗跑動時被樹遮擋，小孩玩耍時被鐵鍊遮擋。
*   官方提供的互動式 Demo 允許使用者自行設置追蹤點，並逐幀查看每個點的運動過程。遮擋時，追蹤點會顯示為加號。

**傳統運動估計方法的局限性：**

*   常用的運動估計方法有兩種：稀疏特徵追蹤和密集光流。
*   稀疏特徵追蹤無法建模所有像素的運動。
*   密集光流無法長時間捕獲運動軌跡。

**OmniMotion 的優勢：**

*   OmniMotion 使用 quasi-3D 規範體積來表徵視頻。
*   通過局部空間和規範空間之間的雙射 (bijection) 對每個像素進行追蹤。
*   這種表徵方法能夠保證全局一致性。
*   即使在物體被遮擋的情況下，也能進行運動追蹤。
*   可以對相機和物體運動的任何組合進行建模。

**OmniMotion 的工作原理：**

*   輸入：幀的集合與成對的噪聲運動估計（例如光流場）。
*   形成：整個視頻的完整全局一致的運動表徵。
*   優化：添加優化過程，使其可以用任何幀的任何像素來查詢此表徵。
*   結果：產生平滑準確的運動軌跡。
*   關鍵：可以識別畫面中的點何時被遮擋，甚至可以穿過遮擋來追蹤點。

**OmniMotion 的技術細節：**

*   OmniMotion 將視頻中的場景表示為規範的 3D 體積。
*   通過局部的規範雙射，映射成每個幀中的局部體積。
*   局部規範雙射被參數化為一個神經網路。
*   在不分離兩者的情況下，捕獲相機和場景的運動。
*   视频可以被看作是一个来自固定静态相机局部体积的渲染结果。
*   由於沒有明確區分相機和場景運動，OmniMotion 形成的表徵不是物理上準確的 3D 場景重建，因此研究人員稱其為 "quasi-3D" 表徵（准3D或偽3D）。
*   OmniMotion 保留了投影到每個像素的所有場景點的信息以及它們的相對深度順序，因此即使畫面中的點暫時被遮擋，也能夠對其進行追蹤。

**OmniMotion 的效果：**

*   與其他方法（如 RAFT、TAP-NET、FLow-Walk、PIPs 等）相比，OmniMotion 對物體的追蹤效果更好。
*   無論是快速移動、遮擋、遠近實體等情況，OmniMotion 的效果都不錯。

**OmniMotion 的局限性：**

*   在某些快速非剛性的運動下，會出現追蹤失敗的情況。

**總結：**

*   OmniMotion 是一項有前景的運動追蹤技術。
*   研究代碼尚未開放，預計很快會發布。

**其他建議：**

*   可以將這份整理過的文稿作為文章大綱，更詳細地解釋 OmniMotion 技術的細節。
*   可以在文中加入更多的圖例，展示 OmniMotion 的追蹤效果。

希望這份整理對您有所幫助！

[model=gemini-2.0-flash,0]
