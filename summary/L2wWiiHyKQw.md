好的，我幫你整理了這篇文稿，主要目的是使其更結構化、重點更突出，並方便閱讀理解。

**整理後的文稿 (結構化重點摘要):**

**標題：26年前的Windows 98電腦運行AI大模型Llama：科技的無限可能**

**引言：**
*   在大飛的「最佳拍檔」節目中，介紹一個令人驚嘆的科技實驗：在26年前的Windows 98系統上運行前沿AI大模型Llama。
*   實驗證明，前沿AI不一定需要高端硬體，舊設備也能煥發新生。

**實驗背景：**
*   EXO Labs團隊挑戰傳統觀點，認為AI不應只依賴數據中心。
*   他們嘗試在一台Windows 98 Pentium II PC上運行Llama模型，探索AI的另一種可能性。

**實驗過程：**

1.  **硬體設置：**
    *   團隊在eBay上購買了一台Windows 98 Pentium II PC（配備128MB記憶體）。
    *   解決了USB鍵盤滑鼠不相容的問題，改用PS/2介面。
    *   發現PS/2端口的插槽位置有特定規則。
2.  **檔案傳輸：**
    *   多種現代方案失敗後，選擇經典的FTP協議。
    *   在M4 MacBook Pro上運行FileZilla FTP伺服器，透過USB-C轉乙太網路連接老電腦。
    *   設定靜態IP，使用命令行傳輸檔案。
    *   解決了可執行檔無法執行的問題，改用二進制模式傳輸。
3.  **程式碼編譯：**
    *   最初嘗試使用mingw失敗，因為奔騰II不支援CMOV指令。
    *   改用26年前的Borland C++ 5.02。
    *   借助Andrej Karpathy開發的llama2.c（一個700行的純C程式碼推理引擎）。
    *   為了在奔騰II和Windows 98上運行，團隊進行了大量的優化調整。

**實驗結果：**
*   在奔騰II CPU上，260K參數量的Llama模型達到每秒39 token的生成速度。
*   15M參數量的模型速度降至每秒1個token以上。
*   1B參數量的Llama 3.2模型速度降至每秒0.0093 token。
*   儘管速度慢，但成功讓現代AI模型在25年前的CPU上運行，具有重要意義。

**EXO Labs的願景：**
*   讓每個人都能平等地獲取AI技術。
*   構建開放的基礎設施，用於訓練前沿模型，並讓任何人都能在任何地方運行它們。
*   透過Windows 98的AI實驗，展示在有限資源下訓練和運行AI能力的可能性。

**BitNet模型：**
*   EXO Labs提出了一種新的人工智慧模型架構BitNet，權重只使用0、-1和1三個值。
*   BitNet的權重只需要1.58位元組的儲存空間，可顯著減少模型的儲存需求和計算量。
*   70億參數的BitNet模型只需要1.38GB的儲存空間。
*   BitNet以CPU優先為設計理念，能效高50%以上。

**結論：**
*   這次實驗展示了科技的頑強生命力和無限可能性。
*   即使是26年前的老舊設備，也能在經過巧妙的改造和努力後運行現代的AI模型。
*   為未來AI的普及和發展帶來了新的思考和方向。

**額外說明：**

*   **章節劃分：** 將文稿分成幾個主要部分，方便讀者快速找到感興趣的內容。
*   **重點標示：** 使用標題、粗體字等方式，突出重點資訊。
*   **精簡描述：**  在不影響理解的前提下，簡化部分描述，使其更易於閱讀。
*   **調整語氣:**  儘量保持原文的語氣，同時使其更像一篇專業的文件整理。

希望這樣的整理對您有幫助!

[model=gemini-2.0-flash,0]
