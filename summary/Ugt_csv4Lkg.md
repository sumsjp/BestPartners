好的，這是我整理後的文稿，著重在重點提煉和結構調整，使其更清晰易懂：

**標題：Meta 最新世界模型 V-JEPA 2：讓 AI 像人類一樣理解世界**

**引言：**

大家好，這裡是最佳拍檔，我是大飛。Meta 最近動作頻頻，繼「超級智能團隊」和收購 Scale AI 後，又推出了基於影片訓練的世界模型 V-JEPA 2。

**V-JEPA 2 的核心概念：**

*   **世界模型：** Yann LeCun 認為，世界模型是一種現實的抽象數位孿生，AI 可以參考它來理解世界並預測行為的後果，讓機器能夠理解物理世界，規劃行動路線，而無需進行數百萬次的試驗。
*   **重要性：** 這種推理和規劃能力具有廣泛影響，例如幫助視障人士、在混合實境中提供指導、讓教育更個人化，甚至理解程式碼的影響。對於自動駕駛汽車和機器人等自主系統也至關重要。

**V-JEPA 2 的特點：**

*   **參數：** 12 億
*   **架構：** 基於聯合嵌入預測架構（JEPA）構建，在處理圖像和 3D 點雲等多模態方面有出色的表現。
*   **能力提升：** 在 V-JEPA 的基礎上，進一步提升了動作預測和世界建模的能力，使機器人能夠通過與陌生物體和環境的互動來完成任務。

**V-JEPA 2 的特殊能力：**

1.  **開啟對世界的理解：** 結合語言建模，提供卓越的運動理解和視覺推理能力。例如，對跳水動作做出專業的描述：「向前 1.5 周空翻，無轉體」。
2.  **預測下一步：** 僅憑演示人員的當前動作，就可以預測一系列的後續動作，如打開冰箱、拿瓶子、關上冰箱、擠瓶子等。

**V-JEPA 2 的性能提升：**

在多個基准測試中，V-JEPA 2 相較於之前的最優模型，均展示出大幅提升：

*   **機器人控制方面：**
    *   **Reach（到達）基准：** 100%（與之前的 Octo 模型相同，表現完美且穩定）
    *   **Grasp（抓取）基准：** 45%（遠超之前 Octo 的 8%，進步顯著）
    *   **Pick-and-place（拾取與放置）基准：** 73%（飛躍性的提升，之前 Octo 為 13%）
*   **預測方面：**
    *   **Epic-Kitchens-100 動作預測任務：** 39.7%（高於之前 PlausiVL 的 27.6%）
*   **理解方面：**
    *   **Something-Something v2 動作識別基准：** 77.3%（高於之前最佳模型的 69.7%）
    *   **Diving48 潛水相關動作識別基准：** 90.2%（高於之前的 86.4%）
    *   **感知測試基准：** 84.0%（略高於之前 PerceptionLM 的 82.7%）
    *   **MVPBench 基准：** 44.5%（優於之前 InternVL-2.5 的 39.9%）

**V-JEPA 2 的創新之處：**

*   **兩個主要組件：**
    *   **編碼器：** 接收原始影片並輸出嵌入信息，捕捉世界狀態的語義信息。
    *   **預測器：** 接收影片嵌入信息和預測內容的附加上下文，輸出預測後的嵌入信息。
*   **訓練方式：**
    *   **基於影片的自監督學習：** 無需人工標註，即可在影片上進行訓練。
    *   **兩個階段：**
        1.  **無動作預訓練階段：** 使用超過 100 萬小時的影片和 100 萬張圖像，使模型深入了解世界的運作方式。
        2.  **動作條件訓練階段：** 利用機器人數據，提升模型的規劃能力。

**V-JEPA 2 的應用：**

*   **零樣本機器人規劃：** 在新環境中放置新物體的成功率達到 65% 到 80%。
*   **視覺模仿學習：** 機器人按照順序嘗試實現視覺子目標。

**Meta 新發布的三個基准測試：**

*   **IntPhys 2：** 衡量模型區分物理合理場景和不合理場景的能力。
*   **MVPBench：** 通過多項選擇題衡量影片語言模型的物理理解能力。
*   **CausalVQA：** 關注模型對物理世界影片中因果關係的理解。

**Meta 的下一步計劃：**

*   **進一步探索世界模型在多個領域的應用。**
*   **訓練能夠跨多個時間和空間尺度進行學習、推理和規劃的分層 JEPA 模型。**
*   **開發能夠利用多種感官進行預測的多模態 JEPA 模型。**

**總結：**

Meta V-JEPA 2 模型在機器人控制、動作預測、行為理解等多任務中表現出明顯的性能提升，展現出更強的多模態處理和任務執行能力，為機器人應用、影片理解等領域帶來了更好的潛力與表現。

**結束語：**

相關的資料會放到影片簡介中，希望能對大家有所幫助。感謝觀看本期影片，我們下期再見。

**整理說明：**

*   **簡化了部分描述：** 刪除了不必要的細節，保留了核心資訊。
*   **使用了條列式整理：** 使重點更突出，更易於閱讀。
*   **增加了標題和副標題：** 讓文章結構更清晰。
*   **使用了粗體標記：** 強調了關鍵詞和短語。

希望這個整理版本對您有幫助！

[model=gemini-2.0-flash,0]
