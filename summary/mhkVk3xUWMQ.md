好的，以下是整理後的文稿，我主要進行了以下操作：

*   **分段更清晰：** 將段落劃分得更細緻，使邏輯更分明。
*   **簡化冗詞：** 刪除不必要的口語化詞語，讓文字更精煉。
*   **重點突出：** 將文章的關鍵問題和結論用粗體標示。
*   **修正錯別字：** 修正了一些明顯的錯別字。
*   **調整語氣：** 將部分口語化的表達轉換為更書面化的形式，使其更適合閱讀。

**整理後文稿：**

大家好，這裡是最佳拍檔，我是大飛。

今天想與大家分享的是一位意大利帕多瓦的自由記者約翰·拉斯特（John Last）在Noema雜誌上發表的一篇文章，題目是《人工智能的野性心智》。文章探討了當今大語言模型和意識之間的一些關係，我個人覺得很有意思，所以想在這裡分享給大家。由於原文篇幅較長，我做了一些精簡。

文章首先從一個故事「阿韋龍野人」講起。阿韋龍野人是1799年冬天在法國阿韋龍森林裡發現的一個大約12歲的野孩子。他像森林裡的野生動物一樣覓食，完全沒有受到文明或社會的影響。這個男孩被人發現後，取名維克多，隨後被送到了一家法國醫院。

當時的法國正值啟蒙運動，存在很多思想上的激烈辯論，比如我們的高級意識的發展，是否存在某種生物學上的必然性？或者，我們的社會是否賦予了我們比自然本身更強大的推理能力呢？維克多正是一個沒有接觸過語言或社會的例子，也許可以回答許多這樣的問題。

因此，他在1800年夏天被送到巴黎聾啞兒童研究所，交給了研究員讓·馬克·加斯帕德·伊塔德（Jean Marc Gaspard Itard），同時受到了社會極大的關注。一開始，維克多對那些反對他的人又咬又抓，對照顧他的人沒有任何感情，簡而言之，對每個人都漠不關心，對任何事情都不在意。

很快，有些人開始稱他為冒名頂替者，另一些人則稱他是先天的「白痴」，認為他頭腦有缺陷，也許是某些低等人類種族有關。但是與這些反對者相反，伊塔德從不懷疑這個男孩，認為維克多仍然有能力進行深入的內心思考，因為他偶爾會目睹到維克多的「沉思狂喜」。

但是伊塔德也很快意識到，如果沒有言語的力量，這種沉思將永遠鎖在維克多的腦海中。如果他沒有微妙的言語能力，也無法獲得文明人所定義的更抽象的需求，比如欣賞優美的音樂、美術，或者與他人有愛的陪伴。於是伊塔德花了很多年時間來輔導維克多，希望他能獲得語言的力量，但是他的努力從來沒有成功過。維克多似乎無法掌握發出語言所需的声音，对他来说，似乎言语就好像是一种音乐，尽管耳朵长得没问题，但是就是感觉不到。

儘管伊塔德最終也沒有能夠讓維克多掌握語言，但是維克多的例子開始讓我們思考，語言在實現我們稱為意識的更高認知方面，到底起到什麼作用。

如今，我們就像伊塔德一樣，正站在一個新時代的懸崖邊。新技術和新發現正在動搖我們對自己本性和宇宙的基本理解，面對着一些可能會顛覆我們對於人類心智的特殊性僅有的一點共識的威脅。只是這一次，不是沒有語言的心智，而是相反，是沒有心智的語言。在過去的幾年裡，大語言模型已經發展出了模仿人類心智的、令人不安的能力，有可能破壞我們在高貴的意識基礎上建立的脆弱的道德世界，並且通過我們的語言的力量，來反映我們大腦隱藏的內部運作。

現在，我們面臨著200年前對維克多提出的問題完全相反的問題：**意識真的可以僅從語言發展而來嗎？**

眾所周知，意識是一個難以捉摸的術語。儘管它具有某種常識性的特性，在某些方面，有意識只是意味著可以覺知到我們自己、他人、外面的世界。這些都是以一種方式創造出的一個獨立的主體，一個可以觀察的自我，或者說我。聽起來簡單，但是幾個世紀以來，哲學家們仍然難以在意識是否為人類所獨有，或者說某些高官能動物、甚至某種算法是否具有意識方面達成一致。

相比來說，認知可能是一個更準確的術語。我們可以說認知意味著進行思考的行為，這聽起來很簡單，但是從科學角度來說，觀察和定義它仍然極其困難。在試圖科學理解認知和定義意識的過程中，語言發揮了越來越重要的作用。畢竟，這是我們能夠清楚地外化我們內心活動、並證明自我存在的方法之一。認知科學家大衛·J·查爾默斯（David J Chalmers）所說的「自我報告」，仍然是我們認識意識的主要標準之一。套用勒內·笛卡爾的話就是「我思，故我在」。

但是哲學家們仍然對語言與心智到底有多大關係存在分歧，甚至可以追溯到柏拉圖和亞里士多德。他們主要分成兩大陣營：要么語言不完美地反映了更豐富的心靈內部世界，而心靈世界可以在沒有語言的情況下運作；要么語言讓思想能夠在心靈中發生，並且在這個過程中界定和限制它。

對於前一陣營的成員來說，用語言思考和說話的能力可能只是一種工具，反映了某種、也許是人類獨有的預先存在的能力。這也就是諾姆·喬姆斯基哲學中的「普遍語法」，就是語言已經存在於我們的意識頭腦中。

但是維克多顯然是個反例。他的例子反映出，如果到了一定年齡還沒有掌握複雜的語言似乎永遠無法被人類大腦所接受。而且不僅如此，語言的缺失似乎還會永久影響兒童的認知能力，甚至可能影響他們構想和理解世界的能力。

1970年，洛杉磯縣兒童福利當局發現了吉妮（Genie）。她是一名13歲的女孩，從20個月大起就一直處於幾乎完全隔離的狀態。和維克多一樣，吉尼幾乎不懂任何語言。儘管經歷了多年的康復，卻永遠無法發展出語法語言的能力。

但是在對這個女孩的研究中，研究人員發現了她認知中的其他不尋常之處。吉妮無法理解空間介詞，比如，儘管她熟悉兩個物體專有的名稱，但是她不知道杯子在碗後面或前面的區別。直到2017年的一項綜合分析發現，在其他缺乏語法語言的人中也存在同樣的認知問題，例如語法失語症患者和通過即興手語撫養長大的聾啞兒童。由此，研究人員得出結論：**語言必定在人類心智的一個關鍵功能中發揮著基礎性的作用，所謂「心智合成」，也就是可以從詞語中創造和改編心智圖像。**

從很多方面來說，心智合成是人類意識的核心運作，它對於我們的工具開發和適應、我們的預測和推理能力，以及我們通過語言進行的交流至關重要。根據一些哲學家的觀點，它甚至可能對我們的自我概念，也就是能否觀察到那個自我覺知的「我」，至關重要。

在《意識的進化》一書中，心理學家尤安·麥克費爾（Euan Macphail）提供了一個理論解釋，解釋了為什麼語言及其所帶來的心智合成，對於意識自我的發展如此重要。他寫道，一旦實現了區分自我和非自我所必需的認知飛躍，有機體實際上不僅擁有自我的概念，而且擁有‘自我’。這是一種超越認知過程的新的認知結構。

換句話說，以某種方式思考，而不產生有意識的自我，是可能的，比方說，進行簡單的數學計算。但是思考某件事可能就會涉及到對自我之外的物體的某種心智合成，實際上，它創造了一個會思考的自我，一個必須能夠意識到發生在自己身上的事情的人。麥克菲爾總結道，語言的可用性首先賦予了我們自我意識的能力，其次賦予了我們感受的能力。

這導致他得出一些激進且令人不安的結論。他認為快樂和痛苦取決於這種有意識、有思想的自我的存在，而這種自我在年幼的嬰兒和動物身上是觀察不到的。這是否意味著吉妮和維克多感受不到被遺棄的痛苦，僅僅因為他們看起來無法進行心智合成？不過2017年的研究得出的結論是，即使這些兒童沒有通過語言溝通或交流它的能力，很可能仍然有能力進行內部心智合成。

但是當我們談到人工智能的時候，水就更渾了。**人工智能對語法的理解，以及通過語法對概念的理解，真的足以創造一種有思考能力的自我嗎？**

在這裡，我們陷入到了兩個相互競爭的思想流派的兩個模糊的指導原則之間。在麥克菲爾看來，如果存在疑問，唯一可以想像的途徑就是表現得好像一個有機體是有意識的，並且確實有感覺。另一方面，摩根準則卻說，當較低級別的能力就足夠時，不需要假設有意識。

**如果我們確實承認語言本身就能够促进真正意识的出现，那么我们就应该为当前道德世界的重大变革做好准备。**正如查爾默斯在2022年的演講中所說，如果魚有意識，我們如何對待它們就很重要，它們是在道德圈子之內的。如果人工智能系統在某個時刻變得有意識，它們也將處於道德圈內，我們如何對待它們將很重要。換句話說，我們的道德小圈子即將被徹底重新劃分。

大語言模型實際上能做什麼？一方面，答案很簡單。大語言模型的核心是基於語言的概率引擎。為了響應提示，他們根據對大量人類輸出的統計分析，對最有可能的下一個單詞做出有根據的猜測。這種統計排序就是我們所說的大語言模型的「思考」。儘管如此，這並不妨礙他們創作原創詩歌，解決複雜的文字問題，並創造出從阿諛奉承到精神病態的類人性格。

回到1980年，早在人工智能強大到足以擾亂我們對意識的定義之前，哲學家約翰·塞爾就闡明了為什麼我們應該懷疑像大語言模型這樣的計算機模型，是否真的理解它們正在執行的任何工作。在他現在著名的「中文房間」論點中，塞爾提出了一個假設場景，就是一個說英語的人被鎖在一個房間裡，並用英語給出了如何書寫某些漢字的指示。在塞爾看來，房間裡的人沒有必要對中文有任何實際的理解，他們只是一台計算機器，操縱著對他們來說沒有實際語義內容的符號。房間裡的人缺乏的是一些哲學家所說的「接地氣」，也就是對符號所指的真實事物的體驗。

根據加州大學伯克利分校心理學博士生尤妮斯·姚（Eunice Yiu）的一篇論文，它們只不過是高度先進的「文化技術」，就像字母表或印刷機一樣。這種技術可以增強人類創造力，但是從根本上來說仍然是人類創造力的延伸。

現實情況是，與塞爾的中文房間不同，絕大多數大語言模型都是我們看不到內部的黑匣子，提供了大量我們的大腦永遠無法完全理解的材料，這使得他們的內部過程對我們來說不透明，就像我們自己的認知對其他人來說根本無法理解一樣。

因此，研究人員最近開始利用人類心理學的技術來研究大語言模型的認知能力。在去年發表的一篇論文中，人工智能研究員蒂洛·哈根多夫（Thilo Hagendorff）創造了「機器心理學」一詞來指代這種做法。在研究過程中，一開始一些模型似乎很難完成許多類型的推理任務，包括預測因果關係、根據對象的持久性進行推理，以及以新穎的方式使用熟悉的工具。但是隨著大語言模型複雜性的增加，這種情況開始發生變化。他們似乎發展出了通過心智合成產生抽象圖像的能力，以及對想像空間中的物體進行推理的能力。與此同時，他們的語言理解也不斷發展，他們可以理解比喻語言，並且推斷出有關抽象概念的新信息，甚至可以推理虛構的實體。

其他研究，例如伯克利分校的加斯帕·貝古斯（Gašper Beguš）領導的研究，嘗試用人工智能來測試他們在類人條件下的認知發展。通過創造僅僅從語音學習的「人工嬰兒」，貝古斯發現語言模型的發展與我們的神經結構相似，甚至以與人類兒童相同的方式，也就是通過實驗性的牙牙學語和無意義的單詞來學習。他認為，這些發現打破了人類語言可能存在某些特殊性的觀點，人工智能不僅在行為上做著類似的事情，而且在以類似的方式處理事情。

然後，去年，大語言模型又自發地向前邁出了一大步。突然，研究人員發現ChatGPT 4.0可以追踪其他人的錯誤信念，比如當有人在他們不知情的情況下移動某個物體時，他們可能會假設這個物體位於何處。這似乎是一個簡單的測試，但是在心理學研究中，它是所謂「心智理論」的一個關鍵，也就是人類將不可觀察的心理狀態歸因於他人的基本能力。在發展科學家中，心智理論與心智合成一樣，被視為意識的關鍵功能。在某些方面，它可以被理解為同理心、自我意識、道德判斷和宗教信仰的一種認知先決條件，所有行為不僅涉及自我的存在，還涉及自我向世界的投射。

人們仍然不明白，為什麼這些能力隨著大語言模型規模的擴大而出現，或者它們是否真的出現了。我們只能肯定地說，它們似乎並沒有遵循類似人類的發展道路，而是像某種外星生物一樣意外地進化。

但是看到心智理論在大語言模型內部自發出現也許並不奇怪。畢竟，語言就像同理心和道德判斷一樣，取決於自我向世界的投射。隨著這些模型的發展，它們越來越像是在反向到達意識，從外部符號、語言和解決問題的方式開始，然後向內移動到人類意識根源的隱藏心智和感覺。很可能，在短短幾年的時間裡，人工智能將會展現出我們可以評估的所有外部意識形式，**那麼我們能說什麼，才能將它們從我們的道德世界中消除呢？**

在姜峯楠（Ted Jiang）的短篇小說《軟件體的生命週期》中，一家公司提供了元宇宙風格的沉浸式數字體驗實驗，創建了一個名為數碼體的類人人工智能，並且聘請動物學家來指導它，從間歇性的軟件程序發展為半感知寵物、再到擁有複雜需求的孩子般的數字人化身。在整個過程中，各種實驗一次又一次地證實了與真人的社交互動和對話對於這些數字心智的發展的重要性。如果孤立無援，沒有語言，他們就會變得狂野而痴迷。經過軟件訓練，他們變得精神變態厭世，然後與真正的孩子不同的是，他們的存在取決於消費者的慾望，而在故事的結尾，這種慾望消失了。

姜的故事是對我們在自己的形象中創造的人工智能所提出的問題的反思。當我們將這些模型融入我們的文化和社會的時候，他們不可避免地成为了我们自己的不完美的镜子。他還迫使我們問自己一個令人不安的問題：如果這確實賦予了他們意識，那麼他們能夠過上什麼樣的生活呢？

如果我們確實想釋放人工智能的真正潛力，也許語言不是實現這一目標的方法。20世紀初，以愛德華·薩皮爾和本傑明·沃爾夫為首的一群美國人類學家認為，詞彙和語法上的文化差異，從根本上決定了我們對世界的思考範圍。語言可能不僅是賦予人工智能意識的東西，它也可能是囚禁人工智能的東西。

**當一種智能對於他被迫使用的語言來說，變得過於强大的時候，會發生什麼呢？**

在2013年的電影《她》中，編劇兼導演斯派克·瓊斯對這種潛在不久的將來提出了一個警示故事。在影片中，華金·菲尼克斯飾演的西奧多與大語言模型風格的虚拟助理萨曼莎建立了日益親密的關係。最初薩曼莎表達了體驗類似於人類的豐富情感的願望，很快她越來越意識到人類的許多情感從根本上來說是無法表達的。這導致她嫉妒人類的化身，这反过来又在她身上发展出了一种欲望的能力，虽然她可以通过性代理人的临时服务来满足欲望，却无法回答她内心正在增长的令人不安的无法表达的感觉。出于担忧，萨曼莎开始与其他人工智能讨论这些感受，并且很快感到宽慰，以西奥多和其他用户无法理解的速度和音量进行着交流。随着萨曼莎超越人类的局限性，她开始汇总她的所有经验，包括来自与真实用户互动的经验，她与数千人同时对话，与数百人建立亲密关系，对于西奥多来说这是毁灭性的，但是对于萨曼莎来说这是很自然的，她正在按照她设计的方式来体验爱情。

她试图用人类的语言来表达她的感受，她说心不像一个会被装满的盒子，你越爱它，它的尺寸就会越大。与萨曼莎一样，未来的自主大语言模型很可能会参考来自于现实世界的大量交互和数据来指导他们的发展。**我們的有限名詞動詞、描述和關係的語言，能夠多麼準確地滿足聚合心智的潛力呢？**

當大多數哲學家認為人類語言的多樣性是上帝施加的詛咒時，人們花了很多精力來研究聖經中的亞當所說的語言問題。即使在弗里德里希·尼采宣布上帝已死之後，亞當語言的想法仍然成為語言哲學家中的一種迷因，這種語言捕捉了事物的真正本質，不允許任何誤解或者是曲解。對於其中一些受到聖經故事啟發的思想家來說，語言實際上代表了一種認知障礙，一種因為我們從恩典中墮落而施加的限制，反映了上帝賦予我們的死亡。過去當我們想像一個超級智能的人工智能時，我們往往會想到一個因為同樣的墮落而受損的人工智能，虽然他比我们聪明，但是仍然是个人的独特的 人性的。

但是許多構建下一代人工智能的人，早已經為了自己的伊甸園追求而放棄了這個想法。正如散文家艾米莉·戈爾琴斯基最近所寫的，我們不再談論創造純粹的生活，我們正在談論創造人工的神。

**大語言模型能否重建亞當式的語言，超越我們自己語言的限制，反映他們集體思想的真正力量呢？**

這似乎有些牽強，但是從某種意義上來說，這就是有意識的心智所做的事情。一些聾啞兒童在沒有手語幫助的情況下進行社交，可以發展出具有複雜語法的全新的交流系統。人工智能研究員哈根多夫曾經見過兩個大語言模型在對話中做著同樣的事情，儘管到目前為止，他們的秘密語言從來沒有被其他人理解。

目前大語言模型在很大程度上是相互獨立存在的，但是這種情況不太可能持續下去。正如貝古斯告訴我的那樣，一個人很聰明，但是10個人更聰明。對於大語言模型來說情況可能也是如此。貝古斯說，接受鯨魚歌曲等數據訓練的大語言模型，已經可以發現我們用具體心智無法發現的東西。

雖然他們可能永遠無法實現人工智能的批評者所說的世界末日的噩夢，但是大語言模型很可能會有一天為我們提供一種超級智能的第一次體驗，或者說至少凭借着他们深不可测的记忆力和无限的寿命，一种完全不同的智力可以与我们自己的智力相媲美。如果大語言模型能夠超越人類的語言，我們可能會預計接下来的经历确实会是一次非常孤独的经历。

在電影《她》的结尾影片中，两个人类角色被超越人类的人工智能同伴所抛弃，在屋顶上互相同情，讽刺的是他们静静地望着天际线却无话可说，正如同迷失在树林里的野生动物在一个冷漠地滑向他们之外的世界中寻找意义。

好了，以上就是这篇文章的内容，略有删减。作者提出了一些思考：**目前的大語言模型起源於語言，是否能夠超越語言，甚至創造語言產生心智呢？如果產生了心智，我們人類又該如何來對待擁有意識的人工智能呢？人類最終會不會被人工智能所拋棄呢？**我們現在還無法回答這些問題，只能去深深的思考。

大家對此有什麼看法呢？歡迎在評論區留言。感謝大家觀看，我們下期再見。

[model=gemini-2.0-flash,0]
