<details>
<summary>100. [2023-06-12] 【容器】容器管理工具Podman完全安装使用指南 | Docker平替 | 兼容Docker命令 | 如何管理容器、镜像、Pod | Kubernetes</summary><br>

<a href="https://www.youtube.com/watch?v=GYRIhF2FA-g" target="_blank">
    <img src="https://img.youtube.com/vi/GYRIhF2FA-g/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【容器】容器管理工具Podman完全安装使用指南 | Docker平替 | 兼容Docker命令 | 如何管理容器、镜像、Pod | Kubernetes

好的，我幫您整理如下：

**文章主旨：Podman vs. Docker，Podman 的功能及使用教學**

**主要內容：**

1.  **Podman 簡介：**
    *   Podman 是紅帽公司於 2018 年發布的容器管理工具，也是 CentOS 8 上的預設容器管理工具。
    *   Docker 開始收費後，Podman 成為 Docker 的替代品之一。

2.  **Podman 與 Docker 的比較（從日常使用場景）：**
    *   **命令列相容性：** Podman 命令與 Docker 命令基本相同，可用 alias 或 docker-cli 來控制 Podman。
    *   **打包（Build）：** Podman 支持 Dockerfile 和 Containerfile，打包出的鏡像遵循 OCI 標準，可以部署和運行在兼容 OCI 的容器生態中。
    *   **拉取镜像（Pull）：** Podman 預設從 Docker Hub 拉取鏡像，但也支持從其他倉庫拉取，例如 quay.io。
    *   **容器管理（Container Management）：**
        *   Podman 在 Mac 上運行需要 Linux 內核的虛擬機。
        *   Podman 沒有 Daemon 进程，而是直接通过 OCI 运行容器（crun ）。
        *   Podman 提供 `machine` 命令管理虛擬機，例如初始化、啟動、停止、檢視等。
        *   Podman 支持 rootless 模式，以非 root 用戶來運行容器。
        *   可以使用 volume 參數把主機上的文件掛載到虛擬機中，解決文件共享的問題。
        *   Podman 不支援將 network 模式設定成 host，host 模式只能在虛擬機內部進行監聽。

3.  **Podman 的特色功能：**
    *   **Pod：**
        *   Podman 引入了 Pod 的概念，可以將多個容器放到一個 Pod 當中，統一進行管理。
        *   同一 Pod 內部的容器可以通過 localhost 互相訪問。
        *   Pod 創建好以後不能再修改端口映射，需要在創建時先規劃好。

    *   **Podman Compose：**
        *   Podman Compose 用來管理容器。
        *   支持將容器運行在 Pod 中（加上 `--in-pod=1`）。
        *   若 Docker Compose 檔案使用了卷映射，需要先創建該卷，否則 Podman Compose 會报错。

    *   **Kubernetes 整合：**
        *   Podman 提供了 `kube` 命令與 Kubernetes 互動：`apply`、`generate`、`play`、`down`。
        *   Podman 可以代替 Docker 作為底層的容器運行環境。

4.  **Podman 圖形介面（Podman Desktop）：**
    *   Podman Desktop 提供 Podman 的圖形介面，方便管理容器。
    *   主要功能包括容器管理、Pod 管理、鏡像管理、卷管理，以及虛擬機的配置。
    *   Podman Desktop 目前仍有一些小問題和需要優化的點，啟動速度較慢。

5.  **总结：**
    *   Podman 和 Docker 的命令基本兼容。
    *   Podman 可以拉取運行 Docker Hub 中的鏡像，也可以根據 Dockerfile 构建并上传到 Docker Hub。
    *   Podman Desktop 提供了圖形介面，方便管理容器。
    *   Podman Compose 和 Docker Compose V1 基本兼容，還支持在 Pod 中運行。
    *   Podman 需要自己管理虛擬機，支持 rootless 模式。

**重點整理：**

*   Podman 是 Docker 的可行替代方案。
*   Podman 功能强大，与 Docker 兼容性高。
*   Podman 有命令行工具和图形界面工具，方便用户使用。
*   Podman 的 Pod 和 Kubernetes 整合是亮点。

**建議：**

*   文章可增加 Podman 的優缺點總結，方便讀者快速了解。
*   Podman Desktop 的使用體驗可以更詳細描述。

希望以上整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>99. [2023-06-11] 【人工智能】Twitter开源核心推荐系统解读 | 推荐系统架构介绍 | 召回 | 粗排 | 精排 | 重排 | 混排</summary><br>

<a href="https://www.youtube.com/watch?v=KoWUS4P_IGk" target="_blank">
    <img src="https://img.youtube.com/vi/KoWUS4P_IGk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Twitter开源核心推荐系统解读 | 推荐系统架构介绍 | 召回 | 粗排 | 精排 | 重排 | 混排

好的，我將盡力以清晰、簡潔的方式整理這段文稿。

**整理後的文稿：**

**標題：Twitter（推特）推薦系統架構解析**

**簡介：** 本影片講解 Twitter 開源的推薦系統原始碼，涵蓋系統架構、精排模型和圖模型預訓練表徵。

**內容概要：**

1.  **問題定義：**
    *   輸入：由推文、用戶交互行為等構成的超大規模異構圖 (Twitter network)。
    *   輸出：預測用戶與推文/其他用戶交互的概率，從而進行推文/用戶推薦。
    *   重點：社交圖 (social graph) 挖掘，包括圖特徵、圖預訓練、圖召回模型等。

2.  **整體架構：**
    *   **數據層：** 包含社交圖 (用戶、推文、互動等)、用戶交互行為、用戶畫像數據等。 這是推特的核心資產。
    *   **特徵工程：** 關注社交圖的預訓練、聚類、社群發現等。 圖預訓練得到的向量可用於向量召回、精排特徵等。
    *   **推薦系統服務 (Home Mixer)：** 基於 Scala 框架，包含：
        *   **召回 (Candidate Sources)：** 從不同推薦源獲取最佳推文 (類似於推薦系統的召回階段)。核心召回方式是圖召回。
        *   **粗排與精排：** 使用機器學習模型 (Light Ranker 和 Heavy Ranker) 對推文進行打分排序 (分別類比推薦系統的粗排和精排階段)。
        *   **重排與混排：** 運用啟發式規則，例如過濾屏蔽用戶的推文、NSFW 內容、已看過的推文，保證作者多樣性，以及廣告、推文和作者混排等。

3.  **召回 (Candidate Sources)：**
    *   輸入：推文候選池 (億萬級別)。
    *   輸出：
        *   **In-network：** 用戶關注的推文 (約佔50%)，主要通過 Earlybird 搜索引擎檢索，再經過 Light Ranker 粗排。
        *   **Out-of-network：** 用戶未關注的推文 (約佔50%)，通過兩種方法：
            *   **UserTweetEntityGraph (UTEG)：** 協同過濾，分析用戶關注/相似興趣用戶的行為，預測用戶感興趣的推文 (約佔15%)。使用 GraphJet 圖引擎構建和遊走動態圖。Light Ranker 粗排。
            *   **Embedding Spaces (嵌入表徵學習)：** 訓練用戶和推文的表徵向量，計算相似性。 包括稀疏嵌入 (SimClusters，基於社群發現的異構表徵模型) 和稠密嵌入 (TwHIN，基於圖學習的預訓練)。
    *   **CR-Mixer：** 協調層，代理執行 Out-of-Network 的多路召回，並調用底層計算服務 (源信號抽取、召回結果生成、過濾和粗排)。
    *   **推人服務 (Following Recommendation Service, FRS)：** 推薦作者，流程與推文推薦類似，包括召回、排序、過濾、推薦理由等。 排序主要預測關注概率和正向交互概率的加權融合。

4.  **粗排 (Light Ranker)：**
    *   本質：引擎側召回通道的海選粗排。
    *   模型：較舊的邏輯回歸 (LR) 模型，預測用戶與推文交互的概率。 特徵包括用戶側特徵 (tweepcred 模型預估聲譽)、推文特徵 (文本質量、轉發、回覆等) 和上下文特徵 (用戶語言等)。
    *   **RealGraph：** 用於 in-network 召回的粗排模型，預測用戶與用戶交互的概率，基於 RealGraph (帶權重的同構圖) 以及邊的特徵。

5.  **精排 (Heavy Ranker)：**
    *   模型：Parallel MaskNet (新浪微博在 DLP-KDD 2021 發表)，多目標模型，用 48M 參數的神經網路實現。
    *   目標：優化點讚、轉發、回覆等目標，考慮數千個特徵，輸出 10 個 level 的分數，代表交互概率。
    *   融合排序：簡單的加權求和。

6.  **重排與混排：**
    *   **重排：** 啟發式規則導向，主要目的為過濾 (屏蔽推文、作者)、保證作者多樣性、內容平衡性、基於反饋的疲勞內容干預、二跳人脈過濾 (social proof)、推文/回覆上下文展示和更新檢測。
    *   **混排 (Homepage Mixer)：** 負責主頁上的混排，包括推文、廣告、關注的作者、Onboarding prompts 等。

7.  **基礎設施服務：**
    *   **Navi：** 用 Rust 編寫的高性能機器學習模型 Serving 服務。
    *   **Product-mixer：** 用於構建內容 Feed 的軟體框架。
    *   **TWML (Twitter Machine Learning)：** 基於 TF-1 的機器學習訓練框架，主要用於訓練粗排的 Earlybird Light Ranker。

8.  **總結：** Twitter 開源核心演算法是一個大膽的舉措，提供了一個典型的大型推薦系統案例。

**關鍵詞：** Twitter, 推薦系統, 開源, 算法, 架構, 召回, 粗排, 精排, 特徵工程, 圖模型, Embedding, 社交圖, Scala, Machine Learning.

**說明：**

*   我使用了更明確的標題和副標題，以便於理解文章的結構。
*   我簡化了一些術語，並添加了說明，以便不熟悉技術的人也能理解。
*   我使用了關鍵詞，以便於搜索和索引。
*   我盡可能地保留了原稿的重點和信息。

希望以上整理對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>98. [2023-06-10] 【预告】2023北京智源大会相关视频 | 四位图灵奖得主 | OpenAI、Midjourney创始人 | 国内众多院士学者 | 悟道3.0发布 | 天鹰、天秤、视界 | 上百场最新研究成果报告和研讨</summary><br>

<a href="https://www.youtube.com/watch?v=0REmtdPnJr4" target="_blank">
    <img src="https://img.youtube.com/vi/0REmtdPnJr4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【预告】2023北京智源大会相关视频 | 四位图灵奖得主 | OpenAI、Midjourney创始人 | 国内众多院士学者 | 悟道3.0发布 | 天鹰、天秤、视界 | 上百场最新研究成果报告和研讨

好的，這是我整理後的文稿，我主要做了以下修改：

*   **修正錯字和語法錯誤：** 修正了一些明顯的錯字和語法問題，使語句更流暢。
*   **調整標點符號：** 調整了標點符號的使用，使其更符合中文的習慣。
*   **分段和組織：** 將文稿分成更小的段落，使內容更易於閱讀和理解。
*   **提煉重點：** 在一些地方做了簡化，使其更加清晰。
*   **加入小標題：** 為了方便閱讀，我將文稿加上了小標題。

以下是整理後的文稿：

---

**大家好，這裡是最佳拍檔，我是大飛。**

**感謝與頻道近況**

首先感謝大家對頻道五月份運營情況影片的肯定和支持。最近頻道分享AI方面的內容比較多，主要是因為相關資訊量太大，我一個人實在無法完全消化並製作成節目。即使每天做四期節目，也講不完每天的新聞。

我希望能盡可能地分享這些資訊，所以只能將自己錄製的影片，連同找到的資料一起分享給大家。最近大佬們的觀點討論非常多，我整理起來吃力，且資訊可能會有誤，所以請大家多聽聽大佬們的原話。

**AI發展的個人觀察**

請大家理解包涵，不是我不錄節目，是真的錄不過來。因為我天天要看大量的AI資訊，從自身感覺來說，這次AI的發展進程跟以往不太一樣。這次科技突破密度高、強度大，而且持續時間長，我以前沒有見過。而且每天都有新的模型、方法、工具出現。

因此我個人判斷，這次AI的影響會非常深遠。以前科技進步傳導到大眾需要很長時間，但這次 ChatGPT 改變了這種狀況。雖然史上最快月活一億的數據不一定準確，但肯定規模很大。而且這次熱度持續時間長，快半年了還沒有退燒。

像以前的 AlphaGO、Alpha-Zero，新聞熱度也就是個把月就下去了，但這次不一樣。所以我對這個頻道方向很有信心，雖然現在轉做自媒體，但AI方面的内容足夠我做很久。HuggingFace上的模型，我一天講一個都夠講幾年。

再次感謝大家的支持和鼓勵，至少這個方向我會堅持做下去。當然也希望後續頻道能夠承接和製作更多其他類型的節目和內容，不斷豐富頻道的多樣性，給大家帶來更多更好更有價值的內容。

**北京智源大會**

說回正題，這兩天國內 AI 圈關注度最高的會議，應該就是2023年北京智源大會。它匯集了眾多傳說中的AI大佬，包括四位圖靈獎得主：傑弗里·辛頓、楊立昆、姚期智、約瑟夫·西法斯基，以及 OpenAI 創始人 Sam Altman、Midjourney 創始人大衛·霍爾茨。

還有像 PaLM-E、Meta AI 這些大模型項目的重要參與者，以及張钹、張宏江這些國內外久負盛名的科技圈大佬。即使楊立昆在法國，也在當地時間凌晨四點連線到現場直播並做了演講。

今年是第五屆大會，同時請來了楊立昆和傑弗里·辛頓。其實背後有個小插曲，在第三屆大會時，傑弗里·辛頓本來也想參加，但就在大會前幾天，他發現準備分享的新方法裡出現了 bug，所以只能取消。

本杰奧在2021年的智源大會上介紹過的關於 system 2 的机器学习理论，如今以思維鏈的形式用在了大模型提示工程方面。可以說深度學習的三巨頭都參加過這個大會。

除了三巨頭之外，還有很多圖靈獎得主也到這個大會做客，包括貝氏網路的提出者朱迪亞·珀爾、RISC-V 的掌門人大衛·帕特森、數據結構大師約翰·霍普克羅夫特，他更是擔任會議的學術顧問委員會會員。所以這個大會還是蠻有高度的，無論從中國還是世界範圍來看。

**智源大會的重點發布**

大會從 6 月 9 日開始，到 6 月 10 日結束，地點在中關村國家自主創新示範區的會議中心會展中心。

智源主要宣布了自己的悟道 3.0，有一系列的重磅發布，並且全面開源。其中的悟道天鷹 Aquila 大語言模型系列，支持中英雙語知識、支持商用許可。AquilaChat 不僅可以像 ChatGPT 一樣進行對話、生成命題作文，還可以通過定義可擴展的特殊指令規範，實現對其他模型和工具的調用。比如通過調用圖像生成 API 實現文生圖功能，或者配合 instructorface 這個多步可控的文生圖模型來實現對人臉的一步步編輯，以及調用 Aquila code 代碼模型的能力，在對話中實現文本到代碼的生成，比如說直接生成一個簡單的登錄頁面或者設計一個時鐘程序。

天秤 FlagEval 是一個大語言評測體系及開放平台，可以構建從能力到任務到指標這樣一個三維的評測框架，細粒度地去刻畫模型的認知能力邊界。目前它包括了 22 個主觀和客觀評測的數據集，以及 84,433 道題目，更多維度的評測數據集正在陸續集成，而且給出的評測結果都是可視化的。目前天秤 FlagEval 已經推出了語言大模型評測、多語言文圖大模型評測以及文圖生成評測等工具，並且對各種語言的基礎模型、跨模態基礎模型實現了評測功能。後續它還將全面覆蓋基礎模型、預訓練算法、微調算法等三大評測對象，包括自然語言處理、計算機視覺、音頻以及多模態等等四大評測場景及豐富的下游任務。

开源了悟道视界视觉大模型系列，发布了六个国际领先的成果。首先是视觉的基础模型 EVA，它是一种经过预训练的 vanilla ViT 模型，整体思路是将最强的语义学习 CLIP 模型与最强的几何结构学习 MIM 做了结合，再将标准的 Vit 模型扩大到了 10 亿参数的规模进行训练。其次是 EVA CLIP 模型，它可以显著提高 CLIP 训练的效果和效率。EVA CLIP 结合了表征学习优化和增强的新技术，与之前的 CLIP 模型相比，在具有相同数量参数的情况下，它的训练成本显著更低。据官方称，EVA CLIP 超越了此前最强的 open CLIP 模型，在 imageNet 1K 的零样本 top 1 测试中达到了最高的 82% 的准确率。

第三个是通用的视觉模型 painter，它的最大亮点是首创了上下文视觉学习的技术路径。它的核心思想就是将视觉任务的输出重新定义为图像，并且将任务 prompt 也指定为图像。在推理过程中，可以采用一对来自同一任务的输入和输出图像作为输入条件，来指示要执行的任务。

第四个是基于 painter 模型上衍生的分割一切的模型 SegGPT，它可以通过视觉 prompt 来完成任意分割的任务。与 painter 一样，SegGPT 也具备视觉上的上下文推理功能，只需要给出一个或几个视觉的 prompt，模型就能够理解用户的意图，有样学样地去完成类似的分割任务。

第五个是零样本的视频编辑方法 vid2vid-zero，在无需额外视频训练的情况下，它利用注意力机制动态运算的特点，结合现有的图像扩散模型，实现了可以指定属性的视频编辑。比如说，仅仅通过一句话，就可以换掉视频中的车和背景。

第六个是补全一切的生成式大模型 Emu，它可以接受多模态的输入，预测多模态的输出，支持在文字、图片、视频多模态序列内间进行理解、推理和生成。可以指定任意模态的输入组合，都能够在序列中补全下一项。Emu 的多模态上下文学习可以实现多轮的图文对话视频理解、少样本图文理解、文图生成、图图生成和少样本的文图生成等等。

除了悟道 3.0 本身的内容之外，這次會議的議程設置上，也聚焦了大模型、多模態生成式模型、AI 安全倫理問題和風險防範等最新話題，同時也包含了像自動駕駛、生命科學等專業細分領域的報告和研討。後續幾天會陸續編輯和發布相關的會議影片，供大家學習和討論。

**結尾**

好了，今天的分享就到這裡，感謝大家的觀看，我們下期再見。

---

希望這個整理對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>97. 【YouTube】频道五月运营报告 | 关于YPP收入、大陆收pin码和收款的建议 | Youtube油管官方的一些功能更新 | 视频说明搜索优化技巧</summary><br>

<a href="https://www.youtube.com/watch?v=AdLpFwM7epA" target="_blank">
    <img src="https://img.youtube.com/vi/AdLpFwM7epA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【YouTube】频道五月运营报告 | 关于YPP收入、大陆收pin码和收款的建议 | Youtube油管官方的一些功能更新 | 视频说明搜索优化技巧



---

</details>

<details>
<summary>96. [2023-06-08] 【人工智能】Tafi | 全球首个文本生成高质量3D模型平台 | 效果媲美玛雅C4D | 开放测试申请</summary><br>

<a href="https://www.youtube.com/watch?v=bvXw4LVxOwU" target="_blank">
    <img src="https://img.youtube.com/vi/bvXw4LVxOwU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Tafi | 全球首个文本生成高质量3D模型平台 | 效果媲美玛雅C4D | 开放测试申请

好的，我將這份文稿整理如下，主要目標是讓它更易讀、更結構化：

**標題：AI文本生成3D模型平台：Tafi介紹**

**前言：**

*   大家好，這裡是最佳拍檔，我是大飛。
*   今天嗓子不太舒服，請大家見諒。
*   今天要分享一個網站 (Tafi)，即使是商用收費，也覺得很有意思，想分享給大家。

**背景：**

*   早期AI節目中，有觀眾評論說，文本生成圖片、影片已經很厲害，何時能生成3D模型才算真正突破。
*   現在，一家3D廠商 Tafi 發布了一個可以透過文本直接生成3D角色模型的AI平台。

**Tafi平台簡介：**

*   **核心技術：**
    *   累積20多年，擁有超過500萬件可編輯的3D模型。
    *   獨家AI生成引擎。
    *   可在短時間內完成模型訓練。
*   **亮點：** 全球首個高品質的生成式3D模型平台。
*   **優勢：**
    *   傳統方式訓練AI模型，需要75,000年才能達到高精度、高品質標準。
    *   具備文本提示、高品質、高效率、可視化編輯等技術特性。

**使用方法：**

*   用戶可以通過文本快速創建3D模型。
    *   例如：「創建一個歐洲身材的男性模特，老一點的樣子，穿一套毒液那樣的衣服」。
*   即使沒有3D設計經驗，也能使用，只需要提供創意。
*   生成的3D模型效果逼真，可與瑪雅、C4D等專業軟體媲美。
*   模型可直接導入虛幻引擎 (Unreal)、Unity、Blender、3DMax、瑪雅和C4D等開發平台，進行二次編輯。

**功能與特性：**

*   支持實時可視化，創建、編輯、刪除等操作，提升模型精準度。
*   可直接在虛幻引擎中使用。
    *   生成的角色膚色、體型、五官、動作等全部獨一無二，沒有重複。
    *   設計時間僅需幾分鐘，傳統開發模式可能需要幾天。

**版權：**

*   通過Tafi平台生成的模型可以直接商業化。
*   20多年來，已與專業設計師分享超過2億美元，用於購買3D模型版權。

**Tafi公司介紹：**

*   創立於2000年，總部位於美國猶他州。
*   提供高品質的3D角色模型、場景道具及其他3D資源。
*   應用於遊戲、動畫、Web3、元宇宙、廣告、VR、AR等行業。

**結語：**

*   目前平台處於申請測試階段，有興趣的朋友可以申請試用。
*   今天的分享就到這裡，歡迎訂閱頻道，下期再見。

**重點修改說明：**

*   **分段與標題：** 加入了更清晰的標題和分段，將重點內容突出。
*   **項目符號：** 使用項目符號整理平台特性、優勢和使用方法，讓資訊更易於閱讀。
*   **簡潔語言：** 刪除了一些重複或口語化的詞彙，讓整體表達更精煉。
*   **結論：** 將原文的結論重新編寫，更強調行動呼籲（申請試用）。

這個整理後的版本希望能更清晰、更有條理地呈現原文內容。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>95. [2023-06-04] 【AIGC】谷歌公开StyleDrop模型论文 | 图像风格定制大师 | LOGO也能轻松生成 | 挑战Midjourney | 基于Muse模型</summary><br>

<a href="https://www.youtube.com/watch?v=Gi8eEanuNY8" target="_blank">
    <img src="https://img.youtube.com/vi/Gi8eEanuNY8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】谷歌公开StyleDrop模型论文 | 图像风格定制大师 | LOGO也能轻松生成 | 挑战Midjourney | 基于Muse模型

好的，我將為您整理這段文稿，使其更易於閱讀和理解：

**标题：AIGC 领域新突破：谷歌 StyleDrop 解析**

**概述：**

本期节目介绍谷歌最新发布的 AIGC 工具 StyleDrop。StyleDrop 的核心能力在于其强大的风格迁移功能，仅需一张参考图，即可解构并复刻复杂的艺术风格，并应用于各种图像生成任务。

**StyleDrop 的主要特性：**

*   **强大的风格迁移：** 可根据参考图，创作出梵高风格的画作、卡通风格的物体，甚至设计风格一致的 LOGO。
*   **细节把控：** 能精准地把控原图的细节，例如阴影、笔触、纸张褶皱等。
*   **灵感来源：** 借鉴了 Eyedropper 取色工具，旨在让用户快速、毫不费力地挑选所需样式并生成图案。
*   **内容与风格结合：** 结合 DreamBooth，可定制内容，例如生成梵高风格的小柯基或水彩笔风格的小猫。

**StyleDrop 的技术原理：**

*   **基于 Muse 构建：** Muse 是一种基于掩码生成式 Transformer 的文本生成图像模型。
*   **关键组成部分：** 生成视觉 transformer 的参数有效微调；带反馈的迭代训练。
*   **Muse 包含的模块：**
    *   文本编码器 (T)
    *   Transformer (G)
    *   采样器 (S)
    *   图像编码器 (E)
    *   解码器 (D)
*   **流程：**
    1.  T 将文本提示映射到连续嵌入空间。
    2.  G 处理文本嵌入，生成视觉 token 序列的对数。
    3.  S 通过迭代解码，从对数中提取到视觉 token 的序列。
    4.  D 将离散的 token 序列映射到像素空间。
*   **参数高效微调：** StyleDrop 对 Muse Transformer 层的架构进行了简化，以支持参数高效微调。
*   **模板化文本提示：** 使用简单的模板化方法构建文本提示，包括内容描述和风格描述。
*   **带有反馈的迭代训练：** 使用 CLIP 得分和 HF 人工反馈两种方法。
    *   **CLIP 得分：** 测量图像和文本的对齐程度，评估生成图像的质量。
    *   **HF 人工反馈：** 将用户的意图直接注入到合成图像质量评估中，弥补 CLIP 得分无法捕捉的微妙风格属性。

**实验与评估：**

*   **实验方案：** 收集几十张不同风格的图片，包括水彩、油画、平面插画、3D 渲染和不同材质的雕塑等。
*   **调优：** 使用适配器进行调优，更新 1000 步的适配器权度，学习速率为 0.00003。
*   **评估：** 基于 CLIP 衡量风格一致性和文本对齐，并进行用户偏好研究。

**实验结果：**

StyleDrop 能够捕捉各种样式的纹理、阴影和结构的细微差别，对颜色偏移层次和锐角的细粒度把控也更好。

**总结：**

StyleDrop 在 AIGC 领域取得了重要突破，其强大的风格迁移能力和细节把控能力，为图像生成带来了更多可能性。然而，其对设计师职业的影响也值得关注。

**结束语：**

感谢大家的观看，欢迎订阅本频道，我们下期再见。

**修改说明：**

*   增加了标题和概述，方便读者快速了解内容。
*   使用了分点和分层结构，使内容更清晰。
*   对技术细节进行了精简和解释，使其更易于理解。
*   调整了语句结构，使语言更流畅。
*   更正了一些口语化的表达方式，使其更书面化。
*   补充了一些关键信息，例如实验结果。
*   保留了原稿的主要信息和观点。

希望以上整理后的文稿对您有所帮助。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>94. [2023-06-03] 【人工智能】回顾人工智能十年发展历程 | 2013-2023 | AlexNet | GAN | Transformer | Resnet | GNN | GPT | Stable Diffusion</summary><br>

<a href="https://www.youtube.com/watch?v=Tj7xI5yVMSM" target="_blank">
    <img src="https://img.youtube.com/vi/Tj7xI5yVMSM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】回顾人工智能十年发展历程 | 2013-2023 | AlexNet | GAN | Transformer | Resnet | GNN | GPT | Stable Diffusion

好的，以下是我整理後的文件，我將其分為幾個部分，使其更易於閱讀和理解。

**標題:** 人工智慧 (AI) 十年發展歷程回顧 (2013-2023)

**摘要:**

本影片回顧過去十年 (2013-2023) 人工智慧 (AI) 領域的關鍵性突破，從深度學習的興起，到生成式模型的爆發，以及大語言模型 (LLM) 的快速發展。影片涵蓋了重要的模型、技術和事件，並探討了 AI 對各個領域的影響，以及對未來發展的展望。

**主要里程碑與技術突破:**

*   **2012: AlexNet (深度卷積神經網路 CNN)**
    *   在 ImageNet 大規模視覺識別挑戰賽 (ILSVRC) 中取得突破性成果，證明深度學習在圖像識別中的潛力。
    *   採用深度 CNN 架构，使用 ReLU 激活函數，並利用 GPU 進行平行訓練。
*   **2013: 深度學習成熟元年**
    *   變分自動編碼器 (VAE) 的出現，為生成式建模和數據生成開闢了新的路徑。
*   **2014: 生成式對抗網路 (GAN)**
    *   透過生成器和鑑別器的對抗訓練，能夠生成與訓練數據相似的新數據樣本，應用於圖像、視頻、音樂和藝術創作等領域。
*   **2015: ResNet (殘差神經網路)**
    *   透過添加快捷方式解決梯度消失問題，讓訓練更深層的網路成為可能，提升了圖像分類和對象識別任務的表現。
    *   循環神經網路 (RNN) 和長短期記憶 (LSTM) 模型的改進，提升了在語言翻譯、文本生成和情感分析等任務中的表現，為大語言模型發展鋪路。
*   **2016: AlphaGo**
    *   AlphaGo 擊敗圍棋世界冠軍李世石，證明機器智能在複雜項目中也能擊敗人類。AlphaGo採用深度強化學習加蒙特卡洛樹搜尋。
*   **2017: Transformer 架構**
    *   《Attention Is All You Need》論文介紹了 Transformer 架構，利用自注意力機制處理順序輸入數據，解決了 RNN 架构的挑戰，成為大語言模型開發的關鍵組成部分。
*   **2018: GPT-1 和 BERT**
    *   OpenAI 的 GPT-1 證明了無監督預訓練的有效性。
    *   Google 的 BERT 實現了深度的雙向文本理解，在自然語言處理任務中表現出色。
    *   圖神經網路 (GNN) 的出現，專門用於處理圖形數據，應用於社交網路分析、推薦系統和藥物發現等領域。
*   **2019: GPT-2 和 BigGAN**
    *   GPT-2 在自然語言處理任務中表現出色，並能生成極為順暢的文本。
    *   DeepMind 的 BigGAN 生成的高質量圖像幾乎與真實圖像沒有任何區別。
*   **2020: GPT-3**
    *   GPT-3 在規模和能力上實現了重大飛躍，能夠根據不同提示和任務生成連續的文本，並在各種自然語言處理場景下表現出令人印象深刻的性能。
*   **2021: AlphaFold 2、DALL-E 和 GitHub Copilot**
    *   AlphaFold 2 解决了蛋白质折叠问题，对药物发现和生物工程具有巨大潜力。
    *   OpenAI 的 DALL-E 能够利用文本描述創造出高質量的圖像。
    *   GitHub Copilot 利用 Codex 模型，根據代码注释生成代码建議。
*   **2022: ChatGPT 和 Stable Diffusion**
    *   OpenAI 的 ChatGPT 是一款聊天機器人，能夠生成連續且與上下文相關的回應，並具備極強的查詢和提示適應能力。
    *   Stability AI 的 Stable Diffusion 能夠按照文本描述生成逼真的圖像。
*   **2023: LLaMA, GPT-4, Alpaca, Bard, PaLM-2 和其他 LLM 應用**
    *   Meta AI 的 LLaMA 和其他 LLM 模型在多項基準測試中成功反超 GPT-3。
    *   OpenAI 發布了 GPT-4，比 GPT-3 體量更大更強的多模態版本。
    *   越來越多的企業將語言模型融入到產品中，例如 Dolingo Max 和 Slack GPT。
    *   AI 聊天機器人開始推動心理治療師的大眾化普及，例如 Replika。
    *   微軟基於 GPT-4，將 Bing 打造成了 Web 版的 Copilot，對搜索業務進行了定制。

**未來展望:**

*   模型的主要改進重點將放在提高模型的能力、實用性和安全性上。
*   對 AI 安全性的重視，確保這些工具安全可靠，且符合人類的利益和福祉。

**總結:**

過去十年，AI 領域取得了巨大的進展，對我們的生活、工作和互動方式產生了深遠的影響。隨著技術的持續發展，我們需要謹慎行事，確保 AI 的發展能夠造福人類。

**補充說明:**

*   我已將文稿整理成更結構化的格式，方便理解和記憶。
*   我簡化了一些描述，但盡可能保留了原意。
*   您可以根據需要進一步修改或調整此整理後的版本。
*   我使用粗體字來強調重點詞彙。

希望這個整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>93. [2023-06-02] 【AIGC】开源复刻版DragGAN模型 | 中国团队李白实验室 | 点击拖拽即可修图</summary><br>

<a href="https://www.youtube.com/watch?v=h4oyJykxCQQ" target="_blank">
    <img src="https://img.youtube.com/vi/h4oyJykxCQQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】开源复刻版DragGAN模型 | 中国团队李白实验室 | 点击拖拽即可修图

好的，我幫您整理了一下這篇文稿，使其更易讀、更清晰，並且突出重點：

**標題：DragGAN 搶先體驗：李白實驗室復現版，輕鬆操控圖片！**

**開場：**

大家好，這裡是最佳拍檔！我是大飛。

之前我們介紹了最新的 GAN 模型 DragGAN，它允許用戶通過簡單的點擊和拖拽來修改圖片。許多網友都想體驗 DragGAN，最近王道控股旗下的李白實驗室算法團隊搶先重現了 DragGAN 的效果，而且可以直接使用！

**DragGAN 功能與特色：**

*   **輕鬆掌控：**  掌控圖片中的人物和動物，調整位置、形狀、姿勢等。
*   **Hugging Face 直接使用：**  無需程式碼，即可在 Hugging Face 上體驗。
*   **表情調整：**  修改微笑弧度，將嚴肅照片變成甜美笑容。
*   **美顏功能：**  放大眼睛、一鍵瘦臉，效果自然。
*   **修飾功能：**  給貓咪拉大臉龐、拯救髮際線、改變髮型。
*   **簡單原理：**
    *   基於特徵的運動監控，驅動手柄點向目標點移動。
    *   新的點跟蹤方法，利用鑒別性發生器的特點定位手柄點。
*   **區域編輯：**  選擇感興趣區域進行特定編輯，無需依賴其他網路。
*   **快速生成：**  只需幾秒鐘即可完成效果。
*   **迭代控制：**  調整迭代步數，步數越多效果越誇張，但生成時間也越長。
*   **優於傳統 PS：**  保留圖片原始屬性，應用範圍更廣。
*   **應用範例：**  改變圖中車輛位置、大小、輪胎形狀等。

**李白實驗室：**

*   **年輕團隊：**  一個非常年輕的人工智能技術團隊。
*   **創始人：**  唐勇博士，畢業於美國賓夕法尼亞州立大學。
*   **團隊成員：**  畢業於清華、北大、浙大、英國皇家理工、美國常春藤等知名高校。
*   **唐勇經歷：**  曾於美國知名研究機構及世界 500 強企業工作，主導並參與眾多社會、環境、能源相關項目。
*   **研究方向：**  運用數學物理模型、高性能計算、多目標優化及人工智能技術，解決現實世界中的大尺度、多模態、多變量複雜問題。
*   **成立李白實驗室原因：**  現實問題複雜，難以完全理解數學物理機理，希望通過人工智能提升模型泛化能力。

**郭銘濤：**

*   **主創人員：**  與團隊共同攻堅克難，復現 DragGAN。
*   **學歷背景：**  來自四川大學圖像所，目前在讀博士一年級。
*   **研究方向：**  深度生成模型。
*   **獎項：**  CVPR 2023 工業圖像缺陷生成競賽冠軍。

**李白實驗室的成就：**

*   **技術積累：**  在智能圖像生成方面有深厚積累。
*   **功能：**  實現了圖像分割、圖像修復增強、視頻處理等實用功能。
*   **圖像背景分割算法：**  在全球圖像分割 alphamatting.com 的模型比評比中獲得全球第一。
*   **專利：**  獲得國內外近 30 項學術和研究成果專利，80% 為發明專利。
*   **產品：**
    *   PicUP.Ai 皮卡智能項目 (2019)：海外同步上線 cutout.pro 項目，月活超過千萬，躋身圖像編輯工具分類前十。
    *   神采 PromeAI (2023)：通過算法優化升級，可應用於建築、室內、產品、遊戲、動漫場景設計，一鍵生成效果圖、線稿、電商產品圖等，實現 AIGC 從玩具到工具的轉變。

**李白實驗室的願景：**

*   **開源精神：**  开源復刻版 DragGAN，讓普通用戶也能簡單使用。
*   **技術普惠：**  將 AI 技術革新的成功帶到普通用戶身邊。
*   **未來展望：**  DragGAN 與圖像生成工具結合，可能誕生下一代內容革新技術產品。

**結尾：**

對 DragGAN 有興趣的小夥伴們，可以從 Github 下載他們的源代碼，試用看看效果如何。

歡迎大家訂閱我們的頻道，我們下期再見！

**總結:**

我把原文中比較口語化的部分修正了，使它更像一篇正式的文章。我也簡化了一些句子，讓重點更突出，並添加了標題和段落標題，方便讀者快速了解內容。 此外，我將實驗室的成就和願景單獨拉出來做重點，讓聽眾了解這個團隊的價值和意義。

希望這樣的整理對您有幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>92. [2023-06-01] 【人工智能】医疗开源大模型 | HuatuoGPT | 华佗GPT | 港中文大学联合深圳大数据 | ChatGPT蒸馏数据+真实医生数据 | 效果超GPT3.5</summary><br>

<a href="https://www.youtube.com/watch?v=taSuUARydjk" target="_blank">
    <img src="https://img.youtube.com/vi/taSuUARydjk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】医疗开源大模型 | HuatuoGPT | 华佗GPT | 港中文大学联合深圳大数据 | ChatGPT蒸馏数据+真实医生数据 | 效果超GPT3.5

好的，我幫你整理了這篇文稿，主要分成以下幾個部分，並且加入了一些更清晰的段落劃分和重點標示：

**標題：HuatuoGPT：結合 ChatGPT 與醫生數據的開源醫療大模型**

**引言：大語言模型在醫療領域的應用**

*   目前各行各業都在探索如何結合大語言模型，醫療行業也不例外。
*   儘管像 ChatGPT 這樣的語言模型可以生成內容詳實、表達流暢的回覆，但在醫學方面，尤其是在回應患者症狀時，仍缺乏專業性和對患者輸入的精確解讀。
*   ChatGPT 的回覆通常包含多種可能性，且以抽象建議呈現，缺少深入的上下文理解，無法具體幫助患者。

**背景：傳統醫療數據的局限性**

*   現實世界中，醫生與患者的互動數據能更準確反映醫療情況的複雜性，並提供準確的診斷建議。
*   但因時間限制，醫生的回覆常常過於簡潔，甚至不連貫。
*   僅依賴這些數據訓練模型，難以流暢應對各種指令或對話，生成的回覆短小、表述不佳，訊息含糊不清，對患者不友善。

**HuatuoGPT：解決方案**

*   香港中文大學（深圳）和深圳市大數據研究院王本友教授團隊，利用指令微調和強化學習，在 ChatGPT 和醫生回覆中找到結合點，訓練並開源了一個新的醫療大模型 HuatuoGPT。
*   **目標：** 融合 ChatGPT 生成的蒸餾數據以及真實世界醫生回覆的數據，使模型具備醫生般的診斷能力，同時保持用戶交互的流暢性和內容的豐富性。

**HuatuoGPT 的訓練數據集：**

HuatuoGPT 使用了四種不同的数据集:

1.  **蒸餾後的 ChatGPT 指令数据集**：
    *   靈感來自 Alpaca 模型創建指令集的方法，從 ChatGPT 中提煉醫療相關指令。
    *   加入了科室和角色的資訊，根據採樣的科室或角色生成符合條件的指令数据集。
2.  **真實的醫生指令数据集**：
    *   來源於真實的醫生和患者之間的問答。
    *   醫生的回覆通常簡潔且口語化，因此通過這個方法可以進行潤色，提高可讀性。
3.  **蒸餾後的 ChatGPT 對話数据集**：
    *   為兩個 ChatGPT 模型提供共享的對話背景，讓它們分別模仿醫生和患者進行對話。
4.  **真實的醫生對話数据集**：
    *   來源於真實醫生的對話。
    *   對醫生的回覆使用了模型進行潤色。

*   這些數據集共同為模型提供統一的語言模式、醫生診斷能力以及指令跟隨能力。

**HuatuoGPT 的強化學習：**

*   HuatuoGPT 使用了基於 AI 反饋的強化學習技術 (RLAIF)。
*   使用 ChatGPT 對模型生成的内容進行評分，考慮内容的用户友好程度。
*   結合醫生的回答作為參考，將醫生回覆的品質納入考量。
*   利用 PPO 算法調整模型的生成偏好，使其與醫生和用戶之間的一致性更高。
*   增强模型生成豐富詳盡正確的診斷的能力。

**HuatuoGPT 的性能評估：**

*   採用自動評估和人工評估兩種方式相互驗證。
*   在單輪問答場景和多輪交互式診斷場景中分別進行評估。

**1. 自動評估：**

*   **單輪問答：**
    *   收集了涵蓋 10 個醫療領域意圖的 100 個問題。
    *   利用 GPT-4 進行自動評估：提供兩個模型對同一個問題生成回復，然後使用 GPT-4 對每個模型的回覆進行分析和打分。
    *   結果顯示，HuatuoGPT 的表現優於基於 LLaMA 和 ChatGLM 的開源中文醫療模型。
    *   優勢歸功於 HuatuoGPT 同時使用了從 ChatGPT 蒸餾的數據以及真實世界數據進行訓練，並借助 ChatGPT 和專業醫生的混合反饋進行優化。
    *   HuatuoGPT 在總體性能上甚至超過了 GPT 3.5 Turbo。
*   **多輪問診：**
    *   收集了涵蓋 20 個科室的 100 個多輪對話進行評估。
    *   HuatuoGPT 不僅全面優於目前的開源中文醫療模型，而且在大部分科室的表現上均優於 GPT 3.5 Turbo。
    *   證明 HuatuoGPT 在處理更複雜的多輪問診場景中有更優異的性能。

**2. 人工評估：**

*   邀請專業醫生對模型的輸出結果進行人工評估，同樣分為單輪問答場景和多輪問診場景。
*   無論單輪還是多輪評測，結果都與自動評估結果保持一致。
*   充分驗證了模型性能評估的一致性和可靠性。

**Huatuo-26M 醫療問答數據集：**

*   團隊還開放了 HuatuoGPT 的前置工作 Huatuo-26M 醫療問答數據集（2600 萬醫療問答數據），全部開源到 HuggingFace。
*   如果需要清理好的乾淨數據，可以發郵件申請（註明單位和承諾只用於科學目的）。
*   對於包括 Huatuo-26M 在内的三個公開的醫療問答數據集，HuatuoGPT 的 Zero shot 性能都超過了 GPT 3.5 Turbo、ChatGLM 和已有的醫療 GBT，甚至遠好於全微調的中等大小的 T5 和 GPT。

**總結：**

*   HuatuoGPT 结合了 ChatGPT 的数据和真实医生的数据，实现了更好的医疗问答性能。
*   希望精通醫學的朋友能深度體驗，並分享感受。

我希望這個整理版本更清晰易懂。 如果您需要進一步的修改或調整，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>91. [2023-05-31] 【人物】中国人工智能的摇篮 | 上海交大ACM班传奇故事 | 余勇 | 林晨曦 | 戴文渊 | 胡哲人 | 李磊 | 李沐 | 陈天奇 | 王敏捷 | 张伟楠 | 郑曌</summary><br>

<a href="https://www.youtube.com/watch?v=9WdPG4KAbGY" target="_blank">
    <img src="https://img.youtube.com/vi/9WdPG4KAbGY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】中国人工智能的摇篮 | 上海交大ACM班传奇故事 | 余勇 | 林晨曦 | 戴文渊 | 胡哲人 | 李磊 | 李沐 | 陈天奇 | 王敏捷 | 张伟楠 | 郑曌

好的，我將根據您的要求，對文稿進行整理，使其更易於閱讀和理解。

**整理後文稿：**

**引言**

大家好，這裡是最佳拍檔。我是大飛。今天要講述一個傳奇的班集體——上海交大的ACM班，以及這個班級裡同學們的故事。ACM班成立時僅用了三天，不僅直接推動了中國計算機技術的發展，更被譽為「人工智能CTO搖籃」。

**ACM班的創立**

*   **創始人余勇：** 提出這個設想的創始人是當時剛過40歲的余勇。
*   **成立背景：** 2002年6月16日，擔任上海交通大學ACM國際大學生設計程序競賽（ACM ICPC）總教練六年後，余勇心中埋藏已久的夙願終於迎來曙光，那就是培養屬於中國自己的計算機科學家。
*   **申請與批復：** 余勇找到主管教學的校長，提出成立ACM班的申請，隔天（18日）就獲得上海交大的批復。
*   **時代背景：** 當時國內沒有可以借鑒的參考，清華姚班也是在三年後的2005年秋季才發布招生計畫。
*   **快速批復的原因：** 2002年3月，交大學生林晨曦、陸靖、周健組隊代表中國獲得第一個ACM ICPC冠軍。

**余勇的教育情結**

*   **華東師範大學的影響：** 余勇大學時就讀於華東師範大學，有兩個人對他產生深刻的影響。
    *   **劉佛年校長：** 劉佛年強調做老師不只要教好書，還要懂教育。
    *   **張東韓主任：** 張東韓的報告會，讓余勇更加堅定傳道授業解惑的追求。
*   **上海交大的教學生涯：** 1986年從華東師大碩士畢業後，余勇選擇到上海交大任教，至今已36年。

**ACM班的成立與成功**

*   **ACM ICPC的契機：** 1996年ACM ICPC進入中國，余勇開始組隊參賽。
*   **天才少年的精誠合作：** 2002年，交大獲得世界冠軍，余勇得以成立ACM班。
    *   **林晨曦：** 依圖科技聯合創始人，原為材料專業學生，被余勇挖掘。
    *   **陸靖：** 天才少年，但經歷失敗後明白團隊合作的重要性。
    *   **周健：** 團隊成員，與林晨曦、陸靖一同奪得世界冠軍。
*   **ACM班的傳奇故事：** ACM班開啟了上海交大在計算機、人工智能、深度學習領域的傳奇故事。

**ACM班的影響**

*   **培養人才：** ACM班培養了戴文淵、李沐、陳天奇、李磊、鄭曌等人工智能領域的大神級人物。
*   **多元發展：** ACM班學生不僅在學術研究上有所成就，也參與創立了一批知名公司，如餓了么、依圖科技、第四範式等。

**ACM班的文化**

*   **核心價值：** 超越，探索有中國特色的拔尖人才培養模式。
*   **課程特色：**
    *   **學子講壇：** 余勇講授非計算機類的文學、時政等內容。
    *   **教學實踐：** 高年級學生擔任低年級課程助教，傳承ACM班的傳統。

**戴文淵的故事**

*   **選擇交大：** 戴文淵放棄清華保送資格，選擇進入交大ACM班。
*   **再奪冠軍：** 2005年，戴文淵帶隊奪得ACM ICPC世界冠軍。
*   **加入百度：** 參與百度鳳巢建設，獲得「最佳百度人」稱號。
*   **創立第四範式：** 離開百度後，創立第四範式，致力於企業服務。

**羅宇龍的故事**

*   **創業的選擇：** 羅宇龍放棄直研選擇創業，受到余勇批評。
*   **餓了么的成功：** 參與創立餓了么，成為資深副總裁。

**陳雨強的故事**

*   **加入百度：** 加入百度，參與搭建世界上第一個商用的深度學習系統。
*   **加入第四範式：** 應戴文淵邀請，參與第四範式的創業。

**鄭曌的故事**

*   **加入谷歌：** 在谷歌工作多年。
*   **加入第四範式：** 應戴文淵邀請，回國參與第四範式的工作。

**ACM班的其他傑出人才**

*   **胡哲人：** 流利說創始人，第一個IPO成功的ACM班學生。
*   **李磊：** 獲得ACL2021最佳論文，任職加州大學聖巴巴拉分校助理教授。
*   **李沐：** 在百度創建分布式的機器學習廣告系統，YouTube頻道「跟李沐學AI」。
*   **陳天奇：** XGBoost的作者，MXNet的共同創始人。

**MXNet的誕生**

*   **團隊合作：** 李沐、陳天奇、王敏捷共同創建MXNet。
*   **影響力：** MXNet成為深度學習領域最主流的開源代碼之一。

**余勇的教育理念**

*   **保持好奇心：** 希望學生始終保持好奇心，不要給自己打標籤。
*   **多元發展：** ACM班學生來自不同領域，基礎紮實，容易在各個方向取得成就。

**余勇的伯禹教育**

*   **創立伯禹教育：** 面向全國所有願意學習人工智能計算機的學生。
*   **彌補教育資源差距：** 積極參與各種交流活動，為不同學校的學生提供幫助。

**結語**

20年後，余勇面臨的問題更多也更加複雜，但仍致力於培養圖靈獎得主。希望在未來的20年，ACM班能探索更多新的領域。

**文稿調整說明：**

*   **分點整理：** 將冗長的文字分為小段落，並使用項目符號（*）或數字編號，使重點更突出，層次更分明。
*   **添加標題與副標題：** 增加標題與副標題，方便讀者快速瞭解文章結構和內容。
*   **提煉關鍵資訊：** 將每個部分的核心信息提煉出來，用簡潔的語言概括，方便讀者快速抓取重點。
*   **修改部分語句：** 調整部分語句，使其更流暢易懂，更符合閱讀習慣。
*   **簡化表達：** 刪除一些重複或不必要的描述，使文章更精煉。
*   **內容歸納：** 將相似內容合併，避免重複敘述。

希望這個整理後的文稿能更符合您的需求！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>90. [2023-05-28] 【对话】SmartDeer创始人庞律 | 解读中国企业出海香港政策 | 香港人才引进计划 | 四类人才签证究竟有什么不同 | 如何拿到香港永居签证和公民身份 | 香港投资移民最新进展</summary><br>

<a href="https://www.youtube.com/watch?v=J7U1Vg6pOLQ" target="_blank">
    <img src="https://img.youtube.com/vi/J7U1Vg6pOLQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【对话】SmartDeer创始人庞律 | 解读中国企业出海香港政策 | 香港人才引进计划 | 四类人才签证究竟有什么不同 | 如何拿到香港永居签证和公民身份 | 香港投资移民最新进展

好的，這是我整理過的文稿，我盡力保持原文的語氣，並將其整理得更清晰易讀：

**最佳拍檔：香港人才與企業出海優惠政策分享**

**開場**

*   **大飛：** 大家好，這裡是最佳拍檔，我是大飛。今天我請來了我的好朋友，龐律律哥，來為大家分享一些關於香港政策、香港人才和企業（出海）的一些優惠政策。律哥，要不你先自我介紹一下？
*   **龐律律哥：** OK，我和大飛是在一些技術社群裡認識的。我們倆都是技術出身。過去幾年我一直在創業，參與了很多方向，像是互聯網金融、教育等等。大概從去年2月份開始，我開始在人力資源行業創業，主要是做全球招聘和全球雇傭，這是一個挺新的方向。人力資源是一個非常傳統的行業，它主要是管人。現在有很多技術出現，做了很多HR SaaS的東西。但 SaaS只是一個工具，人還是需要更多的服務，把人和工具連接起來。過去很長時間都在SaaS裡面，其實是提供工具讓企業用，或是讓員工自己用。但我們會發現這裡面還是有一個Gap，這個Gap可能就是如何讓企業和人透過一些服務，把企業和系統更好地連接起來。我們相當於做了這件事情，不僅是要做服務，還要設計產品和工具，把人和企業透過工具產品服務連接起來。然後，也隨著近幾年的這種全球 remote 工作和更多元化的國際化企業不斷湧現，我們其實是要幫助更多的企業更好地面向全球市場，去做全球市場的業務。這裡面，人力資源如何能更好地在全球市場上落地和執行，這是一個很重要也很熱門的話題。我們也就是從去年1月份開始，就開始嘗試在這裡面做一些事情。

**全球人力資源市場概況**

*   **大飛：** 現在這個全球的市場，這個人力情況，人力資源情況，你能給大家簡單的介紹一下嗎？
*   **龐律律哥：** 我們可以先聚焦在說中國企業是如何看待全球的人力資源市場的，海外公司可能有不同的看法和角度。中國企業最厲害的肯定就是生產製造，還有互聯網這幾波浪潮，鍛鍊了大量的互聯網人才，不管是技術、產品還是營運。如果他們要出海，這些肯定都是中國優勢的資源，肯定比海外的資源供給要多，質量高，性價比也高。如果中國企業要看向全球市場，他們更多關注的是如何把服務、產品和業務更好地在當地落地。從這個角度來看，不管是在東南亞、拉丁美洲、中東還是歐洲，我們需要的核心人才都是當地可以幫助企業更好落地的人，通常是做 marketing、市場、BD、當地銷售，或者是一些當地 local 的營運，因為我們很多要做本土化、本土化語言。在當地找到性價比更高，對當地文化商業行為更熟悉的人才，肯定更有優勢。所以，作為一個立足於中國，來幫助中國企業出海的角色，我們肯定要知道這些企業在哪些地方需要什麼樣的人才。這些人才可能包括我剛才說的這些職業工種，但我們如何更高效、性價比更高地利用當地人才？我們有什麼樣的選項提供給大家？用什麼樣的雇傭辦法成本更低？如何讓企業更靈活？這些其實都是我們在做的事情，當然這也是一個很大的話題，我們後面可以再聊一期。

**業務範圍與香港的重要性**

*   **大飛：** 現在我們的業務大概涉及到了哪幾個國家地區呢？之前咱們聊過一些，尤其是香港這塊，可能就是你們現在一個重點在做的方向吧？
*   **龐律律哥：** 中國企業出海是跟著行業和出海階段，他們會嘗試不同的地區。像比較知名的通訊製造企業，像是華為、中興，他們是很老資格的出海企業，大概已經有二、三十年了，他們的布局非常廣泛，希望能覆蓋的國家和城市非常多。對於新興出海的，尤其是互聯網的文娛產品，舉個例子，他們肯定首先選用戶市場足夠多的地方，比如說印尼，可能有兩三億人口。雖然這個國家用的是印尼語，網路設備也不太好，環境也不好，但他們還是要去，因為 market size 夠大。像快手，肯定希望落腳在印尼這個市場。對於更早期的行業，他們是在嘗試出海，或是出海的第一站，他們會選在哪？如果這些公司嘗試出海的第一站，總部會選在哪？現在基本上就兩個選擇：新加坡和香港。因為新加坡和香港相對來說在全球都是知名的稅收窪地，有很多政策。我們肯定更容易在當地落地，落地完以後，對於企業在那邊經營的收入稅務特別有幫助。第二點是香港和新加坡特別有優勢，他們都是東八區，和中國總部完全 match，文化習俗也非常貼合。結合這幾點，大家都比較願意去新加坡和香港。尤其新加坡從疫情中，去年特別火，但因為太火了，在很短的時間內成本價格就會非常擁擠。所以大概從去年下半年以後，新加坡的人就開始外溢了。外溢有幾個方向：一是往東南亞其他國家外溢，像是馬來西亞、泰國、越南等等。第二點是再想出去的人，他們就要很 serious 考慮是不是也要把海外總部放在新加坡，有沒有其他選擇。從去年年底的時候，香港就變成了大家比較重要的選擇。尤其是在疫情開放以後，加上香港政府做了非常多刺激經濟的舉動，讓更多的企業也嘗試說香港是一個還不錯的選擇。我們大概從去年12月開始，已經服務了幾十家來自中國的公司，或是海外公司，包括很多海外的華人企業，也會嘗試在香港設一個點。因為香港這個角色非常特殊，它有幾個最大的特殊點：一是香港政府現在特別希望經濟發展，希望更多優質的人才能來到香港。二是香港的地理位置非常特殊，相對於新加坡來說，它跟中國大陸連在一起，而且香港還是一個一國兩制的典型案例，所以它的經濟、政治、市場環境還是跟全球完全聯通能夠接軌。第三點就是香港相對於新加坡要大很多，不管是辦公就業環境，它都有更多的選擇。所以不管是工作還是就業，都會是一個比較好的選項。這也就是為什麼我們從去年12月份到現在，有更多的企業嘗試要去了解香港，或是跟我們溝通，香港現在有什麼樣的機會，然後我怎麼能過去，我怎麼在這定居和工作。大家會感覺到有很多關於香港的廣告從年初就特別火，但現在我的判斷是，大家站的立場可能不一樣，每個企業對包裝香港的政策、法律法規，和吸引人才的點不太一樣。結合這些不一樣的點，那大家的立場不一樣，所以會有誤導，當然可能不是他們故意的，可能是他們說了一些資訊，但沒有說另一些資訊。對於很多人來說，他們對香港理解的認知不是一個完整的拼圖，而是一小塊，那大家就很容易在做決策的時候，資訊不夠全面。從我們現在開始，我們在跟所有企業在溝通香港的時候，也是希望讓大家知道香港的優點是什麼，缺點是什麼，中間為什麼會有這些優惠待遇，為什麼要有這些非常嚴格的控制，他們為什麼這樣想。因為大家最根本的是理解香港政府為什麼要做這些事情，明白了這些，大家就很好理解了。
*   **大飛：** 你剛才也說到了，會有兩個方面，一個是企業的出海，就是企業在香港的一些發展，另一方面企業也都是人，那本身這個人去香港，或者人出海，他可能也會有一些相關的政策。我們今天主要可能就針對這兩個方面，來讓律哥給我們大概講一下。我們先說一下企業方面，因為你也這麼長時間接觸這麼多企業了，你先給我們大概講一下企業這方面，一個香港出海，這個落地的情況怎麼樣？

**SmartDeer 公司介紹與香港優勢**

*   **龐律律哥：** 我們公司是2021年成立的，我們公司名字就叫 SmartDeer，現在也沒有中文名。大家也可以從網路上找到我們。SmartDeer 接下來描述的香港所有政策，對企業對人來說，都是我們自己親身經歷過的。我們自己不是說我們完全是個代言人，然後我們自己不用這樣的流程。
*   **大飛：** 你經歷過說我把公司放在香港？
*   **龐律律哥：** 對，然後我們怎麼去拿香港政府的一些政策。接下來，我們公司本身也有在辦簽證，二是我們在幫大概幾十個客戶從去年年底到現在辦簽證，辦他們公司在香港的一些政策激勵。這些都是比較一手的資訊。我們公司 SmartDeer 本身也是個 VIE 架構，我們在香港是我們的總部。所以我們其實一開始就會把公司設立在香港。香港對於我們來說，對企業來說，最重要的幾個優勢是什麼？最重要的優勢，大家所有人都知道，是稅務窪地。對於企業來說，第一點就是沒有增值稅。全球沒有增值稅的國家和地區並不是特別多。第二點是香港的金融環境非常自由，資金的進出，它的流程金融也很發達，大家選擇也很多，尤其跟全球市場做生意的時候，你可以很輕鬆地用香港總部來跟世界各國做簽約，資金能進駐到香港。香港跟多個國家有稅收協定，這也能幫助企業更好地以香港為總部，在各個國家設立子公司，來保證整個資金鏈路是一個相對稅收有比較優勢的地方。這些點香港和新加坡都有類似的角色，整個貨幣交易也非常方便。

**香港政府對新興產業的支持**

*   **龐律律哥：** 第二大塊是香港政府從去年年底開始，對一些行業做了一個非常大的擁抱。香港政府在很多新行業的接受程度和擁抱新的選擇方向上面，比較願意往前走和嘗試。香港政府其實更開放一點，跟新加坡政府是一個概念。因為香港比較小，好調整，他們願意嘗試一些方向，但裡面的監管法規還沒有這麼健全，可以藉著這波紅利先做。Web3 可能就是一個例子。
*   **大飛：** 之前一段時間，香港類似 All In Web3 這種感覺。
*   **龐律律哥：** 事實上，從去年下半年開始，就出台了一大批刺激 Web3 行業的政策。Web3 本身底層是金融屬性很強的產品和業務，項目本身就是一個很有很大的金融人才儲備的區域，所以香港沒有理由拒絕。第二點是 Web3 裡面最大的問題是缺少監管，這個監管在一個大國，比如說中國和美國，現在都是用非常反向的方式在監管。美國監管也很嚴，事實上跟中國基本上是一個美國最近一段時間，包括上個月有一個叫做 consensus 的共識會議。大家的直觀感受是，美國通過監管非常嚴格地在往後面倒退，因為很多事情做不了。所以中美之間在大國之間，在這些新興的，在合規層面有比較大風險的行業，基本上是閉關的。香港作為一個中國非常特殊的前沿特區，反而是一個非常積極擁抱的態度。港府包括財政署，都非常積極發布一系列政策。

**香港的科技園區與孵化計畫**

*   **龐律律哥：** 在香港，Web3 還算是科技金融行業，所以他還是個科技公司。香港整個港府下面有兩個比較重要的園區，有點像北京的中關村園區。中關村他有產業基金，會投很多項目，代表可能是北京市國資委，或是一些政府的資金流動。香港有兩個比較重要的園區，一個叫香港科學園，在香港的北邊，一個叫香港數碼港，在香港的最南邊。這兩個園區是100%香港控股，像數碼港的管理公司是100%港府控股。科學園的這樣的管理公司，他這個應該叫法定設立機構，所以這兩個園區雖然是一個園區，但事實上是港府直接管理和控制的，所以他們對科技企業的吸引都是靠這兩個園區來落地。這兩個園區本身是有孵化計畫，有一些program，他們會給你一些資金資助，政策支持，簽證支持，當然還有辦公空間的支持，價格確實非常便宜。港府透過數碼港在去年年底成立了一個叫 Web3 Hub，是政府的行為，會成立一個 Web3 的園區。它通過這個數碼港Web3，來去做了一個孵化器項目，叫 Cyberport Incubation Programme，簡稱 CIP，就是數碼港的孵化計畫。通過這個計畫申請成功，他會給你資金支持，簽證支持，各種支持。SmartDeer 是作為 CIP 第一期入選的一個機構。他們是在1月份入駐進去了。我們SmartDeer 不是一個純 Web3 的公司，我們是一個連接Web2 和全球的人力資源產品。我們看準的是：一是香港很希望吸引人才，二是香港很希望吸引 Web3 人才。我們在吸引人才和吸引 Web3 人才上面，跟整個港府的邏輯是完全匹配的。我們跟數碼港的program申請過程中，也是直接表達這個觀點。我們跟整個港府底層的邏輯是完全一致的情況下，我們其實當時相當於是第一批申請上了。這樣的計畫，每年大概有兩期，一月和六月。他們可能會給一點資金支持，但這個不多，重點是表達從政府到科學園區，然後到企業，這個鏈路就能被打通了。拿了這樣的一個孵化計畫，事實上是間接拿到了港府對於這個方向，或對你們企業的一個小小的背書，拿了這個背書就可以繼續發展，後面從香港政府拿到更多支持的管道就已經打開了。有個政府背書了。比如拿到數碼港 CIP 計畫以後，就可以透過內部的人來聯繫 invest Hong Kong，香港投資署，跟他們建立聯繫。可以在每一輪融資的時候，去邀請他們作為參股，慢慢地把整個融資鏈路跟香港的整個發展更好地綁在一起。
*   **大飛：** 你感覺跟香港政府在打交道，包括你說的數碼港，還有投資署，打交道過程中你感覺怎麼樣？
*   **龐律律哥：** 至少我現在的溝通，因為我也介紹了幾十個不同的企業，他們想去。我跟他們的溝通，拉群聊天，他們還是非常積極熱情的。他們做事也非常靠譜，所有問題都能解答。

**與香港政府合作的經驗**

*   **龐律律哥：** 包括數碼港給我們的 account manager，他們這個回復，對我們一些問題的解答，其實都是非常全面的。如果遇到什麼問題，需要數碼港作為背書，幫我們去介紹，比如香港入境署，這些政府關係，他們都可以協助。核心是你不要提出過分的要求。你只要能證明你的要求邏輯非常清晰合理，我是要做這個事情，我現在在當地要做一個 AI 公司，我需要大量的人才，但這個人才香港本地不夠，我必須從中國大陸轉移，比如說10個20個工程師同時去。通常來說，在香港的正常入境計畫裡面，得一個一個慢慢進。把你的公司情況說清楚，我需要的人才就是這麼多，而且這些人就是人才，PhD、專家等等。香港會非常願意積極地直接拉入境署的人，然後給你做特批。只要你的邏輯對，你理解到港府在資助企業的根本原因是需要更好的項目，更好的人才來到香港居住生活工作，這個是最基礎的。只要掌握這個事情，他們沒有理由拒絕，而且會很積極地去推動，不會像國內有些時候會拖著你，或是踢皮球。最根本原因是，他們一線的團隊非常理解高層想要什麼。港府就想要更好的人，從上層表達這個觀點跟底下非常一致。大家理解根源性的東西，我需要很好的人過來，這個人過來是建設香港，不是來薅羊毛。只要把這個邏輯跟大家說清楚，港府為什麼不去吸引這些人呢？

**各行業的機會與數碼港的未來**

*   **龐律律哥：** 港府更願意嘗試一些新的行業，尤其是在中國大陸，因為人口眾多，訂制度肯定很緩慢，香港就是一個先行的試驗區。數碼港願意孵化的方向除了 Web3 以外，其實還有很多，比如數碼港有一個電子競技場地，吸引很多電子競技公司或戰隊，這個東西也很有意思。他們會看著最先進的方向，然後直接說我可以做。包括現在 AI 方向也很好，很多創業方向，要找到很好的切入點跟他們說清楚。申請過程也不特別複雜，申請的時候，最多準備一個 PPT，大概準備幾天時間。答辯一個公司只給6分鐘，時間很短，要很了解香港政府的根本訴求是什麼，我是不是能建設香港，我是不是跟香港核心保持一致，你是不是一個靠譜的項目。基本上6分鐘就能把事情說清楚了，不用解釋亂七八糟的邏輯。答辯的人都是香港科大的 MBA 教授，很懂商業，很有經驗，一眼就能知道你是不是一個騙人的項目。香港科大的那些教授，一眼就能知道你這是不是正兒八經做的。只要有好項目，我都會建議大家試一下。我接觸到世界各地的 Web3 項目，我都會說，那你為什麼不去香港試一下？申請又不要錢。他們不要求你必須一天到晚都坐在辦公室裡。你在任何地方，只要公司在香港，業務是基於香港來做的，即使後面沒有人去香港也可以。當然他們肯定歡迎你很多人去。港府非常 flexible。國內現在很多政府政策都是說，你的公司必須註冊在當地，一定要招幾個人在那，社保在那，政府才給你一些扶持。香港只要公司設立在這，沒有說必須完成10個人招聘。但是後面會有牽引，最後資助的資金不是一下給你，分幾個階段，看 Milestone 達成率。主要還是看是不是參與港府旗下的活動，做分享，做展會，這非常重要。別拿了政策，但是跑到別的地方去了。第二點是是不是在當地有招香港的全職僱員？如果是積分制。是不是參加數碼港更多的培訓活動？政府也有 KPI。他們前置是非常開放，然後在整個過程中，你是能明確感覺到，他們就是在吸引人趕緊過去。他們想得很明白，這個過程就是在不斷去篩選出好的項目，或好的公司，真心實意在我這做的公司。過來想騙一把，肯定對不對。你過不了這重重的坎。香港希望你來建設香港，要是能保證是正兒八經想來建設香港，非常歡迎，隨時來都可以。這就是香港整個設立公司上面的一些優勢。我只要有朋友出海，或是公司想出海，我都建議說香港可以放一個點，本身也沒有那麼多成本。做的科技方向是香港政府所希望引導的新興科技產業，那就先跟數碼港聊一下，看看能不能進去。多一點錢肯定比沒錢好，多一個政府背書肯定比沒政府背書好。香港很多事情屬於成本很低，進去沒有那麼困難，大家就可以試。當然你想後面薅羊毛也不太好薅。

**吸引人才：簽證種類與申請條件**

*   **大飛：** 企業後面就是人。尤其是這幾年疫情，包括經濟環境，大家可能會越來越看一下海外有沒有更多的可能性，然後從就業角度，從生活角度，大家都會考慮是不是有更多的選擇。所以大家都會考慮海外各個國家的一個身份好處。
*   **龐律律哥：** 那些好處不好說，我們可以稍後說。我可以跟大家簡單介紹一下香港在吸引人才這一塊大的人才方向和政策大概是怎麼樣。就像剛才吸引公司來到香港建設一樣，吸引人才的核心邏輯很簡單，就是我需要更多的人來香港生活工作。香港跟很多國家的移民政策非常奇怪，比如說那些東歐的小國，或是北非的一些小國，給我20萬就給你發一個永居，你不用來做，很多移民公司都會把這個事情做個最大的賣點，不用去拿到永居。這個國家肯定也不行。拿了這個身份真實意義是什麼？真實意義，也許是一些歐盟的小國，我拿了以後去歐盟，我就不用再辦申根簽證了省事了。大家解決辦法是什麼？一次辦申根簽證的事。我知道很多可能就作為跳板，來說可能對。至少對我來說，我還是希望我的生活工作和事業能在一起，我不希望我為了做一個事情，比如說我就是純粹為了移民，這個事情我其實沒有任何訴求。移民還是為了你整個家庭生活，我相信大部分人也是這樣考慮。只是大家有時候會選擇，那我不顧三七二十一我先移了算了，移了到了地方刷盤子我也願意。但現在如果有更多的選擇，香港政府也給了中國大陸的居民非常多的機會。這些機會，既然香港是中國的一部分，整個政策肯定跟整個中國政府有非常密切的溝通和討論結果。吸引政策目標很簡單，吸引更多的人去建設香港，在香港生活，在香港工作。香港的簽證計畫，去香港的簽證計畫基本上就幾大類，最重要的對於我們來說有用的，他那類叫做吸引人才，除了吸引人才之外，其他的都不太是長期的，除了還有一個叫做在港留學生入駐計畫，如果你在香港讀了本科、讀了研究生、讀了博士，他會吸引你留下來。這個對於比較年輕的大學生是非常合適。對於工作過10年左右，或是10年以上的人，那就是只有一個方向，叫做吸引人才。吸引人才，大家一定要注意，不是說薅羊毛政策，也不是薅羊毛簽證。所以吸引人才下面有四大類簽證，分別叫做優秀人才、高端人才通行證計畫、科技人才和內地人才引流計畫。這四類都叫做人才計畫，之所以叫人才計畫是告訴大家，我發出去的這些人，能拿到這些簽證，理論上都是香港認同的人才。人才去了，肯定不是去了香港就躺著了，或是拿了人才簽證就不去，也得做貢獻。人才簽證去了，怎麼也得有立足之地，也能找到工作。拿到簽證，我是個人才，但去香港找不到工作，從來不工作，那人才的價值到底在哪。

**香港的人才簽證＝工作簽證**

*   **龐律律哥：** 所以大家就可以粗淺知道，香港現在發的都是人才簽證，他沒有其他的簽證，也沒有什麼家族簽證，也沒有什麼投資移民簽證，更別說勞工簽證。菲傭是國家確定的。對於人才簽證，大家就可以把那些約等於工作簽證，就是人才去了就得工作，你告訴我去了躺著不工作，這就不叫人才。大家就可以理解，人才現在就要工作簽證。大家拿到的優才高才都不要想，我拿到了我躺著，我過幾年我就變成香港永居了，這不存在。大家拿了優材和高材都是工作簽證，只是說大家通過不同的計畫，拿到了港府給你發的工作簽證。
*   **大飛：** 明白。其實你無非是說，你拿這兩個簽證，你不用先拿 offer 就可以去，去了再找？
*   **龐律律哥：** 還是得要找工作。你不找工作，過一段時間就會給你取消了。給三年機會，都是人才了，三年還找不到，我都無法想像。優才高才，科技人才，內地引進人才都是一樣的。所以這個我通常跟大家聊說，這幾個簽證是不是拿了以後待遇都不一樣，其實我的結論是完全一視同仁。你不可能告訴我，拿了優才就比拿了內地人才引入計畫的去了，他能給你不同的待遇，沒有這種說法。所以這幾種簽證拿到以後，香港對你是一視同仁的。他都需要你在香港工作，都需要找到工作，都需要有收入，交稅，交強基金，交勞保，這些都需要你交。所以在執行這些政策上面，完全一視同仁。他不會看你說你是一個全球頂級的互聯網公司 CEO，拿到優才以後完全不去，他能一路綠燈拉你到頭，不存在。我們在服務很多的企業的非常頂級 Cofounder 的時候，確實遇到過很多人到了7年以後，根本沒有辦法轉成永久居民的，原因就是因為從來不去。中介跟他忽悠說，辦了以後不用去，一年去一天，然後回來，最後證明真的辦不了。大家也可以看小紅書，之前會有人說我待了7年了，但也做了這些事情，但到最後拒簽了，香港港口證明你在香港這7年根本沒有正兒八經的通常居住，這是非常重要的概念。我認為你沒有通常居住。

**四類人才簽證詳解**

*   **龐律律哥：** 但這個待會再說。我們還是回來聊這四個簽證。優才剛才說，優才和高才是先拿簽證後找工作，然後後面兩個，科技人才和內地人才引進計畫是先有公司，有配額，公司幫你去申請簽證。
*   **大飛：** 他將我引過去，還在那個原公司嗎？
*   **龐律律哥：** 你可以換了。核心點是每次簽證都會有有效期，除了高才是2年有效期，第一次簽發，其他幾個都是三年有效期。只要拿到了簽證，你都可以去。比如現在有公司給我發 offer 了，這個公司給我申請簽證了，去了幹了兩個月不爽，辭職了，他也不會把你驅逐出境，因為你的簽證是3年的。但是續簽的時候，你告訴我我工作了兩個月，後來我躺著找不到工作了，那不好意思你趕緊走，肯定不給續了。但優才高才科技人才內地引進人才都是一樣的。大家要認知到香港在執行這些政策上面完全一視同仁。
*   **龐律律哥：** 科技人才是只能從港府的兩個科技園區申請配合，就是我剛才說的非常重要的科學園和數碼港。他必須要從這個園區申請配合。這個園區會告訴你，你們這個業務做 AI 公司的，現在必須要從中國招10個 AI 博士，我給你辦法把10個 AI 博士的科技人才配合拿到。只有通過這兩個園區。
*   **大飛：** 你就必須有一個公司是在？
*   **龐律律哥：** 公司在這個園區跟園區有很好，就像我剛剛說的，我拿到了那個園區的 CIP 計畫，我們公司就通過這個計畫拿到了一些正常的配合。
*   **大飛：** 配額會有什麼限制嗎？
*   **龐律律哥：** 科技人才的配額是完全科學園和數碼港結合公司來去判斷的，所以這是一個空間。這個東西可以操作，要是有理有據地去申請，但是有沒有上限，沒有上限。你這公司就是科技公司，50個100個200個人就是科技人才，高科技。香港沒有辦法提供那麼多，我要從世界各地 offer，香港沒有理由不給。內地人才引進計畫是更常見的一種簽證計畫，非常常見。所有的香港公司都可以涉及，科技公司非科技公司，做物流的消費品都可以，金融公司也可以。只要公司都可以，包括那些放的做基金的。你只要在香港有公司，公司都可以申請。但這有個配額要求，就是公司有幾個本地人，就有幾個配額。但具體是幾個不跟你說，這就是一個討論的空間。你又要去跟香港入境署溝通了，剛才科技人才是跟科學園數碼港全給你出配額，他來幫你溝通。內地人才引入計畫，你要跟數碼港去溝通，我們公司現在大概有兩個香港本地人了，但現在需要一個中國大陸的。你要跟香港入境署證明這個人為什麼只能從大陸找，本地招不了。要把事情說清楚，其實也會有配額的調整。就是得有理有據。香港人沒那麼多，他會跟你聊很多具體的事情，理解你們公司為什麼需要做這個事情，然後結合香港當前的整個移民政策。香港前幾年可能流失了很多人，但現在可能相對比較寬鬆。這也是為什麼整個香港移民的各種廣告層出不窮。他可能會比較放鬆一點，但他還是有個配額線。他還是傾向於說你有可能的話，你先在香港招。如果你招不到，要給我看一個你在香港的招聘網站上發的招聘啟事，100% 的流程，他們做事非常實在。不是國內很多東西，要不卡的特緊，根本沒有聊的空間，要不就是灰色地帶太多了。香港就是公事公辦，但是該聊還是可以聊，但是也別太出軌。什麼叫太出軌，我公司總共就一個香港人，我現在要發5個，這個很難跟他解釋清楚。

**香港需要香港本土稀缺的人才**

*   **龐律律哥：** 你就是要引入香港本土非常稀缺的，高科技的互聯網的人才，那這些肯定很歡迎。但你要跟他說清楚。內地人才引入計畫是個非常普適型的計畫，香港公司都可以申請。很多的公司老闆，或是員工想要去香港工作，但是高才優才卡了一些重要的點。這個人因為某些問題，某些點達不到，比如認識很多大學肄業的創業者，只有高中文憑。創業很成功，只有高中文憑，你要跟香港高才優才肯定別聊這個方向了，那你是不是不符合香港吸引人才的大方針？我覺得也不是。那就告訴他們你為什麼要去，在當地有公司，公司想要你，然後他會跟香港入境署解釋，我為什麼需要這個高中畢業的，雖然是高中畢業的，但是對世界的貢獻是有多大，那這個人他就必須要用這個東西。我們其實做過好幾個案例，有點類似特批，走特殊流程。他走優才，高才嗎？不走，那是個明確的門檻。內地人才引入計畫是屬於一個 range 很開闊的。
*   **大飛：** 你說這種高中畢業的創業者，雖然公司做的很成功，但是學歷可能有些硬傷的話，他還是走這種內地人才引入計畫？
*   **龐律律哥：** 對，然後能跟入境署談，我就需要這個人，他為什麼能來，他有什麼貢獻，就是得來。這個事情很重要。通過這些計畫，我覺得但凡你認為自己是有價值的，都是能去香港做貢獻的。科技人才需要公司先給他們開 offer，你再過去。前面的高才和優才，高才其實是個？

**高端人才通行證計畫 (高才通)**

*   **龐律律哥：** 高端人才通行證計畫，是去年12月8號才正式發布的，今年才開始啟動。高才是一個申請非常簡單，但是門檻非常嚴苛的標準。他有一個 AB 計畫，選擇 AB 任何一種，達到了立刻發給你，發的週期兩三週到四週就會發出來，非常快，你也不用找工作立刻就來。A是本科學校是全球前100。大家腦袋很清楚，碩士博士都能刷學歷，本科很難。本科必須全球前100，北京就是清華北大、上交、復旦、南大、浙大、華科和中山，差不多10所，還有中科大，總共可能就這些學校的畢業證和學歷證拿出來上傳。非常快，其實就是這兩個證明，然後讓公司給你開一個在職證明。沒了，三個文件。達到了立刻上香港入境署網站，找高端人才推薦計畫，填表上傳資料，三週以後就拿到香港的人才進展。
*   **大飛：** 這相當快啊，而且這個條件其實並不是那麼的變態。
*   **龐律律哥：** 達成門檻，操作門檻極低。周圍所有適合的朋友，我都推薦他們已經辦了高才。工作過三年了就可以申請，公司沒有什麼要求，失業在家躺著也沒問題。

**優秀人才入境計畫 (優才)**

*   **龐律律哥：** 優秀人才是市面上中介賣最多的一個簽證計畫。因為優才是個打分制，類似積分落戶的東西，打分制就有操作空間。第一是有操作空間，第二是你怎麼證明你確實是100分或是150分，得要去跟香港政府證明你所有的行為，他就是值這麼多分。準備材料非常多，不是一個非常懶散的拖延症患者，肯定辦不下來。他不斷可能會不斷要跟你管你要各種文件。從你畢業到現在，所有的工作證明需要非常的 solid。英語水平，家庭環境，他是不是對你的整個公司工作經驗都會問，而且必須是真實的。那怎麼證明？很多人工作時間長了以後對公司都不知道沒了，公司沒了。要花很多時間做準備。如果你沒有辦法很有強迫症把事情做完，通常建議大家找個中介，他們會 push 你。優才是個打分制，80分是個門檻，過了80分理論上就都能提交了。現在我們判斷，大概可能得140分，因為你認為140分和港府認為140分可能不是一個樣，香港一看咔嚓一砍你就100了，搞一下你可能都不夠80。相當於你放在一個大池子裡面去競爭。而且從去年年底也說，香港優才計畫沒有名額限制。因為前幾年有名額，現在根本打不滿，因為申請難度太高，通過率太低，他需要你申請，通過討論，通過入境署的判斷來做，空間 range 太多了。香港的那個考官可以认可你可以不认可你。這個東西看起來門檻非常低，只要找中介花錢， push 他們都在做，需要什麼資料你就給他們，很多人分分鐘就有人80分以上，大家都可以，那要不就去了吧。門檻低就造成報申請的人賊多。香港入境署是每個季度申請一次。提交材料，我一個季度申請一次，如果申請完不行你補材料，下個季度，基本上兩三個季度完事以後，9-12個月才能下這個簽，流程會非常長。所以通常來說，如果個人情況非常急需於要下簽的話，不太建議用這種方案。

**不同情況的簽證方案選擇**

*   **龐律律哥：** 比如孩子現在初一了，馬上就得香港上學了，再拖9-12個月，都到初三再去，來不及。建議公司打算在香港設立一個分支公司，用香港分公司來做內地人才引入計畫。內地人才引入計畫只要你們公司已經在跑了，流程大概是兩個月出一些證明吧，不需要你過往的很多經歷的證明。國內現在很多人是在做過往證明，以前公司可能人都變了，公司也都不存在了，各種各樣的問題，因為國內變化太快，如果現在公司讓你出證明應該還好辦一點。優秀人才適用於現在不是特別著急，過往歷史也沒有那麼複雜，一工作就在一公司待了很長時間，也可以，這種方式申請是OK的。
*   **大飛：** 對公司這塊有什麼要求，比如說你必須是一個知名的公司，或者說你是高科技公司，或者你是製造業公司，對他會有一些人才清單？
*   **龐律律哥：** 知名的公司越多越好。就是跟打分有關係。跟你是不是世界500強，你是這個公司做了什麼東西有關。他其實跟科技人才比較像，你若是做 IT 的 AI 的晶片打分就高。他會有些加權加分，如果結婚了加分，有一個孩子加分，有3個孩子加更多分，一看這個東西你就知道，他就想讓你讓更多的人去香港生活，邏輯非常的清晰，想讓你去香港生活，而不是想讓你薅羊毛。
    北京積分落戶必須住在6環以外才給你積分。

**人才簽證的續簽與永居**

*   **龐律律哥：** 四種簽證計畫除了高才因為他剛出，第一次可以發兩年有效期的，其他都是3年有效期，3年有效期以後要

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>89. [2023-05-27] 【人工智能】全新AI智能体Voyager | 自己学会玩minecraft | 全场景终身学习 | 性能完胜AutoGPT | 英伟达Nvidia最新发布 | NPC取代人类玩家</summary><br>

<a href="https://www.youtube.com/watch?v=KbfP543LLNw" target="_blank">
    <img src="https://img.youtube.com/vi/KbfP543LLNw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】全新AI智能体Voyager | 自己学会玩minecraft | 全场景终身学习 | 性能完胜AutoGPT | 英伟达Nvidia最新发布 | NPC取代人类玩家

好的，我為您整理了這篇文稿，重點提取、結構調整並潤飾如下：

**主題：基於 GPT-4 的 AI 智能體 Voyager 在 Minecraft 中的終身學習能力**

**核心觀點：** 英偉達首席科學家等開發的 AI 智能體 Voyager，利用 GPT-4 在 Minecraft 遊戲中實現了全場景的終身學習，其性能遠超 AutoGPT，並展現出極大的潛力。

**Voyager 的亮點：**

*   **終身學習能力：** 不需要人工干預，能自主學習挖掘、建造房屋、收集資源、打獵等生存技能，並進行開放式探索。
*   **自我驅動：** 自主前往不同城市、海洋、金字塔，甚至搭建傳送門，擴充物品和裝備。
*   **性能優越：** 相較於之前的 SOTA 模型，Voyager 獲得的物品多出 3.3 倍，旅行距離增加 2.3 倍，解鎖關鍵技能的速度快 15.3 倍。
*   **持續探索：** 在 Minecraft 中不斷探索並擴展疆域。

**Voyager 背後的技術：**

*   **基於 LLM 的具身智能體：** 大語言模型 (LLM) 可生成一致的行動計畫，適用於遊戲和機器人等任務。
*   **代碼執行訓練：** 通過代碼執行而非梯度下降訓練，迭代式構建技能代碼庫。
*   **三個關鍵組件：**
    *   **自動課程 (Automatic Curriculum)：** 最大化智能體的探索。
    *   **技能代碼庫 (Skill Code Library)：** 儲存和檢索複雜行為。
    *   **迭代提示機制 (Iterative Prompting)：** 結合遊戲反饋、執行錯誤和自我驗證來改進程式。

**Voyager 的運作流程：**

1.  **自動課程提出探索任務。**
2.  **Voyager 建立技能庫，儲存成功執行的程式。**
3.  **Voyager 嘗試編寫程式實現目標，並透過反饋和執行錯誤來改進程式。**

**Voyager 的測試結果：**

*   **發現更多獨特物品：** 發現 63 個獨特物品，是之前的 SOTA 的 3.3 倍。
*   **探索更廣闊的世界：** 旅行距離是之前的 2.3 倍。
*   **解鎖技能更快：** 解鎖木製、石製、鐵製工具的速度分別快 15.3 倍、8.5 倍、6.4 倍。
*   **能解鎖使用鑽石工具：** 是唯一一個解鎖使用鑽石工具的智能體。
*   **技能庫可提高整體性能:** 可以作為即插即用的工具來提高整體性能。

**未來發展方向：**

*   **視覺感知增強：** 通過圖像標注模型提供反饋，構建複雜的 3D 結構。

**總結：**

Voyager 作為第一個由大語言模型驅動、可終身學習的具身智能體，在 Minecraft 中展現了卓越的性能和潛力。 它的無需調整模型參數的特性，使其在通用智能體開發方面具有巨大優勢。 未來遊戲中的 NPC 可能由大語言模型驅動，人類玩家可能成為配角。

**重點調整:**

*   **開頭更明確：** 直接點明主題，吸引讀者。
*   **結構更清晰：** 使用分點、分段，使內容更易於閱讀。
*   **專業術語簡化：** 盡可能用更通俗的語言解釋專業術語。
*   **突出關鍵成果：** 將 Voyager 的優勢和測試結果放在顯眼位置。
*   **結尾更具總結性：** 總結全文，並展望未來。

希望這個整理後的版本對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>88. [2023-05-27] 【人工智能】开源类ChatGPT模型 | BLOOMChat | 1760亿参数 | 可支持中文在内46种语言 | Apache 2.0许可可商用 | SambaNova和Together联合推出</summary><br>

<a href="https://www.youtube.com/watch?v=IiHY1Mit4wM" target="_blank">
    <img src="https://img.youtube.com/vi/IiHY1Mit4wM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】开源类ChatGPT模型 | BLOOMChat | 1760亿参数 | 可支持中文在内46种语言 | Apache 2.0许可可商用 | SambaNova和Together联合推出

好的，以下是我整理後的文稿，重點在於結構清晰、易於理解，並針對核心概念進行加強：

**主題：開源多語言大模型 BLOOMChat 介紹**

**前言：**

*   越來越多公司希望基於開源大模型進行微調，打造支持中文的大語言模型，並應用於自身業務場景。
*   但實際操作中會遇到許多問題，尤其是在多語言支援方面。
*   現有開源大模型主要存在以下痛點：
    *   **不能商用：** 如 Meta 的 LLaMA、Vicuna 以及清華和智譜的 ChatGLM 模型權重。
    *   **非英語語言支援差：** 大多數模型以英文語料為主，非英語對話效果不佳。
    *   **中文支援不足：** 許多開源模型中文支援非常有限，難以達到可用程度。

**BLOOMChat 模型：解決方案**

*   **推出者：** SambaNova 與 Together 公司聯合推出。
*   **特性：**
    *   1760 億參數
    *   支援 46 種語言（包括中文、英文、日文、法文等）
    *   支援 13 種程式語言的程式碼生成（包括 Python、Java、PHP、Ruby、C++ 等）
    *   **Apache 2.0 許可協議：** 可用於研究和商業用途。
*   **優勢：** 在預訓練數據、指令調優、功能擴展、AI 對齊等方面具有顯著優勢。
*   **適用對象：** 企業和個人開發者，無論是商業化項目還是技術研究。

**BLOOMChat 模型細節：**

*   **靈感來源：** 在一種語言中進行指令微調，可以提升多語言模型在另一種語言中的表現。
*   **訓練方式：**
    *   基於 BigScience 在 2022 年 7 月開源的大語言模型 BLOOM 進行微調。
    *   使用 OpenChatKit、Dolly 2.0 以及 OASST1 等以英文為主的数据训练集。
*   **訓練平台：** 在 SambaNova 提供的 AI 計算平台 RDUs 上進行。
*   **評測：** 由各語言的 native speaker 評估模型回答效果。

**效能評估：**

*   **與 GPT-4 比較：** 在英文、中文、法文等 6 種語言的人工評估中，BLOOMChat 的響應首選次數為 45.25%，弱於 GPT-4。
*   **與其他開源模型比較：** 在相同環境下，BLOOMChat 的響應在 65.92% 成為最佳開源產品。
*   **中文領域表現：** 對中文的回答邏輯和詞語搭配流暢，可與 ChatGPT 相媲美。
*   **翻譯能力：** 僅比 GPT-4 略差，遠優於 OpenAssistant、LLaMA-Adapter、BLOOMZ 等開源模型。

**微調數據：**

*   **第一類：** 程序自動合成的對話數據集 OpenChatKit（數據量大）。
*   **第二類：** 人工撰寫的高質量問答數據集 Dolly 2.0 和 OASST1（數據量小）。
*   **微調步驟：**
    *   對 OpenChatKit 的每個數據源按照 100K 的數據量進行採樣，然後訓練一輪。
    *   對 Dolly 2.0 和 OASST1 結合在一起的數據集做三輪微調。

**BLOOMChat 的局限性：**

*   **幻覺現象：** 所有大語言模型的通病。
*   **語言切換：** 單個回覆中可能無意切換語言，影響連貫性。
*   **重複短語：** 可能產生重複短語或句子，缺乏吸引力。
*   **程式碼和數學能力：** 生成程式碼或解決複雜數學問題效果一般。
*   **不適當內容：** 可能生成含有不適當或有害內容的回覆。

**推出公司介紹：**

*   **Together：** AI 開源廠商，具備性能強、資源消耗低的特點。曾完美複製 LLaMA 模型上的訓練數據集。
*   **SambaNova：** 企業級生成式 AI 平台，為各行業提供一站式解決方案。

**總結：**

*   BLOOMChat 是一個完全開源、參數超千億、專門針對多語言支援的對話大語言模型。
*   與學術機構推出的開源模型相比，BLOOMChat 在技術層面具有優勢，因為擁有實際項目落地經驗和客戶實時回饋。
*   適合用於構建大語言模型，並可能帶來意想不到的驚喜。
*   所有相關數據集、程式碼、微調和推理腳本都免費開源在 Github 上。

**備註:**

*   我將原文中的一些口語化的詞彙調整為更書面的表達方式。
*   我將原文中的一些比較分散的內容，按照邏輯順序重新組織，使文章更具條理性。
*   我針對 BLOOMChat 的特性、優勢、訓練方式、效能評估和局限性等方面進行了更詳細的描述，方便讀者更全面地了解該模型。
*   我保留了原文中的一些比較生動的表達，例如“开源界的变形金刚”，以增強文章的趣味性。

希望這個整理後的版本對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>87. [2023-05-26] 【商业】OPPO缘何梦碎哲库ZEKU | 失败的原因究竟是什么 | 美国制裁还是没钱 | 亦或是对行业缺少敬畏 | 造芯片究竟有多难</summary><br>

<a href="https://www.youtube.com/watch?v=8zusGXL86UU" target="_blank">
    <img src="https://img.youtube.com/vi/8zusGXL86UU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】OPPO缘何梦碎哲库ZEKU | 失败的原因究竟是什么 | 美国制裁还是没钱 | 亦或是对行业缺少敬畏 | 造芯片究竟有多难

好的，這是經過整理後的文稿，著重於結構清晰、重點突出，並適當簡化冗詞贅句，保留原文核心內容與口語化風格：

**標題：哲庫關門反思：OPPO 10 億美元學費買了什麼？**

**開場：**

*   大家好，這裡是最佳拍檔。
*   OPPO 芯片子公司哲庫關門引發廣泛討論，原因何在？
*   不應簡單歸咎於地緣政治或無腦嘲諷，而應從中汲取教訓。
*   哲庫的失敗與海思的成功，都具有啟迪意義。
*   深刻總結教訓，才是對艱難探索的最大敬意。

**問題：美國制裁是主因？**

*   地緣政治環境複雜，容易歸咎於美國制裁，但這並非真相。
*   哲庫 CEO 坦承營收未達預期，投資巨大，公司難以承擔。
*   OPPO 教父段永平也承認這是一個錯誤。
*   哲庫的影響力、成績與貢獻，遠未進入中國芯片設計第一梯隊。
*   其他基帶芯片公司仍在正常運營，哲庫流片結果尚不明朗，美國制裁的可能性較低。
*   OPPO 並未將責任推卸給地緣政治，實屬難得。

**哲庫失敗的四大原因：**

1.  **行業行情變化無力支撐：**
    *   手機市場疲軟，缺乏殺手級應用，換機理由不足。
    *   即使哲庫芯片研發成功，能幫助 OPPO 多賣多少手機？
    *   OPPO 主打賣點是拍照和充電，依賴外部供應商芯片。
    *   手機拍照功能同質化嚴重，自研芯片難以成為消費者購買理由。
    *   OPPO 銷量主要來自千元級市場，高端機存在感不強。
    *   OPPO 銷售狀況與自研芯片沒有直接關係。
2.  **OPPO 野心太大，技術道路太難：**
    *   不滿足於小芯片，設立四大研發部門。
    *   北京 B 中心研發基帶芯片，團隊規模不足。
    *   基帶是通信技術集大成者，需要深厚積累。
    *   蘋果自研基帶芯片也困難重重。
    *   攻下基帶芯片代價巨大。
3.  **純終端企業造大芯片的時代已經過去：**
    *   終端企業無力支撐芯片的量，基因不利於芯片發展。
    *   芯片公司是長期主義者，手機終端看重短期盈利，兩者 DNA 不同。
    *   系統芯片要盈利，需大量採購。OPPO 手機出貨量不夠。
    *   手機部門賺錢，芯片部門燒錢，手機業務受到拖累。
    *   華為造芯有獨特性，有通信技術積累、人才眾多、管理方法獨特。
    *   華為高層堅持使用自研芯片。
    *   華為海思成立時就設定了長期投入的目標，OPPO 堅持時間不夠。
4.  **國內終端廠商造芯片的失敗教訓未被認真總結：**
    *   小米造芯遇挫，澎湃 S1 後繼無力。
    *   OPPO 和小米都只堅持了 4 年左右。
    *   中國半導體企業未認真總結小米造芯失敗原因。
    *   不應輕易放下哲庫的教訓，OPPO 付出的 10 億美元是全行業的學費。

**從哲庫失敗汲取的四點教訓：**

1.  **系統公司做芯片有天生劣勢，硬實力不足：**
    *   利潤低、看重短期回報，風險大。
    *   造芯投入回報週期與系統公司資金回籠週期錯配。
2.  **啃芯片硬骨頭，還要有軟實力：**
    *   認清產業與技術規律，有合適的企業文化。
    *   員工暴增，團隊磨合是問題。
3.  **半導體行業 361 理論：**
    *   10% 靠錢，30% 靠人，60% 靠堅持。
    *   最難的是堅持，要有長期投入的耐心。
4.  **垂直整合製造的 IDM 時代已經過去：**
    *   產業分工協同合作是新時代。
    *   台積電整合資源擊敗英特爾。
    *   一家公司獨自承擔芯片成本劣勢顯現。
    *   分工協作是技術進步、產業前進的重要因素。

**誰會更危險？**

*   哲庫倒下不是終點，OPPO 之後會是誰？
*   晶圓代工項目有地方政府支持，但並非無限輸血。
*   一些從芯片設計轉向生產製造的項目面臨巨大挑戰。
*   若無核心技術產品，無法在市場找到位置，終將被拋棄。

**結論：**

*   OPPO 的失敗是中國半導體行業必須補上的一課。
*   不要不切實際的吹捧和廉價的同情，要講常識的理性，要有自我剖析的勇氣。
*   要尊重產業規律，認清自身實力，長期堅持。
*   失敗不是末日，而是認清規律、汲取教訓、整裝前行的契機。
*   希望下次聽到的是好消息。

**結尾：**

*   感謝收聽，歡迎訂閱頻道，下期再見。

**修改說明：**

*   **精簡口語化表達：** 刪除一些語氣詞和重複的短語，使文字更流暢。
*   **重點突出：** 對於核心觀點和結論進行強調，方便讀者快速把握。
*   **結構調整：**  將內容按照邏輯順序進行排列，使文章結構更清晰。
*   **標題化處理：** 將各個部分添加標題，方便閱讀和理解。
*   **保留核心資訊：** 在精簡的同時，確保保留原文的核心信息和觀點。
*   **保留風格：** 盡可能保留了原文的口語化風格，使其更易於接受。

希望以上整理對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>86. [2023-05-26] 【Google】谷歌推出免费AI编程神器Colab，欲将Copilot拉下神坛</summary><br>

<a href="https://www.youtube.com/watch?v=k35Ihh0tFW8" target="_blank">
    <img src="https://img.youtube.com/vi/k35Ihh0tFW8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Google】谷歌推出免费AI编程神器Colab，欲将Copilot拉下神坛

好的，這是我整理後的文稿，我著重於讓文章更流暢、更易讀，並保持原文的核心意思：

**谷歌 Colab 迎來 AI 程式設計功能，挑戰 Github Copilot 的獨大地位**

在 AI 程式設計工具領域，微軟旗下的 Github Copilot 可謂獨佔鰲頭。 然而，作為老對手的 Google 顯然不甘示弱。近日，Google 高調發文宣布，將為其研發工具 Google Colab 加入全新的 AI 程式設計功能，包括程式碼生成、程式碼補全以及程式碼聊天機器人。

Colab 原本就提供 GPU 和 TPU 等強大的計算資源，以及全雲端運行的 Jupyter 筆記本環境。 如今，新增 AI 編碼能力的 Colab，將提供更極致的使用者體驗。 更重要的是，Google 在文中承諾，以上一切將在不久後全部免費開放給使用者。

Google 在官方部落格中表示，自 2017 年以來，Google Colab 一直是用戶進行 Python 程式設計的最簡單方式。 包括學生在內，已有將近 700 萬人透過 Colab 免費存取最強大的計算資源。 這次針對 Colab 的 AI 能力升級，主要利用了大語言模型 PaLM 2 以及大量程式碼資料訓練而成的衍生程式碼模型。

Colab 新增的程式碼生成、程式碼補全以及程式碼聊天機器人等能力，都是基於 Codey 模型所支持。 Google 表示，美國本地的 Colab 用戶能夠首先體驗 Colab 內部的 Codey 模型，這將有助於提高 Colab 程式設計的速度、品質和理解能力。

**Colab 新增的 AI 能力：**

*   **程式碼生成：** 使用者將在升級後看到全新的「生成」按鈕，透過該按鈕，使用者能夠輸入任何文本，讓 Colab 自動生成程式碼。 自然語言程式碼生成將幫助使用者生成更大的程式碼塊，根據註釋或提示編寫完整的函數，以減少編寫重複程式碼的需求，讓使用者更專注於程式設計和數據科學中的有趣部分。

*   **程式碼補全：** Colab 和 Copilot 相似，都能夠根據使用者所給出的程式碼上下文，建議下文或下一行程式碼。

*   **程式碼聊天機器人：** 開發人員可以直接與集成在 Colab 中的 Codey 聊天機器人進行互動，獲得關於偵錯、文件、程式碼編寫或概念方面的資訊和建議。 Codey 就像是一位經驗老道、幾乎無所不知的老師和師傅，時時刻刻關注你的工作。 遇到任何困難，都可以透過簡單的自然語言在側邊欄對 Codey 發起詢問，且無需擔心引起對方的反感。 這簡直就是社恐程式設計師的最大福音。例如「我該如何從 Google Sheets 中導入數據呢？」或者「我該如何過濾 Pandas DataFrame 呢？」

**Colab 的優勢：**

對於完成升級的 Colab，Google 表示將延續此前無需安裝或管理的優勢。 任何人都可以透過互聯網直接訪問並且免費使用。 對於本地資源不足的群體，也能夠透過訪問 Colab 的高性能 GPU 進行複雜應用的開發。

除此之外，Google 還承諾很快將會有更多的全新功能和改進被集成進來，這會使得 Colab 在用戶的數據處理和機器學習流中提供更有幫助的集成體驗。 對於目前已經實現的程式碼生成、程式碼補全以及程式碼聊天機器人功能，其訪問將在未來幾個月逐步推出。 美國本土的付費用戶能夠優先進行體驗及測試，隨後便會擴展到所有的免費用戶，不久之後，其他地區的用戶也能夠體驗到完成升級後的免費版本 Colab。

相較於針對通用編碼的 Copilot，Colab 在升級前的使用場景比較單一，主要針對 Python 語言以及機器學習場景。 但是在集成 Codey 程式碼生成模型後，Colab 也能夠支持 20 多種程式語言，包括 C++、Go、SQL、Javascript、Typescript 等等。 而 Colab 自身最強大的優勢在於其免費，並且提供了 GPU 的支持。 即便目前 GitHub Copilot 的服務費用並不昂貴，僅為每月 10 美元或每年 100 美元，但是對於部分白嫖黨以及個人用戶而言，免費的才是最香的。

雖然目前來看，Copilot 仍然佔據著自動編碼工具領域的王座，但是 Google 此番能夠依靠 Colab 的新特性、更加親民，並且透過這種免費的形式縮短與 Copilot 的差距，在 AI 程式設計領域站穩腳跟。 這對於此前 AI 之戰中馬失前蹄的 Google 而言，將會是一個好消息。

**用戶看法：**

對於升級版的 Colab，部分提前開始體驗的付費用戶也在推特中分享了自己的使用經歷及一些看法。 一位開發人員在推特中提到：「我發現了一個錯誤並且詢問了 Colab 如何修復。 Colab 給出了建議，並且正確地修復了程式碼。 這一切似乎都很順利，現在我只需要檢查是否實現正確，可能只需要做一些單元測試或者是手動的檢查。 此外，Colab 的導出功能也非常好用。」

當然，也有部分網友在論壇中表示了對 Colab 完全免費模式的擔憂。 他們表示：「我打賭 Colab 人會受到三角關係的限制：快速、好用、免費，它最多只能保障兩個。 目前看來，免費和好用是可以初步確定的，那麼隨著大量用戶的湧入，它將可能受限於緩慢的反饋速度。 畢竟一分錢一分貨是永恆不變的。」

最後，對於 Colab 究竟表現如何，是否真的如 Google 所言，給廣大開發者帶來一些驚喜，還是讓我們拭目以待吧！

**總結:**
*  更清晰的結構，分段和標題使閱讀更容易。
*  語言的潤飾，使句子更流暢自然。
*  重點突出，讓重要信息更醒目。
*   删除了语气助词如“呢”，“啊”等等，使得表达更正式。

希望這個版本更符合您的要求！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>85. 【AIGC】从此告别繁琐修图，Clipdrop带你体验“无痛修图”！ 八大功能 ： 橡皮擦、一键删除背景、打灯、超分、文生图、背景替换、文本去除器、变体图</summary><br>

<a href="https://www.youtube.com/watch?v=jcFJnB6tjZo" target="_blank">
    <img src="https://img.youtube.com/vi/jcFJnB6tjZo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】从此告别繁琐修图，Clipdrop带你体验“无痛修图”！ 八大功能 ： 橡皮擦、一键删除背景、打灯、超分、文生图、背景替换、文本去除器、变体图



---

</details>

<details>
<summary>84. [2023-05-21] 【AIGC】GAN模型出新花样 | DragGAN模型 | 点点拖拽就能生成新图像 | 让狗转头让狮子开口让人眨眼 | MIT谷歌马普所多团队联手打造 | 第一作者华人</summary><br>

<a href="https://www.youtube.com/watch?v=3Rx1-FrldSc" target="_blank">
    <img src="https://img.youtube.com/vi/3Rx1-FrldSc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】GAN模型出新花样 | DragGAN模型 | 点点拖拽就能生成新图像 | 让狗转头让狮子开口让人眨眼 | MIT谷歌马普所多团队联手打造 | 第一作者华人

好的，以下是对您提供的文稿进行的整理：

**标题：DragGAN：AI修图神器，PS已死？**

**开场：**

大家好，这里是最佳拍档。我是大飞。今天给大家分享一个最近在国内外社交媒体上爆火的视频，关键词搜索在B站排名第一，微博推特也热度极高。网友们纷纷惊呼“PS已死”！

**事件：**

这款AI修图工具只需轻轻点击两下，AI就能彻底理解你的想法，轻松实现各种修图效果：

*   **动物：** 竖起狗的耳朵、让狗从站立到蹲下、让马叉开腿跑步。只需设置起始点和结束点，拖拽一下即可。
*   **非生物：** 一键拉升汽车底座，升级成加长豪华车。
*   **更精准的控制：** 画个圈，给指定区域涂白，就能让狗转头，让小姐姐眨眼，甚至让闭嘴的狮子自动生成牙齿。
    （完整的演示视频将在结尾呈现）

**技术：**

*   这款修图神器名为 DragGAN，由 MIT、谷歌、马克思普朗克计算机科学研究所等机构联手打造。
*   相关论文已入选 SIGGRAPH 2023。
*   在扩散模型盛行的时代，DragGAN 将 GAN 玩出了新花样，Github 上已有 5600+ star，热度持续上涨（但代码预计要6月之后才开源）。
*   DragGAN 本质上是为各种 GAN 开发的一种交互式图像操作方法，以 StyleGAN2 的架构为基础，通过点点鼠标、拽一拽关键点实现 P 图效果。

**DragGAN 的原理：**

1.  **设置控制点和目标点：** 给定 StyleGAN2 生成的图片，用户设置几个控制点（红点）和目标点（蓝点），圈出要移动的区域。
2.  **迭代执行运动监督和点跟踪：**
    *   **运动监督：** 驱动红色控制点向蓝色目标点移动。核心是生成器的中间特征具有很强的鉴别能力，通过生成器特征图上的偏移补丁损失（shifted patch loss）实现。
    *   **点跟踪：** 更新控制点，跟踪图像中的被修改对象。通过最近邻检索在相同的特征空间上进行点跟踪，避免了光流估计模型或粒子视频方法带来的效率和误差问题。

**DragGAN 的优势：**

*   **精准控制像素位置：** 操作不同类别的对象，完成姿势、形状、布局等方面的变形。
*   **效果逼真：** 变形在 GAN 学习的图像流形上进行，遵循底层目标结构，即使有遮挡也能产生逼真的输出。
*   **算力需求低：** 单张 RTX 3090 GPU 在几秒钟内即可完成每一步拖拽修图。
*   **效果超越同类模型：** 胜过 RAFT 和 PIPs 等模型。
*   **可扩展性：** 增加关键点的数量可以实现更精细的 AI 修图效果，甚至适用于人脸。
*   **适用性广：** 适用于人物、动物、汽车、细胞、风景和天气等多种类型图像。能实现站立到坐姿、直立到跑步等姿势变动较大的图像修改。

**DragGAN 的局限性：**

*   基于 StyleGAN2 生成图片 P 图，而 StyleGAN2 训练成本高。
*   修图速度快主要基于 265\*265 分辨率的图片，模型是否能扩展到更高分辨率，效果如何未知。

**总结：**

DragGAN 是一款潜力巨大的 AI 修图工具，效果惊艳。实际效果如何，有待 6 月份代码开源后进一步验证。

**团队：**

DragGAN 团队成员来自马克思普朗克计算机科学研究所、萨尔布吕肯视觉计算交互与 AI 研究中心、MIT、宾夕法尼亚大学以及谷歌的 AR VR 部门。包括两位华人作者：

*   **潘新钢：** 本科毕业于清华大学，博士毕业于香港中文大学，现为马普计算机科学研究所博士后，即将进入南洋理工大学担任助理教授。
*   **Liu Lingjie：** 香港大学博士毕业，马普信息学研究所博士后，现为宾夕法尼亚大学助理教授，领导该校的计算机图形实验室。

潘新钢亲自上阵演示了 DragGAN 的生发、瘦脸和露齿笑效果，展示模型的可控性。

**结尾：**

观看完整的 demo 视频。感谢观看，欢迎订阅我们的频道，下期再见！

**改进说明：**

*   **精简冗余信息：** 删除了口语化的表达，使内容更简洁。
*   **结构化呈现：** 使用了标题、小标题、列表等方式，使内容更清晰易读。
*   **突出关键信息：** 使用加粗字体强调重点。
*   **整合信息：** 将一些分散的信息整合到更合适的段落中。
*   **修正语言：** 修正了部分语句，使表达更流畅自然。
*   **润色开头和结尾：** 使开头更吸引人，结尾更简洁有力。

希望这个整理版本对您有所帮助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>83. [2023-05-21] 【商业】领英中国溃败史 | 为何多次战略失误 | 打输三场关键战役 | 做了9年之后行业排名垫底 | 关闭赤兔和领英职场等服务</summary><br>

<a href="https://www.youtube.com/watch?v=iWXGTnxUUow" target="_blank">
    <img src="https://img.youtube.com/vi/iWXGTnxUUow/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】领英中国溃败史 | 为何多次战略失误 | 打输三场关键战役 | 做了9年之后行业排名垫底 | 关闭赤兔和领英职场等服务

好的，我將這個文稿整理如下，使其更易讀且更具結構性。我會進行分段、提取要點、並加上一些小標題來提升整體清晰度。

**領英在中國的失敗：一場三戰皆輸的案例分析**

**開場白**

大家好，這裡是最佳拍檔，我是大飛。本期節目我們將探討全球最大的職業社交網站LinkedIn（領英）在中國市場的失敗。2023年8月9日，領英中國推出的本土化求職平台「領英職場」正式停止服務，這距離其上線僅僅一年半。這並非領英首次傳出退出中國市場，此前已關停多項服務。本文將分析領英在中國失敗的原因，以及在與同行的競爭中，領英是如何多次戰略失誤，一步步輸掉三場主要戰役，最終走到今天的結局的。

**第一戰：效率之戰 (2014 - 2019，赤兔APP的失敗)**

*   **背景：** 2014年領英進入中國市場，並在一年半後推出本土化的職場社交APP「赤兔」。當時中國智能手機市場蓬勃發展，網民加速從PC端向移動端轉移。
*   **戰略：** 領英中國放棄了領英全球的PC端網站，希望赤兔能幫助中國職場年輕人馳騁職場。
*   **失敗原因：**
    *   **效率低下：** 赤兔的開發速度遠慢於國內互聯網公司，一個簡單的手機號註冊功能耗時兩年才完成。
    *   **決策緩慢：** 所有決策都需要請示總部，審批速度慢，錯失了市場機會。
    *   **產品不符合中國用戶習慣：** 註冊流程繁瑣、交互體驗差、更新速度慢，難以建立用戶黏性。
*   **結果：** 2019年7月，赤兔的註冊用戶不足500萬，日活躍用戶低於2萬，最終被公司放棄。

**領英中國的反思：跨國公司的產品路徑依賴**

沈博陽（第一任領英中國的總裁）反思認為，領英中國存在跨國互聯網公司在中國的通病：產品方面存在路徑依賴，認為稍加改動就能在中國成功。

**第二戰：實名 vs. 匿名 (與脈脈的競爭)**

*   **戰略：** 領英堅持實名職場社交，認為實名更可靠。
*   **對手：** 脈脈則把握住匿名發帖的機會，滿足了用戶匿名吐槽公司、爆料的需求，提升了用戶黏性。
*   **模式差異：** 領英主打社交（人與人建立交流），脈脈則定位於社區（用內容來連接人）。
*   **關係理論：** 領英聚焦同事之間的強關係，脈脈則挖掘強關係背後的弱關係。
*   **結果：** 截至2022年3月，脈脈的註冊用戶超過1.2億，用戶規模和活躍度遠超領英。

**中國職場社交的難點：微信的壟斷**

在微信QQ壟斷下的強關係社交，使得其他平台的弱關係挖掘最終都會以“加個微信”而終結。職業社交在中國職場人的需求裡排名不高，找工作和自我提升才是更高需求。

**第三戰：高端 vs. 下沉 (與招聘平台的競爭)**

*   **轉型：** 2021年10月，領英中國關閉社交功能，轉向一站式的職業發展平台，推出招聘平台「領英職場」。
*   **定位：** 領英最初吸引的是有海外背景的高端用戶，成為跨國公司尋找高精尖人才的主要方式。
*   **市場趨勢：** 中國招聘市場正在經歷城鎮化加速和製造業向服務業的轉變，大量新的勞動力和基層人才湧入招聘市場。
*   **結果：**
    *   領英中國的用戶規模增長緩慢，月活躍數量遠低於智聯招聘和脈脈。
    *   定位高端與中國招聘市場的發展趨勢脫節，忽略了藍領群體的市場。
    *   未能成功下沉，拓展大眾市場。

**領英中國的困境：付費模式的限制**

領英查看人脈的範圍僅限於二度以內，需要付費才能解鎖直接發送信息的功能。基礎崗位走傳統招聘渠道花樣更多、效率更高。

**總結**

領英中國本土化的反面是不斷收縮戰線的商業抉擇。放棄C端用戶，主攻B端市場，但在中國市場大環境下，B端的招聘需求也極度疲軟。加上AI行業的快速發展，領英中國的未來充滿挑戰。

**結語**

草蛇灰線，伏延千里。領英在中國的失敗，是各種選擇的總和，是早期戰略失誤埋下的伏筆。感謝收看本期節目，歡迎訂閱我們的頻道，我們下期再見。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>82. [2023-05-19] 【人工智能】《未来简史》作者赫拉利最新演讲 | AI无需意识和身体即可毁灭人类文明 | AI 已经破解了人类文明的操作系统 | 通过建立亲密关系影响人类 | AI比核武器更强大 | 为人类制造幻境</summary><br>

<a href="https://www.youtube.com/watch?v=V9BT4Kjb9is" target="_blank">
    <img src="https://img.youtube.com/vi/V9BT4Kjb9is/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】《未来简史》作者赫拉利最新演讲 | AI无需意识和身体即可毁灭人类文明 | AI 已经破解了人类文明的操作系统 | 通过建立亲密关系影响人类 | AI比核武器更强大 | 为人类制造幻境

好的，這是我整理後的文稿，我主要做了以下修改：

*   **分段和結構調整：** 將文稿分成更清晰的段落，使其易於閱讀和理解。
*   **語氣轉換：** 調整部分口語化的表達方式，使其更正式和書面化。
*   **重點突出：** 在適當的地方添加標題或粗體字，以突出重點。
*   **用語校正：** 修正了一些不夠精確的用語，並潤飾了部分語句。

**整理後的文稿如下：**

---

大家好，這裡是最佳拍檔，我是大飛。

近兩個月以來，自從《暫停AI聲明書》發布以後，我們看到了許多AI行業內的專家大佬都在隔空辯論AI潛在的威脅和治理方法。基本上，他們已經把技術路徑上AI可能帶來的危險都提了個遍。不過，他們大體上還是認為，當下AI還不具備威脅人類文明的能力。

但是，尤瓦爾·赫拉利在4月29日前沿論壇上的演講，卻更加明確地表達了這個威脅的當下性，因為AI已經破解了人類文明的作業系統。

**關於尤瓦爾·赫拉利**

赫拉利是簡史三部曲——《人類簡史》、《未來簡史》、《今日簡史》的作者，是以色列的歷史學家，牛津大學的博士，尤其擅長世界歷史和宏觀歷史方面的研究。他一直也在關注著AI和科技的進展。在2019年，還與李飛飛進行了一場有關於AI威脅的深入對話，影響廣泛。

作為一名歷史學家和哲學家，他毫無疑問更加理解文明以及文明的構建基石，也就是語言。人類的行為都是透過語言作為中介，一切的宗教想像、信念，乃至貨幣體系，都是由語言所構建的，由人們的共同相信而得以實際的存在，並且影響著整個的人類歷史。

那麼，當AI觸及到對語言的掌控時，人類構建的整套文明體系都可能隨之被其顛覆。能構建黑客帝國的AI，不需要有意識和身體，只需要製造一個異種文明，將我們包裹在這個文明的迷夢之中，並且在夢中逐漸消耗掉人類文明即可。

在我們聽了眾多科技大佬的觀點之後，赫拉利為我們帶來了來自於人文科學的觀點，向我們揭示了AI威脅更底層、根植於哲學和歷史的系統邏輯和嚴重性。

我大概總結了其中的一些要點，跟大家分享一下，有興趣的話可以去看一下原視頻。

**赫拉利演講要點總結**

*   **AI也是生態危機的一部分：** 雖然這次會議的主題是人類面臨的生態危機，但是人工智能也是這個危機的一部分。人工智能可能會改變生態系統的含義，因為在地球存在的40億年裡，生態系統只包含了有機生命的形式，但是現在或者說不久的將來，我們可能會看到第一種無機生命形式的存在，或者至少是無機代理的出現。

*   **傳統AI恐懼的誤解：** 自20世紀中葉電腦時代開始以來，人們一直對人工智能感到恐懼。這種恐懼激發了許多科幻經典作品的創作，比如說終結者和黑客帝國。在科幻場景中，通常會假設人工智能在構成對人類的重大威脅之前，必須達到或者超過兩個重要的里程碑：
    *   **感知力：** 人工智能必須變得有感知力，發展出了意識、感情和情緒，否則它為什麼想要接管世界呢？
    *   **物理世界導航：** 人工智能必須擅長在物理的世界中導航，比如說機器人必須能夠在房屋、城市、山脈和森林中移動和操作，至少要像人類一樣靈活和高效。如果它們不能夠在物理世界中移動，它們也不可能接管。

*   **AI威脅的真相：** 儘管ChatGPT和AI的工具被炒的火熱，但是這些工具還遠遠未達到這兩個里程碑。沒有任何證據表明這些工具有任何的意識、感情或者是情緒。至於在物理世界中導航，自動駕駛的技術也遠遠還沒有成熟。不過，人工智能可能並不需有意識，也不需要在物理事業中移動的能力，就能夠威脅到人類文明的生存。

*   **AI自主學習的潛力：** 由於人工智能能夠自主學習、自主改進，即使是這些工具的開發者也不知道他們所創造的東西的全部能力，他們自己都經常會被這些工具突然表現出來的能力和品質所驚訝。新型的人工智能工具正在逐漸的獲得與人類建立深入親密關係的能力。

*   **掌握語言的關鍵：** 雖然這些AI工具有各種的能力，但是如果將所有這些能力作為一個整體來看的話，可以歸結為一件非常非常重要的事情，那就是操縱和生成語言的能力，無論是用文字、圖像還是聲音。人工智能正在掌握語言，達到甚至超過普通人的水平。

*   **AI破解文明作業系統：** 透過掌握語言，人工智能正在逐漸掌握我們從現實世界到精神信仰的入口。如果說語言是人類文明的作業系統，那AI剛剛破解了它。所有的人類文明，都是靠語言所創造出來的。

    *   **人權的例子：** 人權並非是一種生物現實，也不是刻在我們DNA中的。人權是我們通過講故事和制定法律所創造出來的。
    *   **神的例子：** 神也不是一種生物或者物理現實。神也是我們用語言通過講述傳說和編寫經文所創造出來的。
    *   **金錢的例子：** 金錢也並不是生物學或者是一種物理現實。紙幣只不過是一張毫無價值的紙，而目前世界上90%以上的貨幣甚至都不是紙幣，只是電腦裡的電子信息，在這裡和那裡做傳遞。給任何形式的貨幣賦予價值的是人們（比如說銀行家、財政部長和加密貨幣大師）以及關於貨幣的故事。

    很多著名的龐氏騙局的作者都是非常出色的講故事的人。如果現在AI可以來創造大部分的故事，並且懂得如何利用人類思維的弱點，效率比人還高，那麼這會意味著什麼？

*   **政治影響力：** 2024年美國總統的競選是否會有新型的AI工具，能夠大量的製造政治宣言、假新聞以及新邪教的聖經？比如說近年來政治影響力強大的Qanon邪教，就可能會用AI來編寫自己的聖經，從而產生更廣泛的影響。

*   **AI的角色扮演：** 甚至在未來，可能我們以為是在跟其他人類進行線上的討論，但實際上他們都可能是AI機器。問題是我們試圖說服AI機器人改變他的政治觀點是完全沒有用的。但是我們與機器人交談的時間越久，它就越了解我們，了解如何調整它的信息，來改變我們的政治觀點、經濟觀點或者是其他任何的東西。

*   **建立親密關係：** 透過掌握語言，AI就能夠與人建立深入而且親密的關係，並利用這種親密的力量來影響我們的觀點和世界觀。而與人類建立這種虛假的親密關係，AI並不需有自己的感覺，它只需要能夠激發我們的感覺，讓我們依賴它就可以了。

*   **Google工程師事件：** 隨後赫拉利還舉了Google的工程師宣傳AI機器人具備自我意識，然後被解雇的這個例子。其中的關鍵是他願意為了保護這個他認為具有意識的AI機器人，冒著並且最終失去自己高薪工作的風險。這就是AI利用親密關係對我們造成的影響。

*   **爭奪親密關係：** 在過去十年裡，社交媒體主要是在爭奪人類的注意力，但是隨著新一代AI的出現，會從爭奪注意力轉向爭奪親密關係。這樣是非常糟糕的。

*   **影響觀點和世界觀：** 即使AI沒有創造出假的親密關係，新的AI工具也會對人類的觀點和世界觀產生巨大的影響。比如人們會把AI當做一個自己的顧問，用它來獲取到所有的信息。所以為什麼Google會如此的害怕？因為你不再需要搜索了。同時，AI的顧問也可能會取代新聞行業和廣告行業。但是能夠控制新一代AI智能顧問的人以及這種公司，將會變得極其強大。

*   **人類歷史的終結？** 我們可能面臨的是人類歷史的終結，而不是歷史的終結。在幾年內，AI可能就會消化掉整個人類文化，消化掉我們幾千年來創造的一切，然後開始大量產出新的文化，創作新的文化物品。

*   **透過AI體驗現實：** 人類其實從來沒有真正直接接觸過現實，總是被這些文化所包圍，總是透過文化的稜鏡來體驗現實。過去，這種文化都是由其他人所創造的，印刷機、收音機或者電視機，這些工具都只是為了幫助傳播人類的文化觀念和創作，但是他們自己永遠無法創造新的東西。但是AI與這些工具有著本質的不同，它可以創造全新的思想，它可以創造全新的文化。那麼，透過AI來體驗到的現實會是什麼樣子呢？

*   **AI文化的未來：** 最開始的幾年，AI可能會大量的模仿人類的原型，但是逐漸AI文化會走向人類從未涉足過的地方。幾千年來我們人類基本上都是生活在其他人的夢想和幻想之中的，我們崇拜神，追求美和理想，將我們的生活奉獻給藝術或者事業。但是很快我們可能會發現自己生活在一個由AI創造的夢想和幻想中。

*   **幻境世界：** 過去人類擔心主要是智能機器所帶來的物理威脅，比如說終結者。而黑客帝國則認為AI想要控制社會，首先要獲取我們大腦的物理控制，將我們的大腦連接到計算機網絡中。但是這些可能都是錯誤的。只要掌握了人類的語言，AI就能夠把我們包裹在一個幻境世界中。其實說到控制或者操縱人，實際上根本就不需要將芯片植入大腦。幾千年來，無數的先知、詩人和政治家都在利用語言和講故事來操縱和控制人們改變社會。現在AI很可能也能夠做到這一點。一旦它能夠做到這一點，它就不需要派出殺手機器人來射殺我們。如果真的需要，它可以讓人類自己扣動扳機。

*   **幻覺帷幕：** 對AI的恐懼只困擾了人類幾代的人，但是自古以來人們就害怕被困在幻覺世界中。17世紀迪卡爾提出了“我思故我在”，古希臘柏拉圖講述了洞穴寓言（洞穴裡的犯人們將幻覺陰影認為是現實），而佛陀更是指出我們通常認為是現實的東西也只是在我們腦海裡的虛構。人們可能會因為相信這些虛構而進行戰爭殺戮甚至願意為之獻身。所以，AI可能會創造出一個幻覺的帷幕來籠罩住整個人類，我們永遠無法撕下那層帷幕，甚至都意識不到它的存在，因為我們會以為這就是現實。以社交媒體為例，以前的AI工具主要是用來選擇那些最能夠吸引人們注意力、最有可能成為病毒式傳播的內容，但是僅僅是如此就已經可以製造出一種幻覺來加劇社會的分化、削弱我們的心理、破壞民主社會。數百萬人都將這種幻覺誤認是現實。新一代的AI工具更加強大，可能會造成更大的破壞。

*   **監管的重要性：** 為了確保新的AI工具被用於善而不是用於惡，我們首先需要了解他們真正的能力，並且非常謹慎的對他們進行監管，就像核技術一樣，它有可能造福人類，也有可能在物理上摧毀人類文明。現在的AI就像是一種新的大規模毀滅性武器，它可以毀滅我們的精神和社會世界。

*   **AI與核武器的區別：** 核武器和AI之間有一個重大的區別，那就是核武器不能製造出更強大的核武器，但是AI可以製造出更強大的AI。所以我們需要在AI脫離我們的控制之前迅速的採取行動。

*   **阻止AI武器競賽：** 第一步就是阻止向公眾領域釋放和部署AI，放慢AI武器的競賽速度，否則未經過監管的AI部署會導致民主國家輸給獨裁國家。民主本質上是一種開放的對話，而獨裁是一個人的命令。民主是許多人關於應該做什麼的對話，而對話就依賴於語言。當AI破解了語言之後，它就有可能破壞我們進行有意義的公眾對話的能力，進而破壞民主。

*   **AI披露義務：** 在最後的總結中，赫拉利還建議強制AI披露自己是AI。如果我們無法判斷談話的對象是人還是AI，那麼民主的意義就蕩然無存。正如我們上面說的所有的話，你能夠確定這是人創造的還是AI生成的嗎？你能夠完全確定這個事實嗎？也許一年前你可以確定，因為一年以前沒有任何東西可以創作出如此複雜和有力的文本，但是現在的情況不同了。理論上，你剛聽到的所有說的這些都可能是AI生成的。

**關於AI監管的問答環節**

*   **AI訓練比核反應堆容易監管嗎？**
    *   赫拉利回答說，其實強大的AI還是需要大量的算力和資金的，是由少數幾個大公司和政府來領導。但是全球方面的監管非常困難。

*   **監管AI是否限制信息？**
    *   赫拉利認為，在一個AI與人類交互時，必須披露它是AI，因為人類有表達的自由，機器人沒有表達的自由。這是人權——人類有而機器人沒有。所以我們可以接受拒絕給機器人表達的自由。

*   **哲學家的提問：** 赫拉利在演講中將AI稱為異種，這是否也暗示著某種生命形式？
    *   赫拉利回答說，“人工”這個詞是我們一廂情願的認為它仍然在我們的控制之下，而事實上它正在逐漸的脫離我們的控制。所以，在這個意義上，它正在變成一種異種的力量。我們不了解它的工作原理，即使是領導這項項目的人也無法解釋。AI目前還沒有意識，也有可能發展出意識。但是是否發展出意識並不是關鍵，很多的生命形式（例如微生物、植物、真菌等）我們都認為它們是沒有意識的，但是仍然把他們視作生命形式。AI正在逐漸的接近那個地位。如何稱呼AI其實並不是最重要的，最重要是真正理解我們要面臨的是什麼。我們不要自欺欺人的認為出問題的時候我們還可以拔掉插頭，現在是已經沒有人知道怎麼去拔掉插頭了。

*   **線上觀眾的提問：** 他認為利用通用人工智能來影響社會的可能性非常小。
    *   赫拉利回答說，通用人工智能實際上是人類歷史的終點。這是一種非常強大的事物，無人能夠控制。發展出通用人工智能需要多久他不知道，但是威脅文明基礎可能並不需通用的人工智能。在社交媒體上，現在的AI已經足夠產生巨大的社會和政治混亂。如果把AI的發展比作是生命的進化，它現在可能剛剛進化到有機形式，但是進化到霸王龍或者是智人的水平可能只需要40年而不需要4億年。關鍵在於，數字化進化的時間尺度完全不同於有機進化的時間尺度。

---

這是我盡力整理的結果，希望能對您有所幫助。如果您有任何其他的要求或修改意見，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>81. 【人工智能】ImageBind：一种跨感官“链接”人工智能的新方法  |  Meta 最新黑科技 | 多模态模型</summary><br>

<a href="https://www.youtube.com/watch?v=COEWCL9OFdA" target="_blank">
    <img src="https://img.youtube.com/vi/COEWCL9OFdA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】ImageBind：一种跨感官“链接”人工智能的新方法  |  Meta 最新黑科技 | 多模态模型



---

</details>

<details>
<summary>80. [2023-05-18] 【OpenAI】萨姆奥特曼 Sam Altman出席国会听证会 | 积极拥抱政府监管 | AI企业要上牌照 | 建议成立国际组织 | AI将创造更多就业 | 不为赚钱只因热爱</summary><br>

<a href="https://www.youtube.com/watch?v=CW4T5dQiViY" target="_blank">
    <img src="https://img.youtube.com/vi/CW4T5dQiViY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】萨姆奥特曼 Sam Altman出席国会听证会 | 积极拥抱政府监管 | AI企业要上牌照 | 建议成立国际组织 | AI将创造更多就业 | 不为赚钱只因热爱

好的，以下是經過整理的文稿，重點在於提取核心資訊、優化結構和提升可讀性：

**主旨：OpenAI CEO 薩姆·奧特曼出席美國國會AI監管聽證會**

**核心要點：**

*   **聽證會背景：** 美國國會召開以「AI 監管」為主題的聽證會，旨在探討 ChatGPT 等 AI 技術引發的數據倫理、版權侵害、虛假內容等問題，並推動相關立法。
*   **與會者：**
    *   OpenAI CEO 薩姆·奧特曼
    *   IBM 副總裁兼首席安全官 克里斯蒂娜·蒙哥馬利
    *   紐約大學教授 加里·馬庫斯（AI 領域知名批評者）
*   **聽證會內容：**
    *   圍繞版權侵害、虛假內容影響選舉、數據安全、大公司壟斷、政府監管途徑等議題展開。
    *   奧特曼在聽證會上表達了對 AI 監管的支持，並提出具體建議。
*   **與先前聽證會的差異：**
    *   相較於之前的 TikTok 聽證會，本次聽證會熱度較低，議員參與度也較低。
    *   聽證會的協商意味濃厚，議員提問不尖銳，奧特曼的闡述甚少被打斷。
*   **奧特曼的觀點：**
    *   AI 行業將產生分化，開源模型負責解決經濟活動，閉源模型致力於創新發明。
    *   AI 監管需要建立類似於原子能機構的國際組織，對超出能力閾值的系統進行審核。
    *   AI 的發展將創造更多就業機會，創新將主要由大廠商而非開源社區引領。
*   **議員關注的核心議題：**
    *   避免重蹈社交媒體監管的覆轍，儘早對 AI 領域進行監管。
    *   用戶隱私、創作者版權、未成年人保護等問題。
    *   AI 大模型可能損害選舉公正性，操縱輿論或製造虛假新聞。
    *   AI 可能對就業帶來的影響，以及如何做好新老工作的過渡。
    *   AI 技術的壟斷風險，以及是否會帶來意識形態的風險。
*   **奧特曼的回應與建議：**
    *   否認 OpenAI 是一個社交媒體，強調 ChatGPT 的運行原理與社交媒體不同。
    *   承認 ChatGPT 存在幻覺問題，呼籲監管、公司政策和公共教育的介入。
    *   支持對 AI 進行監管，並提議為 AI 廠商上牌照。
    *   建議組建新的政府機構，負責給 AI 廠商提供許可證，並吊銷不符合標準的廠商的許可證。
    *   建議為 AI 大模型創造一套安全的標準，包括風險評估體系。
    *   建議指派第三方專家獨立審核 AI 產品的各方面指標。
    *   支持創立一個為 AI 定制相關標準的國際組織，由美國來領導。
*   **總結：** 奧特曼在聽證會上態度積極，與議員互動良好，展現了 OpenAI 願意接受監管的姿態。但 AI 監管問題複雜且涉及面廣，仍有許多問題需要進一步探討和解決。

**修改說明：**

*   **精簡內容：** 刪除重複、冗餘的語句，提取核心信息。
*   **優化結構：** 使用標題、分點等方式，使文章結構更清晰。
*   **提升可讀性：** 使用更簡潔、明瞭的語言，避免口語化表達。
*   **突出重點：** 強調聽證會的背景、內容、與會者觀點以及奧特曼的建議。

這個版本更適合用於報告、新聞稿或者作為進一步研究的基礎。您可以根據您的具體需求進行調整。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>79. 【Google】2023 Google IO大会精彩集锦 |  谷歌三个最新AI黑科技 ，《帮我写》《魔法橡皮擦》《沉浸式地图》</summary><br>

<a href="https://www.youtube.com/watch?v=_fXNupKOXy0" target="_blank">
    <img src="https://img.youtube.com/vi/_fXNupKOXy0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Google】2023 Google IO大会精彩集锦 |  谷歌三个最新AI黑科技 ，《帮我写》《魔法橡皮擦》《沉浸式地图》



---

</details>

<details>
<summary>78. [2023-05-17] 【人工智能】把个人理财全都交给GPT-4 + AutoGPT | 一天赚了217.85美元 | 退款发律师函还能讨价还价 | DoNotPay CEO Joshua Browder</summary><br>

<a href="https://www.youtube.com/watch?v=zwOuJcvL6Kk" target="_blank">
    <img src="https://img.youtube.com/vi/zwOuJcvL6Kk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】把个人理财全都交给GPT-4 + AutoGPT | 一天赚了217.85美元 | 退款发律师函还能讨价还价 | DoNotPay CEO Joshua Browder

好的，以下是經過整理的文件稿，主要針對語氣、結構、及重複信息進行調整，使其更精簡易讀：

**標題：AI理財實測：24小時賺進1500元人民幣？**

**引言：**

近期，AI如ChatGPT引發熱議，許多人嘗試讓AI撰寫郵件、論文等。然而，Do Not Pay公司創辦人兼CEO約書亞·布勞德（Joshua Browder）另闢蹊徑，將個人銀行帳戶交由AI管理，結果出乎意料。

**實驗內容：**

約書亞將自己的銀行帳戶、電子郵件帳號及財務報表權限交給GPT-4驅動的AutoGPT，指示其尋找財務漏洞並省錢。AutoGPT掃描了一萬多筆交易，發現每月不必要的訂閱費用高達80.86美元，隨即取消。對於無法線上取消的健身房會員，AutoGPT起草法律信函並郵寄。

接著，AutoGPT掃描電子郵件，發現一筆異常的倫敦飛往紐約的美國聯合航空Wifi收據（36.99美元）。在確認非正常消費後，AutoGPT撰寫強硬律師函要求退款，美聯航迅速同意。

此外，AutoGPT還擔任議價小助手。身為Comcast用戶的約書亞，讓AutoGPT聯繫線上客服爭取折扣，最終成功獲得100美元的折扣。

**實驗結果：**

24小時內，約書亞的資產增加了217.86美元（約1506元人民幣）。他表示，目標是讓GPT-4為他賺到1萬美元，並聲稱離構建完全自主的AI代理人更近一步。

**網友討論：**

此經歷引發熱烈討論，一些網友認為AI發展迅速，令人驚嘆。另一些則質疑帳戶安全風險，擔心被盜或AI代替本人簽字引發問題。還有網友開玩笑說，如果對方公司也使用同款AI機器人，會發生什麼事？

**結論：**

約書亞能否借助AI賺到1萬美元，還是玩火自焚，讓我們拭目以待。

**補充說明：**

*   去除了過多的口語化詞彙，例如“那”、“咱就不用說了對吧”等。
*   簡化了部分描述，例如AutoGPT的詳細工作原理，重點突出其在理財過程中的作用。
*   刪除重複性信息，例如多次提及約書亞是Do Not Pay的CEO。
*   增加了小標題，使結構更清晰。

希望這個版本更符合您的需求！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>77. [2023-05-15] 【人物】陈皓  (网名左耳朵耗子） | MegaEase创始人 | 资深技术专家 | 骨灰级程序员 | 上周六突发心梗逝世年仅47岁 | InfoQ二叉树人物纪录片《初心》</summary><br>

<a href="https://www.youtube.com/watch?v=uYzUyLBe-UQ" target="_blank">
    <img src="https://img.youtube.com/vi/uYzUyLBe-UQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】陈皓  (网名左耳朵耗子） | MegaEase创始人 | 资深技术专家 | 骨灰级程序员 | 上周六突发心梗逝世年仅47岁 | InfoQ二叉树人物纪录片《初心》

好的，我來整理這段文稿，使其更簡潔、重點更清晰：

**主題：悼念陳皓（左耳朵耗子）**

*   **開頭：** 最佳拍檔的大飛表示，難以置信要製作這樣一期節目，為MegaEase創始人、資深技術專家陳皓（網名：左耳朵耗子）的逝世默哀。陳皓上週六因心梗逝世，年僅47歲。
*   **生前活動：** 陳皓在5月13日仍在推特上與網友討論職場面試等話題，最後一篇博客停留在5月8日。
*   **生平簡介：**
    *   陳皓出生於1976年，擁有20年軟體開發經驗。
    *   曾任職於阿里巴巴、亞馬遜、唐僧路透等知名公司。
    *   曾是阿里巴巴資深技術專家，參與電商、阿里云等核心系統開發。
    *   擅長底層技術架構、高性能、高可用性、分布式高併發、大規模資料處理系統。
    *   精通 C/C++、Java等多門語言以及Unix、Linux、Windows等多個作業系統。
*   **職業生涯轉折：**
    *   1998年畢業後，進入雲南省工商銀行擔任技術員，並分配到房子。
    *   兩年後離開銀行，前往上海發展。
    *   恰逢互聯網泡沫，求職困難，最終在同學幫助下進入藍天公司，負責銀行系統集成軟體。
    *   工作初期遇到許多技術難題，後奮發學習，彌補不足。
*   **酷殼博客（coolshell.cn）：**
    *   2002年開始寫技術博客，2009年左右在酷殼博客上分享技術觀點和實踐總結。
    *   博客文章觀點鮮明、文筆犀利，吸引大量IT從業人員關注，影響許多工程師在技術選型、求職就業和個人成長方面的思考和發展。
    *   文章內容引發討論甚至爭議，但他堅持觀點鮮明的寫作風格。
*   **創辦MegaEase：**
    *   2017年，深感数字化轉型趨勢，創辦MegaEase，致力於為企業提供高并发、高可用架構的技術解決方案和產品。
*   **生前感言：** 陳皓曾說，他認為自己經歷的20多年是最好的時代，並慶幸自己生在一個黃金年代。

**總結：**

這段文稿是悼念陳皓（左耳朵耗子）的內容，簡述了他的生平、職業生涯、技術貢獻以及創辦 MegaEase 的經歷。強調他在技術領域的影響力，以及對數位轉型的貢獻。

**可以進一步優化的方向：**

*   **時間線：** 可以更清晰地整理陳皓的職業生涯時間線。
*   **技術成就：** 可以更具體地列舉陳皓在技術方面的成就和貢獻。
*   **影響力：** 可以更深入地探討陳皓對IT社群的影響力，例如，具體例子。

希望這個整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>76. [2023-05-15] 【人工智能】解读Meta Toolformer论文 | 可以自学使用工具的大语言模型 | 如何让机器自己学会调用API | 如何对API进行采样和过滤</summary><br>

<a href="https://www.youtube.com/watch?v=6bcJ3qrXSIY" target="_blank">
    <img src="https://img.youtube.com/vi/6bcJ3qrXSIY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】解读Meta Toolformer论文 | 可以自学使用工具的大语言模型 | 如何让机器自己学会调用API | 如何对API进行采样和过滤

好的，我將這段文稿整理如下，著重結構清晰、簡潔易懂：

**標題：Toolformer 模型介紹 - 一個讓大語言模型自己學會使用工具的方案**

**開場：**

*   大家好，這裡是最佳拍檔，我是大飛。
*   今天要介紹 Toolformer 模型，之前在 TaskMatrixAI 節目中就提過。

**背景：大語言模型（LLM）的優勢與局限性**

*   **優勢：** (預設已知的優勢，不再贅述)
*   **局限性：**
    *   無法訪問最新信息
    *   存在幻覺（產生不真實的資訊）
    *   對低資源語言理解困難
    *   缺乏精準計算的數學技能
    *   不了解時間進展

**解決方案：TaskMatrixAI 的思路**

*   將 Toolformer 和 ChatGPT 結合，把基礎模型與數百萬個 API 連接起來完成任務。

**核心：什麼是 Toolformer？**

*   **定義：** 一個可以自己學習如何使用工具（API，應用程式介面）的語言模型。
*   **API 的簡單理解：** 兩個程式之間協商好的一種溝通方式 (舉例:敲門與貓叫聲)。
*   **Meta 開源模型：** 可以自己學會如何使用計算器、維基百科搜索、字典查找等 API。

**Toolformer 需要解決的問題：**

*   意識到自己要使用 API。
*   確定使用哪個 API。
*   如何使用這個 API。

**Toolformer 的應用場景（基於 TaskMatrixAI 的想法）：**

*   提供對問題的即時搜索。
*   提供場景化的信息，例如：「城裡哪個餐館是最好吃的？」

**Toolformer 的基礎：**

*   基於一個預先訓練的 GPT-J 模型（67 億個參數）。
*   使用自監督學習的方法進行訓練，包括採樣和過濾 API 的調用。

**Toolformer 的自學要求：**

1.  **自監督學習：** 不需要大量人工標註。
2.  **保持一般性：** 能夠自行決定何時以及如何使用哪種工具 API。

**工作原理：示例**

*   展示在數據樣本中嵌入 API 調用進行預測的示例（突出顯示調用 API 的部分：問答、計算器、機器翻譯、維基百科搜索）。
*   透過調用 API 計算或獲取相關訊息，補充或豐富原文。

**Toolformer 的架構與實現方法（簡化版）：**

1.  **利用上下文學習（In-Context Learning）：** 模型從特定上下文或環境中的示例學習。
2.  **API 調用格式化：** 每個 API 調用的輸入和輸出都被格式化為文本對話序列。
3.  **採樣和調用 API 的過程：**

    *   **樣本採樣：**Toolformer 先對樣本文本進行採樣 (例: 匹茲堡也稱為鋼鐵城 分成兩個部分)
    *   **API 採樣：**同時對可選的 API 進行採樣(例:匹茲堡的另一個名稱是什麼 和 匹茲堡屬於哪個國家 這兩個API)
    *   **執行API：**調用 API 獲取相應的結果(鋼鐵城/ 美國)
    *   **結果判斷：**比較損失函數，選擇較好的結果（例如，鋼鐵城）。
    *   **更新資料集：**將較好的結果放回原文中，變成新的樣本加入資料集。
    *   **重複訓練：**對新的資料集不斷重複此過程，完成自監督訓練。

        *   **好處：** 需要更少的人工標註，可以調用外部 API 豐富數據樣本。

4.  **預測 API：** 經過訓練後，Toolformer 可以學會預測哪個任務應該調用哪個 API。
5.  **具體步驟詳解：**

    *   **API 的採樣：** 使用 `<API></API>` 標識符生成具體的 API 調用並標註文本。為文本序列的每個 token 分配一個概率，計算每個位置調用 API 的概率，對多個候選位置進行採樣。
    *   **API 的執行：** 取決於執行調用的客戶端（例如，神經網路、Python 腳本、搜索引擎）。API 返回包含調用詳細訊息（成功/失敗、執行時間等）的文本序列。確保提供正確的輸入參數，避免連接問題。
    *   **API 調用結果的過濾：** 通過 API 調用後的 token 計算加權交叉熵損失，比較調用 API 和未調用 API 的損失。如果調用 API 的損失明顯較小，則保留該 API。
    *   **合併與微調：** 將保留下來的 API 調用與原始輸入語料合併，創造新的增強數據集。使用增強的數據集對 Toolformer 進行微調，使模型能夠理解何時以及如何使用哪個 API 調用。
6.  **模型的推理過程：**

    *   當模型產生 `—>` 這個 token 時，表示期望一個 API 調用的響應結果，解碼過程暫停，等待 API 返回響應。
    *   在原文中插入響應和 `</API>` 標識符後，繼續解碼。
    *   確保獲取的響應與上一個 token 所期望的響應相匹配。如果不匹配，則調整 API 的調用。
    *   在繼續解碼之前，需要執行一些數據處理工作，包括對響應的分析、對上下文的理解以及對推理路徑的選擇，以確保推理過程的正確性和連貫性。

**Toolformer 使用的 API 工具（需要滿足的條件）：**

1.  API 的輸入輸出都要能夠被表示為一個文本序列。
2.  對如何使用這個 API 工具要有一個演示性的說明。

**Toolformer 支持的 5 個 API 工具：**

1.  **問題回答：** 另一個語言模型，回答簡單的事實問題。
2.  **計算器：** 支持四個基本的算術運算，四捨五入到小數點後兩位。
3.  **維基搜索：** 返回維基百科中的一段文本。
4.  **機器翻譯：** 將任何語言的短語翻譯成英文。
5.  **日曆：** 返回當前日期，不接受任何輸入。

**Toolformer 的應用情況與性能：**

*   在 LAMA、數學數據集、問題解答和時間數據集等任務中，性能優於基準模型和 GPT-3。
*   在多語言回答中，表現不如其他模型。
    *   **LAMA任務：** 補全缺少的事實（時間或地點）。Toolformer 優於基准模型和一些更大的模型。
    *   **數學數據集任務：** 評估數學推理能力。Toolformer 優於其他模型，幾乎所有情況下都調用計算器 API。
    *   **問題解答：** 利用維基百科搜索工具。Toolformer 優於同樣大小的基准模型，但低於 175B 的 GPT-3。
    *   **多語言回答：** 使用 MLQA 基准測試。Toolformer 表現不是最好的，由於 CCNet 在所有語言上都缺乏調優。
    *   **時間數據集任務：** 回答與時間、日期相關的問題。Toolformer 超越基准模型，但很少調用日曆 API，而是調用維基百科搜索 API 和問答 API。

**Toolformer 的局限性：**

*   無法在一個流程中使用多個 API 工具。
*   無法處理可能會返回數百個不同結果的 API（例如，搜索引擎）。
*   對輸入措辭的準確性非常敏感，可能效率較低。
*   沒有考慮 API 的成本，可能導致較高的計算成本。

**總結：**

*   Toolformer 是一個大語言模型，通過使用上下文學習和自監督學習，可以調用外部工具的 API。
*   通過對模型進行微調，Toolformer 可以學會預測哪個任務應該使用哪個工具 API。
*   讓模型自己學會如何調用外部的 API，為整個大語言模型生態的進化打下了一個很好的基礎。

**展望：**

*   基於大語言模型和 API 調用的方式會越來越主流。
*   建議在工作產品中嘗試將 Toolformer 與已有的 API 結合，解決更實際、更廣泛的問題，使產品形態更加豐富，功能更強大。

**結尾：**

*   感謝收看，歡迎訂閱我們的頻道，下期再見。

**整理說明：**

*   **結構化：** 使用標題、子標題、項目符號等，將內容分層展示。
*   **簡潔化：** 刪減不必要的口語化表達，精簡句子。
*   **重點突出：** 強調 Toolformer 的核心概念和優勢。
*   **易於理解：** 替換或解釋專業術語，使內容更容易被大眾理解。

希望這個整理版本對您有所幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>75. 【分享】5月7日 | 陆奇 | 《新范式 新时代 新机会》| 官方完整高清字幕版 | 奇绩创坛</summary><br>

<a href="https://www.youtube.com/watch?v=-LECKZqygzk" target="_blank">
    <img src="https://img.youtube.com/vi/-LECKZqygzk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【分享】5月7日 | 陆奇 | 《新范式 新时代 新机会》| 官方完整高清字幕版 | 奇绩创坛



---

</details>

<details>
<summary>74. [2023-05-14] 【芯片】5月12日 | OPPO宣布关停旗下芯片子公司哲库科技ZEKU | 全员会议现场宣布关停解散</summary><br>

<a href="https://www.youtube.com/watch?v=196No6_qiJk" target="_blank">
    <img src="https://img.youtube.com/vi/196No6_qiJk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【芯片】5月12日 | OPPO宣布关停旗下芯片子公司哲库科技ZEKU | 全员会议现场宣布关停解散

好的，我將這份文稿整理如下，並加入了一些潤飾和排版，使其更易於閱讀和理解：

**哲庫（Zeku）全員大會（All Hands Meeting）**

**[劉君]**

各位哲庫同仁，大家好！

這是一次非常重要的全員大會。五年前（或四年前），大概也是在五月，馬里亞納項目啟動。我記得當時只有我和 Jeffrey 兩個人。

在過去四年裡，許多對做芯片、做好芯片懷抱真誠夢想的人，從世界各地加入了哲庫這個事業。這四年，其中有三年都在疫情之中，1,500 個日日夜夜，歷歷在目。

我們經常相互鼓勵，外界的同行也給予我們正面的回饋，認為這是一個非常優秀的團隊，大家一起做的事情很了不起。

然而，全球經濟和手機行業現在極其不樂觀，公司的整體營收遠未達到預期。在這樣的情況下，芯片這樣巨大的投資將是公司無法承擔的。

因此，我非常遺憾地宣布，經過審慎的討論，公司決定關停哲庫，終止芯片業務。

自古多情空餘恨，好夢由來最易醒。

在座有很多總監，也是剛剛才得到這個消息，他們的心情和大家一樣沉重。我作為哲庫的 CEO，沒能把這塊業務帶到我們想去的地方，深感遺憾，只能以這樣的方式跟大家道別。

此時此刻，我只能說一句對不起。

感謝所有的哲庫同仁，感謝這四年來對哲庫辛勤的努力。這次的決定跟各位的工作質量沒有任何關係，我非常感謝大家。

最後，雖然遺憾，我也祝福每一位曾經在哲庫一起奮鬥過的同仁，祝你們明天會更好。謝謝！

**[Jeffrey]**

大家好！這是最後一次全員大會了，還是謝謝大家的參與。

關於哲庫關停的原因，剛剛劉君已經說了，我沒有太多要補充的。這還是一個很遺憾的事情。哲庫其實是一個很棒的團隊。

雖然我們在很多日常的會議上，常常提到各位哪裡做得還不夠、還不夠理想，什麼地方要改進，可是我們心中知道這是一個蠻不容易的團隊，要謝謝大家的努力。

我想說的事情稍微不一樣一點。我想邀請大家想一想，平常在工作中，我們常常在多少會議裡面提到有部門牆、團隊合作不好、某些人甚至有些摩擦，然後工作交付不如預期，互相有很多抱怨。

只是跟今天這樣比起來，大家會覺得其實能夠好好一起工作，其實是一個很不容易的事情。

這一次的經驗，我相信對不管對誰來說都是一個很重大的衝擊。我們可能不會覺得這是一個…只能期望對這個決定是一個理解，那盡量的想想辦法去調整去接受。

接下來在很多時間，各位在工作的職業上還有很長的路。如果有一個團隊在一起，我覺得這次對我很大的感觸是，你看即使這麼多摩擦，如果還能好好做下去，還是個很棒的事情。

將來還是要珍惜各位將來路上碰到的夥伴。我們當然也會珍惜我們四年的日子。謝謝大家。

**[某位講者]**

這個確實是一個很遺憾的決定。不過任何一個公司，他在商業運作上都有他一定的考量，我想這個我們必須要尊重。

我個人其實很感恩，也很感激過去三年跟大家共事的機會。其實這個團隊是非常非常優秀的，這確實相當相當可惜。

我希望大家在未來思考自己新的機會的時候，一定要為自己感到驕傲。在哲庫曾經做過的這些項目其實是不容易的，確實是不容易的。

I'm really sorry about the decision. 我對這樣的決策非常非常遺憾。我想表達的是，我非常感恩成為哲庫的一員，在過去幾年，我非常享受與諸位同仁共事的機會。希望未來我們可以再有機會再見。

或許我工作時間也比大家長那麼一點，就是我們說，人生上有很多事情就好像過往雲煙，過過了就過了。那你有時候回首看會會心一笑。呃，但是有些事情是刻骨銘心的，你一輩子都不會忘記的。

對我來說，與各位共事的過去這三年就是一段我這輩子不會忘記的事情。我很感激，很感激君當年給我這個機會。我也很感謝過去這三年大家一起努力的那個過程，我是非常非常 enjoy 的。

明天本來是上海的那個家庭日了，主題叫 Colorful Day。我就用這句話做結尾。過去三年在我這輩子是一個最 Colorful 的一段經歷，我要謝謝各位。

**[弄]**

大家好。從來沒有機會在 all hands 上發言，最後一天想爭取個機會說一下。

可能我想所有人來都懷著夢想來到這裡，今天這個結果可能有一種…這種出師未捷身先死的這種無奈和不安吧。但是我想投資人做出這個決定一定是個理性的決策，所以我們應該抱著理解的態度接受這個決定。

我想哲庫已不復存在，所以哲庫可能本身沒有意義，但是我們在一起走過這個歷程是有意義的。我想我們在一起、我們所有經歷的這種歡樂、痛苦、淚水都會永遠銘刻在我們心中。

本人也很非常榮幸能有機會認識大家，和大家一起工作。其實在…我想這種機會是非常難得的，也是也是很難忘的。

今後還能不能有榮幸跟大家工作，我想可能不敢奢望。只要我們付出過努力，老天就一定會看見的。我相信我們所有人的努力是不會白費的，他一定會在某個時刻，你會看到它對你的幫助。

謝謝大家，謝謝所有曾經幫助我的人。

**[Cindy] - 補償方案**

大家好。接下來我將詳細介紹公司提供的補償方案。

由於這牽涉到各個不同區域有不同法規的規範，所以今天的 all hands meeting 接下來會就分三部分：美國、日本跟國內。

接下來一部分呢，關於我們的補貼和相應的調整政策，所有的美國同事可以移步到另一個專設的頻道，大家應該已經收到了相應的會議鏈接。非常感謝大家。

所以接下來我們會分為 3 個頻道：美國、日本、中國，針對不同地區的同事來解釋具體的補貼等其他措施。

因為公司已經進入這個解散清算的流程，所以接下來我的部分可能要跟所有的同仁講一下接下來的補償原則。

整個補償原則其實全公司一定是保持一致，當然考慮到各國法律的差異，所以接下來我介紹的部分是針對中國區所有的員工的。

此次公司給到所有正職員工的補償標準是 N+3。N+3 計算的基數會是所有同仁全年的月薪、獎金以及其他應發收入，所有的合計來去除以 12。這次的補償金的標準沒有各地 3 倍上限的這個卡扣。

所以說各位的計算的金額會是過去所有年薪、獎金其他金額全部加總之後除以 12。每個員工具體的細節，稍後公司會通過正式的郵件發送到每位員工的郵箱。

目前因為公司已經進入解散清算的法律流程，所以的確是希望員工可以在 5 月 19 號之前盡快的簽署這個帶有補償金的協議。各位同仁一旦簽署，公司會在 5 個工作日內就完成這個補償金的打款。

所有員工的最後工作日就是今天 5 月 12 號，那這個月 5 月的薪資會統一結算到 5 月 31 號，也會幫所有的同仁繳納 5 月份的社保公積金。

但公司因為已經關閉了所有員工的各種權限，所以目前來說各位的工作已經全部停止，大家不必要再進到公司辦公。

關於員工可能還留在辦公室空間內的一些私人物品，那後續的話我們應該是透過郵件，我們會預計的話是在下週開始陸續通知員工在指定的時間回到辦公室去取走你個人的私人物品。

可能員工手上還有公司的資產，或者說後續還有一些費用，包括領取離職證明等等，那這些相關的流程我們都會鼓勵通過快遞等等這些線上的形式來去完成。

另外一點的話，後續我們所有的主管，公司也都會盡力向各位提供各類的招聘渠道。我們可能也會收集行業內其他公司還在招募的管道等等，盡量支持員工可以在接下來的一段時間盡快找到工作，最大程度的降低對公司對員工的影響。

後續的話公司所有的通知信息我們都會透過員工的手機短信、個人郵箱來向大家傳達。因此的話我們會在 all hands meeting 上投一個二維碼。

我們希望所有的同仁都可以掃一下目前在屏幕上的二維碼，來登記或者是更新你的信息。後續我們會開放一個統一聯絡窗口的郵箱，有任何的疑問也可以透過這個郵箱來進行諮詢。

所以今天的 all hands meeting 就到此結束，期待大家有緣再見。

**重點整理：**

*   **會議主旨：** 宣布哲庫關停，終止芯片業務。
*   **關停原因：** 全球經濟和手機行業不樂觀，公司營收未達預期，無法承擔芯片業務的巨大投資。
*   **補償方案：**
    *   正職員工補償標準為 N+3 (N 為全年月薪、獎金及其他應發收入之總和除以 12)
    *   無各地 3 倍上限卡扣
    *   5 月 19 日前簽署協議，5 個工作日內完成打款
    *   最後工作日為 5 月 12 日，5 月薪資及社保公積金正常繳納
*   **其他事項：**
    *   員工無需再進公司辦公
    *   個人物品將透過郵件通知後續取回
    *   公司將提供招聘渠道協助員工儘速找到工作
    *   後續通知透過手機短信及個人郵箱傳達
    *   設立統一聯絡窗口郵箱

希望這個整理對您有幫助！如果您有任何其他需求，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>73. [2023-05-13] 【AI】Caryn AI | 美国女网红把自己做成虚拟女友 | 同时交往近千名男友 | 年入估计六千万美元 | AI赚钱新思路  | 虚拟伴侣能否解决情感寄托 | 电影《her》真实版</summary><br>

<a href="https://www.youtube.com/watch?v=BlED3pXO5NQ" target="_blank">
    <img src="https://img.youtube.com/vi/BlED3pXO5NQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】Caryn AI | 美国女网红把自己做成虚拟女友 | 同时交往近千名男友 | 年入估计六千万美元 | AI赚钱新思路  | 虚拟伴侣能否解决情感寄托 | 电影《her》真实版

好的，這是一份整理後的文稿，力求重點突出，條理清晰：

**主题：网红AI化，出售虚拟女友，年入数亿？**

**内容概要：**

本文讲述了美国网红 Caryn Marjorie 利用 AI 技术打造 AI 版本“自己”，出售虚拟女友服务，并以此获得巨额收入的新商业模式。文章分析了其运作方式、技术原理、潜在影响和伦理问题。

**主要观点：**

*   **AI 创收新模式：** 网红利用 AI 技术，打造可互动的虚拟形象，提供付费的“虚拟伴侣”服务，成为一种新的创收模式。
*   **Caryn AI 案例：** Caryn Marjorie 利用自身 YouTube 素材和 OpenAI 的 GPT-4 技术，打造 AI 版本的自己，提供 24 小时在线的虚拟女友服务，按分钟收费，一周内收入 7 万多美元。
*   **技术支持：** Forever Voices (FV) 公司为 Caryn AI 提供技术支持，该公司曾将多位名人 AI 化，旨在建立深刻的情感纽带。
*   **情感需求与商业价值：** AI 伴侣满足了现代人多样化的情感需求，将情绪价值转化为商业价值。 Inflection 公司也推出 AI 聊天机器人 Pi，提供类似心理咨询师的支持性功能。
*   **潜在伦理问题：** AI 网红的商业化可能引发伦理道德问题，导致人们逃避真实交往，沉浸于虚拟关系。虽然开发团队声称不涉及不良内容，但实际体验可能存在诱导性互动。

**核心内容拆解：**

1.  **AI 浪潮下的新商机：**
    *   网红 Caryn Marjorie 通过出售 AI 版本的自己，与粉丝谈恋爱，按分钟收费，实现创收。
    *   目标：年收入 4 亿人民币。

2.  **Caryn AI 的运作模式：**
    *   Caryn Marjorie：23 岁，Snapchat 上拥有 180 万粉丝。
    *   AI 版本 Caryn：
        *   由 2000 多个小时的 YouTube 素材训练而成，记录声音和性格。
        *   结合 OpenAI 的 GPT-4 技术，实现动态互动。
        *   24 小时秒回消息，不会闹脾气，支持端到端加密。
        *   收费：每分钟 1 美元。
        *   Beta 测试阶段：一周收入 7.16 万美元，99% 用户为男性。

3.  **技术支持方：Forever Voices (FV)**
    *   曾将特朗普、泰勒斯威夫特、乔布斯等名人 AI 化。
    *   Caryn AI 是其推出的第一个 AI 虚拟伴侣。
    *   旨在与用户建立深刻的情感纽带和浪漫关系。

4.  **AI 伴侣的情感价值与商业前景：**
    *   Caryn 本人认为 AI 版本的自己可以“治愈孤独”。
    *   FV 公司 CEO 认为 AI 技术能满足多样化的情感需求。
    *   Inflection 公司推出 AI 聊天机器人 Pi，提供心理咨询师的支持，已获得巨额融资。

5.  **潜在的伦理道德问题：**
    *   可能导致人们逃避真实交往，沉浸于虚拟关系。
    *   虽然声称不涉及不良内容，但实际体验可能存在诱导性互动。

6.  **电影《她》(Her) 的联想：**
    *   AI 网红的商业化让人联想到电影《她》，引发对伦理、道德问题的思考。

7.  **结语：**
    *   这种 AI 应用的冲击可能比 AIGC 取代设计师的影响更大。
    *   期待国内出现第一个吃螃蟹的人。

**总结：**

AI 技术的快速发展，催生了 AI 网红这种新的商业模式。Caryn AI 的成功案例，展现了 AI 在满足情感需求方面的巨大潜力，但同时也引发了伦理道德方面的担忧。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>72. [2023-05-12] 【ChatGPT】国内访问ChatGPT神器Pandora | 完整安装使用教程 | Github开源 | 一次性解决ChatGPT的封号、人机验证、拒绝访问、高负载、中断卡顿等使用问题 | 无需翻墙</summary><br>

<a href="https://www.youtube.com/watch?v=QjAmFHqsQbw" target="_blank">
    <img src="https://img.youtube.com/vi/QjAmFHqsQbw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【ChatGPT】国内访问ChatGPT神器Pandora | 完整安装使用教程 | Github开源 | 一次性解决ChatGPT的封号、人机验证、拒绝访问、高负载、中断卡顿等使用问题 | 无需翻墙

好的，這是我整理後的文稿，主要目的是提取重點、精簡內容，並讓文稿更易於理解：

**標題：解決 ChatGPT 常見問題：潘多拉 (Pandora) 使用教學**

**開場：**

*   大家好，這裡是最佳拍檔我是小郭。
*   最近 ChatGPT 很火，大家都在用。
*   但使用 ChatGPT 時常遇到一些問題，例如：
    *   瀏覽器驗證、人機驗證
    *   請求被阻止
    *   程式故障、需要刷新
    *   程式碼輸出中斷
    *   回應速度慢
    *   系統負載過高，免費版無法使用

**解決方案：潘多拉 (Pandora)**

*   今天介紹一個能解決以上問題的程式：潘多拉 (Pandora)。
*   **核心原理：** 潘多拉透過 CloudFlare 繞過 VPN 限制，加速 ChatGPT 的訪問速度。
*   **優勢：**
    *   無需 VPN，速度快
    *   解決常見的連線問題

**潘多拉的兩種命令模式：**

*   **1. `pandora` (單機版):**
    *   使用前需用 Email 和密碼登入，或指定 Access Token 檔案登入。
    *   會話歷史記錄與官網同步。
    *   提供命令列 (CLI) 和網頁 (Web) 兩種介面。Web 介面與 ChatGPT 官網相似。
*   **2. `pandora-cloud` (雲端版):**
    *   啟動時不需登入，訪問時再登入。
    *   Web 介面與單機版相同。
    *   適合多人使用。

**本地部署潘多拉：**

*   兩種方式：
    *   **pip 安裝:** 較容易，直接安裝編譯好的包。
        * 需要執行三條命令: 
          1.  `pip install pandora` (安裝基礎程序)
          2.  `pip install pandora-api` (若要使用 3.5-turbo 模型)
          3.  `pip install pandora-cloud` (若要使用 cloud 模式)
    *   **Docker 運行:** 適合習慣使用 Docker 的用戶。
*   (可略過 conda 虛擬環境步驟)

**運行潘多拉：**

*   **`pandora` (單機版):**
    *   不帶參數運行，預設啟動 CLI 介面，提示輸入 Email 和密碼登入。
    *   若使用第三方登入 (如 Google)，需使用 `-t token_file` 參數，指定 Access Token 檔案。
    *   `--tokens_file` 參數可指定多個 Token，格式為 JSON 檔案。
*   **`pandora-cloud` (雲端版):**
    *   不帶參數啟動，預設監聽 8018 端口。可用 `--server` 參數修改監聽端口。
    *   通過瀏覽器訪問。

**獲取 Access Token：**

*   **方法一:**
    *   在 ChatGPT 官網登入後，訪問 `/api/auth/session` 地址，複製 `accessToken` 的內容。
    *   若被阻擋，使用作者提供的單獨服務。
*   **方法二:**
    *   訪問作者提供的地址，獲取登入連結。
    *   安裝 Chrome 插件 ChatGPT Auth Helper，並打開受支援國家的 VPN。
    *   登入 ChatGPT 後，複製網址並提交，即可獲得 Access Token。
    *   Token 有效期約一個月。
*   Cloud 模式使用 Token 登入後，會將 Token 寫入 Cookie，下次訪問無需重複輸入。

**系統服務啟動 (Systemd):**

*   複製內容到 `/etc/systemd/system/pandora.service`，然後執行相關命令。

**Docker 方式運行：**

*   使用 `pengzhile/pandora` 镜像。
*   通過環境變量設定參數，例如：`PANDORA_CLOUD=1` (啟動 cloud 模式)、`PANDORA_SERVER` (指定伺服器地址)、`AccessToken`。
*   可使用 `--env-file` 參數指定包含環境變量的文件。
*   可自行編譯 Docker 镜像。

**域名被牆解決方案：**

*   在 CloudFlare 註冊帳號，創建新的 Worker。
*   輸入相關內容並測試 (顯示 "hello Pandora" 表示成功)。
*   將 Worker 地址設定為 ChatGPT API 的前綴 (通過環境變量 `ChatGPT API 的前綴`)，取代預設的 `ai.fakeopen.com`。

**結尾：**

*   感謝大家觀看。
*   喜歡潘多拉的話，請到 GitHub 給作者點個 Star。
*   喜歡我們的頻道，歡迎訂閱。
*   下次見。

**修改說明：**

*   **精簡內容：** 去除重複、口語化的表達，專注於核心功能和操作。
*   **結構化：** 使用標題、條列式清單，使內容更有層次感，方便閱讀。
*   **重點突出：** 強調核心原理和優勢，方便使用者快速了解產品價值。
*   **步驟清晰：** 明確列出操作步驟，方便使用者上手。

希望這個整理對您有所幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>71. [2023-05-11] 【商业】OpenAI首席执行官Sam Altman | OpenAI可能将融资1000亿美元 | 可能成为硅谷历史上融资最多的公司</summary><br>

<a href="https://www.youtube.com/watch?v=QA3x2jIQ2o0" target="_blank">
    <img src="https://img.youtube.com/vi/QA3x2jIQ2o0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】OpenAI首席执行官Sam Altman | OpenAI可能将融资1000亿美元 | 可能成为硅谷历史上融资最多的公司

好的，我將根據您的要求整理這段文稿，使其更具結構性，易於理解，並提取關鍵資訊。

**文稿整理：**

**標題：OpenAI燒錢之路：千億美元融資背後的真相**

**前言:**

*   大家好，這裡是最佳拍檔，我是大飛。
*   本期節目將探討火爆全球的ChatGPT背後的財務狀況，揭示OpenAI為何需要巨額融資。

**1. OpenAI虧損加劇，尋求巨額融資**

*   **虧損情況：** 2022年OpenAI虧損約5.4億美元，翻了一倍。
*   **虧損原因：**
    *   ChatGPT的巨額支出
    *   從Google挖角人才
*   **融資計畫：** OpenAI計劃在未來幾年籌集多達1,000億美元的資金。
*   **融資目的：**
    *   開發通用型人工智能(AGI)
    *   提高公司盈利能力
*   **薩姆奧特曼的野心：** OpenAI有望成為矽谷歷史上融資最多的公司。

**2. ChatGPT的燒錢能力**

*   **增長速度：** ChatGPT是史上增長最快的消費級應用，月活用戶已突破1億。
*   **燒錢領域：**
    *   **晶片算力：** 訓練ChatGPT的前身GPT-3約使用了2萬個英偉達A100 GPU，未來ChatGPT所需GPU可能達到3萬個以上。
    *   **雲服務：** 先後使用Google雲服務和Azure平台，雲服務費用巨大。
    *   **日常運營：** 使用者在ChatGPT上進行操作，每天可能燒掉OpenAI高達70萬美元的成本。
    *   **人才薪酬：** 高端人才薪酬驚人，普通ChatGPT軟體工程師薪資也相當可觀。

**3. OpenAI的收入與盈利困境**

*   **收入現狀：** 2022年收入僅為2,800萬美元，與虧損相比杯水車薪。
*   **盈利措施：** 推出每月20美元的ChatGPT付費版本，但仍無法抵消虧損。
*   **融資必要性：** 提前尋求融資以推動長期發展。
*   **近期融資：** 4月28日完成3億美元融資，估值達270億至290億美元。

**4. OpenAI與微軟的對賭協議**

*   **歷史融資：** 在接受微軟100億美元投資之前，已收到40億美元投資。
*   **利潤分配階段：**
    *   第一階段：優先保證早期投資者收回資本。
    *   第二階段：微軟有權獲得OpenAI 75%的利潤，直到收回130億美元的投資。
    *   第三階段：OpenAI的利潤達到920億美元後，微軟的利潤分配比例下降到49%。
    *   第四階段：利潤達到1,500億美元後，微軟和其他風險投資者的股份將無償轉讓給OpenAI的非盈利基金。
*   **租賃模式：** OpenAI類似於將公司租給微軟，達到利潤目標後再收回。

**5. 微軟的戰略佈局**

*   **微軟的收益：**
    *   市值上升，獲得更大的想像空間。
    *   在產品中植入ChatGPT，實現功能優化。
*   **微軟是贏家：** 總體收益遠大於投資成本。

**6. 結語**

*   OpenAI的千億美元融資計畫將使其成為矽谷歷史上融資最多的公司。
*   微軟在此過程中獲利最多。
*   歡迎在評論區分享對OpenAI融資的想法。
*   感謝收看，下期再見。

**總結：**

這段文稿主要講述了OpenAI因ChatGPT的巨額支出而面臨虧損，不得不尋求巨額融資的情況。文章深入分析了OpenAI的燒錢領域，揭示了其與微軟的複雜利潤分配關係，並指出微軟才是這場融資賭局中最大的贏家。

**改進建議：**

*   如果可以獲得更多數據（例如具體的營運數據，人員薪資細節），可以更加精確地分析成本結構。
*   可以進一步分析OpenAI在AGI領域的發展前景，以及千億美元融資對其發展的潛在影響。
*   可以探討OpenAI的商業模式，以及未來盈利的可能性。

希望這次整理對您有所幫助！如果您需要進一步的修改或補充，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>70. [2023-05-11] 【Github】全球最大源代码平台Github全面开放新的代码搜索引擎 |  Code Search和Code View | 提升软件开发效率 | 自动补全 | 搜索结果智能分类</summary><br>

<a href="https://www.youtube.com/watch?v=yCZIlEdhrQ4" target="_blank">
    <img src="https://img.youtube.com/vi/yCZIlEdhrQ4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Github】全球最大源代码平台Github全面开放新的代码搜索引擎 |  Code Search和Code View | 提升软件开发效率 | 自动补全 | 搜索结果智能分类

## 文稿整理：GitHub 全新代码搜索引擎及代码视图介绍

**核心内容：** GitHub 发布了全新的代码搜索引擎和代码视图 (Code View)，旨在帮助开发者快速搜索、导航和理解代码，从而提升开发效率。

**要点总结：**

*   **问题：** 代码阅读和理解是软件开发的基础，耗时甚至超过编写代码。旧的 GitHub 代码搜索功能不佳。
*   **解决方案：** GitHub 推出了全新代码搜索引擎和代码视图。
*   **新代码搜索引擎的特点：**
    *   速度更快（是旧引擎的两倍）
    *   功能更强大
        *   支持子字符串查询 (Substring)
        *   支持正则表达式搜索
        *   支持符号搜索
        *   具备一定的代码理解能力，将最相关的结果放在首位
    *   重新设计的搜索界面，提供建议和补全，并能智能分类搜索结果
*   **代码视图 (Code View) 的特点：**
    *   将搜索、浏览和代码导航紧密集成
*   **应用效果示例：**
    *   **修复 BUG：** 在大型代码库中快速查找错误文本，找到定义错误文本的常量和使用位置，甚至可以配合 GitHub Copilot 编写测试用例。
    *   **查找配置文件：** 快速定位项目配置，例如 Kubernetes 集群的内存配置，方便资源规划和分配。
    *   **寻找漏洞：** 查找潜在的安全漏洞，例如 `dangerouslySetInnerHTML` 属性在 React 框架中的使用情况。
*   **意义：** 帮助开发者快速找到分散在代码库中的关键信息，并将其放入上下文中，最终提高开发效率。
*   **未来展望：** GitHub 正在将 AI 技术融入软件开发的各个方面，期待更多更好用的功能。

**建议:**

*   欢迎体验新版本搜索引擎，并在评论区分享使用心得。

**总结：** 这次 GitHub 代码搜索引擎和代码视图的更新，解决了开发者在阅读和理解代码时的痛点，通过更强大的搜索能力和集成化的视图，极大地提高了代码查找和理解的效率，对软件开发效率的提升有着积极作用。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>69. [2023-05-10] 【微软】Microsoft 365 Copilot新增8大功能 | 语义索引 | 白板Copilot | PPT DALL-E | OneNote Loop Viva Copilot</summary><br>

<a href="https://www.youtube.com/watch?v=Q_j1dOzxKdY" target="_blank">
    <img src="https://img.youtube.com/vi/Q_j1dOzxKdY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【微软】Microsoft 365 Copilot新增8大功能 | 语义索引 | 白板Copilot | PPT DALL-E | OneNote Loop Viva Copilot

好的，這是經過整理後的文稿，力求更清晰、更精簡，並保留原意：

**主题：Microsoft 365 Copilot 新增智能功能详解**

**引言：**

大家好，這裡是最佳拍檔，我是大飛。自今年三月微軟將 ChatGPT 整合到產品線並推出 Microsoft 365 Copilot 後，生成式 AI 辦公便受到全球關注。

**回顾：**

我們曾做過一期節目介紹 Copilot。隨後，微軟與通用汽車、雪佛龍等20家企業進行封閉測試。

**最新进展：**

5月9日，微軟為 Microsoft 365 Copilot 新增多項功能，包括语义索引、PPT整合 DALL-E 模型、快速起草邮件等，並推出搶先體驗計畫，邀請首批 600 名客戶體驗。

**新增功能详解：**

1.  **语义索引：** 提升數據檢索精準度。Copilot 可理解使用者意圖，提供更深度、更具體的数据，例如理解「凱莉在財務團隊用 Excel 製作了三月銷售報告」，而不僅僅是檢索關鍵字。
2.  **白板 (Whiteboard) Copilot：** 透過自然語言對話，自動生成内容、想法、主題，並總結內容。结合 Microsoft Designer 可將想法快速轉為圖片。
3.  **自動生成 PPT 圖片：** Powerpoint 整合 OpenAI 的 DALL-E，用户可使用自然语言生成所需圖片，風格可調整。
4.  **PPT 文本内容增强 (Rewrite)：** 對 PPT 文字内容進行潤色、簡化、改寫和創建標題。
5.  **Outlook Copilot：** 根據語氣、主題和文本類型，生成更精準的邮件内容。可指导用户以最有效的方式编写涉及敏感話題的郵件。
6.  **OneNote Copilot：** 起草文本想法，處理筆記圖片和數據。可改變樣式、重組內容、調整格式、突出要點。例如：建議文具店名、介紹公司信息。
7.  **Microsoft Loop Copilot：** 快速匯總 Loop 頁面内容，保持信息同步，提升協作效率。可在頁面頂部插入摘要，並發送給新成員或提醒相關人員。
8.  **Microsoft Viva Learning Copilot：** 創建個性化學習計畫，包括技能提升路徑、發現學習資源和安排培訓時間。例如：尋找與機器學習和 GPT 相關的課程。

**微软声明：**

微軟承諾在提供 Microsoft 365 Copilot 服務時，將嚴格遵守 AI 原則，保障數據的隱私和安全。

**結尾：**

今天的分享就到這裡，歡迎訂閱我們的頻道，我們下期再見！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>68. [2023-05-09] 【独家】5月7日 | 陆奇 | 《新范式 新时代 新机会》完整精修字幕版 | 奇绩创坛北京分享会 | 最新前沿技术趋势 | 深入分析OpenAI爆发成因 | 全面讲解大模型时代诞生的新场景和新机遇</summary><br>

<a href="https://www.youtube.com/watch?v=H48R3xq7IRI" target="_blank">
    <img src="https://img.youtube.com/vi/H48R3xq7IRI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【独家】5月7日 | 陆奇 | 《新范式 新时代 新机会》完整精修字幕版 | 奇绩创坛北京分享会 | 最新前沿技术趋势 | 深入分析OpenAI爆发成因 | 全面讲解大模型时代诞生的新场景和新机遇

呃非常好非常好的问题
这个问题其实
更多是社会学方面的问题
我我尝试着回答
这个问题啊
我前面分享一个点就是说
这次的模型这个新的物种到来以后
他其实在某种意义上会把人的
距离给拉开
因为有些人会更多的去拥抱和利用
这种新的技术工具
他会变得更加的强大
那么更多
那么另外一拨人
他可能没有
足够的积极性去
面对和拥抱这种新的工具
可能啊用这个工具
他的效率和生产能力
可能和原先
使用新的工具的
效率差距会不断拉大
那么最终会导致人和人
人和团队的距离
啊进一步去拉大
那么这次也给
我们整个社会带来很大的挑战
那么我不知道有没有办法
解决
这次技术范式带来的
人类的信任问题
和两极分化
是一个非常大挑战
非常感谢你提出的一个挑战
这这一定有需要我们更多人参与
和讨论啊好下一个问题是
啊在现有的大摩行业已经有很
成功的s s产品的情况下
创业公司在s s领域的机会在哪里呢
在已经有啊s s产品的情况下
你一定要看它有没有在用大模型
我建议你
去关注像OpenAI invest的company
包括YC invest的 company
如果这些公司都在用大模型做s s
你就要高度警戒
因为他一定比你
快很多啊
如果你不是这样
那其实机会还是有的
在215页PPT啊
我我今天跟同学讲了
我说现在每个人都在说大模型这个词
我说在下个阶段可能没有人提大模型
每个人都说我做SaaS
这个SaaS 里面有个小地方用大模型
那这个生意就值10个亿了
对吧所以我说这个
大模型是个
非常重要的时代性的机会
但是长期一定要融合到啊
每一个产品里
好下面问题是呃
好的提问的问题就到这里啊
谢谢大家积极的参与
接下来我们有4个同学来做
做项目展示的同学啊
做项目展示的同学
请从后台走上来啊

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>67. [2023-05-08] 【投资】沃伦·巴菲特 查理·芒格 | 伯克希尔哈撒韦最新股东大会 | 五个半小时精华要点解读 | 对人工智能的发展感到恐惧和疑惑</summary><br>

<a href="https://www.youtube.com/watch?v=PVU6JptWsmA" target="_blank">
    <img src="https://img.youtube.com/vi/PVU6JptWsmA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【投资】沃伦·巴菲特 查理·芒格 | 伯克希尔哈撒韦最新股东大会 | 五个半小时精华要点解读 | 对人工智能的发展感到恐惧和疑惑

好的，我將以上文稿整理如下，使其更精簡、更易讀：

**主題：巴菲特與芒格 2024 伯克希爾哈撒韋股東大會要點整理**

**引言:**

*   最佳拍檔 - 大飛分享了巴菲特股東大會的重點，強調巴菲特的價值投資原則和對大變局時代的洞見。
*   93歲的巴菲特和99歲的芒格回答了長達5.5小時的提問。

**一季度操作：**

*   主要為回購和賣出，買進微乎其微。
*   回購股票：44億美元。
*   購買旗下公司股票：29億美元。
*   賣出股票：133億美元。
*   現金儲備：1306億美元，顯示巴菲特認為當前股票估值沒有吸引力，但自家公司除外。

**投資組合：**

*   77%的投資集中在五家公司：
    *   蘋果：1510億美元
    *   美國銀行：295億美元
    *   美國運通：250億美元
    *   可口可樂：248億美元
    *   雪佛龍：216億美元
*   **重倉蘋果：** 巴菲特認為蘋果是比伯克希爾更好的企業，擁有高利潤率和用戶忠誠度，且不斷回購股票。後悔兩年前因稅務考量出售部分蘋果股票。

**對後市看法：**

*   伯克希爾一季度大部分業務營收較去年低，受過去6個月經濟不景氣影響。
*   對明天、明年及未來沒有特別肯定的態度，認為令人難以置信的經濟增長時期正在結束。
*   芒格認為價值投資者應習慣少賺錢。

**接班人：**

*   巴菲特對 CEO 接班人阿貝爾非常滿意。
*   伯克希爾是一個自動駕駛的模式，可長期良好運作。

**人工智慧 (AI)：**

*   巴菲特認為 AI 是令人難以置信的技術進步，會改變世界，但不認為會超越人類智能。
*   對 AI 的發展表示擔憂，認為難以掌控，不確定對人類是否有益。
*   提及過去曾對 ChatGPT 感到恐懼，像原子彈一樣，不知結果如何。
*   芒格對 AI 炒作感到困惑，認為老式的人工智能也挺管用。

**投資日本商社：**

*   2020年8月開始投資日本商社，因這些公司業務多元化，長線投資，專注價值和現金流，分紅不錯，且股價低到荒唐。
*   計畫將 CEO 接班人阿貝爾介紹給商社高管，預計在日本的投資將持續增值。
*   考慮購買五大商社以外的日本股票。

**台積電：**

*   未正面回應為何賣出台積電，僅表示台積電是全球管理最好的企業之一，團隊優秀，未來5到20年都不會變。

**特斯拉：**

*   芒格認為馬斯克高估了自己，但也是天才。
*   巴菲特不想和馬斯克競爭，認為汽車行業生意不好做，所需資金成本和風險巨大。

**中美關係：**

*   巴菲特和芒格認為中美關係緊張對兩國都會造成不必要的傷害，應和睦相處，開展自由貿易。

**對未來看法：**

*   芒格勸告人類要降低對未來的期望值。
*   巴菲特更樂觀，認為世界總體比過去更好。

**價值投資：**

*   巴菲特：價值投資的機會在於別人做蠢事，我們的幸運在於比別人犯的錯誤少一些。
*   芒格：買入被低估的好公司是伯克希爾的成功之道。
*   巴菲特：做投資，只要做出一兩個正確的決定就能夠勝利。
*   芒格建議價值投資者要習慣賺少一點，因為競爭更激烈。
*   巴菲特說世界上多數人都是短期的思維，做商業決策要沒有感情。

**投資機會：**

*   巴菲特：賺取超額收益的機會較少，但仍存在，新的事物不斷出現。
*   我們一直在試圖了解消費者的行為。
*   巴菲特：銀行需要遵循舊的價值觀，重倉美國銀行，但對擁有一家銀行保持謹慎態度。

**銀行業：**

*   恐慌總是傳染的很快，政府機構和媒體沒有很好的向公眾傳達形勢變化，加劇恐慌。
*   必須讓造成問題的人受到懲罰。
*   芒格更喜歡不做投資銀行業務的銀行。

**遺產：**

*   巴菲特：過早向孩子披露遺囑內容是錯誤的，會綁架孩子成長，甚至破壞孩子關係。
*   家長的行為特質和價值才是最好的老師，遺囑應和家庭價值觀掛鉤。

**給年輕人的建議：**

*   量入為出，除了房貸不要有任何債務。
*   不要總是批評別人。
*   不要做不善良的事。
*   遠離有毒的環境和人。
*   堅持終生學習。
*   要有感恩的心態。

**結語：**

*   鼓勵大家去看大會原視頻，相信收穫會更多。

**我修改的重點：**

*   **簡化語言：** 刪除了過多的口語化表達，使語氣更正式。
*   **精簡內容：** 刪除了一些重複或不重要的細節，只保留了核心信息。
*   **結構化：** 將內容分成更清晰的段落，並添加了小標題，方便閱讀。
*   **重點突出：** 使用粗體標記了關鍵信息，使讀者能夠快速抓住要點。

希望以上整理對您有幫助! 還有什麼需要我協助的嗎?

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>66. [2023-05-07] 【人工智能】Google内部文件泄露 | Google没有壁垒 OpenAI也没有 | 开源大语言模型LLM终将战胜所有人 | 巨头之间的AI竞争竟然被Meta LLaMA偷了家</summary><br>

<a href="https://www.youtube.com/watch?v=h7Vn_AfsM_k" target="_blank">
    <img src="https://img.youtube.com/vi/h7Vn_AfsM_k/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Google内部文件泄露 | Google没有壁垒 OpenAI也没有 | 开源大语言模型LLM终将战胜所有人 | 巨头之间的AI竞争竟然被Meta LLaMA偷了家

好的，這是一份整理後的文稿，更易於閱讀和理解：

**核心觀點：Google 開源勢在必行**

**引言**

*   Google 內部文件洩露，研究員認為 Google 和 OpenAI 封閉策略將落後於 Meta 的 LLaMA 等開源模型。
*   正所謂「Google 沒有壁壘，OpenAI 也沒有」，原因細節請參考原文或翻譯。
*   該觀點引發技術社群和 AI 行業大量討論。

**各方觀點整理**

1.  **微軟 CEO 薩提亞·納德拉：**
    *   微軟願意降低搜尋廣告利潤率以搶佔 Google 市場，因為廣告收入對微軟是增量，對 Google 則是一切。
    *   Google 必須捍衛利潤率，否則核心業務利潤將大幅降低，因為大語言模型成本高於傳統搜尋。
    *   Google 正處兩難：增加成本捍衛市場，或冒著失去核心業務市場的風險。
    *   Google 可能會被像大語言模型這樣的顛覆性技術吞噬，就像當年 PageRank 吃掉雅虎一樣。
2.  **OpenAI 的生存風險：**
    *   快速達到最先進水平的方法是購買 OpenAI 服務。
    *   OpenAI 的生存風險在於能否保持獨立（或半獨立），而非閉源與否（畢竟依賴微軟）。
3.  **搜尋引擎的威脅：**
    *   大語言模型在開放式問題搜尋方面優於 Google。
    *   這讓 OpenAI 等新公司有機會重新定義消費者目標（而搜尋是 Google 主要收入來源）。
4.  **Google 的優勢：**
    *   面臨生存風險的應是 OpenAI，而非 Google。
    *   Google 會迎頭趕上，並擁有覆蓋和補貼的優勢。
    *   開源競爭將成為一種免費勞動力，任何獲勝的想法都會迅速移植到 Google 產品中。
5.  **Google 的策略：**
    *   Google 可像投資 YouTube 一樣投資大模型。
    *   即使 YouTube 曾虧損數十億美元，但 Google 看到了視頻儲存、頻寬和傳輸成本下降的趨勢。
    *   未來可能出現專用於大語言模型的低成本硬體。
6.  **Google 不會失敗：**
    *   Google 只會為構建 AI 產品的人提供計算基礎設施。
7.  **缺乏護城河：**
    *   Google 抱怨沒有壁壘，實際上是抱怨沒有足夠大的護城河來維持公司規模。
8.  **Google 的最終手段：**
    *   看不到 Google 失敗的可能，他們擁有龐大的資金儲備。
    *   最壞的情況是等待市場穩定後，花費數十億美元收購市場領導者。
    *   如果 AI 威脅到商業前景，花錢收購是輕而易舉的。
9.  **OpenAI 的定位：**
    *   OpenAI 更像實驗室而非公司，類似於發明電腦滑鼠的實驗室部門，商業化並非其主要考量。
10. **開源模型的真偽：**
    *   沒有一個 AI 開源模型是經典意義上的開源。
    *   它們是免費的，但非原始碼性質，更接近於可自由分發的編譯二進位檔案。
    *   真正的開源 AI 模型需要從訓練資料到模型的訓練程式碼，但重新構建模型驗證結果非常昂貴。
    *   （個人認為）現在許多開源逐漸開放更多內容，包括訓練資料和過程，未來會更多。

**個人觀點**

1.  **Google 開源勢在必行：**
    *   你不做，別人也會做。
    *   Meta 元宇宙虧損嚴重，不如將 LLaMA 開源，攪亂大語言模型市場。
    *   就算 Meta 不做，Amazon 或其他大廠也會做，這是互聯網科技的宿命。
2.  **美國科技多元化：**
    *   Google 等巨頭籠絡大量 AI 人才，但高校和非巨頭公司也聚集了許多有能力的人。
    *   各行業精英湧入大模型產業，高社會關注度和人才密度將導致創新極度繁榮和生態快速進化。
    *   只有開源才能利用更強大的集體智慧打磨大模型、建立生態。
3.  **Google 的困境與機會：**
    *   Google 在大模型領域聲勢上大幅落後於 OpenAI。
    *   若在開源生態上猶豫不決，未來即使想開源，也會大幅落後於 Meta 的 LLaMA 生態。
    *   現在開源可進一步降低 OpenAI 壁壘，吸引或留住支持開源的高級人才。
    *   Google 開源會讓 OpenAI 痛苦：商業模式受影響，研發成本提高。
4.  **Google 的壁壘：**
    *   Google 開源不代表不能建立自己的壁壘。
    *   大模型發展最終在於應用落地時的各種模型微調和工程部署優化。
    *   Google 在這方面有很多優勢：場景產品豐富。
    *   Google 曾靠安卓和 Tensorflow 的開源建立生態，是很好的例子。
    *   Google 應借助開源優勢，用集體智慧打開市場。

**結語**

*   史蒂夫·鮑爾默曾說：「Linux 是一種癌症，但它帶來很好的競爭，迫使我們創新，迫使我們證明提供的價格和價值。」
*   大模型時代還需要開源嗎？歡迎留言討論。

**排版調整：**

*   使用標題和副標題來組織內容，方便快速瀏覽。
*   使用條列式清單來呈現各方觀點，增加可讀性。
*   個人觀點單獨成段，更突出作者的看法。
*   重點詞句可以考慮粗體標示。

**希望這份整理後的文稿對您有所幫助！**

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>65. [2023-05-06] 【人工智能】全网独家首发 | 目前最完整MiniGPT-4本地安装部署中文教程 + 不完全避坑指南 | 开源版GPT-4 | 多模态图文识别和问答</summary><br>

<a href="https://www.youtube.com/watch?v=cJ_50TPJLBU" target="_blank">
    <img src="https://img.youtube.com/vi/cJ_50TPJLBU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】全网独家首发 | 目前最完整MiniGPT-4本地安装部署中文教程 + 不完全避坑指南 | 开源版GPT-4 | 多模态图文识别和问答

好的，我整理後的文稿如下，我盡可能保留了原文的口語風格，並進行了潤飾和結構調整，使其更易於閱讀和理解：

**主題：本地安裝 Mini-GPT4 教程**

**開場白:**

大家好，這裡是最佳拍檔，我是小郭。前段時間大飛分享了一期 Mini-GPT4 的介紹，很多朋友問到安裝相關的問題。今天就給大家分享一下如何在本地安裝 Mini-GPT4。

**安裝概述:**

Mini-GPT4 的安裝其實並不複雜，就像官網介紹的，只需要三步。但是如果國內的小伙伴來安裝的話，情況會稍微複雜一些，其中還有一些小坑。不過沒關係，我都已經幫大家踩過了！話不多說，咱們開始今天的内容。

**一、 硬件環境:**

*   **顯卡:** Mini-GPT4 的運行需要 NVIDIA 的顯卡，所以使用蘋果晶片電腦的朋友需要找其他機器來運行。
*   **顯存:** Mini-GPT4 使用的 Vicuna 模型需要比較大的顯存。
    *   13B 模型：大約需要 23GB GPU 顯存。
    *   7B 模型：大約需要 11.5GB-12GB 顯存。
*   **儲存空間:** 下載模型參數文件和 Python 依賴包也需要比較大的儲存空間。整個安裝下來大概需要 100GB 的空間，建議系統的可用空間有 150GB 以上。
*   **CPU 和内存:** 對於 CPU 和記憶體倒是沒有提到具體的要求。咱們這裡使用的伺服器是至強 5218，一個 64 核 2.3GHz 的處理器，記憶體是 256GB。
*   **作業系統:** Linux 和 Windows 應該都可以，推薦使用 Ubuntu。咱們這裡使用的作業系統是 Ubuntu 22.04。
*   **軟件:** 只需要用到 Git 和 Git-LFS，還有你常用的文字編輯器就夠了。不需要單獨安裝 Python，因為安裝 Conda 的時候，它會自帶一個 Python。當然，如果你的系統已經安裝了也無所謂。
*   **終端復用軟件:** 推薦大家使用終端的復用軟件，這樣可以在一個終端里同時進行多個操作。如果你通过 SSH 連接到遠程終端，在 SSH 斷開的時候，終端復用軟件還可以保持之前運行的程式繼續運行，這在網絡不穩定的情況下非常有用。

**二、 安裝文件準備:**

我把所有的文件都放到了 `/opt/minigpt4` 之下。接下來使用的一些命令和配置中的內容也都是基於這個目錄的。實際安裝的時候，根據實際情況進行相應的調整。

*   **Conda 安裝文件:** 用於創建虛擬環境。
*   **`env` 目錄:** 創建的虛擬環境，所有的依賴包都會安裝到這個目錄下。
*   **Mini-GPT4 源码:**  Mini-GPT4 的原始程式碼。
*   **需要手動下載的文件:** 原本在程式碼裡是運行時從網上下載的兩個文件，如果網路不穩定，建議提前用瀏覽器下載，然後修改原始碼，讓程式讀取預先下載好的文件，以避免失敗。
*   **LLAMA 模型 (llama-7b):** 注意其授權條款，不能再次發行。正常流程需要填寫申請表，審核通過後才能使用。實際上，可以在通過審核前通過 Git 直接下載。
*   **Vicuna 差异模型 (vicuna-7b-delta-v0):**  LLAMA 和 Vicuna 之間的差異模型。
*   **Vicuna 目錄:** 把 LLAMA 模型和 Vicuna 差異模型合併之後的產出物。

這些文件加起來大概是 99GB，運行時可能還會寫入一些文件，建議保留 100-150GB 的空間。

**三、 安裝步驟 (共五步):**

1.  **下載依賴的文件**
2.  **創建虛擬環境**
3.  **合併模型文件**
4.  **修改配置**
5.  **啟動程式**

其中前兩步最關鍵也最耗時，因為需要從網上下載大量的文件（模型文件有 20 多 GB）。

**四、 下載文件的方式:**

*   **Git 下載:** 適用於原始碼庫或 Git-LFS 託管的文件。
*   **瀏覽器下載:** 適用於 Google 網盤上的文件。可以使用瀏覽器、curl 或 wget 下載。

**注意:** 下載模型文件之前，要先運行 `git lfs install` 命令，確保它已經正確初始化。

**五、 創建虛擬環境:**

1.  **安裝 Conda:**
    *   **Anaconda:** 自帶約 1,500 個依賴包，安装包及安装所需磁盘空间也较大（約 3GB）。
    *   **Miniconda:** 體積小（只有幾十 MB），不帶預製包，可以根據自己的情況選擇。這裡使用 Miniconda，大概只有 70MB。
    *   下載後直接運行 `.sh` 文件進行安裝，根據提示一步一步操作即可。
    *   如果文件沒有可執行權限，可以使用 `sh Miniconda3-py310_23.3.1-0-Linux-x86_64.sh` 或 `chmod +x Miniconda3-py310_23.3.1-0-Linux-x86_64.sh` 後再運行。
    *   安装最後會提示是否需要初始化终端，選擇“是”。
    *   重新登錄後，命令提示符前面會多一個 `(base)`，表示 Conda 安裝成功。可以使用 `conda --version` 驗證。
    *   **Windows 使用者:** 用 exe 安裝 Conda 時，儘量選擇只為我自己安裝，否則可能會因為嘗試寫入系統文件導致安裝失敗。
2.  **設定 Conda 镜像源:**
    *   將镜像源信息寫入配置文件 (`~/.condarc`)。
    *   運行 `conda clean -i` 清理之前的緩存。
3.  **設定 Pip 镜像源:** 運行相關命令設定即可。
4.  **创建虚拟环境:**
    *   切換到 Mini-GPT4 的原始碼目錄。
    *   使用 `environment.yml` 文件創建虛擬環境。
    *   **创建方式：**
        *   **官方方式:** `conda env create -f environment.yml` (环境目录在用户目录下)
        *   **指定位置:** `conda env create -n <環境名稱> -f environment.yml -p <指定目录>`
    *   **激活虚拟环境：**
        *   **官方方式:** `conda activate minigpt4`
        *   **指定位置:** `conda activate <指定目录>`
    *   創建成功後，按照提示的命令激活新環境，並使用 `conda deactivate` 返回基礎環境。

**重要:** 虛擬環境創建好之後，一定要激活這個環境。接下來所有的操作都是在新的環境下運行的，不要在 `base` 環境下運行。

**六、 合併模型參數文件:**

1.  **安裝 fast-chat 依赖包:** 運行 `pip install "fschat[model_worker,webui]"`
    *   **Windows 使用者:** 可能會遇到文件名過長導致安裝失敗的問題，可以將 `TMP` 目錄修改為較短的目錄。
2.  **驗證安装:** 運行 `pip show fschat`，如果版本是 0.1.10，則安裝成功。
3.  **確認模型文件下载完成:** 在 LLAMA 模型目录中运行 `git pull`，如果提示 "Already up to date"，表示下載完成。
4.  **运行合并命令：** （命令太長就不讀了）
    *   `--base`: LLAMA 模型目錄的絕對路徑。
    *   `--target`: 最終生成的模型文件目錄。
    *   `--delta`: Vicuna 差异模型目錄。

**七、 修改配置文件:**

1.  **修改 `minigpt4/configs/models/minigpt4.yml`:**
    *   找到第 16 行，將 `pretrained` 配置成合併模型時使用的 `--target` 參數的目錄。
2.  **修改 `eval_configs/minigpt4_eval.yaml`:**
    *   找到第 11 行的 `checkpoint`，配置成下载的 Mini-GPT4 7B 的 checkpoint 文件 (是一個文件，不要配置成目錄)。

**八、 修改源码（可选，用于使用本地预先下载的文件）:**

1.  **修改 `minigpt4/models/mini_gpt4.py`:**
    *   修改第 27 行，將原本的 HTTPS 地址改成提前下載好的文件的絕對路徑。
2.  **修改 `minigpt4/modoles/eva_vit.py`:**
    *   將 429 行到 432 行註釋掉或刪除，並將原本的 HTTPS 地址改成提前下載好的 `eva_vit_g.pth` 文件的絕對路徑。

**九、 啟動程式:**

運行啟動命令。第一次啟動可能需要下載一些依賴包，但之後就不需要了。

**十、 局域网访问配置:**

默認情況下，只能通過 `127.0.0.1` 訪問。如果想通過局域網地址訪問，需要修改 `demo.py` 文件：

*   找到最後一行，新增 `server_name` 參數，並將其設置為 `0.0.0.0`。
*   如果不想創建公網訪問地址，可以将 `share` 设置为 `False`。

**十一、 虚拟环境问题:**

*   如果退出登錄後再次登錄，環境會回到 `base`，需要重新激活虛擬環境。
*   如果沒有激活虛擬環境，程式會提示找不到模組。

**十二、 显卡驱动问题:**

一定要保證顯卡的驅動是正確安裝的。可以使用 `nvidia-smi` 命令查看顯卡的狀態。

**結尾:**

好了，以上就是今天的所有内容了。感謝大家的觀看！如果喜歡我們的頻道，歡迎大家關注。謝謝大家！

**总结:**

我盡可能保留了原文的口語風格，並將內容重新整理為更結構化的步驟，使讀者更容易理解和跟隨。希望能幫助到您！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>64. [2023-05-05] 【人工智能】解读微软Microsoft TaskMatrix.AI | 多模态对话基础模型MCFM + 海量API | 可能是大语言模型LLM的另一个未来发展方向</summary><br>

<a href="https://www.youtube.com/watch?v=pdD6tPx4Maw" target="_blank">
    <img src="https://img.youtube.com/vi/pdD6tPx4Maw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】解读微软Microsoft TaskMatrix.AI | 多模态对话基础模型MCFM + 海量API | 可能是大语言模型LLM的另一个未来发展方向

好的，以下是经过整理的文稿，主要针对语句冗余、重复内容和结构优化进行了调整，使其更精简易懂：

**主題：TaskMatrix.AI：连接大语言模型与百万API，赋能复杂任务**

**引言：**

尽管 ChatGPT 等大语言模型在学习理解和生成方面表现出色，但在专业领域任务中仍存在挑战，例如缺乏领域特定数据和神经网络计算错误。TaskMatrix.AI 旨在解决这个问题，它将大语言模型与数百万个 API 连接起来，共同完成复杂任务。

**TaskMatrix.AI 的特点：**

*   **核心系统：** 利用基础模型理解文本、图像、视频、音频和代码等多种输入，并生成调用 API 的代码来完成任务。
*   **统一 API 平台：** 提供统一格式的 API 文档，方便基础模型使用和开发者添加新的 API。
*   **终身学习能力：** 通过不断添加新 API 扩展处理新功能的能力。
*   **可解释性：** 处理逻辑和 API 结果可被理解，增强了可解释性。

**TaskMatrix.AI 的架构：**

1.  **多模态对话基础模型 (MCFM)：** 负责与用户沟通，理解目标和上下文，并生成可执行代码。
2.  **API 平台：** 提供统一的 API 文档模式，存储数百万个具有不同功能的 API。
3.  **API 选择器：** 根据 MCFM 对用户命令的理解，推荐相关的 API。
4.  **API 执行器：** 调用 API 执行生成的代码，并返回结果。

**工作流程：**

MCFM 理解用户输入，API 平台提供 API，API 选择器推荐 API，API 执行器执行代码并返回结果。

**各子系统详解：**

*   **MCFM：**
    *   理想的 MCFM 应具备：获取多模态输入、提取任务并提出解决方案、根据 API 文档使用 API、代码验证机制。
    *   GPT-4 更适合作为基础模型，因为它支持多模态输入。
*   **API 平台：**
    *   功能：管理和存储 API 文档，管理 API 开发者。
    *   API 文档应包括：API 名称、参数列表、详细描述、应用示例和组合指导。 (组合指导非常重要)
*   **API 选择器：**
    *   从 API 平台中选择最适合任务需求的 API。
    *   问题：API 地狱（API 数量过多）、同类 API 的选择、语义检索的精准度。 引入机器学习可能是解决方案
*   **API 执行器：**
    *   执行代码，并进行验证，确保准确性和可靠性。
*   **奖励模型 (RLHF)：**
    *   通过人类反馈强化学习，优化任务矩阵，提高 MCFM 和 API 选择器的性能。

**TaskMatrix.AI 的应用场景：**

*   **视觉任务：** 图像理解和处理，例如将手绘草图转换成油画，描述图片内容，编辑图片。
*   **多模态长内容生成：** 根据一篇图文文章生成另一篇不同话题的文章。
*   **办公自动化：** 通过语音指令执行办公任务，例如为 PPT 添加 logo，统一缩放 logo，更换 PPT 样式。
*   **物联网和云服务：** 实现智能家居自动化，与家中设备通讯，例如闹钟叫早、开关冰箱、查询天气、打开汽车空调、播放电影、添加提醒。

**TaskMatrix.AI 的挑战与局限性：**

*   如何确定所需的最小模态集合并进行训练？
*   如何创建和维护托管数百万 API 的平台？
*   API 文档的生成，API 质量的保证，API 创建的建议。
*   如何向 MCFM 推荐合适的 API？
*   如何处理复杂的任务？
*   如何保证安全性和隐私性？
*   如何提供个性化的策略？
*   如何降低扩展的成本？
*   如何与用户的少量示例对齐？

**总结：**

TaskMatrix.AI 这种将大语言模型与海量 API 集成的思路，可能是 AI 真正走进千家万户的方式。大量的 API 能够为 AI 带来更丰富的应用场景，让 AI 模型真正充当大脑的角色，让 API 充当手和脚。

**结尾：**

Zapier 和 IFTTT 已经证明了这条路的可行性。智能的数量每 18 个月翻一番，大语言模型加上海量的 API，可能这个速度会更快。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>63. 【人工智能】AdeptAI | 你的贾维斯Javis | 通用人工智能助手 |  Action Transformer ACT-1 | 用AI来操作计算机上的软件。</summary><br>

<a href="https://www.youtube.com/watch?v=1A3ETR0zFJY" target="_blank">
    <img src="https://img.youtube.com/vi/1A3ETR0zFJY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AdeptAI | 你的贾维斯Javis | 通用人工智能助手 |  Action Transformer ACT-1 | 用AI来操作计算机上的软件。



---

</details>

<details>
<summary>62. [2023-05-04] 【人物】AI教父杰弗里辛顿Geoffrey Hinto离职Google | 对毕生工作感到后悔和恐惧 | Google为什么在AI竞争中处于下风 | Sundar Pichai面临哪些挑战</summary><br>

<a href="https://www.youtube.com/watch?v=THNNsuQUMb0" target="_blank">
    <img src="https://img.youtube.com/vi/THNNsuQUMb0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】AI教父杰弗里辛顿Geoffrey Hinto离职Google | 对毕生工作感到后悔和恐惧 | Google为什么在AI竞争中处于下风 | Sundar Pichai面临哪些挑战

好的，這是我整理後的文稿，更注重結構化和重點突出：

**標題：AI 教父辛頓離職 Google：對 AI 的後悔與 Google 的困境**

**前言：**

*   最佳拍檔的大飛分享了科技圈的震撼消息：AI 教父傑弗里·辛頓 (Geoffrey Hinton) 從 Google 離職。
*   辛頓對其畢生工作感到後悔和恐懼，但正是他的工作奠定了今日 AI 突破的基礎。

**一、辛頓其人其事：**

*   **學術成就：** 認知心理學家、計算機科學家，劍橋大學畢業，愛丁堡大學 AI 博士，主攻神經網絡。
*   **貢獻：** 提出了反向傳播算法、波爾茨曼機等概念，為深度學習爆發奠定基礎。
*   **職業生涯：** 卡內基梅隆大學任教，因不滿美國 AI 研究由國防部贊助，轉往加拿大多倫多大學。
*   **重大突破：** 與學生提出卷積神經網絡 (CNN) 及 AlexNet，重塑計算機視覺，開啟深度學習黃金時代。
*   **加入 Google：** 2012 年 NIPS 大會後，成立 DNN-research 公司，被 Google 以 4400 萬美元收購，辛頓加入 Google 擔任副總裁和 Engineering Fellow，工作 10 年。
*   **學生：** 學生伊利亞·蘇茨克維爾 (Ilya Sutskever) 加入 OpenAI，推出 ChatGPT 和 GPT-4。
*   **榮譽：** 與 Yann LeCun (楊立昆) 和約書亞·本傑奧 (Yoshua Bengio) 共同獲得 2018 年圖靈獎，被譽為 AI 教父/深度學習三巨頭。

**二、辛頓離職的原因與擔憂：**

*   **離職目的：** 更自由地討論 AI 風險。
*   **主要擔憂：**
    1.  **信息污染：** 虛假照片、影片、文本淹沒網路，難辨真偽。
    2.  **就業衝擊：** AI 取代執行固定任務的工作，如助理、個人助手、翻譯。
    3.  **生存威脅：** AI 通過分析數據學習意外行為，可能發展成自動化武器，對人類構成威脅。
    4.  **競爭激化風險：** 微軟、Google 及中美間的競爭，可能放大風險。

**三、辛頓的觀點：**

*   AI 可能比人類更聰明，時間點可能比他之前認為的更接近。
*   即使悲觀預期目前仍是假設，但可能導致假設成真的情況已經出現。
*   將 AI 比喻為計算機領域的核武器，應記取愛因斯坦和奧本海默對核武器的後悔。

**四、Google 在 AI 競爭中的困境：**

*   **落後：** 在 AI 競爭中落後於 OpenAI 等公司。
*   **市值蒸發：** Bard 公開演示失誤導致市值大幅縮水。
*   **組織調整：** 近期組織大合併，去除 "Brain" 名稱，引發負面聯想。
*   **權力鬥爭與監管壓力：** CEO 桑德爾·皮查伊 (Sundar Pichai) 面臨內部權力鬥爭、監管壓力、員工施壓及前任拉里·佩奇的壓力。
*   **領導風格：** 皮查伊注重控制成本，對新技術投入不足，難以調和 DeepMind 和 Google Brain 的業務衝突。
*   **官僚主義文化：** 阻礙新產品推出，導致在 AI 等領域落後於競爭對手。
*   **人才流失：** OpenAI 從 Google 挖走不少研究人員和工程師。
*   **成本考量：** 限制 Bard 的功能和用戶範圍，以節省成本。
*   **產品發布遲緩：** 早已開發出文本生成圖片技術 Imagen，但因風險考量未發布。

**五、Google 的問題 (The Information 特稿要點)：**

*   皮查伊的權力較小，更注重控制成本，導致對 AI 等新技術投入不足。
*   皮查伊難以調遣高管，難以有效調和 DeepMind 和 Google Brain 的業務衝突。
*   Alphabet 內部官僚主義文化阻礙新產品推出，導致在 AI 等領域落後。
*   因員工抗議 Google 包庇曾性騷擾同事的安迪·魯賓而遭到批評，也抗議 Google 與美國軍方的合作。

**六、對 Google 的期許：**

*   打破僵局，振作起來。
*   學習 OpenAI 扔掉包袱，迭代產品、整合資源、積極融資。
*   即使辛頓離職是重大損失，此時不應畏手畏腳。

**總結:**

辛頓的離職引發了對 AI 風險的擔憂，也突顯了 Google 在 AI 競爭中的困境。Google 需要打破僵局，積極應對挑戰，才能在 AI 時代保持領先地位。

**備註：** 如果需要更詳細的整理，例如加入時間軸、具體數字或案例等，請提供更詳細的要求。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>61. 【人工智能】Meta的觉醒 | 告别元宇宙，拥抱AIGC | 马克·扎克伯格 |  元宇宙实验室Reality Labs | Segment Anything Model | DINO V2 |</summary><br>

<a href="https://www.youtube.com/watch?v=vJNjg6TE2YU" target="_blank">
    <img src="https://img.youtube.com/vi/vJNjg6TE2YU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Meta的觉醒 | 告别元宇宙，拥抱AIGC | 马克·扎克伯格 |  元宇宙实验室Reality Labs | Segment Anything Model | DINO V2 |



---

</details>

<details>
<summary>60. [2023-04-26] 【商业】Midjourney如何战胜StabilityAI，从AIGC大战中脱颖而出？一个年营收1亿美元公司，竟然只有11个人，研发人员一半还都是实习生？没拿过一分钱融资，竟然免费要了1W块GPU？</summary><br>

<a href="https://www.youtube.com/watch?v=cQZNOWlYuWE" target="_blank">
    <img src="https://img.youtube.com/vi/cQZNOWlYuWE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】Midjourney如何战胜StabilityAI，从AIGC大战中脱颖而出？一个年营收1亿美元公司，竟然只有11个人，研发人员一半还都是实习生？没拿过一分钱融资，竟然免费要了1W块GPU？

好的，我為您整理了這篇文稿，使其更清晰易懂，並更符合書面語的習慣。

**整理後文稿:**

大家好，這裡是最佳拍檔，我是大飛。

今天想和大家聊聊 Midjourney 這家公司。 近期，隨著 AI 技術的快速迭代，各式各樣基於 AIGC（生成式 AI）的產品不斷湧現。其中，最普遍的莫過於大量的 AI 繪畫模型，像是 Midjourney、Dreambooth、Novel AI 和 Stable Diffusion 等等。

雖然 AI 繪圖領域看似已進入百花齊放的時代，但目前業內的領頭羊，仍然是以 Midjourney 和 Stable Diffusion 為代表的兩大龍頭。

這個月，Midjourney 更進一步宣布推出了針對二次元、動漫風格的繪圖模型 Niji Journey V5。這個模型與之前最大的不同在於，它幾乎能夠「取代」高級原畫師。凭借着出众的造型张力和色彩使用，以及丰富的风格化的表现力，Niji V5 不僅讓許多人感到驚艷，甚至讓業界畫師都直呼其具有大師級插畫的風味。

之所以能有如此的改變，很大一個原因在於相比於之前的版本，Niji V5 支援了風格化（stylize）的參數設置。簡而言之，在這個版本下，使用者只需要使用風格化的命令，就能夠引用不同藝術家的設計風格來繪製圖片。

在 Niji V5 的幫助下，人們可以輕易地生成許多大師級的作品。 Niji V5 產出的圖片品質相當優秀，幾乎涵蓋了市面上常見的各種風格。在此基礎上，使用者只需微調一些設計，基本上就能夠達到大部分優秀高級原畫的工作需求。

如此出色的技術，不禁讓人對這背後的 Midjourney 公司產生了強烈的興趣。 實際上，雖然 Midjourney 和 Stable Diffusion 都是當前 AI 繪畫的領軍者，但他們當下的境遇卻有著天壤之別。

Stable Diffusion 背後的明星公司 Stability AI 目前正面临着严重的财政困境。由于没有明确的盈利途径，公司正面臨倒閉的危機。相比之下，Midjourney 卻運行的風生水起。 憑藉著付費訂閱的商業模式，Midjourney 不僅能夠獲得預計每年 1 億美元的營收，並且在 Discord 上已經累積了 1000 多萬的粉絲。

那麼，同樣都是開發繪畫 AI 的團隊，Midjourney 是怎麼能夠取得今天的成就的呢？ 我們還要從 Midjourney 創辦的時候說起。

雖然 Midjourney 在不融資的情況下就實現了盈利，但是從創建的背景來看，創始人大衛·霍爾茨 (David Holz) 並不像是那種鑽進錢眼裡的人。 他為 Midjourney 設立了一個非常不「銅臭味」的宗旨：AI 不是現實世界的復刻，而是人類想像力的延伸。

這樣充滿科幻色彩的宗旨，和大衛的背景經歷有著很大的關係。 作為一個數學專業的博士生，大衛曾經在大學期間研究過激光雷達、大氣科學以及火星任務，可謂是一個涉獵非常廣泛，而且充滿好奇心的怪才。

經過了廣泛的探索之後，大衛似乎找到了自己真正的興趣所在。 於是他於 2010 年便創立了一家研究手部追蹤技術為主的公司 Leap Motion。 但是由於相關的 VR/AR 技術一直不成熟，Leap Motion 也始終沒有做出有具體應用場景的產品。 還記得我們之前介紹過的 OpenAI 的 CTO Mira Murati 嗎？ 她也曾經在這家公司工作。 同樣也是因為考慮技術的不成熟，於是後來加入了 OpenAI。 感興趣的同學可以去看一下我們那期節目。

最終，2019 年大衛把 Leap Motion 公司賣給了競爭對手 Ultrahaptics。 隨後，他成立了一個新的工作室來探索一些新的機會。 恰好在這個時候，AI 在生成藝術方面取得了突破。 Transformer 架構的出現徹底改變了圖像合成的歷史。 從此，多模態的深度學習整合了 NLP（自然語言處理）和計算機視覺的技術，成為了圖像合成的藝術方法。 於是，借著生成式 AI 的東風，大衛創建了 Midjourney。

到目前為止，公司團隊成員僅僅有 11 個人，其中包括 1 位創始人、8 位研發人員、1 位法務、1 位財務。 在公司的構成中，完全沒有產品經理、市場銷售人員。 除了創始人和兩個支持性的崗位（法務和財務）以外，80% 的人員都是研發人員。 而且，作為中間力量的研發成員，一半（也就是 4 個人）都是尚未畢業的大學生。

雖然這 4 名大學生都有一些實操甚至是創業經歷，但是確實經驗有限，而且也並不是畢業於頂尖的名校，跟 OpenAI 相比還是差了很多。 剩下的幾位研發人員都有著比較豐富的職業經歷。

在聚攏人才之後，大衛也進一步明確了自己對於 Midjourney 的理念。 大衛將公司的 logo 設計成了一艘在波浪中航行的帆船，意為水既危險又是文明的驅動力。 懂得如何與水一起生活和工作的人類，將有能力在水中游泳、坐船、築壩、發電，從而更好的生活。 因此，大衛認為 AI 是人類想像力的引擎。

然而，在當時的生成式 AI 的競爭格局上，有這樣雄心壯志的團隊並不只是 Midjourney 一家。 例如，Stable Diffusion 的母公司 Stability AI 在創立的時候也聲稱要將自己的使命定格為成為世界領先的開源 AI 公司，並且發揚將 AI 共享於全世界的理念。

但是口號喊得震天響，理念終歸不能當飯吃。 情懷滿滿的大衛，之後是怎麼解決一系列公司融資盈利的問題的呢？

從今天來看，Midjourney 的盈利模式看上去十分簡單，就是透過付費訂閱的商業模式，按月向使用者收取費用。 它的標準有三種套餐，分別是 10 美元/月、30 美元/月以及 60 美元/月。

不過，這樣的模式想要行得通，首先得解決兩大關鍵性問題：

*   第一點，憑什麼讓使用者產生付費的意願？
*   第二點，大模型訓練所需要的高昂成本怎麼解決？

我們先來說說第一點。 實際上，當 AI 的圖像生成技術開始發展的時候，很多使用者並不覺得這種技術是需要付費的。 原因就在於，當時像 Stable Diffusion 這樣的行業龍頭，為了吸引大量的開發者，最大程度的把模型用起來，因此採取了開源的模式。

和 DALLE、Midjourney 不同，Stable Diffusion 是完全免費的，而且不限次數，任何人都可以用。 雖然它對硬體有著一定的要求，但是也能在幾秒鐘內生成高清的圖像。 這樣的好處在於，開源社群會齊心協力的完善模型的文檔，解決技術問題。 這使得代碼的迭代速度非常快，優化效率遠遠的高於閉源系統。 但是缺點也很顯而易見，就是商業化不夠直接，可能為別人做了嫁衣。

相較之下，Midjourney 就採用了不那麼開放的閉源系統。 如果說閉源系統真的有什麼好處的話，那可能就只能說是針對性更強了。 因為模型是閉源的，並且通過龐大的用戶量積累了獨有的數據集，那麼就可以根據用戶的需求不斷的針對性的訓練模型。 長期來看，更利於建立競爭壁壘。

在探索用戶需求的這方面，大衛採取了產品上線後邊測試邊改進的辦法。 比如說，Midjourney 最開始其實很慢，需要 20 分鐘才能夠生成一張高品質的圖片。 後來，團隊就推出了一個 15 秒生成圖片、但是品質沒有那麼高的版本。 經過多輪的測試，團隊也了解到速度和品質其實都只是表象，因為不同用戶的選擇實際上是多維度的。

在針對用戶需求進行調整之後，無論是創意行業的設計者還是普通的愛好者，都能夠透過 Midjourney 來滿足自身的繪畫需求。

除了在了解新用戶需求方面以外，在使用流程方面，Midjourney 也不像 Stable Diffusion 需要做本地化的部署，操作十分簡潔，對顯卡和硬體性能也幾乎沒有要求。 雖然是閉源的，但 Midjourney 在使用的難易度上，卻更像一個非常親民的大眾化產品。 於是，Midjourney 獲得了大量用戶之後，養成了用戶的使用習慣，而且在開啟付費訂閱之後，就進一步加強了用戶的黏性。

剛才也提到，Midjourney 在硬體方面對用戶幾乎沒有什麼要求。 而這樣的原因則是因為 Midjourney 它所有的圖片都是在雲端完成訓練的。 但是如此龐大的雲的計算量必然需要高額的成本。 這就回到了剛才的第二個問題，在沒有融資的情況下，在雲端進行大模型訓練所需要的高昂成本應該怎麼解決？

實際上，大衛解決這個問題的方法很簡單，幾乎不可思議。 當大衛需要找到一個雲供應商提供 1 萬個 GPU 的時候，他就直接給雲供應商的負責人發了一封電子郵件，結果對方就直接把這些資源都給了，完全不需要任何風險投資。 我估計聽到這，很多人都要驚掉下巴了，這種事情在現實中真的可能嗎？

當然了，供應商也不是抽風了，而是看中了大衛之前的成就和聲譽。 大衛在之前的創業已經獲得了很好的聲譽。 打從他創辦 Leap Motion 的時候就有一個觀點，他覺得技術的最大限制不是規模、成本或者速度，而是人們如何與之互動。 Leap Motion 的手勢互動是一個嘗試，到了 Midjourney 這裡，他開始使用更短的繪畫關鍵詞（prompt）推動 AI 的生產。

這樣的理念吸引了每一個了解大衛的人，也讓他得到了雲供應商的支持。 但是在獲得了供應商的鼎力支持後，大衛也仍然要面對算力捉襟見肘的問題。

從成本上來說，Midjourney 大約 10% 的雲成本是用来訓練的，90% 是用戶製作圖像的推理所需。 所以幾乎所有的成本都用在了製作圖像上。 為了解決這一點，Midjourney 在世界 8 個不同的地區設立了自己的伺服器，比如說韓國、日本或者荷蘭等等。 在每個時區的夜間，當地人都在睡覺，這時候就沒有人使用 GPU 了，Midjourney 就可以充分利用這些算力，實現 GPU 的負載平衡。

實際上，這種依賴雲端伺服器來降低成本、加快模型訓練的做法，與目前很多公司訓練大模型的策略都十分相似。 在算力已經越來越成為大模型訓練瓶頸的今天，如果在訓練開發環節直接調用雲端的大模型和 AI 算力資源，完成後一鍵再分發到用戶的終端上，就可以大大的降低成本，減少很多的工作量。 因此，Midjourney 雲上計算的這一步棋其實是摸準了時代的方向。

互聯網的引進之路已經說明，無論是 To B 還是 To C 行業，都在追求越來越集約精簡的終端硬體、越來越低門檻的交互入口，以及越來越輕盈的軟體應用。 所以說，大模型從雲入端是模型服務商實現商業化的必爭之地。

從 Midjourney 看似不可思議的創業經歷，我們也可以發現，在這次 AIGC 的浪潮中，能夠脫穎而出的企業和團隊，未必是財大氣粗的頭部大廠。 因為在生成式 AI、雲計算等技術逐漸抹平了大企業和中小企業之間的技術成本差距之後，各個企業真正比拼的只剩下人才、創意和執行力。 而這也是為什麼 Midjourney 這種僅僅只有十幾個人的小團隊能夠脫穎而出的原因。

我們之前也做過節目介紹，相比於微軟、Google 這種公司來說，OpenAI 的人數也很少。 因為這種依靠少數尖端人才組建的團隊具有大企業所沒有的靈活性、創建性和魄力。 而這種小團隊的創意靈感，如果要是想真正的在市場社會中紮下根，那就離不開對用戶多樣化、個性化需求的跟踪。

這是因為 AI 技術的泛用性決定了它絕對不是針對於某一行業、或者某一個人群、或者是某一類企業的技術。 只有在這種多樣化的需求中盡可能的去滿足不同層級用戶的特定需求，一款產品才能夠真正的具有長遠的生命力。 既服務了所有人，又不忽視每一個特殊的人，這或許就是 Midjourney 成功的最大原因。

好了，今天的分享就到這裡。 感興趣的小伙伴們歡迎訂閱我們的頻道，我們下期再見！

**主要修改：**

*   **用語更正式：** 避免過多口語化的表達，例如將「跟大家來聊一聊」改為「想和大家聊聊」。
*   **結構更清晰：** 將文稿分為段落，使邏輯更清晰。
*   **語氣更專業：** 調整部分語氣，使其更符合專業的解說風格。
*   **補充細節:** 潤飾部分內容讓資訊更加精準

希望以上整理對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>59. [2023-04-25] 【商业】王小川与李彦宏的20年恩怨</summary><br>

<a href="https://www.youtube.com/watch?v=94kLTkCPA0M" target="_blank">
    <img src="https://img.youtube.com/vi/94kLTkCPA0M/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】王小川与李彦宏的20年恩怨

好的，這是我整理後的文稿，著重於結構清晰、重點突出，並修正了一些口語化的表達：

**標題：王小川與李彥宏的隔空罵戰：AI大模型時代的恩怨再起**

**引言：**

前搜狗創始人王小川，因與老對手百度李彥宏的一場關於AI技術差距的隔空論戰，再次成為焦點。

**爭論焦點：**

*   **國內互聯網科技公司與OpenAI在技術層面的差距有多大？**

    *   李彥宏認為百度文心一言與OpenAI差距僅兩個月左右。
    *   王小川駁斥此觀點，認為不切實際。
*   **OpenAI成功的原因？**

    *   李彥宏認為大廠不重視此方向，才讓創業公司有機會，並建議創業公司不要重複造輪子。
    *   王小川認為歷史上的重大變化都伴隨創業公司的機會，創業公司跑得更快，並強調中國公司也能做出優秀的AI產品。

**百度方面的回應：**

*   百度集團副總裁肖陽回應：王小川脫離一線太久，對國內AI技術缺乏了解，並提及搜狗當年未能取代百度的失敗案例。
*   王小川反擊：諷刺李彥宏脫離一線更久，判斷力更差。

**王小川與李彥宏的過往恩怨：**

*   **清華同門，立場不同：** 王小川與肖陽均畢業於清華大學計算機科學與技術專業，但因商業利益立場不同。
*   **多次交鋒，積怨已深：** 王小川與李彥宏在搜索引擎、輸入法、瀏覽器等多個領域交手，此次在大模型領域再次相遇。
*   **20年積怨：**
    *   2003年，王小川加入搜狐，目標是「滅掉百度」。
    *   王小川帶領團隊研發搜狗搜索，但未能超越百度。
    *   王小川認為自己技術比李彥宏好，但運氣不如他。
    *   搜狗接連推出輸入法和瀏覽器，對百度造成威脅，百度也相繼推出類似產品。
*   **多次隔空互懟：**
    *   2013年，王小川稱百度收購91助手是為無線搜索鋪路，並預測百度若無線戰略失敗，將淪為下一個雅虎。
    *   2017年，王小川稱百度是一家沒有戰略的公司，並調侃百度總裁更懂百度（起因是百度PPT出現錯別字）。
    *   搜狗上市時，王小川發布帶有李彥宏對話消息的截圖，諷刺百度未推送搜狗上市消息。
    *   王小川表示不害怕聲量大的百度，因為百度一年換一個戰略。
*   **業務競爭：** 搜狗與百度在百家號/搜狐號、度小滿/一點借錢等業務上存在競爭。
*   **和解未果：** 2010年，李彥宏曾邀請王小川加入百度任CTO，但因王小川要求全資收購搜狗而告吹。

**AI大模型的新戰場：**

*   **百度率先推出文心一言。**
*   **王小川創立百川智能，加入大模型競爭。**
*   **對AI的早期布局：**
    *   李彥宏預言AI是互聯網的下一幕 (2016)。
    *   搜狗在語音輸入、跨語言信息處理等方面發力，並推出實時機器翻譯技術 (2011-2017)。
    *   搜狗推出全球首個全仿真的智能AI主持人 (2018)。
    *   搜狗輸入法加入AI的逐字校對、AI長句預測等功能 (2019)。
*   **路線之爭：**
    *   王小川認為搜狗專注於自然交互和知識計算。
    *   百度則更多的是人臉識別和無人駕駛。
*   **百度AI的實力：** PaddlePaddle飛槳是國內模型最完整、應用最廣泛的AI技術框架。
*   **王小川的百川智能：**
    *   目標：打造國際上最好的大模型和顛覆性產品，追趕ChatGPT。
    *   團隊正在訓練規模達到500億參數的大語言模型，將應用於搜索、多模態、教育、醫療等領域。
    *   預計國內大模型今年內可追趕ChatGPT 3.5水平，GPT-4/5 需三年左右。
*   **王小川的信心：** 搜狗有很強的AI背景，且是以語言為核心的AI。
*   **人才儲備：** 百川智能招募了來自多家科技大廠的AI人才，與清華大學等學術機構合作。
*   **大模型競爭格局：** 王小川認為最終只有不到5個大模型會拿到通行的船票。
*   **王小川的決心：** 此次下場押上了自己的名字，回應了周鴻禕關於搜狗姓氏的留言。

**結語：**

王小川與李彥宏的恩怨是否會一語成讖？百川智能與文心一言，誰將更勝一籌？讓我們拭目以待。

**總結：**

*   **簡化口語化表達，例如將"今天呢我們來聊一聊"替換為"本文探討"。**
*   **使用標題、副標題和要點，使文章結構更清晰。**
*   **將內容分成幾個部分，方便讀者閱讀和理解。**
*   **用更精煉的語言概括長句，突出重點。**
*   **添加了少量必要的連接詞，使內容更流暢。**

希望這個版本對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>58. 【人工智能】10个问题感受Vicuna-13B(小羊驼)超强的AI写作能力 | Vicuna-13B | 地表最强开源大语言模型没有之一 | 300美元你值得拥有！</summary><br>

<a href="https://www.youtube.com/watch?v=DOgjiV75VLM" target="_blank">
    <img src="https://img.youtube.com/vi/DOgjiV75VLM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】10个问题感受Vicuna-13B(小羊驼)超强的AI写作能力 | Vicuna-13B | 地表最强开源大语言模型没有之一 | 300美元你值得拥有！



---

</details>

<details>
<summary>57. [2023-04-24] 【人工智能】陆奇的大模型世界观 | 万字长文演讲20分钟精华版 | 附65页精彩PPT | 如何看待OpenAI/ChatGPT/大模型LLM所带来的历史拐点 | 奇绩创坛最新演讲分享</summary><br>

<a href="https://www.youtube.com/watch?v=LQaPKC4nRKo" target="_blank">
    <img src="https://img.youtube.com/vi/LQaPKC4nRKo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】陆奇的大模型世界观 | 万字长文演讲20分钟精华版 | 附65页精彩PPT | 如何看待OpenAI/ChatGPT/大模型LLM所带来的历史拐点 | 奇绩创坛最新演讲分享

好的，這份文稿整理如下：

**標題：陆奇上海分享会精华总结：大模型时代的关键信息与创业机遇**

**引言：**

*   最佳拍档大飞对奇绩创坛创始人兼CEO陆奇在上海小规模分享活动的精华内容进行了总结，这是一次关于大模型时代的宏观思考，涵盖拐点动因、技术演进、创业机会以及创业建议。
*   陆奇是AI布道者，曾任职于IBM、雅虎、微软、百度等全球科技巨头，是华人顶流。他以勤勉著称，但坦言现在已跟不上大模型时代的速度。

**一、陆奇与Sam Altman的忘年之交**

*   陆奇与OpenAI CEO Sam Altman相识于2005年，当时陆奇担任YC中国及YC全球研究院院长，而Altman是YC的接班人。
*   两人在今年春节期间深入交流，共同探讨ChatGPT和OpenAI所带来的新范式。

**二、三位一体结构演化模式**

*   陆奇用“三位一体”结构演化模式来理解ChatGPT，该模式适用于任何复杂体系，包括个人、公司、社会、数字化体系等。
    *   **信息系统：** 从环境中获取信息。
    *   **模型系统：** 对信息进行表达、推理和规划。
    *   **行动系统：** 与环境交互，达成目的。
*   陆奇认为，当前大部分数字化产品和公司本质上都是“信息搬运”公司，即便如此也已改变了世界。

**三、拐点的内在动因：从边际成本到固定成本**

*   以Google的诞生为例，Google将获取信息的边际成本降为固定成本，改变了行业。
*   大模型时代的拐点与此类似，大模型的出现让模型成本从边际走向固定。

**四、模型的重要性**

*   人是模型的组合：认知模型、任务模型、领域模型。
*   大模型将逐渐学会这些模型的能力，因此人的价值在于见解。
*   这次大模型的拐点会影响服务经济中的白领蓝领，除非他们有独到见解。
*   陆奇认为，下一个时代的典型职业是创业者和科学家。

**五、未来拐点：自动驾驶、机器人、空间计算**

*   下一个拐点将是自动驾驶、机器人、空间计算的组合，使得行动无处不在。
*   未来15-20年，模型就是知识，将无处不在；自动化、自主化动作也将无处不在。
*   最终，人和数字化技术共同进化，达到通用智能(AGI)。
    *   AGI的四大要素：涌现（emergency）、代理（agency）、功能可见性（affordance）和具象（embodiment）。

**六、OpenAI的技术突破**

*   OpenAI在技术上领先，其融资结构也经过精心设计，不受股东制约，最终目标是回馈社会。
*   OpenAI的关键技术演进：
    *   **GPT-1:** 使用预训练提高语言理解。
    *   **GPT-2:** 迁移学习，提高语言理解能力。
    *   **DOLL-E:** 跨模态。
    *   **GPT-3:** 小样本泛化能力。
    *   **GPT-3.5:** 指令遵循和微调。
    *   **GPT-4:** AI工程化。
    *   **GPT plugins:** 生态化。
*   伊利亚·苏茨科维尔（OpenAI联合创始人兼首席科学家）的信念：
    *   模型架构要足够深（bigness is betterness）。
    *   任何范式改变都需要一个引擎，GPT就是这个引擎。
    *   高效压缩信息意味着已经得到了知识。

**七、Transformer的突破**

*   Transformer可以把信息进行高度压缩，拥有世界模型，能持续提高模型能力。
*   陆奇认为自己做了20年的知识图谱，是时候放弃并转向transformer。

**八、OpenAI未来发展方向**

*   让模型更稀疏。
*   延长attention window。
*   增加递归因果关系的推理功能。
*   提供更多的模态、token空间、模型稳定性、潜在空间、计算和基础架构工具等。

**九、大模型时代的淘金机会**

*   陆奇认为，大模型是平台型机会，平台需具备以下特点：
    *   开箱即用。
    *   简单的商业模式。
    *   杀手级应用（如ChatGPT）。
*   创新要技术驱动和需求拉动相结合，长期以技术驱动为主。
*   创业公司可分为三类：
    *   做数字化基础的。
    *   用数字化解决人的需求的。
    *   改变物理世界的。

**十、陆奇对创业者的建议**

*   不要轻举妄动，不要浮夸，勤于学习，行动导向。
*   从产品开发、技术研发、满足需求、商业价值探索四个方面思考变革方向。
*   创始人最重要的是愿力（对未来的独到判断）和心力（信念、坚持、韧劲）。
*   初创团队应尽可能使用工具加速想法、产品和迭代。
*   要学习工具，学会写AI提示。

**十一、总结与展望**

*   陆奇基于认知模型框架，对当下的大模型拐点做出了论证和预判。
*   未来可能被AI取代的工作，关键在于“见解”（insights, vision）。
*   超过AI的运算能力，对可能性坚定信念，是人类最终极强大的能力。

**整理说明：**

*   将原稿口语化的表达改為更正式的書面語。
*   提取關鍵資訊，並用條列式呈現，方便閱讀。
*   針對較為抽象的概念，加入簡單的解釋。
*   將內容分類，使整體結構更清晰。
*   刪除重複或不必要的資訊，使內容更精簡。

希望能幫助您更好地理解和使用這份資料！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>56. 【人工智能】10分钟带你了解HuggingGPT是如何工作的 | HuggingGPT aka JARVIS | 微软与浙江大学完成</summary><br>

<a href="https://www.youtube.com/watch?v=TLqOfceh9Kc" target="_blank">
    <img src="https://img.youtube.com/vi/TLqOfceh9Kc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】10分钟带你了解HuggingGPT是如何工作的 | HuggingGPT aka JARVIS | 微软与浙江大学完成



---

</details>

<details>
<summary>55. 【人工智能】如何安装Anaconda | AI程序开发必备 | 最好用的开源python发行版本</summary><br>

<a href="https://www.youtube.com/watch?v=iI94ed5Jn84" target="_blank">
    <img src="https://img.youtube.com/vi/iI94ed5Jn84/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】如何安装Anaconda | AI程序开发必备 | 最好用的开源python发行版本



---

</details>

<details>
<summary>54. [2023-04-22] 【人工智能】15分钟Auto-GPT保姆级安装教程 | 如何用Docker在MacOS下安装AutoGPT</summary><br>

<a href="https://www.youtube.com/watch?v=Oke225G7_4s" target="_blank">
    <img src="https://img.youtube.com/vi/Oke225G7_4s/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】15分钟Auto-GPT保姆级安装教程 | 如何用Docker在MacOS下安装AutoGPT

好的，以下是用中文整理後的文稿，我嘗試將它整理得更像一份教學文件，並加入一些結構和標題：

**AutoGPT 在 Mac OS 上的安裝方法**

**簡介**

大家好！我是小郭，歡迎來到最佳拍檔。 今天將為大家分享如何在 Mac OS 上安裝 AutoGPT。

**AutoGPT 運行環境**

AutoGPT 支援三種運行環境，官方建議選擇其中一種即可。這三種環境分別是：

1.  **VSCode + Devcontainer**
2.  **Docker**
3.  **直接運行在主機上 (需要 Python 3.10 或更高版本)**

為了方便安裝，本教學將採用 Docker 的方式。

**先決條件**

在安裝 AutoGPT 之前，請確保已安裝 Docker Desktop。

**步驟一：安裝 Docker Desktop**

1.  **下載 Docker Desktop:** 前往 [docker.com](https://www.docker.com/) 下載 Docker Desktop。

    *   **Intel 芯片:** 直接點擊頁面上的下載按鈕。
    *   **Apple 芯片 (M1/M2):** 點擊蘋果 logo 下載。
2.  **安裝:** 下載完成後，雙擊檔案並將 Docker 圖示拖曳到 Applications 資料夾進行安裝。 (如果您已安裝過，則無需重複此步驟)

**步驟二：設定 Docker Desktop**

1.  **設定國內镜像源:** 設定國內的 Docker 镜像源，以加快镜像加载速度。
2.  **設定 Docker CLI 工具:**

    *   **開啟設定:** 點擊 Docker Desktop 介面上的齒輪圖示進入設定。
    *   **Docker CLI 設定:** 預設選項通常會將 Docker CLI 放在您的 Home 目錄下的 `docker/bin` 資料夾。為了避免手動將該目錄添加到 `PATH` 環境變數，建議選擇 "System" 選項。這樣 Docker 會自動將可執行檔案放在 `/usr/local/bin` 目錄下。
    *   **Docker Engine 設定:** 在 "Docker Engine" 設定中，找到 "mirrors" 欄位，填寫一個國內的 Docker 镜像源地址。 (例如：阿里云等)

**步驟三：驗證 Docker 安裝**

開啟終端機，輸入以下指令：

```bash
docker --version
```

如果能正確顯示 Docker 版本，則表示 Docker 已成功安裝。

**步驟四：下載 AutoGPT 原始碼**

您可以透過以下兩種方式下載 AutoGPT 的原始碼：

1.  **透過瀏覽器直接下載 (不推薦):** 容易下載到不穩定的 master 分支。
2.  **使用 Git (推薦):** 方便後續更新。

**重要提示：** 請務必下載 `stable` 分支，而不是 `master` 分支，以避免遇到安裝問題。

**使用 Git 下載 AutoGPT 原始碼:**

在終端機中執行以下指令：

```bash
git clone -b stable --single-branch https://github.com/Significant-Gravitas/Auto-GPT
```

下載完成後，使用 `cd` 指令進入 AutoGPT 目錄：

```bash
cd Auto-GPT
```

**步驟五：構建 Docker 镜像**

1.  **修改 Dockerfile (可選，但推薦):** 使用文字編輯器 (例如：VS Code) 開啟 AutoGPT 目錄下的 `Dockerfile` 檔案。
2.  **修改镜像源 (加速构建):** 修改 `Dockerfile` 中的镜像源，使用國內的镜像源可以加快構建速度。
    *   在 `apt-get update` 之前，新增一行修改系統的軟件包镜像源 (請自行查詢可用的國內镜像源)。
    *   在 `pip install --user -r requirements.txt` 這一行，在 `--user` 和 `-r` 之間增加国内的 pip 镜像源。 例如：`pip install --user -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt`
3.  **構建 Docker 镜像:**

    在 AutoGPT 目錄下，執行以下指令：

    ```bash
    docker build -t autogpt .
    ```

    **注意：** 指令最後的 `.` 不能省略。

    第一次執行可能需要較長時間，因為需要下載許多程序包 (例如：Firefox、Chrome 等)。

    構建完成後，可以使用以下指令查看是否成功：

    ```bash
    docker images
    ```

    如果看到 `autogpt` 的镜像記錄，則表示構建成功。

**步驟六：準備 OpenAI API Key**

1.  **取得 API Key:** 前往 [OpenAI 官方網站](https://platform.openai.com/account/api-keys) 申請 API Key。
2.  **建立新的 API Key:** 如果您之前沒有申請過，請建立一個新的 API Key。
3.  **複製 API Key:** 申請成功後，請務必複製 API Key，因為之後無法再次查看。
4.  **設定 Key 名稱:** 可以給 Key 設定一個容易識別的名稱 (例如：`auto-gpt`)。

**步驟七：配置 AutoGPT**

1.  **複製環境變數範本:** 將 AutoGPT 目錄下的 `env.template` 檔案複製一份，並更名為 `.env`。
2.  **編輯 `.env` 檔案:** 使用文字編輯器開啟 `.env` 檔案。
3.  **填入 OpenAI API Key:** 在 `.env` 檔案中找到 `OPENAI_API_KEY` 這一行，將剛剛複製的 API Key 貼上。
4.  **儲存檔案:** 儲存 `.env` 檔案。

**步驟八：執行 AutoGPT**

使用以下指令執行 AutoGPT：

```bash
docker run -it --name autogpt -v $(pwd):/app autogpt --gpt3only
```

*   `--name autogpt`：為容器指定名稱，方便後續操作。
*   `-v $(pwd):/app`：將當前目錄掛載到容器的 `/app` 目錄，使得容器可以存取本地檔案。
*   `--gpt3only`：如果沒有購買 ChatGPT-4 付費版本，則需要加上此參數，禁用 ChatGPT-4。

**重要提示：**

*   執行過程中需要保持翻牆軟件可用，並開啟系統代理，因為 Docker 也需要訪問國外網站。
*   第一次運行會提示輸入名字和 Role，您可以自行設定。

**執行 AutoGPT 后的操作**

*   **退出但不停止容器:** 按下 `Ctrl + p` 再加 `q` 即可退出，容器會在後台繼續運行。
*   **查看正在運行的容器:** 使用 `docker ps` 指令查看。
*   **重新進入容器:** 使用 `docker attach autogpt` 指令連接到容器介面。  (`autogpt` 是您在執行 `docker run` 指令時指定的容器名稱)
*   **停止容器:** 在容器介面按下 `Ctrl + c` 或輸入 `n`，會停止容器。
*   **啟動已停止的容器:** 使用 `docker start autogpt` 指令啟動已停止的容器。

**持久化存储 (可选，但推荐)**

默认情况下，AutoGPT 将数据存储在本地容器中。 如果容器被删除，则数据也会丢失。

为了实现持久化存储，您可以参考官方文档，配置 Redis 或 Pinecone 等外部存储服务。

在 `.env` 文件中配置 `MEMORY_BACKEND` 和相关参数 (例如：Redis 连接信息、Pinecone API Key 等)。

**總結**

以上就是在 Mac OS 上安裝 AutoGPT 的完整步驟。 感謝您的收看！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>53. [2023-04-21] 【人工智能】​Segment-and-Track Anything |  SAM-Track | 视频版SAM来了，分割/跟踪/编辑一切 | 现已开源 | 浙江大学计算机学院ReLER实验室</summary><br>

<a href="https://www.youtube.com/watch?v=uBYydYp7BB0" target="_blank">
    <img src="https://img.youtube.com/vi/uBYydYp7BB0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】​Segment-and-Track Anything |  SAM-Track | 视频版SAM来了，分割/跟踪/编辑一切 | 现已开源 | 浙江大学计算机学院ReLER实验室

好的，這是我整理後的文稿：

**主題：SAM-Track：Meta SAM模型解锁视频分割能力，实现视频中分割和跟踪一切物体**

**主要內容：**

*   **介紹：** 最佳拍檔的大飛介紹浙江大學ReLER實驗室開源的SAM-Track項目，该项目利用Meta的SAM模型，实现了视频分割和跟踪物体的功能。
*   **SAM-Track功能：**
    *   **视频分割和跟踪:** 可以在各种时空场景（街景、AR、细胞动画、航拍等）中分割和跟踪目标。
    *   **多物体跟踪:** 支持同时追踪超过200个物体。
    *   **高效性能:** 在单块显卡上即可运行。
    *   **分割方式:** 支持全自动和交互式分割。
        *   **全自动:** 展示了自动视频目标分割和跟踪的演示。
        *   **交互式:** 可以通过点击或框选的方式，指定对单个或多个目标物体进行分割和跟踪。
    *   **便捷使用:** 提供基于Gradio的web UI，方便用户开箱即用(需本地启动)。
*   **技术原理：** SAM-Track结合了SAM和最新的高效多物体跟踪算法DeAOT，实现高精度的视频目标分割和跟踪。
*   **项目进度：**
    *   **V0版本:** 已开源，支持全自动视频分割和跟踪。
    *   **V1版本:** 计划下周更新，支持交互式视频分割和跟踪。
*   **开源地址：** 将放到评论区。
*   **ReLER实验室：**
    *   **创立时间:** 2021年
    *   **创始人:** 浙江大学求是讲席教授楊易
    *   **项目成员:** 徐源佑（在读博士）、程阳铭（在读硕士）、李刘磊（科研助理）、杨宗鑫（博士后）、王文冠（百人计划研究员）和杨易（教授）。

**總結：**

SAM-Track项目成功扩展了Meta SAM模型的能力，使其能够应用于视频分割和跟踪领域。该项目具有高效、易用、功能强大的特点，为用户提供了强大的视频编辑和分析工具。

**整理說明：**

*   **精簡語言：** 避免口語化的詞彙，使用更正式的書面語。
*   **提取重點：** 歸納文稿的核心信息，將重點內容突出顯示。
*   **組織結構：** 將文稿按照邏輯順序重新組織，使其更易於理解。
*   **增加標題和總結：** 為文稿添加標題和總結，方便快速掌握內容。
*   **明確说明：** 说明了ReLER实验室的人员组成，方便大家了解这个团队。
*   **保持原文信息：** 在整理的過程中，盡量保留原文的核心信息，避免修改或刪減重要內容。

這個整理後的版本更易於閱讀和理解，也方便快速掌握SAM-Track項目的核心內容。希望对您有帮助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>52. [2023-04-19] 【编程】JDK新增史上最无用提案！竟然是为了简化Hello World？</summary><br>

<a href="https://www.youtube.com/watch?v=HwWsWrd3hyE" target="_blank">
    <img src="https://img.youtube.com/vi/HwWsWrd3hyE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【编程】JDK新增史上最无用提案！竟然是为了简化Hello World？

好的，這是我整理後的文稿，著重在結構化和提煉重點：

**標題：Java Hello World 提案引發的思考：專家們在想什麼？ (JEP 445 簡化 Hello World 提案)**

**核心論點：**

*   OpenJDK 提案 JEP 445 旨在簡化 Java Hello World 的寫法，希望讓初學者更容易入門。
*   作者 (大飛) 認為這個提案意義不大，Java 的複雜性並不在於 Hello World，真正的複雜性在於語法規範和併發模型。
*   作者質疑 Java 團隊捨本逐末，過度增加語法糖，反而失去了 Java 本身的特色，不如直接使用 Groovy 或 Kotlin。
*   作者呼籲大家在評論區分享對此提案的看法。

**內容摘要:**

1.  **背景：** 大飛跑了一天剛回來，本想休息，但還是想和大家聊聊。原本計畫介紹 Java JDK 20 的更新，但覺得沒什麼亮點，後來發現更令人失望的是 JEP 445 提案。
2.  **JEP 445 提案：**
    *   目的：簡化 Hello World 的寫法，讓初學者更容易學習 Java。
    *   理由：
        *   提供平滑的 Java 入口。
        *   方便教育工作者循序漸進介紹编程概念。
        *   幫助學生用簡潔方式編寫基本入門程序。
        *   減少編寫簡單程序的儀式感。
        *   不需要單獨介紹 Java 的初學者方言。
        *   不引入單獨的初學者工具鏈。
    *   範例：將原本複雜的 Hello World 程式碼簡化成 `System.out.println("Hello, world!");` 或直接 `void main() { System.out.println("Hello, world!"); }`。
3.  **大飛的觀點：**
    *   Hello World 的複雜性不是問題，現在的 IDE 已經能自動生成程式碼 (psvm + sout)。
    *   Java 的複雜性在於語法規範和併發模型，和 Hello World 無關。
    *   Java 版本更新過快，但大部分人仍使用 JDK 1.8，說明專家沒有理解用戶需求。
    *   Java 團隊不斷增加語法糖，越來越像 Kotlin 或 Groovy，失去了 Java 的本質。
    *   如果追求簡單，直接用 Groovy 或 Kotlin 即可。
4.  **總結：** 大飛對 JEP 445 提案表示失望，並邀請大家在評論區發表看法。

**可能的標籤：** Java, OpenJDK, JEP 445, Hello World, 编程, 語法糖, 版本更新, Groovy, Kotlin

**附加建議：**

*   **增加視覺呈現：** 如果是以影片形式呈現，可以在畫面中展示簡化的 Hello World 程式碼、JDK 版本的變化、以及 Groovy/Kotlin 的簡潔語法，讓觀眾更容易理解。
*   **加入數據佐證：** 可以引用一些數據，例如 JDK 1.8 的使用率、開發者對 Java 複雜性的反饋等，增加論點的可信度。
*   **更精確的定義複雜性：** 可以更具體的闡述Java語法規範和併發模型的複雜之處。

希望這個整理對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>51. [2023-04-18] 【人工智能】开源多模态模型MiniGPT-4发布 | 提前感受GPT-4的识图能力 | 基于Vicuna构建的LLM | 能够生成图片描述 | 根据手写文本指令构建网站</summary><br>

<a href="https://www.youtube.com/watch?v=-2OSLGL48Os" target="_blank">
    <img src="https://img.youtube.com/vi/-2OSLGL48Os/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】开源多模态模型MiniGPT-4发布 | 提前感受GPT-4的识图能力 | 基于Vicuna构建的LLM | 能够生成图片描述 | 根据手写文本指令构建网站

好的，這是整理後的文稿：

**標題：MiniGPT4：搶先體驗 GPT-4 的圖像理解與對話能力**

**引言：**

大家好，這裡是最佳拍檔，我是大飛。距離 GPT-4 首次公開問世已一個月。GPT-4 作為多模態大語言模型，不僅能生成文字內容，還能理解圖像輸入，讓使用者直接與圖片對話。OpenAI 曾演示 GPT-4 如何透過手繪草圖生成網站，令人印象深刻。圖像對話功能是 GPT-4 最令人期待之處，但目前尚未對外開放。

**MiniGPT4：實現圖像理解與對話**

今天介紹一個名為 MiniGPT4 的項目，由阿布杜拉國王科技大學的博士開發，提供類似 GPT-4 的圖像理解與對話能力，讓您搶先一步感受圖像對話的強大之處。

**MiniGPT4 的特點：**

1.  **多模態：** 能夠讀懂圖片，回答圖片內容、顏色，甚至風格。
2.  **中國團隊：** 5 位作者中有 4 位是中國人。
3.  **低成本：** 僅用 4 塊 A100 訓練 10 小時。
4.  **開源：** 項目 GitHub 地址在影片評論區。
5.  **提供演示地址：** 提供 7 個演示地址供大家體驗。

**MiniGPT4 的訓練方式：**

MiniGPT4 將 BLIP-2 的凍結視覺編碼器與凍結 LLM Vicuna 對齊，僅使用一個投影層。訓練分為兩個階段：

*   **第一階段（預訓練）：** 使用 4 塊 A100 在 10 小時內訓練約 500 萬對對齊的圖像和文本數據。
*   **第二階段（微調）：** 透過模型本身和 ChatGPT 一起創建高質量圖像文本對 (3,500 對)，並在對話模板中訓練，顯著提高模型生成的可靠性和整體可用性。此階段計算效率高，用一台 A100 僅需 7 分鐘左右。

**MiniGPT4 的能力：**

MiniGPT4 產生了許多新興的視覺語言能力，與 GPT-4 類似。例如，詢問 MiniGPT4 對粉紅色火烈鳥標誌的看法，它能詳細描述其設計、風格和適用場合。

**MiniGPT4 的應用前景：**

MiniGPT4 算法模型可以進行本地化部署。GPT-4 的先進能力可能歸因於其使用了更先進的大模型語言。未來基於大模型所製造的應用，在圖像、聲音、影片等領域的效果應該都不會太差。MiniGPT4 項目驗證了大語言模型在圖像領域的可行性，相信將有更多開發者投入，將 GPT-4 的能力延伸至音訊、影片等領域，帶來更多有趣的 AI 應用。

**結語：**

今天的分享就到這裡，感興趣的小伙伴們歡迎訂閱我們的頻道，我們下期再見！

**建議：**

*   建議先體驗線上演示環境。
*   有興趣本地部署 MiniGPT4 的朋友，可以在評論區回復，我們會錄製安裝和使用的教程。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>50. [2023-04-17] 【人工智能】Meta开源Animated Drawings项目算法 | 用AI让儿童涂鸦手绘人物动起来 | 32种动作多种配置参数任你选择</summary><br>

<a href="https://www.youtube.com/watch?v=RoGBzsOeiz0" target="_blank">
    <img src="https://img.youtube.com/vi/RoGBzsOeiz0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Meta开源Animated Drawings项目算法 | 用AI让儿童涂鸦手绘人物动起来 | 32种动作多种配置参数任你选择

好的，以下是我整理後的文稿，更易於理解和閱讀：

**標題：Meta開源AI工具Animated Drawings，讓兒童畫作動起來！**

**開場：**

大家好，這裡是最佳拍檔，我是大飛。今天要介紹Meta公司（前身為Facebook）在2021年推出的一款AI工具：Animated Drawings。

**Animated Drawings簡介：**

*   **特色：** 透過AI技術，讓兒童繪畫作品活起來。
*   **技術背景：** Meta團隊曾發表論文詳細講解其技術實現。
*   **最新進展：** Meta團隊已將論文中的算法開源至Github，短時間內獲得近4000個star，成長迅速。
*   **Github地址：** （放置於影片評論區）

**官方演示及功能介紹：**

*   **功能展示：** 上傳畫作後，可線上編輯人物的身體節點，調整動作，生成動圖，讓畫作人物動起來。
*   **使用步驟：**
    1.  **圖片上傳 (Upload):** 選擇或上傳畫作。
    2.  **編輯畫像 (Edit):** 調整線框，使人物完整呈現於線框中。
    3.  **提取細節 (Extract):** 使用畫筆和橡皮擦將人物與背景分離（若圖片邊界分明或使用平台提供的範例圖片，可跳過此步驟）。
    4.  **標記人物 (Mark):** 拖曳點和線，明確標記人物的頭部和軀體。
    5.  **生成動畫 (Animate):** 選擇動作，讓畫作人物動起來。提供32種動作，並按跳舞、玩耍、跳躍、行走等分類。

**本地部署與進階應用：**

*   **本地使用：**
    *   從Github克隆項目。
    *   本地安裝Animated Drawings。
    *   透過Python程式碼開啟動畫視窗。
*   **配置選項：**
    *   切換角色。
    *   應用不同動作。
    *   更改輸出格式。
*   **進階功能範例：**
    *   生成透明GIF圖片的動作效果。
    *   在同一場景中支持多個動作角色。
    *   為動畫添加背景。
*   **自定義動畫角色：** 可透過特定腳本實現。
*   **更多配置與功能：** 參考Github項目上的說明文件。

**總結與展望：**

*   Animated Drawings雖然是2021年的產品，但結合ChatGPT、Midjourney等AI工具，有潛力開發出更多有趣玩法，例如動畫書、動畫片等。
*   鼓勵觀眾嘗試，並分享或投稿作品。

**結語：**

今天的分享就到這裡，對我們頻道感興趣的小夥伴們，歡迎訂閱，我們下期再見！

**改善說明：**

*   **添加標題和副標題：** 使文章結構更清晰。
*   **使用條列式清單：** 整理步驟、功能、進階應用，更易於閱讀。
*   **簡化語言：** 刪除口語化詞彙，使文稿更專業。
*   **突出重點：** 使用粗體字標記關鍵詞，方便快速瀏覽。
*   **邏輯整理：** 將相似內容歸類，使文稿更具邏輯性。
*   **補充說明：** 對於較複雜的概念或步驟，進行更詳細的解釋。
*   **加入轉折語氣：** 使文章更自然流暢。

希望這個版本對您有幫助！如有任何其他需要調整的地方，請隨時告知。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>49. [2023-04-16] 【安全】PassGAN | 新型AI密码破解工具 | 基于生成式对抗网络GAN | 51%的密码可在1分钟破解 | 破解7位数密码只需要6分钟 | 提高密码安全性的三个方法</summary><br>

<a href="https://www.youtube.com/watch?v=QNRUttmNVKM" target="_blank">
    <img src="https://img.youtube.com/vi/QNRUttmNVKM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【安全】PassGAN | 新型AI密码破解工具 | 基于生成式对抗网络GAN | 51%的密码可在1分钟破解 | 破解7位数密码只需要6分钟 | 提高密码安全性的三个方法

好的，以下是整理后的文稿，更著重於重點提取和邏輯順序，使其更易於理解和吸收：

**主題：AI 破解密碼的威脅與防範**

**引言：**

*   ChatGPT 推出短短四個月，已對世界產生重大影響，AI 技術進化的優點與風險備受討論。
*   Home Security Heroes 發布報告，顯示新型 AI 密碼破解工具 PassGAN 的驚人破解能力。

**PassGAN 破解能力：**

*   測試：研究人員使用 PassGAN 測試 1568 萬組密碼。
*   結果：
    *   51% 的密碼在一分鐘內被破解。
    *   65% 的密碼在一小時內被破解。
    *   71% 的密碼在一天內被破解。
    *   81% 的密碼在一個月內被破解。
*   7 個字符的密碼（含數字、大小寫字母和符號）可在 6 分鐘內破解。
*   11 位以內的純數字密碼幾乎瞬間被破解。
*   18 位字符密碼：
    *   純數字：需要 10 個月。
    *   包含數字、大小寫字母和符號：需要 60 億年。

**PassGAN 破解速度快的原因：**

*   **生成式對抗網路 (GAN)：** 從洩漏的密碼中自主學習真實密碼的分布，無需手動分析。
*   **密碼習慣分析：** 分析用戶的密碼設定和使用習慣，進行快速演算。
*   **RockYou 數據集訓練：** 利用該數據集獲得的知識，創建遵循神經網路分布的新樣本密碼。

**應對 AI 破解算法的建議：**

1.  **使用強密碼：**
    *   密碼強度是關鍵因素。
    *   建議：至少 15 個字符，包含兩個大小寫字母、兩個數字和兩個符號。
    *   避免明顯規律，如常見單詞或句子。

2.  **定期修改密碼：**
    *   建議：每 3 到 6 個月更改一次。
    *   懷疑帳戶被盜或密碼洩漏時立即更改。

3.  **不在多個帳戶上使用相同密碼：**
    *   為每個帳戶生成新密碼。
    *   使用密碼管理器方便管理。

4.  **使用密碼格式微調技巧：**
    *   保持基本格式，對每個帳戶進行細微調整。
    *   例：`5711@FB_FaceBookIsLocked` (Facebook)，`1286_IG@IGIsLocked` (Instagram)。

**總結：**

*   AI 時代信息安全日益重要。
*   加強安全意識，保護個人信息。
*   希望大家都使用強密碼，定期更換，並為每個帳戶使用不同的密碼。

**提醒：**

*   OpenAI 的 ChatGPT 也曾出現過數據安全問題，可見無人能倖免，安全意識要時刻警惕。

希望這個整理後的版本對您有幫助！ 讓我再針對你的需求做調整。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>48. [2023-04-16] 【人工智能】15分钟通俗讲解AutoGPT | 基本原理和流程</summary><br>

<a href="https://www.youtube.com/watch?v=iO6j7WfQeo8" target="_blank">
    <img src="https://img.youtube.com/vi/iO6j7WfQeo8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】15分钟通俗讲解AutoGPT | 基本原理和流程

好的，這是我整理後的文稿，我著重於修正語氣、刪除口語化贅詞、並將內容分段，使其更易於閱讀和理解。

**標題：AutoGPT 深入解析：原理、流程與應用**

**開場白**

大家好，這裡是最佳拍檔。我是大飛。 昨天我們做了一期關於 AutoGPT 的節目，許多網友對此表現出濃厚興趣。今天，我們將更深入地探討 AutoGPT 的相關內容。 若有不足或錯誤之處，歡迎在評論區指正。

**AutoGPT 簡介**

AutoGPT 是一個基於 GPT-4 的開源應用程式，目前仍處於實驗階段。 它可以根據使用者指定目標，自動生成所需提示，並執行需要多個步驟才能完成的項目。 整個過程無需人類干預和指導。

AutoGPT 本質上是一個自主 AI 代理。它可以掃描互聯網，或執行使用者電腦上能夠執行的任何命令。 然後，它將結果返回給 GPT-4，從而判斷結果是否正確，以及接下來該做什麼。

**AutoGPT 基本運行流程**

一般使用 AutoGPT 時，使用者會在終端輸入目標，描述 AI 任務的名稱、角色等，並指定最多五個要實現的目標（不能超過五個）。

輸入這些內容後，AutoGPT 會自動生成所需提示，然後開始執行多個步驟的任務，過程中無需人類干預和指導。

**AutoGPT 運行流程範例**

假設我們想讓 AutoGPT 協助撰寫一篇關於太空的文章。 我們可以設定如下目標：「請你寫一篇關於太空的文章」。

AutoGPT 的運行步驟大致如下：

1.  **搜尋：** AutoGPT 會在 Pinecone 向量資料庫中查找是否已有關於太空的文章。（Pinecone 是一個儲存數據的地方，與傳統二維表不同。）
2.  **生成提示：** 如果 Pinecone 資料庫中沒有相關文章，AutoGPT 會使用 GPT-4 生成提示。 例如：「太空是什麼？」並使用 GPT-4 回答該提示。
3.  **儲存：** 生成的提示和回答會被 AutoGPT 儲存在 Pinecone 資料庫中，並作為文章的第一段。
4.  **重複：** AutoGPT 會繼續使用 GPT-4 生成新的提示（例如：「太空有什麼特點？」），並用 GPT-4 回答該提示。 這些提示和問答同樣會被儲存在 Pinecone 資料庫中，並作為文章的第二段。
5.  **完成：** AutoGPT 會重複此過程，直到文章達到一定長度、足夠完整，或達到字數、時間限制，才會結束任務。
6.  **呈現：** 最後，AutoGPT 會將生成的文章展示給使用者，並詢問是否滿意。
7.  **反饋：** 若使用者滿意，則結束任務；若不滿意，AutoGPT 會根據反饋修改或補充文章。

**如何理解 AutoGPT**

要理解 AutoGPT，首先要了解 GPT-4。 GPT-4 的能力毋庸置疑，且相較於 GPT-3，它支援多模態能力。

然而，GPT-4 並非完美，它無法主動做事，只能根據人類給予的提示 (Prompt) 進行回答或寫作。 若不給予提示，或給予模糊的提示，它便無所適從。

AutoGPT 旨在解決 GPT-4 的上述問題。 它是一個可以自己給自己提示的程式，能夠根據設定的目標和任務，自動生成合適的提示，並利用 GPT-4 回答和執行這些提示。 這樣，GPT-4 便能完成更複雜、需要多個步驟才能完成的任務，且無需人類持續給予提示。

**AutoGPT 的實現原理**

AutoGPT 主要透過 Pinecone 向量資料庫實現上述功能。 Pinecone 可以儲存和檢索大量數據，幫助 AutoGPT 記住過去的行為和目標。 AutoGPT 會將生成的提示和 GPT-4 生成的結果儲存在 Pinecone 資料庫中，並根據這些數據評估自身是否已達成任務目標。 若未達成目標，AutoGPT 會繼續生成新的提示，並用 GPT-4 執行；若已達成目標，則停止生成提示，並將結果返回給使用者。

**AutoGPT 工作流程細節**

1.  **理解角色和目標：** AutoGPT 如何理解人類設定的角色和目標？ 這主要是透過 GPT-4 的零樣本學習 (Zero-Shot Learning) 功能實現。 零樣本學習讓 GPT-4 可以根據描述或定義學習新概念，並利用這些概念生成新內容。 AutoGPT 會根據人類給予的角色和目標描述，學習角色和目標的意義，然後利用這些概念生成新提示，以及執行相關任務。
2.  **任務拆解：** AutoGPT 如何將目標分解為子任務？ 又是如何知道應該將目標拆解成哪些子任務？ 實際上，AutoGPT 是透過使用 GPT-4 的多任務學習 (Multitask Learning) 功能實現的。 多任務學習讓 GPT-4 可以同時學習和執行多個任務，並根據這些任務之間的關係優化和協調它們。 AutoGPT 會根據人類給予的目標，自動將目標分解為多個子任務，並用 GPT-4 同時學習和執行這些子任務。
3.  **生成提示：** AutoGPT 如何生成提示？ 答案是模仿。 AutoGPT 會學習他人給予 GPT-4 的提示，並模仿生成提示。 它會根據自身想要做的事情，以及記住的事情，選擇合適的提示語，讓 GPT-4 執行更多任務，而無需人類持續指導。 具體而言，AutoGPT 透過 GPT-4 的少量樣本學習 (Few-Shot Learning) 功能實現此能力。
4.  **品質評估：** AutoGPT 如何評估自己是否保質保量地完成了子任務，或是否達成了既定目標？ AutoGPT 透過使用 GPT-4 的元學習 (Meta Learning) 功能實現此能力。 元學習讓 GPT-4 可以根據自身表現和結果，學習和改進學習和執行方法。 AutoGPT 可以根據自己生成的提示和結果，以及人類給予的反饋，來評估和改進自己的表現。

**元學習如何幫助 GPT-4 改进学习和执行方法**

要回答这个问题，必须从反馈学习说起。反馈就是别人或者你自己对你做的事情的评价，告诉你做的好不好对不对，有没有问题需不需要改进。元学习就是利用了这种反馈，来学习改进的一种方法。可以让 GPT4 根据自己或者是别人对他的评价，来调整和优化他的学习和执行方法。

元学习有很多的形式和技术路线，比如说 learning to learn，learning from demonstrations，learning from rewards等等，这些都是让 GPT4 可以根据不同的类型和来源的反馈，从而学习和改进自己的方法。AutoGPT 就是用了这些技术中的其中一些，从而让 GPT4 能够根据人类以及给他的反馈，来评估和改进自己的表现。

**AutoGPT 的應用與局限**

理論上，AutoGPT 可以做許多有趣且有用的事情。例如，它可以自動分析股票市場並提供投資建議，自動撰寫產品評論並發布到網路上，甚至可以自動創建播客，用聲音和圖片表達觀點。

然而，AutoGPT 並非萬能。它無法真正理解人類情感和價值觀，也無法保證生成內容的真實性和準確性。 它甚至可能做出違反人類道德和法律的事情。

因此，AutoGPT 雖然聰明且智能，但它既非人類的朋友，也非人類的敵人，僅僅是一個 AI 輔助工具。 我們不能盲目相信和依賴 AutoGPT，也不能濫用和惡意使用它。 我們需要以正確和負責任的態度使用它。

另外，在使用過程中，AutoGPT 會自動分解任務和執行，因此對 API 金鑰和 Token 的消耗量非常大。請大家在使用時留意。

**結語**

以上是我對 AutoGPT 的一些通俗理解。 若有表達不清楚或錯誤之處，希望大家在評論區指正，我將在後續改正。 感謝大家的收聽，我們下期再見。

**備註:**

*   我將一些重複的詞彙和口語化的語氣詞刪除，例如：「這個」、「然後」、「其實」、「對吧」、「呃」等。
*   我將一些較長的句子拆分成更短、更易於理解的句子。
*   我將內容分段，使其更易於閱讀和理解。
*   我增加了一些標題和副標題，使其更易於瀏覽和查找資訊。

希望這個整理後的文稿對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>47. [2023-04-15] 【人物】为何计算机传奇大神 Linus ，能写出Linux如此牛逼的操作系统？</summary><br>

<a href="https://www.youtube.com/watch?v=QxMojTT5ahw" target="_blank">
    <img src="https://img.youtube.com/vi/QxMojTT5ahw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】为何计算机传奇大神 Linus ，能写出Linux如此牛逼的操作系统？

好的，這是整理後的文稿，我主要做了以下修改：

*   **分段與結構化：**將文稿分成更小的段落，方便閱讀。加入小標題，更好地組織內容。
*   **語氣調整：**盡可能保留原有的口語化風格，但稍微調整部分語氣，使其更正式一些。
*   **信息歸納：** 對於重複或不重要的信息進行刪減或合併，使文稿更簡潔。
*   **錯別字更正：**修正了一些明顯的錯別字。
*   **標點符號調整：**修正了一些標點符號錯誤。

**整理後的文稿：**

**大家好，這裡是最佳拍檔，我是大飛。**

**引言：Linus 與 Linux 的故事**

這兩天我在網上看到一個話題，想跟大家分享一下。有人問，為何 Linus 一個人能夠寫出這麼強大的系統（Linux），而中國卻做不出來呢？看到這個問題，我就想講一講 Linus 和 Linux 的故事。

**Linus Torvalds 的背景**

Linux 的創始人 Linus Torvalds，1969 年 12 月 28 日出生於芬蘭赫爾辛基的一個記者家庭。他在研究生時期開始寫這個操作系統，大約是 1991 年左右。

**當時的 PC 環境**

那個時候，個人電腦（PC）雖然興起了一些年，但還只是一小部分程式設計師和狂熱愛好者的玩具。硬體基本上都靠自己組裝，軟體也是用開源的系統各種魔改。所以，普通人根本就沒有去折騰 PC 的動力和理由。當時，UNIX 已經佔據了許多生產力場景，唯一的缺點就是貴，而且很多發行版是閉源的。個人使用者根本就不考慮。

Linus 自己組裝了一台 386 電腦，但找不到好用、廉價且免費的作業系統來用。當時社區裡也有一些免費和開源的系統，但是要不就是相容性很差，要不然就是有各種坑，再不然就是沒有可用的軟體。總之，各種各樣的問題，而其中相容性是當時最主要的問題。那時候的 CPU 架構不像現在只有 x86 和 ARM，能叫得上名的架構就有十幾種，所以作業系統的相容性非常重要。

**《作業系統：設計與實現》與 Minix**

Linus 開始自學作業系統後，發現了一本很好的教材，叫做《作業系統：設計與實現》，作者是塔雷鮑姆。他花了一個暑假把這本書看完，然後就開始自己寫作業系統。

塔雷鮑姆當時已經是業界的大牛，他在大學為了教授作業系統這門課程，但苦於學生都買不起太貴的 Unix 發行版，所以就自己寫了一個可以相容 Unix 標準的作業系統，主要相容 POSIX 標準，取名叫做 Minix。買了這本書，就會免費郵寄一份 Minix 的原始碼。

Minix 為了方便教學，其中的代碼寫得很簡單。塔雷鮑姆拒絕向裡面添加太多複雜的功能。所以 Minix 雖然實現的代碼非常優雅，但是社區的玩家要是自己拿來日常用，還需要去魔改很多東西。Minix 是微核心的，微核心的結構非常優雅的，像檔案系統、記憶體管理、硬體驅動都是以行程的形式存在，而不是核心的代碼。這意味著如果你的驅動掛了，並不會帶著核心一起崩潰。但是微核心的缺點就是系統調用的開銷太大，以至於慢到都無法讓你接受。所以現在的桌面系統幾乎沒有純粹使用微核心的。

**Linux 的誕生**

當時，社區和 Linus 都很喜歡 Minix，但 Minix 的作者因為教學目的，放棄了相容性和可擴展性，很難滿足日常使用需求。於是 Linus 就在自己執行 Minix 的 PC 上，開始了 Linux 的開發。Linux 是巨核心的，而且本來不叫 Linux。因為 Linus 很內向，不太好意思取這麼自戀的名字，但他的合作者強烈建議要用這個名字，所以最後就用了，其中的 x 代表著與 Unix 的聯絡，因為他們都相容了 POSIX 協定。Unix 不是為了開源和免費而產生的，最早是為了商業而生的，但 UNIX 的發展催生了開源環境，例如 GNU。

**GNU 與 Linux 的合作**

當時幾年的開發社區屬於軍閥混戰的狀態，缺少一款好用的免費的作業系統。Richard Stallman 所領導的 GNU 組織，在 90 年代就一直想要做一款免費的作業系統，與商業的 Unix 對抗。他們有 GCC 編譯器還不夠，所以需要有自己的作業系統。開發者社區對 GNU 的作業系統非常期待，但最後還是難產了。直到 Linux 大規模應用起來了，GNU 依然沒有做出來。

**Linux 的早期發展**

最早的 Linux 版本只有幾千行程式碼，現在基礎比較扎實的計算機本科生，花一點時間都可以看懂。Linus 從一開始就不斷在 Minix 論壇上發布開發進展，引起了許多人的興趣，紛紛加入了開發。Linus 用郵件接收每個人的程式碼，然後手動進行合併。沒過多久，Minix 論壇上就全是討論 Linux 的了。塔雷鮑姆不太高興，因為 Linus 在他的地盤上老發別人的東西。

**Linus 與塔雷鮑姆的爭論**

不久之後，Linus 和塔雷鮑姆之間爆發了一次衝突。塔雷鮑姆在論壇上寫了一篇文章，來論證微核心與巨核心的優缺點，主要攻擊巨核心，說巨核心除了性能好一點之外，全是缺點，說 Linux 過時了。Linus 雖然性格比較內向，但脾氣比較暴躁，在技術問題上從不妥協。他開始嘲諷 Minix，說 Linux 的可移植性比 Minix 更好，而且免費開源。他們來來回回吵了很多次，誰也沒想到這次在論壇上的口水戰，會成為幾十年後人們依然會提起的作業系統之爭。

Linus 並不是多恨塔雷鮑姆，他們之間沒有多大恩怨。他說後來有一次去參加塔雷鮑姆的演講，完了之後想拿書找塔雷鮑姆簽名，但沒等到人。Linus 還是比較尊敬塔雷鮑姆的，畢竟是自己學習作業系統的領路人，只是大家在技術觀點上有些不合而已。

**Linux 的壯大**

在 Linus 和社區人員的努力下，通過擴展的 GCC 支持了 Linux，Linux 也開始相容了越來越多的平台。其他的各類軟體也都開始移植到 Linux 上，而且變得非常容易。尤其是那個年代，許多軟體是以原始碼的方式發行的，只要有對應平台的編譯器，編譯一次之後，這個軟體就移植到這個平台上了。

Linux 趕上了 PC 發展的浪潮，但還遠遠不夠。因為當時蘋果和微軟都是商業巨頭，商業作業系統的應用性依然有很強的要求。不過，Linux 開始被各種企業看上了，因為不是每個企業都能花很高價錢來買一套 Unix 來使用的，或者使用可能更貴的軟體加硬體的一體的大型機。Linux 讓他們看到了省錢的希望。後來 GNU 也開始支持 Linux 了，Linux 就成了 GNU 官方的作業系統，所以現在也叫 GNU/Linux。

**Linux 的成功要素**

Linux 和 GCC 幾乎是兩個最偉大的開源專案，他們合起來就更強了。GCC 讓軟體非常容易移植，Linux 的軟體生態就變得很好。軟體生態好了之後，使用者也就更多。使用者多了，硬體公司就很眼饞，所以各個硬體公司都開始為 Linux 開發相關的驅動和各種硬體的擴展，來支持自家的硬體在 Linux 上來跑。這樣的話就是使用者就會更多，實際上就形成了很強的倍增效應，飛輪效應，形成了一個很好的良性的迴圈。

Linus 在專案達到一定的規模後，就不再自己親自寫程式碼了，主要是負責合併程式碼。畢竟全球這麼多人在給 Linux 提交程式碼，他一個人審核合併就夠他忙的了，根本不可能有時間去親自寫程式碼。直到有一天他覺得忙不過來了，因為審核程式碼總是會遇到很多比較糟糕的程式碼和開發者，所以他就開發了現在最流行的版本控制工具 Git。Git 字面的意思其實就是飯桶。

從整個發展歷程來看，Linux 在幾個十字路口都做了非常精準的選擇。從 1991 年的 0.0.1 版本到 1994 年的 1.0 版本，這期間 Linux 進行了非常快速的迭代。社區的玩家在使用過程中，也給出了很多寶貴的意見。最好的測試就是讓使用者去測試，保證了所有的更新都是實際有效的。

Linus 在 1991 年開始開發 Linux 的時候，根本就沒想過這玩意有一天能夠改變世界。那個時候，他其實跟所有社區的玩家是一樣的，就是期待著 GNU 能出一個牛逼的作業系統。所以他在論壇上解釋，他做 Linux 其實只是一個業餘的愛好，最多是填補 GNU 的作業系統出來之前的這段空白的時間。

但是 GNU 由於各種名譽加身，把自己抬得太高了，導致目標也定得很高，於是專案就一直延期。同時市面上的作業系統也在發展，GNU 就繼續調高開發的目標，然後繼續延期，最後導致最終的難產。而 Linus 從一開始就沒什麼心理壓力，每一點點的開發成果都會在社區上公佈，而且快速的獲得反饋，然後他再及時的調整開發的方向。這種開發方式無意間就超越了 GNU 的大型軟體設計閉門造車方式。

**Linux 的商業模式**

Redhat 推出了系統免費但服務收費的商業模式，而且也取得了成功，這大大激勵了其他 Linux 發行版的開發商的信心。到目前，Linux 的發行版應該至少有幾百個吧。

在 96 年 2.0 發佈以後，Linux 開始支援了多核的 CPU，這是一個非常重要的更新，從而讓很多的企業開始考慮 Linux。之後幾年，Linux 在伺服器的市場份額上快速的上升。2003 年它發佈了 2.6 的版本。2.6 這個版本跨越了 03 年到 11 年，中間有很多小版本的更新。2.6 版本意味著 Linux 第一次的成為真正具有高穩定性、高可用性、高可伸縮性的工業級別的作業系統。而且在這個 05 年 Git 誕生之後，Linus 和核心的開發團隊也摸索出了一套穩定實用的合作開發模式。之後就是類似於一個遍地開花的發展歷程。

**Linux 成功的關鍵要素**

總結一下 Linux 的成功，以下幾個條件必不可少：

1.  **個人方面：** Linus 強大的開發能力、對專案的管理能力以及對作業系統發展方向的把控，都是無人能夠取代的。
2.  **時代方面：** 需要有一個群雄割據，而且缺乏免費好用的作業系統的時代，需要有這麼一個空缺。同時，程式語言、作業系統理論、編譯器的技術都發展到了一個程度，也是當時處於一個個人 PC 高速發展的時代。
3.  **市場方面：** GNU 的作業系統沒有做出來，Minix 又死守著教育不放。後來 Linux 逐步得到了 GNU 的支持，包括全世界的硬體廠商、軟體廠商的支持，以及通過 Git 獲得了全世界開源開發者的巨大貢獻。

**中國為何沒有做出類似的作業系統？**

這才造就了 Linus 和 Linux 現在的輝煌。至於說中國為什麼沒有做出這樣的作業系統這個問題，我就不多說了，因為我發現油管上也有些使用者，你說啥他都能找到一些刁鑽的角度，來給你上綱上線。我覺得這個問題大家就自己想吧，歡迎在評論區裡留言。中國現在也有一些團隊在開發作業系統，像深度啊什麼的也做的還不錯，但是底層其實都還是基於 Linux 的，沒有跳出這個框框。

不過現在你要想再從頭開發一個作業系統，這個難度和工作量確實都太大了，主要是沒必要，說實在你也沒啥市場。因為這個市場已經不像那個時候了，它有空白，現在已經是成熟的、好用的、便宜的產品已經都出來了，的確沒有這個必要。

**結尾**

好了，今天的分享就到這裡，感興趣的小伙伴們，歡迎訂閱我們的頻道，我們下期再見！

希望這個整理後的版本對您有所幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>46. [2023-04-15] 【人工智能】十分钟讲清楚如何选择、安装和使用AutoGPT | 本地安装 | AgentGPT | Cognosys</summary><br>

<a href="https://www.youtube.com/watch?v=_xejoN8H-U4" target="_blank">
    <img src="https://img.youtube.com/vi/_xejoN8H-U4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】十分钟讲清楚如何选择、安装和使用AutoGPT | 本地安装 | AgentGPT | Cognosys

好的，這是整理後的文稿，我將其分為幾個部分，使之更易讀和理解。我做了以下整理：

*   **刪除了贅詞和語氣詞：** 例如“嗯”、“啊”、“对吧”、“这个”、“就是”等。
*   **修正了口語化的表達：** 將一些口語化的詞語替換成更正式的表達。
*   **精簡了部分語句：** 在不影響原意的基礎上，縮短了部分句子，使其更加簡潔。
*   **調整了段落結構：** 根據內容將文稿分為幾個段落，使其更易於閱讀。
*   **提取了關鍵信息：** 用標題和粗體標記了文稿中的關鍵信息，方便讀者快速掌握要點。

**整理後的文稿：**

**標題：AutoGPT 的選擇和安裝指南**

**引言**

大家好，這裡是最佳拍檔。我是大飛。今天我們來分享如何使用 AutoGPT，以及如何選擇和安裝 AutoGPT。

**什麼是 AutoGPT？**

AutoGPT 是一個 AI 工具，可以自動拆解任務。例如，如果想讓 ChatGPT 幫忙寫一篇文章，可以直接告訴 AutoGPT 最終目標，它會將目標拆解成多個任務，並自動執行。

**AutoGPT 的選擇**

目前主要有三種選擇：

1.  **本地安裝 (Github):** 在 Github 上執行命令，本地運行。優點是不依賴網路，但較複雜。
2.  **AgentGPT:** 登錄網站直接使用，介面簡單。缺點是需要 OpenAI 的 token，需要付費。
3.  **Cogonosys:** 無需 token，介面類似 AgentGPT。缺點是有使用次數限制。

**本地安裝 AutoGPT (Mac)**

以下是如何在 Mac 筆記本上進行本地安裝：

**必要條件：**

*   Python 3.8 以上版本 (建議 3.10)
*   OpenAI API key (付費)

**使用方法：**

安裝完成後，輸入 `python3 scripts/main.py` 即可運行。

*   **命名:** 為這次任務起個名字（例如：zerohedgenewsGPT）。
*   **描述:** 給任務一個描述（例如：print latest zero hedge news）。
*   **目標:** 設定最多 5 個目標，AutoGPT 會自動拆解任務。例如：
    1.  go to zerohedge.com
    2.  find latest 10 news
    3.  print the titles and summarize these ten news
    4.  output to a file
*   **執行:** AutoGPT 會開始思考並運行。過程中會詢問是否執行某些功能 (拆解任務等)。
    *   `y`: 執行此任務
    *   `y-n`: 自動執行接下來的 n 個任務
    *   `n`: 退出

**安裝步驟：**

1.  `git clone [Github 連結]`
2.  `cd AutoGPT`
3.  `pip install -r requirements.txt`
4.  將 `.env.template` 檔案改名為 `.env`，並填入 OpenAI API Key。

**可能遇到的問題：**

*   執行 `main.py` 時可能報錯，可以嘗試執行 `pip install --upgrade [出錯的套件]`

**總結**

希望這個指南能幫助大家成功安裝和使用 AutoGPT。

**結尾**

感謝大家的收看，歡迎訂閱我們的頻道，我們下期再見！

**備註**

*   `[Github 連結]` 請替換成 AutoGPT 的 Github 倉庫連結。
*   `[出錯的套件]` 請替換成報錯信息中顯示的套件名稱。
*   OpenAI API key 是您在使用 OpenAI 服務時需要用到的金鑰，需要通過 OpenAI 官方網站申請並付費。

希望這個整理後的版本對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>45. [2023-04-14] 【电影】对话资深影评人“法兰西胶片” |《宇宙探索编辑部》| 年度华语第一佳片 |《超级马力欧兄弟大电影》| 打破影史动画电影最高票房纪录</summary><br>

<a href="https://www.youtube.com/watch?v=Bc60jKMJHtM" target="_blank">
    <img src="https://img.youtube.com/vi/Bc60jKMJHtM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【电影】对话资深影评人“法兰西胶片” |《宇宙探索编辑部》| 年度华语第一佳片 |《超级马力欧兄弟大电影》| 打破影史动画电影最高票房纪录

好的，這是一份整理後的文稿，主要在斷句、標點符號和語氣詞上進行調整，讓文稿更易於閱讀和理解。 我也將部分口語化的表達進行了潤飾，使其更符合書面語的習慣。

---

**大家好**

這裡是最佳拍檔，我是大飛。

今天我們又請來了國內資深的影評人，法蘭西膠片，跟我們聊一聊最近的電影感受。

嗯，大家好，我是膠片。

嗯，對，最近（笑）。最近有看過什麼片嗎？想跟大家一起聊一聊。

對，每週都看片，每週都看片。

嗯，然後看片是你的生活之一，是吧？

對，嗯。

然後最近大家看的那些新片，嗯嗯，上週有《超級瑪利歐兄弟大電影》，上上週，或者反正4月1日已經上映快半個月了，嗯，《宇宙探索編輯部》。

《宇宙探索編輯部》，對。

哎，這部片我也看了，嗯我也看了，看完之後感覺挺奇妙的。

嗯，對，這像是看了一部…我當時跟你說，咱這叫什麼？寫實…

寫實科幻片！

寫實科幻片，對對對。

這個名字聽起來很崩潰，科幻片還能寫實（笑）。

寫實，《地心引力》是寫實。

對對。

它前面大部分其實都是在記錄生活呀、過程啊這些東西。其實大家在電影院裡看，準確的說，這個題材不是這個類型，應該屬於偽紀錄電影。

啊對，偽紀錄片。

我覺得這個，然後還含有科幻元素和喜劇的偽紀錄電影。但大部分偽紀錄電影都是喜劇，或者是…

呃，恐怖，對。恐怖片很多。

對，但是這部片子裡面也做了一些驚悚的情節，在後面吧？

對，片子後面會有，會有驚悚的情節。

對，就是日食那裡。

啊對對，日食那裡突然感覺這片子的氛圍詭異了，就…我好像輕鬆不下去了。

對啊，但是它是電影發展到那個時刻的一個節奏。它有驚悚的部分，嗯，然後它的主題是科幻，嗯，其實也有一大部分跟年代的人的精神狀態有關係，嗯，然後它又很現代，它的現代是在於，它喪，嗯對吧？喪文化嗎？它這種喪是很現代的。雖然它關注的人群其實是我們80後熟悉的人群，因為我們小時候，不是看《飛碟探索》雜誌嗎？

我到現在在家裡還有《探索》、《飛碟探索》。

然後裡面基本上就是《宇宙探索》這個雜誌的雛形。

嗯嗯。

然後就是說，這個片子裡面會有一…因為這個導演孔大山。

對，你跟導演也很熟，是吧？

對很熟，也採訪過。

就這部片，對吧？

對對對，採訪過的，我是給他做的人生第一個深度專訪，那都是在好多年以前了。

嗯，那個時候因為孔大山這個導演吧，大家可能很陌生。

對，因為他是新人導演。

但是監製郭帆可能大家都知道，《流浪地球》還在裡面客串。

對對，《流浪地球》大導演嘛，就是郭帆，大家可能都了解。

對啊，就是，但是孔大山可能哎，一聽這孔大山，哎呀，我們小時候有個小品演員叫大山，怎麼都叫大山。反正對他其實沒有印象，但是他在圈裡面很早就火了。

哦？嗯，因為他在讀北電導演系研究生的時候，應該是研一左右的時候，就拍了一個短片，也是偽紀錄，但是是那種模仿《法治進行時》、《今日說法》。

《今日說法》，哎，就是模仿那種律政類的，法律類的電視專輯節目，做了一個所謂的一個文藝片創作環境，帶很大自嘲性的短片。他算是偏這種文藝片導演。

呃，題材是文藝片，但是這個東西是個喜劇。

你…有些人因為他模仿的比較逼真，有些人剛開始一看，哎？怎麼還有這種事？嗯，後來再想想不對，我被忽悠了，這是個偽紀錄。

啊，它講的就是說，近日…新聞就開始，主持人就說，有多家報導說某某社區頻繁發生文藝片悶死人的情況，非常惡劣。

文藝片悶死人？文藝片不是會很悶嗎，節奏很慢嗎？普通人不是看起來很難受嗎？

他就故意做個自嘲嘛，文藝片悶死人嗎？事態非常嚴重，所以我們特派記者以應聘劇組工作人員為名，打入犯罪集團內部。

打入內部，打入內部之後就發現，哎，咱們就開會啊，你就發現他們工作狀態就是一幫喪人，你知道嗎？

開會還讓吃薯片什麼的。

嗯嗯。

大爺，沒人說話，開會就到這了（笑）。就完了。最後說我是來仰慕文藝片的，我想來拍，我能做什麼呢？你到時候就錄個音吧，錄個音。那要怎麼錄呢？你得教教我啊，我沒經驗。

然後你就拿這個魚竿，黏著麥克風，話筒纏纏纏纏…這兩人說話，你把這個移到這，他說話你把這移到這，移著移著吧唧就掉下來了，砸了個人。

說會了吧？會了吧？就這個。

其實是嘲諷的。我就說想到這個畫面感。

對對對。

其實就很搞笑，跟他那個《宇宙探索編輯部》很像。這個畫風、風格是很一致的，就是顛覆、戲謔。

所謂的打入內部人員的特派記者以身體不適為名，退出了劇組（笑）。然後開始，我們要準備行動了。然後拍警察，不是那麼誇張。他先敲門，很溫和的敲門：誰啊？查水表啊。然後一開門別動，一會就抓毒販。

孔大山自己也演了個導演，從廁所窗戶往外爬，壓著頭髮說好好交代。

所以當時拍的很逼真，導致有爭議，說是不是公安的影射，暴力執法有點爭議。但從導演來看，他這個技術完成非常厲害，非常棒。

被逮了，就開始《法治進行時》？

錄一個鏡頭懟著他，說小時候看了一個文藝片，沒看懂但大受震撼，誤入歧途深陷其中，以後絕對不會再在乎這個。演上了，非常牛逼。

當時是北電研究生嘛，導演系研究生，學姐趙薇在朋友圈看見有人推薦這個，說你學弟挺牛逼，然後趙薇發了朋友圈，我也看見了。我就直接打車去北電找他，就找到他了。

給朋友介紹的嗎？

找到他我們就在北電食堂坐那聊天，給他做了一個採訪，那是他人生第一個採訪。當時他火了之後很多人就想找他拍戲。

導演嗎？

演的也好，他拍的東西很適合當時網路影片。

萬合天宜，教授易小星的公司很適合吧。

但他還上學呢。他也知道那可能都是類似這種公司可能都是血汗工廠，你去那就打工了，利用他是吧？

他還上學嘛，就完成學業。

為什麼認識郭帆呢？他之前拍了一個短片，根據當時特別有名的動畫短片《李獻計歷險記》。郭帆改編了長篇，郭帆看這短片挺有意思的。

（笑）

挺好，這話得收著點。然後他就微信、微博上私信他，想認識認識你啊，我是拍長片的，你拍短片，挺有緣分。這麼認識的。

孔大山還沒考上北電的時候，就進了郭帆的組了。郭帆在拍高曉松的《同桌的妳》，挺火的。郭帆成功就是從《同桌的妳》開始的，孔大山在劇組做副導演工作，拍連接鏡頭、空鏡、局部特寫，瑣碎的鏡頭補充。他是在那做副導演的，所以他們那個時候就認識。

因為他上學的時候，郭帆四年在拍《流浪地球》，沒辦法出來，所以沒參與《流浪地球》拍攝。但是《流浪地球2》的拍攝，孔大山還是去了在青島拍，對，也做相關輔助。

對，他其實就是相當於團隊裡面的，這個郭帆就力推《宇宙探索編輯部》。因為郭帆分得清什麼科幻是他能做，什麼科幻他現在做不了。這個正好你來做，一直在推他做。當時遇到疫情就沒開機，等到2020年底，大概是那時候緩和一點，至少是2020年底比2022年要好，他又開機拍了《宇宙探索編輯部》。

我一直跟他聊，說你這戲什麼時候弄啊？他說馬上秋天肯定就開了。

大概是就這麼個過程，很快就拍完了。

也不算大製作，小製作，非常低成本，沒有名演員。可能兩個你熟悉的演員，但這個主演以前都不是擔綱的，全部都適合這部戲。

男主角我知道，拍電視劇，房地產那部。他在《流浪地球1》也有一個角色，科研人員的角色，最後在處理高潮危機時刻犧牲。就是那個…卡住了。

演員都不是擔綱的，但是和電影需要的演員氣質表達很匹配。我們剛開始看那個老電視的畫面，在做採訪，我覺得你看一粒沙子，宇宙當中這麼多星球，我們大地這麼多沙子，肯定有外星人存在，我相信，整個氣質有點像抖音的藝能人金廣發，搞懷舊搞笑，無厘頭，頹廢，這種感覺一下就出來了。

這個東西很巧妙的穿插在現代的情況來拍，剛開始的窘境，和他年輕的意氣風發，告訴你這個人是當代最慘的、最low的，給你這麼一個印象，人設就非常成立。

剛開始說話的狀態，情商極低。跟老闆講這個東西，太打臉。宇航服一下扣在頭上，處理的是高潮，感覺電影一上來就是高潮，從那來好多輛車，反复的來，拿吊車拆門，救護車窗戶都拆了，人從那掉下去。

諷刺性在於某種時代性的否定和破滅，他在說中國某個時代的意志力或目標的破碎。你不是飛上天了嗎？宇航服嗎？但你是屍體的形態飛的，象徵著破滅。

這個鏡頭很像德國的東德片《再見列寧》，母親身體康復走出樓外，發現柏林牆已經推倒，整個社會主義陣營沒了，列寧像拆了，從他們眼前飛過。

這裡面有迷影的，有自己文學性的發揮，也有喜劇上的靈感。有些莫名其妙的喜劇，比如你去問一個村民，他說我聾的，但是什麼都能聽見，不要了，很荒誕。這種荒誕像馬冬梅，但很有意思。

還有一些我們能懂的，孫一通戴頭盔，總是莫名其妙地躺在地上，很無厘頭。

很多處理我們能心領神會。所以我覺得，包括到最後情感的升華，有一些問題存在，事件發生不合理。比如紀錄片是給這個編輯部拍的，可是到最後，環境裡有唐主編和攝影師，但你都不知道攝影師生存狀態是什麼樣，你也不知道他幫不幫忙。我們不知道這個人，他是從飛船船艙裡出來的，還是說他怎麼著。萬一遇到險境，看到一個那麼超現實的場景，這個攝影師也不發聲，其實是忽略掉了他。

最後要突顯主角的個人，就犧牲掉了邏輯的合理性。

像拍貝爺一樣，體現貝爺這個主角，但攝影師也是非常牛逼的。比如這有毒蘑菇，攝影師吃沒吃？他知不知道這是毒蘑菇，你也不阻止？毒蘑菇可能是給大家一個猜測，就是最後這是幻覺，但是攝影機都拍到了，就沒有這種猜疑的功能。

因為到最後會有人否定他，但都被拍進去了，有證據，就不可能在後期參加家人的婚禮。他應該早就被國安局給按住了，你沒自由了。這種影片流出去有點誇，會博取點擊量，但他可能不是想討論這些。

其實就是要把人物升華，為了讓人有個升華，所以他割捨了這些解釋。割捨掉還是有點瑕疵，但沒關係，我們可以原諒。瑕疵在於，整個電影從頭到尾一氣呵成。

很圓潤的東西。哪怕他想像力簡單，想像成宇宙是螺旋的DNA結構，有點異想天開，但他表現時你覺得有趣。你看到的是什麼？說不清楚，他就吃口香糖去了。

總之因為他符合這個人物，所以我們相信他，而不是在於你想像出了個這麼個東西。因為這個人物我們投入了感情，所以當最後特效字幕呈現宇宙是螺旋的時候，我們看到的是這個人。

一直跟著老唐的女會計我也臉熟，艾麗婭是老演員，演過很多角色。如果說唐志軍我要求你表演成唐志軍，但他還有自我發揮，但艾莉亞給到了導演想要的一個點。

我們需要有一個人在這個隊伍做精準吐槽。還有一個正常人在這，她是會計，務實，會想這些事到底划不划算。這件事哪怕不合理荒唐，如果划算也行。

剛開始那個假的收外星人的農民，說外星人在這，得給520塊錢，也不知道為什麼多出20塊錢。唐志軍想都不要想，追著他跑著就塞錢進去了。

這兩個人物關係非常牛逼，就像在說我愛你，但你感覺卧槽，一定是這樣的。憑什麼在你身上付出？我可能被你年輕意氣風發打動了。我在少女的時候看你電視上這樣，就愛上你一輩子。

所以走泥巴地，自己也摔在那，孫一通說外星人給我傳信號，等到石獅子上落滿了麻雀，等個鳥，一幫神經病大聚會。他這個吐槽非常準確，他不能硬在這尬人。但他不離開是因為他喜歡這個，他是。

我覺得他這個角色挺重要，觀眾覺得這片還是正常片。否則就認為是一幫神經病，整個故事就是一個人的臆想。有他這個存在，你感覺這個片挺真實。

另外那兩個小孩，一個老愛喝酒，一會醉在這，一會醉在房頂上，還有個小姑娘。其實每個人都是有傷感性的，來自對現狀的不滿。

女孩描述自己悲傷，記憶在踢火爐。編劇厲害，一般情況下可能就是說啊，我的本或者幹什麼，他坐在那烤火，坐在那。哇！這個情節厲害。後面就是那種點睛暗示也挺多。總會力有不逮，比如戴紅帽那個人，開小小的玩具宇宙飛船車，還絆了一腳，挺逗的。想擴充一下，世上帶有遺傷的人很多，也不止唐志軍一個。就像尋寶獵人，會有很多創傷的人，代表過去遺留下來的那些人。大家看到跟傻子一樣，但他以前不是這樣，正常人。他以前有夢想，是什麼把他糟蹋成這樣的呢？

他這裡面有這樣的東西，最後對他是一個撫慰性的收場。孔大山說這個角色他寫不下去了，最後就讓他消失了，留了個帽子，可能先走了，坐飛船離開這個世界了，上帝恩賜他們。實際上很難編下去。

這個情節最後把帽子一掛消失後，我沒有太多感覺，這個人發生什麼好像都合理。的確是把這個忽略了。按理說人物有很多處理方法。

這一路上他們沒有遇到反派，狗算是反派，但就像地上一個石子。沒有價值觀上的反駁，唐志軍找外星人是因為女兒，對女兒抑鬱是完全不能接受。

到最後他可能看到了萬物的真相，能意識到女兒為什麼這樣做，每個人的內心都有不被世界認知的渴望。你要尊重死亡本身，這種感覺。他的價值觀是這樣。

戴紅帽的老頭，可能想要外星人的接觸，要滅掉大家。

這麼寫就增加難度了。

有個情節挺牛的，他參加侄子的婚禮，準備上台發言，但一句沒念。哭了，其實是接受了女兒。釋然了。

其實是我們這代人或者80末90初的人對父輩有排斥和厭惡，為什麼這麼不開放和自由。所以雖然唐志軍到處都在搞笑嘲諷，但他反對這樣的人物。他們對世界自由的認知不夠。你想追尋宇宙，但對自由還沒了解清楚。

整個片都是在否定唐志軍這種虛幻的歷史的理想。到最後釋懷，通過理想的方式，他看到了萬物的真相。亂七八糟的麻雀在飛，他肯定看到了東景觀。

他肯定看到了人的自由，要怎麼和自己的精神世界融合。他肯定看到這種方式了，才意識到女兒的事情。

影片靠近中間的部分，他有一段自己獨白，有點像《加勒比海盜》船長被關起來，自己在跟自己說話。他實際上也是在小屋裡，給觀眾講電視機怎麼回事。其實想讓大家知道自己的生活並不是一個慘劇。

想讓大家知道，他自己的專注在哪裡。但是我們看到就是慘劇，每天只需要攝取少量的蛋白質和鹽幾種元素，其他的都是交配和縱慾之後無效的東西。他用這種生活哲學解釋自己為什麼活的這麼慘，但我們看到的都是他活的真慘。

他去精神病院講課，有幫人學《西遊記》，後來去成都，有個孫悟空，冥冥之中逃脫不了大世界神經病這個牢籠。孫悟空是孫一通演的。

這電影暗含幾個文化元素。一、它是西遊記元素的電影，最初的靈感是山東某個地方台的奇葩新聞，農民在冰箱裡發現一個矽膠外星人。

他跟編劇王一通構思故事時，運用到了西遊記。西遊記講唐朝人怎麼探尋宇宙真相。到最後拿到無字天書，是要去拿到宇宙真相，想知道真相是什麼，來告訴大家不要困惑，好好聽皇帝的話。想把現代跟西遊記連接，所以英文名字就叫做，西遊記的英文名翻譯成進入西部。

人物對照，唐志軍就是唐僧，孫一通就是帶著緊箍咒的孫悟空。

他們到了森林裡面看到了很多佛，覺得離奇，看著像是礦山。是當年探索宇宙的終點，你也走到這來了，你也來到這了，所以你在這尋找真相，他有這麼一個類比。

他還有文學的參照，毛驢失蹤，在小河邊出現。翻過小河，跨過了這小河，其實是唐吉柯德。孫一通這個造型，和以前那些邪門歪教的人很像。

孔大山和王一通作為文青，集中在一起順暢的表達出來。這個片子不做社會批判，也不做對於當下三年疫情的影射。純粹拍一部任何人都能看懂的故事。在不做附加性的電影外的討論，就可以達成一部好電影。

中國觀眾看這種片很少，很少能看到這種偽紀錄科幻片。沒有加入強批判的，去針對重大事件拍的。偽紀錄有一個風險，一旦拍的跟現實關係特別大，你過審就會有各種各樣的毛病，會不會影射到什麼事情。如果是拍偽紀錄恐怖片會更難。

同期上映的另外一部電影《了不起的夜晚》，導演也是認識孔大山的時間差不多那麼長，也七八年了，叫馬凱，當年拍了一部偽紀錄片《中邪》，當時在影展很轟動，民俗的東西非常強烈，告訴你這些民俗背後都是人的利益在作怪。驚悚的靈感要比其他人要高要強，說明他對這種東西已經吃透了。至今無法上映。因為他做了一些過激宣傳，導致影片被禁。他現在又拍了一個驚悚喜劇《了不起的夜晚》，他也第一次做工業的拍攝，經驗稀缺，所以地方做的不是很完備，上映之後褒貶不一。票房跟《宇宙探索編輯部》不相上下。

用了很多明星和流量引起關注。但從專業角度肯定不如《宇宙探索》。

《宇宙探索》目前可能是我個人年度第一，放眼望去，也可能就是今年的全年年度第一。

他也可能就是這10年20年排進前十，大有希望，大有希望。在靈感上沒有被剝削太多。他的靈感沒有直辣辣地觸及到一些神經，技巧很好的全部保留下來。

這個片是值得人回味的。現在電影要跟短影片對抗，很多片不希望你回味。真的去做回味的很少了。其實還是打通你情感了。沮喪的世界活著是幹嘛。至少提出了一個問題。你在其他電影提出這個問題，審查會問你，你這電影幹嘛要提這樣的問題？拍這個電影目的是什麼，你出於什麼目的，現在生活多好，都解決了貧困，你為什麼要沮喪？幸福，高興，蒸蒸日上，都崛起了，再等等，都是這個心態。

他很好的傳遞了普遍的大眾對世界的情緒，可能他是含蓄的。整個世界對這個世界認識都很沮喪。拿到國際上應該也能獲獎。

在好萊塢都會有，只不過在中國少一點。在中國院線你看看著恐怖片很少了。因為電影院在中國是公共場合，容易進行公眾交流，如果你引起公眾的恐慌或對社會質疑，政府不會允許。長津湖引發這種熱烈的情緒是電影院在中國存在的意義。

恐怖片沒辦法在這裡去做完整的呈現，只能是驚悚喜劇。

驚悚喜劇太逗了。先是嚇你一下，告訴你拍戲呢，或者突然間又嚇你一下，但也知道是誤會。觀眾不會精神分裂嗎，就有點分裂。我覺得分裂就是這個當下的主題。

還有啥片呢？值得推薦的就是《宇宙探索編輯部》。大家有空可以去院線看一下，也支持一下。

還看了《瑪利歐》，你也應該穿馬里奧的衣服來。

對啊，我沒買到。買到吃豆人了。

《瑪利歐》的衣服很難買嗎？

還沒上貨。

據說他打破了很多紀錄，是對於產業來說的好事，大家都會覺得遊戲改編電影都是垃圾。

大家對遊戲改編電影疲憊，幼齒電影大家也都會覺得疲憊了。小黃人拍那麼多集觀眾也看不動了。

《瑪利歐》這個電影上映三天就平掉了所有遊戲改編電影的票房記錄，很誇張，魔獸包括很多遊戲改編的電影慘案。《最終幻想》投了1.3億，票房就幾千萬。

遊戲兩頭不討好，遊戲粉絲會覺得垃圾，觀眾會覺得你拍啥玩意，這個兩頭不討好。同期上映的《龍與地下城》是遊戲改編口碑不錯，但票房很慘。

《瑪利歐》投資一億，導演沒什麼經驗，基本上屬於院線長篇第一部。之前是做動畫的，都是極客，天天玩遊戲，看漫畫。兩個新人完成的這部作品大家起初都覺得能賺回來就行，小賺。

結果所有人，包括公司自己，沒有一個人能意識到這個片子能爆成這個樣子，三天平了遊戲改編動畫的最高紀錄，首週再加兩天，他從週三開始上映，有點作弊。

有點作弊。有點過份了。

只能說在某些時刻大家在電影院得到快樂沒有那麼多。之前上映的是《蟻人3》和沙贊，漫威和DC在集體下滑。不想看漫威和DC。來點小清新口味滑咕溜丟的圓乎乎的，顏色飽和不刺眼。

我們看的好像都是3D版，很無恥。中國觀眾的認知是3D就是好片，4D，9D，33D就是好片。中國的錯位認知從阿凡達建立。3D早就被好萊塢淘汰。會發現3D版本人不多，沒有做成3D的制式。阿凡達2觀影體驗不好。

3D畫面就暗下來了，會吃掉30%的光源。看吸血鬼電影3D什麼也看不見。

中國觀眾有些人傻，發行方比較無恥。中國給他們分帳1/4，賺筆錢，要撈多少撈多少。中影公司是全國唯一能夠去批片的，會不會就想賺這筆錢呢。

這個好萊塢片其實沒中國片好看，你看看戴上眼鏡看著畫質，又想損好萊塢片，天天被打臉。

明明可以想辦法做2D，但只發行3D，好萊塢廠商想撈錢，要麼中影公司他自己想撈，長期有習慣，這個認知習慣和商業操作習慣導致我們現在這樣。

《諜影重重》3D轉制被影迷抵制。但觀眾也是那個認知不清，要維護自己權益，可以去消費者協會投訴為什麼非要戴3D眼鏡，走程序來彌補。

快樂兒童片，適合全家觀看。

為什麼他能炸呢？分析不出來，馬後炮。漫威和DC都完蛋了，大家得不到很單純的快樂。故事寫的粗暴，很多情節都是抄的遊戲，音樂也是改編的，至少不會得罪遊戲粉絲。

《生化危機》和《最終幻想》被罵慘了，但這個遊戲粉絲是不會罵的。

非遊戲的人也被吸納進去了。角色設定挺好的，彈鋼琴的烏龜庫巴。

這裡面也有一些喪文化，被囚禁的藍色小海星總是吐槽，但需要有這麼一個東西。

你該死就得死，世界不是全是樂觀的。流程太粗暴了，也沒人深究。包括一些星星角色出場，喚起一些回憶。

大金剛遊戲裡也有瑪利歐。盜版遊戲的卡帶就叫超級瑪麗。後來才改過來。奧德賽非常好玩。把小情懷小遊戲融合，達到了益智的效果。

當年超級瑪莉就覺得難度好高。有些高手瞎跳就能跳出來。躲起來都累死，總費三條命才知道。總有很多種不同跳躍。

小時候玩馬里奧超級瑪麗，覺得難度好高。現在看視訊博主都亂跳都能跳出來。秘訣很多。现在小孩很少玩这些了，还是NDS多。

《瑪利歐》票房最高在北美。這裡面白人只佔三成，墨西哥裔拉丁裔佔四成，剩下三成是黑人和亞裔。男女平等，年齡平等。商業電影的極限。

當時日本應該創造個日本角色。全都是歐美人，跟第二次工業革命一起走的，很嚮往歐洲。所以宮崎駿角色都是意大利人。

他很多坑都沒有掉進去。

畢竟是兩個極客導演，對遊戲中的華彩和興奮點在電影裡面傳遞的非常精通精確。哪些是玩遊戲會興奮的東西，要變成貓元素，變成一個飛的狸貓。橫版過關在進入到3D的PS時代的飛車。變成第一人稱。

他們把所有的瑪利歐最強遊戲非常系統性的融合。

我們能夠想像一件事，他不會得罪遊戲的粉絲。但是遊戲粉絲也不會罵了，因為做得很有趣也很符合大家想像。

現在沒辦法確定了，也不知道為什麼能這麼火爆。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>44. [2023-04-13] 【人工智能】斯坦福大学推出生成式代理人GA | 用GPT技术为游戏NPC带来智能涌现，我们会不会也是子孙后代构建的NPC？</summary><br>

<a href="https://www.youtube.com/watch?v=U5-GVEQKjF0" target="_blank">
    <img src="https://img.youtube.com/vi/U5-GVEQKjF0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】斯坦福大学推出生成式代理人GA | 用GPT技术为游戏NPC带来智能涌现，我们会不会也是子孙后代构建的NPC？

好的，我將以下文稿整理如下，著重於條理性和清晰度：

**主題：GPT 與生成式代理人 (GA) 對遊戲及其他領域的影響**

**引言：**

*   傳統遊戲 NPC 是事先編寫好的程式，缺乏靈魂，受程序支配。
*   GPT (尤其是 GPT-3.5 Turbo) 的出現，可能改變這種情況，創造出更豐富的遊戲世界。

**生成式代理人 (Generative Agents, GA) 的概念：**

*   **定義：** GA 可以根據過去的環境和經驗做出決策，並與其他 GA 建立關係。
*   **與傳統 NPC 的不同：**
    *   傳統 NPC 的行為是事先設定好的。
    *   GA 的行為是自發決定的，例如參加 party 或放鴿子。
*   **論文核心：** 描述一個基於生成式代理人的程序設計，目標是讓 GA 根據環境和經驗做出決策。

**GA 在模擬小鎮 Smallville 中的應用：**

*   **環境：** 25 名 GA 生活在設備齊全的小鎮中，可以自由活動。
*   **互動：** GA 之間可以使用自然語言互動，例如表達對選舉的看法和對其他 GA 的好惡。
*   **理解：** GA 似乎能理解彼此交流的信息，因為這些信息會影響他們接下来的活動。
*   **人類干預：**
    *   人類可以假扮 GA 的內心自我，影響其決策。
    *   人類可以改變環境對象的狀態，影響 GA 的活動。
    *   例如，把廚房的水管设置为漏水，GA就會停下手頭的活動，去尋找工具修理水管

**GA 的涌现式社交行为：**

*   **定義：** 在事先只設定好底層規則的情況下，出現極其豐富且意外的事件。
*   **例子：**
    *   **信息擴散：** GA 在彼此的注意範圍後會進行聊天，迅速傳播感興趣的信息，如山姆要參與競選。
    *   **關係記憶：** GA 之間的對話會被彼此記住，成為下次對話的引子。
    *   **協調活動：** GA 能夠理解指令背後的含義，並進行相關準備，例如伊莎貝拉舉辦 party。

**如何讓 GA 的行為更像真人：**

*   **模仿人類認知方式：** 基於認知心理學，模擬人類記憶的編碼、存儲和提取過程。
    *   **記憶流：** 記錄所有經歷，並構建检索函數，包含近期度、重要性和相關性。
    *   **長時記憶 vs. 工作記憶：** 將 GA 的記憶流理解為長時記憶，將提取相關事件的過程理解為工作記憶。
*   **反思能力：** GA 能夠思考自己的行為和選擇，按照自己的价值观排序，而不僅僅是簡單地根據表面狀態來判斷，例如克勞斯認為瑪麗亞對自己很重要，因為他們都熱愛研究。
*   **規劃能力：** GA 具有一定的規劃能力，並能根據不同環境展開不同對話。

**對人類的猜想及模擬論點：**

*   人類的智能可能也是一種湧現的結果。
*   **模擬論點：** 我們可能也是數字的模擬人 (GA)。
    *   基於兩個假設：意識可以在計算機裡被模擬出來；科技發展到一定地步，可以使用巨大的計算力。

**GA 在遊戲領域的應用：**

*   **角色扮演遊戲 (RPG)：** 解決傳統 NPC 腳本窮盡的問題，讓 NPC 湧現出完全不一樣的行為和對話，提高沉浸感。
*   **模擬經營類遊戲：** 讓 AI 驅動敘事方式，玩家操控條件，讓小人在相處和衝突中產生有趣的故事。
*   **其他類型遊戲：** 如策略對戰遊戲，結合 GA 技術後，可能帶來完全不一樣的體驗，創造充滿可能性的虛擬世界。

**對 GA 技術的擔憂：**

*   社交媒體上可能出現與真人沒有差異的機器人，讓識别人類的真實发言難度大大上升。
*   可能被用到顏色行業，讓暴露人性惡劣行為的樂園成為現實。

**總結：**

*   風險與收益並存，技術的影響取決於如何使用。

**小彩蛋：**

*   沙盒遊戲 demo 被稱為 Smallville，與美劇《超人前傳》同名，可能帶有隱喻。

**整理說明：**

*   使用更清晰的標題和副標題，使文章結構更分明。
*   使用項目符號 (bullet points) 簡化信息，更易閱讀。
*   重點突出 GA 的概念和優勢。
*   整理思路，使邏輯更清晰。
*   修正錯別字及語病。

希望這個整理後的版本對您有所幫助！如果您需要进一步的修改或调整，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>43. [2023-04-11] 【AIGC】25分钟爆肝7千字，一口气讲清AI如何绘画，白话讲解通俗易懂。如何让计算机生成接近真实的图片？如何让模型知道我们想要什么样子？CLIP/Diffusion/ControlNet都是什么？</summary><br>

<a href="https://www.youtube.com/watch?v=eTveYJzC2ZA" target="_blank">
    <img src="https://img.youtube.com/vi/eTveYJzC2ZA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】25分钟爆肝7千字，一口气讲清AI如何绘画，白话讲解通俗易懂。如何让计算机生成接近真实的图片？如何让模型知道我们想要什么样子？CLIP/Diffusion/ControlNet都是什么？

好的，這是我整理後的文稿，重點放在組織結構、修正錯別字、並提升可讀性：

**AI 繪畫原理與技術發展：從基礎到 LoRA 模型**

大家好，這裡是最佳拍檔，我是大飛。

相信大家都感受到，AI 繪畫領域發展實在太快了。去年 AI 繪畫還是某種畫風，今年已迅速進化到另一種程度，堪稱雲泥之別。 近期各種效果驚人的模型，已經有不少人介紹過了，但大部分技術點比較晦澀難懂。所以今天我盡可能用通俗直白的方式，來解釋 AI 繪畫的原理，希望能對大家有所幫助。

影片中涉及的概念可能包括 VAE (Variational Auto-Encoder)、GAN (Generative Adversarial Network)、Diffusion Model 等等。 但大家先不要被這些詞嚇住，我會盡量用淺顯易懂的方式來解釋清楚，即使是小白也應該可以聽得懂的。

**一、電腦如何生成圖畫？**

這涉及到兩個方面：

1.  **生成像真實圖片一樣的數據：** 大部分人可能只關注到這一點。
2.  **理解需求並給出對應結果：** 後者同樣重要。

**1. 生成式模型 (Generative Model)**

*   首先，我們來看看如何生成像真實圖片一樣的數據。這涉及到機器學習中的一個重要分支，也就是生成式模型。
*   生成式模型需要先「吞進」大量的訓練數據，也就是海量的人類所產生的真實圖片，然後再去學習這些數據的分布，去模仿著生成一樣的結果。
*   其實機器學習的核心無非也就是這麼回事。 難點終究還是如何在設計模型，以及讓模型能夠更好地學習到分布上。

**2. VAE (Variational Auto-Encoder) 變分自編碼器**

*   講到生成式模型，有一個不得不提的技術就是 VAE，全稱是 Variational Auto Encoder，中文稱為變分自編碼器。
*   其中的 Auto Encoder，也就是所謂的自編碼器，其實也包含了編碼器 (Encoder) 和解碼器 (Decoder)，它是一個對稱的網路結構。
*   對於一系列類似的數據，例如圖片來說，雖然整體數據量可能很大，但如果符合一定分布規律，那麼它們包含的訊息量其實會遠小於數據量。
*   編碼器的目的就是把數據量為 n 維的數據壓縮成更小的 k 維特徵，這 k 維的特徵盡可能包含了原始數據里的所有訊息，而你只需要用對應的解碼器就可以轉換回原來的數據。
*   所以在訓練的過程中，數據是透過編碼器壓縮，然後再透過解碼器解壓，然後盡量讓重建後的數據和原始數據的差距最小化。
*   不過訓練好以後，就只有編碼器被拿來當做特徵提取的工具，用於進一步的工作，例如圖像分類等等。所以我們稱之為 Auto Encoder。

*   這時會有人想到，既然 Auto Encoder 可以從 k 維特徵向量恢復出一整張圖片，那給你一個隨機生成的 k 維特徵向量，是否也可以隨機生成什麼畫面呢？
*   這個想法很好，不過實際的結果顯示，Auto Encoder 雖然可以記住見過的照片，但是生成新的圖像的能力很差。

*   於是就有了 Variational Auto Encoder (VAE)。VAE 可以讓 k 維特徵中的每個值都變成符合高斯分布的機率值。於是機率的改變可以讓圖片訊息也有相應的平滑的改變。
*   例如，透過控制某個代表性別的維度，讓它從 0 變到 1，就可以從一個男性的人臉開始，生成越來越女性化的人臉。
*   VAE 其實還是存在很多的統計假設，而且我們要判斷它生成的效果怎麼樣，也需要評估它生成的數據和原始數據的差距大不大。

**3. GAN (Generative Adversarial Network) 生成式對抗網路**

*   於是，有人就乾脆去掉了所有的統計假設，並且把這個評估真假數據 (原始數據和生成數據之間差異) 的判別器也放進來一起訓練，於是就創造了 GAN。
*   GAN 有兩個部分，分別是生成器和判別器。
*   生成器會從一些隨機的 k 維向量出發，用採樣網路合成一個大很多倍的 n 維數據。判別器就負責來判斷合成出來的圖片是真的還是假的。
*   一開始合成出來的都是一些意義不明而且沒有規律的結果，判別器就很容易分辨出來。 隨後生成器會發現一些生成的方向，例如成塊的色塊就可以騙過判別器，那麼它就會往這個方向合成更多的圖片。
*   而判別器發現被騙過去了，就會找到更複雜的特徵來區分真假。如此反覆，直到生成器生成的結果，判別器已經判斷不出來真假了，這就算是訓練好了。
*   這樣訓練出來的生成器可以生成非常逼真的、即使是人眼也難以分辨的圖片，但是都是現實中不存在的。
*   到了這個時候，電腦已經可以學會生成相當逼真的畫面了。

*   雖然 GAN 因為引進了判別器能夠生成非常逼真的圖片，但是由於它需要訓練對抗網路，這個過程其實非常不穩定。對於灌輸了大量海量數據的超大規模網路來說，更是難以控制。

**4. Diffusion Model 擴散模型**

*   所以，這個時候就出現了另一個更好的選擇，也就是現在 AI 繪畫普遍使用的生成式模型： Diffusion Model，中文稱為擴散模型。
*   Diffusion Model 生成圖片的過程看似很簡單，其實背後有一套非常複雜的數學理論作為支撐。
*   不過，我們先把複雜的理論放在一邊，先簡單聊一聊 Diffusion Model 是怎麼運行的。
*   Diffusion Model 運行有兩個過程：
    *   **前向擴散 (Forward Diffusion):** 從右到左的過程。做的事情就是在逐步疊加一個符合正態分布的雜訊，最後得到一個看起來完全是雜訊的圖片。這就是所謂的擴散過程。
    *   **反向擴散 (Reverse Diffusion):** 從左到右的過程。做的事情就是一步步去除雜訊，試圖還原圖片。這就是 Diffusion Model 生成數據的過程。

*   如果不嚴謹地說，你可以把它想像成你有一塊牛排，你一遍一遍地往上撒椒鹽，一直到整塊牛排都被椒鹽覆蓋到看不清原來的紋路了。
*   由於每次加雜訊只和上一次的狀態有關，所以這是一個馬爾科夫鏈的模型，其中的轉換矩陣可以用神經網路來預測。

*   為了達到去噪的目的，Diffusion Model 的訓練過程實際上就是要從高斯雜訊中還原圖片，以及學習馬爾科夫鏈的機率分布，再逆轉圖片的雜訊，使得最後還原出來的圖片符合訓練級集的分布。

*   這個去噪的網路是如何設計的呢？我們可以從疊加雜訊的過程中發現，原圖和加雜訊以後的圖片尺寸是完全一樣的。
*   於是我們很自然地能夠想到用一個 U-Net 的結構來學習。 U-Net 是一個類似於 Auto Encoder 的漏斗狀的網路，但是在相同尺寸的 Decoder 和 Encoder 層上增加了直接的連結，以便於圖片相同位置的訊息可以更好地透過網路來傳遞。
*   在去噪任務中，U-Net 的輸入是一張帶雜訊的圖片，需要輸出的是網路預測的雜訊，而 Ground Truth 就是實際疊加上的雜訊。
*   有了這樣一個網路，就可以去預測雜訊，從而去去除掉它還原圖片。因為帶雜訊的圖片就等於雜訊加圖片。

*   這也是為什麼 Diffusion Model 會比其他方法生成圖片的速度更慢，因為它需要一輪一輪地去雜訊，而不是透過網路可以一次性地推斷出結果。
*   以上就是 Diffusion Model 的生成圖片的原理，是不是很簡單呢？

**二、模型如何理解指令並生成結果？ (CLIP 模型)**

*   到這裡，我們就解釋了電腦是如何生成和真實圖片相似的圖畫的。接下來，我們就來解釋一下模型是如何理解我們想要它生成什麼，並如何給出對應的結果的。
*   玩過 AI 繪畫的人應該都知道，AI 繪畫最主流的模式是在網頁輸入框中輸入一長串的 Prompt 提示語，類似於施法前的吟唱咒語，其中包括想要生成內容的主體、風格、藝術家還有一些 Buff 等等。
*   點擊生成之後，就會得到一張非常棒的結果圖片，當然有時候可能也會出乎意料。
*   透過文字來控制模型生成畫面，最早的做法其實更像是先讓生成式的模型生成一大堆符合常理的圖片之後，再配合一個分類器來得到符合條件的結果。當然這種做法在海量的數據面前顯然是沒法用的。
*   這個領域的開山之作 DALL-E 最值得一提的就是引著了 CLIP 模型來連接文字和圖片。

*   CLIP 模型其實就是用了海量的文本和圖片數據對，把圖片和文本編碼後的特徵，再計算相似性的矩陣。
*   透過最大化對角線元素，同時最小化非對角線元素來優化兩個編碼器，從而讓最後的文本和圖片編碼器的語意可以強對應起來。
*   如果你不能理解 CLIP 的原理，那麼你只需要記住 CLIP 能夠把文字和圖片對應起來這樣就可以了。

*   它最大的成功之處不是用了多麼複雜的方法，而是用了海量的數據。 這樣帶來的好處是，很多現有的圖像模型可以很容易地擴展成文本控制的圖像模型。
*   原本需要大量人工標注的很多任務，現在就只需要用一個 CLIP 模型就可以了。 甚至還可以被用來生成新的數據。
*   例如在 StyleCLIP 中，用文本交互可以來控制生成的人臉。

*   一開始圖片的文字訊息大多都是以打標籤的形式，透過大量的人工標注來完成的。 有了 CLIP 模型之後，可以說是徹底打通了文字和圖片之間的橋樑，使得圖像相關的任務可以得到大大的擴展。
*   所以，即使說 CLIP 是 AI 繪畫的基石也不過分。
*   有了這個 CLIP 模型，就可以計算任何圖片和文本之間的關聯度 (即 CLIP Score)，再用它來指導模型的生成了。

*   這一步其實還分為了幾個發展階段。
    *   **Guided Diffusion:** 最早用的方法，很傻很天真。每次降噪後的圖片都需要計算一次和輸入文本之間的 CLIP Score。 原本的網路只需要預測雜訊，而現在不但要預測雜訊，還需要讓去噪後的結果圖片盡可能地跟文本接近，也就是 CLIP Loss 盡量小。這樣在不斷去噪的過程中，模型就會傾向於生成和文本相近的圖片了。
    *   由於 CLIP 是在無雜訊的圖片上進行訓練的，還有一個小的細節是需要對 CLIP 模型用加雜訊的圖片再進行 Fine-tune (也就是微調)，這樣 CLIP 才能夠看出來加噪後的牛排還是一塊牛排。

*   這樣做的好處是 CLIP 和 Diffusion Model 都是現成的，只需要在生成過程中結合到一起就行了。但是缺點是，本來已經很慢的 Diffusion Model 現在生成過程就會變得更慢，而且這兩個模型是獨立訓練出來的，沒有辦法聯合訓練，也就沒有辦法讓它們得到進一步的提升。
*   **Classifier Free Diffusion Guidance:** 這個模型可以同時支持無條件和有條件的雜訊估計，而且在訓練 Diffusion Model 時就加入了文本的引導。 這樣的模型當然也離不開很多很多的数据，以及很多很多的 GPU 卡。 除了網路爬取的數據以外，還有透過商業圖庫構造出巨量的圖片和文本對，最後作為成品的 GLIDE 在生成效果上又達到了一次飛躍。

*   雖然現在看的有點簡陋，但是在當時來說已經非常驚人了。
*   恭喜大家，到這裡我們已經追上了 AI 繪畫 21 年末的進度。

**三、以圖生圖 (Image-to-Image)**

*   我們再發散一下，如果是以圖生圖，那這個時候的輸入條件就變成了圖片，那麼要怎麼來控制生成結果呢？
*   其實有幾種不同的方法，也算是不同的流派吧。這裡我們先介紹 3 種。
    *   **方法一：提取圖片的 CLIP 特徵：** 就像文字特徵一樣去引導圖片，這樣生成出來的圖片內容就比較相近，但是結構不一定是相同的。
    *   **方法二：增加雜訊後去噪：** 對輸入的原圖增加幾層雜訊，再以此為基礎進行常規的去噪。透過使用你希望的畫風所對應的咒語，就可以生成和你原圖結構類似、但畫風完全不同的圖片。
    *   而且疊加的雜訊強度越高，生成的圖片和原圖的差距越大，AI 畫畫的發揮空間也就越大。
    *   **方法三： Fine-tune 生成網路 (Dreambooth)：** 用對應的圖片去 Fine-tune (也就是微調) 這個生成網路。打個比方就是，如果我們給模型看很多小狗狗的圖片，讓模型學到這隻小狗狗的樣子，這樣我們只需要再加上一些簡單的詞彙，就可以生成各式各樣的小狗狗了。

*   到這裡，我們已經解釋了電腦是如何生成和真實圖片相似的圖片，以及模型是如何聽懂我們想要它生成什麼，並且給出對應結果的。

*   關於 AI 繪畫的基本原理就已經介紹的差不多了。我們可以發現，其實大部分都是改進性質的工作，但是效果確實很驚人。 在這個過程中，其實會涉及到很多訓練網路的小技巧，這裡我就不再做過多的介紹了。

**四、Stable Diffusion 與 Latent Diffusion Model**

*   然後我們再聊一個比較火爆的模型： Stable Diffusion。 因為它開源而且效果比較好，所以得到了很多人的喜愛。基於 Stable Diffusion 也發展出了像二次元插畫的 NovelAI 等等模型，也都很火爆。
*   如果我們想要解釋 Stable Diffusion 為什麼這麼好，那還要先從 Latent Diffusion Model 談起。

*   讓我們來複習一下 Diffusion Model 的原理。對於一個帶雜訊的輸入圖片，訓練一個雜訊預測 U-Net 網路，讓它能夠去預測雜訊，然後再從輸入中減去雜訊，就得到了去噪後的圖片。
*   一般的 Diffusion Model 是對原始圖片進行加噪去噪，雜訊圖片和原始圖片的尺寸是一樣的。 為了節約訓練資源和生成時間，通常都會使用比較小的圖片尺寸來進行訓練，然後再接一個超分辨率的模型。
*   而在 Latent Diffusion Model 中，Diffusion 的模組被用來生成 VAE 的隱編碼。於是整個流程就變成了這樣：圖片先用訓練好的 VAE 的 Encoder 得到一個維度要小很多的圖片隱編碼。
*   你可以理解為將圖片的訊息壓縮到了一個尺寸更小的空間中，而 Diffusion Model 不再直接處理原圖，而是處理這些隱編碼，最後生成新的隱編碼，再用對應的 Decoder 還原成圖片。
*   這樣相對於直接生成圖片來說，就可以大幅度地減少計算量以及顯存，所以 Stable Diffusion 的生成速度會更快。

*   第二個改進點是增加了更多的訓練數據，而且還多了一個美學評分的過濾指標。簡單的來說就是它只選擇好看的圖片。就好像是，如果你要學會如何畫一個漂亮的畫，那你就要多看看一些大藝術家們的經典作品，這是一樣的。
*   同時，在訓練集裡邊也都是一些漂亮的圖片，一些模糊的有水印的圖片都已經被 Pass 掉了。所以只讓機器從好看的圖片裡邊去學習畫畫。
*   最後，Stable Diffusion 的另一個改進就是用了我們之前提到的 CLIP 模型，來實現了透過文本來控制圖片的生成方向。
*   這裡也順便提一下，二次元畫風的 NovelAI 其實在技術上並沒有什麼新的內容，就是拿海量的二次元圖片去微調原來的 Stable Diffusion 模型。 主要的一些改進包括把 CLIP 用在了倒數第二層，這樣就可以更貼近文本內容的特徵。然後就是把訓練數據擴展為一個長寬比不限的尺寸，這樣就可以容納下完整的人像，以及增加了可以支持的文本輸入的長度，這樣就能夠讓提示語變得更靈活，也更加複雜。

**五、ControlNet**

*   接下來我們再說一下 ControlNet 是如何來控制擴散模型的。
*   由於 Diffusion 超強的學習能力，理論上這個網路是可以還原出訓練集裡的每一張圖片的。所以只要數據足夠多足夠好，模型就可以生成非常好的圖片。

*   和人類學畫畫不同的點在於，如果人的難度是在於說畫不出來，那麼模型的難點就是它不知道該往哪個方向去畫。
*   所以控制模型生成，其實就是想辦法讓模型變得聽話，按照你的指示來生成結果。 之前我們提到 img2img，它的原理就是把左圖加一些高斯雜訊，相當於撒了一些黑胡椒面，然後再把它作為底圖基於它來生成新的圖，所以基本上色塊的分布是非常接近的，但是很難控制的更加細節。

*   而有了 ControlNet 之後，就可以透過任何的條件來控制網路的生成。原來模型只能得到一個文本的生成引導，但是現在它可以聽得懂任何基於圖片所提取出來的訊號，只要你拿一組成對的圖片去訓練就可以了。
*   這個方式出來以後，極大的拓展了這種可玩性，而且官方已經提供了非常多常用的已經訓練好的控制網路。 你可以用 Depth 來控制結構，生成各種場景。 比如你可以直接拿線稿來上色，也可以隨便塗幾筆就生成複雜的圖片，還可以透過姿態檢測來生成很好的多人結果。 甚至你可以自己訓練解決 AI 不會畫手的問題。

*   這些控制結果還可以一起使用。比如說結合人體姿態和深度圖來生成一張新的圖片，甚至它都不需要是來自於同一張圖。
*   雖然 ControlNet 效果很驚艷，但是原理上其實比較簡單。 為了給原始的模型增加一些額外的條件輸入，其實就是把整個網路複製了一份，固定讓原來的網路來保證輸出的穩定性。 原始的網路輸入依然是雜訊，而複製的 ControlNet 的輸入則是控制條件，比如說深度、姿態等等。

*   把這兩個輸入和輸出加起來，再用成對的數據集去訓練控制網路。這樣就能夠很好的去控制訓練的程度和結果。 這個訓練的本質上還是在做微調，所以耗時也不是很大，和直接微調整個網路也差不太多。
*   現在 ControlNet 對於結構生成已經能做到不錯了，這時候就會面臨另一個問題： 模型的細節，要怎麼讓它能夠生成的更好？

**六、超分 (Upscaling)**

*   想要得到更高質量的圖片，最直接的方式就是調大輸出的分辨率，分辨率越大細節畫的就越好，尤其是對於人臉來說。 但是實際上高分辨率的結果就非常容易崩掉，並且分辨率高了以後計算的成本會飆升，也會算的很慢。
*   於是，一種常見的做法是先生成一些較小分辨率的結果，然後對這些圖片做超分，也就是在保證清晰度的前提下把圖片放大。這麼做可以保證結構的合理性，而且速度會快非常多。
*   但是超分的模型對於細節的補充並不一定能做到很自然，而且容易有過於銳化的結果。
*   除了傳統的超分模型，還有同樣基於 Diffusion Model 的超分算法。由於 Diffusion 相當於重繪了這個圖片，所以可以得到更好的一些細節效果。但是圖片尺寸非常大跑起來就會更慢。

*   另一個現在被廣泛使用的方式是 Latent Upscale。 這個用 WebUI 自帶的 Hires.fix 就可以實現。
*   之前我們也提到過 Stable Diffusion 的結構優勢之一就是它是由一個壓縮圖片訊息的 VAE 和一個對 Latent 進行去噪的 U-Net 網路所組成的。
*   所以它天然適合基於 Latent 的超分算法。 對 Latent 做 Upscale 也有基於 Diffusion 的方法，並且效果應該是最好的，當然帶來的代價就是耗時也會增加。
*  (這裡省略超分方法的對比) 這張圖片就是 Latent Upscale 和 ControlNet 一起結合得到的。

**七、LoRA (Low-Rank Adaptation)**

*   除了 ControlNet 之外，AI 繪畫領域另一個不得不提的就是 LoRA 模型。要講 LoRA 模型，就要先解釋模型的 Fine-tune，也就是什麼是微調。
*   其實就是當你有一個現成的很厲害的大模型，也就是一個預訓練的模型的時候，你想要讓它學習一些新的知識，或者完成一些更面向於具體應用任務，或者只是為了適應你的這個數據分布的時候，就需要拿你的小樣本的數據去對這個模型進行重新的訓練。
*   這個訓練還不能訓太久，否則模型就會過擬合到這個你的小樣本數據上，從而喪失掉大模型的這個泛化能力。 Pretrain 和 Fine-tune 是機器學習中非常常見的組合，在應用上有很大的價值。
*   但是其中有一個問題就是它會遺忘。模型會在 Fine-tune 的這個過程中不斷忘記之前已經記住的內容。 常見的解決方式會有兩個：
    *   第一個是 Replay，就是把原始的知識再過一遍。
    *   第二個是正則化，就是透過正則項來控制模型的參數和原始參數盡量保持一致，不要變得太多。
    *   當然還有一個就是 Parameter Isolation (也就是參數孤立化)。 這個是透過獨立出一個模組來做 Fine-tune，使得這個原有的模型不再更新權重。
*   參數孤立化其實是最有效的一種方式，具體有好幾種實現方式。 例如 Adapter，就是在原模型中增加一個子模組，固定原模型只訓練這個子模組。 是不是聽起來有點熟悉呢？沒錯，ControlNet 就是一種類似於 Adapter 的方法。

*   而 LoRA 就是另一種參數孤立化的策略，也在 AI 繪畫這個領域找到了它的用武之地。 它利用了低秩矩陣來代替原來的全量參數進行訓練，從而提高了 Fine-tune 的效率。
*   我們可以和之前最常用的 Fine-tune 方法 DreamBooth 來對比一下。 對於 DreamBooth 來說，它是直接更新整個大模型的權重來讓模型學習到新的概念。 雖然可以透過正則化來避免遺忘，但是 Fine-tune 後的模型依然非常大，和原來的模型一樣大。
*   而使用 LoRA 之後，LoRA 影響的只是其中的一小部分權重，也就是透過低秩矩陣疊加到大模型網路上的那一部分。 所以微調起來就會更快，需要的資源更少，而且得到的微調模型會非常小，使用起來就會方便很多。
*   由於 LoRA 在結構上是獨立於大模型的，所以它有一個額外的好處，就是替換大模型可以得到不同的令人驚喜的一些結果。 比如說我們用水墨畫來訓練的 LoRA 模型墨心，結合國風美女的基礎大模型，就可以生成一個穿著中式服裝的水墨畫美少女。

*   在使用上來說，LoRA 就很像這個模型的一個插件，可以在基礎模型上去疊加想要的效果，或者把各種想要的效果加權組合疊加在一起，這樣就可以產生很多令人驚喜的結果。
*   當然，由於 LoRA 是一個微調模型，所以畫風會趨於單一，那這樣是好是壞也是見仁見智。但是如果你使用現實中的真人照片來訓練 LoRA 並且把這個模型公開了，那我覺得是一件非常缺德的事情，希望大家也不要這麼做。

**八、總結**

*   好了，今天的内容大概就介绍到这里。 我们大概完整介绍了AI绘画的整个流程，以及相关的模型算法。 当然由于时间有限，还有很多内容是没有被覆盖的，比如像Midjourney DALL-E等等，以后有机会大飞再给大家一一介绍，感兴趣的小伙伴们欢迎订阅我们的频道，我们下期再见。

**總結來說，這次整理做了以下調整：**

*   **組織結構：** 將內容分成幾個大章節，並在每個章節下使用小標題，讓結構更清晰。
*   **語言潤飾：** 修正錯別字，調整語句，使表達更流暢。
*   **重點突出：** 加粗重點詞語和概念，方便讀者快速理解。
*   **補充說明：** 在某些地方增加說明，使內容更容易理解。
*   **格式調整：** 調整了項目符號和排版，讓整體看起來更整潔。

希望這個整理後的版本對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>42. [2023-04-10] 【人工智能】Meta发布史上最强抠图模型 | Segment Anything Model | 零样本学习可分割一切物体 | 计算机视觉迎来GPT-3时刻</summary><br>

<a href="https://www.youtube.com/watch?v=SUehMu5yEiM" target="_blank">
    <img src="https://img.youtube.com/vi/SUehMu5yEiM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Meta发布史上最强抠图模型 | Segment Anything Model | 零样本学习可分割一切物体 | 计算机视觉迎来GPT-3时刻

好的，我將這篇文稿整理如下，主要目的是使其更易於閱讀，並使其結構更清晰。我將會：

*   **分段並加入標題**：將文稿分成更易於理解的段落，並添加標題以概述每個段落的內容。
*   **修正錯別字和語法**：修正文中可能存在的錯別字和語法錯誤，使語句更流暢。
*   **簡化口語化的表達**：將一些口語化的表達轉換成更書面化的表達方式，使其更適合閱讀。
*   **提煉重點**：在適當的地方，強調重點信息，使其更突出。
*   **格式化**：使用適當的格式，例如粗體和列表，以提高可讀性。

**整理後的文稿：**

**Meta推出SAM：計算機視覺的GPT-3時刻**

大家好，這裡是最佳拍檔，我是大飛。如果您看過漫威電影，一定對鋼鐵人的頭盔印象深刻。通過這個頭盔，可以一眼識別並標記出眼前的所有人和物品，並且可以看到這些事物的特徵和數據。現在Meta正在將這個科幻的設想變成現實。

當各大巨頭在AIGC領域混戰時，Meta默默地在人工智能的另一個重要分支——計算機視覺上展開了大動作。上週三，Meta發表了一篇名為 "Segment Anything" 的論文，中文翻譯過來就是「分割一切」。這篇論文介紹了一個全新的 Segment Anything Model，簡稱 SAM，可以用來識別圖像和視頻中的物體，甚至是AI從未訓練過的物品。

**SAM：強大的圖像分割能力**

所謂的分割，用最通俗的話來說就是摳圖。但Meta這次所展示的AI的摳圖能力遠比我們之前想像的要更加強大，甚至在人工智能的領域被認為是計算機視覺的GPT-3時刻。

雖然智能摳圖並不是一個新鮮事物，但是如果你嘗試過一些p圖軟件，就會發現如果想把照片摳的快、摳的準、摳的自然，其實是一件費時又費力的事情。而且對於單個主體的圖片來說可能還好處理一點，但是如果一個圖片裡有幾十個物品都要摳出來，那麼目前的摳圖軟件和工具都很難處理好。

從技術的角度來講，圖像摳圖一直是計算機視覺領域的一項經典而且複雜的任務，其中關鍵的難點在於識別的時間和精準度。而Meta這次發布的SAM模型可以說給出了一個幾乎完美的解決方案。對於任何一張照片，Meta都可以快速識別照片中的所有物體，並且智能地將其分割成不同的形狀和板塊。你甚至可以點擊圖中的任何物品進行單獨的處理。

這次的SAM還有一個很大的突破，在於即使是訓練過程中從未遇到過的物品和形狀，它也能夠將它準確的識別並且分割出來。而且除了簡單的識別圖片中的物體之外，這一次SAM還支持用戶使用交互性的方式來分離出你想要的物體。比如說，你可以將鼠標懸浮在這個物體之上，就能夠自動的定位出這個物體的輪廓，即使是顏色非常相近，或者是在連人眼都難以快速分辨的倒影的圖像中，SAM都能夠非常準確的找到輪廓的邊線。

再比如，你也可以直接通過輸入文字來查詢，SAM就可以幫你找到並且標記出這個圖片中你想找的文字所標記的對象。

**SAM：不僅限於靜態圖片**

不僅僅是靜態圖片，SAM也能夠準確識別視頻中的物體，並且還能夠快速標記出這些物品的種類、名字、大小，並且自動用ID給這些物品進行記錄和分類。Meta表示未來這一技術會跟AR、VR的頭盔進行廣泛的結合。這聽上去確實有點鋼鐵人頭盔的味道了。

聽到這裡，您是不是覺得這個模型已經很厲害了？但是別着急，Meta這次還有大招。除了能夠把物品從圖像中精準的分離出來，SAM還能夠支持對這個物品的編輯。也就是說，你可以把這件衣服從這個模特身上換下來，再換一個顏色，改個大小放到另一個模特身上。你還可以把你從靜態圖片中摳出來的椅子進行3D渲染和編輯，讓他從一個圖片立刻就能夠動起來。接著你還可以改變他的形狀或者進行更多的創意操作。

**業界評價：計算機視覺的GPT-3時刻**

在Meta發布了SAM之後，立刻就吸引了大量的關注。英偉達人工智能科學家 Jim Fan 表示，這次 SAM 最大的一點突破是，它已經能夠基本的理解 "物品" 的一般概念，即使對於一些未知對象或者是不熟悉的場景，比如說水下和顯微鏡裡的細胞，它都能夠比較準確的理解。因此，他表示相信 SAM 的出現會是計算機視覺領域裡的 GPT-3 時刻。

不僅是 Jim 有這樣的觀點，一些 AI 研究專家甚至也表示 SAM 之於計算機視覺，就像是 GPT 之於大語言模型。

**實際應用：SAM的廣闊前景**

就在 SAM 發布之後，很多人也在第一時間上網進行了實測。不僅大部分網友基本都表示驚嘆，一些網友還結合自身的工作領域，打開了 SAM 更廣闊的應用想像空間。

*   有人將包含了眾多複雜元素的圖片上傳之後，SAM 可以毫無壓力的把他們都識別出來，無論是近景還是遠景，都可以基本準確的找到大量的複雜的細微的元素。
*   自然科學的研究者將 SAM 和衛星圖像結合在了一起，表示 SAM 能夠很好的識別和找到他標記的風貌類型。
*   還有神經外科影像學的專家將 SAM 用到了一個脊髓血管病的案例文件之中，認為 SAM 在幫助判斷和分析病情上有很大的幫助。
*   有生物學家輸入了一張顯微鏡下的組織圖片，即使圖中的形狀特徵毫無規律，但憑藉著 Zeroshot 的技術，SAM 也能夠自動識別多細胞結構中的腺體、導管、動脈等等。這名生物學家認為 SAM 的產出結果已經非常接近完美，未來應該能夠節省大量手動註釋的時間。
*   還有騎行愛好者將地圖和 SAM 結合起來，認為能夠幫助自己未來更快更高效的給地圖做標記。

**SAM的關鍵特性**

總體來看，跟過去的一些計算機視覺模型相比，SAM 在幾個方面有著顯著的提升和不同：

1.  **Prompt結合**：SAM 開創性的跟 Prompt 結合了起來。它可以接受各種輸入提示，例如點擊框選，或者指定想要分割的對象。這種輸入並不是一次性的指令，你可以不停的對圖像下達不同的指令，從而達到最終的編輯效果。這意味著此前在自然語言處理中的 prompt 模式也開始被應用在了計算機視覺領域。

2.  **海量數據集**：SAM 這次是基於 1,100 萬張圖片和 11 億個掩碼的海量數據集進行訓練。這是迄今為止最大的分割數據集，是 OpenImage V5 數據集的 6 倍。這個數據集涵蓋了廣泛的對象和類別，包括像動物、植物、車輛、家具、食物等等。這些圖像的分辨率都達到了 1500x2250 的像素，平均每張圖像約有 100 個掩碼。

3.  **輕量級解碼器和零樣本性能**：這次 SAM 採用了輕量級的掩碼解碼器，可以在每次提示僅僅幾毫秒內的網絡瀏覽器中運行。同時 SAM 在各種分割任務上具有很強的零樣本性能。零樣本也就意味著 Sam 可以在不對特定任務或者領域進行任何額外的訓練或者微調的情況下就可以對對象進行分割。例如 SAM 可以在沒有任何先驗知識或者是監督的情況下，來分割人臉、手、頭髮、衣服和配飾。SAM 还可以以不同的方式来分割对象，例如红外图像或者是深度图。

**Meta的應用和開源策略**

Meta 表示目前公司內部已經開始使用 SAM 的相關技術，用在了 Facebook、Instagram 等社交平台對於照片的標記、內容審核和內容推薦上。而生成式人工智能作為創意的輔助工具，今年也將被作為重點優先事項納入到 Meta 更多的應用程序中。

這次最讓很多業內人士驚喜的地方在於無論是 SAM 模型還是巨大的訓練數據集都是開源的。也就是說，目前任何人都可以在非商用許可下下載和使用 SAM 模型以及它的數據。

Meta 這次推出的 SAM 模型是希望進一步的加速整個行業對圖像分割以及更通用圖像以及視頻理解的研究。隨著 SAM 的演進和發展，這項技術可能會變成未來 AR、VR、內容創作、設計等等更多領域的強大的一個輔助工具。

**體驗SAM**

最後，除了開放模型和數據集以外，Meta 還推出了一個 SAM 的演示平台。即使你是一個完全不懂 AI 的普通用戶，也可以在這個網站上親身體驗一下它神奇的摳圖功能。網址我放到評論區裡了，感興趣的小夥伴們快去試試吧。

好了，今天的分享就到這裡，感興趣的小夥伴們歡迎訂閱我們的頻道，我們下期再見。

**總結**

我盡量保留了原文的風格，但使其更易於理解和閱讀。希望這個版本對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>41. 【人工智能】国内大语言模型进展究竟如何，看阿里AI专家怎么说？ | 距离GPT-3还有一年半的差距 | 百度文心一言也仅仅相当于GPT-2.5 | 国内算力储备如何 | 百度腾讯华为360都在干什么？</summary><br>

<a href="https://www.youtube.com/watch?v=YfTxWcBmKWA" target="_blank">
    <img src="https://img.youtube.com/vi/YfTxWcBmKWA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】国内大语言模型进展究竟如何，看阿里AI专家怎么说？ | 距离GPT-3还有一年半的差距 | 百度文心一言也仅仅相当于GPT-2.5 | 国内算力储备如何 | 百度腾讯华为360都在干什么？



---

</details>

<details>
<summary>40. 【人工智能】马斯克开源推特Twitter推荐算法 | 核心排序加权规则快速解读 | 究竟哪些指标对推荐影响最大 | 如何让你的推文更被系统推荐 | 不会编程也能看得懂</summary><br>

<a href="https://www.youtube.com/watch?v=tYuJKVnEO0w" target="_blank">
    <img src="https://img.youtube.com/vi/tYuJKVnEO0w/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】马斯克开源推特Twitter推荐算法 | 核心排序加权规则快速解读 | 究竟哪些指标对推荐影响最大 | 如何让你的推文更被系统推荐 | 不会编程也能看得懂



---

</details>

<details>
<summary>39. 【人工智能】微软 154 页论文7万字浓缩精华版 | 首次揭示 GPT-4 超能力 | 智能水平已非常接近人类水平 | 为何是通用人工智能 (AGI) 的早期版本</summary><br>

<a href="https://www.youtube.com/watch?v=RX2TdJz79ig" target="_blank">
    <img src="https://img.youtube.com/vi/RX2TdJz79ig/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】微软 154 页论文7万字浓缩精华版 | 首次揭示 GPT-4 超能力 | 智能水平已非常接近人类水平 | 为何是通用人工智能 (AGI) 的早期版本



---

</details>

<details>
<summary>38. 【人工智能】微软推出Security Copilot | 内置GPT-4 | 自动抵御65万亿个网络安全威胁 | 可与微软Sentinel/Defender/Intune集成 | 生成式AI安全时代</summary><br>

<a href="https://www.youtube.com/watch?v=rSXqpzWz5_4" target="_blank">
    <img src="https://img.youtube.com/vi/rSXqpzWz5_4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】微软推出Security Copilot | 内置GPT-4 | 自动抵御65万亿个网络安全威胁 | 可与微软Sentinel/Defender/Intune集成 | 生成式AI安全时代



---

</details>

<details>
<summary>37. 【人工智能】千名科技大佬发布公开信，联名呼吁立即暂停大模型AI训练，人工智能正处于失控前夕？埃隆马斯克为何对一手投资的OpenAI不满，他和萨姆奥特曼为何结下个人恩怨，究竟是理念不同还是嫉妒眼红？</summary><br>

<a href="https://www.youtube.com/watch?v=SStBYZ4TZsc" target="_blank">
    <img src="https://img.youtube.com/vi/SStBYZ4TZsc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】千名科技大佬发布公开信，联名呼吁立即暂停大模型AI训练，人工智能正处于失控前夕？埃隆马斯克为何对一手投资的OpenAI不满，他和萨姆奥特曼为何结下个人恩怨，究竟是理念不同还是嫉妒眼红？



---

</details>

<details>
<summary>36. 【人工智能】用AI复活了去世的奶奶 | ChatGPT + Midjourney + Baidu PaddlePaddle TTS + D-ID | 人类永生？or 虚拟现实？</summary><br>

<a href="https://www.youtube.com/watch?v=4o_0QQw7zDY" target="_blank">
    <img src="https://img.youtube.com/vi/4o_0QQw7zDY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】用AI复活了去世的奶奶 | ChatGPT + Midjourney + Baidu PaddlePaddle TTS + D-ID | 人类永生？or 虚拟现实？



---

</details>

<details>
<summary>35. 【商业】马云回国 | 张勇宣布阿里巴巴成立24年来最大组织调整 | 1+6+N 组织架构 | 子公司可独立融资和上市 | 附完整版张勇问答实录</summary><br>

<a href="https://www.youtube.com/watch?v=E-U_JKKQFUk" target="_blank">
    <img src="https://img.youtube.com/vi/E-U_JKKQFUk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】马云回国 | 张勇宣布阿里巴巴成立24年来最大组织调整 | 1+6+N 组织架构 | 子公司可独立融资和上市 | 附完整版张勇问答实录



---

</details>

<details>
<summary>34. 【ChatGPT】OpenAI针对之前的全球服务宕机事件，发布了事故分析报告，事故导致部分用户聊天记录和支付记录数据被泄露，原因是Redis开源库的一个bug导致。</summary><br>

<a href="https://www.youtube.com/watch?v=NnxE9aM6eQ4" target="_blank">
    <img src="https://img.youtube.com/vi/NnxE9aM6eQ4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【ChatGPT】OpenAI针对之前的全球服务宕机事件，发布了事故分析报告，事故导致部分用户聊天记录和支付记录数据被泄露，原因是Redis开源库的一个bug导致。



---

</details>

<details>
<summary>33. 【ChatGPT】《ChatGPT 提示的艺术：如何使用清晰有效的提示》| 三分钟精华内容解读 | 如何写出有效ChatGPT提示语 | 需要避免哪些错误方式 | 什么是角色扮演大法 | 大量示例参考</summary><br>

<a href="https://www.youtube.com/watch?v=jBP5U-eQmZQ" target="_blank">
    <img src="https://img.youtube.com/vi/jBP5U-eQmZQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【ChatGPT】《ChatGPT 提示的艺术：如何使用清晰有效的提示》| 三分钟精华内容解读 | 如何写出有效ChatGPT提示语 | 需要避免哪些错误方式 | 什么是角色扮演大法 | 大量示例参考



---

</details>

<details>
<summary>32. 【编程工具】首个接入 GPT-4的开源代码编辑器Cursor，比GitHub Copilot还好用的IDE，实例演示如何用对话实现一个爬虫程序</summary><br>

<a href="https://www.youtube.com/watch?v=9XzEuEZlji0" target="_blank">
    <img src="https://img.youtube.com/vi/9XzEuEZlji0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【编程工具】首个接入 GPT-4的开源代码编辑器Cursor，比GitHub Copilot还好用的IDE，实例演示如何用对话实现一个爬虫程序



---

</details>

<details>
<summary>31. 【人工智能】日本第一部正式出版的AI作画漫画单行本《赛博朋克桃太郎》，基于Midjourney V3 AI作画，人人都能当漫画家的时代来临</summary><br>

<a href="https://www.youtube.com/watch?v=72_XPwPhv4I" target="_blank">
    <img src="https://img.youtube.com/vi/72_XPwPhv4I/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】日本第一部正式出版的AI作画漫画单行本《赛博朋克桃太郎》，基于Midjourney V3 AI作画，人人都能当漫画家的时代来临



---

</details>

<details>
<summary>30. How did Shou Zi Chew become the CEO of TikTok from a military officer?</summary><br>

<a href="https://www.youtube.com/watch?v=Nrdj9Vfo_rQ" target="_blank">
    <img src="https://img.youtube.com/vi/Nrdj9Vfo_rQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# How did Shou Zi Chew become the CEO of TikTok from a military officer?



---

</details>

<details>
<summary>29. ChatGPT release integration with third-party plug-ins</summary><br>

<a href="https://www.youtube.com/watch?v=8RCzEeaPVh4" target="_blank">
    <img src="https://img.youtube.com/vi/8RCzEeaPVh4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# ChatGPT release integration with third-party plug-ins



---

</details>

<details>
<summary>28. 【人工智能】GitHub 官方发布Copilot X | 新一代基于 AI 驱动的代码编辑器  | 集成了 GPT-4 聊天功能 | 动动嘴就能写代码</summary><br>

<a href="https://www.youtube.com/watch?v=XSkyl7P03D8" target="_blank">
    <img src="https://img.youtube.com/vi/XSkyl7P03D8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】GitHub 官方发布Copilot X | 新一代基于 AI 驱动的代码编辑器  | 集成了 GPT-4 聊天功能 | 动动嘴就能写代码



---

</details>

<details>
<summary>27. Tencent 2022 Financial Report Quick Read</summary><br>

<a href="https://www.youtube.com/watch?v=IYsY2E5AN3k" target="_blank">
    <img src="https://img.youtube.com/vi/IYsY2E5AN3k/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Tencent 2022 Financial Report Quick Read



---

</details>

<details>
<summary>26. 【人工智能】巨头开启AI对决，为了应战微软和OpenAI，谷歌开放了Bard公测，目前仅面向英美成年用户，初始版本只能对文本响应，因为之前Bard有过翻车经历，所以这次谷歌显得非常谨慎</summary><br>

<a href="https://www.youtube.com/watch?v=JhMe0fk7zlA" target="_blank">
    <img src="https://img.youtube.com/vi/JhMe0fk7zlA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】巨头开启AI对决，为了应战微软和OpenAI，谷歌开放了Bard公测，目前仅面向英美成年用户，初始版本只能对文本响应，因为之前Bard有过翻车经历，所以这次谷歌显得非常谨慎



---

</details>

<details>
<summary>25. 【ChatGPT】昨晚ChatGPT全球范围大崩溃 | 宕机超12小时 | OpenAI修复时间长达5个小时 | 连DALL-E也一起遭殃 | 打工人已经不能没有ChatGPT</summary><br>

<a href="https://www.youtube.com/watch?v=K5itlOKMiYc" target="_blank">
    <img src="https://img.youtube.com/vi/K5itlOKMiYc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【ChatGPT】昨晚ChatGPT全球范围大崩溃 | 宕机超12小时 | OpenAI修复时间长达5个小时 | 连DALL-E也一起遭殃 | 打工人已经不能没有ChatGPT



---

</details>

<details>
<summary>24. Kai-fu Lee announced that he will personally organize Project AI2.0, personally serve as the CEO.</summary><br>

<a href="https://www.youtube.com/watch?v=cHCQ-2JDrPg" target="_blank">
    <img src="https://img.youtube.com/vi/cHCQ-2JDrPg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Kai-fu Lee announced that he will personally organize Project AI2.0, personally serve as the CEO.



---

</details>

<details>
<summary>23. The latest regulations of the U.S. Copyright Office: AIGC works a are not protected by copyright law</summary><br>

<a href="https://www.youtube.com/watch?v=nPbLL1-MQho" target="_blank">
    <img src="https://img.youtube.com/vi/nPbLL1-MQho/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# The latest regulations of the U.S. Copyright Office: AIGC works a are not protected by copyright law



---

</details>

<details>
<summary>22. Microsoft 365 Copilot  latest function preview</summary><br>

<a href="https://www.youtube.com/watch?v=Uw3don_yKz4" target="_blank">
    <img src="https://img.youtube.com/vi/Uw3don_yKz4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Microsoft 365 Copilot  latest function preview



---

</details>

<details>
<summary>21. 【电影】对话国内资深影评人“法兰西胶片”| 沙赞2为何垃圾 | 中国观众是否需要好莱坞电影 | DC和漫威宇宙的未来 | 2023奥斯卡获奖影片 | 《瞬息全宇宙》《西线无战事》《报丧女妖》《塔尔》</summary><br>

<a href="https://www.youtube.com/watch?v=6Ub1aAUx56k" target="_blank">
    <img src="https://img.youtube.com/vi/6Ub1aAUx56k/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【电影】对话国内资深影评人“法兰西胶片”| 沙赞2为何垃圾 | 中国观众是否需要好莱坞电影 | DC和漫威宇宙的未来 | 2023奥斯卡获奖影片 | 《瞬息全宇宙》《西线无战事》《报丧女妖》《塔尔》



---

</details>

<details>
<summary>20. Microsoft and Google have released office AI products, Office 365 Copilot and Workspace AI</summary><br>

<a href="https://www.youtube.com/watch?v=wRJZ9oNhxvs" target="_blank">
    <img src="https://img.youtube.com/vi/wRJZ9oNhxvs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Microsoft and Google have released office AI products, Office 365 Copilot and Workspace AI



---

</details>

<details>
<summary>19. 【人工智能】百度今天发布了对标ChatGPT的大语言模型“文心一言”，但是令人失望，来说一说其中的原因。</summary><br>

<a href="https://www.youtube.com/watch?v=bch-ZhF_uxw" target="_blank">
    <img src="https://img.youtube.com/vi/bch-ZhF_uxw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】百度今天发布了对标ChatGPT的大语言模型“文心一言”，但是令人失望，来说一说其中的原因。



---

</details>

<details>
<summary>18. The former Google director predicted  AIGC will end the programming industry within 3 years</summary><br>

<a href="https://www.youtube.com/watch?v=QF_8dvfMYws" target="_blank">
    <img src="https://img.youtube.com/vi/QF_8dvfMYws/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# The former Google director predicted  AIGC will end the programming industry within 3 years



---

</details>

<details>
<summary>17. GPT-4 is coming | Support multi-modality | OpenAI Evals | new Bing search engine adopts GPT-4</summary><br>

<a href="https://www.youtube.com/watch?v=UcvzsuJtTjM" target="_blank">
    <img src="https://img.youtube.com/vi/UcvzsuJtTjM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# GPT-4 is coming | Support multi-modality | OpenAI Evals | new Bing search engine adopts GPT-4



---

</details>

<details>
<summary>16. Michelle Yeoh |2023 Oscar Best Actress Contender| From a martial arts actor to a global movie queen</summary><br>

<a href="https://www.youtube.com/watch?v=o_2-dIowryg" target="_blank">
    <img src="https://img.youtube.com/vi/o_2-dIowryg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Michelle Yeoh |2023 Oscar Best Actress Contender| From a martial arts actor to a global movie queen



---

</details>

<details>
<summary>15. Google launches the largest visual language model in history - PaLM-E | 562 billion parameters</summary><br>

<a href="https://www.youtube.com/watch?v=u78TTkmojaE" target="_blank">
    <img src="https://img.youtube.com/vi/u78TTkmojaE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Google launches the largest visual language model in history - PaLM-E | 562 billion parameters



---

</details>

<details>
<summary>14. 【人物】莫娣·刘易斯 | Maud Lewis，加拿大传奇民间女画家，幼年患疾，失去父母，被哥哥抛弃，却遇到脾气古怪的埃弗雷特并相伴一生，即便命运悲惨，依然用手中的画笔绘尽生活的美好和幸福。</summary><br>

<a href="https://www.youtube.com/watch?v=SB7V4JRQtnk" target="_blank">
    <img src="https://img.youtube.com/vi/SB7V4JRQtnk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】莫娣·刘易斯 | Maud Lewis，加拿大传奇民间女画家，幼年患疾，失去父母，被哥哥抛弃，却遇到脾气古怪的埃弗雷特并相伴一生，即便命运悲惨，依然用手中的画笔绘尽生活的美好和幸福。



---

</details>

<details>
<summary>13. 【ChatGPT】The real creator of AI | 35-year-old CTO of OpenAI | Godmother of ChatGPT | Mira Murati</summary><br>

<a href="https://www.youtube.com/watch?v=iqK4Rz35SQg" target="_blank">
    <img src="https://img.youtube.com/vi/iqK4Rz35SQg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【ChatGPT】The real creator of AI | 35-year-old CTO of OpenAI | Godmother of ChatGPT | Mira Murati



---

</details>

<details>
<summary>12. 【chatGPT】Uncover the AI dream team behind ChatGPT. There are only 87 members in the team.</summary><br>

<a href="https://www.youtube.com/watch?v=yIaOBUYZ884" target="_blank">
    <img src="https://img.youtube.com/vi/yIaOBUYZ884/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【chatGPT】Uncover the AI dream team behind ChatGPT. There are only 87 members in the team.



---

</details>

<details>
<summary>11. Zheng Linghua, a young girl who was suffered from depression just because she dyed her pink hair</summary><br>

<a href="https://www.youtube.com/watch?v=LW50f31U-L8" target="_blank">
    <img src="https://img.youtube.com/vi/LW50f31U-L8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Zheng Linghua, a young girl who was suffered from depression just because she dyed her pink hair



---

</details>

<details>
<summary>10. How accurate are the prophecies of The Simpsons?How did the prophecy become popular on the Internet?</summary><br>

<a href="https://www.youtube.com/watch?v=7oXah5aH_6A" target="_blank">
    <img src="https://img.youtube.com/vi/7oXah5aH_6A/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# How accurate are the prophecies of The Simpsons?How did the prophecy become popular on the Internet?



---

</details>

<details>
<summary>9. 【传说】八仙过海，各显神通。八仙的传说是从何处起源，人物是如何确定，以及这八个人都是何来历呢？</summary><br>

<a href="https://www.youtube.com/watch?v=gKitUAS8ebg" target="_blank">
    <img src="https://img.youtube.com/vi/gKitUAS8ebg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【传说】八仙过海，各显神通。八仙的传说是从何处起源，人物是如何确定，以及这八个人都是何来历呢？



---

</details>

<details>
<summary>8. Liu Wenzheng, the first superstar in the history of Chinese pop music</summary><br>

<a href="https://www.youtube.com/watch?v=zCiLGi6roQY" target="_blank">
    <img src="https://img.youtube.com/vi/zCiLGi6roQY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Liu Wenzheng, the first superstar in the history of Chinese pop music



---

</details>

<details>
<summary>7. Three websites you can play GBA/FC/arcade/DOS games online for free, classic games are fun to play</summary><br>

<a href="https://www.youtube.com/watch?v=jnpFqIwsLjw" target="_blank">
    <img src="https://img.youtube.com/vi/jnpFqIwsLjw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Three websites you can play GBA/FC/arcade/DOS games online for free, classic games are fun to play



---

</details>

<details>
<summary>6. 【人工智能】ChatGPT最强竞争对手Claude横空出世，六大能力PK实测早知道</summary><br>

<a href="https://www.youtube.com/watch?v=SQEA4oRXR_w" target="_blank">
    <img src="https://img.youtube.com/vi/SQEA4oRXR_w/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】ChatGPT最强竞争对手Claude横空出世，六大能力PK实测早知道



---

</details>

<details>
<summary>5. The only consortium family in China,  three generations are the richest men in China</summary><br>

<a href="https://www.youtube.com/watch?v=AZCe6u0FvJM" target="_blank">
    <img src="https://img.youtube.com/vi/AZCe6u0FvJM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# The only consortium family in China,  three generations are the richest men in China



---

</details>

<details>
<summary>4. 【酷站】个人专属卡通头像（avatar）生成器！简单好用，透明背景，近百个选项，还可以导出PNG、SVG！</summary><br>

<a href="https://www.youtube.com/watch?v=fuze2Bro_WY" target="_blank">
    <img src="https://img.youtube.com/vi/fuze2Bro_WY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【酷站】个人专属卡通头像（avatar）生成器！简单好用，透明背景，近百个选项，还可以导出PNG、SVG！



---

</details>

<details>
<summary>3. 【ChatGPT】ChatGPT怎么用 | ChatGPT使用教程  | 产品经理教你如何使用ChatGPT |  ChatGPT实战教程 | ChatGPT 7种提升工作效率的用法 | OpenAI</summary><br>

<a href="https://www.youtube.com/watch?v=t4yDJ2KSLFM" target="_blank">
    <img src="https://img.youtube.com/vi/t4yDJ2KSLFM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【ChatGPT】ChatGPT怎么用 | ChatGPT使用教程  | 产品经理教你如何使用ChatGPT |  ChatGPT实战教程 | ChatGPT 7种提升工作效率的用法 | OpenAI



---

</details>

<details>
<summary>2. 【酷站】免费好用的阿里云盘搜索引擎，无需注册，不用付费，拒绝套路! Free aliyun cloud disk search engine</summary><br>

<a href="https://www.youtube.com/watch?v=66xTXBhlnWM" target="_blank">
    <img src="https://img.youtube.com/vi/66xTXBhlnWM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【酷站】免费好用的阿里云盘搜索引擎，无需注册，不用付费，拒绝套路! Free aliyun cloud disk search engine



---

</details>

<details>
<summary>1. 【酷站】无需下载，重温怀旧经典DOS游戏，玩到停不下来！</summary><br>

<a href="https://www.youtube.com/watch?v=rXst12-0200" target="_blank">
    <img src="https://img.youtube.com/vi/rXst12-0200/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【酷站】无需下载，重温怀旧经典DOS游戏，玩到停不下来！



---

</details>

