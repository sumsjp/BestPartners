<details>
<summary>200. [2023-10-28] 【人工智能】波士顿动力Spot开口说话了 | ChatGPT ｜机器狗导游 | 正宗伦敦腔</summary><br>

<a href="https://www.youtube.com/watch?v=8EeX6EwXIpY" target="_blank">
    <img src="https://img.youtube.com/vi/8EeX6EwXIpY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】波士顿动力Spot开口说话了 | ChatGPT ｜机器狗导游 | 正宗伦敦腔

好的，我來幫你整理這段文稿，使其更具結構性和易讀性。我會將其分為幾個部分，並提煉關鍵信息：

**標題：** 波士頓動力 Spot 機器狗整合 ChatGPT：解鎖語言能力，化身導遊

**簡介：**

*   最佳拍檔的大飛介紹了波士頓動力公司發布的 Spot 機器狗新影片，展示了其整合 ChatGPT 後獲得的語言能力和互動性。
*   Spot 現在可以像導遊一樣，用英國口音與人對話，回答問題，並根據語音指令做出相應動作。

**Spot 的新功能：**

*   **語言能力：**
    *   歸功於 ChatGPT，Spot 不僅可以“說話”，還能模仿不同的個性，包括口音、語氣和表達方式。
    *   Spot 可以觀察環境並使用 VQA (視覺問答) 或字幕模型描述物體。
    *   結合文本轉語音技術，Spot 可以與人進行實時對話。
*   **互動性：**
    *   Spot 可以根據語音指令做出相應動作，例如說 "Follow me" 時自動轉身引路。
    *   當人們指著某個物體時，Spot 會抬頭看向該物體並進行解說。
*   **個性化：**
    *   通過修改 Spot 的代碼，可以改變其輸出，包括口音、句子組織和聲音音調，甚至轉頭方式。

**技術細節：**

*   **硬體：**
    *   安裝了揚聲器和環形陣列麥克風（Respeaker V2）用於音訊處理。
    *   實際控制權下放給機外電腦，通過 SDK 與 Spot 進行通信。
    *   配備機械臂和機械臂攝影機。
*   **軟體：**
    *   使用 OpenAI 的 ChatGPT API（gpt-3.5 和 gpt-4）進行對話生成。
    *   採用精心的提示工程，讓 ChatGPT 像編寫 Python 腳本一樣工作。
    *   結合 VQA 和語音轉文字軟體，讓 Spot 能夠理解視覺和聽覺信息。
    *   使用 ElevenLabs 進行文本轉語音，並採用並行流式傳輸以減少延遲。
*   **地圖與定位:**
    *   團隊為 Spot 導覽的建築環境建立 3D 地圖。
    *   為大語言模型注入位置資訊，讓 Spot 知道自己在建築物內的哪個位置(實驗室陽台、天橋、博物館陳列等等)

**大語言模型的應用和優勢：**

*   Spot 利用大語言模型的湧現行為，使其能夠執行既定訓練之外的任務。
*   大語言模型可以作為即興演員，根據大致腳本填補空白動作場景。
*   通過限制大語言模型的使用範圍，降低其可能產生的幻覺風險。

**實驗中的趣事：**

*   當詢問 Spot 波士頓動力執行董事是誰時，它會帶領人們到服務台詢問。
*   當詢問 Spot 的父母是誰時，它會走向 Spot V1 和 Big Dog 的展示區。

**未來展望：**

*   大飛認為大語言模型結合機器人的領域具有非常大的想像空間。
*   具身智能是 AI 最近非常火爆的一個方向。
*   人們對《西部世界》的到來充滿期待。

**總結：**

波士頓動力 Spot 機器狗整合 ChatGPT 後，在語言能力和互動性上取得了重大突破，為具身智能的發展提供了新的可能性。

**後記：**

歡迎大家在評論區留言，分享對於能說話交流的機器人狗子的應用想法。

---

**額外建議：**

*   **加上時間戳：** 如果影片中有重要的時間點，可以在整理後的文稿中加上時間戳，方便讀者快速定位。
*   **配上圖片：** 如果能加上一些截圖或照片，例如 Spot 的外觀、硬體配置、以及它與人互動的畫面，會讓文稿更生動。
*   **关键词：** 在文稿中，Spot, ChatGPT, 波士顿动力，机器人，人工智能，具身智能 等等，可以利用粗体，让读者更容易抓取。

希望這個整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>199. [2023-10-25] 【AIGC】DALL-E 3技术报告解读 | 文生图 | 指令遵循 | 图片标题合成 | CLIP | Latent Diffusion</summary><br>

<a href="https://www.youtube.com/watch?v=2QtOFC7Tgx4" target="_blank">
    <img src="https://img.youtube.com/vi/2QtOFC7Tgx4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】DALL-E 3技术报告解读 | 文生图 | 指令遵循 | 图片标题合成 | CLIP | Latent Diffusion

好的，我將盡力為您整理這篇文稿，使其更易於理解。我會著重於提取關鍵資訊、理清邏輯結構，並提供一些可能的改進建議。

**整理後的文稿：**

**核心觀點：**

DALL-E 3 的主要改進在於提高了提示遵循能力 (Prompt Following)，即生成的圖像與輸入文本提示的一致性。這主要歸功於 OpenAI 使用合成圖像標題來改善訓練數據集。

**整體架構：**

OpenAI 的技術報告分為兩部分：

1.  **如何通過合成訓練數據集中圖像的標題 (Caption)，來提升模型的生成能力。**
2.  **DALL-E 3 和其他文生圖模型的評測比較。**

**第一部分：合成圖像標題**

*   **問題：** 現有文生圖模型在文本理解能力上有缺陷，尤其是在複雜文本描述下，生成的圖像容易忽略部分信息，甚至無法生成符合文本描述的圖像。主要原因是訓練數據集的圖像標題不夠準確（過於簡單或不相關）。
*   **解決方案：** 訓練一個圖像標題生成器 (Image Captioner) 來合成圖像的標題。
    *   模型架構：Google 的 CoCa (類似 CLIP，但增加了一個多模態文本編碼器，可以生成標題)。
    *   微調：
        *   方案一：使用只描述圖像主體的短標題微調。
        *   方案二：使用詳細描述圖像內容的長標題微調。
*   **實驗分析：**
    *   比較了使用原始標題、合成短標題和合成長標題訓練的模型的性能（使用 CLIP 得分評估）。
    *   結果表明，使用合成長標題能顯著提升模型的提示遵循能力。
    *   實驗還找到了最佳的數據混合比例：5% 原始標題 + 95% 合成長標題。
*   **GPT-4 輔助：** 為了避免模型過擬合長標題，DALL-E 3 使用 GPT-4 來將用戶輸入的標題上採樣 (擴展) 為長標題，確保輸入數據與訓練數據的分布一致。

**第二部分：模型評測**

*   **DALL-E 3 的具體實現細節：**
    *   採用 95% 合成長標題 + 5% 原始標題混合訓練。
    *   使用一個更大的基於 T5-XXL 的 latent diffusion 模型 (可能是 SDXL 的擴展版本)。
    *   **細節提升：**
        *   分辨率提升：生成 1024x1024 以上的圖像，可能採用類似 SDXL 的遞進式訓練策略和多尺度訓練策略。
        *   細節提升：額外訓練了一個 latent decoder 來提升圖像的細節（尤其是文字和人臉），基於 DDPM 架構，並使用 Consistency Models 的蒸餾策略加速。
*   **評測方法：**
    *   **自動評測：** 使用 CLIP 得分、GPT-4V 和 T2I-CompBench (評測顏色、形狀、紋理綁定) 等指標。
    *   **人工評測：** 評測提示遵循、風格和一致性 (連貫性)。
*   **評測結果：** DALL-E 3 在各項評測中均優於 DALL-E 2 和 SDXL。
*   **DALL-E 3 的局限性：**
    *   在空間位置關係的處理上容易出錯。
    *   文字生成能力仍有提升空間 (多詞或少詞)。
    *   合成標題可能幻想圖像中的重要細節，導致模型在生成特定種類的東西時不完全可靠。
    *   安全性和偏見 (所有大模型都面臨的問題)。

**總結：**

DALL-E 3 的核心優勢在於使用了合成標題來構建高質量的訓練數據集，從而顯著提升了模型的提示遵循能力。雖然技術上沒有太大的創新，但數據質量的提升是關鍵。OpenAI 訓練了自己的圖像標題生成模型，並且使用GPT-4来优化用户输入。未来文生图模型的发展方向可能会侧重于优化标题来提升模型效果。

**可能的改进建议：**

*   **更清晰的結構:** 將文稿分割成更小的部分，每個部分有一個明確的標題，方便讀者快速定位到自己感興趣的內容。
*   **更明確的術語解釋:** 對於一些技術術語 (例如：latent diffusion model, CLIP, VAE, DDPM 等)，可以提供更簡單的解釋，或者提供外部連結供讀者參考。
*   **增加視覺化元素:** 加入一些圖表或示例圖片，可以幫助讀者更直觀地理解文稿的內容。

我希望這個整理後的文稿對您有所幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>198. [2023-10-23] 【思考】超线性回报 | 保罗·格雷厄姆最新长文 | 万字精华总结 | 如何获得超线性回报 | 指数增长 | 阈值  | 好奇心</summary><br>

<a href="https://www.youtube.com/watch?v=tgseAzI3fmg" target="_blank">
    <img src="https://img.youtube.com/vi/tgseAzI3fmg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【思考】超线性回报 | 保罗·格雷厄姆最新长文 | 万字精华总结 | 如何获得超线性回报 | 指数增长 | 阈值  | 好奇心

好的，這是整理後的文稿，我盡量保持原文的風格，並調整了結構，使其更清晰易讀。

**標題：保羅·格雷厄姆萬字長文解讀：如何獲得超線性回報**

**引言 (大飛)**

大家好，這裡是最佳拍檔，我是大飛。

之前我們介紹過保羅·格雷厄姆 (Paul Graham) 的文章《如何做出偉大的工作》。前兩天他又發表了一篇萬字長文，乾貨滿滿。文章提到，線性增長無法獲得超額回報，而超線性回報往往與「你的付出」不成正比。這讓我想起《10 倍比 2 倍簡單》這本書，書中提到 2 倍增長是線性的，需要更多努力、更辛勤地工作，而不是更聰明地工作；而 10 倍增長是非線性的，巨大的增長並不需要更多努力，往往只需要更少的努力，但要做到更好。

保羅在文章中還提到，現在的時代不同以往，不再需要加入知名組織、機構才能獲取所需資源、實現超額增長。現在有更多的人可以像 20 世紀的藝術家和作家一樣擁有自由。有很多雄心勃勃的項目不需要太多的初始資金。

此外，保羅還講到了如何尋找能夠獲得超線性回報的領域，以及什麼樣的人能夠獲得超線性回報，那就是尋找那些只有少數玩家勝過其他人的領域。如果在一個每個人表現都差不多的領域，不太可能存在超線性回報。在超線性領域，一開始你的成績肯定會微不足道，但是超線性回報的獎勵曲線上升速度會非常快，從專注於一小部分客戶開始，你將通過口碑傳播獲得指數級增長。同理，學習、科研、投資都是如此。

對我最有感觸的還是這句話：「不要把 work 等同於一份 job，要被好奇心驅使，而不是職業主義，要給予你的好奇心自由發揮，而不是只做你應該做的事情。」

以下是對原文的解讀 (有刪減)。

**保羅·格雷厄姆原文核心觀點：超線性回報的本質與獲取方式**

**1. 超線性回報是世界的特徵，而非人為規則**

*   傳統觀念認為回報是線性的，但現實並非如此。
*   在商業中，超線性績效回報是普遍存在的。
*   這種現象在名望、權力、軍事勝利、知識等方面也同樣適用。
*   理解超線性回報的概念，才能真正理解這個世界。

**2. 超線性回報的兩個基本原因：指數增長與閾值**

*   **指數增長：**
    *   類似於細菌培養，擅長培養的人與不擅長的人之間結果差異巨大。
    *   初創企業也存在指數增長，高增長率的公司往往變得非常有價值。
    *   Y Combinator 鼓勵創始人專注於增長率而不是絕對數字。
    *   隨著時間推移，績效的回報與績效的t次方成正比。
    *   儘管指數增長有實際限制（例如：土地面積），但總有方法突破（例如：征服）。

*   **閾值（臨界值）：**
    *   體現在「贏者通吃」的現象中，例如體育比賽。
    *   閾值的存在並非來自競爭本身，而來自結果中存在臨界點。
    *   即使沒有競爭，也可能存在閾值，例如證明一個定理或命中一個目標。

*   **超線性回報的結合：** 跨越閾值會導致指數增長，指數增長又會助你跨越閾值。
    *   例子：名氣（粉絲吸引粉絲的指數增長，以及普通人心智位置有限的閾值）。
    *   例子：學習（知識的指數增長，以及學會騎車、閱讀等知識閾值）。新的發現更是重要的閾值，會引導你進入一個全新的領域。

**3. 如何尋找具有超線性回報的情況**

*   **尋求能夠複合的工作：**
    *   直接複合：表現良好會使你在下一個週期中表現更好（例如：建設基礎設施、品牌營銷）。
    *   通過學習來複合：即使過程中表現不佳，但如果學到很多東西，仍然會獲得指數增長。
    *   不要過於優化學習內容，不要限制自己只學習已知有價值的東西。

*   **利用閾值，但要確保遊戲值得玩：** 如果指數增長足夠快，即使起初微不足道，它也會變得很大。 如果遇到一些平庸卻仍然受歡迎的事物，替換它可能是一個好主意。

*   **被好奇心驅使，而不是職業主義：** 讓好奇心自由發揮，而不是只做你應該做的事情。

**4. 超線性回報的機遇正在增長**

*   技術進步和組織重要性的下降，使得更多人可以像 20 世紀的藝術家和作家一樣擁有自由。
*   現在有更多雄心勃勃的項目不需要太多的初始資金。
*   也出現了新的學習、賺錢、找到同事和觸及觀眾的方式。
*   表現優異的人會表現得更好，但表現糟糕的人會變得更糟。

**5. 誰應該追求超線性回報？**

*   知道自己很優秀，知道在一個變化更大的世界裡會淨賺更多的人。
*   可以承擔風險去嘗試並找出答案的人，尤其是年輕人。

**6. 如何利用績效的超線性回報**

*   **做出傑出的工作：** 指數增長曲線的遠端競爭較少，且少有人嘗試。
*   對工作感興趣，僅僅勤奮是不夠的。
*   了解自己的興趣所在，找到適當的工作方法。
*   選擇適合你情況的工作。
*   培養專注的習慣。
*   努力工作，但不要過度勞累。
*   探索知識前沿的空隙，可能擴展成一個全新的領域。
*   承擔儘可能多的風險。
*   尋找最好的同事，培養良好的品味，向最好的榜樣學習。
*   誠實，尤其是對自己誠實。
*   鍛鍊身體，健康飲食和睡眠。
*   避免危險的藥物。
*   追隨你的好奇心，它比你更知道值得關注的事情。
*   運氣也很重要，解決辦法是多試幾次。

**7. 超線性回報意味著不平等**

*   回報曲線越陡峭，結果的變化就越大。
*   尋找少數大贏家勝過其他所有人的領域，例如體育、政治、藝術、音樂、表演、導演、寫作、數學、科學、創業和投資。
*   在這些領域中，你需要投入最初的努力，超線性回報一開始可能微不足道，但隨著發展，獎勵曲線會上升得非常陡峭。

**8.其他建議**
* 對最初的一小部分客戶付出極大的關注，通過口碑傳播啟動指數增長
* 記住“Do things that don't scale”這個原則

*   不要把 work 等同於一份 job。
*   在超限性回報的領域裡，好奇心比野心更重要。

**結語 (大飛)**

總之，保羅·格雷厄姆的文章強調了做自己真正感興趣的事情，全身心投入，才能帶來遠超你想像的回報。而要想做到這一點，就是傾聽自己的好奇心，讓它來帶領我們找到自己真正感興趣的事情。

希望這次的解讀對大家有一點點的啟發。我們下期視頻再見！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>197. [2023-10-16] 【人工智能】OpenAI科学家Hyung Won Chung演讲精华版 | 2023年的大模型 | 涌现 | Transformer | 并行训练 | 后训练阶段 | 奖励模型 | 目标函数学习</summary><br>

<a href="https://www.youtube.com/watch?v=q45PUg8U1e4" target="_blank">
    <img src="https://img.youtube.com/vi/q45PUg8U1e4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OpenAI科学家Hyung Won Chung演讲精华版 | 2023年的大模型 | 涌现 | Transformer | 并行训练 | 后训练阶段 | 奖励模型 | 目标函数学习

好的，我來整理這份文稿，使其更具結構性、重點更清晰，並移除口語化的部分。

**整理後的文稿：**

**主題：Hyung Won Chung（尚哥）「2023年的大型語言模型」演講分享**

**引言：**

*   介紹AI科學家Hyung Won Chung（簡稱尚哥），他近期從Google跳槽至OpenAI。
*   尚哥的演講涵蓋大語言模型的最新動向和技術細節，內容深入淺出，可與安德烈卡帕西的State of GPT演講齊名。
*   PaLM-2的聯合負責人評價尚哥擁有豐富的全棧大語言模型經驗。

**演講主題：「2023年的大型語言模型」**

*   **時間點的重要性：** 強調“2023年”，因為大型模型定義可能在未來幾年內發生變化，導致現有見解和結論過時。
*   **GPT-4的潛力：** 尚哥認為GPT-4即將超越拐點，性能將實現顯著跳躍，因此需要改變觀點，認識到大語言模型蘊藏的巨大潛力。

**核心觀點：規模效應**

1.  **湧現現象：**

    *   模型規模越大（參數數量、訓練數據大小、計算資源），就越可能發生湧現現象。
    *   小型模型在某些任務上進展緩慢，但當規模達到一定程度時，突然就能夠完成這些任務。
    *   即使當前一代的大語言模型還無法展現出某些能力，也不應輕言放棄，而應思考「它還沒行」的原因。
    *   推理思路應轉變為「一些方法只是在當前不起作用」，隨著模型規模擴大，許多結論都會改變。
    *   研究者應不斷更新、拋棄基於過時觀點的直覺。
    *   新研究者可以嘗試在以前模型上不起作用的想法，這些想法可能在新模型上突然有效。
    *   實驗過程中，應記錄失敗的過程，並在新的模型上再次運行實驗，不斷更新和糾正自我認知和理解。
2.  **不同能力與規模的關係：**

    *   以GPT-3和GPT-4為例，針對不同能力：
        *   “能力一”：GPT-4接近轉折點，可能出現躍進式改進。
        *   “能力二”：GPT-4仍有很大距離，目前方法可能無法提供實質性幫助。
        *   “能力三”：GPT-3已超越轉折點，研究可能只帶來漸進式改變。
    *   堅持這種思維框架，經常回顧和反思，更新直覺，就能明白正在解決哪種問題。
3.  **擴大參數規模的方法：**

    *   目前的大型語言模型都採用Transformer架構。
    *   將Transformer看做是一個包含一系列矩陣乘法的序列到序列的映射，進行數組的轉換。
    *   Transformer通過計算點積，使每個序列token都能與其他token進行交互。
    *   Transformer的規模擴大，就是讓很多機器高效地進行矩陣乘法，並減少機器之間的通信。
    *   通過將注意力機制拆分為單獨的頭、利用多台機器和芯片、使用GSPMD方法進行並行化，可以實現。

**訓練與優化：**

1.  **預訓練成本：**

    *   預訓練成本依然很高。
    *   縮放定律是基於小規模模型數據開發的，預測模型擴展損失非常重要。
    *   僅增大規模並不能解決所有問題。
2.  **模型訓練的四個階段：**

    *   預訓練階段
    *   指令微調（監督微調SFT）
    *   獎勵模型訓練
    *   策略模型訓練

3. **指令微調階段 (SFT):**
    * 為所有任務建立從自然語言指令到自然語言回應的映射.
    *  指令微調的核心思路是擴展到對話場景，模型可以與其他代理交互。
    * 增加更多任務雖可提高效能，但存在著邊際效益遞減的限制，任務的多樣性是關鍵。
    * 指令微調的目標函數是瓶頸，難以使用狹窄的信號訓練大型模型。

4.  **強化學習與RLHF (Reinforcement Learning from Human Feedback):**

    *   最大化預期的獎勵函數。
    *   使用獎勵模型來為更複雜的情況定義獎勵。
    *   通過人類比較兩個答案的優劣，讓模型學習人類偏好，而非直接告知最佳答案。
    *   比較比絕對評分更簡單，獎勵模型實際上是在用最大似然法來訓練。

5.  **策略模型 (Policy Model):**
    * 策略模型通常從監督指令微調的檢查點開始，生成一些補全，並提供給獎勵模型返回得分。
    *  透過策略梯度演算法迭代進行，在滿足 RM 模型條件下，讓策略模型通過強化學習來學習這些偏好。
    *  RLHF 實施困難，獎勵模型容易出錯，產生所謂的“獎勵黑客”問題 (模型為了得到更高獎勵產生沒意義的長答案)。
    *  RLHF 是一個有價值的研究方向，可以幫助我們克服最大似然的偏差。

**人工智能發展的演進：**

*   從基於規則的系統到深度學習，再到可學習的損失函數。
*   深度學習的成功在於採用了更弱的歸納偏差，並允許了更高的可擴展性。
*   下一個演進階段可能是讓損失函數也變得可學習。
*   GAN和RLHF是成功的例子，學習損失函數或目標函數將是下一個範式。

**總結：**

*   規模是關鍵，從規模的角度看問題至關重要。
*   學習損失函數或目標函數將是未來的發展方向。

**附註：**

*   省略了對Transformer和並行計算的詳細講解，可參考原視頻。

**這個版本更著重於組織信息，使其易於理解和查找，並去除了口語化的表達方式。** 這樣更適合作為文件整理的結果。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>196. [2023-10-05] 【商业】37Signals公司的37条Signal | 创业Startup | ShapeUp | Rework | Remote</summary><br>

<a href="https://www.youtube.com/watch?v=IaexGrt3wZ0" target="_blank">
    <img src="https://img.youtube.com/vi/IaexGrt3wZ0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】37Signals公司的37条Signal | 创业Startup | ShapeUp | Rework | Remote

好的，這是經過整理的文稿，我將其結構化、精簡重複內容，並著重於核心觀點：

**最佳拍檔 - 37signals 的 37 條想法分享**

大家好，我是大飛，歡迎來到最佳拍檔。

最近在 37signals 網站上看到他們的 37 條 "Signals"，覺得很有意思，想跟大家分享。

**關於 37signals 公司：**

這是我個人很喜歡的一家極客公司，從外包公司起家，靠著幾款小而美的產品積攢了口碑，估值不錯，也出版過《Rework重構》等書籍，是遠程辦公、敏捷開發的早期推動者。主要產品有 Basecamp 和 Hey，也是 Ruby On Rails 框架的開發者和維護者。

雖然 Ruby On Rails 框架曾經流行過，但我翻譯出版過相關書籍，但最終不敵國內流水線化的大潮，現在國內使用該框架的已經很少了。

接下來，我們一起來看看這 37 個想法，看看這家公司特立獨行的思考。雖然不一定能實踐，但有助於開拓眼界。

**37signals 的 37 條想法：**

1.  **獨立的義務：** 沒有投資者、沒有董事會，不考慮退出，保持獨立性，才能做想做的事，做其他公司不敢做的事。
2.  **工作不是戰爭：** 避免使用戰爭隱喻（征服市場、占領份額等），工作是和平的。
3.  **小團隊：** 小團隊可以幹大事，大團隊難做小事，小的力量，只做需要做的，無需過度浪費。
4.  **利潤驅動：** 收入 > 支出，每一年的經營都是盈利的，這是一種對客戶負責的方式。
5.  **行勝於言：** 立即行動，如果必要，就再做一次，大多數決策缺乏遠見。
6.  **ShapeUP 方法：** (略) 一個迭代，幫助軟體團隊每 6 週設計、開發和交付優秀的軟體，可以單獨介紹。
7.  **賣產品，不賣用戶：** 不出售客戶數據，不使用個人信息進行目標廣告投放，商業模式是賣產品，而不是賣用戶。
8.  **3 個 8：** 8 小時工作 + 8 小時生活 + 8 小時睡眠，睡眠不足是愚蠢的標誌。 (推薦馬修·沃克的《我們為什麼睡覺》)
9.  **拒絕實時：** 避免期望立即回應，認為緊迫性被高估，“盡快 ASAP”是一劑毒藥。
10. **财富500万强的公司：** 更關注像我們一樣的中小型公司。
11. **不要效仿辦公室：** 推崇遠程工作，減少會議，使用異步溝通，信任他人，反對辦公室及其所代表的一切。(相關書籍)
12. **時間是不一樣的：** 60 分鐘連續構成的一小時，質量比被切割成四個 15 分鐘的一小時高，不被打斷的時間，可以帶來更高質量工作
13. **重複：** 要讓其他人聽到新的、獨特的觀點，可能需要重複多年。
14. **開會的代價很昂貴：** 會議應該是最後的手段，衡量開會的成本，並加以權衡，是否可以用寫個文檔來代替？
15. **拒絕焦慮：** 不要讓自己精疲力竭，投入一天的工作後，就關上電腦，繼續生活。
16. **小心邊緣思維的陷阱：** 如果需要一台機器但沒買，最終會發現你付了錢，卻沒有得到它。
17. **避免政治活動：** 尊重政治表達和活動的權利，但避免在工作中、在內部溝通系統中進行政治辯論。
18. **客戶服務的兩枚硬幣：** 不要逼客戶拿起“這是世界末日”的那枚硬幣。
19. **向人員付費，而不是向地址付費：** 相同職位的每個人都應該獲得相同的報酬，無論他們住在哪里，或者他們是誰。
20. **小的科技進步：** 倡導小的科技進步，反對索取、窺探、瞄準、剝削、展現力量、踐踏。
21. **知道拒絕：** 說“不”表示拒絕一件事情，說“是”卻表示拒絕很多事情。
22. **長期創業：** 傾向於長期創業，長期並非是一種僥倖，激發員工的信心。
23. **長期計劃 vs. 短期計劃：** 長期計劃是你在思考的事情，短期計劃是你在想的事情。
24. **固化：** 確保事情在預定時間和預算內完成的方式：縮小範圍。
25. **不同意但是接受和投入：** 達成共識並非目標，正確的決定才是，一旦決定，全力投入和支持。
26. **直面挫折，不要浪費每一次的危機：** 逆境可以幫助你增強反脆弱性。
27. **全球化：** 付費客戶遍布 160 多個國家/地區，團隊遍布世界五大洲，讓世界觀、文化視角和社會政治觀多元化。
28. **目標：** 為設定目標時的我們，來設定目標。
29. **享受錯過而不是害怕錯過：** 寧願慶祝和享受錯過，生活會變得更好。
30. **溝通問題：** 公司沒有溝通問題，是人有溝通不暢的問題，組織或團隊越小，溝通不暢的可能性越少。
31. **容易？：** 不要假設你不熟悉、不常做的事情很容易。
32. **我們發明了 Ruby on Rails：** 是一個免費的開源框架，運行著 Shopify、Coinbase、GitHub、Airbnb 等等，Basecamp 是第一個 Rails 應用程式。
33. **計畫就是猜測：** 越長期的計畫，猜測的準確性越差，習慣用週來代替年，更頻繁的計畫。
34. **睡一覺再說：** 睡一覺再回來看，更能看清楚真相。
35. **公司不是家：** 好公司不會裝成是家，而是家的盟友，不會侵占員工的個人時間。
36. **上下文大於一致性：** 在設計方面，應該圍繞當前的情況進行設計，而不是非要跟之前的設計保持一致。
37. **我們名字中的彩蛋：** 37Signals 是因為人類不斷分析來自外太空的無線電波，寻找外星智慧生命，但仍然有 37 個信號無法解釋。

以上就是 37signals 的 37 個 Signal，感謝大家的觀看，下期再見！

**修改說明：**

*   **精簡語言：** 去除了口語化的語氣詞和重複的描述，使內容更簡潔。
*   **結構化呈現：** 將內容分為公司介紹和 37 條想法兩部分，並對想法進行編號，方便閱讀。
*   **歸納重點：** 將每條想法的重點提取出來，方便快速了解核心內容。
*   **刪除無關內容：** 刪除了一些與主題無關的細節。
*   **修正用词：** 润色部分语句，使其更符合中文语境。

希望這樣的整理對您有幫助！如果您需要更進一步的修改或調整，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>195. [2023-10-04] 【人工智能】Yann LeCun最新德国演讲 | 从机器学习到自主智能 | 自监督学习 | 世界模型 | JEPA</summary><br>

<a href="https://www.youtube.com/watch?v=E1T4l2UReiM" target="_blank">
    <img src="https://img.youtube.com/vi/E1T4l2UReiM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Yann LeCun最新德国演讲 | 从机器学习到自主智能 | 自监督学习 | 世界模型 | JEPA

好的，我將這篇文稿整理如下，更著重重點，並將口語化的語氣轉為更正式的書面語：

**文稿整理：楊立昆（Yann LeCun）「從機器學習到自主智能」演講重點**

**引言**

本次分享內容為深度學習三巨頭之一楊立昆於9月29日在德國的最新演講，主題為「從機器學習到自主智能」。演講旨在闡述楊立昆對AI發展的總體思想，深入淺出，通俗易懂。內容經過精華提煉，以求在最短時間內呈現智者的思考。

**演講核心內容**

楊立昆在此次演講中主要探討目標驅動的AI，旨在打造具有學習、記憶、推理、計畫和常識，且可操控和安全的AI系統。

*   **AI的益處：**
    *   交通：輔助駕駛、自動駕駛可減少碰撞。
    *   藝術：降低創作門檻。
    *   醫學：3D圖像識別技術用於檢測乳腺X光中的腫瘤，MRI數據採集速度提高。
    *   科學研究：神經科學家利用人工神經網路描述大腦工作原理，物理學家基於AI描述粒子碰撞等現象，並驗證暗物質等理論。
    *   環境保護：利用AI模擬化學實驗。
*   **自監督學習的重要性：**
    *   自監督學習無需標注數據或人工干預，即可訓練系統理解數據和世界，在自然語言處理（NLP）領域尤為成功。
    *   範例：BERT模型（透過預測被刪除的文字訓練）。
    *   Dino V2：Meta開發的基礎視覺模型，經過訓練後，能夠從圖像中提取特徵，執行分類、深度估計等任務。
    *   應用：預測樹木高度，估算碳消耗量；AlphaFold預測蛋白質結構；Seamless翻譯200多種語言。
    *   提升內容審核效率：Facebook仇恨言論自動刪除比例從20%提升至95%。
*   **對大語言模型的看法：**
    *   現有大語言模型（如Llama、Llama2）展現卓越性能，但仍存在嚴重錯誤，不真正理解世界，只是被訓練成生成最有可能的單詞序列。
    *   問題：事實錯誤、邏輯錯誤、輸出不一致、缺乏推理能力、缺乏常識。
    *   預測：未來將淘汰自迴歸大語言模型，因其有明顯缺陷。
*   **目標驅動的AI架構（楊立昆提出的解決方案）：**
    *   感知模組（Perception）：感知世界，建立對當前世界狀態的估計。
    *   世界模型（World Model）：預測一系列行動的結果。
    *   演員模組（Actor）：想像動作，並將動作輸入到世界模型。
    *   成本模組（Cost）：代表系統的目標和整體目的，驅動整個系統，衡量不舒適度。
    *   目標：找到一個成本最小化的行動序列，確保系統產生安全的行為。
    *   分層規劃：人類和動物日常活動的基本特徵，但目前機器尚無法自動學習和確定行動計畫的合適層次。
*   **未來的挑戰：**
    *   機器從影片中學習世界模型。
    *   使用聯合嵌入型預測架構（JEPA）在表徵空間中進行預測。
    *   解決學習效率問題（例如，讓機器像青少年一樣快速學會駕駛）。
    *   達成貓級別的人工智能。
*   **對AGI（通用人工智能）的看法：**
    *   AGI是多維的，目前僅為誤導性概念。
    *   機器最終將在所有領域超越人類智能，但這需要數十年時間。
    *   無需過度擔憂機器接管世界，因為AI的發展將從小規模、低智能的模型開始，並在受控環境中進行安全測試。
*   **開源的重要性：**
    *   AI系統應開源，並以眾包方式收集全球知識，避免被少數人控制。
    *   開源有助於發展和應用人工智能，讓人類變得更聰明。

**總結**

楊立昆的演講核心為自監督學習和世界模型，關鍵在於聯合嵌入式的可預測架構（JEPA）。成本模組的實現至關重要，決定了預測結果。然而，目前世界模型面臨工程化問題，需要形成大量的模型，並優化改進。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>194. [2023-10-03] 【人工智能】AI领域的第一性原理是什么 | 最小作用量原理 | 理解常识 | 因果关系</summary><br>

<a href="https://www.youtube.com/watch?v=jmCuzYBn-Sw" target="_blank">
    <img src="https://img.youtube.com/vi/jmCuzYBn-Sw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI领域的第一性原理是什么 | 最小作用量原理 | 理解常识 | 因果关系

好的，我已經閱讀並理解了您提供的文稿，並會按照專業文件整理員的方式進行整理。目標是讓文稿更清晰、更易於理解和使用。

**整理後的文稿如下：**

**標題：人工智能的第一性原理：郭平教授的觀點與最佳拍檔的解讀**

**引言：**

大家好，這裡是最佳拍檔，我是大飛。

今天想和大家分享一篇北京師範大學圖像處理研究中心主任郭平教授的文章。文章以“四個問題”為切入點，探討人工智能的第一性原理，並提出如何運用第一性原理思維解決人工智能缺乏基本常識的問題。郭平教授建議將最小作用量原理作為人工智能的第一性原理。

談到第一性原理，大家可能會想到埃隆·馬斯克。馬斯克曾表示，他成功的秘訣就是運用第一性原理思維，即從物理學的角度看待世界，層層剝開事物表象，直達本質，再從本質出發，向上構建。

今天我們就來探討一下AI領域的第一性原理應該是什麼。以下是大飛整理的文章核心內容，希望能對大家有所啟發。

**文章核心內容：**

**一、人工智能領域存在第一性原理嗎？**

*   **第一性原理的定義：** 亞里士多德將第一性原理表述為在每一個系統的探索中，都存在一個最基本的命題或假設，不能被省略、刪除或違反。
*   **歷史應用：** 第一性原理主要用於哲學、數學和理論物理。
    *   數學：公理（axioms），不能從系統內的任何其他公理中推導出來。
    *   理論物理：計算直接從物理定律建立，不經過經驗模型和擬合參數等假設（也稱為“從頭計算”，ab initio）。
    *   生物學：達爾文的“物競天擇、適者生存”理論。
*   **AI領域的爭議：** AI領域是否存在第一性原理存在爭議。
    *   **反對觀點：** 第一性原理需要在明確定義“智能”之後才有意義。目前對“智能”還沒有明確定義。
    *   **參考定義：**
        *   尼爾斯·約翰·尼爾遜教授（斯坦福大學）：AI是關於知識的學科，怎樣表示知識、怎樣獲得知識並使用知識的科學。
        *   帕特里克·溫斯頓教授（麻省理工學院）：AI就是研究如何使計算機去做過去只有人類能做的智能工作。
    *   **尼爾遜的觀點：** AI目前沒有通用理論，只是一些與工程目標相關的原理，智能是許多過程并行發生和相互作用的結果。AI應被視為一種技術或建立在實驗基礎上的學科。
*   **支持觀點：**
    *   李國傑院士：AI與計算機科學本質上是一門學科，AI系統是用計算機技術對信息加工和處理的系統，因此應該存在第一性原理。
    *   於劍教授：《機器學習：從公理到算法》實際上是將數學的第一性原理應用到了機器學習上。
    *   基於物理的AI：可以借用物理的第一性原理，將“從頭計算”應用到AI，或者將“最小作用量原理”作為廣義的第一性原理。

**二、為什麼是基於物理的人工智能？**

*   物理學是研究物質運動最一般規律和物質基本結構的學科，是自然科學的帶頭學科，其他學科的研究基礎都建立在物理學科之上。
*   哲學與物理關係緊密。
*   楊立昆認為，未來AI的研究需要一種新型的理論，從而構建一個可以實現的世界模型，而基於物理的AI可能是最有希望實現這個理論的方式。
*   對於AI缺乏常識的問題，基於物理的AI框架也可能會提供一種解決思路。
*   常識是與領域相關的，包括生活常識、基本勞作技能、基礎的自然科學常識等等。

**三、如何讓人工智能具有常識？**

*   楊立昆認為，AI要掌握常識，就需要搞清楚物理世界的運作方式並做出合理決定，必須能夠獲取大量的背景知識、了解世界的運行規律，進而做出準確的預測和計劃（歸納性思維）。
*   需要按照第一性原理去思考。
*   **嬰兒學習（baby learning）方法：** 模擬嬰兒自主學習，逐步獲取知識。
*   把常識限定到特定的領域，例如將掌握物理科學常識作為現階段的首要目標。
*   從基本物理原理出發，讓AI先掌握科學常識，從而學習推理。
*   基礎的自然科學常識背後的物理原理是有明確定義的，而且可以用數學公式描述的。
*   AAAI 2017的最佳論文《基於物理和領域知識的神经网络无标签监督》，就是基於萬有引力定律推算出枕頭的運動軌跡，利用網絡的輸出必須滿足物理定律的約束來訓練神经网络，從而實現了神经网络的無標籤監督學習。
*   基於第一性原理思維需要花费更多的精力，构建世界模型也可能需要更大的计算量。
*   物理学中的最小作用量原理可以看作是整个物理学的第一性原理，在热力学、流体力学、相对论、量子力学、粒子物理学和弦理论都有广泛的应用。從具有可操作性的角度考慮，應該將最小作用量原理作為AI的第一性原理。

**四、為什麼要用第一性原理以及如何應用第一性原理？**

*   哥白尼、牛頓、愛因斯坦、達爾文等科學巨匠都運用了第一性原理，本質是邏輯學中的演繹性思維。
*   第一性原理是超越因果律的第一因，且一定是抽象的，或許有助於解決AI無法解釋因果關係的問題。
*   **以第一性原理思维看GPT-3：**
    *   硬件：馮·諾伊曼體系結構，二進制，程序順序執行，AI芯片只是算法硬件化。
    *   软件：GPT-3采用了与GPT-2同样的Transformer架构，融合了一种稀疏自注意力机制。
    *   结论：在当前的架构下，GPT-3不會邁向AGI。
*   關於AI未來的辯論：
    *   陣營一：計算機必須先了解因果關係等事物，然後才能接近人類的智能。
    *   陣營二：AI的問題可以通過投入更多的数据和提高计算机的处理能力来解决（OpenAI）。
*   大多數AI學者（如Yoshua Bengio和杨立昆）屬於前一陣營，認為AGI是不可能創造出來的。
*   受物理规律的制约，深度学习框架的天花板很快就会来临，如果基础理论没有突破，就不可能发展成为硅基文明的AGI。
*   需要重新构建AI基础理论框架，才能够赋予AI常识，发展具有可解释性的AI。
*   張钹院士認為，在探索通往AGI的道路上，我們現在走得並不遠。
*   以第一性原理作为出发点，先让AI具有基于物理规律的科学常识，可能才是通往AGI的正确道路。

**總結：**

郭平教授將物理學中的最小作用量原理作為人工智能的第一性原理，並推導出現有的GPT模型不會走向AGI，更傾向於楊立昆的世界模型理論。這個觀點有一定道理，但理論和實際有非常大的差異。Transformer架構是對知識的一種壓縮，大力出奇跡可能反而是一種更直接有效的手段。

關於什么是AI的第一性原理，每個人可能有自己的理解，短時間內業界也不會有共識。有人從物理學的角度，有人從數學的角度。

**互動：**

大家覺得AI的第一性原理是什麼呢？歡迎在評論區留言。

**結語：**

感謝大家的觀看，我們下期再見！

**整理說明：**

*   **結構化：** 將文稿分為引言、文章核心內容、總結和互動部分，使整體結構更清晰。
*   **分點闡述：** 使用分點、分段的方式，讓重點更突出，方便閱讀。
*   **專業術語保留：** 對於專業術語，如“第一性原理”、“最小作用量原理”、“AGI”、“馮·諾伊曼體系結構”、“Transformer架構”等，均保留原文，以確保信息的準確性。
*   **添加解釋：** 對於一些重要的概念，如“第一性原理的定義”，增加了更詳細的解釋。
*   **潤飾語言：** 對於一些口語化的表達，進行了適當的潤飾，使語言更流暢、更正式。
*   **整理互動環節：** 保留了結尾的互動環節，鼓勵讀者參與討論。

希望以上整理後的文稿對您有所幫助! 讓內容更便於理解和分享。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>193. [2023-09-26] 【OpenAI】Sam Altman和OpenAI究竟想要什么？硅谷著名科技记者Steven Levy深度采访 | 起源 | 转折 | 发展 | 终极目标</summary><br>

<a href="https://www.youtube.com/watch?v=QAyUNgsjj_M" target="_blank">
    <img src="https://img.youtube.com/vi/QAyUNgsjj_M/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】Sam Altman和OpenAI究竟想要什么？硅谷著名科技记者Steven Levy深度采访 | 起源 | 转折 | 发展 | 终极目标

好的，我將上述文稿整理如下，更著重於結構清晰和重點提取：

**主題： OpenAI 和 Sam Altman 的故事**

**主要來源：** 硅谷著名科技記者 Steven Levy 在《連線》雜誌上發表的長文 (約2萬字)，該文記錄了自2015年以來與 OpenAI 團隊的頻繁溝通和採訪。

**核心觀點：** OpenAI 的終極目標是 "Change everything"，即改變一切，他們致力於建立通用人工智能 (AGI)。

**一、 Sam Altman 的崛起與 OpenAI 的願景：**

*   **Altman 的影響力：** 在 GPT-4 發布後，Altman 成為科技界的搖滾明星，他的言論被視為神諭。
*   **OpenAI 的目標：** ChatGPT 和 GPT-4 只是 AGI 的墊腳石。 OpenAI 員工對建立 AGI 比確保其安全更感興趣。 他們相信 AI 的發展將超越生物學的極限。
*   **安全措施：** OpenAI 甚至在財務文件中規定了應急退出措施，以防止 AI 毀滅經濟體系。
*   **信仰：** OpenAI 的員工如同信徒，堅信 AGI 的到來。

**二、 Altman 的早年經歷與轉變：**

*   **科幻迷：** Altman 熱愛科幻小說和《星球大戰》，對計算機和超越人類的能力著迷。
*   **創業：** Altman 從斯坦福大學退學後創辦 Loopt，並接替 Paul Graham 成為 Y Combinator 的負責人。
*   **願景：** Altman 認為 Y Combinator 不僅是創業平台，更應為物種層面的變革提供資金。
*   **轉向 AI：** AI 的春天到來，Altman 相信 AGI 觸手可及，並決心領導一家改變人類的公司。

**三、 OpenAI 的創立與早期挑戰：**

*   **創始團隊：** Altman 與 Elon Musk 等人合作，秘密招募 Greg Brockman、Andrej Karpathy、Ilya Sutskever 等人才。
*   **Ilya Sutskever：** Sutskever 是 Geoffrey Hinton 的門徒，具有驚人的天賦，被 Altman 視為 OpenAI 的靈魂人物和研究的推動力。
*   **開源理念：** OpenAI 最初旨在通過與世界共享，讓 AI 變得安全易用。
*   **早期困境：** OpenAI 研究人員在缺乏頭緒的情況下進行研究，連 Altman 自己都說不知道該怎麼做。

**四、 關鍵突破與 GPT 的誕生：**

*   **Alec Radford：** Radford 在 OpenAI 進行實驗，並利用 20 億條 Reddit 評論訓練語言模型。
*   **無監督情緒神經元：** Radford 的模型能夠確定評論的情感，這是一個意外的突破。
*   **Transformer 架構：** Sutskever 認為 Transformer 非常強大，Radford 嘗試使用 Transformer 架構，並在兩週內取得巨大進展。
*   **Big Transformer：** Radford 提出在超大規模數據集上訓練模型的想法。
*   **GPT-1：** Radford 創建了 GPT-1，含有 1.17 億參數，在理解語言和產生答案等方面超越以往的人工智能。

**五、 OpenAI 的轉型與挑戰：**

*   **GPT-2 的危險性：** Radford 意識到自己做出了科幻小說裡的機器，擔心壞人會利用這項技術。
*   **與馬斯克的決裂：** 馬斯克想要擁有 OpenAI 並拒絕 Altman 的要求，憤然退出董事會。
*   **盈利模式：** OpenAI 創建了盈利性實體，同時設定上限，確保實現技術革命的終極使命。
*   **微軟的投資：** 微软投資 130 億美元，獲得將 OpenAI 技術商業化的獨家許可。
*   **內外壓力：** OpenAI 面臨在每個產品週期內實現革命、滿足投資人需求、與科技巨頭競爭以及肩負起守護人類使命的壓力。
*   **人員流失：** Dario Amodei 等關鍵人物離職，創辦競對公司 Anthropic。

**六、 ChatGPT 的推出與迭代部署：**

*   **戰略考量：** Altman 認為要讓大眾階梯式地適應人工智能，因此先推出基於 GPT-3.5 的 ChatGPT。
*   **安全考量：** Sutskever 認為不應將更強大的智能體藏在地下室裡，而應讓大眾逐步適應。
*   **社會影響：** OpenAI 將自己置於討論的中心，應對失業、信息錯誤、人類滅絕等潛在弊端。
*   **與政府合作：** Altman 與國會議員積極溝通，就如何監管 AI 進行交流。

**七、 OpenAI 的未來：**

*   **重點方向：** 產品本身、商業化公司、與微軟的關係、開發者生態系統、應用商店、AGI 的研究和投資。
*   **合作：** 與美聯社和 Shutterstock 等機構合作，為 OpenAI 的模型提供內容。
*   **轉變：** OpenAI 從一個科學目標的新穎努力，轉變為一個影響我們日常生活的大科技公司。

**結語：** OpenAI 的發展迅速，但未來仍面臨諸多挑戰。 這群 AGI 的信徒們，是否會成為人類進化的新起點，還是會帶來更大的社會風險，還需要時間來驗證。

**改善方向：**

*   **精簡語言：** 去除過多的口語化表達，使文本更加正式和專業。
*   **使用更明確的標題和子標題：** 幫助讀者快速理解文章的結構和重點。
*   **使用項目符號或編號：** 組織信息，使之更易於閱讀。
*   **添加關鍵詞：** 方便檢索和引用。

我希望能滿足您的需求。 如果您需要進一步的修改或調整，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>192. [2023-09-25] 【闲聊】EUV光刻机要实现技术突破了？| 制造芯片为什么需要光刻机 | 生产光刻机究竟有多难 | SSMB的由来 | 实事求是才是科学发展的道路</summary><br>

<a href="https://www.youtube.com/watch?v=w5JIIVPao-I" target="_blank">
    <img src="https://img.youtube.com/vi/w5JIIVPao-I/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【闲聊】EUV光刻机要实现技术突破了？| 制造芯片为什么需要光刻机 | 生产光刻机究竟有多难 | SSMB的由来 | 实事求是才是科学发展的道路

好的，我來幫您整理這份文稿，使其更易於閱讀和理解。我會將其分段，提煉重點，並適當調整語氣，使其更偏向書面風格。

**整理後文稿：**

**主題：中國「光刻廠」傳聞解析：獨立自主研發光刻機的可能性**

大家好，我是最佳拍檔的大飛。最近，國內網路上瘋傳一則科技新聞，聲稱中國科學家發現了一種新的極深紫外光源產生原理，可應用於28nm、14nm、7nm、5nm等多種芯片製程，有望取代ASML的EUV光刻機，突破光刻機的技術封鎖。甚至有傳言說，中國已在雄安建設光刻工廠，並附帶「有圖有真相」的佐證。今天，我們就來深入探討此事，以及剖析光刻機研發的難度，並分析中國是否有可能完全獨立自主地研發出最先進的光刻機。

**一、芯片製造基礎常識**

首先，我們需要了解一些芯片製造產業的基本知識。芯片的製作，是將四價矽摻雜少量三價硼和五價磷，形成PN結，再配合金屬氧化物控制閘，製成晶體管。然後，將海量晶體管密集排列，並按照特定設計互相連接，即構成芯片。

晶圓加工是芯片製造的關鍵步驟。在FAB工廠中，於高純度的矽晶圓（wafer）上，製造出一個個相同的裸芯片（die）。值得注意的是，工業應用上的芯片產量是極其龐大的，以華為Mate 60 Pro的芯片為例，業界估計需求量達數千萬顆。

為了能在短時間內製造出如此大量的芯片，關鍵在於一片晶圓上能夠一次性製造出大量完全相同的裸芯片。以12英寸晶圓為例，其面積約為70659平方毫米。先進芯片的晶體管密度驚人，可達每平方毫米1億個。假設一個裸芯片的面積為140平方毫米，一片晶圓上就能容納約500個裸芯片的位置。

芯片製造存在「良率」的概念，即功能合格的芯片所佔的比例。假設一片晶圓上的500個芯片，經過測試後有400個功能合格，則良率為80%。先進芯片加工的良率雖不一定高，但也不會太低，否則不具備商業價值。以50%的良率估算，一片晶圓至少也能產出200個以上可用的裸芯片。

FAB工廠的產能通常以每月能加工多少萬片晶圓來衡量，多的可達每月10萬片，少的也有1萬片。若每月加工1萬片晶圓，每片晶圓產出200個良品芯片，則每月可生產200萬顆芯片，一年可生產2000萬顆以上。

**二、光刻機在芯片製造中的作用**

許多人誤以為芯片製造全靠光刻機，將其視為核心設備，以為只要將晶圓送入光刻機，就能直接「刻」出芯片。甚至有人認為，購置100台光刻機就能建立100條芯片生產線。

事實上，芯片上的晶體管是通過「蝕刻」製成的，即利用等離子體物理衝擊或化學藥水浸泡等方式，在晶圓上製造出溝槽。而光刻則是用於引導蝕刻的位置，可以說，所有蝕刻步驟都必須先經過光刻。通過「掩膜板」（mask或光罩），告知蝕刻工藝應在何處下手。

晶圓加工的步驟極為複雜，可能多達上千步，光刻也需要反覆進行多次。一般來說，需要多台光刻機，重要步驟使用精度高的光刻機，精度要求較低的步驟則可使用低配光刻機。一片晶圓從開始加工到最終交付客戶，可能需要數月的時間，因為生產線上的機器並非只生產一種芯片，而是會排程加工其他晶圓。如何安排不同芯片的晶圓在指定時間送達指定機器，是FAB生產流程管理的重要課題。即使全力加速單一芯片的加工流程，工序繁多的情況下，一片晶圓也需要一到兩個月才能完成。

因此，客戶向FAB下單加工芯片，並非立即就能取得產品，即使追加訂單，也需要數個月的時間才能交貨。儘管如此，數個月就能生產出上千萬顆芯片，顯示了龐大的加工能力。只有量產，才能降低單顆芯片的成本。所以，FAB的生產能力是芯片工業應用的關鍵。

FAB工廠每月至少需要處理1萬片晶圓，而且光刻機處理一片晶圓往往需要多次曝光。因此，即使只生產一種芯片產品，每月僅生產1萬片晶圓，一台光刻機可能也需要進行10萬次光刻。FAB工廠需要排班運作，甚至週末也不停機。以每月30天計算，光刻機每天可能需要光刻3000次，平均每小時光刻100次是常見的節奏。從工業生產的角度粗略估算，光刻機需要在1分鐘內光刻完一片晶圓上的數百個裸芯片，每個芯片分到的光刻時間只有0.1秒。

若光刻速度無法跟上，就必須增加光刻機並行處理。光刻機是目前人類有能力製造的最精密和複雜的機器之一。

**三、光刻機的組成與技術難點**

一台光刻機由三大關鍵部分組成：光源、光學系統、蝕刻工作台。每個部分都面臨著登月般的技術挑戰。

*   **光源：** 產生13.5奈米波長的極深紫外光，目前的方法是用高功率激光轟擊直徑僅三千萬分之一米的小錫球。要持續穩定產生這種紫外光，需要以每秒約5萬次的頻率轟擊小錫球。這種激光器只有德國通快公司能夠生產，且耗時十年研發。更甚者，通快公司的激光器也依賴於立陶宛公司提供的關鍵設備。
*   **光學系統：** 將極深紫外光收集起來，形成一束激光。全球僅有德國蔡司公司能夠製造EUV光學系統。為了製作出絕對光滑平整的鏡片，鏡片的起伏誤差需控制在一個原子大小的範圍內，接近理論上的物理極限。這套光學系統必須在真空中工作，避免任何干擾。
*   **蝕刻工作台：** 在指甲蓋大小的矽片上刻出數百億個晶體管。這需要精度極高的控制台，由55000個高精度零件構成，且依賴於日本、韓國、中國台灣、美國、德國和荷蘭提供的專利技術。

光刻台的工作原理是，晶圓放置在工作台上，工作台在磁懸浮系統操控下不停游動。這實際上是「步進掃描」，工作台按照自動程序走走停停，停下來的瞬間進行光刻，將光罩上的圖案投射到裸芯片的區域。由於工作台走走停停的加速度非常大，對工作台運動控制和定位的精準度要求極高，這也是光刻機製造的核心難點之一。阿斯麥的光刻機型號有TWINSCAN，表示其具有兩個工作台，一個進行步進掃描光刻，另一個則進行「預對準」。

**四、EUV光刻機的研發歷程**

1997年，英特爾公司和美國能源部共同投資一家公司，開始研發EUV光刻機。經過六年時間，該公司研發了絕大部分的核心專利技術。然而，英特爾和美國能源部並未打算自行製造光刻機，而是將核心技術授權給荷蘭的阿斯麥公司。

在三星和台積電等公司的幫助下，阿斯麥終於在2010年生產出第一台EUV光刻機的原型機，經過測試、優化和升級，最終在2019年推出第一台可正式投入商業生產的EUV光刻機，總共歷時22年。

雖然EUV光刻機由荷蘭的阿斯麥公司生產，但它實際上只是一個組裝廠，僅有15%的零件自主生產，其餘85%的零件需要進口。由於美國能源部擁有光刻機幾乎所有的核心專利，因此阿斯麥生產光刻機需要美國能源部的授權。這也是美國政府能夠限制阿斯麥向中國出口光刻機的原因。

可以說，一台EUV光刻機的生產，涉及七、八個國家的合作。

**五、中國獨立研發光刻機的挑戰與希望**

中國想要突破技術封鎖，獨立生產光刻機，需要在光源、光學系統、蝕刻工作台三大關鍵部分實現完全的自主創新。目前，在光源部分，我們看到了一絲希望，這與趙午提出的「穩態微聚束」（SSMB）原理有關。

2010年，趙午與他的博士生一起，提出了利用巨大的粒子加速器來產生極深紫外光的新原理，即SSMB。2017年，清華大學唐傳祥教授團隊與德國同行合作，完成了實驗的理論分析和物理設計，並進行了一定的原理驗證。2021年2月，他們的論文在《自然》雜誌上成功發表。

然而，我們距離實現生產極深紫外光刻機的目標，仍然十分遙遠，千萬不能過於樂觀。清華大學已於2021年向國家發改委申報將SSMB實驗裝置列為十四五國家重大科技基礎設施，但目前仍處於科研階段。即使明年能夠立項，這種等級的科研裝置也需要至少5年才能建成，建成後還需要數年時間進行測試。

即便我們樂觀地估計，花費5年時間建成實驗裝置，再花3年時間測試成功，然後再花5年建成可以商用的光源，這也需要13年時間。更重要的是，光刻機的另外兩個關鍵部分，目前連影子都還沒有。而且，我們也無法確定13年後，美國和荷蘭是否又研發出了更先進的下一代光刻機。

此外，SSMB本身也存在許多難點問題需要解決。例如微聚束在儲存環中產生與維持的問題，以及SSMB相干輻射發光的問題，這些都需要後續的研究。

**六、結論**

在20年內，世界上不可能有任何一個國家能夠完全獨立自主地製造出一台代表國際最先進水平的光刻機，美國也不例外。我之所以提出這個觀點，是因為我不希望過去大躍進式的悲劇再次重演。

中國人很聰明，但並不意味著我們是特殊材料製成。只有實事求是，才是發展科學技術的正道。光刻機這樣超級精密複雜的機器，只有尋求最大範圍的國際合作，才是最佳的解決方案。

感謝大家的觀看，我們下期再見。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>191. [2023-09-24] 【人工智能】生成式AI拉开第二幕 | 红杉资本美国最新撰文 | 对生成式AI的反思 | 当下AI创业的方向</summary><br>

<a href="https://www.youtube.com/watch?v=4Gaf-NBZnoU" target="_blank">
    <img src="https://img.youtube.com/vi/4Gaf-NBZnoU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】生成式AI拉开第二幕 | 红杉资本美国最新撰文 | 对生成式AI的反思 | 当下AI创业的方向

好的，以下是经过整理的文稿，重点在于提炼核心信息，使其更易于理解和查找。

**主题：红杉美国《Generative AI’s Act Two》文章核心内容分享**

**核心观点：**

*   生成式 AI 正处于“尴尬的青春期”，潜力巨大，但尚未解决价值问题。
*   红杉资本对过去一年生成式 AI 领域的投资逻辑进行复盘，总结经验教训，并揭示未来投资方向。
*   文章提供 AI 应用创业指南，包括技术栈选择、产品形态设计以及需要解决的问题。
*   生成式 AI 市场正从技术驱动的“第一幕”转向客户驱动的“第二幕”，需要端到端地解决人类问题。
*   现有许多AI公司没有PMF（产品市场契合度）或者可持续的竞争优势，整个生态系统的繁荣不可持续。

**红杉资本对生成式 AI 市场机会和发展的预测（错误与正确）：**

*   **预测错误：**
    1.  发展速度过快：原本预计需要十年才能达到的技术水平，在一年内就已实现。
    2.  瓶颈在供应端：最终用户需求超过 GPU 供应。
    3.  垂直分离未发生：应用层公司和基础模型提供商之间未实现干净利落地分离，用户端的成功应用一直垂直整合。
    4.  竞争残酷：竞争激烈程度超出预期，既得利益者反应迅速，加剧竞争。
    5.  壁垒在客户中，而不是在数据中：应用生成的数据并未建立无法逾越的壁垒，工作流和用户网络正在创造更持久的竞争优势来源。
*   **预测正确：**
    1.  生成式 AI 是一回事：每个开发者都在研究，企业买家都需要，市场认可“生成式 AI”的名字。
    2.  第一个杀手级应用已经出现：ChatGPT 迅速达到 1 亿月活用户。
    3.  开发者是关键因素：开发者创造了无法想象的使用案例。
    4.  形态正在发展：AI 应用从自动完成和草稿形式变得越来越复杂，从个体生产力向系统级的生产力发展，从以人类主导向以执行主导的代理系统发展。
    5.  版权、伦理和存在的恐惧：相关辩论如火如荼。

**生成式 AI 面临的问题：**

*   **价值问题：**缺乏持久的用户留存和参与度。用户尚未在 AI 产品中找到足够每日使用的价值。
*   **解决方法：**
    *   解决用户留存问题。
    *   为客户创造足够的价值深度，增加粘性。
    *   将 Demo 演示变成完整的产品体验。

**模型开发栈的新内容：**

1.  新兴的推理技术（链状思维、树状思维和反思）提高模型执行更复杂推理任务的能力。
2.  迁移学习技术（RLHF 和微调）变得更容易使用，开发者可以对开源模型进行更有效的微调。
3.  增强检索生成 RAG 技术引入上下文，减少幻觉，增加真实性和实用性。
4.  新的开发者工具和应用框架帮助创建可重用的构建块，评估、改进和监控生产中的AI模型的性能。
5.  基础设施公司解构公共云，为 AI 公司提供大量 GPU、成本合理、按需可用、高度可扩展以及良好的 PaaS 使用体验。

**新的产品蓝图：**

1.  **生成式界面：** 基于文本对话，逐渐加入其他形态。
2.  **新的编辑体验：** 从 Copilot 到导演模式，创造像相机一样的编辑体验。
3.  **复杂的代理系统：** 逐渐拥有更多自主解决问题的能力和权力，端到端地解决问题。
4.  **系统范围的优化：** 通过自主解决问题，让整个系统变得更加有效。

**总结：**

*   生成式 AI 市场正在从炒作和演示转向真正的价值和完整的产品体验。
*   只有最终赢得客户留存，为客户创造长期深刻价值的应用才会存活下来。
*   关注解决用户根本需求的应用。

**个人建议:**

可以考虑将文章中的关键技术点，如 "链状思维"、"迁移学习"、"RAG技术" 等，做更详细的解释说明，以便更深入的了解AI 的发展方向。

希望这个整理对您有所帮助！如果您需要进一步的提炼或者润色，请随时告诉我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>190. [2023-09-18] 【人工智能】万字综述大语言模型代理 Agent | 研究背景 | 通用框架 | 控制、感知、行动 | 应用场景 | 代理社会 | 前瞻问题</summary><br>

<a href="https://www.youtube.com/watch?v=sxeNBsxPmf0" target="_blank">
    <img src="https://img.youtube.com/vi/sxeNBsxPmf0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】万字综述大语言模型代理 Agent | 研究背景 | 通用框架 | 控制、感知、行动 | 应用场景 | 代理社会 | 前瞻问题

好的，我幫你整理這篇文稿，使其更清晰、更易於理解：

**標題：大模型 Agent 綜述論文核心要點分享（復旦大學自然語言處理團隊論文解讀）**

**開場白：**

*   大家好，這裡是最佳拍檔，我是大飛。
*   最近很多網友想了解 Agent 相關內容，這確實是個熱門話題。
*   之前我們頻道做過 OpenAI 安全系統負責人 Lilian Weng 對 Agent 的看法，可以回顧一下。
*   今天我來分享復旦大學自然語言處理團隊關於大模型 Agent 的一篇綜述論文核心要點。這篇論文長達 86 頁，有 600 多篇參考文獻，全面梳理了基於大型語言模型的智能代理現狀。希望能幫助大家更深入地理解 Agent。

**論文要點：**

1.  **研究背景：**
    *   從哲學家德尼·狄德羅的智慧鸚鵡概念（能回答所有問題就有思想）談起，隱喻高度智能的有機體可能存在類似人類的智能。
    *   艾倫·圖靈將「智能」概念擴展到人工實體，即 Agent。
    *   「代理」概念起源於哲學，指擁有慾望、信念、意圖和行動能力的實體。在人工智能領域，指的是具有自主性、反應性、積極性和社交能力特征的智能实体。
    *   Agent 的中文譯名尚未統一，有智能體、行為體、代理或智能代理等多種翻譯。
    *   Agent 設計一直是人工智能領域的焦點，過去側重增強代理的特定能力（如符號推理、特定技能掌握），忽略了模型固有的通用能力發展（如知識記憶、長期規劃、有效泛化和高效互動）。
    *   大語言模型的出現為智能代理的發展帶來希望，增強模型的固有能力是關鍵。

2.  **NLP 到 AGI 的發展路線（五個級別）：**
    *   語料庫
    *   互聯網 (目前大語言模型階段)
    *   感知
    *   具身
    *   社會屬性

    如果赋予代理感知空间和行动空间的能力，它们将有可能达到第三、第四级。再进一步地，如果多个代理通过它们之间的互动、合作解决掉更复杂的任务，或者反映出现实世界的社会行为，那么代理有潜力来到第五级，即代理社会。

3.  **智能代理通用框架（受達爾文「適者生存」啟發）：**
    *   **控制端（Brain）：** 由大語言模型構成，儲存記憶和知識，負責信息處理、決策，呈現推理和計劃過程，應對未知任務，反映泛化性和遷移性。能力包括：
        *   自然語言交互
        *   知識 (常识知识和专业技能知识)
        *   記憶（過往的觀察、思考和行動序列）
        *   推理和規劃 (Reasoning 和 Planning)
        *   遷移性和泛化性
    *   **感知端（Perception）：** 將智能代理的感知空間從純文本拓展到包括文本、視覺和聽覺等多模態領域。
        *   文本输入
        *   視覺輸入
        *   聽覺輸入
        *   未来可配备更丰富的感知模块（例如触觉、嗅觉等器官)
    *   **行動端（Action）：** 除了常規的文本輸出，還可以賦予代理具身能力、使用工具的能力，適應環境變化，與環境交互，甚至塑造、影響環境。
        *   文本输出
        *   工具使用 (計算器、搜索引擎、語音生成、圖像生成等)
        *   具身行動 (Observation, Manipulation, Navigation)

4.  **Agent 的具體應用場景：**
    *   **設計原則：**
        *   幫助用戶從日常任務重複的勞動中解脫出來，减轻人类的工作压力，提高解决任务的效率。
        *   不再需要用戶提出顯式的低級指令，就可以完成自主的分析規劃解決問題。
        *   在解放用户的双手以后，尝试解放大脑，也就是在前沿的科学领域充分的发挥潜能，完成创新性的探索性的工作。
    *   **應用範式：**
        *   **單代理：** 接受人類的自然語言命令，執行日常任務，有現實使用價值。
            *   任務導向 (模拟网络环境和模拟生活场景)
            *   創新導向 (化学、材料计算机等领域)
            *   生命週期導向 (游戏我的世界)
        *   **多代理：** 代理們如何有效協調和協作解決問題。
            *   合作型互動（無序合作、有序合作）
            *   對抗性互動 (竞争谈判辩论)
        *   **人機交互：** 智能代理通過與人類的交互合作完成任務。
            *   指導者執行者模式
            *   平等合作模式

5.  **Agent 社會：**
    *   模擬社會定義：環境 + 環境中生存互動的個體。
    *   兩個關鍵部分：
        *   **代理：** 內化行為（計劃、推理、反思）、人格特征（認知、情感、性格）。
        *   **環境：** 虛擬沙盒遊戲、真實物理世界，包括人類參與者和各類可用資源。
    *   分析 Agent 在社會中的表現：
        *   **外在社會行為：** 個體行為（輸入、輸出、內化行為）、群體行為（合作、衝突、從眾）。
        *   **內在人格：** 認知能力、情感能力、性格分析。
    *   環境類型：
        *   基於文本的環境
        *   虚拟沙盒环境
        *   真实的物理环境
    *   模擬社會應具有：開放性、持久性、情境性和組織性。
    *   模擬社會的意義：探索群體智能的能力邊界、加速社會科學研究。
    *   模擬社會的風險：有害的社會現象、刻板印象和偏見、隱私安全問題、過度依賴與成癮性。

6.  **前瞻性問題：**
    *   智能代理與大語言模型的研究應該如何互相促進共同發展？
    *   智能代理會帶來哪些挑戰與隱憂？
    *   隨著代理數量的不斷提升，會帶來哪些機遇和挑戰？
    *   Agent 是否是通向 AGI 道路的鑰匙？

**總結：**

*   大語言模型建立了社會底層的通識共識和不斷學習理解的能力。
*   Agent 擁有不同的認知和能力，像人類個體。
*   Agent 社會是否會像人類社會一樣出現各種問題？
*   未來會出現惡意的 Agent 和針對 Agent 的病毒？
*   Agent 的能力大小不一，價值如何定義？
*   短期來看，Agent 仍會被限制在特定範圍內。
*   個人對 Agent 的未來持謹慎態度，因為我們還沒做好面對大規模 Agent 和 Agent 社會的準備。

**結尾：**

*   以上是個人看法，難免偏頗，歡迎大家在評論區發表看法。
*   感謝觀看，下期再見！

**總結說明:**

*   **標題化：** 我將內容分拆成更小的段落，並添加了標題，方便快速閱讀。
*   **層次化：** 使用編號和項目符號整理資訊，使資訊更容易瀏覽。
*   **簡化語言：** 刪除了一些口語化的表達，使內容更精煉。
*   **重點突出：** 對於關鍵概念和觀點進行強調。

希望這樣的整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>189. [2023-09-15] 【科学】2023搞笑诺贝尔奖公布 | Ig Nobel Prizes | 那些最意想不到的科学研究</summary><br>

<a href="https://www.youtube.com/watch?v=24taNsvS2Ac" target="_blank">
    <img src="https://img.youtube.com/vi/24taNsvS2Ac/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【科学】2023搞笑诺贝尔奖公布 | Ig Nobel Prizes | 那些最意想不到的科学研究

好的，以下是用更專業、更清晰的方式整理後的文稿。我會將內容分點歸納，並加入一些潤飾，使其更易於閱讀和理解。

**2023年搞笑諾貝爾獎揭曉：一窺科學家的奇異研究**

**開場白**

大家好，這裡是最佳拍檔，我是大飛。今天和大家聊聊輕鬆話題，一起來看看2023年搞笑諾貝爾獎的獲獎研究。

**搞笑諾貝爾獎簡介**

*   搞笑諾貝爾獎雖是模仿諾貝爾獎，但獲獎者確為科學家。
*   研究乍看荒誕搞笑，實則引人深思。
*   部分搞笑諾貝爾獎得主日後也獲得了真正的諾貝爾獎。
*   獎勵：十萬億津巴布韋幣、諾貝爾獎得主簽名證書、可摺疊成空盒子的紙（內含12罐小可樂）。

**獲獎研究詳解**

1.  **公共衛生獎：監測排泄物的智慧馬桶（史丹佛大學朴勝民博士）**

    *   功能：拍攝尿流和糞便形態，分析異常；尿液檢測試紙分析成分；「肛門識別」技術。
    *   升級：考慮增加心率感測器，綜合檢測健康指標。
    *   意義：以屎為鑑，可以知健康。
2.  **營養學獎：增強味覺的帶電筷子（明治大學宮下研究室）**

    *   原理：利用微弱電流刺激增強咸味感知。
    *   效果：咸味感受增強至原來的約1.5倍。
    *   應用：減少鹽分攝取，提升味覺體驗。
    *   研究者：宮下芳明教授（曾發明可舔到味道的顯示螢幕等）。
3.  **化學和地質獎：科學家舔石頭的原因（揚·扎拉謝維奇）**

    *   原因：濕潤的岩石樣本能讓紋理更突出；舌頭能分辨岩石粒度差異及多孔質感。
    *   應用：更好地區分相似岩石。
    *   案例：扎拉謝維奇用舌頭發現石灰岩中的有孔蟲化石。
    *   注意：部分礦石有毒，非專業人士勿輕易嘗試。
4.  **醫學獎：數屍體鼻毛的研究（加州大學爾灣分校）**

    *   背景：斑禿患者可能脫落鼻毛，導致上呼吸道感染等問題。
    *   目的：評估鼻毛減少對斑禿患者的影響。
    *   方法：對20具遺體（10男10女）進行鼻毛計數和長度測量。
    *   結果：每個鼻孔平均鼻毛數量為120~122.2根，平均長度為0.81~1.035厘米。
5.  **機械工程獎：用死蜘蛛作為抓取工具（萊斯大學工程師）**

    *   原理：利用蜘蛛的液壓系統控制腿部伸展。
    *   方法：將狼蛛凍死，注入空氣改變壓強控制腿部運動。
    *   名稱：「死亡機器人」（Necrobotics）。
    *   優點：抓握輕柔、可生物降解、易於偽裝。
6.  **心理學獎：路人效應（紐約街頭實驗）**

    *   實驗：設置不同規模的看熱鬧群體，觀察路人加入行為。
    *   結果：看熱鬧人數越多，路人加入意願越大；邊走邊看比專門停下來看的多。
    *   結論：路人是否愛看熱鬧與初始群體規模有關。
7.  **物理獎：鳳尾魚「啪啪」行為（南安普頓大學）**

    *   發現：鳳尾魚交配帶來的湍流與大風暴造成的湍流不相上下。
    *   意義：魚群交配對海水混合的影響不容忽視。
8.  **傳播學獎：倒著說話的人的大腦研究**

    *   對象：兩位倒著說話的專家
    *   1號專家 (14歲覺醒): 把每個單詞的字母重新排列再念出來
    *   2號專家 (8歲學會): 經常在生活中倒著說話，但從未練習
    *   結果：大腦都有特殊之處。
        * 1號: 海馬旁回和梭狀回中的灰質體積更大
        * 2號: 額中回和額下回以及右側楔前葉體積更大
9.  **文學獎：重複多少次才不認識字的研究**

    *   實驗：讓受試者一直寫「the」這個單詞。
    *   結果：平均寫到27.7次開始不認識「the」這個單詞。
    *   發現：越常用的詞越容易出現這種現象。
10. **教育獎：師生無聊情緒研究**

    *   内容：略過 (因真的很無聊)

**結語**

看完今年的搞笑諾貝爾獎，不得不佩服科學家們的研究方向，真是太絕了！ 讓我們繼續期待明年的搞笑諾貝爾獎，看看又會出現什麼奇葩研究。

**補充案例：研究大山雀的生物學家**

*   東京大學生物學家鈴木的朋友，為了研究大山雀，把自己打扮成一隻大鳥一年有餘。
*   結果：大山雀族群沒有接納這位「畸形」的外來者。
*   科學家反思：或許走獸類同胞太過誇張，下次打算從天上出發。

**結束語**

感謝大家的觀看，我們下期再見！

**整理說明：**

*   **結構清晰：** 將文稿分成幾個部分，方便讀者快速了解內容概要。
*   **分點歸納：** 將每個獲獎研究的重點提煉出來，使用條列式呈現。
*   **潤飾語言：** 調整了部分語句，使其更流暢易懂。
*   **標題分明：** 增加了小標題，突顯各個研究的主題。

希望這次的整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>188. [2023-09-14] 【解密】三指外星人木乃伊遗骸再现 | 墨西哥国会发布会 | 真相还是骗局</summary><br>

<a href="https://www.youtube.com/watch?v=tSrG_eJ3J_E" target="_blank">
    <img src="https://img.youtube.com/vi/tSrG_eJ3J_E/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【解密】三指外星人木乃伊遗骸再现 | 墨西哥国会发布会 | 真相还是骗局

好的，這是一份整理後的文稿，著重於結構清晰、重點突出，並進行了一些潤飾，讓文章更易於閱讀：

**標題：墨西哥「外星人遺骸」聽證會：一場徹頭徹尾的騙局？**

**引言：**

大家好，我是大飛。今年UFO和外星人頻頻出現，彷彿人類即將揭開神秘面紗。但實際上，這可能只是全世界在「比爛」的表現。

**事件回顧：**

*   **美國國會聽證會（7月26日）：** 美國國會就「不明異常現象UAP」舉行公開聽證會，但僅止於「打嘴炮」。
*   **墨西哥「實物證據」（12日）：** 墨西哥拿出兩具「外星人遺骸」，宣布外星生命的存在。記者傑米·莫桑（Jamie Maussan）展示了2017年在秘魯發現的「非人類」生物遺骸，聲稱DNA不屬於人類，並有X光檢測報告佐證。

**疑點與真相：**

*   **外觀疑點：** 遺骸外型與電影《E.T.》相似，且具有與人類相似的骨骼結構。
*   **知乎爆料：** 知乎用戶指出，莫桑展示的骨骼是用納斯卡人類孩童木乃伊和松鼠猴等動物骨骼拼嫁而成，並經過加工。
*   **秘魯「發現」：** 2017年秘魯一共「發現」了五具遺骸，其中兩具被法國人高價買下，但因無法通過海關而作罷。
*   **詐騙背景：** 秘魯人Mario是盜墓者，擅長加工造假文物，曾因非法走私被捕。
*   **骨骼分析：**
    *   **手指：** 由人類手指、腳趾骨胡亂拼湊而成。
    *   **肋骨：** 鳥類的管狀骨頭。
    *   **四肢：** 人類股骨和脛骨。
    *   **頭骨：** 削切過的前後倒置的羊駝頭骨。
    *   **體表：** 石膏、硅藻土等混合物。
*   **碳14檢測：** 不同部位的碳14年份不同，肢體為800-1700年，皮膚則有7000多年歷史。
*   **DNA檢測：** 宣稱有超過70%的DNA來自地球之外，實際情況是木乃伊只有25%左右的基因來自某個單一人類，剩下的是各種DNA交叉污染、細菌及病毒DNA，以及羊駝DNA。

**結論：**

1.  木乃伊由盜墓賊和詐騙犯「發現」，發現地未經證實，且沒有隨葬物品。
2.  X光和CT掃描證實骨骼由人類骨骼胡亂拼湊而成。
3.  顯微組織學研究證實組織由人類組織和其他物質混合而成。
4.  碳-14鑑定證實木乃伊由於拼湊而成的高度異質性。
5.  DNA檢測證實木乃伊的DNA經歷過高度的交叉污染。

**事件本質：**

這是一場徹頭徹尾的騙局，莫桑可能藉此為新書造勢。

**個人觀點：**

大飛不懷疑外星人的存在，但這種所謂的證據是在侮辱大眾和外星人的智商。各國「比爛」的現象，娛樂化、荒誕化、怪異化的趨勢令人擔憂。

**結語：**

人類有探索未知的天性，但不應被愚弄。希望這種事能少一些。感謝大家的收看，我們下期再見。

**整理說明：**

*   **結構調整：** 將內容重新組織，分為引言、事件回顧、疑點與真相、結論、事件本質、個人觀點和結語，讓結構更清晰。
*   **重點突出：** 使用粗體標題和小標題，突顯文章重點。
*   **潤飾語言：** 稍微修改部分語句，使其更流暢易懂。
*   **刪減贅詞：** 刪除部分口語化的贅詞，使文章更精煉。
*   **添加結論：** 歸納了文章的重點，方便讀者快速理解。
*   **保留原文風格：** 盡可能保留了原文的幽默和口語化風格。

這個版本更易於理解事件的來龍去脈，並能快速抓取關鍵信息。希望您喜歡！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>187. [2023-09-14] 【人工智能】AI能闻到气味么 | 是否拥有并超越人的嗅觉 | Science最新发表研究 | 50万种气味图谱 | 机器感知的新边界</summary><br>

<a href="https://www.youtube.com/watch?v=7BMiE0wG8QU" target="_blank">
    <img src="https://img.youtube.com/vi/7BMiE0wG8QU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI能闻到气味么 | 是否拥有并超越人的嗅觉 | Science最新发表研究 | 50万种气味图谱 | 机器感知的新边界

好的，這是經過整理的文稿，我著重在結構清晰、語言流暢以及重點突出：

**最佳拍檔 - AI聞到氣味了嗎？**

大家好，這裡是最佳拍檔，我是大飛。

我們都知道，AI現在可以創作文字、圖畫和音樂了。但您可能難以想像，它竟然也開始能「聞到」氣味了！

**AI嗅覺突破：超越人類的感知**

還記得這個分子是什麼味道嗎？ (展示榴蓮臭味分子)

上個月底，科學家在《Science》期刊上發表文章指出，AI模型能讓機器擁有比人類更敏銳的嗅覺。

這篇論文提出了一種由數據驅動的人類嗅覺高維圖譜，簡稱POM。這個圖譜逼真地重現了由單一分子誘發的氣味感知類別的結構和關係。研究證明，機器學習模型在理解和描述氣味上已經達到人類水平。更重要的是，在氣味描述的前瞻性預測上，AI的準確度已經超越了人類個體。

這意味著，機器感知的邊界將進一步擴大，從視覺、聽覺再到嗅覺。未來的機器可能將擁有更多感知能力，真正感受和理解自身所處的世界，而不再只是從各種描述中體驗一個懸空的符號世界。

**AI嗅覺的潛在應用**

既然AI模型能夠將分子結構映射到氣味上，那麼它就可以：

*   創造特定的食物口味。
*   發現更適合每個人的香水。
*   找到更好的驅蚊化合物。

**人類如何聞到氣味？**

在詳細介紹AI是如何識別氣味之前，我們先來了解一下人類的嗅覺機制。

*   **鼻子的結構：** 鼻子由外鼻、鼻腔和鼻旁竇組成。鼻腔中的鼻黏膜與嗅覺的產生有直接關聯。鼻黏膜分為呼吸區域和嗅區。呼吸區域負責加溫加濕氣體，而嗅區（嗅上皮）則含有重要的嗅覺受體。
*   **嗅覺的產生：** 我們聞到的氣味，其實是鼻腔接收到空氣中含有氣味的化學物質（嗅質）。嗅質通過上皮黏膜的吸收，擴散到嗅細胞的纖毛上。纖毛上存在著特殊的嗅覺受體，與嗅質結合後產生第二信使類物質，使鈣通道開放，鈉離子與鉀離子進入細胞，從而產生動作電位，傳入嗅球，再傳向嗅覺中樞，引發嗅覺。
*   **嗅覺受體：** 人類有約400個功能性的嗅覺受體，遠遠超過其他感官受體。

**嗅覺研究的挑戰**

儘管如此，是什麼物理特性讓空氣傳播的分子在大腦中產生氣味，一直是個謎。嗅覺也因此被稱為人類最深層、最古老的感覺。

**科學家的研究方法**

莫奈爾化學感官中心和初創公司Osmo共同領導的研究小組，正在研究空氣中的化學物質是如何與大腦中的氣味感知相聯繫。目標是將分子結構映射到氣味感知中，並讓電腦根據分子結構預測氣味，甚至超越人類嗅覺。

**研究團隊的AI模型**

Alex Wiltschko博士和團隊創建了一個名為消息傳遞神經網路（MPNN）的機器學習模型。他們使用5000種已知化合物的數據集訓練模型，這些化合物與它們對應的嗅覺標籤相匹配，例如果味、花香、芝士味、薄荷味等。

數據輸入是分子的形狀，輸出是對哪些氣味詞最能描述它的氣味的預測。模型經過優化後，在經驗感知空間圖中，直觀地表示了感知距離和層次之間的關係。

**模型的有效性驗證**

為了確定模型的有效性，莫內爾大學的研究人員進行了一個盲驗證的過程。

*   **氣味描述實驗：** 15名訓練有素的研究參與者，每人被要求聞400種氣味，並接受相關訓練，使用55個單詞描述每種分子。
*   **質量控制：** 英國雷丁大學的風味化學教授Jane Parker及其團隊驗證了測試樣品的純度，確保雜質不會影響氣味描述的準確性。

**研究結果**

*   在53%的測試分子中，模型的表現優於小組成員的平均值。
*   模型在所有標籤上的表現都在人類評分者的分佈範圍之內，並且在30個標籤上的表現超過了小組成員的中位數。
*   模型在大蒜和腥味等具有明確結構的標籤上表現最佳，但在麝香標籤上表現最差。
*   小組成員對堅果、大蒜和芝士等常見食物氣味的一致性很強，而對於麝香和乾草等標籤的一致性較弱。
*   模型在不同嗅覺任務中的表現依然出色，甚至能在沒有經過訓練的嗅覺任務上也取得成功。

**模型的潛力**

該模型能夠識別出數十對結構不同、但氣味卻非常相似的分子，還能描述潛在氣味分子的各種氣味特性，例如氣味強度。

研究人員根據模型計算出的坐標，編制出了約50萬種潛在的氣味。而人類目前已知的、可購買到的氣味物質才約5000種。

**未來的挑戰**

研究者的下一步目標是找出氣味劑是如何結合並相互競爭的，從而產生人腦能夠解釋的、完全不同的氣味。但預測混合氣味將會非常困難，因為可能的組合數量極為龐大。

**總結與展望**

這項研究提出並驗證了一種新的數據驅動的人類嗅覺圖譜，能夠將化學結構與氣味感知相匹配。AI在嗅覺領域的突破，拓展了一個全新的感官領域。相比於AI已經非常擅長的視覺和聽覺，嗅覺的確還遠遠未被研究和開發。

AI來預測或發現新的氣味，以及氣味對人類和其他物種的影響，並不是遙不可及的事情。

**應用發想**

氣味也許能治病，或者被當做生化武器？

**結尾**

最後，我們再解答下開頭中提到的那個分子，它其實是榴蓮的臭味分子。

感謝大家的觀看，我們下期再見！

**修改說明：**

*   **標題：** 更具吸引力，點明主題。
*   **結構：** 分段清晰，添加小標題，方便閱讀和理解。
*   **語言：** 更加簡潔、流暢，避免口語化，重點明確。
*   **重點：** 突出了AI嗅覺的突破性進展、潛在應用以及研究方法和結果。
*   **結尾：** 總結全文，並提出展望，引人思考。
*   **添加圖片提示：** (展示榴蓮臭味分子)，更生動有趣。

希望這個整理版本對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>186. [2023-09-12] 【人工智能】万字综述大语言模型幻觉 | 如何定义幻觉 | 评估基准和方法 | 幻觉的来源 | 如何减少幻觉</summary><br>

<a href="https://www.youtube.com/watch?v=T142VYGXf38" target="_blank">
    <img src="https://img.youtube.com/vi/T142VYGXf38/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】万字综述大语言模型幻觉 | 如何定义幻觉 | 评估基准和方法 | 幻觉的来源 | 如何减少幻觉

好的，這是針對您提供的文稿所做的整理，我將其結構化、重點化，希望能幫助您更好地理解和運用：

**主旨：大語言模型（LLM）的幻覺問題**

*   **定義：** LLM生成與輸入不符、前後矛盾、或與世界知識不一致的內容。
*   **重要性：** 降低LLM在真實世界場景中的可靠性，可能造成實際風險。

**幻覺的類型：**

1.  **回答含糊不清：** 模稜兩可，無法提供有用答案。
2.  **回答不完整：** 支離破碎，缺少必要資訊。
3.  **回答偏差：** 反映訓練數據中的偏見（種族、性別等）。
4.  **資訊不足：** 無法回答查詢，可能是RLHF過度優化所致。

**論文分析：《AI大海中的海妖之歌：大語言模型中的幻覺調查》**

*   **結構：** 定義、評估、來源、減少方法、其他技術。

**幻覺的定義（論文）：**

1.  **與輸入相衝突：** 生成內容與用戶輸入（任務指令、任務輸入）相背離。
2.  **語境衝突性：** 生成內容與先前資訊矛盾。
3.  **與事實相衝突：** 生成內容與現有世界知識矛盾。

**幻覺的評估：**

*   **評估基準：**
    *   **TruthfulQA:** 評估回答問題的真實性。
    *   **FActScore:** 評估生成傳記的事實準確性。
    *   **HaluEval:** 評估大模型是否包含幻覺。
    *   **FACTOR:** 評估模型是否真實陳述可能性高於非事實陳述。
*   **評估形式：**
    *   問題解答
    *   指令提示
    *   文本補全
*   **評估指標：**
    *   人工評估
    *   模型自動評估 (TruthfulQA, AlignScore, FactScore)

**幻覺的來源：**

1.  **預訓練階段：**
    *   缺乏相關知識或內化錯誤知識。
    *   將虛假相關性誤解為事實。
    *   語料中本身存在幻覺的現象。
2.  **高估自身能力：** 對錯誤答案同樣自信。
3.  **對齊過程（微調、強化）：**
    *   缺乏先決知識的錯誤對齊。
    *   "諂媚" (sycophancy)，偏向用戶觀點而非真實答案。
4.  **生成策略：**
    *   過度承諾（"滾雪球"式自我一致性）。
    *   局部最佳不保證全局最佳。
    *   抽樣策略（top-p, top-k）引入隨機性。

**減少幻覺的方法：**

*   **訓練階段：**
    1.  **預訓練時期：**
        *   人工或自動整理預訓練語料庫，減少錯誤資訊。
        *   自動選擇可靠數據或過濾噪音數據。
    2.  **SFT時期：**
        *   整理SFT訓練數據（手動或自動）。
        *   引入誠實樣本（承認無能力回答）。
    3.  **RLHF時期：**
        *   設計特殊獎勵函數，鼓勵挑戰前提、表達不確定性。
*   **生成推理階段：**
    1.  **設計解碼策略：**
        *   事實核採樣 (Factuality kernel sampling) : 在多樣性和事實性之間取得更有效的平衡
        *   推理時干預（ITI）：調整Transformer模型注意力頭的激活方式。
        *   上下文感知解碼策略 (CAD) : 更多關注上下文訊息，減少對參數知識的依賴
    2.  **借助外部知識：**
        *   獲取相關知識（外部知識庫、外部工具）。
        *   知識利用方式：生成式補充、事後糾正。
    3.  **利用不確定性：**
        *   估算模型結果的置信度。
        *   方法：基於logit、口頭表達、一致性。

**其他減少幻覺的技術：**

1.  **多代理互動：** 多個LLM協作辯論。
2.  **提示工程：** 設計更有效提示。
3.  **利用LLM內部狀態：** 檢測虛假資訊。
4.  **優化模型架構：** 多分支解碼器、不確定性感知解碼器、雙向自迴歸架構。
5.  **MixAlign:** 模型對齊用戶查詢與存儲的知識。

**未來研究方向：**

*   改進自動評估方法。
*   模型編輯：修改模型行為，消除幻覺。
*   誘發幻覺的攻擊與防禦。

**結論：**

幻覺是LLM的一體兩面，如同機遇與風險。重點在於控制、減少風險，學習與幻覺共存，區分幻覺與事實。

**建議：**

*   深入閱讀原始論文及相關引用。
*   持續關注LLM幻覺問題的最新研究進展。

希望這個整理對您有幫助！ 如果您有任何其他問題或需要進一步的協助，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>185. [2023-09-11] 【开源】Github上的一个Star值多少钱 | 开源项目为何要刷星 | 如何给Github项目刷量 | 真假用户行为 | 非监督聚类检测算法</summary><br>

<a href="https://www.youtube.com/watch?v=_6k9l65y4GQ" target="_blank">
    <img src="https://img.youtube.com/vi/_6k9l65y4GQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【开源】Github上的一个Star值多少钱 | 开源项目为何要刷星 | 如何给Github项目刷量 | 真假用户行为 | 非监督聚类检测算法

好的，我將這個文稿整理如下：

**標題：Github Star 的真相：刷星、造假與識別**

**引言：**

*   Github Star 是衡量開源專案受歡迎程度的指標，儘管有虛榮成分，但仍具實際意義。
*   Star 數量的增長趨勢、關注度、技術選型、產品開發策略、投資決策和招募人才等方面都受其影響。
*   利益驅使下，刷星造假行為應運而生。

**刷星造假的現況：**

*   **價格：**
    *   baddhi.shop：100 個 Star 約 8 美元（活躍用戶，有折扣）。
    *   buygithub.com：100 個 Star 約 12 美元。
    *   還可以購買 Github 的 follower、fork 以及 watcher 的數量。
*   **案例：** 開源編排平台 Dagster 團隊親身體驗購買 Github Star。
    *   建立虛構的代碼倉庫並購買 Star。
    *   設計個人資料文件，並使用 GitHub REST API 和 GitHub Archive 數據庫進行測試。
    *   結果：代碼倉庫一夜爆紅。
    *   測試結果：
        *   在 GitHub24 (已失效) 購買的 Star 在 48 小時內交付，一個月後還在。
        *   在 Baddhi Shop 購買的 Star 在一周內交付，但一個月後四分之一被移除 (可能被 Github 官方撤銷)。

**如何識別刷 Star 行為：**

*   **第一類：一眼可辨的假帳號**
    *   個人資料缺乏真實性。
*   **第二類：用心造假的帳號**
    *   帳號有相當真實的活動以掩蓋其假帳號的事實。
    *   **共性：**
        *   同一天註冊。
        *   只有一天的活動記錄。
        *   活躍度極低。
        *   Follower 少於 1。
        *   Follow 的項目少於 1。
        *   個人公開的倉庫數量少於 4。
        *   個人信息 (電子郵件、僱用信息、簡歷、博客、Twitter 用戶名) 為空。
        *   點 Star 的日期與帳號創建/更新日期相同。
*   **工具：**
    *   Github 官方定期清理假帳號。
    *   astronomer、fake-star-detector 等工具。

**更隱蔽的造假行為：**

*   模仿正常開發者的行為，難以從行為數據上區分。
*   **Dagster 提供的檢測思路：** 無監督聚類 (Unsupervised Clustering) 機器學習技術。
    *   正常用戶的特徵分散，虛假用戶的特徵具有相似性，在可視化後會聚集在一起。
    *   用一組行為特徵 (提交代碼、提交 PR、點 Star、修改個人簡介等) 描述一個 Github 帳號，將其表示為高維向量空間中的一個點。
    *   向量空間中相近的點對應的 Github 帳號可歸類為同類帳號。
    *   如果同類帳號中有實錘的假帳號，則其他帳號大概率也是假帳號。

**案例分析：**

*   衡量刷 Star 的倉庫中點 Star 的 Github 帳號的行為。
    *   橫軸：日期跨度
    *   縱軸：帳號交互的倉庫總數
    *   顏色：
        *   藍色：所有用戶
        *   紅色：明確的假 Github 帳號
        *   黃色：根據聚類被懷疑的假帳號
*   結論：通過聚類可以很好地識別出刷 Star 帳號。

**案例分析：Okcash (開源加密貨幣)**

*   有 579 個 Star。
*   經過 Dagster 的方式檢測後，疑似虛假刷 Star 的帳號占比達到 97%。

**總結：**

*   買 Star 行為在 Github 上還不那麼普遍。
*   開源社群的長期發展需要每個開發者的努力。

**建議：**

*   對於想買 Github Star 的人，要不就花點錢買點貨真價實的，要不就乾脆別買。
*   不要因為刷 Star 而被扒出，造成尷尬局面。

**資源：**

*   Dagster 的聚類檢測方法已開源，地址在影片簡介中。

**結尾：**

*   感謝大家的觀看，我們下期再見。

**整理說明：**

*   我將文稿按照內容邏輯分段，並加上標題和副標題，使結構更清晰。
*   使用條列式清單整理重要資訊，如價格、共性、工具等。
*   對專有名詞 (如 Unsupervised Clustering) 進行中英文對照。
*   對案例分析進行簡單描述，突出重點。
*   精簡了部分口語化的表達，使文稿更正式。
*   調整了語氣，使文稿更客觀、更具資訊性。

希望這個整理後的版本對您有幫助！ 如果您有任何其他要求或需要進一步修改，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>184. [2023-09-09] 【AI】人工智能的新机遇 | 吴恩达Andrew Ng | 斯坦福最新7.26演讲 | 15分钟浓缩精华版</summary><br>

<a href="https://www.youtube.com/watch?v=0fZGr93Ni1s" target="_blank">
    <img src="https://img.youtube.com/vi/0fZGr93Ni1s/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】人工智能的新机遇 | 吴恩达Andrew Ng | 斯坦福最新7.26演讲 | 15分钟浓缩精华版

好的，我為你整理了這篇文稿，使其更結構化、易於理解，並突顯重點：

**主題：吳恩達於史丹佛大學商學院講座：人工智慧新機遇**

**講者：吳恩達 (AI Fund CEO, deeplearning.ai 和 Landing AI 創始人, Coursera 主席和聯合創始人)**

**核心內容摘要：**

吳恩達博士在講座中分享了他對人工智慧發展趨勢、機遇、創業以及風險的看法。他將AI視為一種新的電力，並強調了監督學習和生成式AI這兩項關鍵技術。他認為生成式AI作為開發者工具的潛力被嚴重低估，並強調應專注於具體應用和用例。此外，他認為創辦AI公司需要與領域專家合作，並關注具有可驗證性的具體想法。最後，他認為AI對人類的滅絕風險不大，反而是解決流行病和氣候變遷等問題的關鍵。

**主要內容：**

1.  **人工智慧技術和工具的發展趨勢：**
    *   **AI 是一種新的電力：** 一種通用的技術，對許多不同的事物都有用。
    *   **監督學習：** 擅長識別或標記事物，計算輸入到輸出（A 到 B）的映射。過去十年是大規模監督學習的十年，核心思想是使用大規模計算和大規模數據。
        *   例子：建立餐廳評價系統，透過標記積極和消極的評價來訓練AI模型。
    *   **生成式 AI：** 核心思想是使用監督學習來重複預測下一個單詞。
        *   大語言模型 (例如GPT-3)：透過在數百億個字詞的文本上訓練而得。
        *   作為開發者工具的潛力被低估，可以更快地建構應用程式。
        *   例子：快速建立情感分類器，只需要一句提示。

2.  **人工智慧的機遇和應用：**
    *   **AI 技術價值變化：** 監督學習目前價值最高，但生成式AI未來三年將快速成長。
    *   **創新公司或大公司的機會：** 集中在淺綠色或淺橙色的區域，所有技術都是通用技術，需要找到多樣化、具體的用例並建構它們。
    *   **避免不具長期價值和商業優勢的應用：** 如 Lenser 應用程式和手電筒APP。
    *   **重點：** AI 還未被廣泛採用，高度集中在消費者軟體和互聯網領域。其他行業應用還非常初級。需要將 AI 的價值從技術領域和消費軟體領域推向其他領域，甚至推向整個經濟。
    *   **低代碼/無代碼工具的重要性：** 讓使用者可以自己客製化AI應用，不再要求編寫大量程式碼，只需提供數據即可。

3.  **創建初創企業的過程：**
    *   **AI Fund 的孵化模式：**
        *   先與用戶交流想法和需求。
        *   花約一個月時間驗證想法和技術可行性。
        *   與潛在客戶交談確保可行性。
        *   引入 CEO 一起開展項目，共同構建原型並進行深入的客戶驗證。
        *   建立團隊，做MVP和外部融資。
    *   **與領域專家合作：** 使用 AI 資源來確保技術團隊強大，然後與行業或領域專家合作來發掘新的機會。只關注於可以有效驗證或證偽的具體想法。

4.  **人工智慧的風險與社會影響：**
    *   **倫理和道德原則：** 只關注於有助於推動人類前進且不違反倫理和道德原則的項目。
    *   **對就業的影響：** AI 可能影響更多高薪職位，應妥善照顧受到AI衝擊的人們。
    *   **對 AGI 的看法：** AI 尚未達到可以做任何人類能做的事情的程度，距離實現 AGI 仍然需要幾十年。
    *   **對人類滅絕風險的看法：** AI 不會對人類構成任何有意義的滅絕風險。真正可能滅絕人類的是流行病或氣候變化，更智能的 AI 則是解決這些問題的關鍵。

**結論：**

吳恩達認為 AI 作為一種通用技術，為每個人創造了許多新的機會。未來的重點是建立具體的用例，並希望與更多人合作開發這些機會。

**整理說明：**

*   **標題和副標題：** 使結構更清晰，方便快速瀏覽。
*   **要點式呈現：** 將重點內容以條列方式呈現，方便記憶和理解。
*   **案例說明：** 包含具體的例子，幫助理解抽象概念。
*   **強調重點詞彙：** 使用粗體標示重點詞彙。
*   **簡潔的語言：** 避免冗長的句子，使用更精簡的語言。

希望這個整理後的文稿對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>183. [2023-09-04] 【人工智能】OpenAI正在秘密训练GPT-5？| 穆斯塔法·苏莱曼最新访谈 | DeepMind联创&InfectionAI CEO | 比GPT-4大100倍 | DeepMind背后的故事</summary><br>

<a href="https://www.youtube.com/watch?v=0Hk9XFfdeEM" target="_blank">
    <img src="https://img.youtube.com/vi/0Hk9XFfdeEM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OpenAI正在秘密训练GPT-5？| 穆斯塔法·苏莱曼最新访谈 | DeepMind联创&InfectionAI CEO | 比GPT-4大100倍 | DeepMind背后的故事

好的，這是我整理後的文稿，重點歸納、條列分明，並針對部分地方進行了潤飾，使其更易讀：

**文稿主題：OpenAI 是否秘密訓練 GPT-5？穆斯塔法·蘇萊曼訪談重點整理**

**核心內容：**

*   **OpenAI 是否秘密訓練 GPT-5？**

    *   OpenAI CEO 薩姆·奧特曼否認正在訓練 GPT-5。
    *   Inflection AI CEO 穆斯塔法·蘇萊曼懷疑 OpenAI 秘密訓練 GPT-5，認為 OpenAI 可能只是換了個名字。
*   **蘇萊曼訪談重點：**
    *   **蘇萊曼背景：**
        *   Inflection AI 聯合創辦人兼 CEO。
        *   DeepMind 聯合創辦人。
        *   曾任 DeepMind 應用人工智能負責人、Google 政策職務。
    *   **Inflection AI 的發展：**
        *   未來 18 個月內訓練的模型比當前前沿模型大 100 倍。
        *   未來 3 年內訓練的模型比現在大 1000 倍。
        *   目標是打造一個非常好用的個人助理，提供高度客製化的 AI 服務。
    *   **對開源模型的看法：**
        *   未來 5 年內，開源模型始終會落後於最前沿的閉源模型。
        *   開源模型會增加 AI 帶來的社會風險，讓力量快速擴散。
        *   AI 技術可能會降低潛在危險化合物或武器的開發門檻。
        *   並非攻擊開源社群，但仍要堅持表達開源的風險。
    *   **在 Google 和 DeepMind 的經歷：**
        *   花費大量時間試圖將更多外部監督融入到 AI 技術的建構過程中，但過程痛苦。
        *   原本 DeepMind 被收購時提出要設立倫理和安全委員會，但 Alphabet 變得膽怯。
        *   DeepMind 從未獨立過，現在也完全從屬於 Google。
    *   **AI 訓練成本：**
        *   算力成本隨著晶片算力的迭代在不斷下降。
        *   未來可能會出現訓練某个模型的成本相当于在 2022 年花费了 100 亿美元来训练。
    *   **AI 模型的軍備競賽：**
        *   Inflection AI 正在建造世界上最大的超級電腦之一，可能運行比 GPT-4 大 10 倍或 100 倍的訓練。
        *   但因缺乏自主性，模型本身不具有危險性。
        *   擁有大規模算力的公司，應該盡可能保持公開透明。
        *   Google DeepMind 也應該披露 Gemini 接受了多少 FLOPS 訓練。
*   **蘇萊曼新書《即將到來的浪潮》：**
    *   思考人工智能所帶來的社會變化和風險，以及應對措施。
    *   內容包括對人工智能模型進行能力審核、讓批評者參與直接設計人工智能模型、及极大提高政府对人工智能的理解及合理监管的能力等等。

**總結：**

蘇萊曼的訪談內容涵蓋了對 OpenAI、開源模型、AI 安全性等議題的看法，以及他在 Google 和 DeepMind 的經歷。他認為 AI 發展的風險不容忽視，並呼籲保持透明和謹慎。

**大飛觀點：**

大飛將會持續關注 GPT-5 的發展，期待其能夠再次提升大模型 AI 的能力，並解決人們對於 AI 浪潮是否能持續的懷疑。

**建議：**

1.  **分段標題加強：** 每個段落可以加上更具體的標題，例如「蘇萊曼對開源風險的詳細說明」等，讓讀者更容易掌握內容。
2.  **資料佐證：** 針對蘇萊曼的觀點，可以加入一些數據或案例來支持，增加說服力。
3.  **用語調整：** 可以將部分口語化的用語調整為更書面化的表達方式，例如將「大家都在猜測」改為「普遍認為」。

希望以上整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>182. [2023-09-02] 【AIGC】国内首例AI文生图著作权案 | StableDiffusion生成的图片有没有著作权 | 是否属于作品 | 创作主体 | 独创性</summary><br>

<a href="https://www.youtube.com/watch?v=kr_K5FOm5ug" target="_blank">
    <img src="https://img.youtube.com/vi/kr_K5FOm5ug/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】国内首例AI文生图著作权案 | StableDiffusion生成的图片有没有著作权 | 是否属于作品 | 创作主体 | 独创性

好的，以下是我整理後的文稿，主要目的是使其更易於閱讀、理解和查找資訊。我將會：

*   **調整結構：** 將文稿分段，並加上標題和副標題，使其更清晰。
*   **簡化語言：** 避免過於口語化的表達，使文稿更正式。
*   **提煉重點：** 強調案例的關鍵資訊和爭議點。
*   **梳理邏輯：** 使文稿的論述更具邏輯性。
*   **保留原文特色：** 盡可能保留原稿的觀點和風格。

---

**AI文生圖著作權案：國內首例引發的法律爭議**

**引言**

大家好，我是大飛，這裡是誰最佳拍檔。隨著生成式AI的興起，相關的法律問題日益增多。本次我們將聚焦於國內首例“AI文生圖”著作權案件，探討其中涉及的法律爭議。

**案件概述**

8月24日，北京互聯網法院公開開庭審理了一起“AI文生圖”著作權案。原告李某使用Stable Diffusion模型，通過輸入提示詞生成了一張人物圖片，並發布在小紅書上。被告劉某是一位詩詞博主，在其百家號文章中使用了該圖片作為配圖，並去除了水印。李某遂以侵害署名權和信息網絡傳播權為由，將劉某起訴至法院，要求賠償經濟損失並賠禮道歉。

**庭審直播與公眾關注**

由於這是國內首例相關案件，庭審過程在多個平台同步直播，吸引了超過17萬網友的關注。庭審現場和直播間就AIGC的版權問題展開了激烈的辯論。

**爭議焦點**

本案的爭議焦點主要集中在以下幾個方面：

1.  **涉案圖片是否構成作品？**
2.  **如果構成作品，原告是否享有著作權？**
3.  **被告使用圖片的行為是否侵犯了署名權和信息網絡傳播權？**
4.  **如果侵權成立，被告應如何承擔責任？**

由於爭議較大，案件僅進行了庭辯，尚未宣判。

**庭審細節：雙方觀點**

*   **原告李某的觀點：**
    *   AI生成圖片的操作和輸入體現了獨創性的智力勞動。
    *   AI僅是工具，創造活動由使用者完成。
    *   涉案圖片屬於美術作品，或“符合作品特征的其他智力成果”。
    *   被告未經許可使用圖片並刪除水印構成侵權。
*   **被告劉某的觀點：**
    *   文章主要內容為原創詩文，圖片僅為配圖，無商業用途，不具有侵權故意。
    *   圖片通過網絡檢索獲得，來源不明，無法確定李某是否享有權利。
    *   AI繪畫是人類畫家的結晶，涉案圖片創作門檻低，缺乏獨創性，不構成作品。
*   **法官詢問與調解意願:**
    *   李某不同意調解，希望法庭能對AI繪畫作品給出明確的裁量和認定標準。

**案件焦點的法律分析**

本案反映了生成式人工智能在版權領域面臨的幾大新問題：

1.  **AIGC是否屬於人的創作？作者是人還是AI？**
    *   中國《著作權法》規定只有“人類”才能擁有作者身份。
    *   人工智能的本質並非自然人，不符合法律規定的權利主體。
    *   法律強調“人”的主體地位，人工智能只有在人的參與和安排下，才有獲得著作權法保護的可能性。
    *   脫離人的干預，完全由人工智能自主完成的內容不應被視為作品。

2.  **如果AI創作的作者必須是人，那麼應該是誰？**
    *   AI生成圖片的過程涉及多個角色：大模型開發者、訓練數據提供者、微調模型開發者、使用者等。
    *   需要識別各自主體的貢獻，以及貢獻與最終成果的關係。
    *   只有與最終成果存在直接關係且達到“控制”程度的主體，才可能被認定為作者。

3.  **AI文生圖是否具有獨創性？**
    *   作品需具備獨創性，即“作者獨立完成”和“最低限度地創作”。
    *   最低限度創作指的是具備足夠和既有作品相區分的差異性，而非複製抄襲。
    *   大模型具有隨機性，如何判定使用者“控制”了AI生成結果？
    *   初級用戶的“一鍵生圖”難以認定為作者，高級用戶可控制更多細節，但提示詞的個性化選擇與安排是否構成獨創性仍存疑。

4.  **AI生成內容與既有作品的相似性問題**
    *   即使AI軟件使用者主導了製圖過程，如果AI製作出了與世界名畫“蒙娜麗莎”一模一樣的畫作，由於畫作並無獨創性，依然無法受到著作權法的保護。

**國外案例與平台應對**

*   **美國版權局：** 人工智能生成材料的作品，重要的是人類在多大程度上創造性地控制了作品的表達。純粹由AI生成的圖片不受版權保護，但文字和AI圖片結合而成的書的內容受版权保护，因为当中存在人类工作。
*   **創作者抵制：** 創作者公開抵制AI模型和平台學習和使用自己作品的事件頻發。
*   **平台承擔責任：** Adobe和Shutterstock等平台承諾，如果因使用AI生成的圖片引發版權糾紛，將為使用者提供賠償。

**開源模型與商業利用**

*   如果底層模型開源，是否意味著微調模型都可以商用、獲得版權收益？
    *   取決於具體的開源協議。
    *   例如，Stable Diffusion基於MIT協議開源，允許不受限制的處置，包括商業利用。
    *   微調模型的開發者通常會聲明使用條件，例如AsiaFacemix規定10人以下團隊可將模型的輸出用於商業目的。

**中國法律法規**

*   《生成式人工智能服務管理暫行辦法》已於8月15日起實施，對大模型公司要求實行備案制。
*   監管部門關注模型的數據安全、數據來源問題，例如是否侵犯知識產權或隱私。
*   目前生成式AI的法律界限尚不明確，需要更多判例來確立。

**大飛個人觀點**

個人傾向於AI生成物不應具有著作權：

*   創作者僅提供prompt，未參與圖片的繪製過程。
*   圖片缺乏明確的自然人主體，不符合獨創性要素。
*   提示詞易於複製，難以證明其智力成果和獨創性。
*   AI降低了創作門檻，如果賦予AI生成圖片著作權，可能導致濫用和“版權流氓”行為。

**結語**

本案的後續進展值得持續關注。生成式AI對版權體制帶來了根本性的衝擊，法律界限的確立需要時間和案例積累。

---

**注意：**

*   我保留了原文的观点，包括大飞的个人看法。
*   我调整了一些口语化的表达，使其更正式。
*   我增加了一些标题和副标题，使其更清晰。
*   我将一些关键信息以更突出的方式呈现。

我希望这个整理后的文稿对您有所帮助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>181. [2023-09-01] 【Google】SemiAnalysis第三弹爆料 | 谷歌Gemini是GPT-4五倍算力 | 算力王者 | TPUv5 | 算力穷人将被淘汰 | AI芯片世界的救世主？</summary><br>

<a href="https://www.youtube.com/watch?v=APH0iOko50c" target="_blank">
    <img src="https://img.youtube.com/vi/APH0iOko50c/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Google】SemiAnalysis第三弹爆料 | 谷歌Gemini是GPT-4五倍算力 | 算力王者 | TPUv5 | 算力穷人将被淘汰 | AI芯片世界的救世主？

好的，我將為您整理這篇文稿，使其更具條理性、更易讀，並突出重點。以下是整理後的版本：

**核心觀點：谷歌 Gemini 的算力是 GPT-4 的 5 倍，AI 算力競賽白熱化**

**主要內容：**

*   **SemiAnalysis 爆料：** 分析師迪倫·帕特爾（Dylan Patel）和丹尼爾·尼什博爾（Daniel Nishball）爆料，谷歌下一代大模型 Gemini 的算力已達 GPT-4 的 5 倍，暗示 OpenAI 在算力上遠遜於谷歌。

*   **算力為王：** 在 AI 商業化競爭中，掌握足夠 GPU 資源至關重要。谷歌已成為算力王者，其 TPUv5 數量超過 OpenAI、Meta 等公司的 GPU 總和。

*   **Sam Altman 的反應：** OpenAI 的 Sam Altman 對於谷歌算力超越 OpenAI 的說法表示不滿，認為 SemiAnalysis 發布的是谷歌的內部行銷資料。

*   **爆料的可靠性：** 迪倫·帕特爾過去的爆料（如「我們沒有護城河」的谷歌內部文件洩露事件、GPT-4 架構洩密等）均被證實。

*   **GPU 富人和 GPU 窮人：**
    *   **GPU 富人：** 擁有大量 GPU 的科技巨頭（OpenAI、谷歌、Meta 等）將 GPU 視為招聘策略，吸引頂尖研究人員。
    *   **GPU 窮人：** 小型新創公司和開源研究者面臨 GPU 短缺，難以進行有意義的研究。
    *   **安德烈·卡帕希的感慨：** 誰能獲得多少 H100，何時獲得 H100，成為矽谷的熱門話題。

*   **開源模型的困境：** GPU 窮人過於關注模型大小、量化，忽視了資料品質和預訓練的重要性。目前的大模型排行榜已失去意義。

*   **大模型之戰的世界版圖：** 美國和中國持續領先，歐洲因投資和 GPU 短缺而落後，中東國家則加大投資。

*   **HuggingFace、Databricks 等 AI 公司也是 GPU 貧困戶：** 儘管擁有頂尖研究者，但他們只能在算力較低的系統上工作。

*   **英偉達的優勢：** 從 Meta 到微軟，再到新創公司，實際上所有人都只是在充實英偉達的銀行帳戶。

*   **谷歌的希望：** 谷歌擁有 TPU 等 AI 專用基礎設施，以及下一代大模型 Gemini，可能成為拯救者。

*   **TPU 的演進：** 谷歌自 2006 年開始構建 AI 專用基礎設施，並開發了多種 TPU 晶片。

*   **谷歌的算力擴張：** 谷歌擁有的 TPUv5 比 OpenAI、Meta 等公司的 GPU 總和還要多。

*   **Gemini 的訓練：**
    *   Gemini 在 14 個 TPU Pod 上進行訓練。
    *   下一次迭代已開始在基於 TPU V5 的 Pod 上進行訓練，算力高達 10 的 26 次方 FLOPS，比 GPT-4 的訓練大 5 倍。
    *   谷歌還推出了新一代 AI 加速器 Cloud TPU V5E 和基於 Nvidia H100 GPU 的 GPU 超級電腦 A3 VM。

*   **結論：** 谷歌開始整合內部算力資源，以 GPT-4 五倍的算力訓練 Gemini，凸顯了 Google Brain 和 DeepMind 合併後的優勢。一些缺乏資本和資源的 AI 新創公司可能很快被市場淘汰。

**關鍵詞：** Gemini, GPT-4, 算力, GPU, TPU, OpenAI, 谷歌, AI, 大模型, SemiAnalysis, 迪倫·帕特爾, 丹尼爾·尼什博爾, 英偉達, HuggingFace, Databricks。

**潛在的討論方向：**

*   AI 領域的算力競賽是否會持續升級？
*   缺乏算力的小型 AI 公司如何應對？
*   谷歌 Gemini 是否能超越 GPT-4？
*   AI 晶片的未來發展趨勢。
*   英偉達在 AI 領域的壟斷地位。

希望這個整理的版本對您有所幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>180. [2023-09-01] 【独家】DoctorGPT本地安装部署指南 | 你的私人AI医生 | 完全免费 | 跨平台支持 | Llama 2 70亿微调 | 通过美国医学执照考试</summary><br>

<a href="https://www.youtube.com/watch?v=YEWRzuTPRY0" target="_blank">
    <img src="https://img.youtube.com/vi/YEWRzuTPRY0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【独家】DoctorGPT本地安装部署指南 | 你的私人AI医生 | 完全免费 | 跨平台支持 | Llama 2 70亿微调 | 通过美国医学执照考试

好的，這是我整理後的文稿，主要目的是使其更易讀、重點更清晰：

**標題：輕鬆安裝 Doctor GPT：本地部署，AI 醫療助手觸手可及！**

**開場白：**

大家好，我是小郭，歡迎來到最佳拍檔！今天跟大家分享如何安裝 Doctor GPT。

**Doctor GPT 是什麼？**

Doctor GPT 是一款利用人工智能幫助患者的應用程式，它會根據使用者的症狀和醫療歷史，提供個人化的建議，並推薦合適的專科醫生。目的是讓人們更輕鬆、更有效率地獲取醫療建議，不必再長時間排隊或進行大量的網路搜尋。

**Doctor GPT 的優點：**

1.  **完全免費：** 無需額外付費解鎖 Pro 功能。
2.  **本地部署：** 無需擔心隱私洩漏。
3.  **準確性高：** 號稱已通過美國醫師執照考試。
4.  **跨平台：** 支援 Apple、Android、PC，甚至 Web 瀏覽器。

**安裝準備：**

*   已安裝顯卡驅動的圖形化作業系統。
*   可以訪問 Google 等牆外網站。
*   需要安裝一些軟體，例如 Git LFS、NodeJS、Python 或其他 HTTP 伺服器。

**Doctor GPT 模型與 MLC-LLM：**

Doctor GPT 僅提供模型文件，需借助 **MLC-LLM** 才能使用。MLC-LLM 支援將各種語言模型進行本地部署，支援手機、PC 甚至是瀏覽器環境。

**安裝方式：**

*   **手機（不推薦）：** 雖然官方聲稱支援手機，但成功率較低。
    *   **iOS：** 在 Apple Store 搜尋並安裝 MLC Chat（可能需要國外 Apple ID）。
    *   **Android：** 從 GitHub 頁面下載 APK 安裝。
    *   **模型地址：**
        1.  打開 Doctor GPT Github 頁面。
        2.  點擊 "files and versions"。
        3.  將網址中的 `tree/main` 改為 `resolve/main/`，以此作為模型地址。
    *   **可能問題：** 下載目錄權限錯誤、應用程式崩潰、需要至少 4GB 運行記憶體。

*   **Web（推薦）：** 透過 MLC-LLM 的子項目 **web-llm** 在瀏覽器中運行 Doctor GPT，支援硬體加速。
    *   **步驟：**
        1.  下載 web-llm 專案 (ZIP 檔案或 Git clone)。
        2.  使用 VS Code 開啟 `examples/simple-chat` 目錄。
        3.  執行 `npm install --registry=https://registry.npm.taobao.org` (使用國內鏡像)。
        4.  修改 `src/gh-config.js`：
            *   複製 `model_list` 中最後一個紀錄。
            *   將模型地址改為前面提到的 `resolve/main/` 地址。
            *   將 `local_id` 改為 `DoctorGPT_mini`。
        5.  執行 `npm run start`。
        6.  在瀏覽器中打開 `http://localhost:8888`。
    *   **可能問題：** 網路要求較高，需要頻繁從 Hugging Face 下載檔案。

*   **Web（優化版 - 本地加載模型）：** 將所需檔案提前下載到本地，避免頻繁網路請求。
    *   **需要下載的檔案：**
        *   Web Assembly 的 `.wasm` 檔案 (從 `gh-config.js` 的 `model_lib_map` 中找到下載地址)。
        *   模型檔案 (從 Hugging Face 頁面下載，共 50 多個檔案，記得點擊 "Load more files")。
    *   **步驟：**
        1.  修改 `src/mlc_local_config.js`：
            *   複製 `model_list` 中最後一個紀錄。
            *   將 `model_url` 改為本地檔案路徑。
            *   將 `local_id` 改為 `DoctorGPT_mini`。
            *   將 `model_lib_map` 中最後一行的 `URL` 改為本地 `.wasm` 檔案路徑。
        2.  修改 `package.json`：
            *   找到第 8 行，將 `build` 後的 `cp` 命令要複製的檔案改為 `mlc_local_config.js`。
        3.  執行 `npm run build` 編譯。
        4.  下載 `.wasm` 檔案和模型檔案。
        5.  將編譯好的檔案放到 `lib` 目錄下。
        6.  使用 Python 的 HTTP Server 模組啟動伺服器：
            *   切換到 `lib` 目錄。
            *   執行 `python -m http.server 18080` (18080 為端口號，與設定檔一致)。
        7.  在瀏覽器中打開 `http://localhost:18080/llm_chat.html`。
        8.  在模型列表中選擇 `DoctorGPT_mini`。
        9.  如果出現異常，可能需要使用 Google Canary 瀏覽器，並在啟動時加上特定參數。

**模型訓練：**

如果想訓練自己的模型檔案，可以參考官方的 Jupiter Notebook 檔案。據說在付費的 Google Collab 上，使用 A100 GPU 大約需要運行 24 小時。

**結語：**

感謝大家的觀看，下次再見！

**說明：**

*   我將冗長的步驟拆解成更小的、更易於理解的步驟。
*   我強調了重要的檔案和路徑。
*   我使用粗體字來突出重點。
*   我簡化了一些專業術語，使其更容易被一般讀者理解。
*   我去除了語氣詞和口語化的表達，使其更正式。

這個版本應該更易於理解和遵循。希望對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>179. [2023-08-30] 【人工智能】具身智能：下一个AI浪潮 | 稚晖君 | Embodied AI | 什么是具身智能 | 目前发展阶段 | 挑战与困难 | 智元远征A1机器人</summary><br>

<a href="https://www.youtube.com/watch?v=UZBSXzNKB1Q" target="_blank">
    <img src="https://img.youtube.com/vi/UZBSXzNKB1Q/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】具身智能：下一个AI浪潮 | 稚晖君 | Embodied AI | 什么是具身智能 | 目前发展阶段 | 挑战与困难 | 智元远征A1机器人

好的，以下是我整理後的文稿，主要針對段落結構、重點突出、以及更易於閱讀做了調整：

**標題：智元機器人與具身智能：稚暉君的新挑戰**

**開場**

大家好，這裡是最佳拍檔，我是大飛。前幾天分享了稚暉君（彭志輝）的新公司智元機器人的發佈會影片，大家反應熱烈。但也有不少人對他不熟悉甚至認錯了，所以先簡單介紹一下：

*   **稚暉君 (彭志輝)**：1993年出生於江西吉安，畢業於電子科技大學。曾任職OPPO研究院AI實驗室算法工程師，後加入“華為天才少年計劃”，從事昇騰AI芯片和AI算法研究。2022年12月從華為離職，2023年2月創立智元機器人公司 (AGIBot)，現任CTO兼首席架構師。

**稚暉君的成名之路**

稚暉君在B站發布了許多硬核科技產品影片，例如自動駕駛自行車、自製機械臂給葡萄縫針，因此獲得了B站“2021年度百大UP主”稱號。他在Youtube也有頻道，歡迎訂閱。

**具身智能：ChatGPT 之後的新趨勢**

智元遠征A1機器人發佈後，稚暉君撰寫文章闡述了他對具身智能領域的理解。繼ChatGPT之後，具身智能 (Embodied AI) 成為另一個熱門的大模型概念。

*   **學術界：** 圖靈獎得主姚期智認為，人工智能的下一個挑戰是“具身通用人工智能”。
*   **產業界：** 微軟、Google、Nvidia等大廠均投入相關研究，如Google的RT-2、Nvidia的VIMA等。Nvidia創始人黃仁勳也表示，AI的下一個浪潮將是“具身智能”。

具身智能作為人工智能發展的重要分支，正迅速崛起，成為科技界和大众關注的焦点。

**什麼是具身智能？**

簡單來說，具身智能透過在物理世界和數字世界的學習和進化，理解世界、互動交互並完成任務。它是一個由“本體”和“智能體”兩部分耦合而成的智能系統，能在複雜環境中執行任務。

**具身智能的核心要素：**

1.  **本體 (Body)：** 實際的執行者，在物理或虛擬世界進行感知和任務執行。通常是具有物理實體的機器人，形態多樣。本體的能力邊界限制智能體的能力發揮。
    *   例如：四足機器人、複合機器人、人形機器人。
    *   本體需具備環境感知能力、運動能力和操作執行能力。
2.  **智能體 (Embodied Agents)：** 具身在本体之上的智能核心，負責感知、理解、決策、控制等核心工作。
    *   智能體可以感知複雜的環境、理解語義信息、與環境交互、理解任務並做出決策，進而控制本體完成任務。
    *   現代智能體通常由深度網絡模型驅動，結合視覺等多種傳感器的多模態模型是新趨勢。
    *   智能體要能從複雜數據中學習決策和控制範式，並持續自我演進。
3.  **數據 (Data)：** 泛化的關鍵。機器人數據稀缺且昂貴。智能體規模越大，對海量數據的需求越高。
    *   針對具身智能場景，尤其是行業場景的高質量數據，是未來成功應用的關鍵支撑。
4.  **學習和進化架構 (Learning and Evolution Architecture)：** 智能體透過與虛擬或真實物理世界的交互，適應新環境、學習新知識、強化新的解決問題方法。
    *   採用虛擬仿真環境進行部分學習是一種合理設計 (例如Nvidia的Omniverse)。
    *   如何耦合仿真和真實世界，進行高效遷移是架構設計的關鍵。

**具身智能的科研與技術進展**

在基於Transformer的大語言模型浪潮下，微軟、Google、Nvidia等大廠，以及斯坦福、卡內基梅隆等高校，都开展了具身智能的相关研究。

*   **微軟：** 基於ChatGPT生成控制機器人的代碼。
*   **英偉達：** VIMA基於T5模型，融合文本和多模態輸入，預測機器人的下一步行動。
*   **斯坦福大學：** 利用大語言模型的理解、推理和代碼能力，與VLM交互並生成3D value map，規劃機械臂的運行軌跡。
*   **谷歌：**  具身智能路線廣泛且具延續性，包括PaLM-E、RoboCat以及基於RT-1和PaLM-E升級得到的RT-2。其中RT-2通過融合VLM和RT-1中收集的大量機器人真實動作數據，實現了更好的泛化性和湧現性。
    *   RT-2系列模型在面對訓練數據中沒見過的物體、背景、環境時，仍然能夠實現較高的成功率，證明其具有較強的泛化能力。
    *   對於符號理解、推理和人類識別等湧現任務，RT-2系列模型也能以較高的正確率完成，表明語義知識已從視覺語言數據轉移到RT-2中。
    *   思維鏈推理能夠讓RT-2完成更複雜的任務。
    *   Google耗費17個月收集了13台機器人的13萬條真實數據，為RT-1和RT-2的良好性能打下根基。RoboCat則會先收集100-1000個真實的人類專家示例，再合成更多數據，用於後續訓練。

**具身智能的難點與挑戰**

儘管具身智能是迈向通用人工智能（AGI）的重要一步，但要實現好的具身智能，仍面臨諸多挑戰：

1.  **通用本體平台：** 如何解決硬件的關鍵零部件技術突破，形成具有優秀運動能力和操作能力的平台級通用機器人產品，平衡本體的可靠性、成本和通用能力。人形機器人被認為是具身智能的終極形態，這方面的研發將持續成為熱點和核心挑戰。
2.  **智能體系統：** 設計具備複雜環境感知認知能力的智能體，需解決物理3D環境精確感知、任務編排與執行、通識能力、多級語義推理能力、人機口語多輪交互能力、長期記憶能力、個性化情感關懷能力、任務泛化與自學遷移能力等挑戰。具身智能要求實時感知和決策能力，對數據採集、傳輸和處理、AI計算能力和低延遲提出了巨大挑戰。
3.  **高質量數據：** 缺乏足夠的場景數據來訓練完全通用的大模型。耦合的本體需要實際部署到真實環境中才能採集數據。
4.  **學習與進化：** 如何透過虛擬和真實的交互，持續學習和進化。形態與環境适配的智能體可以快速學習到解決問題能力，更好地適應變化。在複雜環境、形態演化和任務的可學習性之間存在未知的關係。

**智元機器人的實踐：遠征A1與具身智腦**

智元機器人提出了“具身智腦” (Embodied Intelligence Brain) 的概念，將機器人的具身智能思維系統分為雲端的超腦、端側的大腦、小腦以及腦幹四層，分別對應於機器人任務級、技能級、指令級以及伺服級的能力。

*   **超腦：** （雲端）互联网能力
*   **大腦：** 完成語義級多段推理任務，結合上下文進行任務理解。
*   **小腦：** 結合各種傳感器的信息進行運動指令⽣成。
*   **腦幹：** 進行精確的伺服閉環控制。

EI-Brain設計上，上層大模型聚焦感知決策和計劃生成，不依賴具體的機器人載體硬件；下層視控模型和運控算法聚焦具體場景的特定動作執行，不用決策整個任務是如何完成的。 超腦大腦與小腦腦幹相互解耦。

遠征A1設計考慮了任務泛化率和任務執行成功率：

*   **任務泛化率：** 針對上層雲端超腦和大腦。大模型對新的任務和3D環境進行精準感知決策和指令計劃生成的能力。
*   **任務執行成功率：** 針對下層小腦和腦幹。視控模型和運控算法是否按照生成的指令計劃進行精準執行的能力。

智元機器人定義了一系列元操作庫 (Meta-Skill)，在有限泛化的場景內，機器人能夠自主推理決策出端到端完成任務所需的動作編排。 隨著元操作庫的擴充，機器人能勝任的任務空間將呈指數級增長。

遠征A1的本体形態與人類相似：

*   身高1.75米
*   重量55公斤
*   最高步速每小時7公里
*   全身49個自由度
*   整機承重80公斤
*   單臂最大负载5公斤

硬件层面，智元自研了关节电机Powerflow、灵巧手SkillHand、反屈膝设计等关键零部件。軟件層面，智源自研了AgiROS機器人運行時中間件系統，能實現自主的任務編排、常識推理以及規劃執行。

**總結與展望**

我個人看好稚暉君，他綜合能力全面，動手能力超強。半年時間做出機器人實體，速度很快。但這次不僅僅是像之前在B站發影片，而是需要證明商業方向、技術突破、量產能力應用落地等多方面的結果，這對他來說是不小的挑戰。雙足機械人領域非常垂直和前沿，沒有太多開源方案可以借鑒。每家的設計理念會直接決定後續的技術方案和量產能力。

可行和可用之間可能有天差地別，各零部件的精度和配合非常考驗設計者和背後整個工業供應鏈的能力。在這個層面上，真正的源源不斷的創新才是關鍵。希望能夠繼續看到他們的創新和突破，我們會持續關注並第一時間跟大家報道。

**結束**

本期影片就到這裡，感謝大家的觀看，我們下期再見。

**整理說明：**

*   **結構化：** 使用標題、子標題、項目符號等方式，將內容組織成更清晰的結構。
*   **重點突出：** 使用加粗字體突出重點信息，方便快速瀏覽。
*   **邏輯性：** 調整段落順序，使邏輯更順暢。
*   **簡潔性：** 刪除一些重複或不必要的語氣詞，使文稿更簡潔。
*   **術語解釋：** 對一些專業術語進行解釋，例如“具身智能”、“元操作庫”等。

希望這個整理後的文稿對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>178. [2023-08-30] 【OpenAI】ChatGPT Enterprise企业版正式发布 | 无限制访问GPT-4 | 32K上下文输入 | 企业级安全隐私保护 | Sam Altman前往中东寻求千亿美元融资</summary><br>

<a href="https://www.youtube.com/watch?v=c5qUwar9tMA" target="_blank">
    <img src="https://img.youtube.com/vi/c5qUwar9tMA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】ChatGPT Enterprise企业版正式发布 | 无限制访问GPT-4 | 32K上下文输入 | 企业级安全隐私保护 | Sam Altman前往中东寻求千亿美元融资

好的，我來幫您整理這篇文稿。我會重點整理內容概要、核心觀點，並將文稿分段，使其結構更清晰，更易於閱讀。

**整理後的文稿：**

**標題：OpenAI推出ChatGPT企業版：最強版本？B端市場全面進攻號角吹響？**

**概要：**

本文介紹OpenAI最新推出的ChatGPT企業版，分析其功能升級、企業級應用、以及對B端市場的影響。同時探討OpenAI面臨的商業壓力與未來的發展方向，並引用業界觀點，分析企業選擇大模型時的考量因素。

**主要內容：**

**一、ChatGPT企業版發布：最強版本的功能升級**

*   **速度更快、無限制存取GPT-4：** 提供更快的速度、無使用上限地訪問GPT-4模型。
*   **更大的上下文窗口：** 擁有32,000個token的上下文窗口，可處理更長的輸入、文件，約等於24,000個單詞。
*   **無限制的高級數據分析：** 無限制訪問程式碼解釋器，加速金融研究、市場分析等數據處理工作。
*   **企業級安全與隱私：**
    *   企業擁有並控制數據，OpenAI不進行訓練或學習。
    *   數據保留時間可設定，符合SOC 2標準。
    *   採用AES 256算法加密靜態數據，TLS 1.2+加密傳輸數據。
*   **管理功能：** 具備專用管理控制台，便於批量成員管理、域驗證、SSO和使用情況分析。
*   **客製化功能:** 允許企業進行客製化，並擁有私有的客製化模型使用權。

**二、OpenAI B端市場戰略與商業壓力**

*   **全面進攻B端市場：** ChatGPT企業版是OpenAI正式向B端市場全面進攻的訊號。
*   **企業版客戶：** 內測客戶包括Block、Canva、雅詩蘭黛等知名企業。
*   **商業壓力：** OpenAI面臨流量下降、成本高昂等商業壓力，亟需擴展B端市場營收。
*   **融資需求：** 山姆·奧特曼尋求中東財團融資，規模不低於1000億美元，目標是實現Super intelligence。

**三、業界觀點：B端大模型市場趨勢分析**

*   **光速創投合夥人古魯查哈爾（Guru Chahal）的觀點：**
    *   企業初期探索使用大型模型，後期轉向小型、專業化、微調模型。
    *   人工智能模型分為巨腦模型（OpenAI）、挑戰者模型（Llama 2）、長尾模型三種類別。
*   **企業選擇模型考量因素：**
    1.  數據隱私與合規要求。
    2.  能否進行模型微調。
    3.  是否達到企業期望的推理性能水平（延遲、準確性、成本）。
*   **ChatGPT企業版分析：** 數據需交由OpenAI處理，微調可透過OpenAI推出的微調介面實現，成本需視具體商務談判情況而定。

**四、OpenAI未來展望**

*   **計劃推出的功能：**
    1.  自定義數據來源，連接企業應用程式。
    2.  為小型團隊提供自助式ChatGPT商務服務。
    3.  更強大的高級數據分析與瀏覽版本。
    4.  為數據分析師、行銷人員、客戶支援等提供更多工具與解決方案。
*   **競爭態勢：** 雖然GPT-4仍領先，但其他大模型差距正在縮小。

**五、總結與討論**

*   OpenAI企業版的推出顯示其技術實力與商業壓力。
*   企業選擇使用ChatGPT企業版需綜合考量。
*   OpenAI的未來發展充滿變數，Super intelligence目標遙遠。

**如果您覺得需要調整，請隨時告訴我！**

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>177. 【AWS】Amazon计划明年推出IPv4新价格 | 43亿IPv4地址四年前已耗尽 | IPv6为何普及不高</summary><br>

<a href="https://www.youtube.com/watch?v=9TF9b7ZWvnk" target="_blank">
    <img src="https://img.youtube.com/vi/9TF9b7ZWvnk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AWS】Amazon计划明年推出IPv4新价格 | 43亿IPv4地址四年前已耗尽 | IPv6为何普及不高



---

</details>

<details>
<summary>176. 【国产】CEC-IDE | 号称自主研发 | 实则套皮开源 | 数字广东 | 究竟是谁在卡我们的脖子 | 汉芯 | 红芯浏览器 | 木兰编程语言</summary><br>

<a href="https://www.youtube.com/watch?v=fOpBEWZVKU0" target="_blank">
    <img src="https://img.youtube.com/vi/fOpBEWZVKU0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【国产】CEC-IDE | 号称自主研发 | 实则套皮开源 | 数字广东 | 究竟是谁在卡我们的脖子 | 汉芯 | 红芯浏览器 | 木兰编程语言



---

</details>

<details>
<summary>175. 【AI】AI终会有意识 | 图灵奖得主Yoshua Bengio | 19人团队88页论文论证 | 没有技术障碍</summary><br>

<a href="https://www.youtube.com/watch?v=RhsSdh8RSgM" target="_blank">
    <img src="https://img.youtube.com/vi/RhsSdh8RSgM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】AI终会有意识 | 图灵奖得主Yoshua Bengio | 19人团队88页论文论证 | 没有技术障碍



---

</details>

<details>
<summary>174. 【Meta】Meta开源代码生成模型 Code Llama | Llama 2家族 | 效果直逼GPT-4 | 免费可商用</summary><br>

<a href="https://www.youtube.com/watch?v=Wr6-bf_e8c0" target="_blank">
    <img src="https://img.youtube.com/vi/Wr6-bf_e8c0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Meta】Meta开源代码生成模型 Code Llama | Llama 2家族 | 效果直逼GPT-4 | 免费可商用



---

</details>

<details>
<summary>173. 【Office】微软EXCEL重大升级 | 原生支持Python | 可视化分析 | 机器学习 | 数据处理 | Anaconda | Microsoft 365</summary><br>

<a href="https://www.youtube.com/watch?v=cYpBDZbrvLA" target="_blank">
    <img src="https://img.youtube.com/vi/cYpBDZbrvLA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Office】微软EXCEL重大升级 | 原生支持Python | 可视化分析 | 机器学习 | 数据处理 | Anaconda | Microsoft 365



---

</details>

<details>
<summary>172. 【OpenAI】GPT-3.5 Turbo开放微调API | FineTuning | 人人可打造专属ChatGPT | GPT-4版本即将推出</summary><br>

<a href="https://www.youtube.com/watch?v=hYAOx-zQ62k" target="_blank">
    <img src="https://img.youtube.com/vi/hYAOx-zQ62k/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】GPT-3.5 Turbo开放微调API | FineTuning | 人人可打造专属ChatGPT | GPT-4版本即将推出



---

</details>

<details>
<summary>171. 【AI】OpenAI的超级对齐究竟要干什么 | 团队负责人Jan Leike访谈深度解析 | 4年内解决超级对齐 | 一盘大棋还是噱头 | 对齐AI的自我升级迭代 | 算力即对齐 | 是否会产生AGI</summary><br>

<a href="https://www.youtube.com/watch?v=XRvjoQWtlHU" target="_blank">
    <img src="https://img.youtube.com/vi/XRvjoQWtlHU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】OpenAI的超级对齐究竟要干什么 | 团队负责人Jan Leike访谈深度解析 | 4年内解决超级对齐 | 一盘大棋还是噱头 | 对齐AI的自我升级迭代 | 算力即对齐 | 是否会产生AGI



---

</details>

<details>
<summary>170. 【AI】十年「AI for Science」发展综述 | 人工智能如何助力科学研究 | 图灵奖Yoshua Bengio团队 | 《Nature》杂志发表 | 是否要投身AI for Science</summary><br>

<a href="https://www.youtube.com/watch?v=ztsE_tgclj4" target="_blank">
    <img src="https://img.youtube.com/vi/ztsE_tgclj4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】十年「AI for Science」发展综述 | 人工智能如何助力科学研究 | 图灵奖Yoshua Bengio团队 | 《Nature》杂志发表 | 是否要投身AI for Science



---

</details>

<details>
<summary>169. 【科学】脑机接口治愈16年抑郁症 | 脑起搏器 | 电极刺激神经核团 | 上海瑞金医院 | 孙伯民</summary><br>

<a href="https://www.youtube.com/watch?v=J3LAuwB0G_c" target="_blank">
    <img src="https://img.youtube.com/vi/J3LAuwB0G_c/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【科学】脑机接口治愈16年抑郁症 | 脑起搏器 | 电极刺激神经核团 | 上海瑞金医院 | 孙伯民



---

</details>

<details>
<summary>168. 【OpenAI】OpenAI首次公开宣布收购 | Global Illumination | 8人小公司为何被青睐 | 开源MMOPRG Biomes</summary><br>

<a href="https://www.youtube.com/watch?v=SctDzExnSw0" target="_blank">
    <img src="https://img.youtube.com/vi/SctDzExnSw0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】OpenAI首次公开宣布收购 | Global Illumination | 8人小公司为何被青睐 | 开源MMOPRG Biomes



---

</details>

<details>
<summary>167. 【AIGC】七千字通俗讲解Stable Diffusion | 稳定扩散模型 | CLIP | UNET | VAE | Dreambooth | LoRA</summary><br>

<a href="https://www.youtube.com/watch?v=F6ApJH5xuVo" target="_blank">
    <img src="https://img.youtube.com/vi/F6ApJH5xuVo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】七千字通俗讲解Stable Diffusion | 稳定扩散模型 | CLIP | UNET | VAE | Dreambooth | LoRA



---

</details>

<details>
<summary>166. 【OpenAI】GPT-4挑战人类内容审核员 | 一天顶6个月 | 自动识别非法信息 | 审核员要下岗了？</summary><br>

<a href="https://www.youtube.com/watch?v=LKxPQk0XTwg" target="_blank">
    <img src="https://img.youtube.com/vi/LKxPQk0XTwg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】GPT-4挑战人类内容审核员 | 一天顶6个月 | 自动识别非法信息 | 审核员要下岗了？



---

</details>

<details>
<summary>165. 【AI】什么是e/acc | 为何能预见这次AIGC浪潮 | 有效加速主义 | 有效利他主义</summary><br>

<a href="https://www.youtube.com/watch?v=e3wR1jlYsvg" target="_blank">
    <img src="https://img.youtube.com/vi/e3wR1jlYsvg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】什么是e/acc | 为何能预见这次AIGC浪潮 | 有效加速主义 | 有效利他主义



---

</details>

<details>
<summary>164. 【小米】雷军2023年度演讲”成长“ | 小米新产品发布会 | 3小时浓缩精华版 | 人因梦想而伟大</summary><br>

<a href="https://www.youtube.com/watch?v=8DVBLrPUaEk" target="_blank">
    <img src="https://img.youtube.com/vi/8DVBLrPUaEk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【小米】雷军2023年度演讲”成长“ | 小米新产品发布会 | 3小时浓缩精华版 | 人因梦想而伟大



---

</details>

<details>
<summary>163. 【AIGC】Stability.AI发布代码生成模型StableCode | 30亿参数 | 16000上下文长度 | 三种模型 | StarCoder | HuggingFace开源</summary><br>

<a href="https://www.youtube.com/watch?v=uumQeZYo6Z0" target="_blank">
    <img src="https://img.youtube.com/vi/uumQeZYo6Z0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】Stability.AI发布代码生成模型StableCode | 30亿参数 | 16000上下文长度 | 三种模型 | StarCoder | HuggingFace开源



---

</details>

<details>
<summary>162. 【人工智能】万字通俗讲解大语言模型内部运行原理 | LLM | 词向量 | Transformer | 注意力机制 | 前馈网络 | 反向传播 | 心智理论</summary><br>

<a href="https://www.youtube.com/watch?v=dIyQl99oxlg" target="_blank">
    <img src="https://img.youtube.com/vi/dIyQl99oxlg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】万字通俗讲解大语言模型内部运行原理 | LLM | 词向量 | Transformer | 注意力机制 | 前馈网络 | 反向传播 | 心智理论



---

</details>

<details>
<summary>161. 【创业】创业者的“迷宫” | 马克.安德森 | A16Z创始人 | 如何看待AI | 创始人背调 | 创业的本质</summary><br>

<a href="https://www.youtube.com/watch?v=6XyLhswQ6j4" target="_blank">
    <img src="https://img.youtube.com/vi/6XyLhswQ6j4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【创业】创业者的“迷宫” | 马克.安德森 | A16Z创始人 | 如何看待AI | 创始人背调 | 创业的本质



---

</details>

<details>
<summary>160. 【人工智能】ChatGPT版权侵权第一案 | 美国两名作家集体诉讼 | 六项指控 | OpenAI | 古登堡计划 | 影子图书馆</summary><br>

<a href="https://www.youtube.com/watch?v=Qh6RU8N1MZY" target="_blank">
    <img src="https://img.youtube.com/vi/Qh6RU8N1MZY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】ChatGPT版权侵权第一案 | 美国两名作家集体诉讼 | 六项指控 | OpenAI | 古登堡计划 | 影子图书馆



---

</details>

<details>
<summary>159. 【Nvidia】英伟达发布史上最快GPU GH200 | AI Workstation | RTX6000 | Ominverse| 黄仁勋 | SIGGRAPH2023</summary><br>

<a href="https://www.youtube.com/watch?v=BfO4Hg9vSmE" target="_blank">
    <img src="https://img.youtube.com/vi/BfO4Hg9vSmE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Nvidia】英伟达发布史上最快GPU GH200 | AI Workstation | RTX6000 | Ominverse| 黄仁勋 | SIGGRAPH2023



---

</details>

<details>
<summary>158. 【开源】盘点开源项目挣钱的22种模式 | SaaS | 软件市场 | 升级服务 | 认证培训 | 流量 | 捐款 | 周边</summary><br>

<a href="https://www.youtube.com/watch?v=Wu8zpztxQO0" target="_blank">
    <img src="https://img.youtube.com/vi/Wu8zpztxQO0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【开源】盘点开源项目挣钱的22种模式 | SaaS | 软件市场 | 升级服务 | 认证培训 | 流量 | 捐款 | 周边



---

</details>

<details>
<summary>157. 【OpenAI】OpenAI公布官方爬虫GPTBot | robots协议 | AI数据究竟如何使用</summary><br>

<a href="https://www.youtube.com/watch?v=51I0Dt3bPRk" target="_blank">
    <img src="https://img.youtube.com/vi/51I0Dt3bPRk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】OpenAI公布官方爬虫GPTBot | robots协议 | AI数据究竟如何使用



---

</details>

<details>
<summary>156. 【人物】Vim 编辑器之父 Bram Moolenaar | 传奇人生 | 最受程序员欢迎的编辑器之一 | 慈善软件发起人 | ICCF</summary><br>

<a href="https://www.youtube.com/watch?v=KBq9ZfmX_WM" target="_blank">
    <img src="https://img.youtube.com/vi/KBq9ZfmX_WM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】Vim 编辑器之父 Bram Moolenaar | 传奇人生 | 最受程序员欢迎的编辑器之一 | 慈善软件发起人 | ICCF



---

</details>

<details>
<summary>155. 【AI】目前AI公司还需要多少张H100 GPU显卡 | 为什么不选AMD和V100  | 半年内H100短缺 | 产能瓶颈在哪里 | 英伟达NVIDIA</summary><br>

<a href="https://www.youtube.com/watch?v=73ItxszMpWw" target="_blank">
    <img src="https://img.youtube.com/vi/73ItxszMpWw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】目前AI公司还需要多少张H100 GPU显卡 | 为什么不选AMD和V100  | 半年内H100短缺 | 产能瓶颈在哪里 | 英伟达NVIDIA



---

</details>

<details>
<summary>154. 【ChatGPT】最新六项功能更新 | 默认使用GPT-4 | 提示示例 | 多文件上传 | 支持快捷键 | 回答建议 | 更长登录状态</summary><br>

<a href="https://www.youtube.com/watch?v=wg4g7f01LpE" target="_blank">
    <img src="https://img.youtube.com/vi/wg4g7f01LpE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【ChatGPT】最新六项功能更新 | 默认使用GPT-4 | 提示示例 | 多文件上传 | 支持快捷键 | 回答建议 | 更长登录状态



---

</details>

<details>
<summary>153. 【分享】傅盛演讲 | AGI时代的AI-Native创业思考 | 大模型创业的机会在哪里 | 学好提示词 | 大模型很大应用很小 | 创业者要把细节做好</summary><br>

<a href="https://www.youtube.com/watch?v=_Z8lLV9TE1A" target="_blank">
    <img src="https://img.youtube.com/vi/_Z8lLV9TE1A/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【分享】傅盛演讲 | AGI时代的AI-Native创业思考 | 大模型创业的机会在哪里 | 学好提示词 | 大模型很大应用很小 | 创业者要把细节做好



---

</details>

<details>
<summary>152. 【医药】抗癌神药是真的么 | AOH1996 | 20年研发历程 | PCNA靶向治疗 | 抑制70多种癌细胞 | 对健康细胞无害</summary><br>

<a href="https://www.youtube.com/watch?v=vn115XvtoZU" target="_blank">
    <img src="https://img.youtube.com/vi/vn115XvtoZU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【医药】抗癌神药是真的么 | AOH1996 | 20年研发历程 | PCNA靶向治疗 | 抑制70多种癌细胞 | 对健康细胞无害



---

</details>

<details>
<summary>151. 【超导】LK-99背后的故事 | 幽灵般出现的波动 | 两人坚持了20年的梦想 | 人类为何如此追求超导</summary><br>

<a href="https://www.youtube.com/watch?v=UyhQtBv_0eE" target="_blank">
    <img src="https://img.youtube.com/vi/UyhQtBv_0eE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【超导】LK-99背后的故事 | 幽灵般出现的波动 | 两人坚持了20年的梦想 | 人类为何如此追求超导



---

</details>

<details>
<summary>150. 【超导】LK-99常温超导晶体 | 中美俄实验室同日复现 | 韩国团队内讧 | 相关美股暴涨 | 专家仪器竟比不过坩埚| 炼金术成真| 第四次技术革命到来？</summary><br>

<a href="https://www.youtube.com/watch?v=0E7znys97z0" target="_blank">
    <img src="https://img.youtube.com/vi/0E7znys97z0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【超导】LK-99常温超导晶体 | 中美俄实验室同日复现 | 韩国团队内讧 | 相关美股暴涨 | 专家仪器竟比不过坩埚| 炼金术成真| 第四次技术革命到来？



---

</details>

<details>
<summary>149. 从罗刹海市到人工智能 | 刀郎 | 维特根斯坦 | 语言哲学 | 人类与AI面临一样的困境</summary><br>

<a href="https://www.youtube.com/watch?v=6jBQDAUk5QQ" target="_blank">
    <img src="https://img.youtube.com/vi/6jBQDAUk5QQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 从罗刹海市到人工智能 | 刀郎 | 维特根斯坦 | 语言哲学 | 人类与AI面临一样的困境



---

</details>

<details>
<summary>148. 【科技】人工智能有多渴 | Google一年消耗一个半西湖 | 大厂把数据中心都建到哪</summary><br>

<a href="https://www.youtube.com/watch?v=kwbt9K307x4" target="_blank">
    <img src="https://img.youtube.com/vi/kwbt9K307x4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【科技】人工智能有多渴 | Google一年消耗一个半西湖 | 大厂把数据中心都建到哪



---

</details>

<details>
<summary>147. 【人工智能】DeepMind发布RT-2 | VAL模型 | 泛化能力优秀 | 机器人版ChatGPT | 具身智能最新进展</summary><br>

<a href="https://www.youtube.com/watch?v=mZVTBB_YnZk" target="_blank">
    <img src="https://img.youtube.com/vi/mZVTBB_YnZk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】DeepMind发布RT-2 | VAL模型 | 泛化能力优秀 | 机器人版ChatGPT | 具身智能最新进展



---

</details>

<details>
<summary>146. 【Twitter】 如何评价Twitter和埃隆马斯克 | 睡地板仍被裁的女高管回忆爆料</summary><br>

<a href="https://www.youtube.com/watch?v=T1wcUohiyRw" target="_blank">
    <img src="https://img.youtube.com/vi/T1wcUohiyRw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Twitter】 如何评价Twitter和埃隆马斯克 | 睡地板仍被裁的女高管回忆爆料



---

</details>

<details>
<summary>145. 【AI】Stack Overflow发布Overflow AI 能否挽救颓势 | 语义搜索 | VS Code 扩展 | Slack集成 | 企业知识提取 | 开发专属论坛</summary><br>

<a href="https://www.youtube.com/watch?v=8qA5ROIWj9M" target="_blank">
    <img src="https://img.youtube.com/vi/8qA5ROIWj9M/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】Stack Overflow发布Overflow AI 能否挽救颓势 | 语义搜索 | VS Code 扩展 | Slack集成 | 企业知识提取 | 开发专属论坛



---

</details>

<details>
<summary>144. 【行业】 2023中国开发者调查报告 | 程序员基本画像 | 年龄 | 收入 | 地域 | 行业 | 工作时长 | 工作状态 | 开发工具 | 如何看待AI</summary><br>

<a href="https://www.youtube.com/watch?v=MnnM7DAr3wM" target="_blank">
    <img src="https://img.youtube.com/vi/MnnM7DAr3wM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【行业】 2023中国开发者调查报告 | 程序员基本画像 | 年龄 | 收入 | 地域 | 行业 | 工作时长 | 工作状态 | 开发工具 | 如何看待AI



---

</details>

<details>
<summary>143. 【资讯】Photoshop测试版推出生成性扩展AI功能 | OpenAI | 微软 | DoorDash | 科技日报03期 | 20230329</summary><br>

<a href="https://www.youtube.com/watch?v=0iRaXZpTAI4" target="_blank">
    <img src="https://img.youtube.com/vi/0iRaXZpTAI4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【资讯】Photoshop测试版推出生成性扩展AI功能 | OpenAI | 微软 | DoorDash | 科技日报03期 | 20230329



---

</details>

<details>
<summary>142. 【商业】AI创业者眼中的AI创业格局 | Sam Hogan  | AI创业时代的壁垒是什么 | 行业先行者是否能够一直笑傲江湖 | 大公司和小公司分别有怎样的机会</summary><br>

<a href="https://www.youtube.com/watch?v=b_Zuitub7OA" target="_blank">
    <img src="https://img.youtube.com/vi/b_Zuitub7OA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】AI创业者眼中的AI创业格局 | Sam Hogan  | AI创业时代的壁垒是什么 | 行业先行者是否能够一直笑傲江湖 | 大公司和小公司分别有怎样的机会



---

</details>

<details>
<summary>141. 【资讯】Stability AI发布SDXL1.0 | Meta Llama2收费 | Cohere推出Coral | 谷歌Brain2Music模型 | 科技日报02期 | 20230328</summary><br>

<a href="https://www.youtube.com/watch?v=4yUI4J7sJXg" target="_blank">
    <img src="https://img.youtube.com/vi/4yUI4J7sJXg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【资讯】Stability AI发布SDXL1.0 | Meta Llama2收费 | Cohere推出Coral | 谷歌Brain2Music模型 | 科技日报02期 | 20230328



---

</details>

<details>
<summary>140. 【资讯】微软最新季度财报创纪录 | Alphabet广告业务重新增长 | 阿里云率先支持Llama 2 | OpenAI停用AI文本检测器 | 科技日报01期 | 20230727</summary><br>

<a href="https://www.youtube.com/watch?v=vk49TN4heAY" target="_blank">
    <img src="https://img.youtube.com/vi/vk49TN4heAY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【资讯】微软最新季度财报创纪录 | Alphabet广告业务重新增长 | 阿里云率先支持Llama 2 | OpenAI停用AI文本检测器 | 科技日报01期 | 20230727



---

</details>

<details>
<summary>139. 【商业】Sam Altman的 Worldcoin 项目正式上线 | 什么是Worldcoin | 是割韭菜还是真的乌托邦 | World ID | Orb虹膜识别 | 加密数字货币</summary><br>

<a href="https://www.youtube.com/watch?v=U88fv5N9ACQ" target="_blank">
    <img src="https://img.youtube.com/vi/U88fv5N9ACQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】Sam Altman的 Worldcoin 项目正式上线 | 什么是Worldcoin | 是割韭菜还是真的乌托邦 | World ID | Orb虹膜识别 | 加密数字货币



---

</details>

<details>
<summary>138. 【人工智能】白宫联合七大AI巨头发起自愿承诺书 |  如何对AI生成的内容添加水印 | 马里兰大学论文解读</summary><br>

<a href="https://www.youtube.com/watch?v=GlaWDx8efps" target="_blank">
    <img src="https://img.youtube.com/vi/GlaWDx8efps/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】白宫联合七大AI巨头发起自愿承诺书 |  如何对AI生成的内容添加水印 | 马里兰大学论文解读



---

</details>

<details>
<summary>137. 【人工智能】用AI检测器来检测AI生成内容到底靠不靠谱 | 《美国宪法》和《圣经》都是AI生成的？| 困惑度和突发性指标 | GPTZero | AI生成数据有毒？</summary><br>

<a href="https://www.youtube.com/watch?v=0GrS3Edsm-4" target="_blank">
    <img src="https://img.youtube.com/vi/0GrS3Edsm-4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】用AI检测器来检测AI生成内容到底靠不靠谱 | 《美国宪法》和《圣经》都是AI生成的？| 困惑度和突发性指标 | GPTZero | AI生成数据有毒？



---

</details>

<details>
<summary>136. 【人工智能】邪恶版ChatGPT现世 | WormGPT | 自动写病毒、钓鱼邮件 | 黑客专用武器库 | BEC攻击 | 奶奶漏洞</summary><br>

<a href="https://www.youtube.com/watch?v=sM5Yr_9Ari4" target="_blank">
    <img src="https://img.youtube.com/vi/sM5Yr_9Ari4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】邪恶版ChatGPT现世 | WormGPT | 自动写病毒、钓鱼邮件 | 黑客专用武器库 | BEC攻击 | 奶奶漏洞



---

</details>

<details>
<summary>135. 【人工智能】 Meta Llama 2技术细节详解 | 伯克利博士解读 | 奖励模型才是关键 | 高质量数据是一切</summary><br>

<a href="https://www.youtube.com/watch?v=e5fBuXeWhRU" target="_blank">
    <img src="https://img.youtube.com/vi/e5fBuXeWhRU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】 Meta Llama 2技术细节详解 | 伯克利博士解读 | 奖励模型才是关键 | 高质量数据是一切



---

</details>

<details>
<summary>134. 【人物】凯文・米特尼克的传奇一生 | 世界头号黑客 | 轻松入侵FBI | 十大通缉要犯 | 59岁因病逝世</summary><br>

<a href="https://www.youtube.com/watch?v=VGgRzU5bSIo" target="_blank">
    <img src="https://img.youtube.com/vi/VGgRzU5bSIo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】凯文・米特尼克的传奇一生 | 世界头号黑客 | 轻松入侵FBI | 十大通缉要犯 | 59岁因病逝世



---

</details>

<details>
<summary>133. 【OpenAI】OpenAI薪资体系揭秘 | 基本工资一年30万 | PPU是什么?是否在给员工画大饼?</summary><br>

<a href="https://www.youtube.com/watch?v=4SOysxlCP1s" target="_blank">
    <img src="https://img.youtube.com/vi/4SOysxlCP1s/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】OpenAI薪资体系揭秘 | 基本工资一年30万 | PPU是什么?是否在给员工画大饼?



---

</details>

<details>
<summary>132. 【Apple】苹果组建团队秘密研发大语言模型 | Apple GPT | 计划跟OpenAI谈合作 | 用AI来增强Siri | 2024年公开</summary><br>

<a href="https://www.youtube.com/watch?v=Va38mwJydGY" target="_blank">
    <img src="https://img.youtube.com/vi/Va38mwJydGY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Apple】苹果组建团队秘密研发大语言模型 | Apple GPT | 计划跟OpenAI谈合作 | 用AI来增强Siri | 2024年公开



---

</details>

<details>
<summary>131. 【GPT】实锤！GPT-4真的变笨了！| 四大任务评估 | 数学能力几乎归零 | 大语言模型的质量究竟是否可控？</summary><br>

<a href="https://www.youtube.com/watch?v=8jmHQ8lL2sI" target="_blank">
    <img src="https://img.youtube.com/vi/8jmHQ8lL2sI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【GPT】实锤！GPT-4真的变笨了！| 四大任务评估 | 数学能力几乎归零 | 大语言模型的质量究竟是否可控？



---

</details>

<details>
<summary>130. 【人工智能】Meta发布Llama 2 | 免费开源可商用 AI 大语言模型 | OpenAI 竞争对手 | 微软又一次赢麻了</summary><br>

<a href="https://www.youtube.com/watch?v=Vl5O5Yn9_4M" target="_blank">
    <img src="https://img.youtube.com/vi/Vl5O5Yn9_4M/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Meta发布Llama 2 | 免费开源可商用 AI 大语言模型 | OpenAI 竞争对手 | 微软又一次赢麻了



---

</details>

<details>
<summary>129. 【人物】奥本海默 | 原子弹之父 | 曼哈顿计划 | 诺兰首部传记电影</summary><br>

<a href="https://www.youtube.com/watch?v=0s7WFLmucMw" target="_blank">
    <img src="https://img.youtube.com/vi/0s7WFLmucMw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】奥本海默 | 原子弹之父 | 曼哈顿计划 | 诺兰首部传记电影



---

</details>

<details>
<summary>128. 【GPT-4】你是否感觉最近GPT-4变笨了呢？究竟是什么原因？OpenAI在搞什么？</summary><br>

<a href="https://www.youtube.com/watch?v=6rKP_GhKjSM" target="_blank">
    <img src="https://img.youtube.com/vi/6rKP_GhKjSM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【GPT-4】你是否感觉最近GPT-4变笨了呢？究竟是什么原因？OpenAI在搞什么？



---

</details>

<details>
<summary>127. 【商业】Threads数据开始下降，这是要黄了么？</summary><br>

<a href="https://www.youtube.com/watch?v=-IPSWBmeB78" target="_blank">
    <img src="https://img.youtube.com/vi/-IPSWBmeB78/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】Threads数据开始下降，这是要黄了么？



---

</details>

<details>
<summary>126. 【xAI】xAI创始团队12人Twitter首秀  | 公司的使命目标及团队分工 | OpenAI的竞争对手 | 探索宇宙的本质</summary><br>

<a href="https://www.youtube.com/watch?v=CQnffaEqemk" target="_blank">
    <img src="https://img.youtube.com/vi/CQnffaEqemk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【xAI】xAI创始团队12人Twitter首秀  | 公司的使命目标及团队分工 | OpenAI的竞争对手 | 探索宇宙的本质



---

</details>

<details>
<summary>125. 【人工智能】如何用LangChain和向量数据库打造语义搜索 | LangChain CEO解读 | 五个典型案例</summary><br>

<a href="https://www.youtube.com/watch?v=tPi7JrcwnnA" target="_blank">
    <img src="https://img.youtube.com/vi/tPi7JrcwnnA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】如何用LangChain和向量数据库打造语义搜索 | LangChain CEO解读 | 五个典型案例



---

</details>

<details>
<summary>124. 【人工智能】马斯克成立新公司xAI | 探索宇宙的本质 | OpenAI的竞争对手 | 十一名创始团队成员就位</summary><br>

<a href="https://www.youtube.com/watch?v=P5WLWIs4rEU" target="_blank">
    <img src="https://img.youtube.com/vi/P5WLWIs4rEU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】马斯克成立新公司xAI | 探索宇宙的本质 | OpenAI的竞争对手 | 十一名创始团队成员就位



---

</details>

<details>
<summary>123. 【人工智能】什么是超级对齐 | Super Alignment | 对齐的十个级别 | OpenAI组建新的超级智能团队</summary><br>

<a href="https://www.youtube.com/watch?v=e-lhpJtk1J8" target="_blank">
    <img src="https://img.youtube.com/vi/e-lhpJtk1J8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】什么是超级对齐 | Super Alignment | 对齐的十个级别 | OpenAI组建新的超级智能团队



---

</details>

<details>
<summary>122. 【GPT4】GPT-4内部核心技术全揭秘 | 1.8万亿参数 | 16个混合专家MoE模型 | 训练一次超6300万美元 | 训练使用13万亿个token | 推理计算瓶颈 | AI算力 | 工程权衡</summary><br>

<a href="https://www.youtube.com/watch?v=dtULz5C5_vU" target="_blank">
    <img src="https://img.youtube.com/vi/dtULz5C5_vU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【GPT4】GPT-4内部核心技术全揭秘 | 1.8万亿参数 | 16个混合专家MoE模型 | 训练一次超6300万美元 | 训练使用13万亿个token | 推理计算瓶颈 | AI算力 | 工程权衡



---

</details>

<details>
<summary>121. 【人工智能】什么是AI智能体 | 基于大语言模型的智能代理 | OpenAI安全系统负责人 | Lilian Weng</summary><br>

<a href="https://www.youtube.com/watch?v=CvD6WuaP_H4" target="_blank">
    <img src="https://img.youtube.com/vi/CvD6WuaP_H4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】什么是AI智能体 | 基于大语言模型的智能代理 | OpenAI安全系统负责人 | Lilian Weng



---

</details>

<details>
<summary>120. 【OpenAI】OpenAI发布全球招募令 | 打造全新团队“Superalignment” | 四年内解决超级人工智能对齐问题</summary><br>

<a href="https://www.youtube.com/watch?v=ti2dDOjC_x8" target="_blank">
    <img src="https://img.youtube.com/vi/ti2dDOjC_x8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】OpenAI发布全球招募令 | 打造全新团队“Superalignment” | 四年内解决超级人工智能对齐问题



---

</details>

<details>
<summary>119. 【思考】如何做出伟大的工作 | 保罗·格雷厄姆最新长文 | 万字精华总结 | 四个步骤 | 找到你感兴趣的工作 | 与好奇心共舞</summary><br>

<a href="https://www.youtube.com/watch?v=Nuf4HsKtt5E" target="_blank">
    <img src="https://img.youtube.com/vi/Nuf4HsKtt5E/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【思考】如何做出伟大的工作 | 保罗·格雷厄姆最新长文 | 万字精华总结 | 四个步骤 | 找到你感兴趣的工作 | 与好奇心共舞



---

</details>

<details>
<summary>118. 【人工智能】开源多模态大语言模型哪家强？| TOP 12 排行榜 | 2个大类14个子任务 | BLIP2 | MiniGPT4</summary><br>

<a href="https://www.youtube.com/watch?v=jMVzOgp5f5k" target="_blank">
    <img src="https://img.youtube.com/vi/jMVzOgp5f5k/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】开源多模态大语言模型哪家强？| TOP 12 排行榜 | 2个大类14个子任务 | BLIP2 | MiniGPT4



---

</details>

<details>
<summary>117. 【OpenAI】OpenAI重磅更新 | GPT-4 API全面开放使用！</summary><br>

<a href="https://www.youtube.com/watch?v=KkJA3a3dTNs" target="_blank">
    <img src="https://img.youtube.com/vi/KkJA3a3dTNs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】OpenAI重磅更新 | GPT-4 API全面开放使用！



---

</details>

<details>
<summary>116. 抑郁症简史 | 从中世纪到现代医学 | 为何世界名人都爱得抑郁症</summary><br>

<a href="https://www.youtube.com/watch?v=0SFj_xcP_3M" target="_blank">
    <img src="https://img.youtube.com/vi/0SFj_xcP_3M/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 抑郁症简史 | 从中世纪到现代医学 | 为何世界名人都爱得抑郁症



---

</details>

<details>
<summary>115. 【人物】以太网之父 | 罗伯特·梅兰克顿·梅特卡夫 | Robert Melancton Metcalfe</summary><br>

<a href="https://www.youtube.com/watch?v=KB_ksi5LOec" target="_blank">
    <img src="https://img.youtube.com/vi/KB_ksi5LOec/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】以太网之父 | 罗伯特·梅兰克顿·梅特卡夫 | Robert Melancton Metcalfe



---

</details>

<details>
<summary>114. 【科技】2023年十大新兴技术报告 | 夏季达沃斯论坛 | Top 10 Emerging Technologies of 2023</summary><br>

<a href="https://www.youtube.com/watch?v=AeN8dooRShw" target="_blank">
    <img src="https://img.youtube.com/vi/AeN8dooRShw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【科技】2023年十大新兴技术报告 | 夏季达沃斯论坛 | Top 10 Emerging Technologies of 2023



---

</details>

<details>
<summary>113. 【人工智能】AIGC领域最大收购 | 13亿美元 | Databricks 收购 MosaicML | 创业2年仅62人 | 估值翻6倍 | Snowflake 收购 Neeva</summary><br>

<a href="https://www.youtube.com/watch?v=9cFbEYujfqM" target="_blank">
    <img src="https://img.youtube.com/vi/9cFbEYujfqM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AIGC领域最大收购 | 13亿美元 | Databricks 收购 MosaicML | 创业2年仅62人 | 估值翻6倍 | Snowflake 收购 Neeva



---

</details>

<details>
<summary>112. 【人生】2023高校毕业演讲 | 叶敬忠  | 罗翔</summary><br>

<a href="https://www.youtube.com/watch?v=CO8YtrtcQDE" target="_blank">
    <img src="https://img.youtube.com/vi/CO8YtrtcQDE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人生】2023高校毕业演讲 | 叶敬忠  | 罗翔



---

</details>

<details>
<summary>111. 【读书】《为什么伟大不能被计划》| 什么是”新奇性搜索“ | 为什么目标会误导我们</summary><br>

<a href="https://www.youtube.com/watch?v=QFfBgYg-1a4" target="_blank">
    <img src="https://img.youtube.com/vi/QFfBgYg-1a4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【读书】《为什么伟大不能被计划》| 什么是”新奇性搜索“ | 为什么目标会误导我们



---

</details>

<details>
<summary>110. 【人物】硅谷千亿大佬要约架？| 八角笼中格斗 | 埃隆马斯克 | 马克扎克伯格 | 打嘴炮还是动真格？</summary><br>

<a href="https://www.youtube.com/watch?v=i0TkYxv21v4" target="_blank">
    <img src="https://img.youtube.com/vi/i0TkYxv21v4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】硅谷千亿大佬要约架？| 八角笼中格斗 | 埃隆马斯克 | 马克扎克伯格 | 打嘴炮还是动真格？



---

</details>

<details>
<summary>109. 【人生】当代年轻人的地狱开局 | 形成如今局面的原因 | 如何破解就业困局 | 发现自己的天赋和擅长 | 拒绝内卷和躺平</summary><br>

<a href="https://www.youtube.com/watch?v=TSLAgFYFjaA" target="_blank">
    <img src="https://img.youtube.com/vi/TSLAgFYFjaA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人生】当代年轻人的地狱开局 | 形成如今局面的原因 | 如何破解就业困局 | 发现自己的天赋和擅长 | 拒绝内卷和躺平



---

</details>

<details>
<summary>108. 【AIGC】AI生成视频攻破“闪烁”难题 | 画面更一致生动 | 零样本视频翻译 | 南洋理工大学最新发表论文</summary><br>

<a href="https://www.youtube.com/watch?v=X8dy7uuD86Q" target="_blank">
    <img src="https://img.youtube.com/vi/X8dy7uuD86Q/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】AI生成视频攻破“闪烁”难题 | 画面更一致生动 | 零样本视频翻译 | 南洋理工大学最新发表论文



---

</details>

<details>
<summary>107. How to install and use Amazon AWS CodeWhisperer</summary><br>

<a href="https://www.youtube.com/watch?v=hsLnqmCT5E0" target="_blank">
    <img src="https://img.youtube.com/vi/hsLnqmCT5E0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# How to install and use Amazon AWS CodeWhisperer



---

</details>

<details>
<summary>106. 【编程开发】2023年最流行和最赚钱的编程语言是什么 |  StackOverflow超过9万名开发者调查报告 | MySQL数据库只能屈居第二 | 新增AI深入调查</summary><br>

<a href="https://www.youtube.com/watch?v=T96d8iNsDUQ" target="_blank">
    <img src="https://img.youtube.com/vi/T96d8iNsDUQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【编程开发】2023年最流行和最赚钱的编程语言是什么 |  StackOverflow超过9万名开发者调查报告 | MySQL数据库只能屈居第二 | 新增AI深入调查



---

</details>

<details>
<summary>105. 【商业】Stability AI创始人Emad Mostaque被曝丑闻 | 剽窃代码 | 学历造假 | 拖欠工资 | 夸大收入</summary><br>

<a href="https://www.youtube.com/watch?v=VOjlOrq1Oh4" target="_blank">
    <img src="https://img.youtube.com/vi/VOjlOrq1Oh4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】Stability AI创始人Emad Mostaque被曝丑闻 | 剽窃代码 | 学历造假 | 拖欠工资 | 夸大收入



---

</details>

<details>
<summary>104. 【OpenAI】ChatGPT的GPT-4、GPT-3.5系列模型重大更新 | 新增函数调用功能 | API价格大幅降低 | API弃用时间表 | LangChain岌岌可危？</summary><br>

<a href="https://www.youtube.com/watch?v=jgHhhjIE_3c" target="_blank">
    <img src="https://img.youtube.com/vi/jgHhhjIE_3c/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】ChatGPT的GPT-4、GPT-3.5系列模型重大更新 | 新增函数调用功能 | API价格大幅降低 | API弃用时间表 | LangChain岌岌可危？



---

</details>

<details>
<summary>103. 【人工智能】OmniMotion | 跟踪视频中的一切物体 | 即使遮挡也可跟踪 | quasi-3D规范体积视频表征 | 康奈尔大学、谷歌研究院和UC伯克利共同研究</summary><br>

<a href="https://www.youtube.com/watch?v=_Zj2jmsEoXA" target="_blank">
    <img src="https://img.youtube.com/vi/_Zj2jmsEoXA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OmniMotion | 跟踪视频中的一切物体 | 即使遮挡也可跟踪 | quasi-3D规范体积视频表征 | 康奈尔大学、谷歌研究院和UC伯克利共同研究



---

</details>

<details>
<summary>102. 【人工智能】Transformer论文《Attention Is All You Need》发表六周年回顾 | 八名作者如今都在干什么 | 多人创立独角兽公司</summary><br>

<a href="https://www.youtube.com/watch?v=a0T8SmHR9Ik" target="_blank">
    <img src="https://img.youtube.com/vi/a0T8SmHR9Ik/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Transformer论文《Attention Is All You Need》发表六周年回顾 | 八名作者如今都在干什么 | 多人创立独角兽公司



---

</details>

<details>
<summary>101. 【BAAI】对2023北京智源大会的一个总结</summary><br>

<a href="https://www.youtube.com/watch?v=ueGR7Dhqeqc" target="_blank">
    <img src="https://img.youtube.com/vi/ueGR7Dhqeqc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【BAAI】对2023北京智源大会的一个总结



---

</details>

