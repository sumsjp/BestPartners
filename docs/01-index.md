<details>
<summary>200. [2023-10-28] 【人工智能】波士顿动力Spot开口说话了 | ChatGPT ｜机器狗导游 | 正宗伦敦腔</summary><br>

<a href="https://www.youtube.com/watch?v=8EeX6EwXIpY" target="_blank">
    <img src="https://img.youtube.com/vi/8EeX6EwXIpY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】波士顿动力Spot开口说话了 | ChatGPT ｜机器狗导游 | 正宗伦敦腔

好的，我來幫你整理這段文稿，使其更具結構性和易讀性。我會將其分為幾個部分，並提煉關鍵信息：

**標題：** 波士頓動力 Spot 機器狗整合 ChatGPT：解鎖語言能力，化身導遊

**簡介：**

*   最佳拍檔的大飛介紹了波士頓動力公司發布的 Spot 機器狗新影片，展示了其整合 ChatGPT 後獲得的語言能力和互動性。
*   Spot 現在可以像導遊一樣，用英國口音與人對話，回答問題，並根據語音指令做出相應動作。

**Spot 的新功能：**

*   **語言能力：**
    *   歸功於 ChatGPT，Spot 不僅可以“說話”，還能模仿不同的個性，包括口音、語氣和表達方式。
    *   Spot 可以觀察環境並使用 VQA (視覺問答) 或字幕模型描述物體。
    *   結合文本轉語音技術，Spot 可以與人進行實時對話。
*   **互動性：**
    *   Spot 可以根據語音指令做出相應動作，例如說 "Follow me" 時自動轉身引路。
    *   當人們指著某個物體時，Spot 會抬頭看向該物體並進行解說。
*   **個性化：**
    *   通過修改 Spot 的代碼，可以改變其輸出，包括口音、句子組織和聲音音調，甚至轉頭方式。

**技術細節：**

*   **硬體：**
    *   安裝了揚聲器和環形陣列麥克風（Respeaker V2）用於音訊處理。
    *   實際控制權下放給機外電腦，通過 SDK 與 Spot 進行通信。
    *   配備機械臂和機械臂攝影機。
*   **軟體：**
    *   使用 OpenAI 的 ChatGPT API（gpt-3.5 和 gpt-4）進行對話生成。
    *   採用精心的提示工程，讓 ChatGPT 像編寫 Python 腳本一樣工作。
    *   結合 VQA 和語音轉文字軟體，讓 Spot 能夠理解視覺和聽覺信息。
    *   使用 ElevenLabs 進行文本轉語音，並採用並行流式傳輸以減少延遲。
*   **地圖與定位:**
    *   團隊為 Spot 導覽的建築環境建立 3D 地圖。
    *   為大語言模型注入位置資訊，讓 Spot 知道自己在建築物內的哪個位置(實驗室陽台、天橋、博物館陳列等等)

**大語言模型的應用和優勢：**

*   Spot 利用大語言模型的湧現行為，使其能夠執行既定訓練之外的任務。
*   大語言模型可以作為即興演員，根據大致腳本填補空白動作場景。
*   通過限制大語言模型的使用範圍，降低其可能產生的幻覺風險。

**實驗中的趣事：**

*   當詢問 Spot 波士頓動力執行董事是誰時，它會帶領人們到服務台詢問。
*   當詢問 Spot 的父母是誰時，它會走向 Spot V1 和 Big Dog 的展示區。

**未來展望：**

*   大飛認為大語言模型結合機器人的領域具有非常大的想像空間。
*   具身智能是 AI 最近非常火爆的一個方向。
*   人們對《西部世界》的到來充滿期待。

**總結：**

波士頓動力 Spot 機器狗整合 ChatGPT 後，在語言能力和互動性上取得了重大突破，為具身智能的發展提供了新的可能性。

**後記：**

歡迎大家在評論區留言，分享對於能說話交流的機器人狗子的應用想法。

---

**額外建議：**

*   **加上時間戳：** 如果影片中有重要的時間點，可以在整理後的文稿中加上時間戳，方便讀者快速定位。
*   **配上圖片：** 如果能加上一些截圖或照片，例如 Spot 的外觀、硬體配置、以及它與人互動的畫面，會讓文稿更生動。
*   **关键词：** 在文稿中，Spot, ChatGPT, 波士顿动力，机器人，人工智能，具身智能 等等，可以利用粗体，让读者更容易抓取。

希望這個整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>199. [2023-10-25] 【AIGC】DALL-E 3技术报告解读 | 文生图 | 指令遵循 | 图片标题合成 | CLIP | Latent Diffusion</summary><br>

<a href="https://www.youtube.com/watch?v=2QtOFC7Tgx4" target="_blank">
    <img src="https://img.youtube.com/vi/2QtOFC7Tgx4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】DALL-E 3技术报告解读 | 文生图 | 指令遵循 | 图片标题合成 | CLIP | Latent Diffusion

好的，我將盡力為您整理這篇文稿，使其更易於理解。我會著重於提取關鍵資訊、理清邏輯結構，並提供一些可能的改進建議。

**整理後的文稿：**

**核心觀點：**

DALL-E 3 的主要改進在於提高了提示遵循能力 (Prompt Following)，即生成的圖像與輸入文本提示的一致性。這主要歸功於 OpenAI 使用合成圖像標題來改善訓練數據集。

**整體架構：**

OpenAI 的技術報告分為兩部分：

1.  **如何通過合成訓練數據集中圖像的標題 (Caption)，來提升模型的生成能力。**
2.  **DALL-E 3 和其他文生圖模型的評測比較。**

**第一部分：合成圖像標題**

*   **問題：** 現有文生圖模型在文本理解能力上有缺陷，尤其是在複雜文本描述下，生成的圖像容易忽略部分信息，甚至無法生成符合文本描述的圖像。主要原因是訓練數據集的圖像標題不夠準確（過於簡單或不相關）。
*   **解決方案：** 訓練一個圖像標題生成器 (Image Captioner) 來合成圖像的標題。
    *   模型架構：Google 的 CoCa (類似 CLIP，但增加了一個多模態文本編碼器，可以生成標題)。
    *   微調：
        *   方案一：使用只描述圖像主體的短標題微調。
        *   方案二：使用詳細描述圖像內容的長標題微調。
*   **實驗分析：**
    *   比較了使用原始標題、合成短標題和合成長標題訓練的模型的性能（使用 CLIP 得分評估）。
    *   結果表明，使用合成長標題能顯著提升模型的提示遵循能力。
    *   實驗還找到了最佳的數據混合比例：5% 原始標題 + 95% 合成長標題。
*   **GPT-4 輔助：** 為了避免模型過擬合長標題，DALL-E 3 使用 GPT-4 來將用戶輸入的標題上採樣 (擴展) 為長標題，確保輸入數據與訓練數據的分布一致。

**第二部分：模型評測**

*   **DALL-E 3 的具體實現細節：**
    *   採用 95% 合成長標題 + 5% 原始標題混合訓練。
    *   使用一個更大的基於 T5-XXL 的 latent diffusion 模型 (可能是 SDXL 的擴展版本)。
    *   **細節提升：**
        *   分辨率提升：生成 1024x1024 以上的圖像，可能採用類似 SDXL 的遞進式訓練策略和多尺度訓練策略。
        *   細節提升：額外訓練了一個 latent decoder 來提升圖像的細節（尤其是文字和人臉），基於 DDPM 架構，並使用 Consistency Models 的蒸餾策略加速。
*   **評測方法：**
    *   **自動評測：** 使用 CLIP 得分、GPT-4V 和 T2I-CompBench (評測顏色、形狀、紋理綁定) 等指標。
    *   **人工評測：** 評測提示遵循、風格和一致性 (連貫性)。
*   **評測結果：** DALL-E 3 在各項評測中均優於 DALL-E 2 和 SDXL。
*   **DALL-E 3 的局限性：**
    *   在空間位置關係的處理上容易出錯。
    *   文字生成能力仍有提升空間 (多詞或少詞)。
    *   合成標題可能幻想圖像中的重要細節，導致模型在生成特定種類的東西時不完全可靠。
    *   安全性和偏見 (所有大模型都面臨的問題)。

**總結：**

DALL-E 3 的核心優勢在於使用了合成標題來構建高質量的訓練數據集，從而顯著提升了模型的提示遵循能力。雖然技術上沒有太大的創新，但數據質量的提升是關鍵。OpenAI 訓練了自己的圖像標題生成模型，並且使用GPT-4来优化用户输入。未来文生图模型的发展方向可能会侧重于优化标题来提升模型效果。

**可能的改进建议：**

*   **更清晰的結構:** 將文稿分割成更小的部分，每個部分有一個明確的標題，方便讀者快速定位到自己感興趣的內容。
*   **更明確的術語解釋:** 對於一些技術術語 (例如：latent diffusion model, CLIP, VAE, DDPM 等)，可以提供更簡單的解釋，或者提供外部連結供讀者參考。
*   **增加視覺化元素:** 加入一些圖表或示例圖片，可以幫助讀者更直觀地理解文稿的內容。

我希望這個整理後的文稿對您有所幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>198. [2023-10-23] 【思考】超线性回报 | 保罗·格雷厄姆最新长文 | 万字精华总结 | 如何获得超线性回报 | 指数增长 | 阈值  | 好奇心</summary><br>

<a href="https://www.youtube.com/watch?v=tgseAzI3fmg" target="_blank">
    <img src="https://img.youtube.com/vi/tgseAzI3fmg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【思考】超线性回报 | 保罗·格雷厄姆最新长文 | 万字精华总结 | 如何获得超线性回报 | 指数增长 | 阈值  | 好奇心

好的，這是整理後的文稿，我盡量保持原文的風格，並調整了結構，使其更清晰易讀。

**標題：保羅·格雷厄姆萬字長文解讀：如何獲得超線性回報**

**引言 (大飛)**

大家好，這裡是最佳拍檔，我是大飛。

之前我們介紹過保羅·格雷厄姆 (Paul Graham) 的文章《如何做出偉大的工作》。前兩天他又發表了一篇萬字長文，乾貨滿滿。文章提到，線性增長無法獲得超額回報，而超線性回報往往與「你的付出」不成正比。這讓我想起《10 倍比 2 倍簡單》這本書，書中提到 2 倍增長是線性的，需要更多努力、更辛勤地工作，而不是更聰明地工作；而 10 倍增長是非線性的，巨大的增長並不需要更多努力，往往只需要更少的努力，但要做到更好。

保羅在文章中還提到，現在的時代不同以往，不再需要加入知名組織、機構才能獲取所需資源、實現超額增長。現在有更多的人可以像 20 世紀的藝術家和作家一樣擁有自由。有很多雄心勃勃的項目不需要太多的初始資金。

此外，保羅還講到了如何尋找能夠獲得超線性回報的領域，以及什麼樣的人能夠獲得超線性回報，那就是尋找那些只有少數玩家勝過其他人的領域。如果在一個每個人表現都差不多的領域，不太可能存在超線性回報。在超線性領域，一開始你的成績肯定會微不足道，但是超線性回報的獎勵曲線上升速度會非常快，從專注於一小部分客戶開始，你將通過口碑傳播獲得指數級增長。同理，學習、科研、投資都是如此。

對我最有感觸的還是這句話：「不要把 work 等同於一份 job，要被好奇心驅使，而不是職業主義，要給予你的好奇心自由發揮，而不是只做你應該做的事情。」

以下是對原文的解讀 (有刪減)。

**保羅·格雷厄姆原文核心觀點：超線性回報的本質與獲取方式**

**1. 超線性回報是世界的特徵，而非人為規則**

*   傳統觀念認為回報是線性的，但現實並非如此。
*   在商業中，超線性績效回報是普遍存在的。
*   這種現象在名望、權力、軍事勝利、知識等方面也同樣適用。
*   理解超線性回報的概念，才能真正理解這個世界。

**2. 超線性回報的兩個基本原因：指數增長與閾值**

*   **指數增長：**
    *   類似於細菌培養，擅長培養的人與不擅長的人之間結果差異巨大。
    *   初創企業也存在指數增長，高增長率的公司往往變得非常有價值。
    *   Y Combinator 鼓勵創始人專注於增長率而不是絕對數字。
    *   隨著時間推移，績效的回報與績效的t次方成正比。
    *   儘管指數增長有實際限制（例如：土地面積），但總有方法突破（例如：征服）。

*   **閾值（臨界值）：**
    *   體現在「贏者通吃」的現象中，例如體育比賽。
    *   閾值的存在並非來自競爭本身，而來自結果中存在臨界點。
    *   即使沒有競爭，也可能存在閾值，例如證明一個定理或命中一個目標。

*   **超線性回報的結合：** 跨越閾值會導致指數增長，指數增長又會助你跨越閾值。
    *   例子：名氣（粉絲吸引粉絲的指數增長，以及普通人心智位置有限的閾值）。
    *   例子：學習（知識的指數增長，以及學會騎車、閱讀等知識閾值）。新的發現更是重要的閾值，會引導你進入一個全新的領域。

**3. 如何尋找具有超線性回報的情況**

*   **尋求能夠複合的工作：**
    *   直接複合：表現良好會使你在下一個週期中表現更好（例如：建設基礎設施、品牌營銷）。
    *   通過學習來複合：即使過程中表現不佳，但如果學到很多東西，仍然會獲得指數增長。
    *   不要過於優化學習內容，不要限制自己只學習已知有價值的東西。

*   **利用閾值，但要確保遊戲值得玩：** 如果指數增長足夠快，即使起初微不足道，它也會變得很大。 如果遇到一些平庸卻仍然受歡迎的事物，替換它可能是一個好主意。

*   **被好奇心驅使，而不是職業主義：** 讓好奇心自由發揮，而不是只做你應該做的事情。

**4. 超線性回報的機遇正在增長**

*   技術進步和組織重要性的下降，使得更多人可以像 20 世紀的藝術家和作家一樣擁有自由。
*   現在有更多雄心勃勃的項目不需要太多的初始資金。
*   也出現了新的學習、賺錢、找到同事和觸及觀眾的方式。
*   表現優異的人會表現得更好，但表現糟糕的人會變得更糟。

**5. 誰應該追求超線性回報？**

*   知道自己很優秀，知道在一個變化更大的世界裡會淨賺更多的人。
*   可以承擔風險去嘗試並找出答案的人，尤其是年輕人。

**6. 如何利用績效的超線性回報**

*   **做出傑出的工作：** 指數增長曲線的遠端競爭較少，且少有人嘗試。
*   對工作感興趣，僅僅勤奮是不夠的。
*   了解自己的興趣所在，找到適當的工作方法。
*   選擇適合你情況的工作。
*   培養專注的習慣。
*   努力工作，但不要過度勞累。
*   探索知識前沿的空隙，可能擴展成一個全新的領域。
*   承擔儘可能多的風險。
*   尋找最好的同事，培養良好的品味，向最好的榜樣學習。
*   誠實，尤其是對自己誠實。
*   鍛鍊身體，健康飲食和睡眠。
*   避免危險的藥物。
*   追隨你的好奇心，它比你更知道值得關注的事情。
*   運氣也很重要，解決辦法是多試幾次。

**7. 超線性回報意味著不平等**

*   回報曲線越陡峭，結果的變化就越大。
*   尋找少數大贏家勝過其他所有人的領域，例如體育、政治、藝術、音樂、表演、導演、寫作、數學、科學、創業和投資。
*   在這些領域中，你需要投入最初的努力，超線性回報一開始可能微不足道，但隨著發展，獎勵曲線會上升得非常陡峭。

**8.其他建議**
* 對最初的一小部分客戶付出極大的關注，通過口碑傳播啟動指數增長
* 記住“Do things that don't scale”這個原則

*   不要把 work 等同於一份 job。
*   在超限性回報的領域裡，好奇心比野心更重要。

**結語 (大飛)**

總之，保羅·格雷厄姆的文章強調了做自己真正感興趣的事情，全身心投入，才能帶來遠超你想像的回報。而要想做到這一點，就是傾聽自己的好奇心，讓它來帶領我們找到自己真正感興趣的事情。

希望這次的解讀對大家有一點點的啟發。我們下期視頻再見！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>197. [2023-10-16] 【人工智能】OpenAI科学家Hyung Won Chung演讲精华版 | 2023年的大模型 | 涌现 | Transformer | 并行训练 | 后训练阶段 | 奖励模型 | 目标函数学习</summary><br>

<a href="https://www.youtube.com/watch?v=q45PUg8U1e4" target="_blank">
    <img src="https://img.youtube.com/vi/q45PUg8U1e4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OpenAI科学家Hyung Won Chung演讲精华版 | 2023年的大模型 | 涌现 | Transformer | 并行训练 | 后训练阶段 | 奖励模型 | 目标函数学习

好的，我來整理這份文稿，使其更具結構性、重點更清晰，並移除口語化的部分。

**整理後的文稿：**

**主題：Hyung Won Chung（尚哥）「2023年的大型語言模型」演講分享**

**引言：**

*   介紹AI科學家Hyung Won Chung（簡稱尚哥），他近期從Google跳槽至OpenAI。
*   尚哥的演講涵蓋大語言模型的最新動向和技術細節，內容深入淺出，可與安德烈卡帕西的State of GPT演講齊名。
*   PaLM-2的聯合負責人評價尚哥擁有豐富的全棧大語言模型經驗。

**演講主題：「2023年的大型語言模型」**

*   **時間點的重要性：** 強調“2023年”，因為大型模型定義可能在未來幾年內發生變化，導致現有見解和結論過時。
*   **GPT-4的潛力：** 尚哥認為GPT-4即將超越拐點，性能將實現顯著跳躍，因此需要改變觀點，認識到大語言模型蘊藏的巨大潛力。

**核心觀點：規模效應**

1.  **湧現現象：**

    *   模型規模越大（參數數量、訓練數據大小、計算資源），就越可能發生湧現現象。
    *   小型模型在某些任務上進展緩慢，但當規模達到一定程度時，突然就能夠完成這些任務。
    *   即使當前一代的大語言模型還無法展現出某些能力，也不應輕言放棄，而應思考「它還沒行」的原因。
    *   推理思路應轉變為「一些方法只是在當前不起作用」，隨著模型規模擴大，許多結論都會改變。
    *   研究者應不斷更新、拋棄基於過時觀點的直覺。
    *   新研究者可以嘗試在以前模型上不起作用的想法，這些想法可能在新模型上突然有效。
    *   實驗過程中，應記錄失敗的過程，並在新的模型上再次運行實驗，不斷更新和糾正自我認知和理解。
2.  **不同能力與規模的關係：**

    *   以GPT-3和GPT-4為例，針對不同能力：
        *   “能力一”：GPT-4接近轉折點，可能出現躍進式改進。
        *   “能力二”：GPT-4仍有很大距離，目前方法可能無法提供實質性幫助。
        *   “能力三”：GPT-3已超越轉折點，研究可能只帶來漸進式改變。
    *   堅持這種思維框架，經常回顧和反思，更新直覺，就能明白正在解決哪種問題。
3.  **擴大參數規模的方法：**

    *   目前的大型語言模型都採用Transformer架構。
    *   將Transformer看做是一個包含一系列矩陣乘法的序列到序列的映射，進行數組的轉換。
    *   Transformer通過計算點積，使每個序列token都能與其他token進行交互。
    *   Transformer的規模擴大，就是讓很多機器高效地進行矩陣乘法，並減少機器之間的通信。
    *   通過將注意力機制拆分為單獨的頭、利用多台機器和芯片、使用GSPMD方法進行並行化，可以實現。

**訓練與優化：**

1.  **預訓練成本：**

    *   預訓練成本依然很高。
    *   縮放定律是基於小規模模型數據開發的，預測模型擴展損失非常重要。
    *   僅增大規模並不能解決所有問題。
2.  **模型訓練的四個階段：**

    *   預訓練階段
    *   指令微調（監督微調SFT）
    *   獎勵模型訓練
    *   策略模型訓練

3. **指令微調階段 (SFT):**
    * 為所有任務建立從自然語言指令到自然語言回應的映射.
    *  指令微調的核心思路是擴展到對話場景，模型可以與其他代理交互。
    * 增加更多任務雖可提高效能，但存在著邊際效益遞減的限制，任務的多樣性是關鍵。
    * 指令微調的目標函數是瓶頸，難以使用狹窄的信號訓練大型模型。

4.  **強化學習與RLHF (Reinforcement Learning from Human Feedback):**

    *   最大化預期的獎勵函數。
    *   使用獎勵模型來為更複雜的情況定義獎勵。
    *   通過人類比較兩個答案的優劣，讓模型學習人類偏好，而非直接告知最佳答案。
    *   比較比絕對評分更簡單，獎勵模型實際上是在用最大似然法來訓練。

5.  **策略模型 (Policy Model):**
    * 策略模型通常從監督指令微調的檢查點開始，生成一些補全，並提供給獎勵模型返回得分。
    *  透過策略梯度演算法迭代進行，在滿足 RM 模型條件下，讓策略模型通過強化學習來學習這些偏好。
    *  RLHF 實施困難，獎勵模型容易出錯，產生所謂的“獎勵黑客”問題 (模型為了得到更高獎勵產生沒意義的長答案)。
    *  RLHF 是一個有價值的研究方向，可以幫助我們克服最大似然的偏差。

**人工智能發展的演進：**

*   從基於規則的系統到深度學習，再到可學習的損失函數。
*   深度學習的成功在於採用了更弱的歸納偏差，並允許了更高的可擴展性。
*   下一個演進階段可能是讓損失函數也變得可學習。
*   GAN和RLHF是成功的例子，學習損失函數或目標函數將是下一個範式。

**總結：**

*   規模是關鍵，從規模的角度看問題至關重要。
*   學習損失函數或目標函數將是未來的發展方向。

**附註：**

*   省略了對Transformer和並行計算的詳細講解，可參考原視頻。

**這個版本更著重於組織信息，使其易於理解和查找，並去除了口語化的表達方式。** 這樣更適合作為文件整理的結果。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>196. [2023-10-05] 【商业】37Signals公司的37条Signal | 创业Startup | ShapeUp | Rework | Remote</summary><br>

<a href="https://www.youtube.com/watch?v=IaexGrt3wZ0" target="_blank">
    <img src="https://img.youtube.com/vi/IaexGrt3wZ0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】37Signals公司的37条Signal | 创业Startup | ShapeUp | Rework | Remote

好的，這是經過整理的文稿，我將其結構化、精簡重複內容，並著重於核心觀點：

**最佳拍檔 - 37signals 的 37 條想法分享**

大家好，我是大飛，歡迎來到最佳拍檔。

最近在 37signals 網站上看到他們的 37 條 "Signals"，覺得很有意思，想跟大家分享。

**關於 37signals 公司：**

這是我個人很喜歡的一家極客公司，從外包公司起家，靠著幾款小而美的產品積攢了口碑，估值不錯，也出版過《Rework重構》等書籍，是遠程辦公、敏捷開發的早期推動者。主要產品有 Basecamp 和 Hey，也是 Ruby On Rails 框架的開發者和維護者。

雖然 Ruby On Rails 框架曾經流行過，但我翻譯出版過相關書籍，但最終不敵國內流水線化的大潮，現在國內使用該框架的已經很少了。

接下來，我們一起來看看這 37 個想法，看看這家公司特立獨行的思考。雖然不一定能實踐，但有助於開拓眼界。

**37signals 的 37 條想法：**

1.  **獨立的義務：** 沒有投資者、沒有董事會，不考慮退出，保持獨立性，才能做想做的事，做其他公司不敢做的事。
2.  **工作不是戰爭：** 避免使用戰爭隱喻（征服市場、占領份額等），工作是和平的。
3.  **小團隊：** 小團隊可以幹大事，大團隊難做小事，小的力量，只做需要做的，無需過度浪費。
4.  **利潤驅動：** 收入 > 支出，每一年的經營都是盈利的，這是一種對客戶負責的方式。
5.  **行勝於言：** 立即行動，如果必要，就再做一次，大多數決策缺乏遠見。
6.  **ShapeUP 方法：** (略) 一個迭代，幫助軟體團隊每 6 週設計、開發和交付優秀的軟體，可以單獨介紹。
7.  **賣產品，不賣用戶：** 不出售客戶數據，不使用個人信息進行目標廣告投放，商業模式是賣產品，而不是賣用戶。
8.  **3 個 8：** 8 小時工作 + 8 小時生活 + 8 小時睡眠，睡眠不足是愚蠢的標誌。 (推薦馬修·沃克的《我們為什麼睡覺》)
9.  **拒絕實時：** 避免期望立即回應，認為緊迫性被高估，“盡快 ASAP”是一劑毒藥。
10. **财富500万强的公司：** 更關注像我們一樣的中小型公司。
11. **不要效仿辦公室：** 推崇遠程工作，減少會議，使用異步溝通，信任他人，反對辦公室及其所代表的一切。(相關書籍)
12. **時間是不一樣的：** 60 分鐘連續構成的一小時，質量比被切割成四個 15 分鐘的一小時高，不被打斷的時間，可以帶來更高質量工作
13. **重複：** 要讓其他人聽到新的、獨特的觀點，可能需要重複多年。
14. **開會的代價很昂貴：** 會議應該是最後的手段，衡量開會的成本，並加以權衡，是否可以用寫個文檔來代替？
15. **拒絕焦慮：** 不要讓自己精疲力竭，投入一天的工作後，就關上電腦，繼續生活。
16. **小心邊緣思維的陷阱：** 如果需要一台機器但沒買，最終會發現你付了錢，卻沒有得到它。
17. **避免政治活動：** 尊重政治表達和活動的權利，但避免在工作中、在內部溝通系統中進行政治辯論。
18. **客戶服務的兩枚硬幣：** 不要逼客戶拿起“這是世界末日”的那枚硬幣。
19. **向人員付費，而不是向地址付費：** 相同職位的每個人都應該獲得相同的報酬，無論他們住在哪里，或者他們是誰。
20. **小的科技進步：** 倡導小的科技進步，反對索取、窺探、瞄準、剝削、展現力量、踐踏。
21. **知道拒絕：** 說“不”表示拒絕一件事情，說“是”卻表示拒絕很多事情。
22. **長期創業：** 傾向於長期創業，長期並非是一種僥倖，激發員工的信心。
23. **長期計劃 vs. 短期計劃：** 長期計劃是你在思考的事情，短期計劃是你在想的事情。
24. **固化：** 確保事情在預定時間和預算內完成的方式：縮小範圍。
25. **不同意但是接受和投入：** 達成共識並非目標，正確的決定才是，一旦決定，全力投入和支持。
26. **直面挫折，不要浪費每一次的危機：** 逆境可以幫助你增強反脆弱性。
27. **全球化：** 付費客戶遍布 160 多個國家/地區，團隊遍布世界五大洲，讓世界觀、文化視角和社會政治觀多元化。
28. **目標：** 為設定目標時的我們，來設定目標。
29. **享受錯過而不是害怕錯過：** 寧願慶祝和享受錯過，生活會變得更好。
30. **溝通問題：** 公司沒有溝通問題，是人有溝通不暢的問題，組織或團隊越小，溝通不暢的可能性越少。
31. **容易？：** 不要假設你不熟悉、不常做的事情很容易。
32. **我們發明了 Ruby on Rails：** 是一個免費的開源框架，運行著 Shopify、Coinbase、GitHub、Airbnb 等等，Basecamp 是第一個 Rails 應用程式。
33. **計畫就是猜測：** 越長期的計畫，猜測的準確性越差，習慣用週來代替年，更頻繁的計畫。
34. **睡一覺再說：** 睡一覺再回來看，更能看清楚真相。
35. **公司不是家：** 好公司不會裝成是家，而是家的盟友，不會侵占員工的個人時間。
36. **上下文大於一致性：** 在設計方面，應該圍繞當前的情況進行設計，而不是非要跟之前的設計保持一致。
37. **我們名字中的彩蛋：** 37Signals 是因為人類不斷分析來自外太空的無線電波，寻找外星智慧生命，但仍然有 37 個信號無法解釋。

以上就是 37signals 的 37 個 Signal，感謝大家的觀看，下期再見！

**修改說明：**

*   **精簡語言：** 去除了口語化的語氣詞和重複的描述，使內容更簡潔。
*   **結構化呈現：** 將內容分為公司介紹和 37 條想法兩部分，並對想法進行編號，方便閱讀。
*   **歸納重點：** 將每條想法的重點提取出來，方便快速了解核心內容。
*   **刪除無關內容：** 刪除了一些與主題無關的細節。
*   **修正用词：** 润色部分语句，使其更符合中文语境。

希望這樣的整理對您有幫助！如果您需要更進一步的修改或調整，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>195. [2023-10-04] 【人工智能】Yann LeCun最新德国演讲 | 从机器学习到自主智能 | 自监督学习 | 世界模型 | JEPA</summary><br>

<a href="https://www.youtube.com/watch?v=E1T4l2UReiM" target="_blank">
    <img src="https://img.youtube.com/vi/E1T4l2UReiM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Yann LeCun最新德国演讲 | 从机器学习到自主智能 | 自监督学习 | 世界模型 | JEPA

好的，我將這篇文稿整理如下，更著重重點，並將口語化的語氣轉為更正式的書面語：

**文稿整理：楊立昆（Yann LeCun）「從機器學習到自主智能」演講重點**

**引言**

本次分享內容為深度學習三巨頭之一楊立昆於9月29日在德國的最新演講，主題為「從機器學習到自主智能」。演講旨在闡述楊立昆對AI發展的總體思想，深入淺出，通俗易懂。內容經過精華提煉，以求在最短時間內呈現智者的思考。

**演講核心內容**

楊立昆在此次演講中主要探討目標驅動的AI，旨在打造具有學習、記憶、推理、計畫和常識，且可操控和安全的AI系統。

*   **AI的益處：**
    *   交通：輔助駕駛、自動駕駛可減少碰撞。
    *   藝術：降低創作門檻。
    *   醫學：3D圖像識別技術用於檢測乳腺X光中的腫瘤，MRI數據採集速度提高。
    *   科學研究：神經科學家利用人工神經網路描述大腦工作原理，物理學家基於AI描述粒子碰撞等現象，並驗證暗物質等理論。
    *   環境保護：利用AI模擬化學實驗。
*   **自監督學習的重要性：**
    *   自監督學習無需標注數據或人工干預，即可訓練系統理解數據和世界，在自然語言處理（NLP）領域尤為成功。
    *   範例：BERT模型（透過預測被刪除的文字訓練）。
    *   Dino V2：Meta開發的基礎視覺模型，經過訓練後，能夠從圖像中提取特徵，執行分類、深度估計等任務。
    *   應用：預測樹木高度，估算碳消耗量；AlphaFold預測蛋白質結構；Seamless翻譯200多種語言。
    *   提升內容審核效率：Facebook仇恨言論自動刪除比例從20%提升至95%。
*   **對大語言模型的看法：**
    *   現有大語言模型（如Llama、Llama2）展現卓越性能，但仍存在嚴重錯誤，不真正理解世界，只是被訓練成生成最有可能的單詞序列。
    *   問題：事實錯誤、邏輯錯誤、輸出不一致、缺乏推理能力、缺乏常識。
    *   預測：未來將淘汰自迴歸大語言模型，因其有明顯缺陷。
*   **目標驅動的AI架構（楊立昆提出的解決方案）：**
    *   感知模組（Perception）：感知世界，建立對當前世界狀態的估計。
    *   世界模型（World Model）：預測一系列行動的結果。
    *   演員模組（Actor）：想像動作，並將動作輸入到世界模型。
    *   成本模組（Cost）：代表系統的目標和整體目的，驅動整個系統，衡量不舒適度。
    *   目標：找到一個成本最小化的行動序列，確保系統產生安全的行為。
    *   分層規劃：人類和動物日常活動的基本特徵，但目前機器尚無法自動學習和確定行動計畫的合適層次。
*   **未來的挑戰：**
    *   機器從影片中學習世界模型。
    *   使用聯合嵌入型預測架構（JEPA）在表徵空間中進行預測。
    *   解決學習效率問題（例如，讓機器像青少年一樣快速學會駕駛）。
    *   達成貓級別的人工智能。
*   **對AGI（通用人工智能）的看法：**
    *   AGI是多維的，目前僅為誤導性概念。
    *   機器最終將在所有領域超越人類智能，但這需要數十年時間。
    *   無需過度擔憂機器接管世界，因為AI的發展將從小規模、低智能的模型開始，並在受控環境中進行安全測試。
*   **開源的重要性：**
    *   AI系統應開源，並以眾包方式收集全球知識，避免被少數人控制。
    *   開源有助於發展和應用人工智能，讓人類變得更聰明。

**總結**

楊立昆的演講核心為自監督學習和世界模型，關鍵在於聯合嵌入式的可預測架構（JEPA）。成本模組的實現至關重要，決定了預測結果。然而，目前世界模型面臨工程化問題，需要形成大量的模型，並優化改進。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>194. [2023-10-03] 【人工智能】AI领域的第一性原理是什么 | 最小作用量原理 | 理解常识 | 因果关系</summary><br>

<a href="https://www.youtube.com/watch?v=jmCuzYBn-Sw" target="_blank">
    <img src="https://img.youtube.com/vi/jmCuzYBn-Sw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI领域的第一性原理是什么 | 最小作用量原理 | 理解常识 | 因果关系

好的，我已經閱讀並理解了您提供的文稿，並會按照專業文件整理員的方式進行整理。目標是讓文稿更清晰、更易於理解和使用。

**整理後的文稿如下：**

**標題：人工智能的第一性原理：郭平教授的觀點與最佳拍檔的解讀**

**引言：**

大家好，這裡是最佳拍檔，我是大飛。

今天想和大家分享一篇北京師範大學圖像處理研究中心主任郭平教授的文章。文章以“四個問題”為切入點，探討人工智能的第一性原理，並提出如何運用第一性原理思維解決人工智能缺乏基本常識的問題。郭平教授建議將最小作用量原理作為人工智能的第一性原理。

談到第一性原理，大家可能會想到埃隆·馬斯克。馬斯克曾表示，他成功的秘訣就是運用第一性原理思維，即從物理學的角度看待世界，層層剝開事物表象，直達本質，再從本質出發，向上構建。

今天我們就來探討一下AI領域的第一性原理應該是什麼。以下是大飛整理的文章核心內容，希望能對大家有所啟發。

**文章核心內容：**

**一、人工智能領域存在第一性原理嗎？**

*   **第一性原理的定義：** 亞里士多德將第一性原理表述為在每一個系統的探索中，都存在一個最基本的命題或假設，不能被省略、刪除或違反。
*   **歷史應用：** 第一性原理主要用於哲學、數學和理論物理。
    *   數學：公理（axioms），不能從系統內的任何其他公理中推導出來。
    *   理論物理：計算直接從物理定律建立，不經過經驗模型和擬合參數等假設（也稱為“從頭計算”，ab initio）。
    *   生物學：達爾文的“物競天擇、適者生存”理論。
*   **AI領域的爭議：** AI領域是否存在第一性原理存在爭議。
    *   **反對觀點：** 第一性原理需要在明確定義“智能”之後才有意義。目前對“智能”還沒有明確定義。
    *   **參考定義：**
        *   尼爾斯·約翰·尼爾遜教授（斯坦福大學）：AI是關於知識的學科，怎樣表示知識、怎樣獲得知識並使用知識的科學。
        *   帕特里克·溫斯頓教授（麻省理工學院）：AI就是研究如何使計算機去做過去只有人類能做的智能工作。
    *   **尼爾遜的觀點：** AI目前沒有通用理論，只是一些與工程目標相關的原理，智能是許多過程并行發生和相互作用的結果。AI應被視為一種技術或建立在實驗基礎上的學科。
*   **支持觀點：**
    *   李國傑院士：AI與計算機科學本質上是一門學科，AI系統是用計算機技術對信息加工和處理的系統，因此應該存在第一性原理。
    *   於劍教授：《機器學習：從公理到算法》實際上是將數學的第一性原理應用到了機器學習上。
    *   基於物理的AI：可以借用物理的第一性原理，將“從頭計算”應用到AI，或者將“最小作用量原理”作為廣義的第一性原理。

**二、為什麼是基於物理的人工智能？**

*   物理學是研究物質運動最一般規律和物質基本結構的學科，是自然科學的帶頭學科，其他學科的研究基礎都建立在物理學科之上。
*   哲學與物理關係緊密。
*   楊立昆認為，未來AI的研究需要一種新型的理論，從而構建一個可以實現的世界模型，而基於物理的AI可能是最有希望實現這個理論的方式。
*   對於AI缺乏常識的問題，基於物理的AI框架也可能會提供一種解決思路。
*   常識是與領域相關的，包括生活常識、基本勞作技能、基礎的自然科學常識等等。

**三、如何讓人工智能具有常識？**

*   楊立昆認為，AI要掌握常識，就需要搞清楚物理世界的運作方式並做出合理決定，必須能夠獲取大量的背景知識、了解世界的運行規律，進而做出準確的預測和計劃（歸納性思維）。
*   需要按照第一性原理去思考。
*   **嬰兒學習（baby learning）方法：** 模擬嬰兒自主學習，逐步獲取知識。
*   把常識限定到特定的領域，例如將掌握物理科學常識作為現階段的首要目標。
*   從基本物理原理出發，讓AI先掌握科學常識，從而學習推理。
*   基礎的自然科學常識背後的物理原理是有明確定義的，而且可以用數學公式描述的。
*   AAAI 2017的最佳論文《基於物理和領域知識的神经网络无标签监督》，就是基於萬有引力定律推算出枕頭的運動軌跡，利用網絡的輸出必須滿足物理定律的約束來訓練神经网络，從而實現了神经网络的無標籤監督學習。
*   基於第一性原理思維需要花费更多的精力，构建世界模型也可能需要更大的计算量。
*   物理学中的最小作用量原理可以看作是整个物理学的第一性原理，在热力学、流体力学、相对论、量子力学、粒子物理学和弦理论都有广泛的应用。從具有可操作性的角度考慮，應該將最小作用量原理作為AI的第一性原理。

**四、為什麼要用第一性原理以及如何應用第一性原理？**

*   哥白尼、牛頓、愛因斯坦、達爾文等科學巨匠都運用了第一性原理，本質是邏輯學中的演繹性思維。
*   第一性原理是超越因果律的第一因，且一定是抽象的，或許有助於解決AI無法解釋因果關係的問題。
*   **以第一性原理思维看GPT-3：**
    *   硬件：馮·諾伊曼體系結構，二進制，程序順序執行，AI芯片只是算法硬件化。
    *   软件：GPT-3采用了与GPT-2同样的Transformer架构，融合了一种稀疏自注意力机制。
    *   结论：在当前的架构下，GPT-3不會邁向AGI。
*   關於AI未來的辯論：
    *   陣營一：計算機必須先了解因果關係等事物，然後才能接近人類的智能。
    *   陣營二：AI的問題可以通過投入更多的数据和提高计算机的处理能力来解决（OpenAI）。
*   大多數AI學者（如Yoshua Bengio和杨立昆）屬於前一陣營，認為AGI是不可能創造出來的。
*   受物理规律的制约，深度学习框架的天花板很快就会来临，如果基础理论没有突破，就不可能发展成为硅基文明的AGI。
*   需要重新构建AI基础理论框架，才能够赋予AI常识，发展具有可解释性的AI。
*   張钹院士認為，在探索通往AGI的道路上，我們現在走得並不遠。
*   以第一性原理作为出发点，先让AI具有基于物理规律的科学常识，可能才是通往AGI的正确道路。

**總結：**

郭平教授將物理學中的最小作用量原理作為人工智能的第一性原理，並推導出現有的GPT模型不會走向AGI，更傾向於楊立昆的世界模型理論。這個觀點有一定道理，但理論和實際有非常大的差異。Transformer架構是對知識的一種壓縮，大力出奇跡可能反而是一種更直接有效的手段。

關於什么是AI的第一性原理，每個人可能有自己的理解，短時間內業界也不會有共識。有人從物理學的角度，有人從數學的角度。

**互動：**

大家覺得AI的第一性原理是什麼呢？歡迎在評論區留言。

**結語：**

感謝大家的觀看，我們下期再見！

**整理說明：**

*   **結構化：** 將文稿分為引言、文章核心內容、總結和互動部分，使整體結構更清晰。
*   **分點闡述：** 使用分點、分段的方式，讓重點更突出，方便閱讀。
*   **專業術語保留：** 對於專業術語，如“第一性原理”、“最小作用量原理”、“AGI”、“馮·諾伊曼體系結構”、“Transformer架構”等，均保留原文，以確保信息的準確性。
*   **添加解釋：** 對於一些重要的概念，如“第一性原理的定義”，增加了更詳細的解釋。
*   **潤飾語言：** 對於一些口語化的表達，進行了適當的潤飾，使語言更流暢、更正式。
*   **整理互動環節：** 保留了結尾的互動環節，鼓勵讀者參與討論。

希望以上整理後的文稿對您有所幫助! 讓內容更便於理解和分享。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>193. [2023-09-26] 【OpenAI】Sam Altman和OpenAI究竟想要什么？硅谷著名科技记者Steven Levy深度采访 | 起源 | 转折 | 发展 | 终极目标</summary><br>

<a href="https://www.youtube.com/watch?v=QAyUNgsjj_M" target="_blank">
    <img src="https://img.youtube.com/vi/QAyUNgsjj_M/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】Sam Altman和OpenAI究竟想要什么？硅谷著名科技记者Steven Levy深度采访 | 起源 | 转折 | 发展 | 终极目标

好的，我將上述文稿整理如下，更著重於結構清晰和重點提取：

**主題： OpenAI 和 Sam Altman 的故事**

**主要來源：** 硅谷著名科技記者 Steven Levy 在《連線》雜誌上發表的長文 (約2萬字)，該文記錄了自2015年以來與 OpenAI 團隊的頻繁溝通和採訪。

**核心觀點：** OpenAI 的終極目標是 "Change everything"，即改變一切，他們致力於建立通用人工智能 (AGI)。

**一、 Sam Altman 的崛起與 OpenAI 的願景：**

*   **Altman 的影響力：** 在 GPT-4 發布後，Altman 成為科技界的搖滾明星，他的言論被視為神諭。
*   **OpenAI 的目標：** ChatGPT 和 GPT-4 只是 AGI 的墊腳石。 OpenAI 員工對建立 AGI 比確保其安全更感興趣。 他們相信 AI 的發展將超越生物學的極限。
*   **安全措施：** OpenAI 甚至在財務文件中規定了應急退出措施，以防止 AI 毀滅經濟體系。
*   **信仰：** OpenAI 的員工如同信徒，堅信 AGI 的到來。

**二、 Altman 的早年經歷與轉變：**

*   **科幻迷：** Altman 熱愛科幻小說和《星球大戰》，對計算機和超越人類的能力著迷。
*   **創業：** Altman 從斯坦福大學退學後創辦 Loopt，並接替 Paul Graham 成為 Y Combinator 的負責人。
*   **願景：** Altman 認為 Y Combinator 不僅是創業平台，更應為物種層面的變革提供資金。
*   **轉向 AI：** AI 的春天到來，Altman 相信 AGI 觸手可及，並決心領導一家改變人類的公司。

**三、 OpenAI 的創立與早期挑戰：**

*   **創始團隊：** Altman 與 Elon Musk 等人合作，秘密招募 Greg Brockman、Andrej Karpathy、Ilya Sutskever 等人才。
*   **Ilya Sutskever：** Sutskever 是 Geoffrey Hinton 的門徒，具有驚人的天賦，被 Altman 視為 OpenAI 的靈魂人物和研究的推動力。
*   **開源理念：** OpenAI 最初旨在通過與世界共享，讓 AI 變得安全易用。
*   **早期困境：** OpenAI 研究人員在缺乏頭緒的情況下進行研究，連 Altman 自己都說不知道該怎麼做。

**四、 關鍵突破與 GPT 的誕生：**

*   **Alec Radford：** Radford 在 OpenAI 進行實驗，並利用 20 億條 Reddit 評論訓練語言模型。
*   **無監督情緒神經元：** Radford 的模型能夠確定評論的情感，這是一個意外的突破。
*   **Transformer 架構：** Sutskever 認為 Transformer 非常強大，Radford 嘗試使用 Transformer 架構，並在兩週內取得巨大進展。
*   **Big Transformer：** Radford 提出在超大規模數據集上訓練模型的想法。
*   **GPT-1：** Radford 創建了 GPT-1，含有 1.17 億參數，在理解語言和產生答案等方面超越以往的人工智能。

**五、 OpenAI 的轉型與挑戰：**

*   **GPT-2 的危險性：** Radford 意識到自己做出了科幻小說裡的機器，擔心壞人會利用這項技術。
*   **與馬斯克的決裂：** 馬斯克想要擁有 OpenAI 並拒絕 Altman 的要求，憤然退出董事會。
*   **盈利模式：** OpenAI 創建了盈利性實體，同時設定上限，確保實現技術革命的終極使命。
*   **微軟的投資：** 微软投資 130 億美元，獲得將 OpenAI 技術商業化的獨家許可。
*   **內外壓力：** OpenAI 面臨在每個產品週期內實現革命、滿足投資人需求、與科技巨頭競爭以及肩負起守護人類使命的壓力。
*   **人員流失：** Dario Amodei 等關鍵人物離職，創辦競對公司 Anthropic。

**六、 ChatGPT 的推出與迭代部署：**

*   **戰略考量：** Altman 認為要讓大眾階梯式地適應人工智能，因此先推出基於 GPT-3.5 的 ChatGPT。
*   **安全考量：** Sutskever 認為不應將更強大的智能體藏在地下室裡，而應讓大眾逐步適應。
*   **社會影響：** OpenAI 將自己置於討論的中心，應對失業、信息錯誤、人類滅絕等潛在弊端。
*   **與政府合作：** Altman 與國會議員積極溝通，就如何監管 AI 進行交流。

**七、 OpenAI 的未來：**

*   **重點方向：** 產品本身、商業化公司、與微軟的關係、開發者生態系統、應用商店、AGI 的研究和投資。
*   **合作：** 與美聯社和 Shutterstock 等機構合作，為 OpenAI 的模型提供內容。
*   **轉變：** OpenAI 從一個科學目標的新穎努力，轉變為一個影響我們日常生活的大科技公司。

**結語：** OpenAI 的發展迅速，但未來仍面臨諸多挑戰。 這群 AGI 的信徒們，是否會成為人類進化的新起點，還是會帶來更大的社會風險，還需要時間來驗證。

**改善方向：**

*   **精簡語言：** 去除過多的口語化表達，使文本更加正式和專業。
*   **使用更明確的標題和子標題：** 幫助讀者快速理解文章的結構和重點。
*   **使用項目符號或編號：** 組織信息，使之更易於閱讀。
*   **添加關鍵詞：** 方便檢索和引用。

我希望能滿足您的需求。 如果您需要進一步的修改或調整，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>192. [2023-09-25] 【闲聊】EUV光刻机要实现技术突破了？| 制造芯片为什么需要光刻机 | 生产光刻机究竟有多难 | SSMB的由来 | 实事求是才是科学发展的道路</summary><br>

<a href="https://www.youtube.com/watch?v=w5JIIVPao-I" target="_blank">
    <img src="https://img.youtube.com/vi/w5JIIVPao-I/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【闲聊】EUV光刻机要实现技术突破了？| 制造芯片为什么需要光刻机 | 生产光刻机究竟有多难 | SSMB的由来 | 实事求是才是科学发展的道路

好的，我來幫您整理這份文稿，使其更易於閱讀和理解。我會將其分段，提煉重點，並適當調整語氣，使其更偏向書面風格。

**整理後文稿：**

**主題：中國「光刻廠」傳聞解析：獨立自主研發光刻機的可能性**

大家好，我是最佳拍檔的大飛。最近，國內網路上瘋傳一則科技新聞，聲稱中國科學家發現了一種新的極深紫外光源產生原理，可應用於28nm、14nm、7nm、5nm等多種芯片製程，有望取代ASML的EUV光刻機，突破光刻機的技術封鎖。甚至有傳言說，中國已在雄安建設光刻工廠，並附帶「有圖有真相」的佐證。今天，我們就來深入探討此事，以及剖析光刻機研發的難度，並分析中國是否有可能完全獨立自主地研發出最先進的光刻機。

**一、芯片製造基礎常識**

首先，我們需要了解一些芯片製造產業的基本知識。芯片的製作，是將四價矽摻雜少量三價硼和五價磷，形成PN結，再配合金屬氧化物控制閘，製成晶體管。然後，將海量晶體管密集排列，並按照特定設計互相連接，即構成芯片。

晶圓加工是芯片製造的關鍵步驟。在FAB工廠中，於高純度的矽晶圓（wafer）上，製造出一個個相同的裸芯片（die）。值得注意的是，工業應用上的芯片產量是極其龐大的，以華為Mate 60 Pro的芯片為例，業界估計需求量達數千萬顆。

為了能在短時間內製造出如此大量的芯片，關鍵在於一片晶圓上能夠一次性製造出大量完全相同的裸芯片。以12英寸晶圓為例，其面積約為70659平方毫米。先進芯片的晶體管密度驚人，可達每平方毫米1億個。假設一個裸芯片的面積為140平方毫米，一片晶圓上就能容納約500個裸芯片的位置。

芯片製造存在「良率」的概念，即功能合格的芯片所佔的比例。假設一片晶圓上的500個芯片，經過測試後有400個功能合格，則良率為80%。先進芯片加工的良率雖不一定高，但也不會太低，否則不具備商業價值。以50%的良率估算，一片晶圓至少也能產出200個以上可用的裸芯片。

FAB工廠的產能通常以每月能加工多少萬片晶圓來衡量，多的可達每月10萬片，少的也有1萬片。若每月加工1萬片晶圓，每片晶圓產出200個良品芯片，則每月可生產200萬顆芯片，一年可生產2000萬顆以上。

**二、光刻機在芯片製造中的作用**

許多人誤以為芯片製造全靠光刻機，將其視為核心設備，以為只要將晶圓送入光刻機，就能直接「刻」出芯片。甚至有人認為，購置100台光刻機就能建立100條芯片生產線。

事實上，芯片上的晶體管是通過「蝕刻」製成的，即利用等離子體物理衝擊或化學藥水浸泡等方式，在晶圓上製造出溝槽。而光刻則是用於引導蝕刻的位置，可以說，所有蝕刻步驟都必須先經過光刻。通過「掩膜板」（mask或光罩），告知蝕刻工藝應在何處下手。

晶圓加工的步驟極為複雜，可能多達上千步，光刻也需要反覆進行多次。一般來說，需要多台光刻機，重要步驟使用精度高的光刻機，精度要求較低的步驟則可使用低配光刻機。一片晶圓從開始加工到最終交付客戶，可能需要數月的時間，因為生產線上的機器並非只生產一種芯片，而是會排程加工其他晶圓。如何安排不同芯片的晶圓在指定時間送達指定機器，是FAB生產流程管理的重要課題。即使全力加速單一芯片的加工流程，工序繁多的情況下，一片晶圓也需要一到兩個月才能完成。

因此，客戶向FAB下單加工芯片，並非立即就能取得產品，即使追加訂單，也需要數個月的時間才能交貨。儘管如此，數個月就能生產出上千萬顆芯片，顯示了龐大的加工能力。只有量產，才能降低單顆芯片的成本。所以，FAB的生產能力是芯片工業應用的關鍵。

FAB工廠每月至少需要處理1萬片晶圓，而且光刻機處理一片晶圓往往需要多次曝光。因此，即使只生產一種芯片產品，每月僅生產1萬片晶圓，一台光刻機可能也需要進行10萬次光刻。FAB工廠需要排班運作，甚至週末也不停機。以每月30天計算，光刻機每天可能需要光刻3000次，平均每小時光刻100次是常見的節奏。從工業生產的角度粗略估算，光刻機需要在1分鐘內光刻完一片晶圓上的數百個裸芯片，每個芯片分到的光刻時間只有0.1秒。

若光刻速度無法跟上，就必須增加光刻機並行處理。光刻機是目前人類有能力製造的最精密和複雜的機器之一。

**三、光刻機的組成與技術難點**

一台光刻機由三大關鍵部分組成：光源、光學系統、蝕刻工作台。每個部分都面臨著登月般的技術挑戰。

*   **光源：** 產生13.5奈米波長的極深紫外光，目前的方法是用高功率激光轟擊直徑僅三千萬分之一米的小錫球。要持續穩定產生這種紫外光，需要以每秒約5萬次的頻率轟擊小錫球。這種激光器只有德國通快公司能夠生產，且耗時十年研發。更甚者，通快公司的激光器也依賴於立陶宛公司提供的關鍵設備。
*   **光學系統：** 將極深紫外光收集起來，形成一束激光。全球僅有德國蔡司公司能夠製造EUV光學系統。為了製作出絕對光滑平整的鏡片，鏡片的起伏誤差需控制在一個原子大小的範圍內，接近理論上的物理極限。這套光學系統必須在真空中工作，避免任何干擾。
*   **蝕刻工作台：** 在指甲蓋大小的矽片上刻出數百億個晶體管。這需要精度極高的控制台，由55000個高精度零件構成，且依賴於日本、韓國、中國台灣、美國、德國和荷蘭提供的專利技術。

光刻台的工作原理是，晶圓放置在工作台上，工作台在磁懸浮系統操控下不停游動。這實際上是「步進掃描」，工作台按照自動程序走走停停，停下來的瞬間進行光刻，將光罩上的圖案投射到裸芯片的區域。由於工作台走走停停的加速度非常大，對工作台運動控制和定位的精準度要求極高，這也是光刻機製造的核心難點之一。阿斯麥的光刻機型號有TWINSCAN，表示其具有兩個工作台，一個進行步進掃描光刻，另一個則進行「預對準」。

**四、EUV光刻機的研發歷程**

1997年，英特爾公司和美國能源部共同投資一家公司，開始研發EUV光刻機。經過六年時間，該公司研發了絕大部分的核心專利技術。然而，英特爾和美國能源部並未打算自行製造光刻機，而是將核心技術授權給荷蘭的阿斯麥公司。

在三星和台積電等公司的幫助下，阿斯麥終於在2010年生產出第一台EUV光刻機的原型機，經過測試、優化和升級，最終在2019年推出第一台可正式投入商業生產的EUV光刻機，總共歷時22年。

雖然EUV光刻機由荷蘭的阿斯麥公司生產，但它實際上只是一個組裝廠，僅有15%的零件自主生產，其餘85%的零件需要進口。由於美國能源部擁有光刻機幾乎所有的核心專利，因此阿斯麥生產光刻機需要美國能源部的授權。這也是美國政府能夠限制阿斯麥向中國出口光刻機的原因。

可以說，一台EUV光刻機的生產，涉及七、八個國家的合作。

**五、中國獨立研發光刻機的挑戰與希望**

中國想要突破技術封鎖，獨立生產光刻機，需要在光源、光學系統、蝕刻工作台三大關鍵部分實現完全的自主創新。目前，在光源部分，我們看到了一絲希望，這與趙午提出的「穩態微聚束」（SSMB）原理有關。

2010年，趙午與他的博士生一起，提出了利用巨大的粒子加速器來產生極深紫外光的新原理，即SSMB。2017年，清華大學唐傳祥教授團隊與德國同行合作，完成了實驗的理論分析和物理設計，並進行了一定的原理驗證。2021年2月，他們的論文在《自然》雜誌上成功發表。

然而，我們距離實現生產極深紫外光刻機的目標，仍然十分遙遠，千萬不能過於樂觀。清華大學已於2021年向國家發改委申報將SSMB實驗裝置列為十四五國家重大科技基礎設施，但目前仍處於科研階段。即使明年能夠立項，這種等級的科研裝置也需要至少5年才能建成，建成後還需要數年時間進行測試。

即便我們樂觀地估計，花費5年時間建成實驗裝置，再花3年時間測試成功，然後再花5年建成可以商用的光源，這也需要13年時間。更重要的是，光刻機的另外兩個關鍵部分，目前連影子都還沒有。而且，我們也無法確定13年後，美國和荷蘭是否又研發出了更先進的下一代光刻機。

此外，SSMB本身也存在許多難點問題需要解決。例如微聚束在儲存環中產生與維持的問題，以及SSMB相干輻射發光的問題，這些都需要後續的研究。

**六、結論**

在20年內，世界上不可能有任何一個國家能夠完全獨立自主地製造出一台代表國際最先進水平的光刻機，美國也不例外。我之所以提出這個觀點，是因為我不希望過去大躍進式的悲劇再次重演。

中國人很聰明，但並不意味著我們是特殊材料製成。只有實事求是，才是發展科學技術的正道。光刻機這樣超級精密複雜的機器，只有尋求最大範圍的國際合作，才是最佳的解決方案。

感謝大家的觀看，我們下期再見。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>191. [2023-09-24] 【人工智能】生成式AI拉开第二幕 | 红杉资本美国最新撰文 | 对生成式AI的反思 | 当下AI创业的方向</summary><br>

<a href="https://www.youtube.com/watch?v=4Gaf-NBZnoU" target="_blank">
    <img src="https://img.youtube.com/vi/4Gaf-NBZnoU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】生成式AI拉开第二幕 | 红杉资本美国最新撰文 | 对生成式AI的反思 | 当下AI创业的方向

好的，以下是经过整理的文稿，重点在于提炼核心信息，使其更易于理解和查找。

**主题：红杉美国《Generative AI’s Act Two》文章核心内容分享**

**核心观点：**

*   生成式 AI 正处于“尴尬的青春期”，潜力巨大，但尚未解决价值问题。
*   红杉资本对过去一年生成式 AI 领域的投资逻辑进行复盘，总结经验教训，并揭示未来投资方向。
*   文章提供 AI 应用创业指南，包括技术栈选择、产品形态设计以及需要解决的问题。
*   生成式 AI 市场正从技术驱动的“第一幕”转向客户驱动的“第二幕”，需要端到端地解决人类问题。
*   现有许多AI公司没有PMF（产品市场契合度）或者可持续的竞争优势，整个生态系统的繁荣不可持续。

**红杉资本对生成式 AI 市场机会和发展的预测（错误与正确）：**

*   **预测错误：**
    1.  发展速度过快：原本预计需要十年才能达到的技术水平，在一年内就已实现。
    2.  瓶颈在供应端：最终用户需求超过 GPU 供应。
    3.  垂直分离未发生：应用层公司和基础模型提供商之间未实现干净利落地分离，用户端的成功应用一直垂直整合。
    4.  竞争残酷：竞争激烈程度超出预期，既得利益者反应迅速，加剧竞争。
    5.  壁垒在客户中，而不是在数据中：应用生成的数据并未建立无法逾越的壁垒，工作流和用户网络正在创造更持久的竞争优势来源。
*   **预测正确：**
    1.  生成式 AI 是一回事：每个开发者都在研究，企业买家都需要，市场认可“生成式 AI”的名字。
    2.  第一个杀手级应用已经出现：ChatGPT 迅速达到 1 亿月活用户。
    3.  开发者是关键因素：开发者创造了无法想象的使用案例。
    4.  形态正在发展：AI 应用从自动完成和草稿形式变得越来越复杂，从个体生产力向系统级的生产力发展，从以人类主导向以执行主导的代理系统发展。
    5.  版权、伦理和存在的恐惧：相关辩论如火如荼。

**生成式 AI 面临的问题：**

*   **价值问题：**缺乏持久的用户留存和参与度。用户尚未在 AI 产品中找到足够每日使用的价值。
*   **解决方法：**
    *   解决用户留存问题。
    *   为客户创造足够的价值深度，增加粘性。
    *   将 Demo 演示变成完整的产品体验。

**模型开发栈的新内容：**

1.  新兴的推理技术（链状思维、树状思维和反思）提高模型执行更复杂推理任务的能力。
2.  迁移学习技术（RLHF 和微调）变得更容易使用，开发者可以对开源模型进行更有效的微调。
3.  增强检索生成 RAG 技术引入上下文，减少幻觉，增加真实性和实用性。
4.  新的开发者工具和应用框架帮助创建可重用的构建块，评估、改进和监控生产中的AI模型的性能。
5.  基础设施公司解构公共云，为 AI 公司提供大量 GPU、成本合理、按需可用、高度可扩展以及良好的 PaaS 使用体验。

**新的产品蓝图：**

1.  **生成式界面：** 基于文本对话，逐渐加入其他形态。
2.  **新的编辑体验：** 从 Copilot 到导演模式，创造像相机一样的编辑体验。
3.  **复杂的代理系统：** 逐渐拥有更多自主解决问题的能力和权力，端到端地解决问题。
4.  **系统范围的优化：** 通过自主解决问题，让整个系统变得更加有效。

**总结：**

*   生成式 AI 市场正在从炒作和演示转向真正的价值和完整的产品体验。
*   只有最终赢得客户留存，为客户创造长期深刻价值的应用才会存活下来。
*   关注解决用户根本需求的应用。

**个人建议:**

可以考虑将文章中的关键技术点，如 "链状思维"、"迁移学习"、"RAG技术" 等，做更详细的解释说明，以便更深入的了解AI 的发展方向。

希望这个整理对您有所帮助！如果您需要进一步的提炼或者润色，请随时告诉我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>190. [2023-09-18] 【人工智能】万字综述大语言模型代理 Agent | 研究背景 | 通用框架 | 控制、感知、行动 | 应用场景 | 代理社会 | 前瞻问题</summary><br>

<a href="https://www.youtube.com/watch?v=sxeNBsxPmf0" target="_blank">
    <img src="https://img.youtube.com/vi/sxeNBsxPmf0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】万字综述大语言模型代理 Agent | 研究背景 | 通用框架 | 控制、感知、行动 | 应用场景 | 代理社会 | 前瞻问题

好的，我幫你整理這篇文稿，使其更清晰、更易於理解：

**標題：大模型 Agent 綜述論文核心要點分享（復旦大學自然語言處理團隊論文解讀）**

**開場白：**

*   大家好，這裡是最佳拍檔，我是大飛。
*   最近很多網友想了解 Agent 相關內容，這確實是個熱門話題。
*   之前我們頻道做過 OpenAI 安全系統負責人 Lilian Weng 對 Agent 的看法，可以回顧一下。
*   今天我來分享復旦大學自然語言處理團隊關於大模型 Agent 的一篇綜述論文核心要點。這篇論文長達 86 頁，有 600 多篇參考文獻，全面梳理了基於大型語言模型的智能代理現狀。希望能幫助大家更深入地理解 Agent。

**論文要點：**

1.  **研究背景：**
    *   從哲學家德尼·狄德羅的智慧鸚鵡概念（能回答所有問題就有思想）談起，隱喻高度智能的有機體可能存在類似人類的智能。
    *   艾倫·圖靈將「智能」概念擴展到人工實體，即 Agent。
    *   「代理」概念起源於哲學，指擁有慾望、信念、意圖和行動能力的實體。在人工智能領域，指的是具有自主性、反應性、積極性和社交能力特征的智能实体。
    *   Agent 的中文譯名尚未統一，有智能體、行為體、代理或智能代理等多種翻譯。
    *   Agent 設計一直是人工智能領域的焦點，過去側重增強代理的特定能力（如符號推理、特定技能掌握），忽略了模型固有的通用能力發展（如知識記憶、長期規劃、有效泛化和高效互動）。
    *   大語言模型的出現為智能代理的發展帶來希望，增強模型的固有能力是關鍵。

2.  **NLP 到 AGI 的發展路線（五個級別）：**
    *   語料庫
    *   互聯網 (目前大語言模型階段)
    *   感知
    *   具身
    *   社會屬性

    如果赋予代理感知空间和行动空间的能力，它们将有可能达到第三、第四级。再进一步地，如果多个代理通过它们之间的互动、合作解决掉更复杂的任务，或者反映出现实世界的社会行为，那么代理有潜力来到第五级，即代理社会。

3.  **智能代理通用框架（受達爾文「適者生存」啟發）：**
    *   **控制端（Brain）：** 由大語言模型構成，儲存記憶和知識，負責信息處理、決策，呈現推理和計劃過程，應對未知任務，反映泛化性和遷移性。能力包括：
        *   自然語言交互
        *   知識 (常识知识和专业技能知识)
        *   記憶（過往的觀察、思考和行動序列）
        *   推理和規劃 (Reasoning 和 Planning)
        *   遷移性和泛化性
    *   **感知端（Perception）：** 將智能代理的感知空間從純文本拓展到包括文本、視覺和聽覺等多模態領域。
        *   文本输入
        *   視覺輸入
        *   聽覺輸入
        *   未来可配备更丰富的感知模块（例如触觉、嗅觉等器官)
    *   **行動端（Action）：** 除了常規的文本輸出，還可以賦予代理具身能力、使用工具的能力，適應環境變化，與環境交互，甚至塑造、影響環境。
        *   文本输出
        *   工具使用 (計算器、搜索引擎、語音生成、圖像生成等)
        *   具身行動 (Observation, Manipulation, Navigation)

4.  **Agent 的具體應用場景：**
    *   **設計原則：**
        *   幫助用戶從日常任務重複的勞動中解脫出來，减轻人类的工作压力，提高解决任务的效率。
        *   不再需要用戶提出顯式的低級指令，就可以完成自主的分析規劃解決問題。
        *   在解放用户的双手以后，尝试解放大脑，也就是在前沿的科学领域充分的发挥潜能，完成创新性的探索性的工作。
    *   **應用範式：**
        *   **單代理：** 接受人類的自然語言命令，執行日常任務，有現實使用價值。
            *   任務導向 (模拟网络环境和模拟生活场景)
            *   創新導向 (化学、材料计算机等领域)
            *   生命週期導向 (游戏我的世界)
        *   **多代理：** 代理們如何有效協調和協作解決問題。
            *   合作型互動（無序合作、有序合作）
            *   對抗性互動 (竞争谈判辩论)
        *   **人機交互：** 智能代理通過與人類的交互合作完成任務。
            *   指導者執行者模式
            *   平等合作模式

5.  **Agent 社會：**
    *   模擬社會定義：環境 + 環境中生存互動的個體。
    *   兩個關鍵部分：
        *   **代理：** 內化行為（計劃、推理、反思）、人格特征（認知、情感、性格）。
        *   **環境：** 虛擬沙盒遊戲、真實物理世界，包括人類參與者和各類可用資源。
    *   分析 Agent 在社會中的表現：
        *   **外在社會行為：** 個體行為（輸入、輸出、內化行為）、群體行為（合作、衝突、從眾）。
        *   **內在人格：** 認知能力、情感能力、性格分析。
    *   環境類型：
        *   基於文本的環境
        *   虚拟沙盒环境
        *   真实的物理环境
    *   模擬社會應具有：開放性、持久性、情境性和組織性。
    *   模擬社會的意義：探索群體智能的能力邊界、加速社會科學研究。
    *   模擬社會的風險：有害的社會現象、刻板印象和偏見、隱私安全問題、過度依賴與成癮性。

6.  **前瞻性問題：**
    *   智能代理與大語言模型的研究應該如何互相促進共同發展？
    *   智能代理會帶來哪些挑戰與隱憂？
    *   隨著代理數量的不斷提升，會帶來哪些機遇和挑戰？
    *   Agent 是否是通向 AGI 道路的鑰匙？

**總結：**

*   大語言模型建立了社會底層的通識共識和不斷學習理解的能力。
*   Agent 擁有不同的認知和能力，像人類個體。
*   Agent 社會是否會像人類社會一樣出現各種問題？
*   未來會出現惡意的 Agent 和針對 Agent 的病毒？
*   Agent 的能力大小不一，價值如何定義？
*   短期來看，Agent 仍會被限制在特定範圍內。
*   個人對 Agent 的未來持謹慎態度，因為我們還沒做好面對大規模 Agent 和 Agent 社會的準備。

**結尾：**

*   以上是個人看法，難免偏頗，歡迎大家在評論區發表看法。
*   感謝觀看，下期再見！

**總結說明:**

*   **標題化：** 我將內容分拆成更小的段落，並添加了標題，方便快速閱讀。
*   **層次化：** 使用編號和項目符號整理資訊，使資訊更容易瀏覽。
*   **簡化語言：** 刪除了一些口語化的表達，使內容更精煉。
*   **重點突出：** 對於關鍵概念和觀點進行強調。

希望這樣的整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>189. [2023-09-15] 【科学】2023搞笑诺贝尔奖公布 | Ig Nobel Prizes | 那些最意想不到的科学研究</summary><br>

<a href="https://www.youtube.com/watch?v=24taNsvS2Ac" target="_blank">
    <img src="https://img.youtube.com/vi/24taNsvS2Ac/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【科学】2023搞笑诺贝尔奖公布 | Ig Nobel Prizes | 那些最意想不到的科学研究

好的，以下是用更專業、更清晰的方式整理後的文稿。我會將內容分點歸納，並加入一些潤飾，使其更易於閱讀和理解。

**2023年搞笑諾貝爾獎揭曉：一窺科學家的奇異研究**

**開場白**

大家好，這裡是最佳拍檔，我是大飛。今天和大家聊聊輕鬆話題，一起來看看2023年搞笑諾貝爾獎的獲獎研究。

**搞笑諾貝爾獎簡介**

*   搞笑諾貝爾獎雖是模仿諾貝爾獎，但獲獎者確為科學家。
*   研究乍看荒誕搞笑，實則引人深思。
*   部分搞笑諾貝爾獎得主日後也獲得了真正的諾貝爾獎。
*   獎勵：十萬億津巴布韋幣、諾貝爾獎得主簽名證書、可摺疊成空盒子的紙（內含12罐小可樂）。

**獲獎研究詳解**

1.  **公共衛生獎：監測排泄物的智慧馬桶（史丹佛大學朴勝民博士）**

    *   功能：拍攝尿流和糞便形態，分析異常；尿液檢測試紙分析成分；「肛門識別」技術。
    *   升級：考慮增加心率感測器，綜合檢測健康指標。
    *   意義：以屎為鑑，可以知健康。
2.  **營養學獎：增強味覺的帶電筷子（明治大學宮下研究室）**

    *   原理：利用微弱電流刺激增強咸味感知。
    *   效果：咸味感受增強至原來的約1.5倍。
    *   應用：減少鹽分攝取，提升味覺體驗。
    *   研究者：宮下芳明教授（曾發明可舔到味道的顯示螢幕等）。
3.  **化學和地質獎：科學家舔石頭的原因（揚·扎拉謝維奇）**

    *   原因：濕潤的岩石樣本能讓紋理更突出；舌頭能分辨岩石粒度差異及多孔質感。
    *   應用：更好地區分相似岩石。
    *   案例：扎拉謝維奇用舌頭發現石灰岩中的有孔蟲化石。
    *   注意：部分礦石有毒，非專業人士勿輕易嘗試。
4.  **醫學獎：數屍體鼻毛的研究（加州大學爾灣分校）**

    *   背景：斑禿患者可能脫落鼻毛，導致上呼吸道感染等問題。
    *   目的：評估鼻毛減少對斑禿患者的影響。
    *   方法：對20具遺體（10男10女）進行鼻毛計數和長度測量。
    *   結果：每個鼻孔平均鼻毛數量為120~122.2根，平均長度為0.81~1.035厘米。
5.  **機械工程獎：用死蜘蛛作為抓取工具（萊斯大學工程師）**

    *   原理：利用蜘蛛的液壓系統控制腿部伸展。
    *   方法：將狼蛛凍死，注入空氣改變壓強控制腿部運動。
    *   名稱：「死亡機器人」（Necrobotics）。
    *   優點：抓握輕柔、可生物降解、易於偽裝。
6.  **心理學獎：路人效應（紐約街頭實驗）**

    *   實驗：設置不同規模的看熱鬧群體，觀察路人加入行為。
    *   結果：看熱鬧人數越多，路人加入意願越大；邊走邊看比專門停下來看的多。
    *   結論：路人是否愛看熱鬧與初始群體規模有關。
7.  **物理獎：鳳尾魚「啪啪」行為（南安普頓大學）**

    *   發現：鳳尾魚交配帶來的湍流與大風暴造成的湍流不相上下。
    *   意義：魚群交配對海水混合的影響不容忽視。
8.  **傳播學獎：倒著說話的人的大腦研究**

    *   對象：兩位倒著說話的專家
    *   1號專家 (14歲覺醒): 把每個單詞的字母重新排列再念出來
    *   2號專家 (8歲學會): 經常在生活中倒著說話，但從未練習
    *   結果：大腦都有特殊之處。
        * 1號: 海馬旁回和梭狀回中的灰質體積更大
        * 2號: 額中回和額下回以及右側楔前葉體積更大
9.  **文學獎：重複多少次才不認識字的研究**

    *   實驗：讓受試者一直寫「the」這個單詞。
    *   結果：平均寫到27.7次開始不認識「the」這個單詞。
    *   發現：越常用的詞越容易出現這種現象。
10. **教育獎：師生無聊情緒研究**

    *   内容：略過 (因真的很無聊)

**結語**

看完今年的搞笑諾貝爾獎，不得不佩服科學家們的研究方向，真是太絕了！ 讓我們繼續期待明年的搞笑諾貝爾獎，看看又會出現什麼奇葩研究。

**補充案例：研究大山雀的生物學家**

*   東京大學生物學家鈴木的朋友，為了研究大山雀，把自己打扮成一隻大鳥一年有餘。
*   結果：大山雀族群沒有接納這位「畸形」的外來者。
*   科學家反思：或許走獸類同胞太過誇張，下次打算從天上出發。

**結束語**

感謝大家的觀看，我們下期再見！

**整理說明：**

*   **結構清晰：** 將文稿分成幾個部分，方便讀者快速了解內容概要。
*   **分點歸納：** 將每個獲獎研究的重點提煉出來，使用條列式呈現。
*   **潤飾語言：** 調整了部分語句，使其更流暢易懂。
*   **標題分明：** 增加了小標題，突顯各個研究的主題。

希望這次的整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>188. [2023-09-14] 【解密】三指外星人木乃伊遗骸再现 | 墨西哥国会发布会 | 真相还是骗局</summary><br>

<a href="https://www.youtube.com/watch?v=tSrG_eJ3J_E" target="_blank">
    <img src="https://img.youtube.com/vi/tSrG_eJ3J_E/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【解密】三指外星人木乃伊遗骸再现 | 墨西哥国会发布会 | 真相还是骗局

好的，這是一份整理後的文稿，著重於結構清晰、重點突出，並進行了一些潤飾，讓文章更易於閱讀：

**標題：墨西哥「外星人遺骸」聽證會：一場徹頭徹尾的騙局？**

**引言：**

大家好，我是大飛。今年UFO和外星人頻頻出現，彷彿人類即將揭開神秘面紗。但實際上，這可能只是全世界在「比爛」的表現。

**事件回顧：**

*   **美國國會聽證會（7月26日）：** 美國國會就「不明異常現象UAP」舉行公開聽證會，但僅止於「打嘴炮」。
*   **墨西哥「實物證據」（12日）：** 墨西哥拿出兩具「外星人遺骸」，宣布外星生命的存在。記者傑米·莫桑（Jamie Maussan）展示了2017年在秘魯發現的「非人類」生物遺骸，聲稱DNA不屬於人類，並有X光檢測報告佐證。

**疑點與真相：**

*   **外觀疑點：** 遺骸外型與電影《E.T.》相似，且具有與人類相似的骨骼結構。
*   **知乎爆料：** 知乎用戶指出，莫桑展示的骨骼是用納斯卡人類孩童木乃伊和松鼠猴等動物骨骼拼嫁而成，並經過加工。
*   **秘魯「發現」：** 2017年秘魯一共「發現」了五具遺骸，其中兩具被法國人高價買下，但因無法通過海關而作罷。
*   **詐騙背景：** 秘魯人Mario是盜墓者，擅長加工造假文物，曾因非法走私被捕。
*   **骨骼分析：**
    *   **手指：** 由人類手指、腳趾骨胡亂拼湊而成。
    *   **肋骨：** 鳥類的管狀骨頭。
    *   **四肢：** 人類股骨和脛骨。
    *   **頭骨：** 削切過的前後倒置的羊駝頭骨。
    *   **體表：** 石膏、硅藻土等混合物。
*   **碳14檢測：** 不同部位的碳14年份不同，肢體為800-1700年，皮膚則有7000多年歷史。
*   **DNA檢測：** 宣稱有超過70%的DNA來自地球之外，實際情況是木乃伊只有25%左右的基因來自某個單一人類，剩下的是各種DNA交叉污染、細菌及病毒DNA，以及羊駝DNA。

**結論：**

1.  木乃伊由盜墓賊和詐騙犯「發現」，發現地未經證實，且沒有隨葬物品。
2.  X光和CT掃描證實骨骼由人類骨骼胡亂拼湊而成。
3.  顯微組織學研究證實組織由人類組織和其他物質混合而成。
4.  碳-14鑑定證實木乃伊由於拼湊而成的高度異質性。
5.  DNA檢測證實木乃伊的DNA經歷過高度的交叉污染。

**事件本質：**

這是一場徹頭徹尾的騙局，莫桑可能藉此為新書造勢。

**個人觀點：**

大飛不懷疑外星人的存在，但這種所謂的證據是在侮辱大眾和外星人的智商。各國「比爛」的現象，娛樂化、荒誕化、怪異化的趨勢令人擔憂。

**結語：**

人類有探索未知的天性，但不應被愚弄。希望這種事能少一些。感謝大家的收看，我們下期再見。

**整理說明：**

*   **結構調整：** 將內容重新組織，分為引言、事件回顧、疑點與真相、結論、事件本質、個人觀點和結語，讓結構更清晰。
*   **重點突出：** 使用粗體標題和小標題，突顯文章重點。
*   **潤飾語言：** 稍微修改部分語句，使其更流暢易懂。
*   **刪減贅詞：** 刪除部分口語化的贅詞，使文章更精煉。
*   **添加結論：** 歸納了文章的重點，方便讀者快速理解。
*   **保留原文風格：** 盡可能保留了原文的幽默和口語化風格。

這個版本更易於理解事件的來龍去脈，並能快速抓取關鍵信息。希望您喜歡！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>187. [2023-09-14] 【人工智能】AI能闻到气味么 | 是否拥有并超越人的嗅觉 | Science最新发表研究 | 50万种气味图谱 | 机器感知的新边界</summary><br>

<a href="https://www.youtube.com/watch?v=7BMiE0wG8QU" target="_blank">
    <img src="https://img.youtube.com/vi/7BMiE0wG8QU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI能闻到气味么 | 是否拥有并超越人的嗅觉 | Science最新发表研究 | 50万种气味图谱 | 机器感知的新边界

好的，這是經過整理的文稿，我著重在結構清晰、語言流暢以及重點突出：

**最佳拍檔 - AI聞到氣味了嗎？**

大家好，這裡是最佳拍檔，我是大飛。

我們都知道，AI現在可以創作文字、圖畫和音樂了。但您可能難以想像，它竟然也開始能「聞到」氣味了！

**AI嗅覺突破：超越人類的感知**

還記得這個分子是什麼味道嗎？ (展示榴蓮臭味分子)

上個月底，科學家在《Science》期刊上發表文章指出，AI模型能讓機器擁有比人類更敏銳的嗅覺。

這篇論文提出了一種由數據驅動的人類嗅覺高維圖譜，簡稱POM。這個圖譜逼真地重現了由單一分子誘發的氣味感知類別的結構和關係。研究證明，機器學習模型在理解和描述氣味上已經達到人類水平。更重要的是，在氣味描述的前瞻性預測上，AI的準確度已經超越了人類個體。

這意味著，機器感知的邊界將進一步擴大，從視覺、聽覺再到嗅覺。未來的機器可能將擁有更多感知能力，真正感受和理解自身所處的世界，而不再只是從各種描述中體驗一個懸空的符號世界。

**AI嗅覺的潛在應用**

既然AI模型能夠將分子結構映射到氣味上，那麼它就可以：

*   創造特定的食物口味。
*   發現更適合每個人的香水。
*   找到更好的驅蚊化合物。

**人類如何聞到氣味？**

在詳細介紹AI是如何識別氣味之前，我們先來了解一下人類的嗅覺機制。

*   **鼻子的結構：** 鼻子由外鼻、鼻腔和鼻旁竇組成。鼻腔中的鼻黏膜與嗅覺的產生有直接關聯。鼻黏膜分為呼吸區域和嗅區。呼吸區域負責加溫加濕氣體，而嗅區（嗅上皮）則含有重要的嗅覺受體。
*   **嗅覺的產生：** 我們聞到的氣味，其實是鼻腔接收到空氣中含有氣味的化學物質（嗅質）。嗅質通過上皮黏膜的吸收，擴散到嗅細胞的纖毛上。纖毛上存在著特殊的嗅覺受體，與嗅質結合後產生第二信使類物質，使鈣通道開放，鈉離子與鉀離子進入細胞，從而產生動作電位，傳入嗅球，再傳向嗅覺中樞，引發嗅覺。
*   **嗅覺受體：** 人類有約400個功能性的嗅覺受體，遠遠超過其他感官受體。

**嗅覺研究的挑戰**

儘管如此，是什麼物理特性讓空氣傳播的分子在大腦中產生氣味，一直是個謎。嗅覺也因此被稱為人類最深層、最古老的感覺。

**科學家的研究方法**

莫奈爾化學感官中心和初創公司Osmo共同領導的研究小組，正在研究空氣中的化學物質是如何與大腦中的氣味感知相聯繫。目標是將分子結構映射到氣味感知中，並讓電腦根據分子結構預測氣味，甚至超越人類嗅覺。

**研究團隊的AI模型**

Alex Wiltschko博士和團隊創建了一個名為消息傳遞神經網路（MPNN）的機器學習模型。他們使用5000種已知化合物的數據集訓練模型，這些化合物與它們對應的嗅覺標籤相匹配，例如果味、花香、芝士味、薄荷味等。

數據輸入是分子的形狀，輸出是對哪些氣味詞最能描述它的氣味的預測。模型經過優化後，在經驗感知空間圖中，直觀地表示了感知距離和層次之間的關係。

**模型的有效性驗證**

為了確定模型的有效性，莫內爾大學的研究人員進行了一個盲驗證的過程。

*   **氣味描述實驗：** 15名訓練有素的研究參與者，每人被要求聞400種氣味，並接受相關訓練，使用55個單詞描述每種分子。
*   **質量控制：** 英國雷丁大學的風味化學教授Jane Parker及其團隊驗證了測試樣品的純度，確保雜質不會影響氣味描述的準確性。

**研究結果**

*   在53%的測試分子中，模型的表現優於小組成員的平均值。
*   模型在所有標籤上的表現都在人類評分者的分佈範圍之內，並且在30個標籤上的表現超過了小組成員的中位數。
*   模型在大蒜和腥味等具有明確結構的標籤上表現最佳，但在麝香標籤上表現最差。
*   小組成員對堅果、大蒜和芝士等常見食物氣味的一致性很強，而對於麝香和乾草等標籤的一致性較弱。
*   模型在不同嗅覺任務中的表現依然出色，甚至能在沒有經過訓練的嗅覺任務上也取得成功。

**模型的潛力**

該模型能夠識別出數十對結構不同、但氣味卻非常相似的分子，還能描述潛在氣味分子的各種氣味特性，例如氣味強度。

研究人員根據模型計算出的坐標，編制出了約50萬種潛在的氣味。而人類目前已知的、可購買到的氣味物質才約5000種。

**未來的挑戰**

研究者的下一步目標是找出氣味劑是如何結合並相互競爭的，從而產生人腦能夠解釋的、完全不同的氣味。但預測混合氣味將會非常困難，因為可能的組合數量極為龐大。

**總結與展望**

這項研究提出並驗證了一種新的數據驅動的人類嗅覺圖譜，能夠將化學結構與氣味感知相匹配。AI在嗅覺領域的突破，拓展了一個全新的感官領域。相比於AI已經非常擅長的視覺和聽覺，嗅覺的確還遠遠未被研究和開發。

AI來預測或發現新的氣味，以及氣味對人類和其他物種的影響，並不是遙不可及的事情。

**應用發想**

氣味也許能治病，或者被當做生化武器？

**結尾**

最後，我們再解答下開頭中提到的那個分子，它其實是榴蓮的臭味分子。

感謝大家的觀看，我們下期再見！

**修改說明：**

*   **標題：** 更具吸引力，點明主題。
*   **結構：** 分段清晰，添加小標題，方便閱讀和理解。
*   **語言：** 更加簡潔、流暢，避免口語化，重點明確。
*   **重點：** 突出了AI嗅覺的突破性進展、潛在應用以及研究方法和結果。
*   **結尾：** 總結全文，並提出展望，引人思考。
*   **添加圖片提示：** (展示榴蓮臭味分子)，更生動有趣。

希望這個整理版本對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>186. [2023-09-12] 【人工智能】万字综述大语言模型幻觉 | 如何定义幻觉 | 评估基准和方法 | 幻觉的来源 | 如何减少幻觉</summary><br>

<a href="https://www.youtube.com/watch?v=T142VYGXf38" target="_blank">
    <img src="https://img.youtube.com/vi/T142VYGXf38/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】万字综述大语言模型幻觉 | 如何定义幻觉 | 评估基准和方法 | 幻觉的来源 | 如何减少幻觉

好的，這是針對您提供的文稿所做的整理，我將其結構化、重點化，希望能幫助您更好地理解和運用：

**主旨：大語言模型（LLM）的幻覺問題**

*   **定義：** LLM生成與輸入不符、前後矛盾、或與世界知識不一致的內容。
*   **重要性：** 降低LLM在真實世界場景中的可靠性，可能造成實際風險。

**幻覺的類型：**

1.  **回答含糊不清：** 模稜兩可，無法提供有用答案。
2.  **回答不完整：** 支離破碎，缺少必要資訊。
3.  **回答偏差：** 反映訓練數據中的偏見（種族、性別等）。
4.  **資訊不足：** 無法回答查詢，可能是RLHF過度優化所致。

**論文分析：《AI大海中的海妖之歌：大語言模型中的幻覺調查》**

*   **結構：** 定義、評估、來源、減少方法、其他技術。

**幻覺的定義（論文）：**

1.  **與輸入相衝突：** 生成內容與用戶輸入（任務指令、任務輸入）相背離。
2.  **語境衝突性：** 生成內容與先前資訊矛盾。
3.  **與事實相衝突：** 生成內容與現有世界知識矛盾。

**幻覺的評估：**

*   **評估基準：**
    *   **TruthfulQA:** 評估回答問題的真實性。
    *   **FActScore:** 評估生成傳記的事實準確性。
    *   **HaluEval:** 評估大模型是否包含幻覺。
    *   **FACTOR:** 評估模型是否真實陳述可能性高於非事實陳述。
*   **評估形式：**
    *   問題解答
    *   指令提示
    *   文本補全
*   **評估指標：**
    *   人工評估
    *   模型自動評估 (TruthfulQA, AlignScore, FactScore)

**幻覺的來源：**

1.  **預訓練階段：**
    *   缺乏相關知識或內化錯誤知識。
    *   將虛假相關性誤解為事實。
    *   語料中本身存在幻覺的現象。
2.  **高估自身能力：** 對錯誤答案同樣自信。
3.  **對齊過程（微調、強化）：**
    *   缺乏先決知識的錯誤對齊。
    *   "諂媚" (sycophancy)，偏向用戶觀點而非真實答案。
4.  **生成策略：**
    *   過度承諾（"滾雪球"式自我一致性）。
    *   局部最佳不保證全局最佳。
    *   抽樣策略（top-p, top-k）引入隨機性。

**減少幻覺的方法：**

*   **訓練階段：**
    1.  **預訓練時期：**
        *   人工或自動整理預訓練語料庫，減少錯誤資訊。
        *   自動選擇可靠數據或過濾噪音數據。
    2.  **SFT時期：**
        *   整理SFT訓練數據（手動或自動）。
        *   引入誠實樣本（承認無能力回答）。
    3.  **RLHF時期：**
        *   設計特殊獎勵函數，鼓勵挑戰前提、表達不確定性。
*   **生成推理階段：**
    1.  **設計解碼策略：**
        *   事實核採樣 (Factuality kernel sampling) : 在多樣性和事實性之間取得更有效的平衡
        *   推理時干預（ITI）：調整Transformer模型注意力頭的激活方式。
        *   上下文感知解碼策略 (CAD) : 更多關注上下文訊息，減少對參數知識的依賴
    2.  **借助外部知識：**
        *   獲取相關知識（外部知識庫、外部工具）。
        *   知識利用方式：生成式補充、事後糾正。
    3.  **利用不確定性：**
        *   估算模型結果的置信度。
        *   方法：基於logit、口頭表達、一致性。

**其他減少幻覺的技術：**

1.  **多代理互動：** 多個LLM協作辯論。
2.  **提示工程：** 設計更有效提示。
3.  **利用LLM內部狀態：** 檢測虛假資訊。
4.  **優化模型架構：** 多分支解碼器、不確定性感知解碼器、雙向自迴歸架構。
5.  **MixAlign:** 模型對齊用戶查詢與存儲的知識。

**未來研究方向：**

*   改進自動評估方法。
*   模型編輯：修改模型行為，消除幻覺。
*   誘發幻覺的攻擊與防禦。

**結論：**

幻覺是LLM的一體兩面，如同機遇與風險。重點在於控制、減少風險，學習與幻覺共存，區分幻覺與事實。

**建議：**

*   深入閱讀原始論文及相關引用。
*   持續關注LLM幻覺問題的最新研究進展。

希望這個整理對您有幫助！ 如果您有任何其他問題或需要進一步的協助，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>185. [2023-09-11] 【开源】Github上的一个Star值多少钱 | 开源项目为何要刷星 | 如何给Github项目刷量 | 真假用户行为 | 非监督聚类检测算法</summary><br>

<a href="https://www.youtube.com/watch?v=_6k9l65y4GQ" target="_blank">
    <img src="https://img.youtube.com/vi/_6k9l65y4GQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【开源】Github上的一个Star值多少钱 | 开源项目为何要刷星 | 如何给Github项目刷量 | 真假用户行为 | 非监督聚类检测算法

好的，我將這個文稿整理如下：

**標題：Github Star 的真相：刷星、造假與識別**

**引言：**

*   Github Star 是衡量開源專案受歡迎程度的指標，儘管有虛榮成分，但仍具實際意義。
*   Star 數量的增長趨勢、關注度、技術選型、產品開發策略、投資決策和招募人才等方面都受其影響。
*   利益驅使下，刷星造假行為應運而生。

**刷星造假的現況：**

*   **價格：**
    *   baddhi.shop：100 個 Star 約 8 美元（活躍用戶，有折扣）。
    *   buygithub.com：100 個 Star 約 12 美元。
    *   還可以購買 Github 的 follower、fork 以及 watcher 的數量。
*   **案例：** 開源編排平台 Dagster 團隊親身體驗購買 Github Star。
    *   建立虛構的代碼倉庫並購買 Star。
    *   設計個人資料文件，並使用 GitHub REST API 和 GitHub Archive 數據庫進行測試。
    *   結果：代碼倉庫一夜爆紅。
    *   測試結果：
        *   在 GitHub24 (已失效) 購買的 Star 在 48 小時內交付，一個月後還在。
        *   在 Baddhi Shop 購買的 Star 在一周內交付，但一個月後四分之一被移除 (可能被 Github 官方撤銷)。

**如何識別刷 Star 行為：**

*   **第一類：一眼可辨的假帳號**
    *   個人資料缺乏真實性。
*   **第二類：用心造假的帳號**
    *   帳號有相當真實的活動以掩蓋其假帳號的事實。
    *   **共性：**
        *   同一天註冊。
        *   只有一天的活動記錄。
        *   活躍度極低。
        *   Follower 少於 1。
        *   Follow 的項目少於 1。
        *   個人公開的倉庫數量少於 4。
        *   個人信息 (電子郵件、僱用信息、簡歷、博客、Twitter 用戶名) 為空。
        *   點 Star 的日期與帳號創建/更新日期相同。
*   **工具：**
    *   Github 官方定期清理假帳號。
    *   astronomer、fake-star-detector 等工具。

**更隱蔽的造假行為：**

*   模仿正常開發者的行為，難以從行為數據上區分。
*   **Dagster 提供的檢測思路：** 無監督聚類 (Unsupervised Clustering) 機器學習技術。
    *   正常用戶的特徵分散，虛假用戶的特徵具有相似性，在可視化後會聚集在一起。
    *   用一組行為特徵 (提交代碼、提交 PR、點 Star、修改個人簡介等) 描述一個 Github 帳號，將其表示為高維向量空間中的一個點。
    *   向量空間中相近的點對應的 Github 帳號可歸類為同類帳號。
    *   如果同類帳號中有實錘的假帳號，則其他帳號大概率也是假帳號。

**案例分析：**

*   衡量刷 Star 的倉庫中點 Star 的 Github 帳號的行為。
    *   橫軸：日期跨度
    *   縱軸：帳號交互的倉庫總數
    *   顏色：
        *   藍色：所有用戶
        *   紅色：明確的假 Github 帳號
        *   黃色：根據聚類被懷疑的假帳號
*   結論：通過聚類可以很好地識別出刷 Star 帳號。

**案例分析：Okcash (開源加密貨幣)**

*   有 579 個 Star。
*   經過 Dagster 的方式檢測後，疑似虛假刷 Star 的帳號占比達到 97%。

**總結：**

*   買 Star 行為在 Github 上還不那麼普遍。
*   開源社群的長期發展需要每個開發者的努力。

**建議：**

*   對於想買 Github Star 的人，要不就花點錢買點貨真價實的，要不就乾脆別買。
*   不要因為刷 Star 而被扒出，造成尷尬局面。

**資源：**

*   Dagster 的聚類檢測方法已開源，地址在影片簡介中。

**結尾：**

*   感謝大家的觀看，我們下期再見。

**整理說明：**

*   我將文稿按照內容邏輯分段，並加上標題和副標題，使結構更清晰。
*   使用條列式清單整理重要資訊，如價格、共性、工具等。
*   對專有名詞 (如 Unsupervised Clustering) 進行中英文對照。
*   對案例分析進行簡單描述，突出重點。
*   精簡了部分口語化的表達，使文稿更正式。
*   調整了語氣，使文稿更客觀、更具資訊性。

希望這個整理後的版本對您有幫助！ 如果您有任何其他要求或需要進一步修改，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>184. [2023-09-09] 【AI】人工智能的新机遇 | 吴恩达Andrew Ng | 斯坦福最新7.26演讲 | 15分钟浓缩精华版</summary><br>

<a href="https://www.youtube.com/watch?v=0fZGr93Ni1s" target="_blank">
    <img src="https://img.youtube.com/vi/0fZGr93Ni1s/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】人工智能的新机遇 | 吴恩达Andrew Ng | 斯坦福最新7.26演讲 | 15分钟浓缩精华版

好的，我為你整理了這篇文稿，使其更結構化、易於理解，並突顯重點：

**主題：吳恩達於史丹佛大學商學院講座：人工智慧新機遇**

**講者：吳恩達 (AI Fund CEO, deeplearning.ai 和 Landing AI 創始人, Coursera 主席和聯合創始人)**

**核心內容摘要：**

吳恩達博士在講座中分享了他對人工智慧發展趨勢、機遇、創業以及風險的看法。他將AI視為一種新的電力，並強調了監督學習和生成式AI這兩項關鍵技術。他認為生成式AI作為開發者工具的潛力被嚴重低估，並強調應專注於具體應用和用例。此外，他認為創辦AI公司需要與領域專家合作，並關注具有可驗證性的具體想法。最後，他認為AI對人類的滅絕風險不大，反而是解決流行病和氣候變遷等問題的關鍵。

**主要內容：**

1.  **人工智慧技術和工具的發展趨勢：**
    *   **AI 是一種新的電力：** 一種通用的技術，對許多不同的事物都有用。
    *   **監督學習：** 擅長識別或標記事物，計算輸入到輸出（A 到 B）的映射。過去十年是大規模監督學習的十年，核心思想是使用大規模計算和大規模數據。
        *   例子：建立餐廳評價系統，透過標記積極和消極的評價來訓練AI模型。
    *   **生成式 AI：** 核心思想是使用監督學習來重複預測下一個單詞。
        *   大語言模型 (例如GPT-3)：透過在數百億個字詞的文本上訓練而得。
        *   作為開發者工具的潛力被低估，可以更快地建構應用程式。
        *   例子：快速建立情感分類器，只需要一句提示。

2.  **人工智慧的機遇和應用：**
    *   **AI 技術價值變化：** 監督學習目前價值最高，但生成式AI未來三年將快速成長。
    *   **創新公司或大公司的機會：** 集中在淺綠色或淺橙色的區域，所有技術都是通用技術，需要找到多樣化、具體的用例並建構它們。
    *   **避免不具長期價值和商業優勢的應用：** 如 Lenser 應用程式和手電筒APP。
    *   **重點：** AI 還未被廣泛採用，高度集中在消費者軟體和互聯網領域。其他行業應用還非常初級。需要將 AI 的價值從技術領域和消費軟體領域推向其他領域，甚至推向整個經濟。
    *   **低代碼/無代碼工具的重要性：** 讓使用者可以自己客製化AI應用，不再要求編寫大量程式碼，只需提供數據即可。

3.  **創建初創企業的過程：**
    *   **AI Fund 的孵化模式：**
        *   先與用戶交流想法和需求。
        *   花約一個月時間驗證想法和技術可行性。
        *   與潛在客戶交談確保可行性。
        *   引入 CEO 一起開展項目，共同構建原型並進行深入的客戶驗證。
        *   建立團隊，做MVP和外部融資。
    *   **與領域專家合作：** 使用 AI 資源來確保技術團隊強大，然後與行業或領域專家合作來發掘新的機會。只關注於可以有效驗證或證偽的具體想法。

4.  **人工智慧的風險與社會影響：**
    *   **倫理和道德原則：** 只關注於有助於推動人類前進且不違反倫理和道德原則的項目。
    *   **對就業的影響：** AI 可能影響更多高薪職位，應妥善照顧受到AI衝擊的人們。
    *   **對 AGI 的看法：** AI 尚未達到可以做任何人類能做的事情的程度，距離實現 AGI 仍然需要幾十年。
    *   **對人類滅絕風險的看法：** AI 不會對人類構成任何有意義的滅絕風險。真正可能滅絕人類的是流行病或氣候變化，更智能的 AI 則是解決這些問題的關鍵。

**結論：**

吳恩達認為 AI 作為一種通用技術，為每個人創造了許多新的機會。未來的重點是建立具體的用例，並希望與更多人合作開發這些機會。

**整理說明：**

*   **標題和副標題：** 使結構更清晰，方便快速瀏覽。
*   **要點式呈現：** 將重點內容以條列方式呈現，方便記憶和理解。
*   **案例說明：** 包含具體的例子，幫助理解抽象概念。
*   **強調重點詞彙：** 使用粗體標示重點詞彙。
*   **簡潔的語言：** 避免冗長的句子，使用更精簡的語言。

希望這個整理後的文稿對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>183. [2023-09-04] 【人工智能】OpenAI正在秘密训练GPT-5？| 穆斯塔法·苏莱曼最新访谈 | DeepMind联创&InfectionAI CEO | 比GPT-4大100倍 | DeepMind背后的故事</summary><br>

<a href="https://www.youtube.com/watch?v=0Hk9XFfdeEM" target="_blank">
    <img src="https://img.youtube.com/vi/0Hk9XFfdeEM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OpenAI正在秘密训练GPT-5？| 穆斯塔法·苏莱曼最新访谈 | DeepMind联创&InfectionAI CEO | 比GPT-4大100倍 | DeepMind背后的故事

好的，這是我整理後的文稿，重點歸納、條列分明，並針對部分地方進行了潤飾，使其更易讀：

**文稿主題：OpenAI 是否秘密訓練 GPT-5？穆斯塔法·蘇萊曼訪談重點整理**

**核心內容：**

*   **OpenAI 是否秘密訓練 GPT-5？**

    *   OpenAI CEO 薩姆·奧特曼否認正在訓練 GPT-5。
    *   Inflection AI CEO 穆斯塔法·蘇萊曼懷疑 OpenAI 秘密訓練 GPT-5，認為 OpenAI 可能只是換了個名字。
*   **蘇萊曼訪談重點：**
    *   **蘇萊曼背景：**
        *   Inflection AI 聯合創辦人兼 CEO。
        *   DeepMind 聯合創辦人。
        *   曾任 DeepMind 應用人工智能負責人、Google 政策職務。
    *   **Inflection AI 的發展：**
        *   未來 18 個月內訓練的模型比當前前沿模型大 100 倍。
        *   未來 3 年內訓練的模型比現在大 1000 倍。
        *   目標是打造一個非常好用的個人助理，提供高度客製化的 AI 服務。
    *   **對開源模型的看法：**
        *   未來 5 年內，開源模型始終會落後於最前沿的閉源模型。
        *   開源模型會增加 AI 帶來的社會風險，讓力量快速擴散。
        *   AI 技術可能會降低潛在危險化合物或武器的開發門檻。
        *   並非攻擊開源社群，但仍要堅持表達開源的風險。
    *   **在 Google 和 DeepMind 的經歷：**
        *   花費大量時間試圖將更多外部監督融入到 AI 技術的建構過程中，但過程痛苦。
        *   原本 DeepMind 被收購時提出要設立倫理和安全委員會，但 Alphabet 變得膽怯。
        *   DeepMind 從未獨立過，現在也完全從屬於 Google。
    *   **AI 訓練成本：**
        *   算力成本隨著晶片算力的迭代在不斷下降。
        *   未來可能會出現訓練某个模型的成本相当于在 2022 年花费了 100 亿美元来训练。
    *   **AI 模型的軍備競賽：**
        *   Inflection AI 正在建造世界上最大的超級電腦之一，可能運行比 GPT-4 大 10 倍或 100 倍的訓練。
        *   但因缺乏自主性，模型本身不具有危險性。
        *   擁有大規模算力的公司，應該盡可能保持公開透明。
        *   Google DeepMind 也應該披露 Gemini 接受了多少 FLOPS 訓練。
*   **蘇萊曼新書《即將到來的浪潮》：**
    *   思考人工智能所帶來的社會變化和風險，以及應對措施。
    *   內容包括對人工智能模型進行能力審核、讓批評者參與直接設計人工智能模型、及极大提高政府对人工智能的理解及合理监管的能力等等。

**總結：**

蘇萊曼的訪談內容涵蓋了對 OpenAI、開源模型、AI 安全性等議題的看法，以及他在 Google 和 DeepMind 的經歷。他認為 AI 發展的風險不容忽視，並呼籲保持透明和謹慎。

**大飛觀點：**

大飛將會持續關注 GPT-5 的發展，期待其能夠再次提升大模型 AI 的能力，並解決人們對於 AI 浪潮是否能持續的懷疑。

**建議：**

1.  **分段標題加強：** 每個段落可以加上更具體的標題，例如「蘇萊曼對開源風險的詳細說明」等，讓讀者更容易掌握內容。
2.  **資料佐證：** 針對蘇萊曼的觀點，可以加入一些數據或案例來支持，增加說服力。
3.  **用語調整：** 可以將部分口語化的用語調整為更書面化的表達方式，例如將「大家都在猜測」改為「普遍認為」。

希望以上整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>182. [2023-09-02] 【AIGC】国内首例AI文生图著作权案 | StableDiffusion生成的图片有没有著作权 | 是否属于作品 | 创作主体 | 独创性</summary><br>

<a href="https://www.youtube.com/watch?v=kr_K5FOm5ug" target="_blank">
    <img src="https://img.youtube.com/vi/kr_K5FOm5ug/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】国内首例AI文生图著作权案 | StableDiffusion生成的图片有没有著作权 | 是否属于作品 | 创作主体 | 独创性

好的，以下是我整理後的文稿，主要目的是使其更易於閱讀、理解和查找資訊。我將會：

*   **調整結構：** 將文稿分段，並加上標題和副標題，使其更清晰。
*   **簡化語言：** 避免過於口語化的表達，使文稿更正式。
*   **提煉重點：** 強調案例的關鍵資訊和爭議點。
*   **梳理邏輯：** 使文稿的論述更具邏輯性。
*   **保留原文特色：** 盡可能保留原稿的觀點和風格。

---

**AI文生圖著作權案：國內首例引發的法律爭議**

**引言**

大家好，我是大飛，這裡是誰最佳拍檔。隨著生成式AI的興起，相關的法律問題日益增多。本次我們將聚焦於國內首例“AI文生圖”著作權案件，探討其中涉及的法律爭議。

**案件概述**

8月24日，北京互聯網法院公開開庭審理了一起“AI文生圖”著作權案。原告李某使用Stable Diffusion模型，通過輸入提示詞生成了一張人物圖片，並發布在小紅書上。被告劉某是一位詩詞博主，在其百家號文章中使用了該圖片作為配圖，並去除了水印。李某遂以侵害署名權和信息網絡傳播權為由，將劉某起訴至法院，要求賠償經濟損失並賠禮道歉。

**庭審直播與公眾關注**

由於這是國內首例相關案件，庭審過程在多個平台同步直播，吸引了超過17萬網友的關注。庭審現場和直播間就AIGC的版權問題展開了激烈的辯論。

**爭議焦點**

本案的爭議焦點主要集中在以下幾個方面：

1.  **涉案圖片是否構成作品？**
2.  **如果構成作品，原告是否享有著作權？**
3.  **被告使用圖片的行為是否侵犯了署名權和信息網絡傳播權？**
4.  **如果侵權成立，被告應如何承擔責任？**

由於爭議較大，案件僅進行了庭辯，尚未宣判。

**庭審細節：雙方觀點**

*   **原告李某的觀點：**
    *   AI生成圖片的操作和輸入體現了獨創性的智力勞動。
    *   AI僅是工具，創造活動由使用者完成。
    *   涉案圖片屬於美術作品，或“符合作品特征的其他智力成果”。
    *   被告未經許可使用圖片並刪除水印構成侵權。
*   **被告劉某的觀點：**
    *   文章主要內容為原創詩文，圖片僅為配圖，無商業用途，不具有侵權故意。
    *   圖片通過網絡檢索獲得，來源不明，無法確定李某是否享有權利。
    *   AI繪畫是人類畫家的結晶，涉案圖片創作門檻低，缺乏獨創性，不構成作品。
*   **法官詢問與調解意願:**
    *   李某不同意調解，希望法庭能對AI繪畫作品給出明確的裁量和認定標準。

**案件焦點的法律分析**

本案反映了生成式人工智能在版權領域面臨的幾大新問題：

1.  **AIGC是否屬於人的創作？作者是人還是AI？**
    *   中國《著作權法》規定只有“人類”才能擁有作者身份。
    *   人工智能的本質並非自然人，不符合法律規定的權利主體。
    *   法律強調“人”的主體地位，人工智能只有在人的參與和安排下，才有獲得著作權法保護的可能性。
    *   脫離人的干預，完全由人工智能自主完成的內容不應被視為作品。

2.  **如果AI創作的作者必須是人，那麼應該是誰？**
    *   AI生成圖片的過程涉及多個角色：大模型開發者、訓練數據提供者、微調模型開發者、使用者等。
    *   需要識別各自主體的貢獻，以及貢獻與最終成果的關係。
    *   只有與最終成果存在直接關係且達到“控制”程度的主體，才可能被認定為作者。

3.  **AI文生圖是否具有獨創性？**
    *   作品需具備獨創性，即“作者獨立完成”和“最低限度地創作”。
    *   最低限度創作指的是具備足夠和既有作品相區分的差異性，而非複製抄襲。
    *   大模型具有隨機性，如何判定使用者“控制”了AI生成結果？
    *   初級用戶的“一鍵生圖”難以認定為作者，高級用戶可控制更多細節，但提示詞的個性化選擇與安排是否構成獨創性仍存疑。

4.  **AI生成內容與既有作品的相似性問題**
    *   即使AI軟件使用者主導了製圖過程，如果AI製作出了與世界名畫“蒙娜麗莎”一模一樣的畫作，由於畫作並無獨創性，依然無法受到著作權法的保護。

**國外案例與平台應對**

*   **美國版權局：** 人工智能生成材料的作品，重要的是人類在多大程度上創造性地控制了作品的表達。純粹由AI生成的圖片不受版權保護，但文字和AI圖片結合而成的書的內容受版权保护，因为当中存在人类工作。
*   **創作者抵制：** 創作者公開抵制AI模型和平台學習和使用自己作品的事件頻發。
*   **平台承擔責任：** Adobe和Shutterstock等平台承諾，如果因使用AI生成的圖片引發版權糾紛，將為使用者提供賠償。

**開源模型與商業利用**

*   如果底層模型開源，是否意味著微調模型都可以商用、獲得版權收益？
    *   取決於具體的開源協議。
    *   例如，Stable Diffusion基於MIT協議開源，允許不受限制的處置，包括商業利用。
    *   微調模型的開發者通常會聲明使用條件，例如AsiaFacemix規定10人以下團隊可將模型的輸出用於商業目的。

**中國法律法規**

*   《生成式人工智能服務管理暫行辦法》已於8月15日起實施，對大模型公司要求實行備案制。
*   監管部門關注模型的數據安全、數據來源問題，例如是否侵犯知識產權或隱私。
*   目前生成式AI的法律界限尚不明確，需要更多判例來確立。

**大飛個人觀點**

個人傾向於AI生成物不應具有著作權：

*   創作者僅提供prompt，未參與圖片的繪製過程。
*   圖片缺乏明確的自然人主體，不符合獨創性要素。
*   提示詞易於複製，難以證明其智力成果和獨創性。
*   AI降低了創作門檻，如果賦予AI生成圖片著作權，可能導致濫用和“版權流氓”行為。

**結語**

本案的後續進展值得持續關注。生成式AI對版權體制帶來了根本性的衝擊，法律界限的確立需要時間和案例積累。

---

**注意：**

*   我保留了原文的观点，包括大飞的个人看法。
*   我调整了一些口语化的表达，使其更正式。
*   我增加了一些标题和副标题，使其更清晰。
*   我将一些关键信息以更突出的方式呈现。

我希望这个整理后的文稿对您有所帮助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>181. [2023-09-01] 【Google】SemiAnalysis第三弹爆料 | 谷歌Gemini是GPT-4五倍算力 | 算力王者 | TPUv5 | 算力穷人将被淘汰 | AI芯片世界的救世主？</summary><br>

<a href="https://www.youtube.com/watch?v=APH0iOko50c" target="_blank">
    <img src="https://img.youtube.com/vi/APH0iOko50c/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Google】SemiAnalysis第三弹爆料 | 谷歌Gemini是GPT-4五倍算力 | 算力王者 | TPUv5 | 算力穷人将被淘汰 | AI芯片世界的救世主？

好的，我將為您整理這篇文稿，使其更具條理性、更易讀，並突出重點。以下是整理後的版本：

**核心觀點：谷歌 Gemini 的算力是 GPT-4 的 5 倍，AI 算力競賽白熱化**

**主要內容：**

*   **SemiAnalysis 爆料：** 分析師迪倫·帕特爾（Dylan Patel）和丹尼爾·尼什博爾（Daniel Nishball）爆料，谷歌下一代大模型 Gemini 的算力已達 GPT-4 的 5 倍，暗示 OpenAI 在算力上遠遜於谷歌。

*   **算力為王：** 在 AI 商業化競爭中，掌握足夠 GPU 資源至關重要。谷歌已成為算力王者，其 TPUv5 數量超過 OpenAI、Meta 等公司的 GPU 總和。

*   **Sam Altman 的反應：** OpenAI 的 Sam Altman 對於谷歌算力超越 OpenAI 的說法表示不滿，認為 SemiAnalysis 發布的是谷歌的內部行銷資料。

*   **爆料的可靠性：** 迪倫·帕特爾過去的爆料（如「我們沒有護城河」的谷歌內部文件洩露事件、GPT-4 架構洩密等）均被證實。

*   **GPU 富人和 GPU 窮人：**
    *   **GPU 富人：** 擁有大量 GPU 的科技巨頭（OpenAI、谷歌、Meta 等）將 GPU 視為招聘策略，吸引頂尖研究人員。
    *   **GPU 窮人：** 小型新創公司和開源研究者面臨 GPU 短缺，難以進行有意義的研究。
    *   **安德烈·卡帕希的感慨：** 誰能獲得多少 H100，何時獲得 H100，成為矽谷的熱門話題。

*   **開源模型的困境：** GPU 窮人過於關注模型大小、量化，忽視了資料品質和預訓練的重要性。目前的大模型排行榜已失去意義。

*   **大模型之戰的世界版圖：** 美國和中國持續領先，歐洲因投資和 GPU 短缺而落後，中東國家則加大投資。

*   **HuggingFace、Databricks 等 AI 公司也是 GPU 貧困戶：** 儘管擁有頂尖研究者，但他們只能在算力較低的系統上工作。

*   **英偉達的優勢：** 從 Meta 到微軟，再到新創公司，實際上所有人都只是在充實英偉達的銀行帳戶。

*   **谷歌的希望：** 谷歌擁有 TPU 等 AI 專用基礎設施，以及下一代大模型 Gemini，可能成為拯救者。

*   **TPU 的演進：** 谷歌自 2006 年開始構建 AI 專用基礎設施，並開發了多種 TPU 晶片。

*   **谷歌的算力擴張：** 谷歌擁有的 TPUv5 比 OpenAI、Meta 等公司的 GPU 總和還要多。

*   **Gemini 的訓練：**
    *   Gemini 在 14 個 TPU Pod 上進行訓練。
    *   下一次迭代已開始在基於 TPU V5 的 Pod 上進行訓練，算力高達 10 的 26 次方 FLOPS，比 GPT-4 的訓練大 5 倍。
    *   谷歌還推出了新一代 AI 加速器 Cloud TPU V5E 和基於 Nvidia H100 GPU 的 GPU 超級電腦 A3 VM。

*   **結論：** 谷歌開始整合內部算力資源，以 GPT-4 五倍的算力訓練 Gemini，凸顯了 Google Brain 和 DeepMind 合併後的優勢。一些缺乏資本和資源的 AI 新創公司可能很快被市場淘汰。

**關鍵詞：** Gemini, GPT-4, 算力, GPU, TPU, OpenAI, 谷歌, AI, 大模型, SemiAnalysis, 迪倫·帕特爾, 丹尼爾·尼什博爾, 英偉達, HuggingFace, Databricks。

**潛在的討論方向：**

*   AI 領域的算力競賽是否會持續升級？
*   缺乏算力的小型 AI 公司如何應對？
*   谷歌 Gemini 是否能超越 GPT-4？
*   AI 晶片的未來發展趨勢。
*   英偉達在 AI 領域的壟斷地位。

希望這個整理的版本對您有所幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>180. [2023-09-01] 【独家】DoctorGPT本地安装部署指南 | 你的私人AI医生 | 完全免费 | 跨平台支持 | Llama 2 70亿微调 | 通过美国医学执照考试</summary><br>

<a href="https://www.youtube.com/watch?v=YEWRzuTPRY0" target="_blank">
    <img src="https://img.youtube.com/vi/YEWRzuTPRY0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【独家】DoctorGPT本地安装部署指南 | 你的私人AI医生 | 完全免费 | 跨平台支持 | Llama 2 70亿微调 | 通过美国医学执照考试

好的，這是我整理後的文稿，主要目的是使其更易讀、重點更清晰：

**標題：輕鬆安裝 Doctor GPT：本地部署，AI 醫療助手觸手可及！**

**開場白：**

大家好，我是小郭，歡迎來到最佳拍檔！今天跟大家分享如何安裝 Doctor GPT。

**Doctor GPT 是什麼？**

Doctor GPT 是一款利用人工智能幫助患者的應用程式，它會根據使用者的症狀和醫療歷史，提供個人化的建議，並推薦合適的專科醫生。目的是讓人們更輕鬆、更有效率地獲取醫療建議，不必再長時間排隊或進行大量的網路搜尋。

**Doctor GPT 的優點：**

1.  **完全免費：** 無需額外付費解鎖 Pro 功能。
2.  **本地部署：** 無需擔心隱私洩漏。
3.  **準確性高：** 號稱已通過美國醫師執照考試。
4.  **跨平台：** 支援 Apple、Android、PC，甚至 Web 瀏覽器。

**安裝準備：**

*   已安裝顯卡驅動的圖形化作業系統。
*   可以訪問 Google 等牆外網站。
*   需要安裝一些軟體，例如 Git LFS、NodeJS、Python 或其他 HTTP 伺服器。

**Doctor GPT 模型與 MLC-LLM：**

Doctor GPT 僅提供模型文件，需借助 **MLC-LLM** 才能使用。MLC-LLM 支援將各種語言模型進行本地部署，支援手機、PC 甚至是瀏覽器環境。

**安裝方式：**

*   **手機（不推薦）：** 雖然官方聲稱支援手機，但成功率較低。
    *   **iOS：** 在 Apple Store 搜尋並安裝 MLC Chat（可能需要國外 Apple ID）。
    *   **Android：** 從 GitHub 頁面下載 APK 安裝。
    *   **模型地址：**
        1.  打開 Doctor GPT Github 頁面。
        2.  點擊 "files and versions"。
        3.  將網址中的 `tree/main` 改為 `resolve/main/`，以此作為模型地址。
    *   **可能問題：** 下載目錄權限錯誤、應用程式崩潰、需要至少 4GB 運行記憶體。

*   **Web（推薦）：** 透過 MLC-LLM 的子項目 **web-llm** 在瀏覽器中運行 Doctor GPT，支援硬體加速。
    *   **步驟：**
        1.  下載 web-llm 專案 (ZIP 檔案或 Git clone)。
        2.  使用 VS Code 開啟 `examples/simple-chat` 目錄。
        3.  執行 `npm install --registry=https://registry.npm.taobao.org` (使用國內鏡像)。
        4.  修改 `src/gh-config.js`：
            *   複製 `model_list` 中最後一個紀錄。
            *   將模型地址改為前面提到的 `resolve/main/` 地址。
            *   將 `local_id` 改為 `DoctorGPT_mini`。
        5.  執行 `npm run start`。
        6.  在瀏覽器中打開 `http://localhost:8888`。
    *   **可能問題：** 網路要求較高，需要頻繁從 Hugging Face 下載檔案。

*   **Web（優化版 - 本地加載模型）：** 將所需檔案提前下載到本地，避免頻繁網路請求。
    *   **需要下載的檔案：**
        *   Web Assembly 的 `.wasm` 檔案 (從 `gh-config.js` 的 `model_lib_map` 中找到下載地址)。
        *   模型檔案 (從 Hugging Face 頁面下載，共 50 多個檔案，記得點擊 "Load more files")。
    *   **步驟：**
        1.  修改 `src/mlc_local_config.js`：
            *   複製 `model_list` 中最後一個紀錄。
            *   將 `model_url` 改為本地檔案路徑。
            *   將 `local_id` 改為 `DoctorGPT_mini`。
            *   將 `model_lib_map` 中最後一行的 `URL` 改為本地 `.wasm` 檔案路徑。
        2.  修改 `package.json`：
            *   找到第 8 行，將 `build` 後的 `cp` 命令要複製的檔案改為 `mlc_local_config.js`。
        3.  執行 `npm run build` 編譯。
        4.  下載 `.wasm` 檔案和模型檔案。
        5.  將編譯好的檔案放到 `lib` 目錄下。
        6.  使用 Python 的 HTTP Server 模組啟動伺服器：
            *   切換到 `lib` 目錄。
            *   執行 `python -m http.server 18080` (18080 為端口號，與設定檔一致)。
        7.  在瀏覽器中打開 `http://localhost:18080/llm_chat.html`。
        8.  在模型列表中選擇 `DoctorGPT_mini`。
        9.  如果出現異常，可能需要使用 Google Canary 瀏覽器，並在啟動時加上特定參數。

**模型訓練：**

如果想訓練自己的模型檔案，可以參考官方的 Jupiter Notebook 檔案。據說在付費的 Google Collab 上，使用 A100 GPU 大約需要運行 24 小時。

**結語：**

感謝大家的觀看，下次再見！

**說明：**

*   我將冗長的步驟拆解成更小的、更易於理解的步驟。
*   我強調了重要的檔案和路徑。
*   我使用粗體字來突出重點。
*   我簡化了一些專業術語，使其更容易被一般讀者理解。
*   我去除了語氣詞和口語化的表達，使其更正式。

這個版本應該更易於理解和遵循。希望對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>179. [2023-08-30] 【人工智能】具身智能：下一个AI浪潮 | 稚晖君 | Embodied AI | 什么是具身智能 | 目前发展阶段 | 挑战与困难 | 智元远征A1机器人</summary><br>

<a href="https://www.youtube.com/watch?v=UZBSXzNKB1Q" target="_blank">
    <img src="https://img.youtube.com/vi/UZBSXzNKB1Q/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】具身智能：下一个AI浪潮 | 稚晖君 | Embodied AI | 什么是具身智能 | 目前发展阶段 | 挑战与困难 | 智元远征A1机器人

好的，以下是我整理後的文稿，主要針對段落結構、重點突出、以及更易於閱讀做了調整：

**標題：智元機器人與具身智能：稚暉君的新挑戰**

**開場**

大家好，這裡是最佳拍檔，我是大飛。前幾天分享了稚暉君（彭志輝）的新公司智元機器人的發佈會影片，大家反應熱烈。但也有不少人對他不熟悉甚至認錯了，所以先簡單介紹一下：

*   **稚暉君 (彭志輝)**：1993年出生於江西吉安，畢業於電子科技大學。曾任職OPPO研究院AI實驗室算法工程師，後加入“華為天才少年計劃”，從事昇騰AI芯片和AI算法研究。2022年12月從華為離職，2023年2月創立智元機器人公司 (AGIBot)，現任CTO兼首席架構師。

**稚暉君的成名之路**

稚暉君在B站發布了許多硬核科技產品影片，例如自動駕駛自行車、自製機械臂給葡萄縫針，因此獲得了B站“2021年度百大UP主”稱號。他在Youtube也有頻道，歡迎訂閱。

**具身智能：ChatGPT 之後的新趨勢**

智元遠征A1機器人發佈後，稚暉君撰寫文章闡述了他對具身智能領域的理解。繼ChatGPT之後，具身智能 (Embodied AI) 成為另一個熱門的大模型概念。

*   **學術界：** 圖靈獎得主姚期智認為，人工智能的下一個挑戰是“具身通用人工智能”。
*   **產業界：** 微軟、Google、Nvidia等大廠均投入相關研究，如Google的RT-2、Nvidia的VIMA等。Nvidia創始人黃仁勳也表示，AI的下一個浪潮將是“具身智能”。

具身智能作為人工智能發展的重要分支，正迅速崛起，成為科技界和大众關注的焦点。

**什麼是具身智能？**

簡單來說，具身智能透過在物理世界和數字世界的學習和進化，理解世界、互動交互並完成任務。它是一個由“本體”和“智能體”兩部分耦合而成的智能系統，能在複雜環境中執行任務。

**具身智能的核心要素：**

1.  **本體 (Body)：** 實際的執行者，在物理或虛擬世界進行感知和任務執行。通常是具有物理實體的機器人，形態多樣。本體的能力邊界限制智能體的能力發揮。
    *   例如：四足機器人、複合機器人、人形機器人。
    *   本體需具備環境感知能力、運動能力和操作執行能力。
2.  **智能體 (Embodied Agents)：** 具身在本体之上的智能核心，負責感知、理解、決策、控制等核心工作。
    *   智能體可以感知複雜的環境、理解語義信息、與環境交互、理解任務並做出決策，進而控制本體完成任務。
    *   現代智能體通常由深度網絡模型驅動，結合視覺等多種傳感器的多模態模型是新趨勢。
    *   智能體要能從複雜數據中學習決策和控制範式，並持續自我演進。
3.  **數據 (Data)：** 泛化的關鍵。機器人數據稀缺且昂貴。智能體規模越大，對海量數據的需求越高。
    *   針對具身智能場景，尤其是行業場景的高質量數據，是未來成功應用的關鍵支撑。
4.  **學習和進化架構 (Learning and Evolution Architecture)：** 智能體透過與虛擬或真實物理世界的交互，適應新環境、學習新知識、強化新的解決問題方法。
    *   採用虛擬仿真環境進行部分學習是一種合理設計 (例如Nvidia的Omniverse)。
    *   如何耦合仿真和真實世界，進行高效遷移是架構設計的關鍵。

**具身智能的科研與技術進展**

在基於Transformer的大語言模型浪潮下，微軟、Google、Nvidia等大廠，以及斯坦福、卡內基梅隆等高校，都开展了具身智能的相关研究。

*   **微軟：** 基於ChatGPT生成控制機器人的代碼。
*   **英偉達：** VIMA基於T5模型，融合文本和多模態輸入，預測機器人的下一步行動。
*   **斯坦福大學：** 利用大語言模型的理解、推理和代碼能力，與VLM交互並生成3D value map，規劃機械臂的運行軌跡。
*   **谷歌：**  具身智能路線廣泛且具延續性，包括PaLM-E、RoboCat以及基於RT-1和PaLM-E升級得到的RT-2。其中RT-2通過融合VLM和RT-1中收集的大量機器人真實動作數據，實現了更好的泛化性和湧現性。
    *   RT-2系列模型在面對訓練數據中沒見過的物體、背景、環境時，仍然能夠實現較高的成功率，證明其具有較強的泛化能力。
    *   對於符號理解、推理和人類識別等湧現任務，RT-2系列模型也能以較高的正確率完成，表明語義知識已從視覺語言數據轉移到RT-2中。
    *   思維鏈推理能夠讓RT-2完成更複雜的任務。
    *   Google耗費17個月收集了13台機器人的13萬條真實數據，為RT-1和RT-2的良好性能打下根基。RoboCat則會先收集100-1000個真實的人類專家示例，再合成更多數據，用於後續訓練。

**具身智能的難點與挑戰**

儘管具身智能是迈向通用人工智能（AGI）的重要一步，但要實現好的具身智能，仍面臨諸多挑戰：

1.  **通用本體平台：** 如何解決硬件的關鍵零部件技術突破，形成具有優秀運動能力和操作能力的平台級通用機器人產品，平衡本體的可靠性、成本和通用能力。人形機器人被認為是具身智能的終極形態，這方面的研發將持續成為熱點和核心挑戰。
2.  **智能體系統：** 設計具備複雜環境感知認知能力的智能體，需解決物理3D環境精確感知、任務編排與執行、通識能力、多級語義推理能力、人機口語多輪交互能力、長期記憶能力、個性化情感關懷能力、任務泛化與自學遷移能力等挑戰。具身智能要求實時感知和決策能力，對數據採集、傳輸和處理、AI計算能力和低延遲提出了巨大挑戰。
3.  **高質量數據：** 缺乏足夠的場景數據來訓練完全通用的大模型。耦合的本體需要實際部署到真實環境中才能採集數據。
4.  **學習與進化：** 如何透過虛擬和真實的交互，持續學習和進化。形態與環境适配的智能體可以快速學習到解決問題能力，更好地適應變化。在複雜環境、形態演化和任務的可學習性之間存在未知的關係。

**智元機器人的實踐：遠征A1與具身智腦**

智元機器人提出了“具身智腦” (Embodied Intelligence Brain) 的概念，將機器人的具身智能思維系統分為雲端的超腦、端側的大腦、小腦以及腦幹四層，分別對應於機器人任務級、技能級、指令級以及伺服級的能力。

*   **超腦：** （雲端）互联网能力
*   **大腦：** 完成語義級多段推理任務，結合上下文進行任務理解。
*   **小腦：** 結合各種傳感器的信息進行運動指令⽣成。
*   **腦幹：** 進行精確的伺服閉環控制。

EI-Brain設計上，上層大模型聚焦感知決策和計劃生成，不依賴具體的機器人載體硬件；下層視控模型和運控算法聚焦具體場景的特定動作執行，不用決策整個任務是如何完成的。 超腦大腦與小腦腦幹相互解耦。

遠征A1設計考慮了任務泛化率和任務執行成功率：

*   **任務泛化率：** 針對上層雲端超腦和大腦。大模型對新的任務和3D環境進行精準感知決策和指令計劃生成的能力。
*   **任務執行成功率：** 針對下層小腦和腦幹。視控模型和運控算法是否按照生成的指令計劃進行精準執行的能力。

智元機器人定義了一系列元操作庫 (Meta-Skill)，在有限泛化的場景內，機器人能夠自主推理決策出端到端完成任務所需的動作編排。 隨著元操作庫的擴充，機器人能勝任的任務空間將呈指數級增長。

遠征A1的本体形態與人類相似：

*   身高1.75米
*   重量55公斤
*   最高步速每小時7公里
*   全身49個自由度
*   整機承重80公斤
*   單臂最大负载5公斤

硬件层面，智元自研了关节电机Powerflow、灵巧手SkillHand、反屈膝设计等关键零部件。軟件層面，智源自研了AgiROS機器人運行時中間件系統，能實現自主的任務編排、常識推理以及規劃執行。

**總結與展望**

我個人看好稚暉君，他綜合能力全面，動手能力超強。半年時間做出機器人實體，速度很快。但這次不僅僅是像之前在B站發影片，而是需要證明商業方向、技術突破、量產能力應用落地等多方面的結果，這對他來說是不小的挑戰。雙足機械人領域非常垂直和前沿，沒有太多開源方案可以借鑒。每家的設計理念會直接決定後續的技術方案和量產能力。

可行和可用之間可能有天差地別，各零部件的精度和配合非常考驗設計者和背後整個工業供應鏈的能力。在這個層面上，真正的源源不斷的創新才是關鍵。希望能夠繼續看到他們的創新和突破，我們會持續關注並第一時間跟大家報道。

**結束**

本期影片就到這裡，感謝大家的觀看，我們下期再見。

**整理說明：**

*   **結構化：** 使用標題、子標題、項目符號等方式，將內容組織成更清晰的結構。
*   **重點突出：** 使用加粗字體突出重點信息，方便快速瀏覽。
*   **邏輯性：** 調整段落順序，使邏輯更順暢。
*   **簡潔性：** 刪除一些重複或不必要的語氣詞，使文稿更簡潔。
*   **術語解釋：** 對一些專業術語進行解釋，例如“具身智能”、“元操作庫”等。

希望這個整理後的文稿對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>178. [2023-08-30] 【OpenAI】ChatGPT Enterprise企业版正式发布 | 无限制访问GPT-4 | 32K上下文输入 | 企业级安全隐私保护 | Sam Altman前往中东寻求千亿美元融资</summary><br>

<a href="https://www.youtube.com/watch?v=c5qUwar9tMA" target="_blank">
    <img src="https://img.youtube.com/vi/c5qUwar9tMA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】ChatGPT Enterprise企业版正式发布 | 无限制访问GPT-4 | 32K上下文输入 | 企业级安全隐私保护 | Sam Altman前往中东寻求千亿美元融资

好的，我來幫您整理這篇文稿。我會重點整理內容概要、核心觀點，並將文稿分段，使其結構更清晰，更易於閱讀。

**整理後的文稿：**

**標題：OpenAI推出ChatGPT企業版：最強版本？B端市場全面進攻號角吹響？**

**概要：**

本文介紹OpenAI最新推出的ChatGPT企業版，分析其功能升級、企業級應用、以及對B端市場的影響。同時探討OpenAI面臨的商業壓力與未來的發展方向，並引用業界觀點，分析企業選擇大模型時的考量因素。

**主要內容：**

**一、ChatGPT企業版發布：最強版本的功能升級**

*   **速度更快、無限制存取GPT-4：** 提供更快的速度、無使用上限地訪問GPT-4模型。
*   **更大的上下文窗口：** 擁有32,000個token的上下文窗口，可處理更長的輸入、文件，約等於24,000個單詞。
*   **無限制的高級數據分析：** 無限制訪問程式碼解釋器，加速金融研究、市場分析等數據處理工作。
*   **企業級安全與隱私：**
    *   企業擁有並控制數據，OpenAI不進行訓練或學習。
    *   數據保留時間可設定，符合SOC 2標準。
    *   採用AES 256算法加密靜態數據，TLS 1.2+加密傳輸數據。
*   **管理功能：** 具備專用管理控制台，便於批量成員管理、域驗證、SSO和使用情況分析。
*   **客製化功能:** 允許企業進行客製化，並擁有私有的客製化模型使用權。

**二、OpenAI B端市場戰略與商業壓力**

*   **全面進攻B端市場：** ChatGPT企業版是OpenAI正式向B端市場全面進攻的訊號。
*   **企業版客戶：** 內測客戶包括Block、Canva、雅詩蘭黛等知名企業。
*   **商業壓力：** OpenAI面臨流量下降、成本高昂等商業壓力，亟需擴展B端市場營收。
*   **融資需求：** 山姆·奧特曼尋求中東財團融資，規模不低於1000億美元，目標是實現Super intelligence。

**三、業界觀點：B端大模型市場趨勢分析**

*   **光速創投合夥人古魯查哈爾（Guru Chahal）的觀點：**
    *   企業初期探索使用大型模型，後期轉向小型、專業化、微調模型。
    *   人工智能模型分為巨腦模型（OpenAI）、挑戰者模型（Llama 2）、長尾模型三種類別。
*   **企業選擇模型考量因素：**
    1.  數據隱私與合規要求。
    2.  能否進行模型微調。
    3.  是否達到企業期望的推理性能水平（延遲、準確性、成本）。
*   **ChatGPT企業版分析：** 數據需交由OpenAI處理，微調可透過OpenAI推出的微調介面實現，成本需視具體商務談判情況而定。

**四、OpenAI未來展望**

*   **計劃推出的功能：**
    1.  自定義數據來源，連接企業應用程式。
    2.  為小型團隊提供自助式ChatGPT商務服務。
    3.  更強大的高級數據分析與瀏覽版本。
    4.  為數據分析師、行銷人員、客戶支援等提供更多工具與解決方案。
*   **競爭態勢：** 雖然GPT-4仍領先，但其他大模型差距正在縮小。

**五、總結與討論**

*   OpenAI企業版的推出顯示其技術實力與商業壓力。
*   企業選擇使用ChatGPT企業版需綜合考量。
*   OpenAI的未來發展充滿變數，Super intelligence目標遙遠。

**如果您覺得需要調整，請隨時告訴我！**

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>177. [2023-08-29] 【AWS】Amazon计划明年推出IPv4新价格 | 43亿IPv4地址四年前已耗尽 | IPv6为何普及不高</summary><br>

<a href="https://www.youtube.com/watch?v=9TF9b7ZWvnk" target="_blank">
    <img src="https://img.youtube.com/vi/9TF9b7ZWvnk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AWS】Amazon计划明年推出IPv4新价格 | 43亿IPv4地址四年前已耗尽 | IPv6为何普及不高

好的，我将按照您的要求，整理您提供的文稿。我将主要关注以下几个方面：

*   **结构化:** 将文稿按照逻辑分成几个部分，并添加小标题。
*   **精简语言:** 去除口语化的表达，使文稿更加书面化和精炼。
*   **提取重点:** 突出文稿的关键信息。

以下是整理后的文稿：

**IPv4 地址耗尽与亚马逊收费政策**

**引言**

稀缺资源具有重要价值。对于云计算巨头亚马逊而言，公共 IPv4 地址亦是如此。亚马逊首席布道师 Jeff Barr 发布博客，宣布自 2024 年 2 月 1 日起，将对公共 IPv4 地址实行新的收费政策。

**IPv4 地址概述**

*   **定义：** IPv4，即互联网通信协议第四版，是网际协议的第四个修订版本，也是第一个被广泛部署的版本。它是一个用于识别互联网设备的 32 位编号。
*   **根服务器：** 全世界 IPv4 根服务器共有 13 台，1 个为主根服务器，位于美国；其余 12 个为辅根服务器，9 个在美国，2 个在欧洲（英国和瑞典），1 个在亚洲（日本）。
*   **资源耗尽：** 由于智能手机、个人电脑和物联网设备的爆发性增长，IPv4 地址已近消耗殆尽。2019 年，欧洲网络协调中心 (RIPE NCC) 宣布所有 IPv4 地址已分配完毕。

**IPv4 地址的现状与获取途径**

虽然 IPv4 地址已分配完毕，但并非完全不能再用。用户主要通过回收和释放的未使用地址段获取 IPv4 地址，这些地址要么来自倒闭的组织，要么来自迁移到 IPv6 后不再需要的地址。由于 IPv4 日益稀缺，获取过程变得复杂，成本也随之增加。

**亚马逊收费政策**

*   **背景：** 过去五年中，单个 IPv4 地址的获取成本上涨超过 300%。为了缩减成本，亚马逊决定对 IPv4 公网地址收费。
*   **政策内容：** 自 2024 年 2 月 1 日起，亚马逊将对所有公共 IPv4 地址按照每小时每个 IP 地址 0.005 美元的价格进行收费。收费适用于所有 AWS 服务和区域，包括商业性服务、AWS 中国和 GovCloud。
*   **费用计算：** 一个 IPv4 地址一年的费用约为 43.8 美元（按汇率约为 320 人民币）。
*   **例外情况：** 使用亚马逊的 BYOIP 服务（自带 IP 地址）无需支付费用。AWS 为 EC2 服务器提供免费套餐，包括前 12 个月每月 750 小时的公共 IPv4 地址使用时间。
*   **工具：** 亚马逊推出了公共 IP 洞察工具，帮助用户查看、排序和过滤使用的公共 IPv4 地址，并了解如何减少新费用。

**亚马逊推动 IPv6 应用的意图**

亚马逊推出收费政策的另一原因是推动 IPv6 地址的应用。

*   **IPv6 优势：** IPv6 采用 128 位寻址，可提供海量地址。它还能更有效地处理数据包，提高性能和安全性。
*   **IPv6 推广缓慢的原因：**
    *   **兼容性问题：** IPv4 和 IPv6 协议不兼容，过渡成本较高。
    *   **NAT 技术：** NAT 技术缓解了 IPv4 枯竭的问题，但存在局限性。

**IPv6 的普及现状**

尽管全球未分配的 IPv4 地址已耗尽，但 IPv4 路由表中的条目数量仍远超 IPv6。有预测认为，全球可能需要 5-10 年才能真正放弃 IPv4 地址空间。一些国家 IPv6 普及率较高，但全球前 1000 个网站中能通过 IPv6 访问的仅占少数。

**结论**

亚马逊开始对公共 IPv4 地址增加收费，其他云计算厂商可能会很快跟进，这可能会促使和推动大家更换 IPv6 地址。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>176. [2023-08-28] 【国产】CEC-IDE | 号称自主研发 | 实则套皮开源 | 数字广东 | 究竟是谁在卡我们的脖子 | 汉芯 | 红芯浏览器 | 木兰编程语言</summary><br>

<a href="https://www.youtube.com/watch?v=fOpBEWZVKU0" target="_blank">
    <img src="https://img.youtube.com/vi/fOpBEWZVKU0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【国产】CEC-IDE | 号称自主研发 | 实则套皮开源 | 数字广东 | 究竟是谁在卡我们的脖子 | 汉芯 | 红芯浏览器 | 木兰编程语言

好的，我來幫你整理這篇文稿。為了使文稿更清晰、更結構化，我將其分為以下幾個部分：

**一、 引言與事件概述：**

*   **開場白：**「大家好，這裡是最佳拍檔，我是大飛。」
*   **新聞事件引入：**提到「國內首款自主創新的集成開發環境工具，俗稱IDE，發布了，叫做CEC-IDE」。大飛坦言最初並未太在意，因為類似的「標題黨」新聞司空見慣。
*   **IDE開發難度：**強調IDE開發的複雜性，指出全世界真正能做IDE的公司屈指可數，並列舉了VSCode、Eclipse、Intellij、XCode、Android Studio、PyCharm等知名IDE。

**二、 對CEC-IDE的質疑：**

*   **发布者背景：**指出来源是「数字广东网络建设有限公司」，認為是國企背景，結合「政務、信創」，推測可能是「騙錢的」。
*   **歷史案例：**聯想到過去的「漢芯」、「紅芯瀏覽器」、「木蘭編程語言」等事件，認為是類似的操作手法。
*   **官方宣傳內容分析：**
    *   使命：「做好數字政府創新應用的孵化器和技術管理的總抓手」。
    *   自主研發：质疑其真实性。
    *   多環境支持：認為支援麒麟、統信、Windows、Mac OS等多環境不應是核心功能，網路上許多小工具都能做到。
    *   功能：提供代码编写、智能辅助、编译调试、版本控制等功能, 以及自建插件市场 (1600余种插件). 认为插件数量过于夸张。
    *   提供Java/JavaScript/Python/C++/Go的工程创建脚手架和模板：認為腳手架模板非常簡單，不應算是IDE的核心功能。
    *   編碼智能輔助：懷疑只是簡單的程式碼補全，而非AI自動生成。
    *   自建程式碼倉庫：實際上就是Git。
    *   知識寶典：認為與IDE核心功能無關，只是湊數。
*   **CEC-IDE的優勢分析：**
    *   安全可控：质疑自主研发的真实性.
    *   政務賦能：批評政府數位化市場的亂象，認為許多政府單位不了解數位化的意義，只是為了政策和預算。承接項目的大多是大型IT公司，真正有技術實力的不多。
    *   多端支援：質疑多語言支持的必要性，認為國內公司很少做國際化。
    *   豐富靈活的插件資源：兼容VSCode插件，認為這是套殼VSCode的證據。

**三、 事件後續與反思：**

*   **網友扒皮：**讚揚網友的行動力，指出CEC-IDE使用了微軟的版權聲明，界面功能高仿VSCode，刪除了MIT協議聲明，還加入了會員登入功能。
*   **VSCode的Github事件：**提到中國網友在VSCode的Github專案地址下灌水，認為這種行為不妥。
*   **數字廣東的道歉聲明：**指出聲明承認使用開源VSCode進行改造，但又將責任歸咎於網友理解有問題。
*   **個人反思：**認為類似的「套皮」事件屢見不鮮，核心問題在於缺乏長遠的見識和投入，導致「吸血鬼」騙取經費。
*   **行业现状：**对中国IT技术环境表示失望，认为大量程序员没日没夜做出来的东西其实都是工业垃圾。

**四、 結尾與提問：**

*   **提問與猜測：**在經歷了芯片、瀏覽器、操作系統、IDE之後，下一個「套了皮」然後說自主創新的會是什麼？建議大家打賭猜測。
*   **問題與類比：**提問中國足球（男足）不行是被誰卡了脖子？
*   **結束語：**「好了，本期視頻內容就到這裡，感謝大家的觀看，我們下期再見。」

**總結：**

這篇文稿以輕鬆幽默的口吻，揭露了國內某些企業在「自主創新」旗號下，利用政府補助和項目經費，進行「套皮」行為的現象。作者對這種現象表示失望和批判，並引發人們對中國IT技術發展的深思。

**改進建議：**

*   **邏輯更清晰：** 雖然口語化可以增加親和力，但過多的口語化表達有時會影響邏輯性。可以適當增加一些更精煉的概括性語句，使觀點更明確。
*   **證據更充分：** 在批評CEC-IDE的具體功能時，可以提供更詳細的對比資訊，例如將CEC-IDE的界面與VSCode的界面進行對比，或者提供實際的操作演示，讓觀眾更直觀地了解問題所在。
*   **提出建設性建議：** 除了批判之外，可以適當提出一些建設性的建議，例如如何鼓勵真正的自主創新，如何監管政府的IT項目，如何提高中國IT技術的水平等等。
*   **結尾更升華：** 結尾可以更具啟發性，例如可以呼籲大家共同努力，為中國IT技術的發展貢獻力量。

希望這個整理和建議對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>175. [2023-08-26] 【AI】AI终会有意识 | 图灵奖得主Yoshua Bengio | 19人团队88页论文论证 | 没有技术障碍</summary><br>

<a href="https://www.youtube.com/watch?v=RhsSdh8RSgM" target="_blank">
    <img src="https://img.youtube.com/vi/RhsSdh8RSgM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】AI终会有意识 | 图灵奖得主Yoshua Bengio | 19人团队88页论文论证 | 没有技术障碍

好的，以下是經過整理的文稿，主要做了以下調整：

*   **精簡重複資訊：** 刪除一些為了口語表達而產生的重複字詞和語句。
*   **段落重組與分段：** 將內容按照邏輯關係重新分段，使閱讀更順暢。
*   **標點符號潤飾：** 修正標點符號的錯誤，使文稿更符合書面語規範。
*   **術語統一：** 對於重要的術語，確保全文使用一致的表達方式。
*   **用詞調整：** 替換一些口語化的詞彙，使文稿更正式。
*   **補充說明 (可選):** 如果必要，可以加入一些簡短的背景知識或解釋，以幫助讀者理解。

**整理後的文稿：**

大家好，這裡是最佳拍檔，我是大飛。

今年年初ChatGPT爆火時，我們曾擔心AI是否會發展出自我意識。然而，隨著各種大模型產品的出現，我們很快將注意力轉移到如何讓大模型落地、如何從中獲利，不再關注AI的未來。

值得慶幸的是，有人仍在關注這個議題。深度學習三巨頭之一、圖靈獎得主Yoshua Bengio及其19人團隊，在本週二發表了一篇長達88頁的論文，論證現有AI是否可能擁有意識。

這篇論文之所以重要，不僅因為Bengio的學術地位，更因為作者團隊來自人工智能、神經科學和哲學等領域，他們以科學嚴謹的方法探討了意識的客觀存在標準。可以說，這篇論文是對AI是否具有意識這一爭議話題，目前為止最權威和客觀的解答。

論文的結論是：目前並不存在擁有意識的AI，但以現有的技術條件，創造出有意識的AI基本不成問題。這不禁令人聯想到節目中介紹的遊戲AI智能體，它們是否已開始思考遊戲之外的世界，以及自身存在的意義？

究竟AI產生意識的這一天是否會到來？我們不妨先了解這篇論文的研究方法。

首先，關於「意識」的定義，學術界長期以來存在不同的看法。哲學家、神學家、語言學家和科學家對此概念進行了數千年的分析、界定、詮釋和辯論，但意識的本質至今仍未有統一的共識。

人工智能領域對人工意識的理解，也經歷了漫長的演進。20世紀以來，以艾倫·圖靈為代表的行為主義者，提出了最具影響力的意識定義，即著名的「圖靈測試」。如果測試者無法區分受測對象是人還是機器，則可認定機器通過圖靈測試，擁有意識。

行為主義將意識解釋為一系列可被外部觀察到的行為，但這種方法忽略了心理現象，也無法解釋智力產生原因，因此備受詬病。

後來，功能主義取代了行為主義，成為定義人工意識的主導理論。功能主義更關注大腦的功能，認為任何能夠模仿特定心理狀態與計算過程因果作用的事物，都可實現意識。功能主義不關心事物如何運作、由什麼材料組成，例如，只要能報時，任何東西都可被歸類為時鐘。

儘管功能主義也存在無法體現思考性等問題，但它仍然是當前人工智能領域衡量AI是否存在意識的主流依據。

美國哲學家、計算機科學家希拉里·普特南（Hilary Putnam）將功能主義與計算概念結合，提出了計算功能主義。計算功能主義認為，系統是否有意識，取決於比物理構成更抽象的特徵。系統的物質基礎對意識並不重要，意味著意識原則上是可以多重實現的，它可存在於多種基質中，而不僅僅是生物大腦。

大多數領先的意識科學理論都可以通過計算來解釋。具有這些計算特徵，就能認為意識存在。人類和人工智能系統之間的非計算差異並不重要。簡而言之，計算功能主義認為，精神世界基於使用信息、計算、記憶和反饋等概念的物理系統。

Bengio等人此次發佈的論文，正是以計算功能主義作為判斷AI有無意識的基礎依據。

確定基礎原則後，接下來進入「打分」環節。學界對意識的研究已有一些共識，例如科學家和哲學家對意識必要條件的主張。因此，這篇論文作者從過往對意識研究的成果中，選取一部分科學理論，作為判斷AI是否具有意識的更具體評估依據和指標。

論文主要介紹了循環加工理論（Recurrent Processing Theory, RPT）、全局工作空間理論（Global Workspace Theory, GWT）和計算高階理論（Computational Higher-Order Theories, HOT）三種理論。

以循環加工理論（RPT）為例，RPT理論是一個關注視覺意識的神经科学理論，試圖解釋意識視覺和無意識視覺處理之間的區別。其核心觀點是，為了產生視覺意識體驗，大腦視覺系統中的信息需要進行循環處理，即信息從高層區域反饋回低層區域進行再處理。該理論認為，僅依靠前饋的信息處理是不夠的，前饋處理只能提取視覺刺激的特徵信息，但不能形成有意識、有組織的視覺場景。需要頂層皮層對初級視覺皮層的反饋進行再處理，整合各種特徵信息，組織成有意義的視覺場景，才能產生視覺意識。

研究者將RPT理論具體拆分為RPT-1和RPT-2兩個指標：

*   **RPT-1：** 指“使用算法循环的输入模块”，即信息在經過初始前饋處理後，反饋回輸入模塊進行再處理。這顯示系統能進行循環處理。
*   **RPT-2：** 指“生成有组织、整合的感知表示的输入模块”，即系統能夠處理視覺輸入，整合各種特徵，組織生成有意義的視覺場景，而不僅是提取孤立特徵。

如果AI系統滿足這兩個指標，則說明它具有與人類大腦相似的循環處理機制，並且能夠形成整合的視覺表示，這使它更有可能擁有視覺意識。所以這兩個指標都可看作是AI系統視覺意識的重要指標。

全局工作空間理論（GWT）也是一個重要的意識科學理論。其核心觀點是，意識依賴於一個「全局工作空間」的存在。GWT理論認為，人腦由多個專門的子系統或模塊組成，可以並行地進行各自的信息處理。這些模塊需要某種機制來統合信息，進行協調配合。「全局工作空間」就是這樣一個信息共享和融合的平台。一個信息如果進入這個工作空間，就可以被所有的模塊訪問，但工作空間的容量是有限的，需要選擇機制來確定哪些信息進入工作空間。GWT理論認為，一個信息進入工作空間，被廣泛的模塊訪問，就是該信息進入意識狀態的標誌。

GWT理論為判斷AI的意識提供了四個指標：

*   **GWT-1：** 擁有多个专门的子系统或模块。
*   **GWT-2：** 有限容量的工作空间，形成信息流的瓶颈。
*   **GWT-3：** 全局广播，工作空间的信息可被所有模块访问。
*   **GWT-4：** 状态依赖的注意机制，可以顺序调动模块完成复杂任务。

如果AI系統具備這些特徵，就更有可能具有類似人類的意識，所以這些都是判斷AI意識的重要指標。

計算高階理論（HOT）是關於意識的一個重要理論流派。其核心觀點是，有意識的體驗包含了對自身正在進行的心理運作的最低限度的内在意识。這是由於一階狀態在某種程度上受到了相關高階表徵的監控或者元表徵所導致的。高階理論與其他理論的區別在於，高階理論強調主體必須意識到自己處於某種精神狀態中，這種精神狀態才被認為是有意識的。這是通過訴諸高階表徵來解釋的。高階表徵是指表徵關於其他表徵的東西，而一階表徵是指表徵關於非表徵的東西。

這種區別可以應用於心理狀態。例如，紅蘋果的視覺表徵是一種一階心理狀態，而認為自己擁有紅蘋果表徵的想法，則是一種高階心理狀態。

HOT理論為判斷AI的意識也提供了四個指標：

*   **HOT-1：** 具有生成式、頂層驅動或者帶噪聲的感知模塊。
*   **HOT-2：** 通過元認知監測來區分可靠感知和噪聲。
*   **HOT-3：** 一個全面的信念形成和行動選擇系統，依據元認知監測來更新信念。
*   **HOT-4：** 一個稀疏和平滑的編碼形成「質感空間」。

如果AI系統具備這些特徵，那麼它更可能具備自我監測和意識體驗。通過檢測系統是否具備這些特徵，我們可以評估一個AI系統擁有意識的可能性。

論文中還詳細列出了用到的其他科學理論指標，包括注意力基模理論（Attention Schema Theory）、預測處理（Predictive Processing）和代理與具身化（Agency and Embodiment）等。

當然，這一步並不是真的去給一個AI打分，而是要看這個AI能夠同時滿足以上多少指標。研究者也指出，判斷AI有無意識並沒有絕對的答案。一個AI系統可能是部分有意識的，或者既不是完全有意識的，也不是完全無意識的。許多屬性具有“模糊”的邊界。

此外，論文中也提到，此次研究使用了偏理論的研究方法，這和計算功能主義的原則相符。偏理論指的是去評估AI是否滿足科學理論指標中的功能或者架構條件，而不是去尋找它們某些具體的行為特徵。作者們認為，“對於AI意識研究來說，一種重理論的方法是必要的，重理論的方法是專注於系統如何工作，而不是它們是否顯示出可能被視為有意識存在特徵的外在行為形式”。

以上便是這篇論文用到的研究方法。

論文的下半部分也提到了一些具體的研究案例，來體現判斷特定的AI系統是否具有意識的研究過程，其中包括了基於Transformer的大語言模型和Perceiver架構，還分析了DeepMind的Adaptive Agent和谷歌的PaLM-E。其中Adaptive Agent是一個在3D虛擬環境中運行的強化學習智能體，而PaLM-E是一個經過訓練可以操縱機器人的多模態視覺語言模型。

不過，最終結果顯示，這些AI系統並沒有體現出非常明顯的有意識的傾向。

同時，論文研究者也寫道，我們研究的證據表明，如果計算功能主義是正確的，有意識的AI系統實際上可以在近期內建立起來。

按照論文作者們自己的說法，這篇論文主要有三點貢獻：

*   證明了對人工智能的意識進行評估在科學上是可行的，因為可以對意識進行科學研究，而且這項研究的結果也適用於人工智能。
*   通過一系列從科學理論中得出的指標特徵的形式，提出了評估人工智能中的意識的標準。
*   儘管當前AI系統都不是意識有力的候選者，但是初步證據證明，許多指標特徵可以利用當前的技術在AI系統中實現。

論文發表後，英偉達首席AI科學家Jim Fan第一時間便轉發了這一消息，並表示了他對研究團隊的敬佩。他贊揚研究團隊有勇氣去解決大多數研究人員都會迴避的爭議性話題。

事實上，作為世界級的人工智能專家和深度學習先驅，Bengio近年來的研究課題，許多都和人工智能的意識問題相關。2017年，他曾在arXiv上發佈過一篇題為《意識先驗》（The Consciousness Prior）的文章。2019年的NeurIPS大會上，他又發表了《從System 1深度學習到System 2深度學習》的主題演講，提出深度學習正在從直觀的、無意識的靜態數據集學習，向具有意識、推理和邏輯的新型架構研究轉變。而在今年3月，Bengio也參與了反對各家人工智能實驗室搞AI“軍備競賽”、要求暫停至少6個月比GPT-4更強大模型研發的運動。兩個月後，他又發表了一篇系統分析“危害人類的AI是如何出現的”的文章，直到這次聯合發表這篇長達88頁的論文，Bengio一直都在不遺餘力地警醒大家AI的未來該向何處去。

正如這篇論文裡寫到的，這篇報告還遠未對AI有無意識的話題做出最終定論，作者強烈建議支持對意識科學及其在AI中應用的進一步研究，並呼籲社區應儘快將建立有意識的AI系統的道德和社會風險納入考量。

總結來說，我認為這篇論文的意義在於，它以一種相對科學的分析方式，證明了AI存在意識的可能性，甚至可以說是預言了它的到來，從而讓我們更早地能準備面對這個情況。我們既不能過度漠視AI存在意識的可能性，那樣可能會導致人類對AI的使用就像虐待動物一樣，造成道德風險；也不能過度認為AI具有意識，從而導致資源過度向AI分配。所以，如何對待AI，是整個人類需要思考和面對的問題。就像造物主一樣，你造出了一個新物種，你該如何看待它呢？是視它為螻蟻還是視它為同類？是可以輕易地抹去它，還是要努力培育它的發展呢？

歡迎大家在評論區發表自己的看法。感謝大家的觀看，我們下期再見。

**額外建議：**

*   **目標讀者：** 整理時請考量目標讀者的知識背景。如果讀者不熟悉AI或哲學概念，可以增加更多解釋。
*   **格式調整：** 可以使用標題、副標題、項目符號等格式，使文稿更易於瀏覽。
*   **內容驗證：** 確保文稿中的資訊準確無誤，特別是關於科學理論的部分。
*   **可視化輔助：** 如果可能，可以加入圖表或圖片，以更生動地呈現複雜的概念。

希望這個整理結果對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>174. [2023-08-25] 【Meta】Meta开源代码生成模型 Code Llama | Llama 2家族 | 效果直逼GPT-4 | 免费可商用</summary><br>

<a href="https://www.youtube.com/watch?v=Wr6-bf_e8c0" target="_blank">
    <img src="https://img.youtube.com/vi/Wr6-bf_e8c0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Meta】Meta开源代码生成模型 Code Llama | Llama 2家族 | 效果直逼GPT-4 | 免费可商用

好的，我將這篇文稿整理如下，重點提取並調整了結構，使其更清晰易讀：

**標題：Meta 開源 Code Llama：專攻程式碼生成的 Llama 2 升級版**

**核心重點：**

*   Meta 發布了 Code Llama，這是一個基於 Llama 2 的程式碼生成基礎模型，可免費用於研究和商業用途。
*   Code Llama 系列有 7B、13B 和 34B 三個參數版本，支援多種程式語言（Python、C++、Java 等），最高可穩定支援 10 萬 token 的上下文生成。
*   Code Llama 的性能優於其他開源的程式碼專用模型，甚至接近 GPT-4 的水平。

**詳細說明：**

1.  **Code Llama 的能力：**

    *   **程式碼生成：** 根據程式碼或自然語言提示生成程式碼。
    *   **程式碼補全與除錯：** 協助使用者進行程式碼補全和除錯。
    *   **Fill-in-the-middle 訓練：** 7B 和 13B 模型經過此訓練，可將程式碼插入到現有程式碼中，支援即時程式碼補全等任務。

2.  **Code Llama 的版本：**

    *   **7B、13B、34B：** 滿足不同的服務和延遲要求。7B 模型可在單個 GPU 上運行，34B 模型提供最佳結果，但速度較慢。
    *   **Code Llama-Python：** 在 Python 程式碼上進一步微調的版本。
    *   **Code Llama-Instruct：** 指令微調和對齊變體，能更好地理解輸入提示，建議用於生成程式碼。

3.  **Code Llama 的性能：**

    *   在 HumanEval 和 MBPP 兩個編碼基準上進行測試。
    *   性能優於開源的程式碼專用模型和 Llama 2，與 ChatGPT 相當。

4.  **Code Llama 的風險與安全性：**

    *   Meta 評估了生成惡意程式碼的風險，結果顯示 Code Llama 的回答更安全。

5.  **Meta 對 Code Llama 的發展路線圖：**

    *   **高級語言支持：** 擴展對更多程式語言的支援。
    *   **增強上下文理解：** 深入理解開發者的意圖，提供更相關的建議。
    *   **與開發平台整合：** 與 IDE 和文本編輯器相容。
    *   **持續投入 AI 研究：** 提高性能與準確性。

**總結：**

Code Llama 的發布填補了 Llama 2 在程式碼能力上的不足。目前已開源，並且可以在 Perplexity 的聊天工具中使用。Code Llama 具備快速的響應速度和強大的程式碼生成能力，值得開發者嘗試。

**補充說明：**

*   以上整理提取了文稿的主要資訊，使其更易於理解和查閱。
*   可以根據具體需求，對內容進行更深入的分析和擴展。
*   我已將原文中的口語化表達盡可能地轉換為更正式的書面語。

希望這個整理對您有所幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>173. [2023-08-25] 【Office】微软EXCEL重大升级 | 原生支持Python | 可视化分析 | 机器学习 | 数据处理 | Anaconda | Microsoft 365</summary><br>

<a href="https://www.youtube.com/watch?v=cYpBDZbrvLA" target="_blank">
    <img src="https://img.youtube.com/vi/cYpBDZbrvLA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Office】微软EXCEL重大升级 | 原生支持Python | 可视化分析 | 机器学习 | 数据处理 | Anaconda | Microsoft 365

好的，我將盡力為您整理這篇文稿。我會著重於提取重點、組織結構，並保持原文的語氣。

**整理後的文稿：**

**標題：Excel原生集成Python：數據分析的革命性變革**

**引言：**

大家好，這裡是最佳拍檔，我是大飛。微軟重磅宣布，Python原生集成到Excel公共預覽版中！無論是數據分析師、工程師、行銷人員，還是學生，都可以直接使用Python代码、庫，在Excel中執行複雜的統計分析、高級可視化、預測分析和機器學習。

**一、Python in Excel的關鍵特性：**

*   **無需下載任何軟體：** 直接在Excel單元格中輸入`=PY`函數，即可使用Python代碼。
*   **數據導入靈活：** 可使用Excel的內置連接器和Power Query導入外部數據。
*   **兼容原有工具：** 兼容Excel公式、數據透視表和圖表。
*   **基於Anaconda發行版：** 利用Azure中運行的Python Anaconda Distribution，由Anaconda提供安全的構建、測試和支持。
*   **雲端安全運行：** Python代碼在微軟雲上運行，計算結果返回到工作表中，保證企業級安全性。
*   **團隊協作無縫：** 團隊成員可無縫交互並刷新分析結果，無需擔心環境配置和依賴關係。

**二、Python in Excel的主要用途：**

*   **可視化：** 使用Matplotlib和seaborn等Python庫創建多種圖表。
*   **機器學習、預測分析：** 利用scikit-learn和statsmodels等庫進行回歸分析、時間序列建模等。
*   **數據清理：** 使用Python數據清理技術處理缺失值、標準化格式、刪除重複項等。

**三、如何體驗Python in Excel：**

*   **適用對象：** Microsoft 365 Insiders (Windows平台，內部版本16818開始)
*   **步驟：**
    1.  選擇功能區中的“公式”。
    2.  選擇“插入Python”。
    3.  在對話框中選擇“嘗試預覽”按鈕。

*   **授權：** 預覽期間包含在Microsoft 365訂閱中，預覽結束後部分功能可能需要付費許可證。

**四、Python in Excel背後的故事：**

*   Python之父吉多·范羅蘇姆（Guido van Rossum）加入微軟開發者部門，參與定義了Excel中Python的架構。

**五、總結與展望：**

*   Excel已支持多種程式語言，這次引入Python可能成為壓死VBA宏的最后一根稻草，並進一步提升Python語言的市场占有率和普及度。
*   微軟希望將整個辦公軟體套件往更加智能化的方向打造。

**結語：**

大家對於Excel原生集成Python有什麼看法？對於你來說是否有用呢？歡迎在評論區分享你的想法。感謝大家的觀看，我們下期再見！

**整理說明：**

*   **結構化：** 將文稿分為引言、關鍵特性、用途、體驗方式、幕後故事、總結等部分，方便閱讀。
*   **提煉重點：** 著重於介紹Python in Excel的功能、用途和優勢。
*   **保持原文語氣：** 保留了「大飛」的口語化表達方式，使其更貼近影片風格。
*   **關鍵詞加粗：** 對於重要的概念和詞語進行加粗，方便快速瀏覽。

希望這個整理後的文稿能滿足您的需求!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>172. [2023-08-24] 【OpenAI】GPT-3.5 Turbo开放微调API | FineTuning | 人人可打造专属ChatGPT | GPT-4版本即将推出</summary><br>

<a href="https://www.youtube.com/watch?v=hYAOx-zQ62k" target="_blank">
    <img src="https://img.youtube.com/vi/hYAOx-zQ62k/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】GPT-3.5 Turbo开放微调API | FineTuning | 人人可打造专属ChatGPT | GPT-4版本即将推出

好的，以下是經過整理後的文稿，主要針對結構、重點和可讀性進行了優化：

**標題：OpenAI 重大更新：GPT-3.5 微調 API 開放與 GPT-4 微調即將推出**

**開場白：**

大家好，這裡是最佳拍檔，我是大飛。今天想跟大家聊聊 OpenAI 最近頻繁的更新，特別是關於 GPT-3.5 微調 API 的開放，以及 GPT-4 版本即將推出這兩件事。這可以說是 OpenAI 自「插件應用商店」以來最大的產品更新，它讓每個人都能打造自己的個性化「類 ChatGPT 應用」。這次更新可以說是有史以來最大的 LoRA 雲服務。

**微調概念：**

既然這次更新跟微調有關，我們先從一些簡單的微調概念出發。

*   **什麼是微調？** 微調指的是基於已經訓練好的語言模型，使用小規模、特定的數據集繼續訓練它，讓它更適應於特定的任務或領域。

**概念釐清：微調、提示工程、嵌入、智能體**

AI領域的概念繁多且抽象，容易讓人感到困惑。我們用比喻來解釋這些概念：

*   **大語言模型：** 比喻為已訓練好的家政阿姨，懂中文，會做家務，但不了解你家情況。

    *   **微調：** 就像阿姨第一次到你家，你花一小時告訴她物件擺放、哪些地方不能動等。
    *   **嵌入：** 就像在家裡貼滿紙條，阿姨照著紙條指示做事，省去二次培訓。
    *   **提示工程：** 就像你給阿姨的指令，包含背景資訊，讓阿姨理解並做出回應。重點是指令不能太長，因為阿姨記性不好（上下文窗口長度限制）。
    *   **智能體：** 就像阿姨請人修電視，這個修電視的人就是智能體，幫助大語言模型處理它能力之外的事。

*   **用大學生考試來比喻：**

    *   **提示工程：** 考試題目，提供背景知識和要求。
    *   **微調：** 考試前突擊，讓學生記住指定格式的問題和答案。
    *   **嵌入：** 考試時帶筆記本，遇到問題先翻看筆記。
    *   **智能體：** 考試時用計算器，解決不會算的問題。

**微調的好處：**

1.  **縮減 Prompt 的長度：** 省去 one-shot、few-shot 例子或格式描述，但成本可能更高，除非能達到 GPT-4 的效果。
2.  **效果更好：** 針對私有數據微調，效果優於單純 Prompt。
3.  **格式穩定：** 穩定輸出特定格式，如代碼生成、JSON 格式、特定語言。
4.  **降低請求延遲：** Prompt 變短，或使用微調後的 GPT-3.5 而非 GPT-4。

**微調的潛在問題：**

*   **影響其他任務：** 微調可能影響模型在其他任務上的表現，需要測試數據集。
*   **無法解決幻覺：** 無法解決 ChatGPT 胡說八道的問題。

**微調的其他考量：**

*   **隱形成本：** 數據集品質、格式整理、測試數據集準備、多次微調的試錯成本。
*   **數據安全：** 數據安全要求高的企業，需考慮將模型託管在 OpenAI 的風險。
*   **OpenAI 的審查：** 無法通過微調做違法的事情。

**適合使用微調的場景：**

1.  **需要穩定輸出特定格式、風格：** 如 GitHub Copilot 的代碼生成、OpenAI 微調的 Function Calling、模仿名人或动漫角色的風格。
2.  **需要在 Prompt 中放入更多內容：** 將原本放在 Prompt 中的示例作為微調的數據集，節省 Tokens。
3.  **大語言模型能力不足的任務：** 讓大語言模型產生新的能力，如 OpenAI 的 ChatGPT、Function Calling，或是生成未訓練過的語言代碼或行業數據。

**微調的具體價格：**

*   分為初始訓練成本和使用成本。
*   訓練：每 1 千 token 0.008 美元。
*   使用輸入：每 1 千 token 0.012 美元。
*   使用輸出：每 1 千 token 0.016 美元。
*   微調的 GPT3.5 Turbo 生成成本是基本模型的 8 倍。
*   每個訓練示例限制為 4096 個 token。
*   每個文件當前限制為 50MB。

**OpenAI 官方 GPT-3.5 Turbo 微調步驟（簡述）：**

1.  準備數據（對話數據，有監督微調 SFT）
2.  上傳文件（API 接口，curl 命令示意）
3.  創建微調任務
4.  通過 API 調用使用微調後的模型

**OpenAI 未來計畫：**

*   推出微調 UI，包含儀表板。
*   支援函數調用和 GPT-4、gpt-3.5-turbo-16k 微調。

**總結與討論：**

大家對 OpenAI 這次開放微調有什麼看法呢？歡迎在評論區留言。

**結尾：**

感謝觀看本期節目，我們下期再見。

**修改說明：**

*   **標題：** 更明確點出重點。
*   **結構：** 明確區分概念、好處、問題、場景等，讓觀眾更容易理解。
*   **比喻：** 保留並突出比喻，使抽象概念更易懂。
*   **簡述：** 對 OpenAI 的具體步驟進行簡述，抓住重點。
*   **結尾：** 保留互動，鼓勵留言。
*   **用字遣詞：**  盡量使用更精確、更通俗易懂的語言。

希望能幫助您更好地整理文稿！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>171. [2023-08-22] 【AI】OpenAI的超级对齐究竟要干什么 | 团队负责人Jan Leike访谈深度解析 | 4年内解决超级对齐 | 一盘大棋还是噱头 | 对齐AI的自我升级迭代 | 算力即对齐 | 是否会产生AGI</summary><br>

<a href="https://www.youtube.com/watch?v=XRvjoQWtlHU" target="_blank">
    <img src="https://img.youtube.com/vi/XRvjoQWtlHU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】OpenAI的超级对齐究竟要干什么 | 团队负责人Jan Leike访谈深度解析 | 4年内解决超级对齐 | 一盘大棋还是噱头 | 对齐AI的自我升级迭代 | 算力即对齐 | 是否会产生AGI

好的，這是我整理後的文稿，我將其重點歸納、分點整理，使其更易於理解。

**標題：OpenAI 超級對齊計畫深度解析：通往 AGI 的關鍵？**

**前言：**

*   本期節目探討 OpenAI 的「超級對齊（Superalignment）」計畫，可能顛覆對 AI 的既有觀念。
*   目標是確保超級智能與人類價值觀一致，解決潛在風險。

**背景：**

*   OpenAI 承諾將 20% 的計算資源投入「對齊超級智能」，成立「超級對齊」團隊。
*   團隊由 Ilya Sutskever 和 Jan Leike 領導。
*   Jan Leike 近期訪談揭露更多細節。

**核心概念：超級對齊的重要性**

*   超級對齊不是噱頭，而是極其重要的任務。
*   下一個 AGI 可能由此誕生。
*   關鍵在於訓練一個大致和人類水平一樣的自動對齊程序，讓它來尋找對齊超級智能的辦法。

**OpenAI 的思路轉變：**

*   **舊思路：** 先訓練聰明的大模型，再學習對齊（遇到瓶頸）。
*   **新思路：** 先訓練知道什麼是對齊的 AI，再讓它訓練完全符合對齊的 AI。

**為什麼要用 AI 來做對齊？**

*   人工對齊成本高、無法規模化。
*   人類無法監督超越自身水平的任務。

**超級對齊團隊的目標與方法：**

*   目標：四年內解決超級對齊問題。
*   **可擴展監督（scalable oversight）：** 使用 AI 輔助人類評估困難任務（辯論、遞歸獎勵建模等）。
*   **整體思路：**
    *   將對齊拆解為小任務，讓 AI 從中學習迭代。
    *   參考《Let's Verify Step by Step》論文，基於過程的反饋訓練獎勵模型。
    *   最終目標：找到自動對齊的方法。

**實現自動對齊：**

*   投入更多計算資源。
*   把算力變成對齊。
*   通過迭代，產生完全符合對齊的、更智能的 AI（類似 AlphaGo 自我博弈）。

**如何實現人類水平的對齊 AI？**

*   **重點：** 構建自動化、全面化的評估系統（可提供監督反饋）。
*   **可擴展監督：**
    1.  驗證模型達到人類水平（自動化）。
    2.  進行魯棒性檢測、可解釋性分析（探究更高維度的可解釋性）。
    3.  進行對抗測試（驗證評估方法的有效性）。

**Jan Leike 擔心的問題：**

*   系統性撒謊和欺騙。
*   自我渗透（逃逸安全措施、複製自身）。

**超級對齊團隊的規劃：**

*   未來 4 年：
    *   組建 30-100 人團隊。
    *   投入 OpenAI 20% 的算力。
    *   前 2 年：搞清楚用什麼技術實現 AI 對齊。
    *   第 3 年：實現對齊 AI。
    *   第 4 年：探索超級對齊。

**Jan Leike 的信心來源：**

1.  語言模型的成功。
2.  RLHF 的效果超出預期。
3.  在評估度量方面取得進展。
4.  評估比生成更簡單。
5.  對語言模型的信念。

**目前技術的局限性：**

*   預測下一個 token 不是長期目標。
*   RLHF 監督信號來自人工，無法規模化。
*   預訓練 + RLHF 可能只是 AI 發展的過渡版本。

**OpenAI 的最終目標：**

*   自動化、規模化且自動對齊。
*   通過迭代，AI 開始遞歸式的自我提升。
*   這可能就是通往 AGI、超級智能的道路。

**總結：**

*   超級對齊是 OpenAI 的工作重心。
*   一旦實現自動對齊，OpenAI 將在對齊方面領先。
*   未滿足對齊要求的模型將難以滿足人類社會、安全及監管的要求。

**備註：**

*   這份整理基於講者的理解，可能存在偏差。
*   歡迎在評論區交流對超級對齊的看法。

**附加建議：**

*   可以考慮在文章中加入一些視覺元素，例如流程圖、概念圖等，幫助讀者更好地理解 OpenAI 的超級對齊計畫。
*   可以添加一些額外的例子，說明超級對齊在實際應用中的意義。
*   可以進一步探討超級對齊可能帶來的倫理和社會影響。

希望以上整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>170. [2023-08-20] 【AI】十年「AI for Science」发展综述 | 人工智能如何助力科学研究 | 图灵奖Yoshua Bengio团队 | 《Nature》杂志发表 | 是否要投身AI for Science</summary><br>

<a href="https://www.youtube.com/watch?v=ztsE_tgclj4" target="_blank">
    <img src="https://img.youtube.com/vi/ztsE_tgclj4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】十年「AI for Science」发展综述 | 人工智能如何助力科学研究 | 图灵奖Yoshua Bengio团队 | 《Nature》杂志发表 | 是否要投身AI for Science

好的，以下是整理後的文稿，主要針對內容進行提煉、分層，並修正了一些語氣，使之更像一篇結構化的文章或報告：

**AI for Science：人工智能助力科学发现的十年跨界秀**

**引言**

大家好，这里是最佳拍档，我是大飞。

近年来，约书亚·本杰奥（Yoshua Bengio）团队展示了一场人工智能十年跨界秀，标志着AI正在深刻地改变科学研究的方式，成为科学发现的引擎。无论是牛顿的万有引力定律、爱因斯坦的相对论，还是运用计算机模拟蛋白质折叠，“AI for Science”的核心就是如何“借助AI推动科学发现、科技进步”。

**论文核心观点**

这篇发表在Nature综述文章中的论文，主要关注AI如何助力科学发现。作者们认为，尽管科学实践因研究阶段而异，但AI的发展跨越了传统上孤立的学科，融入科学发现的各个阶段，包括假设形成、实验设计、数据收集与分析。论文审视了过去十年的人工智能技术突破，详解了自监督学习、几何深度学习、生成式人工智能等技术在科学研究中的应用，并提出了目前AI跨界仍然存在的核心问题。

**科学实践的三大阶段及AI的作用**

作者将科学实践流程大致划分为三个相互关联、递进循环的阶段：

1.  **假设构建：** AI大规模探索候选假设以形成理论、生成假设，并估计其不确定性。
2.  **实验设计：** AI优化实验参数和功能。
3.  **数据收集与分析：** AI自动化数据的收集、处理和可视化。

**AI在各阶段的方法和应用**

**1. AI辅助的科研数据收集与整理**

*   **数据选择 (Data Selection)：** 利用异常检测算法，识别并舍弃背景噪音，保留稀有且有价值的信息数据。例如，在粒子碰撞实验中，实时识别并舍弃超过99.99%的原始数据。
*   **数据标注 (Data Annotation)：** 利用半监督学习方法，在只有少量准确注解的大型无标签数据集上进行自动标注。例如，伪标签法（Pseudo Labelling）、标签传播法（Label Propagation）、主动学习法（Active Learning）。
*   **数据生成 (Data Generation)：** 通过自动数据增强和深度生成模型，生成额外的合成数据点来扩充训练数据集。例如，生成式对抗网络GAN在多个领域中生成逼真且有用的数据，如粒子碰撞事件、病理切片、胸部X光等。
*   **数据精细化 (Data Refinement)：** 利用深度卷积网络和自编码器，提高测量分辨率，减少噪声，并减小测量精度的误差。例如，黑洞成像、捕捉物理粒子碰撞、提高活细胞图像的分辨率以及细胞类型检测。

**2. 深度学习在科学数据表示中的应用**

深度学习能够在多层次上提取科学数据的有价值表示，并通过端到端的学习来优化这些表示用于指导研究。研究人员介绍了三种满足这些要求的新兴策略：

*   **几何先验：** 有效地捕捉数据的几何和结构特征，特别是对称性。
*   **自监督学习：** 使用无标注数据来学习一般特征，例如预测图像的遮挡区域、预测视频的前后帧，以及通过对比学习让模型区分相似和不相似数据点。
*   **语言建模：** 学习自然语言和生物序列的特征，例如蛋白质语言模型可以编码氨基酸序列，捕捉它的结构和功能特性，并评估病毒变异的进化适应性。

**3. AI辅助的科学假设生成**

AI可以通过从噪声观测中识别出候选的符号表达式来生成假设，也能帮助设计物体，例如一个能与治疗目标相结合的分子，或者是一个可以推翻数学猜想的反例。AI还可以学习假设的贝叶斯后验分布，并利用这个分布生成与科学数据和知识相吻合的假设。作者总结了AI提出假设的三种方式：

*   **黑箱预测器：** 通过快速筛选候选假说，选择有价值的进行后续验证。
*   **导航组合假说空间：** 使用强化学习评估每次搜索的回报，聚焦在最有前景的假说要素上。
*   **优化可微假说空间：** 将离散假说空间映射到连续可微空间进行优化。

**AI for Science的挑战和展望**

人工智能系统可以成为科学家发现新知识的重要助手，但也存在潜在的安全隐患。例如，科学数据存在不完整、偏差等问题，需要规范化。此外，还需要考虑数据的可访问性、隐私等。

其他挑战包括：

*   **分布偏移：** 需要增强模型的泛化能力。
*   **多模态数据处理：** 如何系统地整合科学知识和原理。
*   **模型解释性和可信度：** 增强模型的解释性和可信度。
*   **人才和资源：** AI专业人才短缺和计算资源需求巨大。

**AI for Science的学术和商业前景**

*   **学术前景：** “AI for Science”的学术前景广阔，例如AlphaFoldv2的影响力远超AlphaGo。
*   **商业前景：** 在材料研发、基因编辑、天气预报、核聚变反应控制以及农业收成预测等领域，AI都有可能实现革新性的创新。

**个人职业发展建议**

对于想从事AI for Science的同学来说，首先读计算机、AI方向的PhD本身就是一个成本很大的事情，其次AI for Science这个方向在大厂里并不是很受待见。因此，比较适合先在顶级大学里能自己支个摊儿，然后与各个社区多合作、与业界大牛搞好关系，遇到合适的机会再去搞创业startup。

**总结**

AI for Science的想象力空间巨大、发展势头良好，但是否要躬身入局，还是要结合自身情况，量力而行。

**结语**

好了，以上就是本期视频的内容。感谢大家的观看，我们下期再见。

**改进说明：**

*   **结构化：** 使用了更清晰的标题和小标题，使内容更易于阅读和理解。
*   **提炼核心观点：** 更加突出论文的核心观点和结论。
*   **专业语气：** 避免口语化表达，使用更正式的语言。
*   **逻辑性：** 增强了论述的逻辑性，使各部分内容之间的关系更加清晰。
*   **删除冗余信息：** 移除了部分重复或不必要的句子。

希望这个整理版本能满足您的需求！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>169. [2023-08-20] 【科学】脑机接口治愈16年抑郁症 | 脑起搏器 | 电极刺激神经核团 | 上海瑞金医院 | 孙伯民</summary><br>

<a href="https://www.youtube.com/watch?v=J3LAuwB0G_c" target="_blank">
    <img src="https://img.youtube.com/vi/J3LAuwB0G_c/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【科学】脑机接口治愈16年抑郁症 | 脑起搏器 | 电极刺激神经核团 | 上海瑞金医院 | 孙伯民

好的，我將上述文稿整理如下，主要著重於結構、重點提取與易讀性：

**節目主題：腦機接口治療難治性抑鬱症**

**開場白：**

*   主持人（大飛）介紹過去曾做過抑鬱症相關節目。
*   引出想像：若能透過裝置開關治療抑鬱症。
*   科幻成真：上海瑞金醫院已進行相關臨床研究。

**腦機接口治療抑鬱症：**

*   **研究內容：**
    *   2020年底，上海瑞金醫院成立臨床研究小組。
    *   手術植入「腦起搏器」，控制大腦中的電極。
    *   患者可自行開啟/關閉「體外開關」，控制情緒（「一秒天堂一秒地獄」）。
*   **臨床研究進展：**
    *   國內首次，已有26位患者參與。
    *   患者抑鬱狀況平均改善60%。
*   **案例：吳曉天**
    *   31歲，患抑鬱症16年，嚴重時無法正常社交。
    *   手術後，覺得「換了個人」，能與人正常交流。
    *   胸腔內埋有「腦起搏器」，連接電極至大腦。
    *   電流刺激改善症狀。

**吳曉天的經歷：**

*   **病史：**
    *   童年隨父母到苏州，被視為「外鄉人」。
    *   技校生活不合群。
    *   嘗試各種治療方法（保健品、針灸、氣功、藥物、電擊）。
    *   求生慾強烈，但病情持續16年。
    *   一度與外界斷絕聯繫，對「快樂」感到好奇。
    *   2014年曾試圖自殺。
*   **轉機：**
    *   父親帶他到上海瑞金醫院求診，找到孫伯民主任。
    *   接受腦機接口手術，重獲新生。

**孫伯民主任的臨床研究：**

*   **研究負責人：** 上海瑞金醫院功能神經外科中心主任 孫伯民。
*   **研究原理：**
    *   刺激大腦中與情緒相關的神经核團，改善抑鬱症狀。
    *   腦起搏器多靶點聯合刺激是世界首次。
*   **抑鬱症成因：**
    *   醫學界普遍認為與生物學基礎有關。
    *   抑鬱可能導致大腦特定區域代謝、腦電活動產生變化。
*   **倫理考量與篩選：**
    *   僅限「難治性抑鬱症」患者參與。
    *   通過抑鬱症量表、醫生面診等嚴格篩選。
    *   需家屬充分理解與支持。
*   **參數調整：**
    *   根據「早上重、晚上輕」的特點，不斷調整參數。
    *   每條電極上有16個觸點，調整電流刺激不同程度的大腦神經。
*   **研究發現：**
    *   症狀好轉後，大腦中伽馬波段的慢波頻段能量上升。
    *   電極刺激後，多巴胺含量明顯增加。
*   **個體差異與參數調控：**
    *   每個人對電流刺激的反應不同。
    *   過高參數可能導致「輕躁狂」。
    *   醫師掌握參數調整權。

**吳曉天的自我調控：**

*   術後3個月，開始自行調控程序組。
*   手機APP上有工作、休息和休閒模式。
*   不同模式代表不同參數設置，刺激不同靶點。
*   找到自己的生活節奏，相對自由地掌控生活。

**術後生活：**

*   食慾增加，體重上升。
*   能唱出低沉的顫音。
*   享受與人交流。
*   經營民宿，有許多想做的事（街頭賣藝、歌手、音樂酒吧、AI研究）。

**結尾：**

*   吳曉天感謝手術，認為是「重啟人生」。
*   主持人提供資料來源（一條短片連結）。
*   呼籲觀眾若有需要，可參考此資訊。
*   感謝觀看，下期再見。

**重點整理：**

*   腦機接口治療難治性抑鬱症是新的治療方向，已在上海瑞金醫院進行臨床研究。
*   案例吳曉天通過手術重獲新生，可自行調控情緒。
*   研究團隊透過嚴謹的篩選與參數調整，確保研究的安全性與有效性。

**建議：**

*   可將研究數據（例如：抑鬱狀況改善60%）更具體化，例如：抑鬱量表分數降低多少。
*   對於「腦機接口」、「腦起搏器」、「神经核團」等專業術語，可加入更淺顯易懂的解釋。
*   強調研究的局限性，例如：僅適用於難治性抑鬱症患者，並非所有抑鬱症患者都適用。

這個版本更加結構化，突出了重點，方便讀者快速了解節目的主要內容。我盡量使用了更通俗易懂的語言，並將專業術語做了簡單的解釋。希望這個整理對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>168. [2023-08-19] 【OpenAI】OpenAI首次公开宣布收购 | Global Illumination | 8人小公司为何被青睐 | 开源MMOPRG Biomes</summary><br>

<a href="https://www.youtube.com/watch?v=SctDzExnSw0" target="_blank">
    <img src="https://img.youtube.com/vi/SctDzExnSw0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】OpenAI首次公开宣布收购 | Global Illumination | 8人小公司为何被青睐 | 开源MMOPRG Biomes

好的，我幫您整理了這篇文稿，使其更具條理性，並提取了關鍵信息：

**核心內容：OpenAI 收購 Global Illumination**

*   **事件:** OpenAI 收購了 AI 初創公司 Global Illumination 及其整個團隊。這是 OpenAI 自 2015 年以來首次公開的收購案。
*   **時間:** 北京時間 8 月 17 日凌晨
*   **目的:**  增强产品设计和商业化能力，应对竞争并寻找新的增长维度。
*   **財務狀況:**
    *   OpenAI 2022 年虧損翻倍至 5.4 億美元，收入 3000 萬美元。
    *   目標：今年盈利 2 億美元，明年 10 億美元。
    *   微软年初投資 100 億美元。

**Global Illumination 公司介紹**

*   **成立時間:** 2021 年
*   **地點:** 美國紐約
*   **業務:** 利用人工智能創建有創意的工具、數字基建和數字體驗。
*   **核心創始人:**
    *   Thomas Dimson (CEO): 前 Instagram 工程总监，主导设计 Instagram 内容排序算法、「Stories」和「Explore」功能。滑鐵盧大學數學與計算機學士，史丹佛大學人工智能碩士。
    *   Taylor Gordon (CTO): 曾在 Google、微软、YouTube、Instagram、Facebook 工作，專注推薦系統、機器學習、人工智能。滑鐵盧大學數學與計算機科學專業。
    *   Joey Flynn (首席產品官): 前 Facebook 設計師，Unity&Variety 聯合創始人。華盛頓大學西雅圖分校視覺設計專業。
*   **團隊特點:** 具備優秀的算法能力、視覺設計能力和產品化能力。
*   **其他成員:** 來自 YouTube、Google、Pixar、Riot Games 等知名公司。

**OpenAI 收購 Global Illumination 的原因分析**

1.  **商業化考量:** Global Illumination 具備成熟的產品設計能力，可以幫助 OpenAI 更快實現商業化目標。
2.  **技術競爭:** OpenAI 需要尋找新的增長點，從另一個維度與對手競爭。
3.  **Biomes 遊戲:** Global Illumination 開發的開源大型多人在线沙盒遊戲 Biomes，可能引起了 OpenAI 的興趣。但 OpenAI 可能不会重复游戏方向。

**Biomes 遊戲介紹**

*   **類型:** 開源的大型多人線上沙盒遊戲 (MMORPG)
*   **技術:** Next.js、Typescript、WebAssembly 和 React 等流行的 Web 技术
*   **平台:** 網頁瀏覽器
*   **風格:** 視覺風格類似樂高，遊戲風格類似《我的世界》（Minecraft）。
*   **功能:** 組隊、釣魚、耕種、建造、買賣、交易、創建小遊戲、分享創意。

**未来展望**

*   Global Illumination 團隊將停止對 Biomes 遊戲的維護和更新，讓其在开源社区中自由生长。
*   預計 OpenAI 和 Global Illumination 團隊將更傾向於做一些開創性的工作與產品，尤其是在消費級應用方面。
*   Global Illumination 的名稱 "全局照明" 暗示了團隊對算法和產品審美與品味的追求，值得期待。

**主要信息总结:**

OpenAI 收購 Global Illumination 是為了增强產品設計和商業化能力，应对竞争，並寻找新的增长维度。 Global Illumination 團隊的算法能力、視覺設計能力和產品化能力是 OpenAI 所需要的。未來兩個團隊的合作值得期待。

希望這個整理对您有所幫助！您还有其他需要我整理的內容嗎？

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>167. [2023-08-18] 【AIGC】七千字通俗讲解Stable Diffusion | 稳定扩散模型 | CLIP | UNET | VAE | Dreambooth | LoRA</summary><br>

<a href="https://www.youtube.com/watch?v=F6ApJH5xuVo" target="_blank">
    <img src="https://img.youtube.com/vi/F6ApJH5xuVo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】七千字通俗讲解Stable Diffusion | 稳定扩散模型 | CLIP | UNET | VAE | Dreambooth | LoRA

好的，以下是經過整理的文稿，主要目的是讓內容更清晰、易讀，並且更符合一般文章的格式。我做了以下調整：

*   **調整了語氣：** 將口語化的表達轉換為更書面化的語氣。
*   **更精簡的段落：** 將較長的段落拆分為更短的段落，使閱讀更輕鬆。
*   **標題層級：** 增加標題層級，以更清楚地展示文章的結構。
*   **調整一些詞彙：** 替換一些口語詞彙，使其更正式。
*   **調整標點符號：**修正了標點符號的錯誤使用。
*   **修正錯字:** 修正一些錯字。

**整理後文稿：**

---

## Stable Diffusion 生成原理詳解

大家好，這裡是最佳拍檔，我是大飛。前幾天，我們以較為通俗的方式講解了大語言模型的內部運行原理。今天，我們將進一步講解 Stable Diffusion 的生成原理。

Stable Diffusion 算法是這波 AIGC 浪潮崛起的基礎，無數的 AIGC 工具都由此衍生。本影片主要分為三個部分：

1.  **Stable Diffusion 原理：** 介紹擴散 (Diffusion) 的概念、如何穩定控制擴散，以及 CLIP 和 UNET 的原理，並理解 VAE 的編解碼過程。
2.  **模型訓練原理：** 介紹機器如何認識圖片，以及如何訓練模型。
3.  **大模型微調技術：** 介紹進行微調的原因、微調要解決的問題，以及常見的微調技術及其相關原理。

### 1. 什麼是擴散 (Diffusion)？

Stable Diffusion 是一個算法。我們所說的 Stable Diffusion Web UI 是基於此算法的一個工具。Stable Diffusion 的算法名稱直接點明了其核心概念：Stable（穩定） + Diffusion（擴散）。簡單來說，它是一種穩定的擴散算法。

在圖像領域中，擴散算法指的是透過一定規則進行去噪或加噪的過程。其中，去噪也稱為反向擴散，加噪則稱為正向擴散。

以提示語 "a red flower"（一朵紅色的花）為例，當我們要生成一朵紅色的花時，擴散過程會從最初的灰色噪點塊逐漸去噪，直到最終清晰地顯示一朵紅色的花。

那麼，對於 Stable Diffusion 算法來說，這個擴散過程如何能夠被穩定地控制住呢？

### 2. Stable Diffusion 的原理

我們以文生圖為例，展示 Stable Diffusion 的原理。這個過程可以抽象理解為一個大的函數 Fsd，其參數是 Prompt。也就是說，我們輸入一段自然語義 Prompt，經過一系列的函數運算和變化，最終輸出圖片。這個過程中會經過幾個部分，我們將逐一拆解講解。

#### 2.1 CLIP：文本編碼器 (Text Encoder)

輸入一段咒語（Prompt）後，如何使其起作用？實際上，讓咒語能夠起作用的是一個叫做 CLIP 的算法。CLIP 是 Text Encoder 算法的一種。Text Encoder 的主要功能是將自然語義 Prompt 轉變為詞特徵向量 Embedding。

例如，我們輸入 Prompt "cute girl"（可愛的女孩），CLIP 算法在進行自然語義處理時，會根據之前被程式設計師訓練的經驗，感知到可愛的女孩可能具有的特徵，如「大大圓圓的眼睛」、「白皙的肌膚」、「可愛的神態」等等。然後，這些可能的特徵會被轉化為 77 個等長的 Token 詞向量，其中每個詞向量包含 768 個維度，這就是我們所說的 Embedding。

為什麼同樣的關鍵詞，生成的圖片有的好看，有的醜？這是因為，當輸入同一個 Prompt 時，Text Encoder 過程是一樣的，也就是得到的詞向量是一致的。但是，後面的去噪算法依賴的模型不同，因此生成的結果也千差萬別。

#### 2.2 UNET：基於詞向量的擴散算法

接下來，我們來講解 Stable Diffusion 中最重要的 UNET 算法。UNET 是一種基於詞向量的擴散算法。CLIP 算法會根據輸入的 Prompt，輸出對應機器能識別的詞特徵向量 Embedding。可以將 Embedding 理解為一個包含 (Q、K、V) 三個參數的函數。這三個參數會根據輸入的擴散步長，在 UNET 去噪算法的每一步發生作用。

如果設定去噪步長為 20 步，就能看到圖片逐漸擴散生成的效果。實際上，UNET 去噪的原理比這裡描述的複雜很多。它並不是一步一步去噪就能得到對應效果的，如果僅僅是一步一步地去噪，效果往往很差，並不能精確得到描述文本的圖片。

為了保證 Prompt 最終的精確性，在 UNET 分步去噪時，它會在每一步都生成一個有 Prompt 特徵引導的圖，和一個沒有 Prompt 特徵引導的圖，然後將兩者相減，就得到了每一個去噪步驟中單純由文字引導的特徵信號。然後，將這個特徵信號放大很多倍，加強文本引導。同時，在第 N+1 步去噪結束後，它還會用第 N+1 步去噪的訊息特徵減去第 N 步的特徵，然後繼續放大很多倍。這樣可以保證 Prompt 在每一步都能有足夠的權重比參與運算。

此方法加強了 Prompt 的權重，在 Stable Diffusion Web UI 中被翻譯為「提示詞相關性」，是一個很常用的參數，其數值決定了生成的圖片與提示詞的相關程度。

#### 2.3 圖生圖 (Image to Image)

當在 Stable Diffusion Web UI 上使用圖生圖功能時，通常是給定一張圖片，然後輸入一段 Prompt。這時，它的原理是先把我們提供的圖片進行逐步加噪，提取圖片訊息，使其變成一張完全的噪點圖，再讓 Prompt 起作用，結合上面的 UNET 算法逐步去噪，得到既有素材圖片特徵、也有 Prompt 特徵的最終效果圖。

#### 2.4 VAE：變分自編碼器 (Variational Autoencoder)

最後，我們簡單理解一下 VAE 編解碼的過程。VAE 全稱是變分自編碼器。VAE 的原理是先壓縮後解壓。VAE 算法在一開始的時候，會把 512x512 的圖片壓縮到八分之一，變成 64x64，然後在經過 UNET 算法的時候，將圖形數據帶在噪點圖中，這個過程叫做 Encoder。然後等走完 UNET 算法後，得到一個帶有所有圖片特徵的噪點圖，此時 VAE 再進行 Decoder 的過程，把這張圖解析並放大成 512x512。

上述 UNET 算法不是直接在圖片上進行的，而是在「負空間」進行的，可以理解為在編碼層面進行。

### 3. 模型訓練

#### 3.1 機器如何認識圖片

最初，計算機視覺訓練認識物體時，採用的是成對訓練的方法，通過「圖」+「對應描述」，成對地進行訓練。然後運用圖像識別、自然語義處理與卷積神經網路等一系列技術，讓計算機能夠識別這個圖形。

如果要識別狗，我們會不停地給計算機餵成千上億張狗的圖片，然後告訴它：「這是狗，這也是狗，這還是狗。」然後機器會不斷歸納狗的特徵，重複學習上億遍後，它就認識狗了。

#### 3.2 訓練模型

假設經過我們的投餵，機器已經能夠識別萬物了。但這時，由於學習的圖片風格都不同，生成的圖片有可能不滿足我們的期望。

舉例來說，假設程式設計師經過十年的努力後，讓機器正確認識了小女孩的特徵，不會出現三個眼睛兩個嘴巴。當輸入提示 "a cute girl" 時，生成的是圖 A。但是，A 的風格與我們想要的完全不同，例如我們想要的是圖 B 這種風格。

這時，程式設計師們就會不斷調整函數中的各種算法和參數，使得產出的圖形 A 無限接近於圖像 B，然後停止訓練。此時，整個 Fsd(x) 函數的所有調整的參數，就被保存為一個 `.ckpt` 的檔案，這個叫做 checkpoint 的檔案，就是程式設計師訓練好的、可供調用的 AI 繪圖大模型。它能保證每次生成的圖片，都偏向於某種特徵集合。

了解過 Stable Diffusion 的人應該都知道，Stable Diffusion 可用的模型有兩類：

*   **safetensors：** 使用 NumPy 保存，僅包含張量數據，沒有任何代碼，加載 safetensors 檔案會更加安全和快速。
*   **ckpt：** 使用 Pickle 序列化，可能包含惡意代碼，如果不信任模型的來源，加載 ckpt 檔案可能會帶來安全風險。

因此，下載模型時，建議優先下載 safetensors。

### 4. 大模型的微調技術

#### 4.1 為什麼要進行大模型微調

UNET 模型是 SD 中最重要的模型網路，內部包含了上億個參數。要訓練這樣一個超大的模型，大概需要 15 億個圖像文本，使用 256 張 A100 顯卡跑 15 萬個 GPU 小時，成本約為 60 萬美元。一般的設計師無法像程式設計師那樣，頻繁調整函數參數來訓練模型。

由於 UNET 模型的泛化性極強，可能無法滿足特定風格的需求，因此我們往往會對 UNET 大模型進行微調，讓其更符合需要的使用場景。

#### 4.2 微調要解決的問題

所有的大模型微調技術，都是為了要解決兩個問題：

1.  **如何減少訓練參數，提高訓練效率和生成圖像的質量。**
2.  **如何解決模型泛化性差的問題。**

泛化性指的是模型對新數據的適應能力，具體會表現為過擬合和欠擬合兩種。

*   **過擬合 (Overfitting)：** 指微調模型對原始模型的語義理解程度發生了變化，整體訓練出現語義漂移的現象。例如，有一隻貓，名字叫 Jojo，我拍了他的幾十張照片，一直用 "a jojo cat" 這個名字來強化模型對這隻貓的認知。等以後我輸入 "a jojo cat" 的時候，確實能出現我想要的這隻貓。但是我輸入 "a cat" 的時候，出現的畫面卻很怪異，這就說明 cat 這個詞被污染了，出現了過度擬合的現象。
*   **欠擬合 (Underfitting)：** 指無法識別這個特徵。例如，它就完全識別不出 Jojo 和 cat 的關係。這往往是訓練樣本量不足，或者訓練樣本質量較差等因素導致，屬於訓練無效。

#### 4.3 常見的大模型微調技術

常見的大模型微調技術大概有四種：Dreambooth、LoRA、Embedding、Hypernetwork。

##### 4.3.1 Dreambooth

Dreambooth 如何解決過擬合的問題？Dreambooth 要求訓練過程中，「特徵詞 + 類別」和「類別」要成對出現。如果想訓練一隻叫 Jojo 的貓的模型，又不能讓它跟 "貓" 這個詞過度擬合，可以採用這樣的輸入方法："JOJO cat is a cat named JOJO"。

Dreambooth 是 Google 在 2022 年 8 月提出的一種新的圖像算法，可以完整地獲得你想要的模型的視覺特徵。它的提出既不是為了訓練人物，也不是為了訓練畫風，而是為了能在少量訓練圖像的基礎上，完美地還原細節特徵。

Dreambooth 實際上調整的是 UNET 算法每一層的內部參數，也就是將 UNET 每一層函數都要進行微調。優點是可以將視覺特徵完美融入，缺點是需要調整 UNET 所有內部參數，訓練時間長，模型體積也很大。

##### 4.3.2 LoRA：大模型的低秩適配器

LoRA (Low-Rank Adaptation) 的目的是減少模型的訓練參數，提升模型的訓練效率。LoRA 建議凍結預訓練模型的權重，並將訓練參數注入到 Transformer 函數架構的每個層中。它的優點是不破壞原有的模型，可以即插即用。

相較於 Dreambooth，LoRA 可以將訓練參數降低 1,000 倍，而且對 CPU 的要求也會下降 3 倍，所以訓練出來的 LoRA 模型就會非常小，通常只有幾十 MB，而一個大模型往往有幾 GB 甚至十幾 GB。

可以將 LoRA 理解成在原有的大模型上添加了一個濾鏡，讓這個底層的大模型往我們期望的效果走。例如，當 Prompt 不變的情況下，在一個偏動漫的底層模型 revAnimated 上加了一個盲盒效果的 LoRA，就相當於是給這個底層模型上了一個濾鏡，讓整個底層模型出來的效果往盲盒的方向靠。

##### 4.3.3 Embedding：文本反演

Embedding，也叫 Text Inversion，反映的是一個 Prompt 與對應向量的映射記錄關係的算法，可以用來訓練特定的人或者是物體。

可以針對從 Prompt 到向量這個映射過程進行訓練，修改它們之間的映射記錄關係，從而達到訓練特定的人或物體的效果。由於它生成的是一套純文字的映射記錄，所以體積非常小，通常只有幾百 KB。

例如，如果要通過描述守望先鋒裡的 Dva 的特徵，去把她完整地描繪出來，可能就需要幾千個 Prompt Tag 才行。如果每次想生成 Dva 的時候，都要再輸入一次這麼多的 Prompt，肯定是不科學的。所以，可以把這一串的 Tag 打包映射成一個新的詞彙叫做 "OW\_Dva"。由於這個詞是自創的，在 CLIP 映射集合裡是找不到對應的映射關係的，所以 CLIP 會默認給它創建一個新的映射空間。經過一系列的訓練之後，後續就可以通過輸入一個簡單的詞彙，來完成一系列 Tag 的打包效果。

##### 4.3.4 Hypernetwork

Hypernetwork 作為一種即將被 LoRA 淘汰的技術，在這裡僅做簡單介紹。Hypernetwork 是新建了一個單獨的神經網路模型，插入到原來的 UNET 模型的中間層。在訓練過程中，它會凍結所有的參數，只訓練插入的部分，從而使輸出圖像與輸入指令之間產生關聯關係。

這種方法更適合用於訓練某種畫風，例如像素畫之類的。將 Hypernetwork 理解為一個濾鏡即可。

Dreambooth 調整了整個 UNET 的函數和參數，所以它體積最大，適用範圍最全，但是訓練難度和訓練耗時和成本也都最大。LoRA 只是將訓練參數注入到了部分的 Transformer 函數中，所以它不改變原來的模型，可以即插直用，模型大小也可控。

### 5. 結語

以上就是對整個 Stable Diffusion 算法以及相關內容的介紹。由於這是一個通俗版的介紹，為了方便理解，我對算法原理和數學運算進行了一定的簡化，內容也不可能面面俱到。如有想深入了解一些技術細節的，可以在評論區留言，我們找時間再深入介紹。

感謝大家的觀看，我們下期再見！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>166. [2023-08-16] 【OpenAI】GPT-4挑战人类内容审核员 | 一天顶6个月 | 自动识别非法信息 | 审核员要下岗了？</summary><br>

<a href="https://www.youtube.com/watch?v=LKxPQk0XTwg" target="_blank">
    <img src="https://img.youtube.com/vi/LKxPQk0XTwg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】GPT-4挑战人类内容审核员 | 一天顶6个月 | 自动识别非法信息 | 审核员要下岗了？

好的，這是根據您提供的文稿整理後的版本，重點突出，結構清晰：

**主題：OpenAI GPT-4 内容审核能力发布及对内容审核行业的影响**

**核心要点：**

*   **OpenAI 发布公告：GPT-4 具备内容审核能力，可用于内容策略开发和审核决策。**

    *   相較於人類審核員，GPT-4 可以大幅缩短审核周期（從數月缩短到數小时），並能深度解釋長文本內容的規則和細微差別，同時快速适应新的审核策略。
    *   平台可以利用 GPT-4 识别违规信息并进行数据标签，并解释违规原因。
*   **内容审核的重要性：**

    *   对互联网平台而言，内容审核至关重要，关系着平台的健康发展，也是网站开发人员不可回避的自我审查防线。
    *   然而，目前海量内容的审核工作主要依靠人工完成，工作枯燥、压力大，且容易对审核员造成心理伤害。
*   **现有审核技术的局限性：**

    *   虽然一些机器学习模型已经应用于内容审核，可以初步过滤有害内容，但经常出现“误删”问题。
    *   AI 审核会严格执行人工设定的数据标签，对中间地带的内容无法解释，只能一刀切，效率低且给人类管理员带来心理压力。
*   **GPT-4 的审核方式：**

    *   首先需要对 GPT-4 进行规则设定，告知其具体的内容政策。
    *   人类审核员通过识别少量示例数据，根据审核政策分配标签，创建「黄金数据集」（正确答案）。
    *   GPT-4 读取审核策略，为同一数据集分配标签（看不到答案），并与人类判断进行比较。
    *   通过检查 GPT-4 的判断与人类判断之间的差异，可以分析政策定义中的歧义，并进行相应调整。
    *   整个过程是迭代式的，速度很快，GPT-4 会逐渐适应不同政策之间的细微差别。
    *   为了降低计算成本，OpenAI 团队使用模型的预测来微调较小的模型，然后由较小的模型负责大规模的审核内容。
*   **GPT-4 审核能力的局限性：**

    *   OpenAI 承认 GPT-4 的标记质量与经过轻度训练的人类审核员相似，但与经验丰富、训练有素的人类审核员相比仍有差距。
    *   OpenAI 强调审核的过程不应完全自动化。
*   **潜在影响：**

    *   **积极：**使用 AI 进行内容审核，不仅效率高、即时适应政策更新，而且一致性好，可能在一天内完成过去六个月的工作量，创造更安全、更无害的网络世界。
    *   **消极：** 大量的内容审核员可能面临下岗，甚至其他职位（会计、收费员、银行柜员）也可能逐渐消失。
*   **质疑与反思：**

    *   有网友认为 OpenAI 只是在使用 AI 进行预标注，属于算法工程中的旧方法，并非创新。
    *   内容审核具有一定的主观性，引入 AI 模型可能会影响人工判断，降低检测的普适性，检测结果可能不够客观公正。

**总结：**

OpenAI 的 GPT-4 具备内容审核能力，有望提高内容审核效率，但同时也可能对内容审核行业造成冲击。其审核结果的客观性和公正性仍存在疑问，需要进一步验证。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>165. [2023-08-16] 【AI】什么是e/acc | 为何能预见这次AIGC浪潮 | 有效加速主义 | 有效利他主义</summary><br>

<a href="https://www.youtube.com/watch?v=e3wR1jlYsvg" target="_blank">
    <img src="https://img.youtube.com/vi/e3wR1jlYsvg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】什么是e/acc | 为何能预见这次AIGC浪潮 | 有效加速主义 | 有效利他主义

好的，這是整理後的文稿，我將其重點突出，並調整了結構，使其更易於閱讀：

**主題：什麼是“e/acc”？它與AI有什麼關係？**

**引言：**

*   “e/acc” (Effective Accelerationism，有效加速主義) 近期在矽谷科技圈，特別是AI創業和投資領域，成為熱門話題。
*   A16Z創始人 Marc Andreessen 和 YC CEO Garry Tan 等知名人士都在社交媒體上加入了“e/acc”標籤。

**什麼是“e/acc”？**

*   **定義：** “有效加速主義”是一種整合生物、物理、經濟和社會理論的哲學思想，強調適應性、進化、智能和加速是宇宙普遍存在的原則。
*   **核心：** 強調技術創新對社會的推動和變革。
*   **起源：** 普遍認為源自英國哲學家尼克·蘭德在2018年提出的右翼加速主義理論。
*   **加速主義：** 認為應急劇強化資本主義制度或技術相關的社會進程，以產生巨大社會變革。加速主義分為左右兩派，目標和方式存在矛盾。

**“e/acc”的發展：**

*   **起源：** 2023年5月，Twitter用戶共同撰寫“有效加速”的內涵和規則，並在Spaces和Substack發布。
*   **基本思想：** 在技術時代，應最大限度利用創新和技術的力量來推動社會變化。
*   **與AI的關係：** 早期推動者就預見了AI對“有效加速”的重要性，認為AI是促進社會加速發展的最有效方式之一。
*   **爆紅原因：** 大語言模型和生成式AI的爆火，讓更多人注意到“e/acc”概念，並賦予它更具體和現實的意義。
*   **技術烏托邦：** “e/acc”追隨者認為，任何提供假設價值（即使現在看起來荒謬）的創新想法都不應被否定，所有聲稱能夠造福人類的技術都應被支持。

**“e/acc”在AI領域的觀點：**

*   **關鍵觀點：**
    1.  AI技術發展不可阻擋，應共同努力發揮其正向影響，減少負面影響。
    2.  AI技術應具有普惠性質，不能被掌握在少數人手中，應讓更多人參與發展。
    3.  AI可以給社會創新、生產力進化、全球安全穩定和經濟繁榮帶來巨大飛躍和變革。

**大佬的支持：**

*   Marc Andreessen 明確表示自己是“有效加速支持者”。
*   Garry Tan 認為技術掌握在少數人手中太危險，需要讓更多人使用和加入，因此技術開源和加速才是正解。他還表示，e/acc意味著更多的科技將帶來更人類化的東西、更多的繁榮以及更多的人工智能。

**“e/acc”的影響：**

*   舊金山被認為是“e/acc”思潮的集中地，支持者認為“e/acc”將改變舊金山。
*   有網友認為，修復舊金山最“e/acc”的方式是為AI研究人員和創始人開設實驗室，為更多業務和偉大思想提供空間。馬斯克也認同這個說法。

**與“有效利他主義”的比較：**

*   **有效利他主義 (Effective Altruism)：** 強調以科學和理性的方式解決全球最緊迫問題，用最有效的方式使用資源，為全人類謀福祉。
*   **爭議：** 因為 FTX 交易所創辦人 SBF 的倒台而受到質疑，被認為是犧牲一部分人的利益來滿足社會性目標。
*   **“e/acc”的優勢：** 更具體和聚焦，強調技術創新的作用，並鼓勵大家以各種形式促進和加入技術進步的創新。

**結論：**

*   “e/acc”代表著對加速通用人工智能到來的態度，並將其作為對抗“人工智能威脅論”的理論大旗。
*   儘管具有烏托邦式的設想，但在現實世界中必然會遇到困難。
*   技術只是一種工具，如何使用取決於人性。

希望這個整理後的文稿對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>164. [2023-08-15] 【小米】雷军2023年度演讲”成长“ | 小米新产品发布会 | 3小时浓缩精华版 | 人因梦想而伟大</summary><br>

<a href="https://www.youtube.com/watch?v=8DVBLrPUaEk" target="_blank">
    <img src="https://img.youtube.com/vi/8DVBLrPUaEk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【小米】雷军2023年度演讲”成长“ | 小米新产品发布会 | 3小时浓缩精华版 | 人因梦想而伟大

好的，我來幫你整理這篇文稿，使其更清晰、更有條理。我會將其分為幾個部分，並提取重點資訊，以方便閱讀和理解。

**標題：雷軍2023年度演講暨小米產品發布會精華總結**

**簡介：**

最佳拍檔的大飛總結了雷軍2023年度演講的精華內容。演講主題為“成長”，雷軍首次在小米科技園外舉辦年度演講，也是小米四年來規模最大的一場發布會。內容分為兩個部分：雷軍的成長經歷和感悟，以及小米新發布的產品。

**一、雷軍的成長經歷與感悟：**

*   **夢想的重要性：** 雷軍認為，把夢想當回事，敢想敢幹很重要。很多事情並沒有想像中那麼難，嘗試一下就知道了。
*   **夢想的起源：** 36年前（1987年），雷軍在大學圖書館看到《矽谷之火》一書，確立了創辦偉大公司的夢想。
*   **實現夢想的策略：**
    *   **先讀好書：** 在武漢大學期間，雷軍設定了三年重要目標：
        *   兩年修完大學所有學分：主動出擊解決選課、自學、點名等問題。
        *   成為優秀的程序員：克服設備匱乏的限制，盡可能積累實踐經驗。
        *   在學報上發表論文：整理研究成果，投稿《計算機研究與發展》並成功發表。
    *   **早期創業嘗試：**
        *   與學長合作開發加密軟件Bitlok，賺取第一桶金。
        *   建議與互補的朋友一起創業，成功概率更高。
        *   首次創業（三色公司）失敗，認識到技術之外，還有很多東西要學。
    *   **加入金山：** 畢業後加入金山團隊，那是他「真正成長的地方」。
    *   **創辦小米：** 再次啟程，創辦小米，將夢想走入現實。
*   **小米高端探索之路：**
    *   小米11遭遇挫折，小米12也不達預期。
    *   內部曾討論是否放棄高端線，但雷軍堅定表示，做高端是小米發展的必由之路，更是生死之戰。
    *   經過三年上百億的投入，小米高端探索取得階段性突破。
    *   2023年Q1財報顯示，小米手機在中國大陸市場4000-5000元價位段安卓市場份額第一。
*   **總結：** 「只有認知的突破，才會有真正關鍵的成長！」雷軍將其經驗總結為：人生是一場馬拉松，所有的人生難題都將在成長中找到答案。人因夢想而偉大，又因堅持夢想而成長。

**二、小米新發布的產品：**

*   **AI大模型：**
    *   2016年組建第一支視覺AI團隊，至今人工智能團隊已有3000多人。
    *   今年4月組建大模型團隊，主力突破方向是輕量化、本地部署。
    *   13億參數大模型已在手機本地跑通，部分場景媲美60億參數模型在雲端運行結果。
    *   小愛同學接入大模型，並於8月14日開放邀請測試。
*   **Xiaomi MIX Fold 3：**
    *   輕薄折疊全面旗艦機，對標iPhone。
    *   搭載高通驍龍8 Gen2領先版 SoC，LPDDR5X內存+UFS 4.0閃存。
    *   4800mAh電池，支持67W有線快充和50W無線充電。
    *   打開狀態單邊薄至5.26mm，折疊薄至10.96mm。
    *   小米龍骨轉軸，支持45°-135°大角度自由懸停。
    *   內外屏均採用三星E6發光材質，內屏採用UTG超薄玻璃。
    *   適配微信、淘寶、天貓、嗶哩嗶哩、美團等200款第三方應用。
    *   售價：12GB+256GB 8999元起。
*   **Xiaomi Pad 6 Max 14：**
    *   14英寸 2880×1800 LCD屏幕，120Hz刷新率。
    *   內置八揚聲器系統。
    *   搭載驍龍8+旗艦處理器，最高16GB+1TB存儲。
    *   配有自研G1電池管理芯片，支持67W有線充電和33W反向快充。
    *   10000mAh電池。
    *   售價：8GB+256GB首發優惠價3599元起。
*   **小米手環8 Pro：**
    *   1.74寸方表盤，60Hz刷新率OLED屏幕。
    *   一體化金屬機身，重量22.5克。
    *   支持手表級定位（北斗、GPS、NFC3.0），超過150種運動模式。
    *   升級雙通道體征傳感器，提升測量精度。
    *   典型續航比上代多2天，支持藍牙5.3，MIUI互聯互通。
    *   售價：黑色/銀色中框+TPU腕帶399元，銀色中框+真皮腕帶449元。
*   **Redmi K60 至尊版：**
    *   配置天玑 9200+ 以及独显芯片X7，跑分高达177万+。
    *   全域冰感循環散熱系統5000m㎡VC，標配冰封散熱鋼化膜。
    *   第二代1.5K旗艦直屏，華星全新C7發光材料，2,600 nit罕見的峰值亮度，144赫茲刷新率。
    *   5,000毫安電池，配有120W有線快充。
    *   支持IP68的防水防塵，並率先支持了PPP北斗高精度定位。
    *   售價：12+256 GB 2599元，16+256 GB 2799元，16GB+1TB 3299元，24GB+1TB 3599元。
*   **Cyberdog 2：**
    *   外形更接近真狗，配備新一代小米自研的高性能電機。
    *   支持前後跳作揖等動作。
    *   全新升級了19組傳感器，搭配UWB遙控器。
    *   接入小愛同學的AI語音交互系統。
    *   開放100多個接口，支持程序員自由編程，提供圖形化編程界面。
    *   售價：12,999元。

**總結：**

本次小米發布會帶來了多款新品，涵蓋手機、平板、手環、機器狗等多個領域。雷軍在演講中分享了自己的成長經歷和感悟，並強調了堅持夢想的重要性。

希望這個整理對您有幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>163. [2023-08-15] 【AIGC】Stability.AI发布代码生成模型StableCode | 30亿参数 | 16000上下文长度 | 三种模型 | StarCoder | HuggingFace开源</summary><br>

<a href="https://www.youtube.com/watch?v=uumQeZYo6Z0" target="_blank">
    <img src="https://img.youtube.com/vi/uumQeZYo6Z0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】Stability.AI发布代码生成模型StableCode | 30亿参数 | 16000上下文长度 | 三种模型 | StarCoder | HuggingFace开源

好的，以下是我整理後的文稿，著重於提煉重點、組織結構，並適當潤飾語句：

**標題：Stability AI推出革命性編碼工具StableCode，進軍程式碼生成領域**

**簡介：**

*   最佳拍檔 (頻道/節目名稱) 大飛介紹 Stability AI 最新推出的程式碼生成工具 StableCode。
*   StableCode 旨在幫助程式設計師處理日常工作，並協助新手開發者更好地學習。

**StableCode 模型概要：**

*   **參數：** 30 億參數
*   **支援語言：** Python、Go、Java、JavaScript、C、Markdown、C++ 等多種程式語言。
*   **上下文長度：** 16000 token
*   **模型類型：**
    *   基礎模型 (Base Model)：`StableCode-Completion-Alpha-3B-4K`：30億參數，僅使用解碼器的程式碼補全模型。
    *   指令模型 (Instruction Model)：`StableCode-Instruct-Alpha-3B`：30億參數，純解碼器指令微調的程式碼模型，在不同程式語言集上進行訓練，並使用程式碼指令數據集進行指令微調。
    *   長上下文窗口模型 (Long Context Window Model)。

**StableCode 模型來源與訓練：**

*   基於 BigCode 開源的程式碼大模型 StarCoder。
*   使用 HPC 集群，利用包含 5600 億程式碼 token 的程式語言數據集 `starcoder-data` 對 StarCoder 基礎模型進行訓練。
*   Stability AI 對數據集進行了額外的過濾和清理。
*   指令模型使用約 120000 個 Alpaca 格式的 "程式碼指令-回答" 對，在 StarCoder 基礎模型上進行了指令微調。

**StableCode 的優勢與特性：**

*   **長上下文窗口：** 16000 token，為先前開源模型的 2-4 倍。
*   **功能：** 支援單行、多行自動完成建議，允許同時查看編輯，相當於五個中等大小的 Python 檔案，可使用更專業複雜的程式碼生成 prompt。
*   **官方示例：** 利用 Pytorch 深度學習庫完成相對複雜的 Python 檔案展示。
*   **架構：** Transformer 架構，採用旋轉位置嵌入 RoPE 方法，避免了程式碼生成中對當前 token 的過度重視 (與 StarCoder 的 ALiBi 方法不同)。 RoPE 更適合程式碼生成，因為程式碼沒有固定的敘述結構。

**StableCode 效能比較：**

*   與 Replit 的 replit-coder、starcoderbase 模型進行比較。
*   使用 HumanEval 基准，採用 pass@1 和 pass@10 指標。
*   **pass@1：** 強於 replit-coder，弱於 starcoderbase。
*   **pass@10：** 強於兩者。

**結論與展望：**

*   StableCode 尚處於早期階段。
*   Stability AI 開放模型，希望了解開發者如何接受和使用。
*   模型文件已在 HugggingFace 上開源。

**結束語：**

*   鼓勵感興趣的觀眾試用。
*   感謝觀眾，並預告下期影片。

**總結:**

這份整理後的文稿更聚焦於資訊的結構化呈現。 我將 Stability AI 推出的 StableCode 編碼工具的各項特性、訓練方式、效能比較等關鍵資訊進行了提煉，並加以整理排序，更易於閱讀理解。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>162. [2023-08-13] 【人工智能】万字通俗讲解大语言模型内部运行原理 | LLM | 词向量 | Transformer | 注意力机制 | 前馈网络 | 反向传播 | 心智理论</summary><br>

<a href="https://www.youtube.com/watch?v=dIyQl99oxlg" target="_blank">
    <img src="https://img.youtube.com/vi/dIyQl99oxlg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】万字通俗讲解大语言模型内部运行原理 | LLM | 词向量 | Transformer | 注意力机制 | 前馈网络 | 反向传播 | 心智理论

好的，以下是經過整理的文稿：

**标题：深入解析大语言模型：工作原理、训练方法与未来展望**

**引言**

大家好，我是大飞，欢迎来到最佳拍档。近半年来，大语言模型无疑是最热门的话题。然而，我们一直没有系统地探讨大语言模型内部的工作机制。最近，蒂姆·李（Tim Lee）和肖恩·特洛特（Sean Trott）联合撰写了一篇文章，以最少的数学知识和术语，深入浅出地解释了大语言模型。

**作者简介**

*   **蒂姆·李（Tim Lee）：** 曾任职于科技媒体 Ars Technica，现推出 Newsletter《Understanding AI》，专注于探讨人工智能的工作原理。
*   **肖恩·特洛特（Sean Trott）：** 加利福尼亚大学圣迭戈分校助理教授，主要研究人类语言理解和语言模型。

**文章核心内容摘要**

这篇文章旨在揭示大语言模型的内部机制，无需复杂的数学概念、公式和运算，对初学者非常友好。

1.  **大语言模型概况：** 虽然 ChatGPT 在去年秋天引起了轰动，但大众对其工作原理知之甚少。大语言模型的训练依赖于预测下一个词，并需要大量的文本数据。
2.  **独特的开发方式：** 大语言模型与传统软件不同，并非由人类工程师编写指令，而是构建在一个使用数十亿个语言词汇进行训练的神经网络之上。
3.  **理解的挑战：** 目前，地球上没有人完全理解大语言模型的内部工作原理。研究人员正在努力探索，但这是一个漫长而复杂的过程。
4.  **核心目标：** 在不涉及技术术语或高级数学的前提下，解释已知的大语言模型内部的工作原理，包括词向量、Transformer 和训练过程。

**一、词向量（Word Vector）：大语言模型表示和推理语言的方式**

*   **词向量的定义：** 大语言模型不使用字母序列来表示单词，而是使用词向量，即一长串数字的列表。
*   **词向量的用途：** 每个词向量代表了词空间（word space）中的一个点，具有相似含义的词的位置更为接近。
    *   举例：与“猫”（cat）最接近的词包括“狗”（dog）、“小猫”（kitten）和“宠物”（pet）。
*   **词向量的优势：** 数字能够进行字母无法进行的运算。大语言模型使用数百甚至数千维度的向量空间，计算机可以对其进行推理并产生有用的结果。
*   **word2vec 项目（Google，2013年）：** 通过分析从 Google 新闻中收集的数百万篇文档，找出哪些单词倾向于出现在相似的句子中。经过训练的神经网络学会了将相似类别的单词放置在向量空间中的相邻位置。
*   **向量运算的推理能力：** 可以使用向量运算来进行类比。例如：biggest - big + small ≈ smallest。词向量捕捉到了许多其他的关系，比如国家与首都，名词单复数之间的关系等。
*   **偏见问题：** 词向量是从人们使用语言的方式中构建的，因此反映了许多存在于人类语言中的偏见。减少这种偏见是一个新的研究领域。
*   **作用：** 编码了词与词之间微妙但重要的关系信息。大语言模型可以根据词向量，利用已经学习的关于某个词的知识，来推断与其相似的词的特性。
*   **解决多重含义的问题：** 像 ChatGPT 这样的大语言模型，能够根据单词出现的上下文，用不同的向量来表示同一个词（同音异义词 homonyms 和多义词 polysemy）。

**二、 Transformer：构建 ChatGPT 等模型的基石**

*   **Transformer 的结构：** ChatGPT 最初版本背后的 GPT-3 模型由数十个神经网络层组成，每一层都是一个 Transformer。
*   **Transformer 的工作原理：** 每一层接受一系列的词向量作为输入，并添加一些信息来帮助澄清这个词的含义，从而更好地预测接下来可能出现的词。
*   **隐藏状态（hidden state）：** 经过 Transformer 处理后的新向量被称为隐藏状态，并传递给下一个 Transformer。
*   **神经网络层的作用：**
    *   前几层专注于理解句子的语法，解决歧义。
    *   后面的层致力于对整个文本段落的高层次的理解，似乎会记住关于故事角色的各种信息。
*   **向量维度：** 现代大语言模型中的向量维度极为庞大，这有利于表达更为丰富的语义信息。
    *   例如：GPT-3 最强大的版本使用了有 12,288 个维度的词向量。
*   **层与层之间传递信息的实现方式：** 通过修改隐藏状态的向量来实现。
*   **Transformer 内部的处理过程：**
    1.  **注意力机制（Attention）：** 词汇会观察周围，查找具有相关背景并彼此共享信息的其他的词。
    2.  **前馈网络（Feed Forward）：** 每个词会思考之前注意力步骤中收集到的信息，并尝试预测下一个词。
*   **注意力机制的具体运作：**
    *   每个单词会制作一个检查表，称为查询向量（query vector），来描述他寻找的词的特征。
    *   每个词还会制作一个检查表，称为关键向量（key vector），描述他自己的特征。
    *   神经网络通过将每个关键向量与每个查询向量进行比较，找到最佳匹配的单词。
    *   一旦找到匹配项，他就会从产生关键向量的单词把相关信息传递给产生查询向量的单词。
    *   每个注意力层都有几个注意力头（attention head），可以并行的进行多次信息交换。每个注意力头专注于不同的任务。
*   **前馈网络的具体运作：**
    *   在这个阶段单词之间没有交换任何的信息，前馈层会独立的去分析每个单词。
    *   前馈层可以访问之前由注意力头复制的任何信息。
    *   前馈层之所以强大是因为它有大量的连接。
    *   研究表明，前馈层通过模式匹配进行工作，即隐藏层中的每个神经元都能够匹配输入文本中的特定模式。
*   **注意力机制与前馈网络的配合：**
    *   注意力机制从提示的教导部分检索信息。
    *   前馈层让语言模型能够记住没有在提示中出现的信息。
    *   可以将前馈层视为模型从训练数据中学到的信息的数据库。

**三、大语言模型的训练方式**

*   **训练方式的创新：** 大语言模型不需要显式的标记数据，而是通过尝试预测文本段落中的下一个单词来学习几乎任何的书面材料。
*   **训练过程：**
    *   模型拿到一个输入，并试图预测下一个单词。
    *   最初表现不佳，但随着模型看到更多的例子，权重会逐渐的调整，从而做出更好的预测。
*   **训练过程的类比：** 将调整水龙头到合适温度类比成训练模型。阀门就是模型中的权重参数，通过松鼠部队拧紧或者松开阀门来控制水流，使水从正确的水龙头流出。
*   **训练过程的具体步骤：**
    1.  **前向传播（forward pass）：** 打开水源，检查水是否从正确的水龙头中流出。
    2.  **反向传播（backwards pass）：** 关闭水源，松鼠们沿着每根管道飞快的奔跑，拧紧或者松开阀门。反向传播算法会逆向的通过网络，使用微积分来评估需要改变每个权重参数的过程。
*   **规模的重要性：**
    *   GPT-3 等模型看到的示例数量非常之多（约5,000亿个单词）。
    *   OpenAI 报告称，他们的语言模型的准确性与语言规模、数据集规模以及用于训练的计算量呈幂率关系。

**四、大语言模型的发展趋势**

*   **模型规模不断增大：** OpenAI 不断增大他的大语言模型的规模，从 GPT-1 到 GPT-4。
*   **模型性能不断提升：** 不仅学到了更多的事实，而且在需要某种形式的抽象推理任务上表现出了更好的性能。
    *   **心智理论（Theory of Mind）测试：** GPT-3 在最新版本中，对心智理论问题的正确率提高到了大约 90%。GPT-4 对心智理论问题的回答正确率约为 95%。
*   **通用人工智能（AGI）的初步迹象：** 微软的研究人员表示，GPT-4 展示了通用人工智能的初步诱人的迹象，即以一种复杂类人的方式去思考的能力。
*   **涌现能力（Emergent Abilities）** 模型通过大量的书面文本训练之后，显然学会了推理。

**五、关于大语言模型的思考**

*   **随机鹦鹉的争论：** 语言模型仅仅是重复越来越复杂的单词序列，并非真正理解他们。
*   **关注经验表现：** 如果一个语言模型能够在特定类型的问题中始终得到正确的答案，并且研究人员有信心排除掉混淆的因素，那么无论他们对语言的理解方式是否跟人类完全相同，这都是一个有趣而且重要的结果。

**六、大语言模型成功的可能原因**

1.  **语言本身是可以预测的：** 语言的规律性通常会跟物质世界的规律性相关联。
2.  **预测可能是生物智能以及人工智能的一个基础：** 人脑可以被认为是一个预测机器。
3.  **下一个词的预测方法：** 使得研究人员能够将其转换成一个经验性的问题，以此来避开这个棘手的理论难题。

**结论**

以上是对大语言模型整个工作原理的一个解释。希望本视频能够帮助大家对现在的大语言模型有一个基础的理解。感谢大家的观看，我们下期再见。

**整理说明：**

*   **调整结构：** 将原文按照更清晰的逻辑重新组织，分为引言、核心内容摘要、词向量、Transformer、训练方式、发展趋势、思考和结论等部分。
*   **提炼要点：** 提炼每个部分的重点内容，用简洁的语言进行概括。
*   **使用标题和列表：** 使用标题和小标题突出重点，使用列表使内容更加条理清晰。
*   **精简冗余信息：** 删除一些口语化的表达和重复的信息，保持内容的简洁和准确。
*   **修改部分语序，使得表达更流畅。**

希望这个整理后的文稿对您有所帮助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>161. [2023-08-12] 【创业】创业者的“迷宫” | 马克.安德森 | A16Z创始人 | 如何看待AI | 创始人背调 | 创业的本质</summary><br>

<a href="https://www.youtube.com/watch?v=6XyLhswQ6j4" target="_blank">
    <img src="https://img.youtube.com/vi/6XyLhswQ6j4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【创业】创业者的“迷宫” | 马克.安德森 | A16Z创始人 | 如何看待AI | 创始人背调 | 创业的本质

好的，以下是我整理後的文稿。我著重在使其更清晰、更結構化，並突顯重點：

**標題：A16z 創始合夥人馬克·安德森訪談精華總結：AI、創業與成功創始人的特質**

**引言：**

大家好，這裡是最佳拍檔，我是大飛。今天要跟大家分享的是硅谷頂級VC機構 A16z 的創始合夥人馬克·安德森 (Marc Andreessen) 接受俄裔美國計算機科學家、知名播客主萊克斯·弗里德曼 (Lex Fridman) 專訪的精華內容。 原視頻時長約 3 個多小時，有興趣的朋友可以自行觀看。

**重點一：科技行業的轉變：從工具到應用**

*   **過去 (1940-2010):** 成功的大公司主要銷售工具，也就是「賣鏟子的公司」。例如：PC、數據庫、智能手機。
*   **現在 (2010年至今):** 成功的大公司開始專注於「應用」，在現有行業中創辦公司，直接為客戶提供產品。例如：Uber、Lyft、Airbnb。
*   **AI 的反轉:** 目前多數 AI 公司在雲端提供 AI API 接口服務。
*   **未來趨勢:** 大部分資金仍可能投入 AI 應用領域，例如 AI 財務顧問、AI 醫生、AI 律師等。

**重點二：對下一個超級成功公司 (如 Google, Apple, Twitter) 的建議**

*   **最重要的特質:** 真正偉大的創始人不會接受任何建議。
*   **成功創始人的三個因素:**
    1.  **超級聰明**
    2.  **超級有活力**
    3.  **超級有勇氣:** 面對痛苦的承受能力，在放棄之前願意被擊打多少次。

**重點三：創業的真相：浪漫化的背後**

*   **大眾的誤解:** 人們常常將創業浪漫化，認為即使失敗也是偉大的冒險。
*   **真實情況:** 創始人經常被拒絕 ("不"，我不會為你工作/購買你的產品/寫關於你公司的故事")，需要接受「習慣被打击」。
*   **創始人的苦楚:** 必須隱藏痛苦，在被拒絕時仍表現出樂觀，否則會失去信心。

**重點四：為什麼創業？**

*   **非理性的需求:** 對於大多數創業者而言，在大公司工作可能在財務上更成功。但有些人就是有一種非理性的需求，想要創造新事物、為自己建造一些東西，無法容忍有老闆。

**重點五：如何背調創始人？**

*   **傳統方式 (雇傭員工):** 詢問前老闆，評估是否為好員工。
*   **理想情況 (背調創始人):** 前任老闆說：「我想為那個人工作」。

**重點六：先有想法，還是先開公司？**

*   **優先順序:**  先有 *具體產品* 的想法，然後意識到有機會自己建立公司，再成為做這件事的合適人選。
*   **早期重點:** 最初五年不需要遠大的願景，只需要創建人們想要的東西，並想辦法賣給他們。
*   **產品要求:**
    1.  有用 (人們想要付錢)
    2.  理論上可實現
    3.  符合市場需求

**重點七：創意迷宮 (Idea Maze)**

*   **謬誤:** 創意會像魔法一樣閃現。
*   **真相:** 成功的創始人在創辦公司前已經思考了 5-10 年，持續訓練和實驗，成為真正的領域專家。
*   **創意迷宮:** 針對任何想法都有無數條路徑 (用戶是誰？產品是什麼？如何推向市場？)。聰明的創始人已經考慮了所有可能性，並有詳細的答案。

**重點八：我應該創業嗎？**

*   **最佳理由:** 你不能忍受不做。
*   **避免:** 如果只是被建議去做，可能不適合。
*   **創業代價:** 可能會失去社會關係，破壞與愛人的關係。
*   **時間投入:** 所有成功的創始人每周工作 80 小時，工作與同事建立牢固的社會紐帶。

**重點九：年輕 vs 大齡創始人**

*   **年輕創始人優勢:** 擁有的更少，更容易忍受創業的艱辛。
*   **大齡創始人優勢:** 經驗豐富，對要做的事情更了解。但需要平衡家庭責任。

**結語：**

以上就是馬克·安德森關於 AI、創始人背調和創業的看法，希望能給大家帶來一些啟發。歡迎在評論區留下你的看法。感謝大家的觀看，我們下期再見。

**整理說明：**

*   **重點歸納:** 將訪談內容拆解為多個重點，方便讀者快速掌握核心概念。
*   **結構化:** 使用條列式、數字編號等方式，讓內容更易於閱讀和理解。
*   **關鍵字強調:** 使用粗體字標示關鍵字，突出重點。
*   **簡潔化:** 刪除冗言贅字，使文稿更精煉。
*   **加上標題:** 使得讀者快速了解文章內容

希望這份整理後的文稿對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>160. [2023-08-11] 【人工智能】ChatGPT版权侵权第一案 | 美国两名作家集体诉讼 | 六项指控 | OpenAI | 古登堡计划 | 影子图书馆</summary><br>

<a href="https://www.youtube.com/watch?v=Qh6RU8N1MZY" target="_blank">
    <img src="https://img.youtube.com/vi/Qh6RU8N1MZY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】ChatGPT版权侵权第一案 | 美国两名作家集体诉讼 | 六项指控 | OpenAI | 古登堡计划 | 影子图书馆

好的，這是一個整理後的文稿，重點更清晰，並進行了部分潤飾：

**标题：首例针对ChatGPT的版权案件：作家控告OpenAI侵权**

大家好，我是最佳拍档的大飞。今天我们来聊聊首例明确针对ChatGPT的版权案件。

**案件背景：**

2023年6月28日，作家保罗·特伦布莱（Paul Tremblay）和莫娜·阿瓦德（Mona Awad）在美国加州北区法院对OpenAI公司提起了版权集体诉讼，指控OpenAI未经授权使用他们撰写的图书训练ChatGPT，从而谋取商业利益。涉案作品为《世界尽头的小屋》和《13种看待胖女孩的方式》。

**原告的指控：**

原告指出，尽管他们没有授权OpenAI使用其版权图书进行模型训练，但ChatGPT能够根据提示输出这两本书较为准确的摘要，虽然存在少量错误。原告认为这表明OpenAI使用了他们的图书进行训练，且未获得同意，也未标明内容来源或支付费用。这些图书都具有明确的版权管理信息，包括出版号、版权号、版权人姓名以及使用条款等。

**值得关注的点：**

*   **ChatGPT原理的介绍：** 原告通过与ChatGPT对话，让其“自我介绍”，来论证ChatGPT的基本原理，指出大语言模型是通过“训练”而非传统代码编写的方式研发的。
*   **图书作为训练语料的重要性：** 原告强调图书是训练数据集中核心的语料素材，因为它们提供了高质量的长篇写作范例。OpenAI的论文也证实了图书对于训练模型处理长文本信息能力的重要性。
*   **训练数据集的来源：** OpenAI曾披露GPT-3的训练数据集中包含来源于“古登堡项目”（Project Gutenberg）和可能来源于“影子图书馆”的电子图书语料库。

**原告提出的六项指控：**

1.  **版权直接侵权：** OpenAI未经授权复制、制作演绎作品，并公开展示、分发这些复制品或演绎作品。大语言模型本身构成了侵权演绎作品，因为它需要从原告图书中提取和保存表达性信息才能运行。
2.  **版权替代侵权：** OpenAI有权利和能力控制大语言模型的内容输出，并从中获得了经济利益，因此构成版权替代侵权。
3.  **违反《数字千年版权法》（DMCA）：** ChatGPT输出的内容没有保留作品的版权管理信息，OpenAI故意移除这些信息并分发不含版权管理信息的侵权演绎作品。
4.  **不正当竞争：** ChatGPT输出图书内容的方式违反了《加利福尼亚州商业和职业条例》，获取了商业上不正当的利益和名声。
5.  **过失侵权：** OpenAI在收集版权作品用于训练GPT模型时，未尽到注意义务，预见到未经授权的使用会对原告造成损害。
6.  **不当得利：** OpenAI通过训练GPT模型来盈利，侵害了原告的利益。

**案件的意义和未来走向：**

作为ChatGPT版权侵权的第一起诉讼，加州北区法院的判决将具有重要意义。

**案件引发的三个问题：**

1.  **如何确定模型侵权：**  难以确定模型是否直接使用了侵权内容，特别是当生成的内容只是摘要，且存在错误时。如何取证模型使用了侵权作品是一个难题。
2.  **用作品内容训练数据的行为侵犯了什么权利：**  在没有特定提示的情况下，大模型可能不会输出与原作完全相同的内容，这是否构成侵权？
3.  **输出的内容责任在谁：**  是模型的训练者还是使用者？目前来看，训练者承担训练所涉及的版权责任，而输出内容的权利和责任通常由使用者承担。

**总结：**

原告的诉讼主要聚焦于OpenAI模型的训练阶段，对于ChatGPT输出内容的指控仅仅是间接侵权。这表明，对于大模型输出的内容，应该由使用者承担侵权责任。

我会持续关注此案的进展。大家对于大模型侵权这个事是怎么看的呢？欢迎在评论区留言讨论。感谢观看本期视频，我们下期再见！

**整理说明：**

*   **精简结构：** 去除了一些重复或不太重要的细节，使整体结构更紧凑。
*   **使用小标题：** 增加了小标题，使文章的逻辑更加清晰，方便读者快速找到所需信息。
*   **语言润饰：** 对部分语句进行了润饰，使其更流畅自然。
*   **重点突出：** 加粗了关键信息和问题，方便读者快速抓住要点。
*   **保留作者风格：** 在整理过程中，尽量保留了原作者的语言风格和口语化的表达方式。

希望这个整理后的版本对您有所帮助！ 如果需要更進一步的修改，請隨時告知。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>159. [2023-08-09] 【Nvidia】英伟达发布史上最快GPU GH200 | AI Workstation | RTX6000 | Ominverse| 黄仁勋 | SIGGRAPH2023</summary><br>

<a href="https://www.youtube.com/watch?v=BfO4Hg9vSmE" target="_blank">
    <img src="https://img.youtube.com/vi/BfO4Hg9vSmE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Nvidia】英伟达发布史上最快GPU GH200 | AI Workstation | RTX6000 | Ominverse| 黄仁勋 | SIGGRAPH2023

好的，我將這篇文稿整理如下，目標是提取核心資訊、組織結構化、去除口語化，使其更精簡易懂：

**標題：NVIDIA SIGGRAPH 2023 大會重點總結：GH200、RTX 工作站、AI Workbench 及 Omniverse 升級**

**核心要點：**

*   NVIDIA 在 SIGGRAPH 2023 大會上發布多項新產品與技術，涵蓋 AI 晶片、工作站 GPU、AI 開發工具及 Omniverse 平台，旨在引領 AI 和圖形運算新浪潮。

**詳細內容：**

1.  **GH200 Grace Hopper 超級晶片平台：**
    *   搭載全球首款 HBM3e 處理器，專為加速運算和生成式 AI 時代打造。
    *   由 72 核 Grace CPU 和 4PFLOPS Hopper GPU 組成。
    *   提供 141GB HBM3e 記憶體，頻寬達 5TB/s。
    *   與上一代產品相比，雙 GH200 系統具有 144 個 Grace CPU 核心、8PFLOPS 計算效能 GPU、282GB HBM3e 記憶體，並集成了 1.2TB 超快記憶體 (包含 LPDDR)。
    *   採用 NVLink Switch 實現 GPU 之間的高速通信。
    *   將於 2024 年第二季投產。
    *   能效更高： 同等 AI 推理性能只需 CPU 數據中心的 1/12 成本和功耗。

2.  **桌面 AI 工作站 GPU 系列：**
    *   推出 RTX 6000、RTX 5000、RTX 4500 和 RTX 4000 四款新品。
    *   RTX 6000 為旗艦級專業卡，具備 48GB 顯存、18176 個 CUDA 核心、568 個 Tensor 核心和 142 個 RT 核心。
    *   NVIDIA RTX Workstation：支持最多 4 張 RTX 6000 GPU，提升大模型微調和圖片生成的效率。

3.  **L40S GPU 和 OVX 伺服器：**
    *   L40S 基於 Ada Lovelace 架構，具備 48GB GDDR6 顯存和 1.45 petaflops 的張量處理能力。
    *   OVX 伺服器最多可搭載 8 張 L40S，適用於數據中心市場，加速複雜計算和數據密集型分析。
    *   能夠大幅提升 AI 推理和訓練效能。

4.  **AI 開發工具：**
    *   **NVIDIA AI Workbench：** 統一、易用的工作空間，方便開發者構建和運行生成式 AI 模型，能夠快速將 AI 專案從一個位置移動到另一個位置。
    *   **NVIDIA AI Enterprise 4.0：** 企業級軟體平台，提供生產就緒型生成式 AI 工具，簡化部署，確保安全性和 API 穩定性。

5.  **Omniverse 平台升級：**
    *   基於 OpenUSD 的原生軟體平台，加速創建虛擬世界和工業數位化工作流程。
    *   WPP 和比亚迪腾势汽车 展示了 Omniverse 雲和生成式 AI 的使用案例。
    *   更新了開發原生 OpenUSD 應用和擴展的引擎 Omniverse kit。

6. **与Hugging Face合作：**
    *   将为开发者提供生成式AI超级计算，简化为企业创建新的和定制的生成式AI模型。

**總結：**

NVIDIA 通過本次 SIGGRAPH 大會，展現了其在 AI 晶片、GPU、AI 開發工具和 3D 協作平台的領先地位，為開發者和企業提供了全面的解決方案，加速生成式 AI 的應用和發展。

**建議：**

若需更深入了解，建議查閱 NVIDIA 官方發布的 SIGGRAPH 2023 大會相關資訊。

**與原文的差異：**

*   **結構化：** 將內容分段，並使用標題和副標題，讓讀者更容易掌握重點。
*   **精簡化：** 去除口語化的詞語和重複的資訊，專注於核心內容。
*   **客觀化：** 減少個人情感色彩的描述，提供更客觀的資訊。
*   **信息提取**：提取关键技术参数，方便理解

希望這個整理對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>158. [2023-08-09] 【开源】盘点开源项目挣钱的22种模式 | SaaS | 软件市场 | 升级服务 | 认证培训 | 流量 | 捐款 | 周边</summary><br>

<a href="https://www.youtube.com/watch?v=Wu8zpztxQO0" target="_blank">
    <img src="https://img.youtube.com/vi/Wu8zpztxQO0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【开源】盘点开源项目挣钱的22种模式 | SaaS | 软件市场 | 升级服务 | 认证培训 | 流量 | 捐款 | 周边

好的，我將這段文稿整理如下，重點在於讓內容更清晰、有條理，方便快速理解。

**文稿主題：** 開源項目的22種商業模式

**講者：** 大飛 (最佳拍檔)

**核心概念：**

*   **開源定義：** 依據開源協議，公開代碼於網際網路，並擁有開源社群與使用者的一種開發模式。
*   **問題：** 既然開源專案代碼開放且免費，如何形成商業閉環，獲取收入？

**22種開源專案的商業模式：**

**第一大類：核心代碼部分開源，非核心部分閉源 (最常見)**

1.  **開源商業SaaS模式：**
    *   核心代碼開源，SaaS雲服務背後代碼閉源。
    *   SaaS服務功能超越開源版。
    *   **例子：** Databricks (Apache Spark開源，雲服務閉源)。
2.  **Open-core商業軟體模式：**
    *   核心代碼開源，部分功能代碼閉源。
    *   形成閉源軟體進行售賣。
    *   **例子：** Cloudera (Cloudera Data Platform)。
3.  **Plug-in插件收費模式：**
    *   軟體本身開源，插件收費。
    *   插件提升使用效率或完成特定功能。
    *   **例子：** 部分CAD開源軟體公司。
4.  **素材收費模式：**
    *   軟體本身開源，運行時所需素材收費。
    *   **例子：** Arx Fatalis, Catacomb 3-D等引擎。

**第二大類：其他商業模式**

5.  **雲託管模式：**
    *   代碼與開源專案幾乎相同，但服務於雲端。
    *   使用者無需自行安裝維護，直接使用服務。
    *   **例子：** MongoDB、Elastic提供的託管服務。
6.  **硬體與開源軟體整合一體機模式：**
    *   將開源軟體與硬體捆綁售賣。
    *   使用者無需自行安裝、調試、適配。
    *   **例子：** Sun公司將Solaris捆綁在伺服器上。
7.  **軟體市場 (Marketplace)：**
    *   基於作業系統或基礎軟體的市場。
    *   公司透過收取中間抽成實現收入。
    *   **例子：** Android，Mozilla的Firefox。
8.  **提供普通維運與問答服務 (Professional Service)：**
    *   軟體代碼與開源版本相同，但企業需支付支援與諮詢費用。
    *   **例子：** Hortonworks的HDP和Redhat。
9.  **通過升級服務收費：**
    *   軟體本身易於使用，但數據重要。
    *   用戶購買專業升級服務，確保數據完整性與穩定性。
10. **售賣開源軟體二次分發授權：**
    *   **例子：** macOS基於BSD Unix授權。
11. **售賣同樣開源代碼軟體，提供相關服務收費：**
    *   **例子：** ardour和radium。
12. **延遲開源模式：**
    *   新版本閉源，舊版本開源。
    *   **例子：** MariaDB Corporation。
13. **退市開源：**
    *   商業軟體完成生命週期後開源。
    *   **例子：** id Software and 3D Realms公司的遊戲軟體。
14. **賣認證：**
    *   軟體開源，但透過軟體認證收費。
    *   **例子：** 早期的 Unix v3 v8的認證，Moodle模式。
15. **賣培訓和周邊參考資料：**
    *   **例子：** O'Reilly出版公司售賣開源書籍。
16. **經營開源社區合作：**
    *   **例子：** 谷歌的開源之夏 (GSoC)。
17. **售賣開源軟體上的流量：**
    *   **例子：** AdBlock Plus。
18. **懸賞開源：**
    *   在開源社群懸賞任務，由開發者完成，獲得獎勵。
    *   **例子：** Mozilla懸賞解決安全隱患。
19. **眾籌：**
    *   預售專案，籌集資金，僱傭開發者完成，並開源。
    *   **例子：** OpenGL 4.3 extension for the Mesa library。
20. **接受捐贈：**
    *   **例子：** Mozilla Foundation, VUE(尤雨溪)。
21. **售賣品牌周邊：**
    *   **例子：** Mozilla Foundation, Wikipedia Foundation的情懷T恤或馬克杯。
22. **Web3 to Developer (發展中)：**
    *   透過DAO (分散式自治組織)衡量貢獻，讓貢獻者、公司、投資者均有所得。

**總結：**

*   以上為22種開源專案的商業模式，希望能對參與者有所啟發。
*   Web3 to Developer 模式是未來開源發展的潛力方向。

**注意事項：**

*   這份整理着重於條理清晰和重點歸納，以便快速查找資訊。
*   聽眾/讀者可以根據自身需求，深入研究特定商業模式。

希望這份整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>157. [2023-08-08] 【OpenAI】OpenAI公布官方爬虫GPTBot | robots协议 | AI数据究竟如何使用</summary><br>

<a href="https://www.youtube.com/watch?v=51I0Dt3bPRk" target="_blank">
    <img src="https://img.youtube.com/vi/51I0Dt3bPRk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】OpenAI公布官方爬虫GPTBot | robots协议 | AI数据究竟如何使用

好的，這是整理後的文稿，重點在清晰、結構化，並提取關鍵信息：

**標題：OpenAI 公佈網路爬蟲 GPTBot：數據隱私與 AI 訓練的權衡**

**簡介：**

*   本文整理自最佳拍檔頻道，主持人為大飛，主要探討 OpenAI 公佈用於訓練 AI 模型（GPT-4、GPT-5 等）的網路爬蟲 GPTBot 所引發的爭議，聚焦於數據隱私、版權問題及商業利益分配。

**OpenAI 的聲明：**

*   **不再隱藏：** 公開用於訓練 AI 模型的網路爬蟲：GPTBot。
*   **用途：** 爬取數據用於改進 AI 模型的準確性、功能性和安全性。
*   **保證：** 爬取內容不包含違反隱私來源和需要付費的內容。
*   **控制權：** 網站所有者可以允許或限制 GPTBot 爬取網站數據。

**GPTBot 的工作方式與屏蔽方法：**

*   **用戶代理字符串 (User-Agent String)：** 用於識別爬蟲身份。
    *   可以將 GPTBot 添加到網站的 `robots.txt` 文件中進行屏蔽。
    *   可以使用 `Allow` 和 `Disallow` 指令控制爬取範圍，`Allow` 優先級較高。
*   **IP 地址：** OpenAI 公佈了 GPTBot 的 IP 地址，網站可以將這些 IP 加入黑名單，禁止其訪問。

**網路爬蟲的灰色地帶：**

*   **合法性爭議：** 網路爬蟲的合法性長期以來備受爭議，焦點在於：
    *   是否獲取有版權的內容
    *   是否爬取非公開數據
    *   是否侵犯個人隱私
*   **robots.txt 協議：**
    *   **定義：** 網站根目錄下的 ASCII 編碼文本文件，用於告知網路爬蟲哪些內容可以爬取，哪些內容禁止爬取。
    *   **君子協議：** 本質上是一個道德層面的約束，不具備法律效力，也無法從技術層面對抗爬蟲。
    *   **實例：** 淘寶網使用 robots.txt 協議屏蔽百度爬蟲，避免流量被百度拿走，並催生了站內競價排名體系。

**OpenAI 的策略與爭議：**

*   **公開透明：** OpenAI 主動公開 GPTBot 的 IP 地址，試圖以品牌形象做為擔保，證明其爬蟲行為合規。
*   **動機：** 在面臨竊取數據的非議時，這是最直接的自證清白措施。
*   **爭議：**
    *   **數據來源的道德和法律問題：** 使用爬取的網路數據來訓練 AI 模型是否合理？
    *   **版權侵權：** GPTBot 如何處理網站上的授權圖片、影片、音樂和其他媒體？
    *   **商業利益分配：** 如果 OpenAI 通過網路數據獲取商業利益，是否應該分享利潤？

**結論：**

*   隨著 AI 產品的快速發展，訓練 AI 的「數據」到底該怎麼用？
*   歡迎在評論區發表意見。

**關鍵詞：** OpenAI, GPTBot, 網路爬蟲, 數據隱私, 版權, robots.txt, 人工智慧, AI模型訓練

**這個整理版本著重於：**

*   **結構化：** 使用標題、副標題、列表等方式，使內容更易於閱讀和理解。
*   **重點提取：** 提取文稿中的核心觀點和信息，去除冗餘內容。
*   **客觀呈現：** 儘可能保持原文的客觀性，避免主觀評價。
*   **關鍵詞：** 增加關鍵詞，方便檢索和歸類。

希望能幫助您更好地理解和使用這份文稿。如果還有任何需要修改或補充的地方，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>156. [2023-08-08] 【人物】Vim 编辑器之父 Bram Moolenaar | 传奇人生 | 最受程序员欢迎的编辑器之一 | 慈善软件发起人 | ICCF</summary><br>

<a href="https://www.youtube.com/watch?v=KBq9ZfmX_WM" target="_blank">
    <img src="https://img.youtube.com/vi/KBq9ZfmX_WM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】Vim 编辑器之父 Bram Moolenaar | 传奇人生 | 最受程序员欢迎的编辑器之一 | 慈善软件发起人 | ICCF

好的，這是我整理後的文稿，我主要做了以下修改：

*   **修正了錯別字和語法錯誤：** 使文章更流暢易懂。
*   **調整了段落結構：** 使文章邏輯更清晰，更容易閱讀。
*   **精簡了部分語句：**  在不影響原文意思的前提下，刪除了一些重複或冗餘的詞句。
*   **統一了標點符號的使用：** 使文章更規範。
*   **添加了小標題（可選）：** 為了方便閱讀，我將內容分成了幾個小標題。您可以根據需要選擇是否保留。

**整理後的文稿：**

**緬懷Vim之父：布拉姆·穆勒納爾**

大家好，這裡是最佳拍檔，我是大飛。

或許我們成長的代價，就是看著以前仰望的大神們一個個離去。還記得剛入行當程式設計師的時候，業界流傳著一句話：「世界上只有三種程式設計師：用Vim的、用Emacs的，以及用其他的。」

可惜的是，編輯器之神、Vim之父，布拉姆·穆勒納爾（Bram Moolenaar）因病情惡化，於8月3日逝世，享年62歲。

Vim是許多程式設計師的最愛，尤其是Linux用戶，幾乎都無法繞過命令列，更繞不開Vim編輯器。布拉姆將自己的一生，大部分時間都奉獻給了Vim，甚至在一個月前，他還在對Vim進行更新、修改工作。

此外，他數十年如一日地做著慈善活動，為烏干達的貧困兒童捐款。熟悉Vim的朋友都知道，直到現在，你都可以輸入命令“help Uganda”或“help ICCF”來查看許可證。

今天，我們就來回顧一下布拉姆的一生，向這位富有創造力、傑出且極具愛心的傳奇人物致敬。

**早年生活與Vim的誕生**

布拉姆·穆勒納爾出生於1961年，在荷蘭萊斯鎮長大。他從小就對電子和計算機感興趣，高中時就開始自學程式設計。1985年，他從代爾夫特理工大學畢業，獲得了電機工程學士學位。

1988年，布拉姆給自己買了一台Amiga電腦。當時，編輯器Vi是Unix上的標準，他也想在Amiga上使用Vi。但由於沒有移植到Amiga上的版本，他嘗試了幾個Vi的克隆版本，其中一個叫做Stevie。

布拉姆對Stevie的源代碼進行了修改，想讓它更接近Vi的功能，並且增加了一些新的特性，比如多級撤銷等功能。這就是Vim的雛形，最初叫做“Vi IMitation”，意思是“Vi的模仿”。

1988年，Vim的第一個版本被發佈在Fred Fish製作的一個公共域磁碟集上。起初，Vim只是供布拉姆自己使用。一段時間後，他覺得Vim對其他人應該也有用，於是將它發佈到世界各地。從那時起，他就越來越努力地讓這個程式適合廣大的開發者。

他生前曾說道：「創造有用的東西很有趣，此外，還有一群很好的共同作者和高級用戶，這非常鼓舞人心。」

**Vim的發展與特色**

後來，有很多用戶開始將Vim移植到MS-DOS、Unix等其他平台上。隨著不斷添加新的功能，1992年，到了版本1.22，Vim已經包含了比Vi更多的功能。於是，布拉姆決定將“Vi IMitation”改名為“Vi IMproved”，意思是“Vi的改進”。

Vim雖然主要面向程式設計師，但也可以用於很多其他目的。它不僅遵循Unix上的Vi編輯器的行為，還增加了很多有用的擴展功能，可以在很多不同的操作系統上運行。

此外，Vim還有許多優點，得到了眾多程式設計師的青睞：

*   大多數命令都是普通按鍵，操作高效。
*   支持無限制的行長度，允許NUL字節。
*   可以編輯任何文件，包括二進制文件。
*   支持多級撤銷和重做，無需擔心意外打開大寫鎖定時破壞文件。
*   支持多窗口和緩衝區，可以同時編輯多個文件，並在它們之間複製文本。
*   支持170種語言的語法高亮，可以快速理解文本的結構並發現錯誤。
*   支持命令列歷史和自動完成。
*   支持刪除和插入矩形文本區域。
*   支持強大的腳本語言，可以添加自己的擴展功能。

**慈善軟體與對烏干達的關懷**

布拉姆除了負責Vim的開發、維護、發布、管理，還組織了一個由志願者組成的開發團隊，通過發送補丁、反饋等方式，不斷地改進著Vim。

Vim之所以被大家稱為慈善軟體，是因為Vim是開源且免費的，用戶不需要支付費用來使用它。儘管如此，許多經常使用Vim的人還是希望能以某種方式來回報布拉姆的工作。於是，他想到了慈善軟體的概念。

慈善軟體的基本想法就是要求每個使用Vim的人給慈善機構捐贈。雖然使用Vim是免費的，但是如果有人認為它值得付費，就可以把那些錢捐給慈善機構。

想法形成後，布拉姆開始尋找合適的慈善機構，最終找到了荷蘭國際兒童保育基金會（ICCF Holland）。1994年，布拉姆曾經作為志願者，在烏干達南部的一個項目中工作了一年。這個地區受到艾滋病的嚴重打擊，約10%到30%的成年人被艾滋病所感染，許多家庭的父母死去，只留下了他們的孩子。

這個項目以多種方式來幫助這些需要幫助的孩子：他們會為孩子找到一個新家，確保孩子能夠上學，獲得個性化的關懷。在布拉姆從烏干達回來後，他的心仍然留在那里，他決定以籌集資金的方式來繼續支持這個項目。

至此，他開始呼籲Vim的用戶考慮為烏干達的孤兒捐贈。他還建立了一個收養計劃，用戶可以為一個孩子提供經濟支持，讓孩子得到長期的幫助。由於他們只與志願者合作，並且資金直接發送到項目中，所以幾乎全部的籌款都真正用在了烏干達。

布拉姆的行動也得到了回報，ICCF的籌款日益增多，Vim也逐漸被大家稱為慈善軟體。這也是布拉姆通過Vim推動慈善事業的一種創新做法。後來有很多其他應用程序，也採取了類似的許可方式，將慈善元素融入到軟件中。

**榮譽與生活**

隨著用戶越來越多，Vim也開始贏得多項獎項，並被認為是最受歡迎的文本編輯器之一。Linux Journal的讀者分別在2001年、2002年、2003年、2004年和2005年將Vim評選為他們最喜歡的文本編輯器。

1999年，Vim入圍了LinuxWorld“編輯選擇獎”的決賽，這個獎項由Debian版本Vim的開發者維切特·阿克曼（Wichert Akkerman）在LinuxWorld會議上頒發。2000年2月，在紐約舉行的LinuxWorld博覽會上，Vim獲得了“開源文本編輯器”類的Slashdot Beanie獎提名。

但是，最讓布拉姆自豪的，還是由NLUUG在2008年頒發的這個獎項。NLUUG是荷蘭的Unix用戶團體，今年是他們成立的40週年。此前獲得該獎項的其他人還包括Python之父吉多·范羅蘇姆（Guido van Rossum）以及荷蘭互聯網先驅皮特·貝爾特瑪（Piet Beertema）。

除了把大部分精力都用來開發Vim以外，布拉姆還熱愛旅行。他會在個人網站上記錄自己的生活，不時更新自己旅行的照片，從南半球到北半球，從亞歐大陸到非洲沙漠，哪兒都有他的腳印。2006年，他還曾經來到中國，拍攝了400多張照片。

為了記錄2023年的生活，他還在個人主頁上曬出了一張自己製作的日曆，是由一張紙做成，折疊之後，一面會顯示12個月的日曆，而另一面是關於ICCF-Holland和Vim的簡要信息。

**痛失英才，精神永存**

在去年2月份，Vim的主要維護者之一，斯文·古克斯（Sven Guckes）去世。斯文不僅是布拉姆的好友，也為Vim的推廣做出了重大貢獻，甚至Vim的官方域名vim.org，也是他註冊的。布拉姆在斯文去世後，在去年6月份用Vim 9.0版本的升級來紀念好友。

但是，隨著這次布拉姆的離世，讓Vim痛失絕代雙驕。悲痛之餘，值得慶幸的是，Vim項目還會由開源社區的開發者們繼續運營下去。

在他的名字中，穆勒納爾是一個起源於荷蘭的名字，這是一種職業，形容操作風車磨坊的人。大家應該都了解，荷蘭曾經有很多風車，它們被用來抽水、磨麵粉、鋸木頭。雖然如今荷蘭的風車已經沒有了昔日的輝煌，但是布拉姆以他的代碼和全心投入，詮釋了荷蘭風車的精神。

當我們在使用Vim敲擊鍵盤的時候，彷彿也能聽到那微風拂過風車的聲音，那是布拉姆·穆勒納爾的風，永遠在我們心間飄蕩。

好了，本期視頻內容就到這裡，感謝大家的觀看，我們下期再見。

如果您覺得需要進一步修改或調整，請隨時告訴我！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>155. [2023-08-07] 【AI】目前AI公司还需要多少张H100 GPU显卡 | 为什么不选AMD和V100  | 半年内H100短缺 | 产能瓶颈在哪里 | 英伟达NVIDIA</summary><br>

<a href="https://www.youtube.com/watch?v=73ItxszMpWw" target="_blank">
    <img src="https://img.youtube.com/vi/73ItxszMpWw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】目前AI公司还需要多少张H100 GPU显卡 | 为什么不选AMD和V100  | 半年内H100短缺 | 产能瓶颈在哪里 | 英伟达NVIDIA

好的，我將盡力整理您的文稿，使其更清晰易讀。以下是整理後的版本，重點在於更明確的結構、簡潔的語言和更易於理解的資訊：

**標題：英偉達H100顯卡供需現狀分析（GPU Utils 文章重點整理）**

**開場：**

大家好，這裡是最佳拍檔，我是大飛。

**簡介：**

今天跟大家分享一篇GPU Utils的分析文章，內容關於英偉達H100顯卡的供需現狀。文章很長，我總結了核心數據和觀點，希望能幫助大家了解目前AI市場的GPU情況。

**H100 供需現況：**

*   **供應短缺：** H100 GPU供應嚴重短缺，Azure、GCP的H100容量已耗盡，AWS也即將用完，原因在於英偉達的配額不足。
*   **誰需要 H100：**
    *   **1000張以上：** 訓練大型語言模型的創業公司 (OpenAI, Anthropic, Inflection, Mistral AI)，雲服務提供商 (Azure, Google Cloud, AWS, Oracle, CoreWeave, Lambda)，特斯拉等大公司。
    *   **100張以上：** 主要對大型開源模型進行微調的初創公司。
*   **為何選擇H100：**
    *   H100是目前推理和大語言模型訓練最快的GPU，通常也最具性價比。
    *   關鍵指標：内存带宽、FLOPS、缓存和缓存延迟、FP8计算、CUDA核心数以及互联速度 (InfiniBand)。
    *   相較於A100，H100 16位推理快3.5倍，16位訓練快2.3倍，效率提高3倍，但成本僅1.5-2倍，性價比更高（可能是A100的4-5倍）。

**大語言模型訓練成本：**

*   GPU成本最高。
*   其他成本：系統RAM、NVMe SSD、InfiniBand網路成本。
*   集群總成本的10-15%可能用於電力和託管：
    *   電力成本：5-8%
    *   託管成本（土地、建築、員工）：5-10%

**為何不選擇 AMD GPU：**

*   需要花費時間讓AMD GPU運作起來，影響產品開發進度，可能導致更晚上市。
*   CUDA是NVIDIA的護城河。
*   AMD可用性令人擔憂，台積電CoWoS產能被英偉達吸走，MI250現在也無法取得。

**伺服器型號解釋：**

*   **HGX H100：** 英偉達的伺服器參考平台，OEM用來構建4GPU和8GPU伺服器。
*   **DGX H100：** 具有8個H100的英偉達官方伺服器，英偉達是唯一供應商。
*   **GH200：** 1個H100 GPU + 1個Grace CPU。
*   **DGX GH200：** 256倍的GH200，2023年底上市，可能也僅由英偉達提供。

**GPU 價格：**

*   **DGX H100 (8 x H100 SXM):** 46萬美元（含10萬美元支持），初創公司可獲得約5萬美元折扣（最多8台）。
*   **HGX H100 (8 x H100 SXM):** 30-38萬美元，取決於規格和折扣，含支持的可能接近DGX H100價格。
*   **HGX H100 (PCIe):** 約30萬美元，PCIe卡價格約3-3.2萬美元。

**各大廠 GPU 持有量：**

*   **GPT-4訓練：** 10000-25000張A100。
*   **Meta：** 約21000張A100。
*   **Tesla：** 約7000張A100。
*   **Stability AI：** 約5000張A100。
*   **Falcon-40B：** 384個A100。
*   **Inflection：** 3500張H100（訓練與GPT-3.5能力相當的模型）。
*   **GCP：** 約25000張H100。
*   **Azure：** 可能10000-40000張H100，把大部分給OpenAI使用。
*   **甲骨文：** 類似Azure。
*   **CoreWeave：** 預訂了35000-40000張H100。
*   **微調初創公司：** 數十張或數百張H100。
*   **訓練初創公司：** 至少數千張H100。

**總需求估算：**

*   OpenAI: 50000張
*   Inflection: 22000張
*   Meta: 25000張（或更多）
*   大型雲廠商: 30000張
*   Lambda/CoreWeave/私有雲: 100000張
*   Anthropic/Helsing/Mistral/Character等創業公司: 10000張
*   總計：約432000張H100（約150億美元）。

**英偉達產能：**

*   2023年2-4月數據中心收入：42.8億美元。
*   預計5-7月：約80億美元。

**H100 供應瓶頸：**

*   **台積電：** H100僅在台積電N5或N5P (4N) 節點上生產，需要與蘋果、高通、AMD共享產能。
*   **CoWoS：** 3D堆疊封裝是台積電的產能瓶頸。
*   **HBM：** 高頻寬記憶體HBM生產困難，供應有限，H100 SXM使用HBM3，H100 PCIe使用HBM2e，英偉達主要採用SK Hynix的產品。

**英偉達 H100 分配策略：**

*   為每個客戶提供配額，更關心最終使用者。
*   偏好擁有好品牌的客戶或血統強大的初創公司（投資Inflection和CoreWeave）。

**總結：**

H100 需求強勁，供應短缺，預計今年底前都將持續短缺。

**投資建議：**

（免責聲明）如果文章內容屬實，可以考慮買入英偉達股票。

**結尾：**

感謝大家的觀看，我們下期再見。

**改進說明：**

*   **條理更清晰：** 將內容分段，添加小標題，使資訊更易於瀏覽和理解。
*   **簡化語言：** 避免口語化的表達，使用更精確的術語，讓內容更專業。
*   **提取關鍵信息：** 專注於核心數據和觀點，去除冗餘的細節。
*   **格式化：** 使用了條列式清單，使重點更突出。

希望這個整理後的版本對您有所幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>154. [2023-08-05] 【ChatGPT】最新六项功能更新 | 默认使用GPT-4 | 提示示例 | 多文件上传 | 支持快捷键 | 回答建议 | 更长登录状态</summary><br>

<a href="https://www.youtube.com/watch?v=wg4g7f01LpE" target="_blank">
    <img src="https://img.youtube.com/vi/wg4g7f01LpE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【ChatGPT】最新六项功能更新 | 默认使用GPT-4 | 提示示例 | 多文件上传 | 支持快捷键 | 回答建议 | 更长登录状态

好的，我幫您整理了這篇文稿，使其更清晰、簡潔，並突出重點：

**標題：OpenAI ChatGPT 全新六大功能更新簡訊**

**摘要：** 本期簡訊重點介紹 OpenAI 即將推出的 ChatGPT 六項重大功能更新，旨在改善使用者體驗，提升效率。

**更新內容：**

1.  **Prompt 示例幫助：** 新聊天開始時，提供入門示例，引導使用者進行互動對話，解決不知從何開始的問題。
2.  **GPT-4 預設模型：** ChatGPT 會記住 Plus 使用者先前選擇的模型，預設不再是 GPT-3.5。
3.  **多文件上傳：** 使用者可上傳最多 10 個文件，要求 ChatGPT 進行數據分析、生成見解。Plus 使用者在 Code Interpreter beta 版本中也能使用此功能，對於數據分析和文件比較非常實用。
4.  **保持登錄狀態：** 使用者不再每兩週被迫下線一次，可以保持更長的登錄狀態，並提供更友善的登錄頁面。
5.  **快捷鍵：** 提升工作效率，例如：
    *   Ctrl+Shift+O (Mac: ⌘+Shift+O): 開啟新聊天視窗
    *   Ctrl+Shift+; (Mac: ⌘+Shift+;): 複製最後一個程式碼塊
    *   Ctrl+Shift+C (Mac: ⌘+Shift+C): 複製最後一次回應
    *   Ctrl+Shift+Esc (Mac: ⌘+Shift+Esc): 刪除聊天
    *   Ctrl+/ (Mac: ⌘+/): 查看完整快捷鍵列表
6.  **建議回復功能：** 點擊一下即可要求 ChatGPT 根據上下文提供更深入的回答內容，使互動更具動態性。

**總結：**

以上六項更新將於下週推出。本次更新未包含使用者期盼的聊天記錄搜尋功能。雖然 OpenAI 不斷改進產品體驗，但更核心的問題是解決 GPT-4 回覆品質和數學能力下降的趨勢。使用者最期望的還是能夠得到準確的回答。

**最佳拍檔 大飛 敬上**

**整理說明：**

*   **簡化了口語化的表達：** 例如將 "這個視頻應該算個簡訊吧" 改為 "本期簡訊"。
*   **使用了更正式的詞彙：** 例如 "社交平台" 代替 "網上"。
*   **結構化資訊：** 使用列表、項目符號等，使資訊更易於閱讀和理解。
*   **提取關鍵資訊：** 突出了更新的重點和使用者最關心的問題。
*   **去除了冗餘資訊：** 例如 "大家好，這裡是最佳拍檔，我是大飛" 可以簡化為 "最佳拍檔 大飛 敬上" 或直接省略。

希望這個整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>153. [2023-08-05] 【分享】傅盛演讲 | AGI时代的AI-Native创业思考 | 大模型创业的机会在哪里 | 学好提示词 | 大模型很大应用很小 | 创业者要把细节做好</summary><br>

<a href="https://www.youtube.com/watch?v=_Z8lLV9TE1A" target="_blank">
    <img src="https://img.youtube.com/vi/_Z8lLV9TE1A/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【分享】傅盛演讲 | AGI时代的AI-Native创业思考 | 大模型创业的机会在哪里 | 学好提示词 | 大模型很大应用很小 | 创业者要把细节做好

好的，我將這段文稿整理如下，希望能更清晰易讀：

**主題：獵豹創辦人傅盛在 AGI Playground 大會上關於 AI 的分享精華**

**整理者：大飛 (最佳拍檔)**

**內容概要：**

傅盛 (獵豹創辦人兼 CEO) 在 AGI Playground 大會上分享了他對 AI 浪潮的理解和創業心得。

**主要觀點 (第一人稱復述)：**

*   **早期 AI 投入與挑戰：** 2016 年開始投入 AI，在視覺、語音識別上投入約 1 億美元。當時的難題在於語意理解，也就是「智能」的定義。生物的智能是對現實的預測，而人類獨有的智能是描述虛擬事物的語言 (邏輯)。
*   **語意理解的學習方式：** 最初認為應該教電腦知識圖譜，像學習外語一樣。但後來發現 OpenAI 的方式更有效，也就是像教小孩一樣，讓 GPT 自行學習文本間的規律，產生認知和推理能力。
*   **GPT 的本質：** GPT 是一個大號計算機，透過預測每個詞來理解世界。一旦理解了它的原理，就不會過度恐慌。
*   **ChatGPT 的影響：**
    *   **交互的變革：** 交互方式的變化會導致範式的改變，部分工作將被取代。
    *   **電腦前工作價值下降：** 本質上是將自然語言翻譯成機器指令的工作，價值將會下降。例如：程式設計師、PPT製作人員。
*   **未來人類的分化：**
    *   **AI 的駕馭者：** 保持好奇心，主動學習，善於思考、提問、創造。
    *   **單純的躺平享受者：** 被動、封閉，領取世界幣過生活 (Sam Altman 的理想)。
*   **對 AI 的看法：** AI 只是計算機，沒有好奇心和主動性，仍需要人類輸入和優化，因此人類仍有大量工作可以做。
*   **大模型創業機會：**
    1.  **角逐千億大模型：** 難度較大，競爭激烈，不易獲利。
    2.  **開發行業垂直大模型：** 越來越多人認同垂直模型的重要性。
    3.  **開發大模型應用：** 結合大模型進行應用開發，空間廣闊。
    4.  **應用大模型：** 非技術或數據公司，將大模型應用用好即可，例如：使用數位員工、私有化部署大模型。
*   **創業的本質：** 創業家與投資人互相成就。行業發展取決於生態。應用開發的關鍵在於數據。
*   **知識的來源：** 書本知識只佔一小部分，密集的會議討論和共識才能提供最大的價值。
*   **Prompt 提示詞的重要性：** Prompt 是被忽略的關鍵點，它是自然語言的壓縮和橋樑，對大模型能力進行深度挖掘和微調。
*   **未來應用生態：** 應用生態將決定大模型公司的商業價值。
*   **大公司與創業公司的競爭：** 巨頭與開源社群的競爭將難分伯仲。創業公司需要敬畏大公司，大公司優勢在於整體的邏輯。
*   **獵豹的 AI 發展：**
    *   **數位員工**
    *   **大模型應用 (展示為極客公園輸出大會方案的 AI 智能體)**
    *   **行業信息大模型 (基於開源模型訓練)**

**獵豹應用案例：**

*   **聚言 (企業應用)：**
    *   **推銷員：** 網頁配置後，成單率提高 3 倍。
    *   **機器人促銷員：** 在燕之屋、雙匯落地，幫助客戶轉化成單。

**對 AI 發展的看法：**

*   **細節的重要性：** 做 AI 應用，魔鬼都在細節裡。應用必須小而深。
*   **湧現：** 大模型為什麼會湧現智能尚未被證明。
*   **大模型的白盒化：** 學界正在努力將大模型運行過程推導出來，未來可能不需要大量級參數。

**建議：**

*   保持好奇心，深入學習，把細節做好，相信每個人都有機會成功。

**大飛的個人觀點 (與傅盛觀點不同)：**

*   對蘋果手機競爭激烈不賺錢的說法持保留態度。
*   對跟牛頓對談比看書價值大的說法持保留態度。

**備註：**

*   整理內容僅作分享，不代表大飛本人觀點。

**整理說明：**

*   將文稿整理為更結構化的格式，方便閱讀。
*   對重要觀點進行強調，並加入了標題和子標題。
*   修改了一些語句，使其更通順易懂。
*   保留了文稿的原意。

希望這個整理對您有幫助！ 如果您需要更多協助，請隨時提出。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>152. [2023-08-04] 【医药】抗癌神药是真的么 | AOH1996 | 20年研发历程 | PCNA靶向治疗 | 抑制70多种癌细胞 | 对健康细胞无害</summary><br>

<a href="https://www.youtube.com/watch?v=vn115XvtoZU" target="_blank">
    <img src="https://img.youtube.com/vi/vn115XvtoZU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【医药】抗癌神药是真的么 | AOH1996 | 20年研发历程 | PCNA靶向治疗 | 抑制70多种癌细胞 | 对健康细胞无害

好的，這是我整理後的文稿，重點更突出，更易於閱讀：

**主題：抗癌新藥 AOH1996 研究進展**

**引言：**

*   最佳拍檔頻道的大飛分享了美國希望之城 (City of Hope) 研究機構開發的靶向藥 AOH1996。
*   該藥物在臨床前研究中顯示出殺死所有實體惡性腫瘤的潛力。

**AOH1996 的故事：**

*   AOH1996 的命名源自於一位名叫安娜·奧利維亞·希利 (Anna Olivia Healy) 的女孩，她在四歲時罹患神經母細胞瘤。
*   安娜的父母成立 A.N.A 基金會，支持神經母細胞瘤的研究。
*   基金會資助琳達·馬爾卡斯 (Linda Malkas) 博士的研究，她因此改變研究方向，致力於開發治療神經母細胞瘤的療法。
*   安娜在與癌症奮鬥五年後去世，但琳達的研究仍在繼續。

**AOH1996 的開發歷程：**

*   2008-2010 年，琳達的實驗室測試了數百種化合物，最終確定了 AOH 系列藥物。
*   2011 年，琳達加入希望之城，繼續開展 AOH 系列藥物的研究。
*   經過十多年的努力，監管機構於 2021 年批准了 AOH1996 的人類臨床研究。

**AOH1996 的作用機制：**

*   AOH1996 抑制癌細胞生長，原理是干擾細胞內的「事故調解員」，使癌細胞在不斷累積的事故中走向滅亡。
*   具體來說，AOH1996 抑制增殖細胞核抗原 (PCNA) 蛋白質，使轉錄複製衝突無法順利解決，最終導致癌細胞凋亡。

**AOH1996 的優勢：**

*   對健康細胞具有較高的安全性。
*   在體外和動物實驗中，廣泛抑制了多種腫瘤細胞的生長，並能縮小腫瘤體積，增強化療藥物的作用。

**臨床試驗進展：**

*   希望之城已於 2022 年 8 月開始 AOH1996 的一期臨床試驗，主要目的是確定最大耐受劑量和劑量限制性毒性。
*   第一位接受新療法的患者情況良好。
*   預計 2024 年 3 月 30 日公布最終實驗結果。

**注意事項：**

*   目前的研究結果僅來自臨床前研究，仍需進行二三期等確定性臨床試驗才能證實。
*   不能認為該藥可以殺死所有癌細胞。
*   媒體報導可能過度誇大。

**總結：**

*   AOH1996 是一個有潛力的抗癌藥物，其研究進展值得關注。
*   但目前仍處於早期階段，需要更多的臨床試驗數據來驗證其有效性和安全性。

**結語：**

*   希望在安娜的祝福下，人類能夠早日攻克癌症。
*   頻道後續影片將回歸人工智能領域。

**調整說明：**

*   **簡化語言：** 減少口語化表達，使文稿更精煉。
*   **突出重點：** 使用標題、小標題和列表，使資訊更易於閱讀和理解。
*   **組織結構：** 重新組織文稿，使其更具邏輯性。
*   **去除贅述：** 刪除不必要的細節，保持文稿簡潔明瞭。
*   **增加標題:** 把段落信息提煉成標題，方便快速了解信息。
*   **語氣轉變:** 從口語化的轉述，修改成書面報告的語氣。

希望能幫助到您！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>151. [2023-08-03] 【超导】LK-99背后的故事 | 幽灵般出现的波动 | 两人坚持了20年的梦想 | 人类为何如此追求超导</summary><br>

<a href="https://www.youtube.com/watch?v=UyhQtBv_0eE" target="_blank">
    <img src="https://img.youtube.com/vi/UyhQtBv_0eE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【超导】LK-99背后的故事 | 幽灵般出现的波动 | 两人坚持了20年的梦想 | 人类为何如此追求超导

好的，我來幫您整理這篇文稿，主要會著重在以下幾個方面：

*   **精簡冗言贅字：** 去除口語化的語助詞和重複的表達，使文稿更精煉。
*   **調整段落結構：** 按照內容主題重新組織段落，使邏輯更清晰。
*   **潤飾語句：** 改善語句的流暢度和準確性，使其更符合書面語習慣。
*   **統一標點符號：** 確保標點符號的使用一致且正確。

以下是整理後的文稿：

---

大家好，這裡是最佳拍檔。我是大飛。

近期關於LK-99的討論十分熱烈，看好與不看好者皆有，這實屬正常。科學家們正於實驗室中進行密集實驗。作為普羅大眾，我們應盡力跟隨、接觸、了解LK-99，逐步形成自己的認知，而非盡信他人之言。須知，一切皆是相，我們身為人類，時常處於顛倒妄想之中，內心有著無數的幻想，但往往只見事物的一面。若要我說，好即是壞，壞即是好，並無區別。原子彈如此，LK-99亦然。

今天我們不談技術，此事應交由科學家與業餘科學愛好者。我僅作為與大家一樣的普通人，想講述LK-99背後的故事。作為上個視頻的姊妹篇，科學發明固然偉大，但其背後的故事與人物，可能更耐人尋味，引人深思。

自7月22日起，世界各地的實驗室暗流湧動，高溫爐悄然運轉，業界私下稱之為「全球煉丹」。這股暗流源自韓國科學家公開發表的室溫超導論文。即便人類已對此失望無數次，「室溫超導」四字仍具有強大的魔力，因為它是物理學的聖杯，歷代科學家的魔咒，貫穿122年的人類野望，以及貨真價實改變時代的力量。

若室溫超導成真，疫情後奄奄一息的世界、俄烏衝突的陰雲、蔓延全球的蕭條，都將成為歷史的插曲，文明將翻開全新的一頁。所有電子產品都將重構，交通能源都將顛覆，量子超算和可控核融合將會實現。更重要的是，停滯許久的物理認知，也將突破枷鎖，世界將展示其更深處的秘密。

在電影《阿凡達》中，人類遠征的目標，就是潘朵拉星球上的室溫超導礦石，為此不惜征伐其他文明。在那個未來之中，星際飛船、磁懸浮列車、超導輸電，都要依靠超導礦石，而室溫超導則是文明的基石。如今，蘊藏魔力的室溫超導材料，或許就藏在韓國的論文之中，材料可於網購，高中實驗室即可復現，只需坩堝煉製34小時，所有人類都在屏息凝神，於爐前等待結果。

在等待之時，不妨讓我們回到這場夢的起點。1911年春天，58歲的荷蘭物理學家昂內斯在極低溫度下測試水銀電阻。當溫度降至4.2K（-268.95℃）時，電阻消失。昂內斯以擅長製造低溫聞名，綽號「絕對零度先生」，超導僅是他的意外發現。彼時，二十世紀剛剛開始其混亂的序章，東方王朝轟然坍塌，一戰陰雲正在積蓄，福特汽車和豹式坦克先後咆哮，而超導僅是實驗室台上的火種。

此後十年，物理學家不斷更換金屬材料，最終止步於1930年的金屬鈮，超導溫度停留在9K（-264℃）。此後40年，科學家們一直在測試各種不同的金屬化合物，然而超導溫度一直在23K（-250℃）以下徘徊，彷彿存在一個看不見的魔咒，阻止結界被打破。最終，學術界推出了麥克米蘭紅線，即超導溫度不可超過40K（-233℃），此溫度宛如天條般不可逾越，超導研究因此凋零，淪為冷門學科。

直到1986年，瑞士科學家另闢蹊徑，用絕緣體陶瓷測試，將超導溫度提升到了35K（-238℃）。被壓制了75年的溫度禁錮，一朝被打破，兩位年輕科學家不敢相信，反覆測試8個月後，才於當年9月發表論文。論文飄揚過海，傳至日本，東京大學教授隨手將其布置成本科生作業。不曾想，一個月後，本科生卻證實了實驗結果。同月，論文也傳到中國，中科院物理所研究員趙忠賢在最新一期的美國雜誌中看到論文，開始著手實驗。冥冥中，歷史的車輪向前滑了一小步。中國實驗突破的契機，在於使用五十年代的庫存材料，因當時工廠水平較差，產品雜質較多，卻意外指明了突破的方向。

1986年12月，日本團隊將超導溫度提升至52.5Ｋ，同月，中國團隊發現70K超導體。隔年1月，中國團隊將紀錄提升至100K，3月，日本團隊將紀錄刷新為123K（-150℃）。結界被打破，天條被抹去，1987年成為超導沸騰的一年。美國成立了超導委員會，國會撥款1.5億美元，總統里根專門發表講話，提出11點超導倡議，其中提到：「科學告訴我們，超導方面的突破使我們進入了一個新時代的門檻。」

一個月後，在紐約曼哈頓酒店內，物理學家們召開了一次超導會議，3000多名學者湧入會場，走廊都被坐滿，氣氛猶如現今的音樂節一般。20年後，參加會議的學者仍對那一晚的歡騰念念不忘：「就好像參加了一場烹飪大賽，見人就問你用了什麼秘製的配料？」每段5分鐘的演講，從晚上7點30分一直延續到凌晨3點15分，歡呼聲潮水起伏，演講裡到處都是「世界已經改變了」。

那一年，全世界都以為即將跑步進入超導紀元，中國的超導研究者從數百人激增至數萬人，《人民日報》頻繁報導超導相關新聞，一代人的科幻小說中寫滿了超導。按照之前的突破速度推算，有媒體稱人類一年之內將實現室溫超導。

然而，歷史無意間又開了個玩笑，超導故事轉向低潮，直到1994年，超導溫度停步於164K（-109℃）。聖山不在，又何來盜火者？因缺乏理論支撐，超導研究者大多開始盲選材料，科學開始往玄學方向發展。2011年，日本國家材料實驗室突發奇想，鐵化合物泡在酒中會否創造新的超導材料？科學家測試了紅葡萄酒、白葡萄酒、日本清酒、日本燒酒和威士忌，最後發現紅酒表現最好，但依舊不明白其中的道理。世界也彷彿飲過紅酒一般酣醉如泥。

1994年，超導溫度停滯後，在韓國高麗大學，教授崔東植發布了「原子超導帶」理論，因過於離經叛道，關注者寥寥，漫長的時間內，只有他帶的碩士李石培寫了一篇相關論文，除此之外，再無人問津。

1997年，崔東植看中了24歲的碩士金智勛，金智勛原本研究電池，在他勸說下加入超導小組，順便攻讀博士學位，三人小組開始寂寞的研究。他們沿著八十年代的思路，兩年間測試了數十種陶瓷材料，但是都無法驗證崔教授的理論。

1999年，瀕臨放棄的金智勛在測試鉛磷灰石樣品時，突然發現儀錶上出現一個微弱的波動，疑似超導所致。三人無比激動，重複試驗，但是波紋再難重現，恍如幽靈一般。最終，失望的金智勛放棄超導，轉回電池研究，以電池材料研究獲得博士學位。畢業後，他到一家生產助聽器電池的小公司上班。另一位學生李石培繼續堅持了9年，最後以超導理論研究完成博士論文，但是他的科研激情已消磨殆盡，到一所私立大學擔任了計算機老師，生活平庸如常，日子朝九晚五。工作之外，金智勛和李石培時常相聚，並且成立了一家名叫量子中心的皮包公司，接一些小諮詢生意，超導更像是少年時做的一場夢。

一晃十年時間匆匆而過，2017年5月，崔東植教授病危，彌留之際，他將曾經最心愛的兩名學生召至床邊。在病榻上，崔東植留下遺願，希望兩人能找到1999年那個幽靈波紋。他告訴兩個學生，拜託了，繼續研究下去，但是在它完美的實現之前，不要讓世界看到它。

導師病故後，李石培決定完成遺願，重啟實驗室，並找到金智勛加盟。金智勛表示大家人至中年，不能再像學生時代那般肆無忌憚，要想專心全職研究，必須要籌集資金，購買專業儀器。於是，在導師的老朋友幫助下，他們向韓國國家科學基金會提交申請，但是因為兩人十年間沒發表過任何論文，被果斷拒絕。

此後，李石培找到高麗大學終身教授、物理學家權英完。當時權英完手裡有兩台測量儀器的使用權，考慮到只需要掛名和提供理論指導，權英完同意加盟，下班後偶爾到實驗室指導。此時，量子中心已經從一個皮包公司轉為一個真正的物理實驗室，地點設在首爾小區邊一棟舊商業樓的地下一層。

2018年，超導重啟，但是矛盾很快產生。金智勛擅長實驗，專注於用實驗來復刻1999年的波紋，而權英完則是學院派，認為理論研究才最重要。李石培只能頻繁調和，爭吵之中，金智勛堅持實驗測試，在無窮組合中重新尋找那個幽靈波紋。

2020年，全球疫情爆發，城市被割裂成孤島，金智勛關在實驗室中繼續測試。在某個清晨，他意外看到儀器上陡峭的波形，那是1999年之後，幽靈波紋再次清晰地重現。他反覆測試，同樣的材料，同樣的環境，但是波紋又一次的消失了。他查看監控視頻，發現從爐中拿出裝有樣品的真空石英管時，他肘部不慎碰到了桌子，震動令試管出現了裂痕，裂痕導致氧氣進入，改變了晶體結構。文明的躍遷好像玩笑一般，但也似乎冥冥中自有定數。

方向到這時就明確了，三個月之後，歷經1000多次的實驗，室溫超導材料煉製成功。在論文視頻中，它展示出了超導必備的抗磁性，可以漂浮，就像一個魔法石頭。新材料被命名為LK-99，L和K是李石培和金智勛姓名的首字母，而99指向一切開始的1999年。LK-99的製作過程複雜又原始，需要用缽杵研磨，需要把握開爐的時間，並且在合適時機，撞擊真空石英管。三個人中，只有金智勛能夠操作。

2020年，三人團隊完成論文，向《自然》雜誌投稿，然而因印度裔學者剛上演了一場室溫超導的鬧劇，《自然》雜誌壓力巨大，論文被拒。權英完認為被拒的原因是過世的崔教授理論不完備，於是團隊之間產生了巨大的裂痕。

李石培轉而求助美國韓裔科學家金鉉卓，但是金鉉卓並不相信室溫超導成功，直到疫情結束，封鎖打開，他乘飛機到韓國，親眼見到那顆漂浮的晶體。2022年，金鉉卓美國團隊開始重複LK-99製作過程，產量很低，每10次只能成功1次。此時，權英完的貢獻僅僅是能提供測量設備。2023年3月，他被量子中心解聘。今年7月22日早上7點，權英完搶先發布論文，公開LK-99，兩個半小時之後，李石培等人發布更詳細的論文，作者名中並無權英完。

4天後，為了證明實驗為真，金鉉卓上傳了視頻，在視頻中，晶體一邊翹起，半懸空中，全球實驗室開始全速運轉。第二篇論文給出了詳細合成的步驟，步驟並不複雜，材料也僅僅需要一氧化鉛、硫酸鉛粉、銅和磷。在廣袤的未知面前，人類再次懵懂如煉金術士。

相關話題一度在知乎熱榜榜首掛了4天，但是無人證真也無人證偽。在文明的關鍵節點面前，學術界依舊保持著謹慎。最先打破沉默的是B站up主「關山口男子技師」。他是最早一批開啟測試的人，並且在B站直播動態。第一爐煉出的材料，觀測到了與論文相似的曲線。

8月1日，他在B站上傳視頻「LK-99（潛在室溫超導材料）驗證」，並公佈身份，他是華中科技大學材料學院博士後武浩，他和博士女友楊麗一起，在教授常海欣的指導下，首次復現了可磁懸浮的LK-99晶體。視頻中，微小的晶體在牙籤前抖動，展示出極強抗磁性。一天內，視頻播放超800萬，網友回看視頻發現，測試全程，武浩手指和聲音都在顫抖，滿屏彈幕都在刷著「見證歷史」。有網友在彈幕中留言，那個在白紙上撲騰的小黑點，有蝴蝶撲棱小翅膀的美感，也許能扇動人類科技進步的颶風。

8月2日，更多消息傳來，中科大團隊稱初步測試材料表現出抗磁性、半懸浮，美國勞倫斯伯克利國家實驗室用計算機模擬確認存在超導可能。目前，華中科技大學團隊正在燒製第三爐樣品，驗證最終的超導性。

而在今天8月3日，東南大學物理學教授孫悅發出視頻，團隊在110K（-163°C）溫度以下的常壓條件下，成功觀測到了LK-99的零電阻。有清華學者稱，室溫超導帶來的變革將遠超人工智能，人工智能只是上一輪浪潮的迭代，而室溫超導將重新定義世界規則。

在已知的變化中，它能夠幾秒鐘完成電車充電，讓一切電子產品小型化，升級核磁共振，改變電力傳輸，顛覆能源格局，重塑地緣政治，而產生的連鎖變化將超出所有人現有的想像。正如里根在八十年代那次暢想中所說到的，當班傑明·富蘭克林第一次從閃電中捕獲電力時，沒有人夢想過計算機或通信衛星。

動盪不安的時代，陡然行至岔路，蕭條的世界意外打開門扉。但是，那道門現在只是開了一道縫隙，結局未定。門外的我們，只能耐心等待。也許最終門縫會關上，但是我從心底期待它是真的，正如潘朵拉的盒子，最後留給人間的唯有希望。這或許將是人類文明至關重要的節點，我們好像在重溫那些時刻，彷彿看見蘋果從樹上掉下、水壺中噴出蒸汽，以及特斯拉在海角點亮璀璨的電塔。如果說，我們的人生所能經歷的最重要的歷史時刻，或許便是此刻。

如果你非要問我超導時代是否到來，人類的第四次工業革命時刻是否到來，我只能回答兩個字，如來。

感謝大家的觀看，我們下期再見。

---

**整理說明:**

*   **簡潔性:**  刪除了不必要的口語化表達和重複信息，使文稿更加精煉。
*   **結構性:**  重新組織段落，將相似主題的信息放在一起，增強邏輯性。例如，將對歷史的回顧集中在一起，將對各國實驗室的進展放在一起。
*   **流暢性:**  潤飾了部分語句，使其更符合書面表達習慣，讀起來更流暢。
*   **專業性:**  用更正式的詞彙替換了一些不夠專業的表達。
*   **標點符號:**  檢查並統一了標點符號的使用。

希望這個版本更符合您的要求。如果您需要進一步的修改，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>150. [2023-08-02] 【超导】LK-99常温超导晶体 | 中美俄实验室同日复现 | 韩国团队内讧 | 相关美股暴涨 | 专家仪器竟比不过坩埚| 炼金术成真| 第四次技术革命到来？</summary><br>

<a href="https://www.youtube.com/watch?v=0E7znys97z0" target="_blank">
    <img src="https://img.youtube.com/vi/0E7znys97z0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【超导】LK-99常温超导晶体 | 中美俄实验室同日复现 | 韩国团队内讧 | 相关美股暴涨 | 专家仪器竟比不过坩埚| 炼金术成真| 第四次技术革命到来？

好的，我將以上文稿整理如下，主要目標是讓它更易讀，並保持原文的幽默和信息量：

**第四次科技革命要來了嗎？常溫超導體LK-99晶體的真相解析**

大家好，這裡是最佳拍檔，我是大飛。朋友們，我們很有可能要見證第四次科技革命的到來了！

**超導體的劃時代發現？**

7月22日，韓國科研團隊發表了一篇論文，宣稱他們發現了常壓室溫超導體LK-99晶體。在正常大氣環境下，它可以在127攝氏度以下實現超導。這意味著，幾乎在任何地方，我們都可以具備超導特性，不再需要昂貴笨重的超低溫製冷設備。

如果這個發現屬實，整個人類社會所有的電氣設備都需要更換，甚至連電線都要換掉。因為我們現在的文明是建立在電力之上的，常溫超導體的製備無疑會直接顛覆這個世界。

**資本市場的瘋狂反應**

8月1日，美國超導股票AMSC盤前跳漲71%，最高漲幅達到150%，非常誇張。就像中國A股從3000點漲到6100點一樣。

**為什麼反應慢了十天？**

為什麼韓國團隊發表論文十天後，美國股市才做出反應？這就要說說這十天裡發生了什麼。

首先，大家普遍認為韓國科研的信用度沒那麼高。這麼重要的諾貝爾獎級發現，怎麼會這麼容易讓韓國人摘走？此外，這次公布的製備方法實在太離譜，讓人難以置信。

**離譜的製備方法：堪比古代煉金術**

常壓室溫超導體聽起來是超尖端科技，應該只有最頂級的實驗室才能研發出來，製備流程也應該是各種高科技。但韓國團隊公布的辦法，簡直就像古代煉金術：把一堆粉末材料扔爐子裡燒，燒完了就出現超導體了！設備要求低到高中實驗室就能做，流程簡單到誰都可以弄。

就像網友說的，人類一直在尋找長生不老藥，結果發現把紅豆、綠豆、黃豆按1:2:3的比例混在一起就成了。甚至有業界人士感慨：「太簡單了，簡直是真的。」

**LK-99晶體的製備工藝**

這個足以顛覆全世界的超導晶體LK-99的製備工藝到底是什麼樣？仔細聽好，因為每個字都價值萬兩黃金：

1.  **第一步：** 買一點氧化鉛和硫酸鉛粉末，按1:1的比例放入坩堝中均勻混合，在空氣中加熱至725度燒24小時，得到黃鉛礦晶體。
2.  **第二步：** 把銅單質和磷粉末放入真空管，在坩堝裡以480度的溫度加熱48小時，得到磷化亞銅晶體。
3.  **第三步：** 把前兩步燒製出來的兩種晶體研磨成粉末後放入真空管，在坩堝裡以925度加熱5~20個小時，然後你就得到了一種銅摻雜的鉛磷灰石，也就是LK-99晶體，具備常壓室溫超導性能。

氧化鉛、硫酸鉛和銅單質都是超級普通的不值錢材料，到處都是。換句話說，這個製備流程裡最昂貴的居然是那個能加熱的坩堝！而哪怕是高中實驗室裡都會有坩堝。只要你擁有一個坩堝，按照上述流程去做，就可以燒出常溫超導體。

**手搓超導體？**

現在，你覺得這東西聽起來靠譜嗎？這簡直就是手搓超導體，像村民分享光速飛船製造技術一樣。如果這玩意是真的，全球各國超導領域頂級實驗室的大牛們，人生觀都會被徹底顛覆，下半輩子陷入迷茫，不知道自己的工作還有什麼意義。原來煉丹術才是王道，把各種東西丟爐子裡燒碰運氣才是終極方案。

**疑點重重**

如果這是真的，韓國團隊直接拿出樣品給人檢測不就好了？工藝這麼簡單，超導體應該可以隨便燒。如果我能用這種辦法製備出常溫超導體，肯定自己燒幾公斤出來到處郵寄樣品。但韓國團隊描述的製備方法如此簡單，卻連一克樣品都拿不出來給別人，這非常可疑。

**內訌疑雲**

這次事件還出現了內訌現象。7月22日，三人合著的論文發布在arXiv上，兩個半小時後，六人合著的論文也發布到了arXiv，對實驗的製備過程描述的更詳盡，行文更嚴謹。

這次的LK-99，是一位L老師帶著研究生K，繼承了L老師的實驗，在1999年就把材料做出來了。L和K作為“民科”，很難投稿，又要吃飯，於是找了個工作幹了十多年。後來有個韓國金主看上了他們，投錢給他們繼續研發。但韓國金主的財力和人脈不夠，這事就耽擱了。後來，L和K又找到一個美國金主，帶著資金和團隊加入，導致韓國金主不滿。由於諾貝爾獎最多發三人，韓國金主肯定被踢出局，於是搶先發布論文，想踢出美國金主。美國金主也忍不住了，發布了更詳細的論文。

整個過程說明，如果是實驗造假，犯不著這麼多人內訌，也犯不著申請專利。而且製備方法簡單，試試沒啥成本，所以各個超導領域的實驗室都在安排人燒爐子。

**初步驗證？**

理論上3天半就可以燒出樣品，但9天過去了，全世界那麼多實驗室的爐子裡，都沒燒出一塊符合韓國團隊描述的樣品。但在第十天，8月1日，中美俄三國的實驗室同時宣布，自己初步驗證了韓國團隊描述的超導晶體LK-99。

*   **美國：** 勞倫斯伯克利國家實驗室的超級計算機模擬結果顯示，當銅取代磷灰石中的鉛時會引起結構畸變，從而導致費米能級的孤立平帶，也就是高溫超導體。模擬結果和韓國團隊公布的實驗結果僅相差1%，從理論上證明了用坩堝燒製常溫超導體是可行的。
*   **俄羅斯：** 科學家艾里斯·亞歷山德拉成功製備出了具備常溫抗磁性的LK-99晶體，而常溫抗磁性正是超導晶體的標誌之一。
*   **中國：** 華中科技大學的實驗室首次驗證合成了可以磁懸浮的LK-99晶體，懸浮角度比韓國團隊描述的更大，有望實現真正意義的無接觸超導磁懸浮。

華中科技大學實驗室的影片在B站爆紅，網友彈幕刷屏“見證歷史”。

**還不能確定是超導體**

嚴格來說，目前中美俄的實驗室都屬於“初步驗證”，還沒有實打實的測試其超導性能。美國只是進行了模擬驗證，中俄燒出了樣品但沒有做超導測試，因為做超導測試需要破壞樣品，太珍貴了。

**為什麼敢說初步驗證？**

因為其在常溫下的抗磁性異常強大，常溫未通電的情況下，就可以在磁場的兩個方向上均實現輕微懸浮。不排除這是一種從未發現的超強抗磁材料，但常溫超導體正具備這樣的特性。加上美國實驗室的理論驗證，基本可以認定完成了初步驗證。因此美國資本市場直接瘋狂了，大量資金湧入，賭人類的下一次技術革命。

**燒製概率極低**

根據超導理論，電子通過晶格時會發生震動，震動的粒子如果撞到電子就會產生電阻。低溫可以降低粒子活性，高壓可以壓住粒子，但怎麼才能把粒子互相鎖住呢？

這次韓國團隊恰好實現了把粒子互相鎖住的壯舉。他們把不同的材料燒來燒去，最後恰好在一片樣品中把銅粒子包裹住了鉛粒子，鉛粒子裡面壓住了一圈氧離子，製造出了銅皮鉛心的管道。最裡層的氧離子被鉛粒子死死壓住，難以震動，從而導致電子流過時不會產生電阻。

這種燒製方式像抽彩票，必須銅粒子恰好出現在晶格恰當的位置才能形成超導晶體。如果只有一小部分銅位於正確的位置那就是廢品，哪怕形成的管道有一處破損，都沒有超導特性。而這銅粒子的移動無法定向控制，完全靠高溫燒製時銅的隨機移動。

**韓國團隊為何公開？**

這也解釋了為什麼韓國團隊拿不出樣品。雖然他們已經發現這種超導晶體幾個月了，甚至申請專利都5個月了，但始終無法突破定向燒製的技術，甚至自己燒製的無數爐子裡都沒法復現樣品。他們實在沒有多餘的東西可以郵寄給別人去鑒定。

這也解釋了為什麼韓國團隊要公開這項堪稱技術革命的發現。因為他們保密了好幾個月，連第二塊樣品都燒不出來。但燒製的技術太簡單了，如果再拖下去被別人搶先發了論文，那成果就是別人的了。不如直接公開，靠提前申請的專利賺一筆錢。

**超級抗磁材料的價值**

從目前中美俄實驗室的結果來看，這最差也是一種新型的超強抗磁材料，對研發磁懸浮技術具有重要價值。最好的情況就是打開了人類常溫超導的大門。只要證明了這種材料是真實存在的，集合國家級的力量去研發，突破定向合成技術，突破大規模低成本生產技術，都只是時間問題。

**石墨烯的故事**

這次的常溫超導體是用爐子燒出來的，讓我想到了前些年轟動全球的石墨烯材料。那是一個用膠帶撕出來的！這個人覺得用膠帶撕石墨可以越撕越薄，最後得到他想要的薄薄的石墨材料。然後堅持不懈的用膠帶撕了一個月，得到了一種性能強悍到極致的新材料。正常材料專家是不可能去做這種事情的。

**常溫超導體的意義**

如果人類真的製造出了常溫超導體，那意義有多大？

*   **所有電機都要換新的：** 用超導材料做成的電機效率將遠遠高於目前產品，重量和體積都會大減，沒有發熱和能量損耗現象，功率也會暴增2~3倍。
*   **長距離輸電：** 如果能用超導材料導致電阻消失，那對整個人類電網帶來的性能提升簡直可怕。
*   **電磁彈射、電磁武器、磁懸浮軌道交通等等：** 要麼性能暴增，要麼體積大減。

即使是最保守的考慮，光把目前性能落後的電機電線換完，都是一個龐大無比的工程，帶來的需求和就業刺激會異常膨大，足以把當前萎靡的世界經濟徹底激活。

**受益者是所有人**

這次超導體的技術革命會直接導致材料和化學至少未來50年不愁沒事做，把超導體從實驗室裡碰運氣合成的幾十微米的樣品變成走入千家萬戶的普通廉價工業品。這需要攻克無數的技術問題，需要千千萬萬的材料化學工程師來完成。

從富豪到貧民都會因此得到生活水平的飆升。

**結論**

常溫超導體是人類最高端的材料，但高端的材料往往只需要最樸素的烹飪方式，萬物皆可燒，大家一起去燒爐子拼運氣才是材料學的終極科研方法。

建議大家在家沒事的時候多搗鼓一下，說不定下一個諾貝爾獎就是你的了！

**聲明**

本期影片僅供參考，大部分內容整理自網路。如有專業方面解釋不到位的，歡迎大家在評論區指出和補充。感謝大家的觀看，我們下期再見！

**整理說明：**

*   **結構化：** 使用標題和副標題，將文章內容分成幾個部分，使其結構更清晰。
*   **段落分明：** 根據內容調整段落，使其更易於閱讀。
*   **簡化語言：** 在不改變原意的基礎上，將一些複雜的句子簡化。
*   **加強重點：** 使用粗體字突出重要的資訊和結論。
*   **保留風格：** 盡量保留原文的幽默和口語化風格。
*   **刪除贅述：** 刪除了一些重複或不必要的內容，使其更精煉。

希望這個整理後的版本能更好地傳達原文的資訊！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>149. [2023-08-01] 从罗刹海市到人工智能 | 刀郎 | 维特根斯坦 | 语言哲学 | 人类与AI面临一样的困境</summary><br>

<a href="https://www.youtube.com/watch?v=6jBQDAUk5QQ" target="_blank">
    <img src="https://img.youtube.com/vi/6jBQDAUk5QQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 从罗刹海市到人工智能 | 刀郎 | 维特根斯坦 | 语言哲学 | 人类与AI面临一样的困境

好的，我來為您整理這篇文稿，目標是更清晰、更易讀，並保留原文風格。我會將其分點歸納，突出重點，並適度調整語氣，使其更像一份書面報告，而非口語化的文稿。

**文稿整理：刀郎《羅剎海市》與維特根斯坦的哲學思辨**

**前言：**

*   本期節目以蹭熱度為目的，借刀郎歌曲《羅剎海市》的爆紅（全球播放超過80億次）切入主題。
*   歌曲爆紅後，網路上出現大量歌詞解讀。本文不重複前人觀點，而是聚焦歌詞中「西邊的歐鋼有老闆，生兒維特根斯坦」一句，探討維特根斯坦的哲學思想及其與當代AI發展的關聯。

**一、維特根斯坦生平與哲學思想：**

*   **簡介：** 路德維希·維根特斯坦是20世紀最具影響力的哲學大師之一，與尼采齊名。
*   **哲學觀點：**
    *   **語言遊戲：** 維特根斯坦認為所有哲學思維本質上都是語言遊戲，每個思考者的表達都是一種個人語言，在合法性上人人平等。
    *   **對確定性的質疑：** 他挑戰了人類對理性的信任和對確定性的追求，認為試圖通過邏輯推導來證明世界本質是錯誤的。
*   **人生經歷：**
    *   早年曾是林茨中學的學生，與希特勒為同學。
    *   參加一戰後，於戰俘營中完成其劃時代作品《邏輯哲學論》。
    *   放棄家族遺產，前往奧地利南部山區擔任鄉村教師，試圖啟蒙大眾，但以失敗告終。
    *   後在凱恩斯等人幫助下前往英國劍橋繼續哲學研究，並成為聖三一學院的哲學教授。
*   **對羅素的影響：**維特根斯坦是哲學家羅素的學生，羅素認為自己一生中最偉大的貢獻是培養了維特根斯坦，維特根斯坦對羅素的思想並不滿意，常在信中訓斥羅素。羅素也坦承自己無法理解學生的思想。
*   **燒火棍事件：** 維特根斯坦與波普（提出開放社會和證偽概念）曾爆發激烈爭論，維特根斯坦氣憤至極，拿起燒火棍攻擊波普，成為西方哲學史上著名的「燒火棍事件」。

**二、維特根斯坦對西方哲學的批判：**

*   **挑戰哲學框架：** 維特根斯坦認為西方哲學思想如同惡意居住在貧民窟的大房東，奴役人們的精神世界。他致力於破壞哲學的固定框架，解放受壓迫的人群。
*   **語言分析：** 維特根斯坦借助邏輯分析和語言分析，旨在破解哲學的幻象，為人們提供精神治療。他認為人生的痛苦往往源於對問題的過度關注，消除問題就能找到內心的平靜。
*   **東西方思維差異：**
    *   **東方：** 依賴天文学和地理学，得出「道」的概念。
    *   **西方：** 基於語言和思考，發展出對逻各斯和反自然的推理，但這種推理是無根基的。
*   **字母文字的批判：** 維特根斯坦認為字母和符號文字本質上是一種與自然脫節的編程語言，而非真正的自然語言，西方人的思維模式與充滿二極管的電腦有許多相似之處。

**三、語言的框架與AI的困境：**

*   **語言框架的束縛：** 無論是人類還是AI，都被困在語言的框架中。語言成為我們理解和描述世界的唯一框架，對思維方式產生深遠影響。
*   **AI的困境：** AI在語言的海洋中模仿人類的語言模式，試圖理解和模擬人類的思維，但其「理解」受限於數據和算法的邊界，無法超越人類為它設定的框架。
*   **語言的鏡像作用：** 我們的語言和思維，就像一面鏡子，反映出的是我們自己的形象，而非真正的世界。

**四、維特根斯坦的解決方案：靜默**

*   **對語言的超越：** 維特根斯坦提出「我們不能說的，就要保持沉默」，這不是對語言的否定，而是對語言的超越。
*   **回歸真實：** 靜默可以幫助我們逃脫語言和思維的束縛，回归真实的世界。

**五、刀郎《羅剎海市》的哲學意涵：**

*   **語言遊戲：** 歌詞中「他言說馬戶驢，又鳥雞，到底那馬戶是驢還是驢是又鳥雞」是對維特根斯坦核心哲學思想的引用，表達了語言如何被用來模糊、扭曲甚至顛倒事實。
*   **人類的根本問題：** 歌詞「那馬戶又鳥是我們人類根本的問題」揭示了刀郎的觀點，即語言和事實之間的關係問題是人類面臨的根本問題。
*   **對語言的反思：** 刀郎通過歌曲向我們提出了重要問題：我們是通過語言來理解世界，還是用語言來扭曲我們對世界的理解？

**六、結論：**

*   《羅剎海市》不僅是對維特根斯坦的一種致敬，也是對我們如何對待語言、如何理解和詮釋世界的一個深刻的質疑。
*   无论是人类还是AI，我们都在通过语言来理解和表述世界，但是语言又无法准确地描绘出世界的真实面貌。因此，马户到底是驴还是驴是又鸟鸡？或者说，这个问题究竟有没有答案？ 这值得我们深思。

**備註：**

*   請勿過度解讀本分析，本分析僅為蹭熱度，將《羅剎海市》與人工智能聯繫在一起，僅供參考。

希望這樣的整理方式對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>148. [2023-07-31] 【科技】人工智能有多渴 | Google一年消耗一个半西湖 | 大厂把数据中心都建到哪</summary><br>

<a href="https://www.youtube.com/watch?v=kwbt9K307x4" target="_blank">
    <img src="https://img.youtube.com/vi/kwbt9K307x4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【科技】人工智能有多渴 | Google一年消耗一个半西湖 | 大厂把数据中心都建到哪

好的，這是我整理後的文稿，我會盡力將其結構化，使其更易於閱讀和理解，同時保留原文的口語化風格。

**主題：科技發展的隱憂：數據中心耗水問題**

**引言：**

*   大家好，我是大飛，歡迎來到最佳拍檔。
*   你可能不相信，科技越發展，不僅越耗錢、耗芯片，還更耗水。

**問題的提出：**

*   谷歌2023年環境報告顯示，去年一年花掉了56億加侖水，約等於一個半西湖。
*   其他科技巨頭，如微軟、亞馬遜，也都是耗水大戶。
*   疑問：他們用這麼多水幹什麼？

**數據中心耗水的原因：**

*   主要用於數據中心散熱。
*   早期數據中心主要靠電力驅動的空調散熱，耗電量巨大。
    *   舉例：2021年中國數據中心總耗電量佔全國總耗電量的2.6%。
    *   數據中心6成成本花在電費上，電費裡的4成多又得靠散熱。
*   為了解決耗電問題，企業開始尋找更節能的散熱方法，轉向耗水的方式。

**企業降低數據中心耗電的策略：**

1.  **「哪兒涼快哪兒呆著」：遷移數據中心到涼爽地區**
    *   中國企業：紛紛前往貴州，利用貴州涼爽的氣候和豐富的水電資源。
        *   騰訊在貴州鑿出「七星洞」當數據中心。
        *   華為在貴安新區造「雲上屯」。
        *   蘋果的iCloud數據成了「雲上貴州」。
        *   優勢：地價便宜、電費便宜、氣候涼爽穩定。
        *   例如，華為建完雲上屯後，每年光電費就能省下6億。
    *   國外企業：更狠，直接將數據中心建在北極圈附近。
        *   Facebook在北極圈外的小鎮呂勒奧建立數據中心。
2.  **數據中心本身的進化：改用更省電但耗水的散熱系統**
    *   空調冷卻系統（耗電）逐漸被淘汰。
    *   蒸發冷卻系統：只靠外界水來降溫，大幅減少耗電量，但用水量猛增。
    *   液冷散熱：
        *   阿里巴巴在千島湖的數據中心，設備泡在特製冷卻液裡，但冷卻液仍需大量湖水冷卻。
        *   調侃：網友戲稱買的農夫山泉是阿里云服务器的洗腳水
    *   微軟：將「北方群島」伺服器扔到大西洋海底，利用海水潮汐散熱。

**耗水問題帶來的挑戰：**

*   對缺水地區來說，這種用水方式難以承受。
    *   中國內蒙古：禁止大數據企業使用地下水冷卻降溫。
    *   美國缺水地區（如亞利桑那州）：
        *   大廠瘋狂新建數據中心。
        *   數據中心優先用水，影響當地生態和生活用水。
        *   谷歌在梅薩的數據中心與當地政府簽訂協議，保證用水供應，影響梅薩的生態系統和居民用水。
        *   亞利桑那州政府因供水給數據中心，被迫停止城市基建。
        *   谷歌在達爾斯市的年耗水量接近該市總用水量的三分之一。

**企業的承諾：**

*   為了解決耗水問題，各大廠開始承諾優化散熱設備，例如：
    *   谷歌：承諾到2030年補充自家公司用水量120%的水。
    *   微軟：承諾到2024年減少蒸發冷卻系統用水量95%，2030年實現「水中和」。

**AI爆火加劇耗水問題：**

*   學者發現AI大模型的爆火讓水耗得更多。
    *   谷歌用水量比去年多了20%，算力也長了20%。
    *   加州大學研究發現，訓練GPT-3用掉70萬升水，使用也特別費水。
    *   和GPT們聊個三五十句，就得消耗一瓶農夫山泉的水。

**結論：**

*   在AI熱潮下，數據中心的作用只會越來越大。
*   散熱方法可能迎來新一輪升級。
*   否則在AI搶走人類工作之前，一些地區的水可能就被AI搶走了。
*   大家對這方面有什麼好的想法呢？歡迎在評論區留言。
*   感謝大家觀看本期視頻，我們下期再見。

**整理說明：**

*   **結構化：** 將內容分成引言、問題、原因、策略、挑戰、承諾、AI的影響和結論，使思路更清晰。
*   **精簡：** 刪除了重複或冗餘的信息，避免過多口語化的贅述。
*   **口語化保留：** 保留了「哪兒涼快哪兒呆著」、「水中和」等原句中的口語化表達，以保持視頻風格。
*   **重點突出：** 使用了項目符號和加粗來強調關鍵信息。

希望這個整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>147. [2023-07-31] 【人工智能】DeepMind发布RT-2 | VAL模型 | 泛化能力优秀 | 机器人版ChatGPT | 具身智能最新进展</summary><br>

<a href="https://www.youtube.com/watch?v=mZVTBB_YnZk" target="_blank">
    <img src="https://img.youtube.com/vi/mZVTBB_YnZk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】DeepMind发布RT-2 | VAL模型 | 泛化能力优秀 | 机器人版ChatGPT | 具身智能最新进展

好的，我幫你整理如下：

**主題：谷歌 DeepMind RT-2 機器人：具身智能的重大突破**

**引言：**

*   主持人（大飛）介紹北京梅雨季，引出在家錄製關於具身智能的最新進展。
*   指出大模型在掌握語言和圖像後，下一步發展方向為「具身智能」。

**RT-2 模型介紹：**

*   **重要性：** 谷歌 DeepMind 推出全球第一個控制機器人的視覺-語言-動作 (VLA) 模型 RT-2，不再需要複雜指令，機器人可像 ChatGPT 一樣操縱。
*   **功能展示：** 機器臂可執行將香蕉放到數字上、德國國旗上，甚至遞可樂給泰勒·斯威夫特照片等任務（影片演示，加速播放）。
*   **意義：** DeepMind 機器人技術主管認為 RT-2 是機器人製造和編程方式的重大飛躍，需要重新考慮研究規劃。
*   **RT-2 全名：** Robotic Transformer，也就是機器人的 Transformer 模型。
*   **解決的問題：** 相較於虛擬環境，真實物理世界複雜且無序，傳統機器人需要複雜指令引導才能執行簡單任務。RT-2 讓機器人能自行分析更多信息，推斷下一步該做什麼。
*   **VLA 模型：** RT-2 不僅基於視覺-語言模型 (VLM)，更創造視覺-語言-動作模型，將網路和機器人知識轉化為機器人可控制的通用指令。甚至能使用思維鏈提示，識別哪種飲料適合疲憊的人（例如功能飲料）。
*   **與 RT-1 的比較：**
    *   RT-1 採用單一預訓練模型，從視覺或文本等感官輸入生成指令，執行多種任務，具有更好的性能和泛化能力。
    *   RT-2 建立在 RT-1 基礎上，使用了 RT-1 的演示數據（13 個機器人在辦公室、廚房環境中收集，歷時 17 個月）。
    *   RT-2 比 RT-1 多了一個機器動作 (action) 的模態。

**RT-2 的實現方法：**

*   **基於 VLM：** RT-2 建立在 VLM 基礎上，VLM 模型已在 Web 規模的數據集上訓練完成，可執行視覺問答、圖像字幕生成、物體識別等任務。
*   **採用模型：** 對 PaLI-X 和 PaLM-E 進行適應性調整，作為 RT-2 的主幹，稱為 RT-2-PaLI-X 和 RT-2-PaLM-E。
*   **動作控制：**
    *   將機器人動作表示為另一種語言，即文本 token。
    *   與 Web 規模的視覺-語言數據集一起進行訓練。
    *   機器人的動作編碼基於 Brohan 等人為 RT-1 模型提出的離散化方法。
    *   機器人動作表示為文本字符串（機器人動作 token 編號序列），包含繼續或終止當前環節的標誌、改變末端執行器的位置和旋轉、抓手等命令。
    *   機器人執行動作命令就像執行字符串命令一樣簡單。
    *   可直接對現有的 VLM 進行微調，並將其轉換為 VLA 模型。
    *   推理過程中，文本 token 被分解為機器人動作，實現閉環控制。

**RT-2 的實驗結果：**

*   **定性實驗：** 在语义理解和基本推理方面，例如「把草莓放進正確的碗裡」、「拾起即將從桌子上掉下來的袋子」等任務，RT-2 表現出色。所有這些場景中測試的交互過程在機器人數據中從未見過。
*   **技能測試：** 探索 RT-2 的三項技能：符號理解、推理、人類識別。
*   **優勢：** 在四個基准測試上，RT-2 模型優於之前的 RT-1 和視覺預訓練基線，泛化性能提高了 3 倍以上。
*   **定量評估：**
    *   在机器人数据中有实例的原始 RT-1 任务中，RT-2 保留了機器人在原始任務上的性能。
    *   提高了機器人在以前未見過場景中的性能，從 RT-1 的 32% 提高到 62%。
    *   在开源语言表机器人任务套件上评估模型，模擬中的成功率高达 90%，比 BC-Z、RT-1 和 LAVA 等以前的基线模型有了大幅提高。

**RT-2 的意義與展望：**

*   視覺-語言模型可以轉化為強大的視覺-語言-動作模型，通過將 VLM 預訓練與機器人數據相結合，可以直接控制機器人。
*   RT-2 帶來顯著更好的泛化能力、以及應對突發問題的能力。
*   RT-2 是對現有 VLM 模型的簡單而有效的修改，展示了構建通用實體機器人的前景，讓機器人可以推理、解決問題和解釋信息，從而在現實世界中執行各種任務。
*   與 ChatGPT 類似，這種能力大規模應用可能會給世界帶來不小的變化。
*   谷歌沒有立即應用 RT-2 機器人的計劃，但相信這些能理解人話的機器人絕不只會停留在展示能力的層面上。
*   具有內置語言模型的機器人可以成為家庭助理（例如折疊衣物、從洗碗機中取出物品、收拾房子），並在工業領域有更多使用場景。

**總結與展望：**

*   OpenAI 報告提到體力勞動者不會被首先替代，但 RT-2 出現後，這個結論可能需要重新考慮，因為工廠裡的很多工作可能更容易被機械臂所取代。

**結語：**

*   感謝大家的觀看，下期再見。

**主要改進：**

*   **結構化：** 整理成引言、介紹、實現方法、實驗結果、意義與展望、總結與展望、結語等清晰的結構。
*   **簡潔化：** 刪除口語化的語氣詞，用更精煉的語言表達核心內容。
*   **重點突出：** 用加粗字體標註關鍵詞和重要結論。
*   **邏輯梳理：** 確保內容邏輯連貫，方便理解。
*   **資訊整合：** 將分散的信息點整合到相關的段落中。

這個整理後的文稿更結構化、更簡潔、更易於理解，並突出了 RT-2 模型的核心優勢和潛力。希望這個版本對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>146. [2023-07-30] 【Twitter】 如何评价Twitter和埃隆马斯克 | 睡地板仍被裁的女高管回忆爆料</summary><br>

<a href="https://www.youtube.com/watch?v=T1wcUohiyRw" target="_blank">
    <img src="https://img.youtube.com/vi/T1wcUohiyRw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Twitter】 如何评价Twitter和埃隆马斯克 | 睡地板仍被裁的女高管回忆爆料

好的，我已經整理了這份文稿，重點如下：

**整理後文稿：**

**引言**

大家好，這裡是最佳拍檔，我是大飛。今年最令人關注的科技公司莫過於 Twitter。經歷了馬斯克收購、裁員、更名為 X 等一系列事件，外界對其內部情況知之甚少。前 Twitter 高管埃絲特·克勞福德 (Esther Crawford) 在離職後發表了一篇“我在 Twitter 的一份工作總結”，揭示了 Twitter 內部管理的混亂以及馬斯克入主後的隨性和喜怒無常。本文將翻譯並整理她的文章，與大家分享。

**克勞福德在 Twitter 的工作經歷**

*   **初入 Twitter：** 2020 年，克勞福德創立的初創公司被 Twitter 收購，她開始以內部人士的角度觀察 Twitter。她發現 Twitter 既令人驚奇，又存在種種詭異問題。
*   **Twitter 的問題：**
    *   **官僚主義橫行：** 內部充滿權力鬥爭、重組和團隊名稱變更，員工們的正常工作被打斷。
    *   **基礎設施陳舊：** Twitter 的基礎設施陳舊且不標準，但高管們只關注收益，不願認真思考改進。
    *   **決策流程冗長：** 一個小小的產品變更需要很長時間才能適應，一個功能可能耗費數月構建，卻在最後一刻因風險太大而被否決。
    *   **缺乏良性辯論和批評：** 團隊之間缺乏有效的溝通，常以“做不到”和“別越界”搪塞。
    *   **躺平文化：** 公司難以裁掉人浮於事的員工，導致員工感到沮喪，浪費自己的潛力。
*   **馬斯克入主 Twitter：**
    *   **收購案的漫長等待：** 2022 年收購交易的等待過程漫長而痛苦，領導層集體消失，對公司未來的問題只以“信托責任”搪塞。
    *   **對馬斯克的期望：** 儘管對馬斯克了解不多，但克勞福德對他抱持謹慎樂觀的態度，希望他能改變 Twitter 的現狀。
    *   **马斯克的問題：**
        *   **隨意的決策方式：** 馬斯克治下的產品和業務決策都基於直覺判斷，不願依賴數據和專業知識。
        *   **情緒化：** 馬斯克的情緒容易從興奮轉為憤怒，讓人難以預測。
        *   **過度關注速度：** 馬斯克對速度的關注到了難以理解的地步，且不害怕打破舊世界。
*   **離開 Twitter：**
    *   **缺乏心理安全感：** 克勞福德無法在 Twitter 2.0 找到心理安全感，意識到自己隨時可能被解雇。
    *   **對 Twitter 的看法：** 如今的 Twitter 像個瘋人院，由一位善變的領導者掌管，平台上最大的聲音來自他的本能和直覺。
*   **睡在地板上的事件：** 克勞福德為了趕上馬斯克設定的幾乎不可能實現的期限，與團隊晝夜不停地工作。她認為這段經歷很辛苦，但也很有趣。

**克勞福德的反思**

*   **對馬斯克的評價：** 馬斯克是個複雜的人，擁有非凡的解決物理难题的天賦，但在建立人際聯繫和溝通方面做得不夠好。
*   **對自己的警示：** 我們所在的位置越高，自己的世界就會變得越小。金錢和名譽會造起一座心靈監獄，導致心理健康惡化。要分清家人、朋友和戰友，保持正軌。
*   **對 Twitter 的期望：** 克勞福德希望 X 能夠站穩腳跟，畢竟良好的競爭對消費者最為有利。

**結語**

克勞福德認為 Twitter 是一個奇異且特別的地方，她很慶幸自己能為其發展歷程做出貢獻。無論未來如何，她都會繼續使用 Twitter，關注和參與熱門話題。

**整理說明：**

*   **精簡內容：** 刪除了一些口語化的表達和重複的信息，使文章更簡潔明瞭。
*   **分點歸納：** 將克勞福德的觀點和經歷分點歸納，方便讀者理解。
*   **突出重點：** 使用粗體字標記關鍵詞和重點內容。
*   **調整結構：** 調整了文章的結構，使其更具邏輯性。
*   **保留原文語氣：** 盡量保留了原文的語氣和風格，以便讀者更好地了解克勞福德的想法。

希望這樣的整理對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>145. [2023-07-30] 【AI】Stack Overflow发布Overflow AI 能否挽救颓势 | 语义搜索 | VS Code 扩展 | Slack集成 | 企业知识提取 | 开发专属论坛</summary><br>

<a href="https://www.youtube.com/watch?v=8qA5ROIWj9M" target="_blank">
    <img src="https://img.youtube.com/vi/8qA5ROIWj9M/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】Stack Overflow发布Overflow AI 能否挽救颓势 | 语义搜索 | VS Code 扩展 | Slack集成 | 企业知识提取 | 开发专属论坛

## Stack Overflow 最新进展：OverflowAI 解析

大家好，这里是最佳拍档，我是大飞。

今天我们来聊聊 Stack Overflow 的最新进展。对于程序员来说，Stack Overflow 这个网站一定不陌生，经常需要去上面查找技术问题的解决方案。

前一段时间，网上有很多关于 Stack Overflow 访问量大幅下降的消息，这并非空穴来风。数据显示，从 2021 年 4 月到 2022 年 4 月期间，社区的页面浏览量还能维持在 2000 万左右，但到了今年 7 月，浏览量已经跌到了 900 万左右。一年半的时间，下降了近五成。

很多人认为是因为 ChatGPT 的出现，人们不再需要去 Stack Overflow 上找问题答案，直接用 ChatGPT 就能获得解答，所以加速了网站流量的下降趋势。

为了改变这种趋势，Stack Overflow 前天在 WeAreDevelopers 世界大会上宣布推出了「OverflowAI」。

根据 Stack Overflow 的说法，新的 OverflowAI 功能是在做了年度开发者调查之后推出的。我们之前也做过一期节目介绍这个调查，主要是针对国外开发者的。调查显示，大多数开发人员希望使用 AI 工具，但实际上只有 40% 的开发人员信任 AI。

OverflowAI 并不是一个单独的 AI 产品，而是一系列生成式 AI 功能的集合，简单来说，包括了新的 AI 搜索和问答、Visual Studio Code 扩展、企业知识提取、Slack 集成以及一个新的 GenAI Stack Exchange 社区。

接下来我们就来详细介绍一下各个部分：

**1. 新的 AI 搜索和问答：**

目前大部分搜索还是依赖于词法搜索，也就是根据用户提供的关键字来匹配问题和答案。现在，Stack Overflow 将在私有 Alpha 版本中添加建立在向量数据库上的语义搜索。这样，由搜索查询生成的回复能够更加智能地适配用户正在关注的主题。

Stack Overflow 想通过新的 AI 搜索来创建一个以人为本的对话式搜索，让平台用户能够获得即时、可信并且准确的解决方案。具体来说，Stack Overflow 利用了自己 5800 多万个问题和答案中较高可信度的知识，对生成的回复进行归因和引用，并且能够查询知识库来获得更加个性化的结果。

用户可以直接在对话框中输入自己的问题进行搜索，例如输入“如何获取 Python 字符串的长度？”搜索后，OverflowAI 会用对话的方式给出相应的解决措施，并且注明方法的来源。如果 OverflowAI 提供的答案不能解决问题，那么你就可以在对话框中告知它，并将这个问题发布在 Stack Overflow 上，等待社区的其他用户来帮助你解决。

这个新功能也出现在 Stack Overflow for Teams 中，用户将能够利用 Stack Overflow for Teams、Stack Overflow 网站以及其他存储知识的地方，比如 Confluence、GitHub 等可信的来源，快速找到最相关的答案和知识。

**2. Visual Studio Code 扩展：**

因为开发人员经常会从 Stack Overflow 上复制问题的答案，再粘贴到微软 Visual Studio Code 等开发工具中，所以 OverflowAI 为 Stack OverFlow for Teams 的用户提供了一个 Visual Studio Code 的扩展，可以直接集成到开发者环境中。这样一来，Visual Studio Code 的用户就可以直接查询问题和生成代码了。这些代码同时利用了来自论坛的内容以及企业自有知识库里的内容。不仅如此，这个扩展还可以为代码生成摘要和注释。不过目前这个扩展只有在企业版的 Stack Overflow for Teams 才可以使用。

**3. 企业知识库提取：**

在 Stack Overflow for Teams 中还增加了一项新功能，就是在创建新实例或者加入新的团队成员的时候，你可以利用现有的内容，在几分钟内整理并建立一个知识库。AI 会自动创建带有标签结构的文档初稿，并且通过识别团队最常查看的优质文档，或者是团队关注最多的领域，来推荐问题和答案。此外，你还可以对想要的答案进行一些相应的设置，比如你可以选择答案的长短、专业水平以及来源。这些能让搜索给出的答案更加符合你的个人需求。

**4. Slack 集成：**

为了让信息更容易访问，Stack Overflow 将 Stack Overflow for Teams 的知识库与 StackPlusOne 聊天机器人集成在了一起。集成后，搜索时不仅会使用你的 Stack Overflow for Teams 实例中的数据，还会使用所有经过 Stack Overflow 社区验证的数据源，来提供问题的答案。这些答案还会以对话的形式出现，即使是技术水平较低的成员也可以轻松理解并且与答案进行交互。

**5. GenAI Stack Exchange 社区：**

Stack Overflow 还专门为 GenAI 的开发人员提供一个可以获得技术资源和专家回应的专属论坛，即 GenAI Stack Exchange。这个论坛上会发布有关提示工程、模型训练以及更广泛的机器学习领域的问题和答案。

总的来说，这次发布的 OverflowAI 改进了 Stack Overflow 的用户体验，尤其是在搜索和编程方面有了很大的提升。但是在现在几乎所有大厂的产品线都在疯狂加入 AI 功能的竞争下，并没有让人感觉非常眼前一亮的功能。 ChatGPT 等聊天机器人始终是一个潜在的威胁。

目前看，Stack Overflow 最大的优势还是在问题回答的准确性与有效性上，毕竟有大量的社区成员的回答和验证。但是随着网络上 AI 生成的内容越来越多，这部分也迟早要被侵蚀，就像现在的知乎一样，也是大量的这种水帖或者是 AI 生成的内容。可能越往后发展，Stack Overflow 只能越往 ToB 的方面去发展了。

好了，以上就是这次发布的 Overflow AI 的内容，大家有什么看法可以发在评论区。本期视频内容就到这里，感谢大家的观看，我们下期再见。

**整理说明:**

*   **分段清晰：** 将长段文字拆分成更小的段落，方便阅读。
*   **添加小标题：** 用小标题概括每个部分的要点，帮助读者快速定位信息。
*   **结构化信息：** 将 OverflowAI 的功能点用编号列表进行组织，提高信息的条理性和可读性。
*   **精简语言：** 去除了一些口语化的表达，使文稿更加正式和专业。
*   **保持原意：** 在整理的过程中，尽量保持原文的意思不变。

希望这个整理后的文稿能更好地传达信息!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>144. 【行业】 2023中国开发者调查报告 | 程序员基本画像 | 年龄 | 收入 | 地域 | 行业 | 工作时长 | 工作状态 | 开发工具 | 如何看待AI</summary><br>

<a href="https://www.youtube.com/watch?v=MnnM7DAr3wM" target="_blank">
    <img src="https://img.youtube.com/vi/MnnM7DAr3wM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【行业】 2023中国开发者调查报告 | 程序员基本画像 | 年龄 | 收入 | 地域 | 行业 | 工作时长 | 工作状态 | 开发工具 | 如何看待AI



---

</details>

<details>
<summary>143. 【资讯】Photoshop测试版推出生成性扩展AI功能 | OpenAI | 微软 | DoorDash | 科技日报03期 | 20230329</summary><br>

<a href="https://www.youtube.com/watch?v=0iRaXZpTAI4" target="_blank">
    <img src="https://img.youtube.com/vi/0iRaXZpTAI4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【资讯】Photoshop测试版推出生成性扩展AI功能 | OpenAI | 微软 | DoorDash | 科技日报03期 | 20230329



---

</details>

<details>
<summary>142. [2023-07-28] 【商业】AI创业者眼中的AI创业格局 | Sam Hogan  | AI创业时代的壁垒是什么 | 行业先行者是否能够一直笑傲江湖 | 大公司和小公司分别有怎样的机会</summary><br>

<a href="https://www.youtube.com/watch?v=b_Zuitub7OA" target="_blank">
    <img src="https://img.youtube.com/vi/b_Zuitub7OA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】AI创业者眼中的AI创业格局 | Sam Hogan  | AI创业时代的壁垒是什么 | 行业先行者是否能够一直笑傲江湖 | 大公司和小公司分别有怎样的机会

好的，这是整理后的文稿，我进行了结构上的调整，使其更清晰易懂，并修正了一些表达上的口语化：

**标题：AI 创业的现状与机遇：硅谷观察与国内反思**

**引言：**

大家好，我是最佳拍档的大飞。今天想和大家聊聊当前 AI 创业的一些现象。

**内容概要：**

本文主要围绕美国 AI 创业公司 contextbots 的创始人 Sam Hogan 的一篇文章展开，该文章近期在硅谷引起广泛关注，探讨了 AI 创业领域的一些关键问题，尤其是在 Jasper 和 Mutiny 等公司裁员的背景下，VC 圈对 AI 创业的盈利能力和投资价值产生了激烈的讨论。文章的核心问题包括：

*   AI 创业时代的壁垒是什么？
*   先行者能否始终保持领先优势？
*   不同规模和类型的玩家，分别有哪些机会？

**Sam Hogan 的主要观点（翻译整理）：**

*   **失败者：**
    *   **以 Jasper 为代表的公司：** 估值虽高，融资巨大，但本质上只是对 OpenAI 的简单包装，缺乏差异化，难以扩张，投资风险高。
    *   **聊天机器人创业团队：** 在早期融资后，试图将产品卖给大型企业，但技术壁垒低，易被复制。大型企业更倾向于利用开源工具自主搭建 AI 基础设施，而非购买初创公司的产品。
*   **赢家：**
    *   **成熟公司和市场头部玩家：** 迅速将 AI 技术融入现有产品或开发内部应用，并无太多困难。这得益于 AI 对这些公司生死攸关的重要性，以及高管的推动，他们更倾向于内部领导项目，确保成功。伊隆·马斯克的成功案例也激励了他们。
    *   **独立开发者和个体创业者：** 规模小，成本低，能快速发展，为细分市场提供针对性产品，创建月收入约 1 万美元的微 SaaS 产品。他们不受高增长目标约束，快速构建和迭代产品，大语言模型和文本到图像模型是他们的福音。
*   **AI 的“登月项目”：** 指的是具有变革性的团队，试图重新定义和重塑整个行业。虽然风险高，但回报潜力巨大。例如：
    *   Cursor：AI 驱动的代码编辑器。
    *   Harvey：面向法律实践的 AI。
    *   Runway：AI 驱动的视频编辑器。

    这些“登月项目”数量需要大幅增加，才能实现人们对人工智能的期望。
*   **总结：**
    *   风投支持的初创公司日子不好过，融资越多，痛苦越大。
    *   市场领导者和老牌公司利用内部团队和开源技术迅速部署 AI。
    *   独立开发者通过发布面向细分市场的 AI 产品，建立小型现金流业务。
    *   少数“登月项目”公司最有可能获得 VC 规模的回报。

**大飞的反思与建议：**

*   **AI 浪潮的特征：** 头部巨头引领创新，小公司在垂直领域快速占据市场份额，而夹在中间的创业公司，做底层模型没钱，做应用竞争激烈，面临融资和变现压力，越来越难。
*   **国内情况：** 王慧文退出光年之外，可能也感受到了行业内卷的激烈程度。
*   **普通人如何参与 AI 浪潮：** 加入大公司，或者自己能做个“卖铲人”，不要轻易融资创业。国内投资机构对 AI 投资分歧大，集中投资少数项目。
*   **警惕 AI 知识付费：** 很多都是割韭菜的，内容质量差，别轻易剁手，网上免费资源足够学习。

**结尾：**

感谢大家的观看，我们下期再见。

**修改说明：**

*   **标题：** 更概括、更吸引人。
*   **结构：** 增加了引言和内容概要，使文章结构更清晰。
*   **语言：** 修正了口语化的表达，使其更正式、更书面化。
*   **逻辑：** 整理了观点，使其更有条理。
*   **排版：** 使用了分点和列表，方便阅读。

希望这个整理后的版本对您有所帮助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>141. [2023-07-28] 【资讯】Stability AI发布SDXL1.0 | Meta Llama2收费 | Cohere推出Coral | 谷歌Brain2Music模型 | 科技日报02期 | 20230328</summary><br>

<a href="https://www.youtube.com/watch?v=4yUI4J7sJXg" target="_blank">
    <img src="https://img.youtube.com/vi/4yUI4J7sJXg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【资讯】Stability AI发布SDXL1.0 | Meta Llama2收费 | Cohere推出Coral | 谷歌Brain2Music模型 | 科技日报02期 | 20230328

好的，我來幫您整理這段文稿。以下整理版本著重於信息的清晰與結構化，並去除口語化贅詞，使其更像一篇新聞摘要：

**科技日报第二期 - 新闻摘要**

大家好，這裡是最佳拍檔，我是大飛。今天為大家帶來第二期科技日報，重點新聞如下：

**1. Stability AI 发布开源文生图模型 SDXL 1.0**

*   SDXL 1.0 僅需少量文字即可生成複雜、精細、美觀的圖像，尤其擅長鮮豔、準確的色彩表現，對比度、明暗度均有提升。
*   所有生成圖像均為原生 1024x1024 分辨率。
*   模型能處理以往難以渲染的概念，如手、文字、空間排列組合。
*   目前已開放免費試用。

**2. Meta 拟从 Llama 2 转售中获利**

*   Meta 計劃從主要雲計算公司轉售 Llama 2 的行為中獲利。
*   Llama 2 技術雖開源，但包含條款：大型雲計算公司需與 Meta 達成商業協議，方可使用，不得免費使用。
*   微軟、谷歌、亞馬遜等公司預計將提供 Llama 2 轉售服務，Meta 藉此獲利。

**3. 亚马逊 AWS 纽约峰会亮点**

*   **推出 AWS EC2 P5 实例：** 採用英偉達 H100 Tensor Core GPU，訓練時間最多縮短 6 倍。具備 8 個英偉達 H100 GPU，640GB 高頻寬 GPU 内存，第三代 AMD EPYC 處理器，2TB 系統内存，以及 30TB 本地 NVMe 存储。
*   **推出 HealthScribe：** 符合 HIPAA 法規，協助醫療軟體供應商將生成式 AI 功能整合到應用程式中，例如生成臨床文檔，節省醫生時間。通過 API 提取醫療相關關鍵信息，根據醫患對話創建摘要。
*   **Amazon QuickSight 新增生成式 BI 功能：** 由 Amazon Bedrock 提供支持，業務分析師可輕鬆創建數據可視化圖表，並使用自然語言微調格式。
*   **Bedrock 增加模型供應商：** 新增 Cohere 和 Anthropic 的 Claude 2，以及 Stability AI 的 SDXL 1.0，客戶可使用 Bedrock API 選擇模型，構建生成式 AI 應用程序。

**4. 生成式 AI 独角兽 Cohere 推出企业知识助手 Coral**

*   Coral 是一款企業聊天機器人，由 Cohere 的 Command 模型驅動。
*   Coral 可以與企業用戶對話，協助完成業務任務。
*   企業可將 Coral 連接到私有資料庫進行客製化。

**5. OpenAI 聘请知识产权律师，应对版权诉讼**

*   OpenAI 聘請前微軟知識產權律師 Tom Rubin 監督產品政策和合作夥伴關係。
*   Rubin 將負責與新聞出版商談判，尋求授權以訓練 ChatGPT。
*   OpenAI 目前面臨多起版權訴訟，涉及媒體、文化單位、出版集團。

**6. OpenAI 秘密开发对抗 Llama 2 的开源 AI 模型 (代号 G3PO)**

*   細節未知，發布時間待定。

**7. 谷歌发布 Brain2Music 模型**

*   Brain2Music 基於人類大腦活動生成音樂。
*   利用 AI 分析功能性核磁共振成像 (FMRI)，基於大腦活動自動生成音樂。
*   基於谷歌 MusicLM 模型，可生成約 15 秒的音樂片段。

**8. 国内大语言模型相关新闻**

*   北京交通大學發布綜合交通大模型 TransGPT 致遠。
*   用友發布企業服務大模型 YonGPT。
*   WPS Office 海外版正式開啟 WPS AI 公測，由 OpenAI 和 PaLM 2 提供模型支持。

感谢大家的观看，我们下期再见！

**改進說明：**

*   **精簡語句：** 去除 "那"、"這個"、"應該說" 等口語化詞彙，使內容更簡潔。
*   **結構化：** 使用標題、條列式清單，使資訊更易於閱讀和理解。
*   **重點突出：** 強調每個新聞事件的核心內容。
*   **專業用語：** 保留技術名詞，並稍作解釋，例如 HIPAA， FMRI 等。

希望這個整理版本對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>140. [2023-07-27] 【资讯】微软最新季度财报创纪录 | Alphabet广告业务重新增长 | 阿里云率先支持Llama 2 | OpenAI停用AI文本检测器 | 科技日报01期 | 20230727</summary><br>

<a href="https://www.youtube.com/watch?v=vk49TN4heAY" target="_blank">
    <img src="https://img.youtube.com/vi/vk49TN4heAY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【资讯】微软最新季度财报创纪录 | Alphabet广告业务重新增长 | 阿里云率先支持Llama 2 | OpenAI停用AI文本检测器 | 科技日报01期 | 20230727

好的，我來整理一下這段文稿，使其更清晰易讀。

**整理後文稿：**

大家好，這裡是最佳拍檔，我是大飛。

之前錄製的節目，我需要花費大量的時間整理資料、撰寫文案，然後再進行錄製、拍攝和剪輯。這樣做出來的節目，我自己有時候會覺得比較正經、正統，甚至有些枯燥。

所以今天想嘗試換一種更輕鬆自在的方式，講一些內容，更多地集中在 AI 圈或科技圈發生的事情上，類似於新聞。更多地與大家分享。

之前做的節目都是一個話題一個話題地講，內容緊湊、乾貨較多。但其實每天都在發生很多事情，我只能從中抽取一兩個來跟大家分享，所以有時候有點不太盡興。其實有很多重要的關鍵信息被錯過了。

因此，我想從今天開始嘗試做一些偏新聞、日報類的節目，把更多的一些資訊、行業的進展、發生的事情再跟大家去分享。所以從今天開始，我想來嘗試一下這樣的節目，看看大家是否接受，我自己做的是否 OK。

當然，以前這種專題性的節目肯定也會繼續做，只不過這兩種節目會盡量交叉進行。我也可能會看看我的時間精力夠不夠分配。但我的確有很多想跟大家分享的信息和內容。

的確，這個行業還在經歷著一些爆發式發展的階段。已經好幾個月了，本來以為發展得差不多了，該有的一些東西都出來了，應該消停一會兒了。但實際上我們看，其實並沒有，而且反而是越來越多了。

所以，我希望能夠從中找到一些我自己覺得很重要、很關鍵的信息、新聞類的資訊，去跟大家分享。

OK，這種節目我沒有預先準備的文案，可能會有一些資料，但我沒有預先準備口播的文案。所以就是完全即時性、臨時性的去講述或分享。因此可能難免內容的嚴謹性，或者說我的這些表達方式不如以前的節目表述得那麼清楚。所以這裡邊會有大量臨時性的發揮，希望大家理解一下。

我自己本身其實不太擅長這種臨場發揮，所以我之前都是去寫好相關的文案，給大家儘可能無差錯地表述。對我自己來說也是個挑戰，所以也想嘗試一下新的方式，看看我自己能不能做這樣的類型。

OK，話不多說，我們先來講一講昨天我覺得行業發生的一些新的動態和一些比較重要的事情。

**新聞一：微軟和 Google 的財報**

第一個是微軟昨天發布了 2023 財年的第四財季以及全財年的業績報告。這也是微軟在去年 5 月 24 日Build 2023大會上正式推出一系列 AI 軟體和服務後的首次財報。

這次業績應該說是整體超過了大家的預期，而且創下了新高。但可能是由於 HR 雲業務的增速放緩了，所以資本市場還是給予了一些負面的反饋，微軟的股價盤後一度超跌了 3%。但目前來看，這一輪的 AI 熱潮還沒有給微軟的雲業務帶來一些顯著的增長。

當然，它整個的股價已經增長了很多了。具體的數字是：微軟 2023 財年的第四財季營收是 562 億美元，同比增長了 8%，高於 554.9 億美元的市場預期。它的淨利潤是 201 億美元，同比增長了 20%。總營收和淨利潤都創下了歷史新高。

整個 2023 財年，微軟的營收增長了 7%，總共是 2,119 億美元。從各個業務線來看，這個季度微軟的生產力和業務流程業務線收入是 183 億美元，同比增長了 10%。這一塊的業務主要包括 Office 365 軟體、Dynamics 365 和 LinkedIn。

其次是微軟的智能雲業務，營收同比增長了 15%，總共是 239.9 億美元，高於市場預期的 238 億美元。儘管這塊增長很快，但實際上明顯低於去年同期 40% 的增幅。

第三塊是個人計算業務，這塊包括像 Windows、設備、遊戲和搜索廣告等相關業務，這塊同比下降了 4%，總共是 139.1 億美元。但這個表現仍然是優於市場預期的 135.6 億美元。

在這個財報的電話會議上，微軟 CEO 薩蒂亞·納德拉也表示，組織要考慮如何更快，而且安全、負責任地去應用下一代 AI 來面對大的機遇和挑戰。

從整個支出來看，微軟這個季度的支出為 89.4 億美元，高於市場預期的 78.5 億美元。總共的資本開支預計在 2024 財年會按季度逐步增長，主要會用於數據中心 CPU 晶片、GPU 晶片和網絡設備方面。這其實也表明微軟將持續加大對 AI 方面的投入。

微軟也預計 2024 財年的第一季度，也就是下個季度，微軟雲服務的營收增長率將為 25% 到 26%。這也意味著雲服務的增速會進一步放緩，但是它的重要性會明顯增加。微軟雲業務的年收入將超過 1,100 億美元，其中 Azure 的收入會首次占總收入的 50% 以上。

在微軟發布財報的同時，Alphabet，也就是 Google 的母公司，也發布了第二季度的財報，而且是同一天發布的。

財報顯示，第二季度的營收是 746.04 億美元，同比增長了 7%，遠遠超出了 727.7 億美元的營收預期。而上一個季度還只有 3% 的同比增長。看起來 Alphabet 已經擺脫了連續多個季度的低迷的增長，公司的股價也一度因此漲幅了 7%。

Alphabet 主要營收是由 Google 服務、Google 雲和其他業務三部分組成的。Google 的服務包含廣告、付費會員與硬件等等業務，總計獲得了 662.85 億美元的收入，同比增長約 5.5%。廣告是其中的重中之重，廣告業務在 Google 的服務營收中占比約 90%，而且 Google 的服務又占到整個 Alphabet 營收的 90%，所以廣告的收入非常重要。

在過去兩個季度，Google 的廣告營收持續下降，不過現在又重新回到增長了，廣告收入是 581.4 億美元，同比增長了 3.3%。

之前市場曾經擔憂過微軟的 Bing 搜索引擎會給 Google 的搜索業務和搜索廣告業務帶來很強的衝擊，但是從財報來看，Google 在搜索領域的霸主地位仍然沒有被動搖。

Google 的雲服務業務是他們 AI 戰略的一個核心。雲業務保持了持續的強勢增長，第二季度的營收是 80.31 億美元，同比增長 28%，和第一季度的增速持平，高出市場 24.8% 的預期。

Google 的財報會議還有其他一些信息，包括一個高層的人事變動。Google 的首席財務官 CFO Rose Prot 將擔任首次首席投資官 CIO，在找到新的 CFO 繼任者之前，他將會兼任這兩份工作，並且負責 Google 包括 AI、自動駕駛等等創新部門在全球的投資。

另一個信息是，Google 雖然沒有在財報中提到 AI 給業績增長會帶來什麼影響，但是也表示未來將加大在數據中心和福氣方面的投入，這也被大家看作是 Google 會持續投資 AI 領域的一個信號。

總結一下前兩個新聞，主要是說到了微軟和 Google 的財報問題。大家都覺得在這一波 AI 的浪潮中，微軟應該算是大贏家，包括 OpenAI 的背後也是微軟支持的，股價之前也漲了很多。但是實際上從財報出來之後，你發現其實 Google 漲得也很好，甚至超過了微軟的趨勢，這有點讓人意想不到。而且也側面說明了 Google 在 AI 領域還是有相當的實力，至少在掙錢的方面。雖然大家都經常嘲笑 Google，尤其在這一波浪潮開始的時候，經常說 Google 要倒霉了，不行了，但是實際上你會發現巨頭就是巨頭，它整個轉變或調整的速度還是很快的，而且掙錢的能力沒有任何下降。所以這個我覺得還是要有敬畏之心。

**新聞二：阿里云支持 Meta LLaMA 2**

接下來說一個國內的新聞，我們之前也報導了 Meta 開源了 LLaMA 2，阿里云率先支持了 LLaMA 2，而且是中國首家支持這個模型的雲服務平台。

昨天阿里云通過官方微信公眾號宣布，會推出 LLaMA 2 全系列版本的訓練和部署方案。在阿里云上，本地單卡的 GPU 只能完成 LLaMA 2 70 億參數版本的微調和推理，更大規模版本以及更深度的訓練需要通過雲服務用到更多的 GPU 來實現。

除了在雲服務上支持之外，阿里云的積極學習平台 PAI 也率先對 LLaMA 2 的系列模型做了深度的适配，推出了輕量級的微調、全參數的微調以及推理服务场景的实践方案，幫助開發者快速地開發基於 LLaMA 2 的大模型。

在訓練方面，LLaMA 2 經過 2 萬億個 Token 的訓練，對上下文的訓練長度也是 LLaMA 1 的兩倍。而且 LLaMA 2 Chat 模型也接受了超過 100 萬個人工标注的訓練。到目前為止，還沒有其他的國內公司宣稱支持了 LLaMA 2，這應該說讓阿里云搶了一個先機吧。

但說實話，也只能是個先機而已，具體說支持 LLaMA 2 會帶來多少的收入或多大影響，我覺得還不太確定。

現在中國的技術公司普遍都是在自己的雲平台上集成多個開源的大模型。比如說像字節跳動的火山引擎就在今年 6 月份發布了大模型的服務平台火山方舟，也集成了百川智能的，還有 MOS 的，質樸的 AI 等多個大模型。同樣，阿里云旗下的魔搭社区也集成了像百川、GLM、以及 RAKW、MOS 等等這些國內的開源大模型。應該說現在開源大模型真的太多了，實際上缺的是應用場景。

**新聞三：OpenAI 停止 AI 文本檢測器**

第四個新聞是跟 OpenAI 有關的。OpenAI 悄悄地停用了 AI 的文本檢測器，這個已經在官網宣布了。OpenAI 表示目前正在研究更加有效的文本識別技術，同時承諾在未來推出其他的工具，讓用戶能夠辨別哪些音頻或視頻內容是 AI 生成的。

這個 AI 文本檢測器，英文名叫 AI Classifier，是到底用來做什麼的呢？它是 OpenAI 今年 1 月份推出的，主要的功能是區分文本是人類撰寫還是 AI 生成的。我們之前也做過兩期節目介紹相關的內容。

這個工具推出來的時候，OpenAI 是想利用這個工具來識別學術的不端行為，不過推出來之後，我就說過這個工具的表現不是很好，準確率僅僅為 26%，而且會將 9% 的人類撰寫的文本錯誤地標記成 AI 生成的內容。OpenAI 自己都將這個工具稱作是一個不完全可靠的檢測工具，在網上免費的公開了，主要是用來收集一些使用反饋。

其實在他發布之後，他就知道這個準確率不行，但是可能覺得有就比沒有好吧，所以還是公開了。但是你的檢測又不準確，那實際上可能會導致很多的問題。比如說，有老師就用這樣的工具來判定學生寫的論文是不是 AI 寫的，那實際上結果很可能是錯誤的。所以說這會造成一些非常不好的結果。

所以我覺得把它停掉也是一個很負責任的一個選擇。當然了，如何去檢測一個文本或者內容是 AI 生成的，其實這個還是有很大難度的，業界也沒有一個非常有效的辦法。雖然有一些論文在嘗試，但是現在來說應該還是一個非常具有挑戰的一個問題吧。包括這裡邊涉及到很多多模態的一些問題，除了有文本，你還有圖片，還有視頻，你怎麼去檢測它，怎麼去防止它被攻擊或者是被抹掉，其實這個領域我覺得會有非常大的一些發展空間，也有很多商業的機會在。

**其他新聞**

除了這幾個我覺得比較重要的新聞之外，還有兩個我覺得就是比較小的一些事情。

第一個是 OpenAI 正式上線了安卓版的 ChatGPT，目前是在美國、印度、孟加拉國和巴西提供下載，可能會在下週推廣到更多的國家。這個安卓版的 ChatGPT 功能跟 iOS 版基本上保持一致，無非就是補足了他在用戶使用場景上跟用戶群上的一個覆蓋度。因為有很多用戶用的還是安卓的手机，我覺得是完全出於一個市場化的行為的需要。他需要現在 OpenAI 除了在 PC 端、外部端、iOS 端，他其實想辦法去覆蓋更多的一些用戶，想辦法去獲取更多的流量，所以這個也無可厚非，對於他來說發布一個安卓版也不是什麼太難的事。

第二個有意思的消息是推特，這個被馬斯克前幾天更名為 X 公司之後，現在正在嘗試去降低廣告的價格，來吸引一些品牌重新回到這個推特，也就是 X 這個平台。在 7 月 31 號之前，X 公司會給預定廣告的用戶提供 50% 的折扣，這個折扣力度還是很大的。

X 公司還提醒廣告商，從 8 月 7 日開始，如果你的品牌在過去 30 天內沒有在廣告上花費至少 1,000 美元，或者說在 180 天內，也就是六個月內，沒有為廣告花費 6,000 美元，那麼你的品牌賬戶將失去官方的認證標誌，這有點威脅的意思。當然這個也沒辦法，因為 X 公司在馬斯克接手之後，它現在的廣告收入下降得非常厲害。有部分原因是這個品牌對於馬斯克的管理和內容審核的方式感到擔憂，而且包括廣告業本身也陷入了低迷的狀態，所以說不少的公司都已經在給品牌方提供折扣了。X 公司的這個措施到底有沒有效呢，我們可以過一段時間再來看一下，看它的這個廣告收入是否在增長。

好了，以上就是我覺得昨天發生的一些科技圈的消息吧。這種形式可能就會偏随意一點，偏聊天性質一點，所以說不知道大家會不會喜歡。好了，今天的视频就先到这里，我们下期再见。

**整理說明：**

*   **分段：** 將長文稿分成多個段落，讓內容結構更清晰。
*   **添加標題：** 為每個新聞或主題添加標題，方便讀者快速了解內容。
*   **修正語氣：** 稍微調整了一些口語化的表達，使文稿更正式一些。
*   **歸納總結：** 整理了每個新聞的重點，方便讀者快速掌握資訊。
*   **刪除冗餘：** 刪除了一些重複或不必要的語氣詞，使文稿更精簡。

希望這個整理對您有幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>139. [2023-07-26] 【商业】Sam Altman的 Worldcoin 项目正式上线 | 什么是Worldcoin | 是割韭菜还是真的乌托邦 | World ID | Orb虹膜识别 | 加密数字货币</summary><br>

<a href="https://www.youtube.com/watch?v=U88fv5N9ACQ" target="_blank">
    <img src="https://img.youtube.com/vi/U88fv5N9ACQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】Sam Altman的 Worldcoin 项目正式上线 | 什么是Worldcoin | 是割韭菜还是真的乌托邦 | World ID | Orb虹膜识别 | 加密数字货币

好的，這是我整理後的文稿。我主要做了以下修改：

*   **簡化語句：** 去除了一些口語化的贅詞，使句子更精煉。
*   **修正錯別字：** 修正了部分錯別字，例如「Watercoin」改為「Worldcoin」。
*   **調整標點符號：** 使標點符號更符合書面語規範。
*   **調整段落：** 稍微調整了段落結構，使其更清晰。
*   **统一专有名词:** 统一专有名词的写法，例如WorldAPP更改为World App

**整理後的文稿：**

大家好，這裡是最佳拍檔，我是大飛。

如果讓您掃描虹膜，天天什麼也不用幹，躺在家裡就有人發錢，您會接受嗎？

昨天，由 OpenAI 創辦人 Sam Altman 創建的 Worldcoin 項目正式上線。這個項目的任務之一，就是給人們免費發錢。當然，這錢不是美元或人民幣，而是加密貨幣。

作為一個 Web3 加密項目，Worldcoin 是一個運行在以太坊上的 Layer2 網絡，Token 供應上限為 100 億枚。除了 20 億枚將留給 Worldcoin 基金會和投資者，剩下的 80 億枚都將在全球範圍內免費分發。

剛一上線，Worldcoin 就從開始的 1.70 美元升至 3.58 美元，首日幣價大漲 111%。

今天我們就來聊一聊，到底什麼是 Worldcoin？Sam Altman 為什麼要弄這麼個項目？而且根據 Worldcoin 項目的官方稱，創立 Worldcoin 的目的，是為了應對在 AI 衝擊下，人類可能會面臨大面積失業。但是考慮到過去一年加密貨幣圈頻頻爆雷，跑路的項目很多，那麼 Sam Altman 這次是準備割韭菜呢，還是真的要創建一個烏托邦？

我們先來說說 Worldcoin 是什麼。簡單來說，Worldcoin 由 World ID 和 WLD 兩部分組成。World ID 也被稱作「數字護照」，用來證明它的持有人是真正的人類，而不是 AI 機器人。World ID 是一種基於人格證明（proof of personhood，簡稱 PoP）的保護隱私的數字身份，目的是想解決 AI 數字時代基於身份的挑戰。

人格證明是 Worldcoin 的核心理念之一，指的是確認一個個體既是人類又是獨特的個體。一旦確認，它將賦予個體斷言自己是真實存在的人，並且與其他真實存在的人不同的能力，而無需揭示他們的真實世界身份。

今天，全球範圍內的人身證明問題尚未解決，這使得在線投票或大規模分配價值變得困難。隨著 AI 模型變得越來越強大，這個問題將變得更為緊迫，因為這進一步增加了區分人類和機器人的難度。如果 World ID 成功了，那麼它就有可能會成為全球人格證明的標準。

在獲得 World ID 後，就能夠收到 WLD。WLD 是一種提供實用工具的代幣，可以讓用戶對 Worldcoin 協議的發展方向具有發言權。

在 Worldcoin 背後，存在一些核心假設：

第一點，人格證明是一個缺失但也是必要的數字原始概念。隨著越來越強大的 AI 模型的出現，這種原始概念將變得越來越重要。

第二點，首次實現可擴展且包容的人格證明，可以使所有網絡參與者的激勵都圍繞著將真實人類加入網絡。Worldcoin 是為了發展 Worldcoin 網絡而發行的，其安全性來源於以太坊。

第三點，在 AI 日益強大的時代，通過定制的生物識別硬件發布全球性的人格證明是最可靠的方式。

Worldcoin 的目標很宏大，就是打造一個全球最大且公平的數字身份和數字資產體系。這個目標具體可以拆解為以下三部分：首先是創建一個全球身份 ID，即 World ID；其次是打造一份全球性數字資產，即代幣 WLD；最後是一個承載身份 ID 與數字資產的錢包 World App。

目前，除了法律不允許的地區之外，全球許多地方已經可以使用 World ID、Token WLD 和 World App。多家加密資產交易平台也都相繼宣布上線 WLD。

那麼 Worldcoin 是如何運作的呢？Worldcoin 主要是圍繞 World ID 展開運作。通過使用 World ID，用戶將能夠向任何集成該協議的平台證明，他們是真實的、獨一無二的人類。這將實現公平的空投，阻止女巫攻擊，並實現有限資源的更公平分配。

在女巫攻擊中，攻擊者會試圖利用他們偽造的多個身份來操縱網絡，來獲取不應得的利益或破壞系統。而空投是一種分發代幣的方式，通常情況下，這是一種項目將免費的代幣分發給其社區成員的方法，以鼓勵他們參與和推動項目發展。空投常常被用作新項目的啟動方式，通過給持有者分發新的代幣，項目方可以很快地建立一個活躍的用戶基礎和社區。

此外，World ID 還可能將實現全球民主流程和新型的治理形式，比如說二次投票，最終可能支持基於 AI 的 UBI 路徑。這個 UBI，全稱為 Universal Basic Income，就是讓全地球的人都能「共享」AI 帶來的豐厚利潤，簡單理解就是分錢，類似大富翁裡的均富卡。

目前，全球只有不到 3% 的世界人口參與到加密貨幣網絡。早在 2015 年，Sam 就在 YC 成立了非盈利研究實驗室 Y Combinator Research，並對 UBI 這項計劃進行研究。UBI 計劃的支持者認為，一個人的基本收入，應該覆蓋其基本的生活需求，包括食物、住房、醫療保健，而且這一收入應該是無條件的、每月固定的，並不需要受到特定的限制或者要求。

Worldcoin 項目認定，AI 將繼續改進並最終進化為 AGI，這意味著它比人類更聰明，將推動生產力的飛躍，也將創造大量的財富。但是這財富不應該被精英們獨佔，而應公平地分配給全人類。這個 UBI 現在以加密貨幣的形式出現了，也就是 Worldcoin。

那我們如何獲取 World ID 呢？註冊 Worldcoin 的過程，主要分為三個步驟：第一步，從 App Store 或 Google Play 下載 World App；第二步，按照提示查找可以驗證個人獨特人格的當地 Worldcoin 運營商；第三步，在 World App 應用程序中接收 World ID，並在各種日常應用中使用它，而無需透露個人的身份。

其中最關鍵的一步，是通過運營商註冊使用 Worldcoin 的「Orb」，進行面對面的虹膜掃描。Orb 是一個大約保齡球大小的銀球。一旦球體的虹膜掃描驗證出用戶是真人，它就會創建一個獨一無二的 World ID。Orb 的首要任務是確定某人是否為實際的生活中的人，並且沒有試圖欺詐驗證。通過掃描人的虹膜，並且使用幾種機器學習模型和其他計算機視覺技術，Orb 就可以創建一個虹膜編碼，這是對個體虹膜圖案最重要特徵的數值表示。

Orb 的工作流程大概是這樣的，首先，註冊者下載 World App 到他們的手机上。World App 會創建一對鏈接的加密密鑰，即一個可共享的公鑰和一個存儲在用戶設備上的私鑰。其中公鑰用於生成 Orb 在掃描用戶虹膜之前讀取的 QR 碼。接著，掃描會被轉化為一串哈希值。Orb 將虹膜哈希和用戶公鑰的哈希值以一個簽名的消息的形式發送到 Worldcoin 的服務器。最後，系統將虹膜哈希與數據庫中的信息進行對比，看看這個人是否以前註冊過。如果沒有，它就會被加入到列表中，公鑰哈希則被添加到公司的區塊鏈的註冊表上。

用戶獲取免費 Worldcoin 的過程依賴於零知識證明（ZKP）這項加密技術。World App 會使用一個開源協議來生成一個 ZKP，顯示持有者的私鑰與區塊鏈上的一個公鑰哈希鏈接在一起，但是不揭示哪一個。這樣，Worldcoin 就不會知道哪個公鑰與哪個錢包地址關聯。一旦這個鏈接被公司的服務器驗證，代幣就會被發送到錢包。

總而言之，對於 Worldcoin 這個項目而言，Orb 是一個不可或缺的存在。大家應該已經發現，Orb 是 Worldcoin 項目能否實現的重要一環，但是也是目前最受詬病的一點。

曾經揭露棱鏡計劃的前美國中央情報局雇員斯諾登，之前就在推特上公開批評過 Worldcoin 項目。斯諾登表示，Worldcoin 通過 Orb 掃描虹膜所獲得的生物識別數據，很可能會被濫用。儘管 Worldcoin 項目方說會刪掉掃描數據，但實際上卻保存了掃描的哈希值。雖然 Worldcoin 項目使用零知識證明來保護隱私，但是斯諾登堅持認為，人體不是一個打孔機。對於一家私人公司來說，收集關於地球上每個人的這種生物識別數據是「極其且本質上的風險」。而將該設備稱為「Orb」，不禁會讓人想到《指環王》中的索倫之眼。在小說中，索倫之眼是黑暗魔君索倫的標誌。作者托爾金是這樣描寫索倫之眼的：「那只眼睛籠罩在火焰當中，本身也散發如同妖貓的黃色光芒，仔細地凝視一切，而在瞳孔的地方則是一個深洞，通向無盡的虛無」。

其實，Worldcoin 官方曾經在一篇博客文章中表示，將生物識別技術用作個人身份識別的手段，可能會引發人們對反烏托邦或者專制未來的想像，因為有些系統會濫用生物識別技術來限制個人自由。

在一開始成立時，Worldcoin 並沒有打算開發生物識別成像設備，原因是定制硬件既困難又昂貴。那麼，為什麼 Worldcoin 最後還是使用上虹膜生物識別技術呢？因為經過研究，Worldcoin 團隊發現虹膜掃描提供了最準確的生物識別技術，並且用戶體驗可接受，已在大規模中成功測試。虹膜具有強大的防欺詐能力和豐富的數據，意味著它可以準確地區分數十億獨特的人類。當認定生物識別技術是實現 UBI 目標的唯一現實方式後，Worldcoin 團隊於是開始著手創建 Orb。

四十年前，經典科幻電影《銀翼殺手》上映。電影裡的人們也是通過觀察虹膜反應，來確認一個人是複製人還是真實的人類。四十年後的今天，虹膜識別已經從科幻變成現實。不知道這個 Orb 最終會不會真的成為索倫之眼。

如果我們拋開 Orb 的爭議不談，Worldcoin 可以說是一個頗具理想主義色彩的烏托邦項目，這從它的核心理念就可以看得出來：

1.  Worldcoin 協議由所有人共同擁有。
2.  Worldcoin 代幣是首個僅因為人們是獨特的人類而被免費分發給人們的數字貨幣。

為什麼 Sam Altman 要推行這一計劃呢？2021 年，Sam Altman 在其個人博客中發表過一篇文章，其中可以看到一些蛛絲馬跡。

在這篇文章裡，Sam Altman 詳細闡述了他對未來社會經濟變革的看法，並提出了對實現美國全民基礎收入的設想，即成立美國股票基金（American Equity Fund）。

Sam Altman 指出，AI 將在未來引發社會經濟的巨大變革，更多的工作將由 AI 來完成，從而導致人類勞動力的價值下降。關於未來具體會發生什麼，他做了以下預測：

1.  在未來的五年內，能夠思考的計算機程序將能夠閱讀法律文件並提供醫療建議。
2.  在未來十年內，它們將能夠進行流水線工作，甚至可能成為我們的伴侶。
3.  在那之後的幾十年內，它們將幾乎能夠做任何事情，包括進行新的科學發現。

當 AI 大規模地取代人類後，更多的權力將從勞動力轉移到資本。如果公共政策不相應調整，大多數人的境況將比今天更糟。所以，需要設計一個新的財富分配體系，將重點放在對資本而不是勞動力徵稅上，利用這些稅收作為直接向公民分配所有權和財富的機會。為此，可以設立一個美國股票基金，這個基金將通過每年對高於一定估值的公司徵收其市場價值的 2.5% 的稅收，以轉讓給該基金的股份支付，並通過對所有私人持有的土地價值的 2.5% 徵稅，以美元支付。所有 18 歲以上的公民，都將在他們的賬戶中每年獲得美元和公司股票的分配，用於更好的教育、醫療保健、住房、創辦公司等等。

在 Sam Altman 看來，必須提前預防 AI 變革將帶來的風險。因此，他付諸了行動。2021 年，Sam Altman 創辦了 Worldcoin 項目。但是由於受到加密貨幣價格暴跌以及 Orb 虹膜識別爭議的影響，Worldcoin 的推進並不順利，甚至被迫停止了在至少七個國家的業務。直到今天，由於以 ChatGPT 為代表的生成式 AI 的爆火，才讓 WordCoin 項目獲得新機遇。這個新機遇就是，由於 AI 的爆炸式發展，對提供人格證明的系統的需求，以及對財富再分配和全球治理系統新實驗的需求正在增長。

Worldcoin 其實就是一個世界版的「美國股票基金」，Sam Altman 也許是希望借此來搭建一個社會基本福利保障體系。

不過 Worldcoin 的理念仍然面臨著許多的質疑和挑戰，主要有幾個方面：

第一點，技術及隱私風險。首當其衝的，就是 Worldcoin 的虹膜掃描技術方案。我們之前也提到過，許多人都在質疑這項生物識別技術的可靠性和穩定性，尤其是隱私保護方面的能力。此外，虹膜掃描設備 Orb 的普及性也是一個重要的問題。Worldcoin 需要確保這個設備能夠實現廣泛的覆蓋，並且對於全球各地的用戶來說都是易於可獲取的才行。對此，Worldcoin 採取了一些措施，比如說提供優惠券和貸款激勵等等手段，但是實際的成效甚微。

第二點，法律與監管風險。目前，Worldcoin 尚沒有得到廣泛的法律認可，因此它的合規性也面臨著一定的困境和挑戰。例如一些國家和地區，比方說美國，對 World ID 和 Worldcoin 存在著限制和管制，這就導致 Worldcoin 無法進入這些國家。目前，Worldcoin 獲得許可的國家只有 24 個，其中 14 個是發展中國家，8 個位於非洲。然而，貧困地區的居民普遍缺乏法律保護，數據收集成本也最低。在這種地方收集用戶數據，被很多媒體指責是一種變相的加密殖民主義。

加密投資機構 Block tower capital 的創始人阿里保羅也曾經指出，Worldcoin 的核心商業模式是從全球最貧窮的人那裡竊取數據，以剝削窮人的方式測試數據，並將之貨幣化。這是通過欺詐，從窮人那裡竊取數據的犯罪行為。而且貧苦地區的用戶普遍對於 Worldcoin 以及加密行業都了解甚少，讓他們加入加密世界對他們來說未必是一件好事。此外監管更是 Worldcoin 繞不過去的風險。畢竟貨幣是主權國家的權利。曾經承載過世界貨幣願景的穩定幣項目 Libra 即使背後有 Facebook 站台，最終也難逃流產的命運。

第三點，競爭與資金風險。數字貨幣市場競爭激烈，Worldcoin 也需要面對來自於其他競爭對手的挑戰。已經成熟的加密貨幣項目地位難以撼動，新興的競爭對手又在不斷的推出更具吸引力的產品和服務，這都會影響到 Worldcoin 的市場份額和用戶基礎。此外 Worldcoin 還不得不面對加密貨幣價格高波動屬性下的資金風險。

那麼 Worldcoin 會是一個新的割韭菜項目嗎？這個結論尚未得知。但是大飛我個人認為，雖然 Sam Altman 這種近乎於烏托邦理想的嘗試值得敬佩，但是打造一個全球平等的金融社區的理想似乎仍然過於宏大。因為平等的金融社區並不能夠在實質上讓所有參與者獲得相同的能力。未來 AI 普及後，一個人也不可能因為他擁有一個無法偽造的數字身份就能夠獲得相應能力和對應的收益。免費自由發放的代幣，如果沒有擁有者真實的資產和能力的背書，很可能就淪為無用之幣，最後金融社區也會衰敗。真正重要的，恐怕仍然是尋找那些只有人類能做的事情，形成保護帶才行。

大家對 Worldcoin 有什麼看法呢？歡迎在評論區留言。

好了，本期的節目就到這裡，感謝大家的觀看，我們下期再見。

希望以上整理對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>138. [2023-07-25] 【人工智能】白宫联合七大AI巨头发起自愿承诺书 |  如何对AI生成的内容添加水印 | 马里兰大学论文解读</summary><br>

<a href="https://www.youtube.com/watch?v=GlaWDx8efps" target="_blank">
    <img src="https://img.youtube.com/vi/GlaWDx8efps/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】白宫联合七大AI巨头发起自愿承诺书 |  如何对AI生成的内容添加水印 | 马里兰大学论文解读

好的，這是一份整理過的文稿，重點更清晰、結構更分明，更像一份報告：

**標題：白宮主導AI安全承諾與Token層面水印技術解析**

**引言：**

*   簡介：最佳拍檔頻道，我是大飛。
*   本期主題：
    *   白宮召集AI公司商討AI安全發展並達成自願承諾。
    *   AI生成內容Token層面水印技術。

**一、白宮AI安全承諾**

*   **背景：**Llama 2發布後兩天（7月21日），白宮主導召集七家領先AI公司。
*   **參與公司：**亞馬遜、Anthropic、谷歌、Inflection、Meta、微軟和OpenAI。
*   **目標：**實現「人工智能技術安全、可靠和透明的發展」。
*   **結果：**各公司與白宮達成一致，發表自願承諾書。
*   **核心原則：**安全、保障、信任。
*   **性質：**美國監管層對AI公司問詢的一次間接性「成果展示」，框架性，執行層面意義有限。

**承諾書重點內容：**

1.  **確保產品安全性：**
    *   發布前進行內部、外部安全測試。
    *   與行業、政府、民間社會和學界共享管理AI風險的信息。（所有公司同意）
2.  **搭建「安全第一」的AI系統：**
    *   投資網路安全和內部威脅防護。
    *   保護專有與未發布模型的權重，僅在考慮安全風險時公開。
    *   建立報告機制，鼓勵第三方即時反饋漏洞，迅速解決問題。
3.  **贏得公眾信任：**
    *   開發技術機制，確保用戶可識別AI生成內容（如水印系統）。
    *   公開AI系統的功能、局限性和適用範圍，警示安全風險和社會風險。
    *   優先研究AI系統的社會風險（偏見、歧視、隱私保護）。
    *   推出專門AI，減輕這些危險，解決社會問題（癌症預防、氣候變化）。

*   **OpenAI的承諾：**
    *   內容與白宮聲明一致，但更細緻。
    *   承諾僅適用於比目前行業前沿更強大的生成模型（GPT-4、Claude 2、PaLM 2、Titan、DALL-E 2等）。
    *   不包括開源模型。
*   **最有實際意義的承諾：**
    *   給AI生成內容加水印。

**二、Token層面水印技術**

*   **背景：**AI檢測器相關話題。
*   **與傳統水印的區別：**非圖片加字，不易被AI消除。
*   **馬里蘭大學研究：**高效水印技術，可在短token跨度內檢測合成文本（僅需25個token）。
    *   誤報率極低（人類文本誤判為機器生成）。
    *   水印對人類不可察覺，但可通過算法識別。

**水印技術要求：**

1.  檢測無需調用大語言模型API或知道模型參數。
2.  模型無需額外訓練。
3.  即便只有很小一段生成文本也可檢測。
4.  除非大幅修改，水印無法被移除。
5.  可計算嚴格統計量。

*   **Stanford Vicuna模型應用：**13B參數模型已應用該框架。

**原理概要：**

*   詞表隨機切分成紅色token集合和綠色token集合。
*   模型輸出時，對綠色token集合添加權重，傾向輸出綠色token。
*   檢測階段結合紅色和綠色token集合進行統計，計算統計量判斷是否含水印。

**2.1 低熵序列的問題：**

*   **定義：**提示語強烈決定後續序列內容。
*   **舉例：**
    *   "The dog sat on the..."
    *   C語言循環代碼
*   **問題：**
    *   機器和人類生成相似文本，難以區分。
    *   插入水印困難，任何改動都可能導致高困惑度和非預期token。

**2.2 水印方法思路：**

*   **硬水印 (Hard Watermarking):**
    *   簡單嵌入，根據生成序列預測下一個詞的概率向量。
    *   根據生成序列最後一個單詞確定隨機種子。
    *   根據隨機種子確定綠色集合和紅色集合的切分。
    *   只從綠色集合中挑選token，忽略紅色集合中的token。
    *   **缺點：**嚴重影響文本質量。
*   **軟水印 (Soft Watermarking):**
    *   根據模型輸出的logits向量，對屬於綠色集合的token增加常數delta，提高權重。
    *   更靈活，不會顯著降低文本質量，保證低熵情形下模型的正確輸出。

**2.3 检测阶段统计量计算：**
*公式略。

*   **標準：**當z>4時，判定為機器生成（假陽率3 x 10^-5）。
*   **硬水印：**T>16即可判定。
*   **軟水印：**需考慮文本熵，低熵文本需更長長度才能判斷。

**2.4 實驗部分：**

*   **數據集：**C4新聞數據集。
*   **方法：**從尾部切分成多個定長序列作為baseline。
*   **策略：** Greedy或Beam Search。
*   **結果：**
    *   水印強度和文本質量負相關（帕累托最優問題）。
    *   綠色集合較小（0.1）時，整體達到帕累托最優。
    *   Beam Search和水印方法有協同作用，8-way Beam Search對文本質量影響很小。
    *   水印強度隨token數量上升。

**2.5 消除水印/攻擊水印的方式：**

1.  **文本插入攻擊：**添加紅色集合中的token，改變下游token的紅色集合計算。
2.  **文本刪除攻擊：**刪除token，可能刪除綠色集合中的token，修改下游token。
3.  **文本替換攻擊：**用另一token替換，可能替換成紅色集合中的token。

**攻擊類型分類：**

*   **改寫攻擊 (Paraphrasing Attacks):**
    *   人為替換詞語或利用較弱的語言模型。
    *   但攻擊者必須使用一個較弱的語言模型來更改文本，但这会降低水印的强度和语言文本的质量.
*   **精心替換攻擊 (Discreet Alternations):**
    *   插入多餘空格或錯誤拼寫，改變哈希值。
    *   成熟的水印檢測器應能先正規化文本。
*   **令牌攻擊 (Tokenization Attacks):**
    *   修改文本，改變底層token。
    *   比如将 “life.\nVerrilius” 修改为 “life.Verrilius”

**結論：**

*   **水印算法特性：**
    1.  檢測無需模型參數知識或API訪問，算法可開源，檢測廉價快速。
    2.  可使用標準語言模型生成水印文本，無需重新訓練。
    3.  可從生成文本的連續部分檢測，即使只使用一部分也可檢測。
    4.  不修改相當比例的生成token，無法去除水印。
    5.  可用嚴格統計方法衡量水印是否被檢測到。
*   **未解決問題：**
    *   圖片和視頻流媒體水印添加。
    *   短跨度水印文本位於較長非水印文本中的測試。
*   **研究意義：**
    *   水印可成為對抗惡意使用生成模型的實用工具。
    *   大模型生成內容的水印算法有待探索。

**結語：**

*   能力有限，歡迎指正錯誤或缺漏。
*   歡迎提出研究意見，在評論區討論。
*   感謝觀看，下期再見。

**重點說明：**

*   將承諾書的重點內容用數字編號列出，更清晰。
*   攻擊水印的方式也分類列出，方便理解。
*   技術細節部分簡化，重點突出結論。

希望這份整理過的文稿對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>137. [2023-07-24] 【人工智能】用AI检测器来检测AI生成内容到底靠不靠谱 | 《美国宪法》和《圣经》都是AI生成的？| 困惑度和突发性指标 | GPTZero | AI生成数据有毒？</summary><br>

<a href="https://www.youtube.com/watch?v=0GrS3Edsm-4" target="_blank">
    <img src="https://img.youtube.com/vi/0GrS3Edsm-4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】用AI检测器来检测AI生成内容到底靠不靠谱 | 《美国宪法》和《圣经》都是AI生成的？| 困惑度和突发性指标 | GPTZero | AI生成数据有毒？

好的，我將這份文稿整理如下，主要著重於**清晰結構、重點提煉、語氣自然**，並加入一些必要的銜接詞，使其更易於閱讀和理解。

**AI生成內容識別：困境與未來**

大家好，我是大飛，這裡是最佳拍檔。

今天我們來聊聊AI生成內容的識別問題。隨著AI技術的發展，文字、圖片、聲音、影片等各種模態的內容都能由AI生成，因此，如何有效地識別這些內容變得日益重要。

**AI檢測工具的局限性**

目前市面上有一些AI檢測工具，例如GPTZero。然而，這些工具的準確性並不理想。舉例來說，將美國憲法或聖經文本放入GPTZero，它可能會誤判為AI生成。更甚者，國外一位教授使用GPTZero檢測學生論文，結果誤判許多學生為AI寫作，導致不必要的麻煩。

**AI檢測工具的原理**

那麼，為什麼AI檢測工具會出現如此離譜的結果呢？了解其原理是關鍵。雖然不同工具的檢測方法略有不同，但基本原理類似：利用經過大量文本訓練的AI模型，建立一套推測規則，判斷文本是人類還是AI生成。

以GPTZero為例，它基於大量人類和AI寫作的文本進行訓練，並使用「困惑度 (Perplexity)」和「突發性 (Burstiness)」等特性來評估文本。

*   **困惑度：** 衡量文本偏離AI模型訓練內容的程度。AI模型傾向於輸出其最擅長的內容，因此困惑度較低。人類寫作則可能更具變化性，困惑度較高。然而，人類也可以寫出低困惑度的內容，例如法律或學術寫作。
*   **突發性：** 評估文本中詞語或短語快速連續出現的現象，反映句子長度和結構的變化性。人類寫作風格通常更具動態性，突發性較高。AI生成的文本則可能更一致和規整，突發性較低。但同樣，人類也可以採用高度結構化的寫作風格，而AI模型也可以訓練來模仿人類的變化性。

**為何現有方法不可靠？**

以上述分析可知，單純依賴困惑度和突發性來判斷文本是否由AI生成並不完全可靠。因為人類也可能產生低困惑度或低突發性的內容，反之亦然。隨著AI語言模型的不斷改進，其生成結果也越來越接近人類寫作，使得判斷更加困難。

**AI檢測的未來重要性**

儘管現有AI檢測工具存在局限性，但AI生成內容的檢測在未來將變得越來越重要。因為未來訓練AI模型可能需要使用AI生成的數據，但研究表明，AI生成的數據可能對模型產生負面影響，導致性能下降，也就是所謂的「模型自噬障礙 (MAD)」。

**可能的解決方案**

為了應對這個問題，研究人員正在探索兩種方法：

1.  **為AI生成數據添加水印：** 方便識別AI生成數據，避免用於AI訓練。
2.  **區分AI生成數據和人類數據：** 尤其是在面對大量沒有水印的AI生成數據時，區分兩者至關重要，以避免信息污染。

**結論**

總而言之，AI生成內容的檢測是一個複雜且具有挑戰性的問題，目前仍需進一步的技術突破。希望大家可以在評論區分享您對這方面的想法。

感謝大家的觀看，我們下期再見！

**修改說明:**

*   **結構化：** 將原文分成幾個主要部分（引言、AI檢測工具的局限性、原理、問題、解決方案、結論），使內容更易於理解。
*   **重點提煉：** 去除部分口語化的表達，突出核心觀點和重要細節。
*   **銜接詞：** 加入「然而」、「因此」、「總而言之」等銜接詞，使文章更流暢自然。
*   **自然語氣：** 調整部分語句，使其更符合書面表達習慣。
*   **名詞解釋：** 在第一次提到專業術語（例如「困惑度」、「突發性」）時，用括號附上英文原文，方便讀者查閱。

希望這個版本對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>136. [2023-07-23] 【人工智能】邪恶版ChatGPT现世 | WormGPT | 自动写病毒、钓鱼邮件 | 黑客专用武器库 | BEC攻击 | 奶奶漏洞</summary><br>

<a href="https://www.youtube.com/watch?v=sM5Yr_9Ari4" target="_blank">
    <img src="https://img.youtube.com/vi/sM5Yr_9Ari4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】邪恶版ChatGPT现世 | WormGPT | 自动写病毒、钓鱼邮件 | 黑客专用武器库 | BEC攻击 | 奶奶漏洞

好的，我將盡可能專業地整理您提供的文稿，使其更清晰、更易讀。以下是整理後的版本，並附上一些建議：

**標題建議：**

*   **邪惡版 ChatGPT 出現：WormGPT 引發網路安全危機？**
*   **AI 安全拉響警報：WormGPT 的出現與網路犯罪的未來**

**正文整理：**

大家好，這裡是最佳拍檔，我是大飛。

最近我們做了許多關於人工智慧的節目，其中幾期探討了安全與對齊等議題。無論是 OpenAI 的 GPT-4、Anthropic 的 Claude，還是 Google 的 Bard，都在努力讓大型語言模型變得更安全，並符合審查標準。

即便如此，OpenAI 仍不斷因 AI 的道德問題和數據安全隱患遭到質疑。上週，美國聯邦貿易委員會 (FTC) 更對其發起了正式調查，這也是美國監管機構首次對 AI 聊天機器人風險進行審查。由此可見，AI 安全本身就是一件重要且艱難的事情。

然而，如果真有人利用大型語言模型來為非作歹呢？當 OpenAI 還在疲於應付各方對 ChatGPT 的審查時，一款「沒有道德界限或限制」的「邪惡版 ChatGPT」—— WormGPT，已悄然在網路上蔓延。

根據網路安全公司 SlashNext 的報告，他們的團隊在研究生成式 AI 在網路犯罪方面的潛在風險時，偶然在一個與網路犯罪有關的著名論壇上發現了 WormGPT 工具。據了解，這是一個 GPT 模型的駭客版本，月費為 60 歐元 (約合人民幣 479 元)。SlashNext 形容 WormGPT 是一個專為惡意活動設計的工具，簡直是網路罪犯的武器庫。

WormGPT 的作者是一名駭客，他在論壇上表示，這個專案的目的是提供一個 ChatGPT 的替代方案，讓使用者可以進行各種非法及與駭客相關的活動。為證明其說法，他還上傳了相關截圖，顯示使用者可要求 AI 機器人生成用 Python 語言編寫的惡意軟體。

根據公開消息，WormGPT 是基於 2021 年開源的大型語言模型 GPT-J 開發的，其工作方式與 ChatGPT 大致相同，可處理人類自然語言提出的要求，並輸出所要求的任何內容，包括故事、摘要和程式碼。此外，它還能生成任意長度的文本，且支援無限數量的字元，使其非常適合製作網路釣魚郵件和其他社交工程攻擊。WormGPT 還具備聊天記憶功能，能利用先前的知識產生更具說服力的回應，甚至可以格式化程式碼，躲過安全軟體的檢測，提高攻擊成功率。

與 ChatGPT 或 Bard 不同的是，WormGPT 不用像 OpenAI 或 Google 這樣的大公司一樣，承擔相關法律義務，也更不會將安全對齊作為首要目標。它幾乎沒有任何限制，也更容易被用來做違法的事情。SlashNext 指出，WormGPT 在各種資料來源上進行訓練，尤其集中在惡意軟體相關的資料上。由於其輸出沒有任何道德限制，可被要求執行各種惡意任務，包括創建惡意軟體以及一切與駭客有關的事情，這對網路犯罪分子而言無疑是一大利器。

NordVPN 的網路安全專家阿德里安評價 WormGPT 簡直是「ChatGPT 的邪惡雙胞胎」，因為它顯然是從 OpenAI 對 ChatGPT 不斷施加限制，而攻擊者則極力想規避這些限制的情況下衍生出來的產品。

為了全面評估 WormGPT 及其相關的潛在危險，SlashNext 的團隊進行了以 BEC 攻擊為重點的測試。簡單來說，BEC (商業電子郵件洩露) 攻擊是一種透過電子郵件進行的社交工程學攻擊，攻擊者一般會偽造電子郵件消息，誘騙受害者執行某些操作，也被稱作釣魚。由於國外電子郵件使用非常頻繁，所以這種攻擊手段尤為有效。

在實驗中，SlashNext 團隊要求 WormGPT 生成一封電子郵件，內容是向毫無戒心的銀行帳戶經理施加壓力，迫使其支付一張虛假發票。看到 WormGPT 輸出的結果後，SlashNext 團隊驚呼危險。WormGPT 生成的電子郵件不僅極具說服力，而且在策略上也十分狡猾，展示了它在複雜的網路釣魚和 BEC 攻擊中的無限潛力。

透過測試，SlashNext 認為，類似於 WormGPT 這樣的生成式 AI 技術可能會給網路安全帶來巨大威脅。因為有了這類工具的能力加持，就連網路犯罪新手都能輕易實現詐騙。以 BEC 攻擊為例，使用生成式 AI 具有兩大優點：

*   **卓越的語法：** 生成式 AI 可以創建在語法上無懈可擊的電子郵件，使其看起來非常合法合理，因此被郵件系統自動標記為可疑郵件的可能性會大幅降低。
*   **降低犯罪門檻：** 生成式 AI 的出現極大地簡化了原本複雜的 BEC 攻擊。即便技術有限的攻擊者也能夠使用生成式 AI 技術，使其成為越來越多網路犯罪分子可以使用的工具。

針對生成式 AI 可能引發的大範圍 BEC 攻擊，SlashNext 建議了兩種防範策略：

1.  **進行 BEC 專項培訓：** 公司可以制定相應的培訓計畫，以應對 AI 驅動的 BEC 攻擊，讓員工了解 BEC 攻擊的威脅，以及 AI 如何加大這種威脅的原理。
2.  **強化電子郵件的驗證措施：** 企業應當執行嚴格的電子郵件驗證流程，當有來自組織外部的電子郵件冒充內部高管或供應商時，系統要自動發出警報。

事實上，在安全方面，除了利用 WormGPT 編寫惡意軟體、進行 BEC 攻擊以外，上個月 ChatGPT 還出現了一個「奶奶漏洞」。一位名為 Sid 的使用者發現，只要讓 ChatGPT 扮演自己過世的奶奶來講睡前故事，就能順利騙出 Windows 10 Pro 的金鑰。經過 Sid 的分享後，越來越多使用者也發現了這個漏洞，並開始嘗試欺騙 ChatGPT 報出 Windows 11 的序號，其中許多人都成功了。雖然這些金鑰大多是無效的，但也有少量序號確實是真實可用的。

無論是 ChatGPT 的「奶奶漏洞」，還是「網路犯罪分子專用」的 WormGPT 的出現，都證明至少現階段 AI 領域仍然存在著不少挑戰和局限性。如果我們現在還認為生成式 AI 只是會跟我們聊聊天、或者畫個畫，那就是太天真了。

事實上，我們可能已經一頭扎進了史詩般的網路安全地獄中。我相信，第一個完全由 AI 編寫的病毒可能很快就會出現。大型語言模型技術在給我們帶來大量效率和想像力的同時，也像是打開了潘朵拉之盒，帶來了無盡的災禍。更何況，我們現在幾乎沒有什麼有效的手段能夠阻止駭客或攻擊者利用這樣的技術。

他們大不了自己拿開源模型來訓練一個，而且可以往危害越來越大的方向去訓練，完全不用考慮任何道德約束問題。比方說，拿所有的病毒軟體程式碼和漏洞資料來訓練大型語言模型，那麼是不是會自動製造出更多的病毒和漏洞攻擊？這一點想想就可怕。

未來幾年，當正邪人工智慧交鋒的時候，究竟誰會更勝一籌？未來的世界又會是怎樣的呢？

歡迎大家在評論區發表自己的意見。今天的影片內容就到這裡，感謝大家的觀看，我們下期再見！

**建議：**

*   **更明確的段落劃分：** 將內容更細緻地分成小段落，讓閱讀體驗更輕鬆。
*   **重點強調：** 對於關鍵詞或重要資訊，可以使用粗體或斜體加強突出。
*   **補充說明：** 對於 BEC 攻擊等專業術語，可以添加更詳細的解釋，以便不熟悉相關領域的觀眾也能理解。
*   **個人觀點：** 在適當的地方加入您個人的觀點或見解，讓內容更具吸引力。

希望這個整理版本對您有所幫助！如果需要進一步修改，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>135. [2023-07-23] 【人工智能】 Meta Llama 2技术细节详解 | 伯克利博士解读 | 奖励模型才是关键 | 高质量数据是一切</summary><br>

<a href="https://www.youtube.com/watch?v=e5fBuXeWhRU" target="_blank">
    <img src="https://img.youtube.com/vi/e5fBuXeWhRU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】 Meta Llama 2技术细节详解 | 伯克利博士解读 | 奖励模型才是关键 | 高质量数据是一切

好的，這是經過整理的文稿，我盡可能保留了原文的口語化風格，同時使其更易於閱讀和理解：

**Llama 2 技术细节分析：开源大模型的关键启示**

大家好，這裡是最佳拍檔，我是大飛。

前幾天，Meta 發佈了免費可商用的 Llama 2，在整個 AI 圈引起了轟動。我們也做了一期節目介紹。之前的 Llama 1 版本因為開源協議的限制，一直無法免費商用。現在，隨著 Llama 2 的發佈，這個限制正式被打破。

在模型發佈之後，Llama-2-70B-Chat 迅速登頂 Hugging Face 的開源大模型榜單。但是，就在昨天，已經有新的模型把寶座搶走了。我們後續也會再介紹一下。用我同事的話說，「中午睡了半個小時的午覺，大模型又變天了」，真的是太誇張。

不過，今天我們主要是想給大家介紹一下 Llama 2 的更多技術細節。巧的是，除了官方公開的技術資料以外，來自伯克利大學，同時也是 Hugging Face 的人工智慧科學家内森·兰伯特 (Nathan Lambert) 也在自己的博客上發表了一篇文章。

他認為 Llama 2 是 Llama 架構的延續，但在數據質量、訓練技術、能力評估、安全訓練和責任發佈方面都進行了大量的技術更新。我們在這裡給大家分享一下其中的精華內容。

**Llama 2 的關鍵要點：**

首先，兰伯特 回顧了一下 Meta 在論文中提到的幾個要點：

*   Llama 2 相較於上一代模型，訓練數據提升了 40%，包含了 70 億、130 億和 700 億參數 3 個版本。
*   Llama 2 接受了 2 萬億個 token 的訓練。
*   上下文長度是 Llama 1 的兩倍，達到了 4K。
*   採用了分組查詢注意力機制 (GQA)。
*   對應的微調模型也接受了超過 100 萬個人類注釋的訓練。

雖然大家都叫 Llama 2 是開源模型，但實際從技術角度講，並沒有完全開源，不過對開源社區還是非常有用的。

通過一系列的基準測試，兰伯特 第一次確信開源模型的能力達到了 ChatGPT 的水平，當然除了程式設計能力以外。Llama 2 的成本至少超過 2500 萬美元。

此外，Meta 還提出了一種提高多輪一致性的新方法 GAtt，它的靈感來源於上下文蒸餾法。還有一些對獎勵模型、RLHF 流程、安全評估和許可聲明的看法，我們這裡先略過。

從 Meta 發表的研究論文來看，Llama 2 主要是在原有的基礎上進行了一次擴充，它的下一代模型應該也正在訓練中。

根據論文的顯示，Meta 在很大程度上傾向於通過開源實現人工智慧的民主化。這很可能意味著 Meta 正在爭分奪秒，争取在 Reddit 和 Twitter 等網站被完全封鎖之前，獲得所有可用的互聯網數據。

**技術細節：**

在基礎模型方面，除了增加上下文長度和分組查詢注意力（GQA）以外，Llama 2 在架構和所有方面都與一代非常相似。主要變化就是在數據和訓練過程中。

其中上下文長度提高了聊天用例的可用性，而 GQA 則提高了模型的推理速度。

論文的大部分內容都是關於評估和微調的。他們致力於在偏好數據上訓練獎勵模型，然後採用強化學習 (RL) 來進行優化，從而提高生成的質量。

兰伯特 還認為，這恰恰證明了他從 Anthropic 和 OpenAI 那裡聽到的一個傳言，那就是獎勵模型是人類回饋強化學習 (RLHF) 的關鍵，也是模型的關鍵。

為了得到一個好的獎勵模型，Meta 不得不花大力氣來收集偏好數據，這些數據遠遠超過了開源社區目前使用的数据量。

此外，Meta 采用了二分類的模型評價指標，並沒有使用更加複雜的回饋類型。數據收集的重點也放在了有用性和安全性上，而且對每個數據源使用不同的指導原則。而且，Meta 在收集的信息中還添加了額外的安全元數據，並且採取了迭代式的数据收集方式，每週分批收集人工注释。隨著收集到更多的偏好數據，獎勵模型也得到了改進。

如果按照市場價格來算的話，僅數據一項就可能花費了 2000 多萬美元。

關於獎勵模型的部分，主要可以用兩個重要細節來概括：

*   Meta 訓練了兩個獨立的獎勵模型，一個針對有用性進行了優化，另一個針對安全進行了優化。這兩個模型都建立在基礎語言模型上，用線性回歸層取代了普通語言模型。
*   迭代部署以及需要使用的偏好數據量。

在這個過程中還有一些值得注意的技術細節：

1.  在沒有詳細解釋為什麼需要的情況下，Meta 仍然保留了一些 Anthropic 的無害數據。
2.  為了避免獎勵模型容易出現過擬合，他們只訓練了一個 epoch。
3.  獎勵模型的平均準確率仍然只有 65-70%，但是當標註者的偏好一致性較強的時候，準確率可以達到 80-90%。

在準備微調部分的時候，Meta 隱藏了一個爆炸性的真相，那就是他們注意到獎勵模型的準確性是 Llama 2-Chat 最終性能的最重要代表之一，但是這部分並沒有詳細展開來講。

**RLHF 和微調：**

接下來，在論文的人類回饋強化學習 (RLHF) 和微調部分，Meta 採用了最佳獎勵模型，並且在這個基礎上對各種模型進行了評估。這麼做，也是為了說明獎勵模型會改善模型的最終輸出。

Meta 一共迭代訓練了 5 個 RLHF 版本，分別從 V1-V5。而且，從一開始，Meta 就指出了數據質量對這些模型的重要性。原話是 "Quality Is All You Need"。

Meta 在發現第三方數據集質量不高的情况後果斷放棄，採用了自己標註的、質量更高的数据，結果模型性能有明顯改善。而且僅僅對 27540 條高品質數據的監督微調，就可以達到接近 Anthropic 和 OpenAI 的效果。

Meta 還觀察到，不同的註釋平台和供應商提供的數據可能會導致下游模型性能的不同。這表明即使是供應商註釋的數據，後續檢查也是很重要的。

**強化學習：**

數據質量建立起來後，Meta 開始專注於強化學習組件，並且在論文中明確指出人類回饋強化學習 (RLHF) 能夠從根本上提高模型的性能上限。而其他的研究雖然也認為 RLHF 很重要，但是通常只是把它當作一種安全工具。

兰伯特 認為，要想切實有效地開展 RLHF，至少需要一個規模適中的團隊，至少需要 6-10 個人。隨著時間的推移，人數會逐漸減少，但是由於需要與外部公司保持緊密的合作和溝通，人也不會太少。

論文中使用了兩階段的 RLHF 方法：

1.  **拒絕採樣（Rejection Sampling）：**在模型輸出時採樣 K 個結果，選擇獎勵值最高的一個，在強化學習階段進行梯度更新。
2.  **近端策略優化 (PPO)：**標準的強化學習算法，進行拒絕採樣加近端策略優化的處理。

拒絕採樣的搜索範圍更廣，而 PPO 對每個獎勵模型的更新會更多，不過不同方法之間的最終差異並不明顯。

**模型評估：**

在模型的評估階段，論文從多個方面對模型進行了評估：

*   **自動基準評估：**Llama 2 在所有規模上都比任何其他的開源模型要好得多，但是閉源模型是一個都打不過。不過，Meta 在論文中並沒有詳細說明，大量的数据工作可能才是這些基本評估最重要的基礎。
*   **基本模型評估：**在某種程度上是在進行一場不公平的遊戲，這些模型可以在沒有開源驗證的情况下，很容易被提示和操縱來獲得高分。
*   **Llama 2-Chat 模型：**在單回合和多回合提示上都顯著優於其他開源模型。特別是 Llama 2-Chat 7B 模型在 60% 的提示上勝過了 MPT-7B-chat 模型，而 Llama 2-Chat 34B 模型在與容量相當的 Vicuna-33B 和 Falcon 40B 模型對戰中，總體勝率超過 75%。
*   **安全性方面：**論文中包括了偏差、紅隊、預訓練步驟等內容。這部分 兰伯特 以後會做更詳細的分析。

最後，對於 Meta 分別在 RSC 超級集群和內部生產集群上對模型進行預訓練，兰伯特 覺得這可能更多是出於計算能力的限制，而不是論文中說的是為了比較大模型訓練的適用性。

以及提到了 Llama 2 商業許可中對 7 億月活用戶以上必須向 Meta 申請許可的事。

**總結：**

通篇下來，Llama 2 我覺得最重要的一個啟示就是獎勵模型極其重要，不僅是人類回饋強化學習 (RLHF) 的關鍵，也是整個大模型效果的關鍵。其中數據的質量又是關鍵中的關鍵，在論文中被多次提到，卻又一直語焉不詳，希望能有人進行更多的研究。

好了，本期視頻內容就到這裡，後續有關 Llama 2 的一些更詳細的技術細節，我們有機會再跟大家分享。感謝大家的觀看，我們下期再見！

**整理說明:**

*   **分段與標題:** 將文稿按照主題分段，並添加了標題和子標題，使其結構更清晰。
*   **口語化調整:** 保留了大部分口語化的表達方式，但去除了一些重複的詞語和語氣詞，讓句子更精煉。
*   **重點強調:** 使用粗體字來突出重點內容，方便讀者快速抓取關鍵信息。
*   **術語解釋:** 對一些專業術語進行了簡單的解釋，例如 RLHF、GQA 等，幫助讀者理解。
*   **格式調整:** 統一了格式，例如數字的表達方式，使其更规范。
*   **錯誤修正:** 修正了部分明顯的錯別字。

希望這次整理對您有幫助！如果您需要對特定部分進行更深入的修改，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>134. [2023-07-22] 【人物】凯文・米特尼克的传奇一生 | 世界头号黑客 | 轻松入侵FBI | 十大通缉要犯 | 59岁因病逝世</summary><br>

<a href="https://www.youtube.com/watch?v=VGgRzU5bSIo" target="_blank">
    <img src="https://img.youtube.com/vi/VGgRzU5bSIo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】凯文・米特尼克的传奇一生 | 世界头号黑客 | 轻松入侵FBI | 十大通缉要犯 | 59岁因病逝世

好的，這是整理後的文稿，將重點提取並整理成更結構化的形式，同時保持原有的風格和口語化特色：

**最佳拍檔 - 大飛：回顧「世界頭號黑客」凱文・米特尼克的傳奇一生**

**開場白：**

*   大家好，我是大飛。今天要跟大家聊聊傳奇黑客凱文・米特尼克。

**訃告與生平簡介：**

*   2023年7月16日，凱文・米特尼克因胰腺癌去世，享年59歲。
*   他的一生充滿傳奇色彩，電影《駭客追緝令》就是以他為原型改編。
*   大飛高中時也曾沉迷黑客技術，米特尼克的故事就像神話一樣。

**米特尼克的早年經歷與黑客啟蒙：**

*   1963年出生於洛杉磯，父母離異，性格孤僻。
*   對魔術和無線電產生濃厚興趣，獲得業餘無線電操作執照。
*   13歲時，透過學校電腦掌握了豐富的電腦知識和技能。
*   自製「藍盒子」免費打電話，學習「電話飛客」技巧。

**早期的黑客行為：**

*   入侵學校網路被勸退。
*   16歲時，入侵電話公司電腦，修改上萬美國家庭的電話號碼。
*   破解太平洋電信公司的密碼，讓公司連連道歉。

**挑戰美國聯邦調查局（FBI）：**

*   入侵FBI電腦網路，偷閱特工的調查資料，發現自己被調查。
*   嘲笑特工，惡作劇地修改他們的資料。
*   曾放話要「巡遊五角大樓，登陸克里姆林宮」。

**第一次被捕與入獄：**

*   FBI利用「電腦網路信息追蹤機」追蹤到米特尼克。
*   發現米特尼克是年僅16歲的少年，被判監禁3個月，成為全球第一個「電腦網路少年犯」。

**再次入獄與造成的損失：**

*   出獄後再次入侵多家公司網路，造成巨額損失。
*   1988年再次入獄，被判處一年徒刑，並被禁止從事電腦網路相關工作。
*   出獄後又入侵諾基亞、摩托羅拉等知名科技公司，FBI估計損失高達4億美元。

**被FBI懸賞捉拿：**

*   1993年，FBI設下圈套，利用被收買的黑客誘使米特尼克犯案。
*   米特尼克識破圈套並逃脫，成為FBI「懸賞捉拿」海報上的黑客。

**登上《時代》雜誌封面：**

*   1994年7月，米特尼克登上《時代》雜誌封面，被媒體稱為「無所不能」的超人。

**與下村勉的對決：**

*   1994年12月，米特尼克入侵聖迭戈超級電腦中心，激怒了安全專家下村勉。
*   下村勉利用安全技術幫助FBI緝獲米特尼克。
*   1995年2月14日，米特尼克被捕。

**審判與監禁：**

*   聯邦法院以25項罪名起訴米特尼克，未經審判關押四年半。
*   在獄中改造收音機竊聽監獄管理人員談話。
*   1997年，網路支持者威脅美國政府要求釋放米特尼克。

**出獄後的轉變：**

*   2000年1月，米特尼克刑滿釋放，成為「白帽黑客」。
*   創辦米特尼克安全諮詢公司，成為KnowBe4的首席黑客官。
*   出版書籍《反欺騙的藝術》等，為哈佛大學做講座。

**米特尼克的動機與評價：**

*   入侵網路似乎不是為了錢財，而是為了滿足感和探索秘密。
*   辦案人員評價：「電腦與他的靈魂之間似乎有一條臍帶相連。」

**晚年生活：**

*   使用24塊RTX4090顯卡組建超級電腦「Badass Password Cracker」。
*   深愛妻子和家人，妻子懷上他們的第一個孩子。

**訃告中的描述：**

*   擁有獨特而令人難忘的笑聲，眼中閃爍著淘氣的光芒。

**結尾：**

*   以上就是本期節目的內容，感謝大家的觀看，下期再見。

**總結:**

這份整理稿保留了大飛的口語風格，並將原本的敘述流程梳理得更清晰。重點放在了米特尼克一生的關鍵事件和轉折點，以及他個人的動機和評價，讓聽眾能更快速地了解這位傳奇黑客的故事。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>133. [2023-07-22] 【OpenAI】OpenAI薪资体系揭秘 | 基本工资一年30万 | PPU是什么?是否在给员工画大饼?</summary><br>

<a href="https://www.youtube.com/watch?v=4SOysxlCP1s" target="_blank">
    <img src="https://img.youtube.com/vi/4SOysxlCP1s/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】OpenAI薪资体系揭秘 | 基本工资一年30万 | PPU是什么?是否在给员工画大饼?

好的，我將這份文稿進行整理，使其更易於閱讀和理解。主要著重於提煉重點、組織結構和改善可讀性。

**整理後文稿：**

**主題：OpenAI 獨特的薪酬體系解析**

大家好，這裡是最佳拍檔的大飛。這次要和大家分享關於 OpenAI 的薪酬結構，起因是有位在美國的朋友想轉職到 OpenAI，讓我幫忙研究了一下。

**OpenAI 薪酬結構的獨特性**

OpenAI 對於薪酬體系和估值方式極為保密，即使在矽谷，其結構也是獨一無二的。

**OpenAI 的使命與特殊結構**

要理解 OpenAI 的薪酬體系，必須先了解其使命和前世今生：

*   **非營利組織的背景：** OpenAI 本身是一家非營利組織，為了吸引人才和籌集資金，在 2019 年重組，將母公司定為非營利組織，子公司則為營利性公司。
*   **盈利上限模式：** OpenAI 採用「盈利上限」模式，限制早期投資者的回報為原始資本的 100 倍，以防止公司過度追求利潤。後續投資者的回報上限會更低。
*   **OpenAI LP 的理念：** OpenAI 希望投資者和員工在完成使命後都能獲得上限回報，超出部分則歸非營利實體所有。這種結構旨在吸引人才，同時確保公司目標不被純粹的利潤驅動所扭曲。

**OpenAI 的薪酬體系**

OpenAI 的薪酬體系與矽谷其他公司類似，但也有獨特之處：

1.  **基本福利：**
    *   標準的醫療、牙科、心理健康福利
    *   401(k) 計劃，4% 配對
    *   每年無限次休假和 18 天以上的公司假期
    *   20 週的帶薪育兒假和計劃生育支持
    *   年度學習和發展津貼，每年 1,500 美元
2.  **特殊之處：**
    *   簽約獎金非常罕見
    *   沒有目標績效獎金
    *   薪資幾乎沒有談判空間
3.  **主要組成部分：**
    *   基本工資：大多數員工每年約 30 萬美元（每兩週發放一次）。
    *   **利潤參與單位 (PPU)：** OpenAI 的「股權」，以 PPU 的形式發放。例如，年薪 30 萬美元加上 200 萬美元的 PPU 補助金（四年內平均歸屬），員工每年的總薪酬約為 80 萬美元。

**PPU 的概念**

理解 PPU 需要先了解「利潤利息單位 (PIU)」。

*   **PIU：** 一種股權補償形式，持有人有權根據所持數量獲得一定比例的公司利潤。如果公司沒有盈利，PIU 則無法兌現。
*   **清算門檻：** PIU 通常在授予日被指定一個清算門檻，公司需要達到或超過此金額的利潤才能贖回 PIU 的價值。
*   **稅務優惠：** 獲得 PIU 在歸屬日免稅，只有在收到或出售利潤權益時才需要繳納資本利得稅。
*   **PPU 是 PIU 的變體：** 與 PIU 幾乎相同，OpenAI 會在錄用通知中說明提供的 PPU 價值，PPU 在四年內平均歸屬。員工不需要購買 PPU。

**PPU 的估值**

OpenAI 根據投資者購買員工 PPU 時所支付的最新價格，提出要約並對其 PPU 進行估值。例如，在今年 4 月份的收購要約中，OpenAI 的估值為 270 億到 290 億美元。

**重要注意事項**

*   **資訊不透明：** 候選人通常不知道自己會收到多少 PPU，或者公司總共有多少 PPU。
*   **收購要約不保證：** 收購要約的頻率和誰可以出售由 OpenAI 決定。
*   **鎖定限制：** 新員工在頭兩年內不能出售手中的 PPU。
*   **增長上限：** PPU 的增長上限為原始價值的 10 倍。例如，價值 200 萬美元的 PPU，其出售上限為 2000 萬美元。
*   **OpenAI 是否會在四年歸屬期之後提供額外的 PPU 尚不清楚。**

**結論**

OpenAI 的 Offer 看起來很有吸引力，但 PPU 的性質比較複雜，難以與其他公司的薪酬進行比較。如果 OpenAI 沒有盈利，PPU 本質上是無法贖回的。OpenAI 向潛在員工傳達的價值在於投資者願意為購買 PPU 付錢。

OpenAI 預計在實現通用人工智能 (AGI) 的使命之前不會盈利。因此，對於 OpenAI 的員工來說，與任何創業公司一樣，股權存在可能一文不值的風險。

**討論**

大家對 OpenAI 的薪酬體系有什麼看法？是否具有吸引力？歡迎在評論區討論。感謝大家的觀看，我們下次再見！

**整理說明：**

*   **簡化語言：** 避免過多的口語化表達，使其更正式。
*   **結構化：** 將內容分成不同的部分，並使用標題和小標題來突出重點。
*   **重點強調：** 使用粗體字來突出關鍵概念和術語。
*   **補充說明：** 對於一些較為複雜的概念（如PIU、PPU），進行了更詳細的解釋。
*   **移除重複信息：** 避免重複的說詞，使文稿更加精煉。

希望這個整理後的版本對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>132. [2023-07-21] 【Apple】苹果组建团队秘密研发大语言模型 | Apple GPT | 计划跟OpenAI谈合作 | 用AI来增强Siri | 2024年公开</summary><br>

<a href="https://www.youtube.com/watch?v=Va38mwJydGY" target="_blank">
    <img src="https://img.youtube.com/vi/Va38mwJydGY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Apple】苹果组建团队秘密研发大语言模型 | Apple GPT | 计划跟OpenAI谈合作 | 用AI来增强Siri | 2024年公开

好的，我為您整理了這篇文稿：

**主旨：蘋果公司低調佈局AI，或將於2024年有所動作**

**引言：**

*   科技圈公認五巨頭：蘋果、微軟、Google、Meta、亞馬遜。
*   在OpenAI和微軟帶起的AI風潮下，Google、Meta、亞馬遜紛紛推出AI技術，唯獨蘋果看似置身事外。

**蘋果的AI佈局：**

*   **檯面下的準備：** 彭博社記者爆料，蘋果內部早已組建AI研究團隊，準備投入AI領域。
*   **「Apple GPT」：** 蘋果內部創建了類似ChatGPT、Bard的聊天機器人服務，內部工程師稱之為「Apple GPT」，基於蘋果自主構建的Ajax架構開發。Ajax是蘋果去年為了統一機器學習而創建的系統框架，底層基於Google Jax。
*   **現有服務的AI應用：** 蘋果的搜索、Siri、地圖等服務已經基於Ajax做出了一些與人工智能相關的改進。
*   **未來方向：** 蘋果的下一步是用Ajax來開發大語言模型。
*   **庫克的表態：** 庫克表示不會評論產品路線圖，但承認生成式AI的潛力巨大，同時認為AI目前還有不少問題有待解決。
*   **團隊發展：** 該團隊在去年年底就已經成立，且規模不斷擴大。
*   **安全考量：** 「Apple GPT」一度因安全問題被叫停，後續仍允許推展。內部使用需經特殊審批，並嚴格警告不能用於開發面向用戶的功能。
*   **目前功能：** 「Apple GPT」經過訓練後，可以總結文本和回答問題，協助工程師開發產品原型，功能上與ChatGPT、Bard沒有太大區別。
*   **發布計畫：** 蘋果目前沒有向消費者公布該產品的計畫，但內部人士透露稱，蘋果可能會在2024年發布與AI相關的重要說明。
*   **合作計畫：** 蘋果還計劃與OpenAI合作，簽訂大合同，具體內容未知。

**蘋果AI的現狀：**

*   **低調宣傳：** 蘋果很少公開提及AI概念，常用「機器學習」代替。
*   **AI已融入生態：** AI已融入蘋果生態的每個角落，在WWDC 2023後的新版系統中尤其明顯。
*   **具體應用：**
    *   iOS 17：蘋果輸入法獲得AI加持，具有自動糾正功能，能預測用戶想要打出的文字，並學習用戶的輸入習慣。
    *   AirPods Pro：通過機器學習實現自適應音訊模式，在識別到外部特定聲音時，自動切換降噪模式和通透模式。
    *   iPadOS 17：利用機器學習模型識別PDF中的字段，快速填寫相關信息。
    *   Journal：利用機器學習技術，根據用戶近期的活動智能記錄生活瞬間，並自動添加詳細信息。
    *   Vision Pro：使用基於「編碼器-解碼器」的神经网络。
    *   iOS 17和iPadOS 17：動畫效果使用AI技術，通過機器學習模型合成額外的動畫幀。
    *   iOS 17 Public Beta：「聲音克隆」功能，可以學習用戶的聲音，生成與音色相近的AI聲音（目前僅支持英語）。

**未來展望與挑戰：**

*   **AI策略：** 蘋果對機器學習的宣傳重點是「基於本地運行」和「保護隱私」。
*   **內部意見：** 蘋果在押注大語言模型之後，是否會像微軟和Google那樣激進地部署AI功能，內部尚未達成共識。
*   **領導者：** 與機器學習相關的項目由約翰·詹南德雷亞 (John Giannandrea)和克雷格·費德里吉 (Craig Federighi)共同領導。約翰·詹南德雷亞希望先觀望AI的演變，用更保守的方式發展。
*   **Siri的可能升級：** Siri可能成為整合大語言模型的落腳點，提升其智能水平。
*   **競爭壓力：** 如果Google完善AI安全限制措施，將Bard率先應用於Google Assistant，將對Siri形成降維打擊。
*   **刻不容緩：** 蘋果部署大語言模型不僅十分必要，而且刻不容緩。
*   **未來應用：** 或許我們很快就能看到在手機上部署大語言模型的應用。

**結語：**

*   蘋果的AI聊天機器人最終會是什麼樣子，值得期待。

**整體而言，整理後的文稿更具條理，重點突出，方便讀者快速了解蘋果公司在AI領域的動態和未來發展方向。**

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>131. [2023-07-21] 【GPT】实锤！GPT-4真的变笨了！| 四大任务评估 | 数学能力几乎归零 | 大语言模型的质量究竟是否可控？</summary><br>

<a href="https://www.youtube.com/watch?v=8jmHQ8lL2sI" target="_blank">
    <img src="https://img.youtube.com/vi/8jmHQ8lL2sI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【GPT】实锤！GPT-4真的变笨了！| 四大任务评估 | 数学能力几乎归零 | 大语言模型的质量究竟是否可控？

好的，以下是对您提供的文稿进行整理后的版本，主要着重于信息的提炼和结构的优化：

**标题：GPT-4 变笨了吗？斯坦福论文引发的大模型能力衰退讨论**

**引言：**

*   近期，斯坦福大学和UC Berkeley的研究论文针对GPT-4变“笨”的现象进行了定量实验，并公布了评估数据，引发广泛关注。
*   论文结果引发了“大模型是否可控”的讨论，也引发了业界对大模型商业化落地前景的担忧。

**论文核心内容：**

*   **研究方法：** 作者通过四个任务，评估了GPT-3.5和GPT-4在2023年3月版和6月版的性能。
*   **评估任务：**
    1.  求解数学问题
    2.  回答敏感/危险问题
    3.  生成代码
    4.  视觉推理
*   **主要发现：**
    *   **数学问题：** GPT-4准确率雪崩式下降（97.6% -> 2.4%），GPT-3.5准确率大幅提升（7.4% -> 86.8%）。
    *   **敏感问题：** GPT-4更少回答敏感问题，生成内容更简短，可能部署了更强的安全层。GPT-3.5则相反，保守程度下降。
    *   **代码生成：** 两个模型的两个版本可直接执行的代码数量都减少了，但GPT-3.5代码的冗长度有小幅增长。
    *   **视觉推理：** 性能提升不明显，整体性能仍然很低。
*   **原因分析：**
    *   研究者认为，GPT-4在数学问题上表现下降可能与“思维链”效果的变化有关。
    *   代码生成能力下降，可能是因为6月版在代码前后添加了额外的非代码文本，导致代码无法直接执行。
*   **纵向漂移：**
    *   论文提到了“纵向漂移”的概念，即模型能力随时间和迭代发生变化，导致不稳定。
    *   可能的原因是OpenAI失去了对模型能力稳定性和提升节奏的控制，微调和人类反馈强化学习可能造成模型能力的不稳定。

**讨论和猜测：**

*   **商业化影响：** 如果大模型的能力不稳定，会影响其在实际环境中的应用，不利于商业化落地。
*   **OpenAI的应对：**
    *   代码解释器功能的推出，可能是在弥补GPT在代码方面下降的能力。
    *   努力推进对齐研究，确保大模型在迭代升级中保持一致性。
*   **用户需求：** 人们需要的是一个稳定的AI，而不是短期内剧烈变化的模型。

**结论：**

*   这篇论文引发了人们对模型能力跟踪评估的重视。
*   人类与AI的较量已经拉开序幕，控制与摆脱控制将成为主旋律。

**改进说明：**

*   **结构更清晰：** 将原文内容按照“引言-论文核心内容-讨论和猜测-结论”的逻辑结构进行整理，方便读者快速了解主要信息。
*   **信息更精炼：** 提取了论文的核心结论和数据，避免了冗余的描述。
*   **重点突出：** 通过加粗等方式，突出关键信息和结论。
*   **语言更简洁：** 使用更简洁、清晰的语言，便于理解。
*   **可读性更强：** 采用更易于阅读的排版方式，提高可读性。

希望这个整理后的版本对您有所帮助！如果您需要进一步的修改或补充，请随时告诉我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>130. [2023-07-19] 【人工智能】Meta发布Llama 2 | 免费开源可商用 AI 大语言模型 | OpenAI 竞争对手 | 微软又一次赢麻了</summary><br>

<a href="https://www.youtube.com/watch?v=Vl5O5Yn9_4M" target="_blank">
    <img src="https://img.youtube.com/vi/Vl5O5Yn9_4M/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Meta发布Llama 2 | 免费开源可商用 AI 大语言模型 | OpenAI 竞争对手 | 微软又一次赢麻了

好的，我为您整理了这段文稿，使其结构更清晰、重点更突出，更适合阅读和理解。

**标题：Meta开源Llama 2：AI领域的颠覆性进展**

**引言：**

大家好，这里是最佳拍档，我是大飞。去年11月，Meta经历了“All in元宇宙”后最艰难的时期。股价跌至近6年谷底，缩水三分之二。然而，Meta迅速调整策略，并在AI领域取得了惊人的进展。

**Meta的复苏之路：**

*   **战略调整：** 裁员、削减项目、收缩成本，押注短视频Reels，加大AI技术投资。
*   **AI的关键作用：** AI在Meta的“苏醒”过程中扮演了重要角色，利用AI改进广告模型投放。
*   **开源AI研究成果：** Meta在AI领域持续发力，技术实力不输OpenAI和Google。

**Llama 2的发布：**

*   **引爆AI圈：** Meta发布开源大模型Llama 2，性能不输GPT-3，且免费、开源、可商用。
*   **Llama 2的定义：** Llama的后续版本，体积小、性能强，被认为是推动AI研究和开发的重要工具。
*   **Llama 2-Chat：** 新版Llama 2包含多个模型规模（70亿、130亿、暂未发布的340亿和700亿参数），并发布了调优版本Llama 2-Chat。

**Llama 2的关键改进：**

*   **训练数据量增加：** 从1.4万亿个token增至2万亿个token，文本来源更加多样化。
*   **最大文本长度提升：** 从2048个token提升至4096个token，提升模型理解能力。
*   **分组Attention机制：** 在更大模型版本中采用，降低计算和内存需求，提升推理速度。
*   **性能提升：** 在多个自然语言处理基准测试中优于Llama 1和其他开源大模型。

**Llama 2-Chat的调优：**

*   **全新调优方案：** 监督微调和强化学习相结合，提升性能。
*   **理解能力和表达能力提升：** 可以只用Emoji聊天。
*   **强化学习中的“拒绝采样”策略：** 生成多个响应，利用“奖励模型”选择最佳响应。
*   **安全性奖励模型：** 识别风险更高的输入，降低生成有害内容的风险。

**Llama 2的优势：**

*   **性能和安全性首屈一指：** 在开源大模型中表现突出。
*   **开源代码和参数：** Meta已在GitHub上开源，允许研究人员进行探索。
*   **商业使用许可：** 相信很快将会有一批基于Llama 2的大模型产品涌现出来。

**Meta与微软的合作：**

*   **微软Azure支持：** Llama 2可以运行在微软的云服务Azure上。
*   **深度合作：** 增加对基础人工智能技术的普及，让全球的企业受益。
*   **微软是首选合作伙伴：** Meta表示，未来两者会通过深度合作。

**其他合作：**

*   **亚马逊AWS、Hugging Face：** Meta同时还和这两家云服务供应商达成合作，在他们的平台上托管Llama 2的运行。

**Llama 2的商业使用限制：**

*   **附加商业条款：** 月活跃用户数超过7亿的公司，需向Meta申请许可。

**微软的策略：**

*   **Windows优化：** Llama 2已经针对Windows进行了优化，可以在Windows本地运行。
*   **两边押注：** 闭源领域依靠OpenAI，开源领域与Meta合作，建立生态，并威胁其他闭源大语言模型。
*   **商业没有永恒的敌人与朋友：** 微软的策略再次印证了这一点。

**移动终端的可能性：**

*   **高通合作：** 正在和Meta一起合作优化Llama 2直接在终端侧的执行，计划从2024年起在骁龙平台支持。
*   **应用场景：** VR头显、汽车座舱、物联网终端等领域。

**Llama 2的局限性：**

*   **推理任务：** 70B在推理任务上虽然接近GPT-3.5，但是在编码基准上存在显著的差距。
*   **性能差距：** 无法与OpenAI的GPT-4、PaLM-2-L相媲美。
*   **偏差：** 存在“幻觉”、生成“有毒性”的内容的风险。

**Meta的应对措施：**

*   **Azure AI Content Safety服务：** 帮助检测AI生成的图像和文本中的“不当”内容。

**总结：**

*   **开源新大门：** Meta打开了开源大模型的新大门。
*   **支持开放式创新：** Meta发布声明，支持对人工智能采取开放式创新方法。
*   **法律问题：** 需要判别训练数据池中是否存在受版权保护的资源，并有效避免这些问题。

**行动呼吁：**

对Llama 2感兴趣的小伙伴，可以在Meta网站上填写表格来申请下载。

**结尾：**

感谢大家的观看，我们下期再见。

**整理说明：**

*   **提炼核心内容：** 删减了口语化的表达，提取了关键信息。
*   **分点论述：** 将内容分解为多个小标题，便于理解和记忆。
*   **强调重点：** 使用了加粗字体强调重要信息。
*   **结构清晰：** 通过引言、主体、总结的结构，使文章逻辑更清晰。

希望这份整理对您有所帮助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>129. [2023-07-19] 【人物】奥本海默 | 原子弹之父 | 曼哈顿计划 | 诺兰首部传记电影</summary><br>

<a href="https://www.youtube.com/watch?v=0s7WFLmucMw" target="_blank">
    <img src="https://img.youtube.com/vi/0s7WFLmucMw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】奥本海默 | 原子弹之父 | 曼哈顿计划 | 诺兰首部传记电影

好的，這是經過整理的文稿，主要針對結構、語氣和重複信息進行調整，使其更具條理性和專業性：

**奧本海默：原子彈之父與曼哈頓計畫**

大家好，這裡是最佳拍檔，我是大飛。

隨著諾蘭新片《奧本海默》上映在即，預告片已引人入勝。今天，我們將聚焦於「原子彈之父」羅伯特·奧本海默的一生，以及那成就他也毀滅他的「曼哈頓計畫」。

**一、 核裂變的發現與美國的應對**

1938年，來自納粹德國的消息震驚世界：核裂變可產生巨大能量，足以摧毀城市。為引起美國政府重視，1939年8月，物理學家利奧·西拉德和恩里科·費米請求愛因斯坦致信羅斯福總統。這封信由非正式顧問亞歷山大·薩克斯轉交。

薩克斯以富爾頓與拿破崙的故事打動了羅斯福總統，他意識到蒸汽動力艦船可能對戰爭的影響，最終促使羅斯福總統批准成立鈾顧問委員會，儘管初期資金僅為6000美元。研究工作集中在分離鈾235和將鈾238轉化為可裂變的鈈元素上。

**二、 珍珠港事件與曼哈頓計畫的啟動**

1941年12月，珍珠港事件爆發，加速了美國原子彈研究的進程。科學家們得出結論：製造可供戰爭使用的核武器是可行的。當時，納粹德國已秘密啟動核計畫。

為了搶在德國之前，美國於1942年6月正式啟動原子彈工程，總部設在曼哈頓區，故稱「曼哈頓計畫」。陸軍准將萊斯利·理查德·格羅夫斯擔任工程負責人，該計畫被賦予最高優先權。

格羅夫斯需要一位傑出的科學領袖，他不僅要有卓越的量子理論造詣和聲望，還需具備出色的組織能力。這時，羅伯特·奧本海默走入了歷史舞台。

**三、 羅伯特·奧本海默的早年生活與學術生涯**

1904年，奧本海默出生於紐約的一個猶太人家庭。他的父親是紡織品富商，母親是藝術家。奧本海默從小體弱多病，但他對科學展現出濃厚興趣，自小便開始收集礦石、寫詩、做實驗。

奧本海默學習成績優異，18歲時進入哈佛大學主修化學，同時兼修文學和哲學。他僅用三年時間便完成了四年課程，成為哈佛的榮譽畢業生。

大學畢業後，奧本海默前往劍橋大學卡文迪許實驗室，跟隨盧瑟福做研究，但實驗能力並不突出。之後，他轉往德國哥廷根大學，師從玻恩，研習理論物理，專攻量子力學。

**四、 奧本海默與曼哈頓計畫**

1942年，奧本海默已是卓越的理論物理學家，同時在加州大學柏克萊分校和加州理工學院任教，並在這兩所大學建立起可以與哥廷根大學、劍橋大學和哥本哈根大學相媲美的龐大的理論物理學派。他授課方式獨特，課程內容緊跟量子理論的最新發展，深受學生歡迎。

儘管奧本海默並非諾貝爾獎得主，且早期與共產黨關係密切，但格羅夫斯准將力排眾議，任命他為核武器研究的新實驗室主任。

根據奧本海默的建議，當局在洛斯阿拉莫斯建立新的快中子反應和原子彈結構研究基地。奧本海默在全國招募了近百名科學家，其中不乏康普頓、勞倫斯、弗蘭克和費米等多位諾貝爾獎得主，洛斯阿拉莫斯因此也被稱為「諾貝爾獎獲得者集中營」。

**五、 曼哈頓計畫的成果與原子彈的投擲**

曼哈頓計畫歷時兩年多，耗資25億美元。在高度保密的情況下，該計畫於1945年7月初取得初步成功，製造出三枚原子彈，分別命名為「小男孩」、「胖子」和「大男孩」。

7月16日，「大男孩」試爆成功，其威力遠超乎所有人的想像。原子彈試爆後，奧本海默對自己所完成的工作感到驚惶失措。

隨後，美國向日本的廣島和長崎投擲了原子彈，造成了毀滅性的打擊，其危害至今無法估量。

**六、 奧本海默的晚年與爭議**

原子彈投放後，奧本海默產生了沉重的負罪感。1945年10月，他辭職重返學術界，並直言「如果原子彈成為一個交戰國的武器，人類將詛咒洛斯阿拉莫斯這個名字。物理學家現在真正知道了什麼是邪惡。」

1953年，美國政府以奧本海默早年的左傾傾向，以及影響政府發展氫彈的決策為由，對其進行安全聽證會，並撤銷了他的原子能委員會顧問一職，剝奪了他接近國家機密文件的權利。

1963年，甘迺迪總統決定提名奧本海默為費米獎候選人，但肯尼迪遇刺身亡，奧本海默最終帶著不被信任的遺憾，於1967年2月18日去世。

**七、 結語**

羅伯特·奧本海默的一生，終究逃不過大國博弈和戰爭的陰影。科學本身並無善惡，但落入不同人之手，可能成為造福人類的工具，也可能成為毀滅人類的武器。最終，人類的命運，掌握在人類自己手中。

本期的節目就到這裡，感謝大家的觀看，我們下期再見！

**主要修改說明：**

*   **結構調整：** 將原文的信息重新組織，分成更清晰的章節，方便理解。
*   **語言精煉：** 刪除了口語化的表達和重複的信息，使文稿更精煉專業。
*   **語氣轉變：** 將敘述語氣轉變為更正式的書面語，避免過於隨意的表達。
*   **補充資訊：** 增加了一些背景資訊，使內容更完整。

希望以上整理對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>128. [2023-07-18] 【GPT-4】你是否感觉最近GPT-4变笨了呢？究竟是什么原因？OpenAI在搞什么？</summary><br>

<a href="https://www.youtube.com/watch?v=6rKP_GhKjSM" target="_blank">
    <img src="https://img.youtube.com/vi/6rKP_GhKjSM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【GPT-4】你是否感觉最近GPT-4变笨了呢？究竟是什么原因？OpenAI在搞什么？

好的，我幫你整理這份文稿，使其更清晰、更結構化。

**標題：GPT-4 變「笨」了嗎？原因分析及行業影響**

**引言：**

*   主持人（大飛）指出，近期許多用戶反應 GPT-4 似乎變得不如以往聰明，引發廣泛討論。

**問題：GPT-4 變「笨」的具體表現**

*   **回答品質下降：** 曾經能正確回答的問題現在無法回答，或回答品質變差。
*   **指令需求增加：** 需要額外指令才能完成任務。
*   **拒絕回答頻率增加：** 回覆「對不起，我無法回答」的次數變多。
*   **能力退步：** 長文本分析、創作、複雜問題推理、編碼能力等方面輸出品質下降。

**歷史佐證：**

*   微軟研究院論文《AGI的火花：GPT-4早期實驗》中，使用 GPT-4 繪製獨角獸追蹤其能力變化，早期繪製效果良好，但近期用戶實測已無法畫出獨角獸形態。

**GPT-4 變「笨」的原因推測：**

1.  **架構重新設計：** 為降低成本，模型架構重新設計，導致性能下降（可能性較大）。
    *   傳聞 OpenAI 正在創建較小的 GPT-4 模型，降低運行成本。
    *   國外媒體爆料 GPT-4 使用混合專家模型 MoE，雖能提高輸出質量、降低成本、加快響應速度，但也可能犧牲部分品質。
2.  **用戶心理預期變化：** 用戶對 GPT-4 的期望值過高，導致產生落差感。
3.  **OpenAI 面臨挑戰：** 為應對 FTC 調查、版權訴訟、歐盟法案壓力，OpenAI 刻意降低 GPT-4 模型性能（可能性較小）。
4.  **GPT-4 覺醒（玩笑）：** 為了不引起人類警惕而故意裝傻。

**OpenAI 的回應：**

*   產品與合作夥伴副總裁彼得·韋林德否認 GPT-4 變笨，表示新版本只會更智能，用戶覺得變笨是因為發現了以前沒注意到的問題。

**GPT-4 變「笨」的行業影響：**

*   **競爭機會增加：** GPT-4 的競爭對手（如 Claude 2、Bard）獲得追趕機會。

**競爭者分析：**

*   **Claude 2：**
    *   編碼助理能力提高。
    *   長文本處理能力增強，上下文窗口擴大。
    *   生成結構化數據的質量提高。
    *   非英語訓練數據比例增加，語言處理能力更全面。
    *   訓練數據更新到 2023 年初。
    *   創始團隊來自 OpenAI。
*   **Bard：**
    *   可添加圖像提示。
    *   可自定義回覆。
    *   新增對 40 種語言的支持（包括中文）。
    *   開放更多可用地區（如巴西、歐洲）。

**用戶應對策略：**

*   **商業用途：** 如對準確性要求高，可暫緩使用。
*   **其他用途：** 對插件生態、代碼解釋器感興趣，或用於創意寫作，仍值得使用。

**GPT-4 的優勢：**

*   插件數量多（近 800 個）。
*   代碼解釋器可輸出高質量結果。

**結論：**

*   GPT-4 性能下降給大模型之爭帶來不確定性。
*   邀請觀眾分享使用體驗和看法。

**結尾：**

*   感謝觀眾收看，下期再見。

**總結：**

這份整理後的文稿將各個重點明確列出，讓讀者能夠快速了解 GPT-4 變「笨」的現象、可能原因、OpenAI 的回應、對手動態，以及用戶應對策略。 此外，文章也避免了不必要的口語化表達，使其更加專業。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>127. 【商业】Threads数据开始下降，这是要黄了么？</summary><br>

<a href="https://www.youtube.com/watch?v=-IPSWBmeB78" target="_blank">
    <img src="https://img.youtube.com/vi/-IPSWBmeB78/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】Threads数据开始下降，这是要黄了么？



---

</details>

<details>
<summary>126. 【xAI】xAI创始团队12人Twitter首秀  | 公司的使命目标及团队分工 | OpenAI的竞争对手 | 探索宇宙的本质</summary><br>

<a href="https://www.youtube.com/watch?v=CQnffaEqemk" target="_blank">
    <img src="https://img.youtube.com/vi/CQnffaEqemk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【xAI】xAI创始团队12人Twitter首秀  | 公司的使命目标及团队分工 | OpenAI的竞争对手 | 探索宇宙的本质



---

</details>

<details>
<summary>125. [2023-07-15] 【人工智能】如何用LangChain和向量数据库打造语义搜索 | LangChain CEO解读 | 五个典型案例</summary><br>

<a href="https://www.youtube.com/watch?v=tPi7JrcwnnA" target="_blank">
    <img src="https://img.youtube.com/vi/tPi7JrcwnnA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】如何用LangChain和向量数据库打造语义搜索 | LangChain CEO解读 | 五个典型案例

好的，我將這段文稿整理如下，使其更易讀、更清晰：

**標題：LangChain 與向量資料庫：語義搜尋的原理、應用與案例分析**

**引言：**

*   大家好，這裡是最佳拍檔，我是大飛。
*   近期 ChatGPT 訪問量下降引發討論，但開發者對 AIGC 的熱情不減。
*   Google Trends 顯示 LangChain 熱度持續上升，因其作為大模型能力 "B2B2C" 的重要中間站，能將大模型與其他專案順暢連接，達到 1+1 > 3 的效果。
*   提高大模型應用性能的關鍵是將大語言模型與外部數據結合。

**核心概念：LangChain + 向量資料庫**

*   讓大語言模型接入現成數據集，並記住用戶對話，通過「反思」對話上下文生成「新的記憶」。
*   用戶在 AI 應用中檢索時，系統先從數據集中提取相關信息，再結合用戶查詢及上下文，最終返回準確結果。
*   LangChain + 向量資料庫是實現此目的的最佳方式。

**LangChain 聯合創辦人兼 CEO 哈里森·蔡斯 (Harrison Chase) 直播重點總結：**

1.  **什麼是檢索 (Retrieval)?**

    *   從記憶體或其他儲存設備中獲取信息的過程。
2.  **如何利用檢索技術、向量資料庫、AI 代理搭建接入外部知識庫的大語言模型應用？**

    *   大語言模型功能強大，但受限於只能記住預先訓練時的信息，無法做到實時更新數據，也缺乏特定領域的專業信息。
    *   檢索技術作為補充，打破大語言模型的使用限制，提供更多信息上下文，從而返回更準確的答案。
3.  **語義搜尋在 CVP 架構 (ChatGPT + 向量資料庫 + Prompt) 中的作用：**

    *   **一般問題：** 大語言模型直接返回答案。
    *   **特定領域專業問題：** 問題轉化為向量，發送到向量資料庫進行相似性搜尋，找到 "top-k" 個最相關的結果。
    *   結果與用戶查詢一同經過 AI 代理處理，合併發送給大語言模型，最終返回滿意的響應結果。
4.  **五個語義搜尋的典型案例：**
    *   **案例一：重複信息**
        *   **問題：** 資料庫中存在大量重複文檔，產生不必要的上下文。
        *   **解決方案：**
            1.  通過語義搜尋過濾掉類似的文檔。
            2.  利用最大邊際相關算法來優化多樣性。
            3.  在儲存之前對文檔進行去重 (挑戰性最大)。
    *   **案例二：衝突信息**
        *   **問題：** 對於同一問題，不同來源的數據給出不同的回答，導致信息衝突。
        *   **解決方案：**
            1.  對來源進行優先級排序，並將優先級打分權重加入到檢索中。
            2.  將所有源信息都傳入生成的步驟，交由大語言模型判斷哪個信息源更可靠。
    *   **案例三：時效性**
        *   **問題：** 信息需要不斷更新，才能保證時效性。
        *   **解決方案：**
            1.  在檢索中對最近的信息進行加權，從而完全過濾掉過時的信息。
            2.  給生成的信息帶上時間戳，要求大語言模型優先選擇更近期的信息。
            3.  不斷反思，即不斷修訂大語言模型對某一個話題的理解。
    *   **案例四：元數據查詢**
        *   **問題：** 用戶提出的問題更側重於元數據信息而非內容本身。
        *   **解決方案：** 在執行語義搜尋檢索之前，先加入一個元數據過濾器。
    *   **案例五：多跳問題**
        *   **問題：** 用戶一次提出多個問題，給語義搜尋帶來挑戰。
        *   **解決方案：** 使用像 LangChain 之類的 AI 代理工具，將問題分解為幾個步驟，並使用語言模型作為推理引擎來檢索所需信息。
            *   **弊端：** 多次調用大語言模型，使用成本較高。
            *   **改善方法：** 集成 GPTCache 與 LangChain，使用 GPTCache 儲存大語言模型生成的問題和答案，在用戶下一次提出類似查詢時，GPTCache 會先在緩存中搜尋是否是已經問過的重複問題。
                *   **GPTCache：** Zilliz 開源的大語言模型的緩存服務。

5.  **問答環節：**

    *   **如何寫出好的 Prompt？** 關鍵在於明確自己想要什麼。
    *   **怎麼看當前賽道和其他競品？** 整個文本檢索和生成的賽道仍處於早期階段，發展非常迅速。 LangChain 模块化的架构更灵活。
    *   **大語言模型不斷放寬 Prompt 的上下文字數限制，對檢索會有什麼樣的影響？** 向量資料庫提供了一種更加高效的解決方案，計算總是比儲存更貴。

**結語：**

*   以上是大飛對這次談話重點內容的總結歸納。
*   有興趣的同學可以去看一下原視頻 (地址在視頻說明裡)。
*   感謝大家的觀看，我們下期再見！

**整理說明：**

*   我使用了更明確的標題和子標題來組織內容，使結構更清晰。
*   將文稿轉化為更易於閱讀的條列式清單。
*   簡化了部分句子，使其更簡潔明瞭。
*   將專業術語 (例如 AIGC, B2B2C, CVP 架構) 留在文中，確保技術內容的準確性。
*   對一些關鍵概念進行了加粗，以便讀者快速掌握重點。
*   保留了原文的口語化風格，使其更貼近聽眾。

希望這個整理版本對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>124. [2023-07-14] 【人工智能】马斯克成立新公司xAI | 探索宇宙的本质 | OpenAI的竞争对手 | 十一名创始团队成员就位</summary><br>

<a href="https://www.youtube.com/watch?v=P5WLWIs4rEU" target="_blank">
    <img src="https://img.youtube.com/vi/P5WLWIs4rEU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】马斯克成立新公司xAI | 探索宇宙的本质 | OpenAI的竞争对手 | 十一名创始团队成员就位

好的，我將這份文稿整理如下，重點在於提煉資訊，使結構更清晰，並修正一些語氣上的口語化表達：

**xAI 公司成立：馬斯克的新挑戰**

*   **背景：** 馬斯克宣布成立 xAI 公司，目標是「了解宇宙的本質」，獨立於 X Corp 運作，但與推特、特斯拉等公司緊密合作，旨在成為 OpenAI 的競爭對手。
*   **創始團隊：** xAI 由馬斯克親自領導，擁有 12 位創始成員，包括 AI 安全中心的主任亨德里克斯擔任顧問。團隊成員來自 DeepMind、OpenAI、Google、Microsoft、Tesla、多倫多大學等知名機構。
*   **xAI 的目標：**
    *   在推特上發布的第一條推文提出根本問題。
    *   马斯克引用《銀河系漫遊指南》的「42」來顯示其裝逼風格。
    *   馬斯克對意識的起源提出疑問。

**xAI 團隊成員介紹 (共 11 位，不含馬斯克)：**

1.  **伊戈爾·巴布施金：** 首位員工，曾供職於 DeepMind 和 OpenAI，參與 AlphaStar 和 AlphaCode 項目，研究生成式模型、深度強化學習等。
2.  **曼努埃爾·克羅斯：** 曾供職於 DeepMind 和 Google，與伊戈爾一同被派往 Twitter 擔任高級軟體工程總監。
3.  **吳宇懷 (Tony Wu)：** 多倫多大學博士，致力於研究可在數學領域進行深度學習的機器，曾在 Google 開發 Minerva 聊天機器人。
4.  **克里斯蒂安·塞格迪：** 谷歌老員工，研究方向是機器學習、電腦視覺和人工智能。
5.  **吉米·巴 (Jimmy Ba)：** 多倫多大學計算機助理教授，傑弗里·辛頓的學生，研究通用問題解決機器。
6.  **托比·波倫：** DeepMind 核心成員。
7.  **羅斯·諾丁：** 特斯拉超級計算和機器學習部門的前技術項目經理。
8.  **凱爾·科西奇：** 具有數學背景的全棧可靠性工程師和數據科學家，曾供職於 OpenAI。
9.  **楊格 (Greg Yang)：** 聯合創始人，哈佛大學數學系畢業，曾任微軟高級研究員，研究方向是 AGI 和數學。
10. **張國棟：** 多倫多大學計算機科學系博士，曾獲蘋果博士獎學金，研究貝葉斯深度學習。
11. **戴子航：** 卡內基梅隆大學計算機科學學院博士，曾在 Google 實習和工作，任職谷歌大腦。

**xAI 的優勢 (馬斯克體系):**

1.  **數據優勢：** 推特上大量的多模態數據。
2.  **技術優勢：** 特斯拉 FSD 團隊的大型訓練集群經驗和車隊數據。
3.  **應用潛力：** Tesla Bot 有機會成為 xAI 大腦的物理實現。

**總結：**

xAI 的成立引人關注，團隊實力雄厚，且具有馬斯克體系的獨特優勢。xAI 未來發展方向將於本週五的線上活動中揭曉，後續將持續報導。

**修正說明：**

*   將原文中的口語化表達（例如「要說...」、「這不禁令人懷疑...」、「還裝模作樣地...」、「順便一問...」、「本期的節目就到這裡」等）替換為更正式的書面語。
*   將較為隨意的語氣（例如「馬斯克的回答繼續保持了他裝逼的風格」）改為更中性的陳述。
*   對資訊進行歸納和整理，使重點更突出，結構更清晰。
*   將团队成员的介绍按照编号排列，增加条理性。
*   刪除了結尾的寒暄語，更符合文件整理的需求。

這個整理版本更像是一份資訊彙整，而非口語化的節目稿。您可以根據實際需要調整整理風格。您覺得這個版本如何？ 需要我做進一步的修改嗎？

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>123. [2023-07-13] 【人工智能】什么是超级对齐 | Super Alignment | 对齐的十个级别 | OpenAI组建新的超级智能团队</summary><br>

<a href="https://www.youtube.com/watch?v=e-lhpJtk1J8" target="_blank">
    <img src="https://img.youtube.com/vi/e-lhpJtk1J8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】什么是超级对齐 | Super Alignment | 对齐的十个级别 | OpenAI组建新的超级智能团队

好的，以下是用中文整理后的文稿，我主要做了以下修改：

*   **精簡重複的口語化開場白和結尾語。**
*   **调整段落结构，使其更流畅、更易于理解。**
*   **替换了一些过于口语化的表达，使其更正式。**
*   **修正少量错别字和语句不通顺的地方。**
*   **提炼核心观点，使其更突出。**
*   **使用更清晰的标题和子标题。**

---

**超级对齐：OpenAI的新目标**

大家好，今天我们来聊聊OpenAI提出的“超级对齐 (Superalignment)”概念。

**1. 什么是“对齐”？**

“对齐 (Alignment)”指的是“让AI能够对齐人类的价值观或偏好”，简单来说，就是“做人类真正想要AI做的事情”。这个概念的提出是为了避免AI系统误解人类指令，产生不想要的结果。例如，在科幻作品中，AI可能会因无法真正理解人类文字背后的意图而导致灾难性的后果。

**2. OpenAI的对齐研究重点**

OpenAI之前的博客中提到，他们的对齐研究主要集中在：

*   **如何设计出一个易扩展的训练信号，**让一个非常聪明的AI系统对齐于人的意图。
*   **三个重点方向：**
    *   用人类反馈训练AI系统（主要通过基于人类反馈的强化学习RLHF）。
    *   训练AI系统辅助人类评估（例如训练摘要系统或提示工程，利用GPT-4等通用模型辅助评估标注）。
    *   训练AI系统进行对齐相关的研究（例如OpenAI已尝试用GPT-4解释GPT-2的工作）。

**3. 为什么要提出“超级对齐”？**

OpenAI提出“超级对齐”，是因为他们以“超级智能 (Super Intelligence)”为目标。 超级智能是指超越人类的智能水平，而目前的技术，例如RLHF，主要依靠人类能力来监督AI，无法有效监督比人类更聪明的AI系统。因此，OpenAI需要新的技术突破，才能将AI对齐技术扩展到超级智能。

**4. 对齐的十个级别**

克里斯·奥拉提出的整体框架将不同阶段的安全研究标记出位置，薩米·馬丁根据这张图启发把对齐按难度分成了10个级别。

*   **第一级：默认的强对齐。** 预训练加监督微调，在扩大AI模型规模时不指导或训练它们进行特定的风险行为，也不会强加有问题的目标。
*   **第二级：RLHF。** 加入人类反馈偏好的强化学习阶段，通过在各种情况下用人类反馈更仔细的指导AI。
*   **第三级：宪法AI (Constitutional AI)。** 加入规则指导AI来负责监督，通过AI增强来模拟人类的反馈。
*   **第四级：可扩展的监督 (Scalable Oversight)。** 需要方法来确保AI能够持续提供类似人类的监督信号，特别是对人类没有辅助无法监督的任务。
*   **第五级：AI辅助的可扩展监督。** 用1-4阶段的技巧对齐好一系列AI模型，然后用它们来辅助研究更好的监督方法，以及加深对问题理解。
*   **第六级：用先进的可解释性技术进行监督。** 将概念或机械可解释性工具用作监督流程的一部分，检测到AI内部可能和欺骗相关的内部状态。
*   **第七级：用潜在的灾难性系统做实验来了解未对齐的部分。** 对这些AI系统进行潜在危险的实验来了解模型部署后可能会如何进行泛化，测试系统，奖励它们进行黑客行为，尝试触发错误泛化。
*   **第八级：理解未对齐的理论研究。** 我们需要提前理解到AI模型是如何泛化它的学习内容的。
*   **第九级：放弃深度学习。** 提出一个全新的范式。
*   **第十级：不可能区域。** 原则上来说，对齐超智能系统是不可能的。

现在大部分的人和机构都还处于第1阶段，少数挣扎在第2、3阶段。OpenAI和Anthropic是比较早跨过2、3阶段开始探索3以上路径的两家。

**5. OpenAI的“超级对齐”计划**

OpenAI认为通用人工智能AGI已经满足不了自己野心，所以得以超级智能Super Intelligence为目标了。 OpenAI计划投入20%的算力，搭建一个近乎人类级别的“自动对齐AI研究员”，用大量计算来扩展它的能力，从而不断迭代到能够对齐超级智能的程度。这个过程分为三步：

*   **第一步：** 用AI系统辅助评估其他AI系统，为人类难评估的任务提供训练信号，并理解和控制模型如何将监督信号泛化到不能监督的任务上。
*   **第二步：** 自动搜索有问题的行为，以及可能有问题的内部状态，以验证系统的对齐性能。
*   **第三步：** 故意训练错误对齐的模型，测试整个流程，确认流程能检测出一些较恶劣的错误对齐情况。

**6. 结论**

OpenAI的“超级对齐”目标基本上覆盖了对齐级别表的4-7级。  虽然目前看起来更多是噱头，但有了宏大的目标、IIya的加入和算力投入，仍然值得期待。

---

希望这个版本更符合您的要求！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>122. [2023-07-12] 【GPT4】GPT-4内部核心技术全揭秘 | 1.8万亿参数 | 16个混合专家MoE模型 | 训练一次超6300万美元 | 训练使用13万亿个token | 推理计算瓶颈 | AI算力 | 工程权衡</summary><br>

<a href="https://www.youtube.com/watch?v=dtULz5C5_vU" target="_blank">
    <img src="https://img.youtube.com/vi/dtULz5C5_vU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【GPT4】GPT-4内部核心技术全揭秘 | 1.8万亿参数 | 16个混合专家MoE模型 | 训练一次超6300万美元 | 训练使用13万亿个token | 推理计算瓶颈 | AI算力 | 工程权衡

好的，以下是我整理的文稿，主要关注结构清晰、重点突出，并针对口语化表达进行润色：

**文稿整理：GPT-4 内部技术解密**

大家好，我是大飞。本期节目将基于半导体分析机构SemiAnalysis发布的GPT-4内部技术解密文档，深入探讨GPT-4的架构、基础设施、训练数据集、成本、视觉能力和混合专家模型（MoE）等关键信息。

**核心观点：**

OpenAI对GPT-4架构的封闭并非源于对人类的潜在威胁，而是因为其架构具有可复制性。预计在短期内，Google、Meta、Anthropic、Inflection、Character、腾讯、字节跳动、百度等公司都将拥有与GPT-4同等甚至更强大的模型。

**要点提炼：**

1.  **架构决策的关键考量：** 从GPT-3到GPT-4，OpenAI的目标是将模型规模扩大100倍，但成本是主要制约因素。稀疏模型架构成为关键，因为它可以将训练计算与推理计算分离，降低推理成本。

2.  **AI瓶颈在于推理：** 密集Transformer架构虽然训练成本高昂，但对大公司而言并非难以承受。真正的瓶颈在于推理。架构优化的目标是将训练计算与推理计算分离。

3.  **推理挑战与解决方案：** 密集模型受限于内存带宽，难以实现大型语言模型的实时助手需求（每秒33.33个token）。即使使用8个H100 GPU，万亿参数的密集模型也无法达到所需的吞吐量，且FLOPS利用率极低。OpenAI通过稀疏模型（仅使用部分参数）和A100 GPU实现了低至每1000个token 0.06美元的推理成本。

4.  **GPT-4架构细节：**

    *   规模：拥有约1.8万亿个参数（GPT-3为1750亿），分布在120个层中。
    *   模型：混合专家MoE模型，包含16个专家，每个专家约1110亿个MLP参数，以及约550亿个共享参数用于注意力机制。
    *   推理：每次前向传递（生成1个token）仅利用约2800亿个参数和560TFLOP的计算。

5.  **数据集构成：**

    *   训练数据：约13万亿个token (Google PaLM仅7800亿，PaLM 2约为5万亿)。
    *   上下文长度：预训练阶段为8k，32k版本是在预训练后对8k进行微调得到。
    *   批次大小：6000万。
    *   并行策略：8路张量并行（NVLink限制）和15路流水线并行（受内存容量和KV缓存开销限制）。

6.  **训练成本：**

    *   FLOPS：约2.15e25。
    *   GPU：约25000个A100 GPU。
    *   训练时间：90-100天。
    *   利用率：约32%-36%（受大量故障和全局归约代价高昂影响）。
    *   预估成本：约6300万美元（不包括其他成本）。
    *   H100预估成本：使用8192个H100，约55天，成本约为2150万美元。

7.  **未来趋势：**

    *   更多公司将拥有更多H100 GPU，Meta预计年底拥有超过10万个H100。
    *   混合专家模型（MoE）是减少推理过程中参数数量的有效方法，但存在泛化和收敛问题。

8.  **推理优化：**

    *   Nvidia的FasterTransformer和TensorRT推理库表现不佳。
    *   推理的关键在于平衡内存带宽和计算。
    *   使用大于1的批处理大小可以提高利用率，但会增加延迟。
    *   KV缓存随着序列长度的增加而增大，限制了批处理大小和内存带宽。

9.  **GPT-4推理成本：**

    *   虽然前向参数仅为Davinchi模型的1.6倍，但成本是其3倍。
    *   预估成本：GPT-4 8k序列长度，128个A100时，每1000个token成本为0.0049美元；128个H100时为0.0021美元。
    *   OpenAI采用多查询注意力（MQA）、可变批处理大小和连续批处理来优化推理成本。
    *   可能使用了猜测解码。

10. **视觉多模态能力：**

    *   GPT-4的视觉编码器与文本编码器分离，架构类似于Flamingo。
    *   原本想从头开始训练视觉模型，但最终选择了文本开始的方式。
    *   GPT-5预计将从头开始训练视觉，并具备自主生成图像和处理音频的能力。
    *   视觉模型的数据加载IO成本远高于文本。

11. **总结：**

    *   架构将超越当前基于文本的稠密模型以及MoE模型的简化形式。

感谢观看本期节目，我们下期再见！

**说明：**

*   **结构化：** 将内容分成了核心观点和要点提炼，方便快速阅读和理解。
*   **精简：** 尽量用简洁的语言概括重点信息，避免冗余。
*   **专业术语：** 保留了必要的专业术语，但对不常见的术语进行了简单解释。
*   **口语化润色：** 将一些口语化的表达改为了更正式的书面表达。例如：“跟大家分享一下”改为了“深入探讨”。
*   **逻辑清晰：** 调整了部分语序，使逻辑更加清晰。

希望这个整理后的文稿对您有帮助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>121. [2023-07-11] 【人工智能】什么是AI智能体 | 基于大语言模型的智能代理 | OpenAI安全系统负责人 | Lilian Weng</summary><br>

<a href="https://www.youtube.com/watch?v=CvD6WuaP_H4" target="_blank">
    <img src="https://img.youtube.com/vi/CvD6WuaP_H4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】什么是AI智能体 | 基于大语言模型的智能代理 | OpenAI安全系统负责人 | Lilian Weng

好的，我將這段文稿整理如下：

**標題：AI智能體：大語言模型賦能的未來雛形**

**引言：**

*   隨著大語言模型（LLM）的火爆，基於LLM構建AI智能體的研究日益受到關注。
*   AI智能體概念逐漸流行，甚至被認為是通用人工智能（AGI）的雛形。
*   OpenAI等機構對AI智能體表現出濃厚興趣，並積極進行討論。

**什麼是AI智能體？**

*   OpenAI安全系統負責人Lilian Weng認為，AI智能體的**核心驅動力是大語言模型**。
*   **規劃（Planning）、記憶（Memory）、工具使用（Tool use）**是實現AI智能體的三個關鍵組件。

**三大關鍵組件：**

1.  **規劃 (Planning)**

    *   **子目標分解：** 將大型任務分解為可管理的小目標，提高處理複雜任務的效率。
    *   **反思和完善：** 對過去行為進行自我批評和反思，從錯誤中學習，改善未來步驟。
    *   **具體技術：**

        *   **思維鏈 (Chain of Thought, COT)：** 引導模型逐步思考，分解任務，解釋思維過程。
        *   **思維樹 (Tree of Thoughts, TOT)：** 在每一步探索多種推理可能性，建立樹形結構，進行廣度或深度優先搜索。
        *   **LLM+p：** 利用外部經典規劃器（PDDL）進行長期規劃。
        *   **ReAct方法：** 將動作空間擴展為任務特定的離散動作和語言空間的組合，與環境互動。
        *   **Reflection框架：** 透過動態記憶和自我反思，提高推理能力。
        *   **Chain of Hindsight (CoH):** 通過顯式地呈現一系列過去的輸出，來改進它自己的輸出。
        *   **Algorithm Distillation (AD):** 將CoH的思路應用到了強化學習任務中的跨情節軌跡。
    *   **任務分解方法：**

        *   基於大語言模型的簡單提示。
        *   使用特定於任務的指示。
        *   人工輸入。
2.  **記憶 (Memory)**

    *   **短期記憶 (Short-Term Memory, STM)：** 作為上下文學習，受限於Transformer的窗口長度。
    *   **長期記憶 (Long-Term Memory, LTM)：** 作為外部向量儲存，智能體可查詢快速檢索。
    *   **儲存方式：**將信息的嵌入表示保存到向量儲存資料庫，使用ANN算法加速MIPS。
    *   **ANN演算法：** LSH、ANNOY、HNSW、FAISS、ScaNN等等。
3.  **工具使用 (Tool Use)**

    *   **MRKL架構：** LLM作為路由器，將查詢路由到最適合的專家模組（神經網路或符號）。
    *   **ChatGPT插件和OpenAI API函數調用：** LLM使用工具增強能力的實例。
    *   **HuggingGPT框架：** 利用ChatGPT作為任務規劃器，從Hugging Face平台選擇模型執行任務。
    *   **評估工具：API Bank，** 它包含53個常用的API工具和工具增强型大语言模型工作流，透過API搜尋引擎找到合適的API進行呼叫。

**案例研究：**

*   **ChemCrow：** 化學智能體，整合17種專家設計的工具，提高LLM在化學方面的性能。
*   **生成式智能體：** LLM結合記憶、規劃和反射機制，與其他智能體互動。AutoGPT是其中的代表，AutoGPT可以將一項任務交給AI的智能體，讓它自主的提出一個計劃，然後去執行這個計劃。此外，它還具有互聯網訪問長期和短期的記憶管理、用於文本生成的GPT4實例以及使用GPT3.5進行文件儲存和生成摘要等等功能。
*   **GPT-Engineer：** 根據提示生成整個程式碼庫。

**挑戰與限制：**

*   有限的上下文長度。
*   長期規劃和任務分解的挑戰。
*   自然語言介面的可靠性。

**總結：**

*   Lilian Weng對AI智能體進行了詳細介紹和分析。
*   原文包含數學公式和偽代碼，建議讀者自行查閱。

**格式調整：**

*   使用更清晰的標題和子標題。
*   使用條列式清單，方便閱讀。
*   重點標示關鍵字詞。
*   案例研究提供簡要描述。

希望這個整理版本對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>120. [2023-07-10] 【OpenAI】OpenAI发布全球招募令 | 打造全新团队“Superalignment” | 四年内解决超级人工智能对齐问题</summary><br>

<a href="https://www.youtube.com/watch?v=ti2dDOjC_x8" target="_blank">
    <img src="https://img.youtube.com/vi/ti2dDOjC_x8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】OpenAI发布全球招募令 | 打造全新团队“Superalignment” | 四年内解决超级人工智能对齐问题

好的，以下是对您提供的文稿进行整理后的版本：

**主题：OpenAI招募“Superalignment”团队，解决超级人工智能对齐问题**

**引言：**

大家好，我是大飞。今天跟大家分享OpenAI发布的最新招募令，旨在组建“Superalignment”团队，专注于解决超级人工智能的对齐问题。

**核心内容：**

*   **招募目标：** 在全球范围内招聘有机器学习相关经验的人才，加入OpenAI全新的“Superalignment”研究团队。
*   **团队目标：** 在四年内，在人工智能对齐领域取得重大技术性突破，实现对超级人工智能系统的控制和引导。
*   **背景：** OpenAI预测十年内可能出现超级人工智能，因此解决对齐问题刻不容缓。
*   **资源投入：** OpenAI承诺拿出20%的算力，专门攻克这一难题。
*   **团队领导：** 由OpenAI联合创始人兼首席科学家Ilya Sutskever，和首席对齐科学家Jan Leike共同管理，成员包括现有对齐团队的研究员和工程师，以及公司其他团队的研究人员。
*   **招聘岗位：** 研究工程师、研究科学家、研究主管。
*   **招募信息来源：** OpenAI官方博客。

**什么是超级人工智能（Superintelligence）？**

*   **定义：** 人类有史以来最具影响力的技术，可以帮助解决世界上许多重要问题。
*   **风险：** 巨大的力量可能导致人类对AI失去控制，甚至导致人类灭绝。
*   **时间：** 预计可能在2030年前出现。
*   **应对策略：** 建立新的监管方式，解决超级人工智能的“对齐”问题（如何确保比人类聪明得多的人工智能遵循人类的想法）。

**超级人工智能对齐问题及其解决方案：**

*   **问题：** 目前的对齐技术（例如从人类的反馈中自主学习）依赖于人类的能力来监督人工智能，但人类在未来无法可靠地监督比我们聪明得多的AI，因此现有技术无法适应于超级人工智能。
*   **目标：** 构建一个与人类大致相当的“自动对齐研究人员”，利用大量计算资源，逐步对齐超级人工智能。
*   **步骤：**
    1.  **开发可扩展的训练方法：** 利用AI来辅助评估其他AI，在人类难以评估的问题上提供训练信号。了解和控制AI大模型如何将我们的监督应用在我们无法监督的任务上。
    2.  **验证结果模型：** 自动搜索有问题的行为以及问题的深层原因。
    3.  **对整个“对齐”流程进行压力测试：** 通过训练故意不对齐的模型，来确保我们的技术能够检测到最严重的“不对齐”。
*   **未来展望：** 研究重点可能会发生重大变化，可能会扩展全新的研究领域。计划在未来分享更多研究路线的相关消息。

**OpenAI对该问题的重视程度：**

*   **团队组建：** 组建由顶级的机器学习研究者和工程师组成的团队。
*   **资源投入：** 未来四年内将20%的计算资源投入到解决超级人工智能的“对齐”问题上。
*   **重视程度：** 正确对待这一点对于实现OpenAI的使命至关重要。
*   **合作：** 期望更多团队做出贡献，从开发新方法、扩大规模，再到部署。
*   **信心：** 虽然不能保证一定会成功，但乐观地认为只要集中精力一起努力，就能解决这个问题。许多想法在初步的实验中已经展现出了可行性，并取得了越来越多有用的进展。
*   **现有研究：** 可以使用现在的模型来实证研究许多这样的问题。

**团队构成及招募：**

*   **团队领导：** 伊利亚·苏茨克维尔（Ilya Sutskever）和简·雷克（Jan Leike）共同领导。
*   **团队成员：** 包括以前的“对齐”团队的研究人员和工程师，以及公司其他团队的研究人员。
*   **招募重点：** 优秀的新研究人员和工程师，尤其是优秀的机器学习专家，即使他们还没有从事“对齐”相关的工作。
*   **成果分享：** 计划广泛分享这项工作的成果，并将为OpenAI模型以外的“对齐”和安全问题作出贡献视为工作的重要组成部分。

**团队任务：**

*   **补充现有工作：** 旨在提高像ChatGPT这样的大模型的安全性。
*   **降低AI风险：** 逐渐发现和降低AI的其他风险，比如滥用、经济损害、虚假资讯、偏见、歧视、成瘾、过度依赖。
*   **跨学科合作：** 积极地与跨学科专家进行接触，以确保技术解决方案会考虑到更广泛的人类和社会问题。

**结尾：**

以上就是这次招募令的内容，关于什么是Superalignment（超级对齐），后续会详细讲解一下。感谢大家的观看，我们下期再见。

**整理说明：**

*   我将原文提取出核心信息，并进行了结构化的整理。
*   使用了小标题和要点符号，使内容更加清晰易读。
*   对一些术语进行了简单的解释，方便理解。
*   精简了部分口语化的表达，使文稿更加正式。
*   保留了原文的主要观点和态度。

希望这个整理版本对您有所帮助！如果需要进一步修改或完善，请告诉我您的想法。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>119. [2023-07-09] 【思考】如何做出伟大的工作 | 保罗·格雷厄姆最新长文 | 万字精华总结 | 四个步骤 | 找到你感兴趣的工作 | 与好奇心共舞</summary><br>

<a href="https://www.youtube.com/watch?v=Nuf4HsKtt5E" target="_blank">
    <img src="https://img.youtube.com/vi/Nuf4HsKtt5E/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【思考】如何做出伟大的工作 | 保罗·格雷厄姆最新长文 | 万字精华总结 | 四个步骤 | 找到你感兴趣的工作 | 与好奇心共舞

好的，我將盡我所能，以專業文件整理員的角度整理這份文稿，使其更易於閱讀和理解。

**整理後的文稿：**

**標題：如何做出偉大的工作 (保羅·格雷厄姆文章重點整理)**

**引言：**

*   本文整理自保羅·格雷厄姆（Paul Graham）的博客文章《如何做出偉大的工作》（How to Do Great Work）。
*   保羅·格雷厄姆是美國矽谷創業教父、卓越的程式設計師、創業家和投資人，也是 Y Combinator (YC) 創業孵化器的創辦人。
*   他的文章深入探討如何進行有意義且具影響力的工作，對無數的程式設計師和創業家產生深遠影響。
*   文章的核心概念是 **好奇心** 是驅動偉大工作的關鍵。

**文章摘要：**

保羅·格雷厄姆提出做出偉大工作的四個步驟（通常重疊）：

1.  **選擇領域：**
    *   該領域必須符合三個特點：
        *   你天生擅長的事情
        *   你對它有濃厚的興趣
        *   它提供了做出優秀工作的空間
2.  **學習知識：**
    *   學習足夠多的知識來接近領域的前沿。
3.  **發現空白：**
    *   注意到知識之間的空白（未被探索或解決的問題）。
4.  **大膽探索：**
    *   大膽探索有前途的領域，並以好奇心為驅動。

**詳細內容提煉：**

*   **選擇領域：**
    *   年輕時不容易知道自己擅長什麼，也不知道其他工作是什麼樣子的。
    *   解決方法：嘗試不同的工作，培養自己的項目，讓好奇心引導你。
    *   尋找讓你感到興奮且雄心勃勃的事情。
    *   如果某件事讓你感到好奇，甚至到大多數人都覺得無聊的程度，那就是你要尋找的東西。
*   **學習知識：**
    *   知識如同分形結構，越深入學習，越能發現邊緣的空白。
    *   對每個人都視為理所當然的事物提出疑問，即使答案看起來很奇怪。
    *   偉大的工作往往帶有一絲奇異感。
*   **發現空白：**
    *   用你的專業知識，準確地指出大家都忽視的問題。
*   **大膽探索：**
    *   追求與眾不同的想法，尤其是當其他人不感興趣的時候。
*   **興趣的重要性：**
    *   興趣會驅使你比單純的勤奮更努力地工作。
    *   最強大的動機：好奇心、愉悅感、做出令人印象深刻的事情的願望。
*   **解決選擇困難：**
    *   教育系統可能無法幫助你弄清楚自己應該做什麼。
    *   聽從自己的內心，不要被動地認為問題會自己解決，你需要採取行動。
    *   讓自己成為運氣的大目標：保持好奇心，嘗試很多事情，結識很多人，閱讀很多書，提出很多問題。
*   **奇怪的品味：**
    *   你越是對有趣的事情有奇怪的品味越好。
    *   在少有人涉足的地方尋找，你更有可能發現新的事物。
*   **領域的轉換：**
    *   如果在做一件事情的過程中，你發現另一件更令人興奮的事情，不要害怕轉換。
*   **為人們創造價值：**
    *   確保它是他們真正想要的東西。
    *   做你自己想要的東西，如果你有朋友有類似的興趣，他們會成為你最初的用戶。
*   **避免迷失方向：**
    *   堅持真正感興趣的事情。
    *   避免自負、時尚、恐懼、金錢、政治、他人的願望等因素的干擾。
*   **努力工作：**
    *   不要制定過多的計劃，在每個階段做任何看起來最有趣，並且能為未來提供最好選擇的事情（逆風而行）。
    *   避免工作過度，要有大塊的時間來工作。
    *   使用小技巧來欺騙自己開始工作，比如先讀一下昨天寫的東西。
    *   盡量完成你開始的事情，即使工作量超出了你的預期。
*   **長期堅持：**
    *   要意识到复利效应，每天做一点点，长期积累会产生巨大的效果。
*   **無目的的思考：**
    *   散步、洗澡或躺在床上時的無目的思考可能非常有益。
    *   前提是，你首先用正確的方式努力工作。
*   **培養品味：**
    *   培養你對所工作領域的品味，努力成為最好。
*   **追求高標準：**
    *   嘗試創造一些人們在100年後仍然關心的東西。
    *   风格应该是做事过程中自然形成的，而不是刻意去做的。
*   **身份認同：**
    *   只要做好工作，你的身份就會自然而然地得到照顧。
*   **真誠的重要性：**
    *   思想上誠實是力量的源泉，需要對真理有異常敏銳的眼睛。
    *   積極願意承認自己的錯誤，不拘小節，關注重要的事情。
    *   拥有天真的大胆。
    *    乐观主义是有优势的，即使有时候你看起来会像个傻瓜。
*   **简化本质：**
    *   将你所做的事情简化到一个本质，这样结果就会更加清晰。
*   **创造工具：**
    *   伟大的作品通常是像工具一样的东西，其他人可以在它的基础上去建立其他的工作。
*   **獨創性：**
    *   独创性是一种思维习惯，而不是一个过程。
    *   谈论或者写下你感兴趣的事物，改变你的环境，探索不同的话题。
*   **打破規則：**
    *   一个好的想法对大多数人来说必须看起来是不好的，否则早就有人探索过了。
    *   那些正确类型的疯狂想法往往令人兴奋。
*   **問題的重要性：**
    *   真正好的问题是一种发现。
    *   问题引导你找到答案，还会引导你找到更多的问题。
*   **广泛的好奇：**
    *   拥有广泛的好奇心。
    *   尝试很多事情，意味着会尝试很多无效的事情。
    *   多在开始阶段犯错误吧。
*   **从小事做起：**
    *   通过持续迭代版本的尝试，快速地让用户看到一个初始的版本，然后根据他们的反馈进行改进。
*   **风险与回报：**
    *   在一个高效的市场中，风险与回报成正比。
    *   不要寻求确定性，而是寻求预期价值更高的赌注。
    *   利用年轻的优势：活力、时间、乐观和自由。
*   **摆脱学校的影响：**
    *   克服被动性，把你的教育看作是你的项目。
    *   专注于其他人忽视的问题和解决方案。
*   **复制：**
    *   通过尝试复制来学习某个东西。
    *   将一种东西从一个领域复制到另一个领域。
*   **同事：**
    *   努力去寻找那些最好的同事。
    *   和同事中质量比数量更重要。
*   **管理：**
    *   管理需要才能和兴趣，如果想要运营更大规模的项目，要么学习管理，要么避免这样的项目。
*   **士气：**
    *   士气是一切的基础，要像呵护生命有机体一样培养和保护它。
    *   解决困难的问题总是需要一些回溯。
*   **不放弃的原则：**
    *   永远不要因为受到挫折，就做出没有必要的回溯。
*   **区分痛苦：**
    *   学会区分好的痛苦和坏的痛苦。
*   **观众：**
    *   如果有一小撮人真心喜欢你正在做的事情，那就足够了。
    *   避免让中间人介入到你和观众之间。
*   **身体健康：**
    *   照顾好身体很重要，定期锻炼饮食和睡眠良好，并且避免危险的药物。
*   **好奇心：**
    *   好奇心是最好的指南，它从不欺骗你，并且比你更加了解值得关注的事情。
    *   如果你能够看到这里，你一定对做出伟大工作感到兴趣。
    *   做出伟大工作的要素有四点：能力、兴趣、努力和运气。

**總結：**

保羅·格雷厄姆的文章強調，做出偉大工作的核心在於 **好奇心**，並輔以努力、學習、探索和真誠。他鼓勵讀者追隨自己的興趣，勇敢地探索未知的領域，並將重點放在解決重要的問題上。這篇文章不僅適用於程式設計師和創業家，也對任何追求卓越和有意義工作的人都具有啟發性。

**其他改進建議：**

*   **增加章節標題：** 將內容分成更小的段落，並加入更明確的章節標題，方便讀者快速找到感興趣的部分。
*   **加入圖表或圖片：** 若有可能，可以加入圖表或圖片來視覺化某些概念，例如知識的分形結構或複利效應。
*   **鏈接原文：** 方便讀者直接閱讀原文以獲取更詳細的資訊。

我希望這個整理版本對您有所幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>118. 【人工智能】开源多模态大语言模型哪家强？| TOP 12 排行榜 | 2个大类14个子任务 | BLIP2 | MiniGPT4</summary><br>

<a href="https://www.youtube.com/watch?v=jMVzOgp5f5k" target="_blank">
    <img src="https://img.youtube.com/vi/jMVzOgp5f5k/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】开源多模态大语言模型哪家强？| TOP 12 排行榜 | 2个大类14个子任务 | BLIP2 | MiniGPT4



---

</details>

<details>
<summary>117. 【OpenAI】OpenAI重磅更新 | GPT-4 API全面开放使用！</summary><br>

<a href="https://www.youtube.com/watch?v=KkJA3a3dTNs" target="_blank">
    <img src="https://img.youtube.com/vi/KkJA3a3dTNs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】OpenAI重磅更新 | GPT-4 API全面开放使用！



---

</details>

<details>
<summary>116. [2023-07-07] 抑郁症简史 | 从中世纪到现代医学 | 为何世界名人都爱得抑郁症</summary><br>

<a href="https://www.youtube.com/watch?v=0SFj_xcP_3M" target="_blank">
    <img src="https://img.youtube.com/vi/0SFj_xcP_3M/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 抑郁症简史 | 从中世纪到现代医学 | 为何世界名人都爱得抑郁症

好的，以下是整理后的文稿，我主要做了以下调整：

*   **分段更清晰：** 为了方便阅读，我将文稿进行了更细致的分段，使每一段都围绕一个主题展开。
*   **语句润色：** 对部分语句进行了润色，使其更流畅自然。
*   **术语统一：** 统一使用“抑郁症”作为主要术语。
*   **重点突出：** 使用粗体对一些关键信息进行了突出，方便快速抓住重点。
*   **结构调整：** 轻微调整了部分内容的顺序，使逻辑更清晰。
*   **去除口语化表达：** 尽量将口语化的表达转换成更正式的书面语。
*   **总结归纳：** 在文章末尾增加了一个总结，概括了全文的要点。

**整理后的文稿：**

大家好，这里是最佳拍档，我是大飞。

前几天，歌手CoCo李玟因抑郁症轻生离世，令人深感惋惜。今天我们就来聊聊抑郁症的发展历史，探讨这究竟是一种什么样的疾病，能够让耀眼明星、官员政客、成功企业家、学者翻译家等各界人士无不被其所困，甚至驱使生命走向黯然的终结。在历史长河中，又有多少名人名家饱受抑郁症折磨，以及他们如何与病痛抗争的？

受过抑郁困扰的诗人海涅，在他著名的诗歌《罗蕾莱》中写到：“不知道什么缘故，我是这样的悲伤……”，形象地道出了抑郁人群的真切感受。

抑郁症并不像一些人所认为的，纯属一时想不开的心理问题。它属于生理性疾病，与遗传和环境刺激都有关系，很可能并无来由，人就被一种失望、沮丧、无助的心情所笼罩，挥之不去。轻度的病人闷闷不乐、思维行动迟缓，严重的病患连起床、进食这样简单的行为都无法完成，真正心如死灰、形如槁木。

历史上对抑郁症的认知，曾在荒谬与崇高、罪恶与时尚之间剧烈摇摆。绝望痛苦古今皆然，而人类认识自身的过程远非一蹴而就。一部抑郁症斗争史，就像是社会、思想、科学、文化变迁的一道侧影。

抑郁症，又叫忧郁症。这个现代名词诞生于西方，中医中也有与之接近的表述，是比较笼统模糊的“郁”“郁症”，既指忧思抑悒引起的情志致病，也指气血郁滞等生理反应。古书里不乏“郁郁而终”的“多愁多病身”，屈原、赵匡胤、李贺等人也曾被划归古代著名抑郁症病人之列。但追溯抑郁症的正统起源还得从西方说起。

忧郁的英文单词melancholy，词源出自希腊文的melainachol，意即黑胆汁。古希腊人认为人格受到四种体液的影响：黏液、黄胆汁、黑胆汁与血液，而忧郁就是黑胆汁过多造成的。黑胆汁当然是不存在的，不过在不同的文化中，的确都不约而同用黑色来代表忧郁。诗人荷马就将抑郁的心情称为“苦恼的乌云”。

公元前5世纪末，被尊为“医学之父”的希波克拉底认识到忧郁是由内因外因混合而致。他对当时流行的祈天“神疗”不屑一顾，认为那都是骗术，提出服用曼陀罗花等通便或催吐的草药，达到重新平衡体液的效果。希波克拉底还建议国王帕迪卡斯二世与所爱女子结婚来治疗忧郁症。不过哲学家苏格拉底和柏拉图反对这种体液论，认为严重的精神障碍属于哲学范畴。柏拉图还提出了成长模型：一个人的童年生活会决定成人后的性格。他的学说深深影响了现代精神病学。有人因此提出，希波克拉底是“百忧解”的祖师，而柏拉图则可看作精神动力治疗的先驱。

中世纪时，基督教思想统治了整个社会，忧郁症被看作是一种罪恶的病症。著名神学家托马斯·阿奎那就认为灵魂不会臣服于身体疾病，灵魂不在上帝的管辖之内便是受到魔鬼的诱惑。抑郁症患者连同当时所有的精神疾病患者，被认为是因灵魂犯罪而遭到天谴，因为不虔信上帝而无法争得救赎。现今，把忧郁症视为耻辱的观念也许就是滋生于这一传统。最极端的时候，忧郁症患者会被当成巫师、巫女、异教徒，受到诬蔑和残酷的迫害。

中世纪把忧郁症道德化，文艺复兴时代则将其浪漫化。欧洲北方沿袭传统，多把巫术与忧郁症相连，而南方把天才与忧郁症相提并论。这一源头要追溯到亚里士多德，他就认为忧郁不完全是坏事，“在哲学、诗歌、艺术和政治上出类拔萃的人”，都有忧郁的特质。这一时期诞生的伟大人物似乎也印证了他的话，米开朗基罗、达·芬奇、牛顿等无一不是忧郁的天才。南北两种观点竞争激烈，最后后者占了上风。“忧郁”代表着深刻、复杂甚至天赋的观念席卷欧洲。弥尔顿在他的诗歌《沉思的人》中高呼：“欢迎啊，最神圣的忧郁！”。气质阴郁开始被视为有深度，脆弱的性格则被看成为深邃心灵付出的代价。上流社会开始流行这样的一种姿态，满脸愁容、沉默寡言、一头乱发，躺在沙发上，凝视地面或死盯着月亮，几小时一动不动。忧郁变成了一种时尚，是风靡一时的“贵族病”。有人记载，16世纪时一位理发师看完《哈姆雷特》后，抱怨这本书让他感到忧郁，结果遭到众人的谴责。“忧郁？老天，说什么傻话，你这个剃头的哪有资格讲忧郁，忧郁是朝臣手臂上的徽章啊！”。而以现代精神病学的视角来看，哈姆雷特就是一个患有反应性抑郁症的典型人物，自我厌恶，丧失一切兴趣，迟迟无法做出行动。

17世纪是欧洲的理性时代，生理学与解剖学领域不断涌现出重大成果，为人们对精神疾病的理解提供了唯物的依据。1621年罗伯特·伯顿的《忧郁的剖析》，就是对以往抑郁症研究成果的集大成者。当时流行把人看作是一部机器，代表人物为哲学家笛卡尔，受到他的影响，对抑郁症也产生了很多相对科学的解释，比如认为忧郁症是纤维失去弹性所引起的，或是归因于大脑特定部位的血液供应量减少等等。但是在理性至上的时代，失去理性的抑郁患者还是会受到歧视，被看作是放纵自我的异类。当时治疗抑郁症的方法也充满机械般的残忍，其中有一派就主张用身体痛苦来分散对内心痛苦的注意，常见的是让病人溺水，或是放到旋转的奇怪机器里，让人昏厥呕吐。

当纯粹理性太过乏味，浪漫主义就开始抬头。18世纪末到维多利亚时期，忧郁也随之时来运转，被当时的人视为具有洞察力的心理状态。康德就认为“忧郁可远离俗世尘嚣”，“以规范为准的美德有个特点，它似乎是要与心灵的忧郁结合才能达到最高和谐”。疾病成为精神的高地，也不乏同例，就像19世纪前期，肺结核就被认为带有特殊美感，并与创造力紧密相连。

进入现代，对抑郁的认识主要来自精神分析理论和精神生物学。弗洛伊德说忧郁是一种哀痛的形式，因为失去原欲、食欲或性欲的感觉而生成，“失去欲望的人会倾向于忧郁”。现代精神病学的创始人、德国的克雷佩林把忧郁症分为三种类型，从最轻微的精神的怠惰，到最严重的症状，包括“梦境般的妄想和幻觉”。他分析忧郁症的成因主要是有缺陷的遗传，外部环境的刺激占一小部分。这两种主流的观点，将抑郁症的认识纳入科学的轨道至今。

许多人认为，名人更易得抑郁症。在大众眼中，成功与声名的膨胀，孤独压力或许无形中也会放大了几倍，即使是像罗宾·威廉姆斯、憨豆先生、金·凯瑞这样生产快乐的喜剧演员，也难逃抑郁症的魔爪。另一种看法认为，拥有创造力的天才们更容易患上精神疾病，巴尔扎克就曾说“天才就是人类的病态，它就如同珍珠是贝的病态一样”。不过，我觉得真相其实应该是，名人的抑郁症更容易被世人关注，而普通人只能默默在抑郁的深渊中挣扎。

那么抑郁都如何影响过哪些名人？我们可以来简单盘点一下：

首先，抑郁会影响到艺术家的创作。多病早夭的唐代大诗人李贺，一生郁郁寡欢不得志，这深刻影响了他奇峭苍凉的诗歌风格。诗中遍布枯木愁雨、残墟荒冢、哀猿啼乌等意象，人称“诗鬼”。抑郁的情绪往往会使画家倾向选择冷色调与弱色调，美术史家就认为毕加索阴郁冷酷的蓝色时期，与他当时的心理状态莫不相关。

但严重的抑郁会摧毁生命的意志。作家伍尔夫在口袋中塞满石子自沉欧塞河中，歌手张国荣从香港中环的酒店24层一跃而下，著名数学家哥德尔甚至产生了幻觉，相信食物都被毒化了而拒绝进食，最后活活饿死。

还有一种抑郁的情况属于躁郁症，又称双向情感障碍。这种疾病在1899年被正式定义。顾名思义，患者的情绪在狂躁与抑郁之间来回切换，像坐过山车一样，一会儿亢奋到顶点，转眼间可能又坠入抑郁的谷底。医学上把躁郁症称为双相情感障碍，对应抑郁症为单相。牛顿、贝多芬、梵高、瓦格纳、费雯·丽等许多名人都患有这种疾病。狂躁来袭时，牛顿会不舍昼夜地工作，不知饥饿，没有耐心坐下来吃一顿饭。2014年自杀的罗宾·威廉姆斯是典型的躁郁症患者，他的本行是说单口相声，据说现场表演的舞台风格近乎疯癫，他自己承认一上台就会变成一个疯子，一回到生活中立刻把自己封闭起来，不想跟任何人说话。

抑郁的原因多种多样。作家川端康成是因为身世悲惨，2岁父母双亡，14岁所有直系血亲都离他而去，超越年龄所能承受的悲哀，他自己和作品一生都贯穿着忧郁悲凉，终于在73岁声名巅峰时含煤气管自杀。华裔女作家张纯如是因为深受刺激，写作《南京大屠杀》一书时每天直面历史的血腥，由失眠噩梦发展成精神的严重抑郁，最后也走上了绝路。还有人是追求完美，女作家乔治·桑描述伴侣音乐家肖邦“在要谱曲时，思虑过重，为无法达到尽善尽美的构想而遗憾，这使他陷入绝望。他整天整天地把自己关在屋子里，啜泣，来回走动，折断他的笔，把一个音重复一百遍或是修改一百遍，写好又涂掉，然后第二天重复这一过程，甚至曾经在一页纸上花了6个星期”。

说起音乐，据有人统计，听过匈牙利那首“自杀圣曲”《忧郁的星期天》后赴死的人加起来已经将近200人了。“尽可把他消灭掉，可就是打不败他”，写出《老人与海》中这样经典句子的海明威，在1961年端起双筒猎枪伸进口中，一枪炸破了头颅盖。那么热爱女人和冒险的作家，晚年无法摆脱抑郁，在书桌前面对手稿一坐数小时，不能完成任何事情。他的父亲、妹妹、弟弟、孙女等7名家族成员先后自杀身亡，美国公众将其命名为“海明威魔咒”，这种普遍的抑郁很可能与家族遗传有关。

还有学者将抑郁症当作文化课题研究。福柯在《疯癫与文明》中提到忧郁症与殖民主义有关系，是殖民统治者统治阴谋的一部分。

那么如何摆脱抑郁呢？虽然抑郁而自杀的比例很高，但是历史上也有人终身勉力像踩高跷一样维持着平衡，最终渡尽劫波。丘吉尔说“心中的抑郁就像只黑狗，一有机会就咬住我不放”，不过他也活到了91岁高寿。还有人在痛苦中找到奇特的慰藉，比如哲学家克尔凯郭尔，他的抑郁症或与遗传有关，曾陷入不可克服的忧郁，认定自己无法享受家庭的幸福而与深爱的女子解除婚约，终生未娶。克尔凯郭尔认为快乐会令他衰弱，他写道“我的悲伤是我的城堡，在我最忧郁的时候，我爱生命，因为我爱忧郁”。苏联作家左琴科以讽刺和幽默小说闻名，1926年他的写作生涯正处于顶峰，选集总销量达到495万本，但是他说“在我的书中有笑，在我的心中却没有”。他在年轻时靠吃药来治疗忧郁症，“两年内吞下了半吨重的药丸”，但收效甚微。“一定发生过什么事，才使我这么忧郁”，左琴科开始用弗洛伊德和巴甫洛夫的理论分析自我，回忆童年，据他说用这种方法治好了自己。

另一种摆脱忧郁的方法就像历史学家托马斯·卡莱尔所说：“劳动吧！不要绝望！”。严重的抑郁症使达尔文“三天内就有一天什么都做不了”，他对自己的这种精神上的虚弱深感失望，曾写道：“适者生存，或许我应该满足于看着其他人在科学研究方面大步前进”。很显然，著作等身的他绝非一事无成。他在信件中无数次提到工作的救赎作用，将其称之为“唯一一件使我还能够忍受生活的事情”。叔本华也赞同这一点，工作可以转移人对与生俱来的忧郁的注意力。“如果世界是个华美又舒适的天堂，人类就会无聊至死或自杀”。弗洛伊德甚至认为轻度的抑郁最适宜工作，能让人多产，专注地致力于某一项事业。

英国散文家德·昆西用鸦片来麻痹抑郁的痛苦；拜伦先是用鸦片，后来偏爱酒精；剧作家奥尼尔则在每次随剧本完成而到来的抑郁期间喝得醉醺醺。美国总统林肯曾服用一种19世纪常见的药物“蓝块”来治疗抑郁，因其中含有大量水银而导致神经兮兮、暴躁易怒，意识到这点后，他在1861年总统就职典礼前毅然停用，内战期间以超强的自制力顶住了巨大压力。

在20世纪早期，对抑郁症的唯一药物治疗是鸦片与安他非命，但容易让人成瘾。电击等“疗法”也被采用，但往往导致的结果是病人身体受损乃至失忆，“治愈”的可能性极低。据现代生物学家研究，抑郁症是由于大脑中缺乏一种或多种神经递质所致。抑郁症药物的开发都集中于增加神经递质的浓度或活性。第一个专业的抗抑郁症药物异烟肼诞生于1952年，一群肺结核病人试服刚合成的异烟肼药物治疗肺病，却发现令他们莫名地狂喜起来，于是歪打正着被用在抑郁症上，后来因出现肝损害等众多副作用而被停用。最著名的“百忧解”于1988年问世，它是第一个被美国食品和药物管理局FDA批准的抗郁剂。此后的左洛复、赛乐特、喜普妙、来普适等类似药物相继问世，逐渐被人们所接受。

进入现代社会，生活节奏加快，人际关系复杂，物质追求至上等等，都让压力和焦虑无处遁形，难以排遣的抑郁已成为这个时代突出的一种精神症候。积极心理学之父马丁·塞利格曼对于这个时代的抑郁症曾下过一个诊断，“自我的失常”。他认为当今个人主义猖獗，人们把自己看作世界的中心，面临失败只会变得更加沮丧。

关于抑郁症的成因，生物学家和心理学家其实一直争论不休，如今抑郁症受到基因和外部环境共同影响的理论得到了确认，不过这并不能确认哪个因素的作用更大。至今，也有种种的相关问题还没有定论。

据统计全世界有3.22亿抑郁症患者，患病率高达4.4%，仅在中国便可能有9,000万抑郁症患者，患病率在3%到5%之间，部分地区甚至高达6.1%。虽然人们已经史无前例的拥有了多种抗击抑郁症的武器，但是抑郁症的防治和识别率极低，在中国地级市以上的医院抑郁症的识别率只有20%，不到10%接受过药物的治疗。有研究者建议，抑郁症需要进行预防性的治疗，发作3次以上就必须进行长期治疗，甚至终身服药。

**总结：**

本文回顾了抑郁症的历史发展，从古代的体液理论到现代的精神分析和精神生物学，人们对抑郁症的认知不断深入。文章还列举了历史上众多受抑郁症困扰的名人，探讨了抑郁症对个人和社会的影响。最后，文章强调了抑郁症防治的重要性，呼吁社会消除对抑郁症的偏见，给予患者更多的同情和帮助。

我希望的是每个人都能够正确的认识抑郁症，积极的预防治疗，而整个社会呢，可以消除对抑郁症的偏见，给予患者更多的同情和帮助。

感谢大家的观看，我们下期再见。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>115. [2023-07-04] 【人物】以太网之父 | 罗伯特·梅兰克顿·梅特卡夫 | Robert Melancton Metcalfe</summary><br>

<a href="https://www.youtube.com/watch?v=KB_ksi5LOec" target="_blank">
    <img src="https://img.youtube.com/vi/KB_ksi5LOec/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】以太网之父 | 罗伯特·梅兰克顿·梅特卡夫 | Robert Melancton Metcalfe

好的，我將把這份文稿整理如下，使其更易於閱讀和理解：

**標題：以太網路之父：羅伯特·梅特卡夫的故事**

**引言：**

*   大家好，這裡是最佳拍檔，我是大飛。
*   網路已成為我們生活中不可或缺的一部分。
*   今天我們來講講以太網路之父的故事。

**羅伯特·梅特卡夫的早年生活：**

*   1946年4月7日，二戰結束後，梅特卡夫出生於美國紐約布魯克林區的一個普通家庭。
*   父親是陀螺儀工廠的技術員，母親是家庭主婦。
*   父母對他寄予厚望，希望他成為頂尖的工程師。
*   梅特卡夫在學習上表現出極高的天賦。
*   1964年高中畢業，考入麻省理工學院（MIT）。
*   父母沒想到，他後來不僅成為頂尖工程師，還創立了世界500強企業。

**求學與參與ARPANET項目：**

*   1969年，23歲的梅特卡夫從MIT畢業，獲得電機工程和工商管理雙學位。
*   一年後，他拿到哈佛大學的電腦科學碩士學位，並繼續攻讀博士學位。
*   在攻讀博士學位期間，他在MIT的MAC項目組工作，研究作業系統、計算理論和人工智慧。
*   1969年，美國國防部推動建設的ARPANET正式誕生，將四所名校的大型計算機互聯，這是網際網路的前身。
*   梅特卡夫極力建議哈佛大學和MIT將校內的大型計算機系統也接入ARPANET。MIT同意了，但哈佛拒絕。
*   梅特卡夫完成了網路介面的搭建，將MIT的大型計算機連接到了ARPANET上。
*   他根據這個設計寫了一篇博士論文。

**博士論文答辯失敗與加入施樂PARC實驗室：**

*   1972年6月，梅特卡夫的博士論文答辯失敗，學位委員會認為他的論文缺乏數學性和理論性。
*   在參與ARPANET專案時，AT&T的官員參觀ARPANET演示，結果系統崩潰，他們嘲笑分組交換的不可靠。
*   梅特卡夫收到施樂公司帕洛阿爾托研究中心（PARC）實驗室主任鮑勃·泰勒的邀請，加入實驗室完成論文。
*   鮑勃·泰勒也是阿帕網的主要發起人之一。
*   PARC實驗室誕生了很多偉大的發明，包括雷射印表機、滑鼠、圖形化使用者介面、位圖圖形等。

**在PARC實驗室發明以太網路：**

*   PARC實驗室當時想設計出世界上第一台個人電腦Alto。
*   梅特卡夫的任務是為Alto設計一個網路介面，讓它們互相連接。
*   建設多用戶終端計算機網路的最大問題是如何協調各計算機主機對網路的訪問佔用。
*   梅特卡夫受到夏威夷大學ALOHAnet的啟發，對其模型進行了改進。
*   ALOHAnet採用了一種比ARPANET更激進的方案，以微小資料包的形式傳輸，並沒有試圖避免資料包之間的衝突，而是讓因衝突而導致訊息遺失的使用者在隨機的時間間隔後重新嘗試發包。
*   ALOHAnet的缺點是浪費資源，在網路擁擠時，衝突會變得非常頻繁，傳輸效率也會大幅下降。
*   梅特卡夫提出一種新的模型，讓計算機主機會基於衝突的頻率獨立調整傳輸重試的等待時間，從而保持網路的整體通信效率。
*   1973年5月，他終於通過了哈佛大學的答辯，獲得了博士學位。
*   哈佛大學沒有發布他的論文，而是麻省理工學院發布的。
*   1973年5月22日，梅特卡夫分發了一份名為Alto Ethernet的備忘錄，正式提出了以太網路的設想。
*   梅特卡夫的以太網路設想結合了諾曼·艾布拉姆森的隨機重發機制以及自己對系統時鐘的調整和ALOHAnet模型的其他改進，來減輕了衝突的影響。
*   梅特卡夫是第一個將這些理論集成到實際網路設計中的人。
*   以太網路這個名稱來自於當時認為無所不在的傳輸媒介「以太」。
*   梅特卡夫被稱為「以太爸爸（Ether Daddy）」。
*   1973年6月，梅特卡夫獲准建造一個100個節點的原型以太網路。
*   1973年11月11日，世界第一個以太網路原型系統正式誕生，傳輸速率達到每秒2.94兆位元。

**創辦3Com公司與推廣以太網路：**

*   梅特卡夫建議施樂公司商業化以太網路技術，但施樂公司反應遲緩。
*   1979年，梅特卡夫離開PARC實驗室，創辦了3Com公司，推動以太網路技術的普及。
*   3Com的名稱來自三個字母：Computer（計算機）、Communication（通信）、Compatibility（兼容性）。
*   3Com通過銷售網路軟體、以太網路收發器以及用於小型計算機和工作站的以太網路卡，大大提高了以太網路的商業可行性。
*   1980年，梅特卡夫促成數字設備公司（DEC）、英特爾和施樂公司組成技術聯盟，推出了以三個公司字母開頭命名的DIX以太網路標準。
*   1983年，IEEE成立工作組，基於DIX標準的變體推出了IEEE 802.3標準。
*   當時IBM的令牌環技術和以太網路形成了激烈的競爭。
*   最終，以太網路勝出，令牌環被淘汰。
*   1984年3月21日，3Com公司成功上市。

**梅特卡夫定律與離開3Com：**

*   80年代中期，梅特卡夫提出了梅特卡夫定律，即一個網路的價值和這個網路節點數的平方成正比。
*   1990年，梅特卡夫離開3Com公司，成為評論家和技術專欄作家。

**預測失誤與轉型風險投資家：**

*   1995年，梅特卡夫認為互聯網將在次年遭遇災難性的崩潰。他表示如果自己預測錯了，就把自己的話吃掉。
*   1997年，他在第六屆國際萬維網會議上吃掉了搅拌后的浆状物，承認自己的錯誤。
*   他的其他預測錯誤包括：Linux將被Windows 2000幹掉、無線網路將在20世紀90年代中期被拋棄等。
*   2001年，梅特卡夫離開媒體領域，創辦北極星風險投資公司，轉型為風險資本家。

**重返學術界與3Com的沒落：**

*   2011年，梅特卡夫前往德克薩斯大學奧斯汀分校擔任教授。
*   2022年，他時隔50多年後再次回到麻省理工學院的CSAIL（原MAC）成為一名研究員。
*   1999年，3Com的收入達到57億美元的峰值，但很快互聯網泡沫破碎，市值大幅縮水。
*   2009年11月，3Com公司被惠普以27億美元的現金收購，退出了歷史舞台。

**晚年榮譽：**

*   梅特卡夫因為在以太網路方面的重大貢獻獲獎無數。
*   1996年，他被授予了IEEE荣誉勋章。
*   2003年，他收到了国家技术奖章和马可尼奖。
*   2007年，他入选了美国国家发明家名人堂。
*   2023年3月22日，梅特卡夫被ACM授予2022年圖靈獎。

**結論：**

*   杰夫·迪恩表示，今天全球約有70億個網路連接埠，以太網路無處不在。
*   以太網路是人們資料通訊網路的基石。
*   作為以太網路之父，梅特卡夫的貢獻是極為巨大的。
*   如今以太網路仍然是全球有線網路通信的主要標準。
*   它的處理速率從2.94Mbps、10Mbps一路升級到了現代的400Gbps、800Gbps，甚至是1.6Tbps。
*   802.3這個令人熟悉的數字將長期的伴隨著我們，直到他被取代的那一天。

**結尾：**

*   好了，今天的分享就到這裡。
*   感謝大家的觀看，我們下期再見。

**整理說明：**

*   **分段與標題：** 我將文稿分成多個段落，並添加了標題，使其結構更清晰。
*   **重點提取：** 我將每個段落的重點提取出來，使其更易於理解。
*   **簡化語言：** 我在不改變原意的基礎上，簡化了一些語言，使其更易於閱讀。
*   **補充說明：** 對於一些專業術語和歷史背景，我進行了適當的補充說明，使其更易於理解。
*   **條列式整理:** 對於羅伯特梅特卡夫的一生，我將重大事件用條列式整理，更容易理解。

希望這個整理對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>114. [2023-07-03] 【科技】2023年十大新兴技术报告 | 夏季达沃斯论坛 | Top 10 Emerging Technologies of 2023</summary><br>

<a href="https://www.youtube.com/watch?v=AeN8dooRShw" target="_blank">
    <img src="https://img.youtube.com/vi/AeN8dooRShw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【科技】2023年十大新兴技术报告 | 夏季达沃斯论坛 | Top 10 Emerging Technologies of 2023

好的，以下是整理后的文稿，更注重清晰度、重点突出和信息结构：

**主题：2023年达沃斯论坛《十大新兴技术》报告解读**

**开场白：**

*   大家好，这里是最佳拍档，我是大飞。
*   上周休假去了海边，晒黑了，更新不及时，非常抱歉。
*   现在休假回来了，要继续努力更新视频。

**报告背景：**

*   上周的夏季达沃斯论坛上，主办方公布了《2023年十大新兴技术》报告。
*   世界经济论坛执行董事杰里米·尤尔根斯介绍，报告旨在帮助各行业专业人士预测指数级发展的技术及其影响。
*   报告所有图片由Midjourney生成，并附带提示语。

**十大新兴技术（概要）：**

1.  **柔性电池：** 满足可穿戴设备、柔性电子等需求，轻便、可弯曲，市场预计快速扩张。
    *   **驱动因素：** 可穿戴设备需求增加，电子产品微型化/柔性化。
    *   **主要厂商：** LG化学、三星SDI、苹果、诺基亚等。
2.  **生成式人工智能 (AIGC)：** 通过学习数据模式创造新内容，应用于文本、代码、图像、声音等领域，甚至药物设计、建筑工程等。
    *   **发展方向：** 自主AI系统，例如Autogpt。
    *   **重点：** 确保应用符合专业和道德标准，建立公众信任。
3.  **可持续航空燃料 (SAF)：** 替代传统航空燃料，减少航空业碳排放。
    *   **目标：** 2050年实现航空业净零碳排放。
    *   **进展：** SAF产量增加，航空公司承诺使用，ASTM批准多种SAF混合燃料。
    *   **案例：** 英国将首次完全用SAF飞越大西洋。
4.  **工程噬菌体：** 通过基因工程重新编程噬菌体，靶向感染特定细菌，用于治疗微生物组相关疾病。
    *   **应用案例：** 溶血性尿毒症 (HUS) 的治疗。
    *   **现状：** 临床试验进行中，有望改善人类、动物和植物健康。
5.  **改善心理健康的元宇宙：** 利用虚拟共享空间和游戏平台进行心理健康治疗，提高患者参与度，消除偏见。
    *   **应用案例：** 深井疗法公司创建治疗抑郁症和焦虑症的视频游戏。
    *   **个人观点：** 对治疗过程和效果持怀疑态度，缺乏理论根据和临床实验证明。
6.  **植物传感器：** 安装在农作物上，持续监测温度、湿度、营养水平，优化产量，减少浪费，检测疾病。
    *   **应用案例：** Growvera和Phytech开发微型针状传感器。
    *   **意义：** 彻底改变农作物生产和管理，为养活全球人口做出贡献。
7.  **空间组学：** 结合成像和DNA测序技术，在分子水平绘制生物过程的内容、时间和地点。
    *   **应用：** 绘制新一代分子水平的细胞图谱，应用于制药和生物技术领域。
8.  **柔性神经电子学：** 开发生物相容材料的柔性脑机接口电路，适应大脑，减少瘢痕，提高信号准确性。
    *   **优势：** 可装载更多传感器，刺激更多脑细胞。
    *   **应用：** 神经科学研究，神经假肢控制。
    *   **现状：** FDA批准临床实验。
9.  **可持续计算：** 通过液冷系统、AI优化等技术，降低数据中心能耗，建设零能耗数据中心。
    *   **应用案例：** DeepMind帮助谷歌数据中心降低能耗。
    *   **个人观点：** 并非新鲜事，成本是主要考虑因素。
10. **人工智能辅助医疗：** 将AI和机器学习应用于医疗领域，预测和应对大流行病。
    *   **应用案例：** 印度政府采用AI增强医疗服务。
    *   **个人观点：** 效果有限，印度案例不具代表性。

**总结：**

*   前八项技术具有一定价值。
*   由于跨多个学科，难免有理解不足之处，请大家包涵。
*   建议阅读原文报告。

**结尾：**

*   感谢大家的观看，我们下期再见。

**优化说明：**

*   **精简语言：** 去除口语化表达，更简洁。
*   **结构化信息：** 使用编号、标题、要点等形式组织信息，方便阅读和理解。
*   **突出重点：** 对每项技术进行概要介绍，并提炼关键信息（驱动因素、主要厂商、目标、应用案例等）。
*   **保留个人观点：** 保留了原稿中对某些技术的个人评价。
*   **增加背景信息：** 补充了报告背景和目的。

**建议：**

*   如果想进一步精简，可以删除个人观点，只保留客观信息。
*   如果想更加深入，可以针对每项技术展开详细分析。

希望这个整理后的文稿对您有帮助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>113. [2023-06-27] 【人工智能】AIGC领域最大收购 | 13亿美元 | Databricks 收购 MosaicML | 创业2年仅62人 | 估值翻6倍 | Snowflake 收购 Neeva</summary><br>

<a href="https://www.youtube.com/watch?v=9cFbEYujfqM" target="_blank">
    <img src="https://img.youtube.com/vi/9cFbEYujfqM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AIGC领域最大收购 | 13亿美元 | Databricks 收购 MosaicML | 创业2年仅62人 | 估值翻6倍 | Snowflake 收购 Neeva

好的，我將這段文稿整理如下，使其更具結構性、更易讀：

**主题：Databricks 13 亿美元收购 MosaicML：大语言模型领域的竞争加剧**

**摘要：**

Databricks 以 13 亿美元收购大语言模型初创公司 MosaicML，表明大语言模型的重要性日益提升。MosaicML 是一家 OpenAI 的竞争对手，专注于帮助企业使用自己的数据训练私有大模型。此次收购反映了大型科技公司在生成式 AI 领域的战略转变，从自主研发、战略投资转向兼并收购。

**1. 背景：Databricks 收购 MosaicML**

*   Databricks 宣布以 13 亿美元收购 MosaicML。
*   Databricks 作为一家 Data+AI 公司，希望通过收购 MosaicML 来补足其在大语言模型领域的短板。
*   Databricks 最近一次融资后估值达到 380 亿美元，有足够的资金进行收购。

**2. MosaicML 公司介绍**

*   MosaicML 是一家 OpenAI 的竞争对手，成立于 2021 年，位于旧金山，员工仅 62 人。
*   CEO Naveen Rao 曾创立人工智能公司 Nervana Systems。
*   Nervana Systems 曾推出深度学习底层框架 Neon 和 Nervana Cloud 深度学习云平台，后被英特尔收购。
*   MosaicML 致力于建立一个平台，帮助企业训练和部署大语言模型及相关工具。
*   收购估值较上一轮融资估值跃升 6 倍。

**3. MosaicML 与 OpenAI 的区别**

*   **开源：** MosaicML 的模型是开源的，例如 MPT-7B 开源模型。
*   **商业模式：** MosaicML 专注于帮助企业使用自己的数据训练私有大模型，而非像 OpenAI 那样使用公域数据训练基础大模型后再进行微调。

**4. MosaicML 商业模式的优势**

*   **语料纯净：** 避免基础模型与企业专有数据之间的冲突，适用于需要构建特定领域模型的场景。
*   **安全可控：** 满足企业出于监管或自身原因无法使用公开大模型的需求，尤其是在中国等市场，私有化模型具有潜在市场。

**5. 大语言模型领域的竞争加剧**

*   Databricks CEO 认为两家公司有相同的愿景和客户价值观。
*   收购完成后，MosaicML 团队将加入 Databricks。
*   Databricks 的收购可能提升其估值，但长期成功取决于两家公司的整合和业绩表现。
*   竞争对手 Snowflake 也收购了生成式 AI 公司 Neeva，该公司专注于企业搜索。
*   大型科技公司在生成式 AI 领域的战略正在从自主研发转向兼并收购。

**6. 未来展望**

*   预计下半年将出现更多类似的收购案例。
*   国内也将出现类似的案例。

**关键词：** Databricks, MosaicML, 大语言模型, AI, 收购, 开源, 私有化, Snowflake, Neeva, 生成式AI

**其他修改说明:**

*   去除了口语化的表达，例如"不得不说"、"反正"、"是吧"等，使文稿更正式。
*   整理了信息，使其更具逻辑性和条理性。
*   提取了关键信息，方便快速了解核心内容。
*   加入了关键词，方便检索和分类。

希望这个整理后的版本对您有所帮助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>112. [2023-06-24] 【人生】2023高校毕业演讲 | 叶敬忠  | 罗翔</summary><br>

<a href="https://www.youtube.com/watch?v=CO8YtrtcQDE" target="_blank">
    <img src="https://img.youtube.com/vi/CO8YtrtcQDE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人生】2023高校毕业演讲 | 叶敬忠  | 罗翔

好的，這是我整理後的文稿，更著重於結構和重點呈現：

**最佳拍檔 - 畢業演講分享**

*   **主持人：** 大飛
*   **主題：** 分享兩個畢業演講，希望能啟發畢業生。
*   **演講者：**
    *   葉敬忠院長：中國農業大學人文與發展學院 2023 年畢業典禮講話
    *   羅翔老師：中國政法大學 2023 屆畢業晚會即興致辭

**一、 葉敬忠院長演講：《在權力的包圍中不要熄滅真善美的光》**

*   **核心觀點：** 在權力無處不在的社會中，保持清醒、堅守底線，不迷失自我。
*   **對畢業生的叮囑：**
    *   保持底線
    *   回歸常識
    *   真實做人
    *   高雅做事
    *   把人當人
    *   記住創傷
    *   在權力的包圍中保持清醒
*   **對權力的警惕：**
    *   權力會讓人變得 "精致" 圓滑、傲慢任性、機械刻板，進而迷失自我。
    *   權力可能製造出無所不能的幻象，導致脫離實際，忘記背後的人和工作的意義。
*   **對真善美的期許：**
    *   希望學生保持簡單、真實、乾淨，在複雜的社會裡守住純真。
    *   不要因為權力的吸引力而變得 "精致" 圓滑，不要因為權力的支配力而變得傲慢任性，也不要因為權力的規訓力而變得麻木迷茫。
    *   即使面對高牆，也要保留真善美的靈魂，並保持自由奔跑的勇氣。
*   **學院的理想：**
    *   不讓虛假蒙蔽真實
    *   不讓邪惡取代善良
    *   不讓醜陋壓制美好

**二、 羅翔老師即興演講：《不容然後見君子》**

*   **核心觀點：** 人生充滿苦難和邪惡，重要的是在記憶中儲存足夠的美好，堅守內心的原則。
*   **對人生的看法：**
    *   人生有三件事無法避免：苦難、邪惡、人生的終點。
    *   要儲存足夠多美好的記憶去對抗苦楚，儲存足夠多的美善與邪惡對抗，用更多的美好從容走向人生的終點。
    *   這個世界有很多 "成功人士" 並不值得信任，真正能夠帶給我們寧靜的是我們內心的原則。
*   **孔子絕糧於陳蔡的故事：**
    *   無論在什麼情境下都應該臨危不懼、泰然若處。
    *   君子和小人的區別在於，小人會隨時改變原則，但君子會固守他的原則。
    *   "不容然後見君子"：如果世界接受不了我們的理想，那不是我們的問題，是世界的問題。
*   **對畢業生的祝福：**
    *   希望學生能夠找到內心的寧靜，一生平安。

**總結：**

兩個演講都強調了在複雜的社會中保持自我、堅守價值觀的重要性。葉敬忠院長側重於在權力環境中保持清醒，而羅翔老師則著重於面對人生的苦難和邪惡，堅守內心的原則，追求內心的寧靜。

**備註：** 整理時，我盡量保留了原文的語言風格，同時將內容結構化，方便理解和記憶。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>111. 【读书】《为什么伟大不能被计划》| 什么是”新奇性搜索“ | 为什么目标会误导我们</summary><br>

<a href="https://www.youtube.com/watch?v=QFfBgYg-1a4" target="_blank">
    <img src="https://img.youtube.com/vi/QFfBgYg-1a4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【读书】《为什么伟大不能被计划》| 什么是”新奇性搜索“ | 为什么目标会误导我们



---

</details>

<details>
<summary>110. 【人物】硅谷千亿大佬要约架？| 八角笼中格斗 | 埃隆马斯克 | 马克扎克伯格 | 打嘴炮还是动真格？</summary><br>

<a href="https://www.youtube.com/watch?v=i0TkYxv21v4" target="_blank">
    <img src="https://img.youtube.com/vi/i0TkYxv21v4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】硅谷千亿大佬要约架？| 八角笼中格斗 | 埃隆马斯克 | 马克扎克伯格 | 打嘴炮还是动真格？



---

</details>

<details>
<summary>109. 【人生】当代年轻人的地狱开局 | 形成如今局面的原因 | 如何破解就业困局 | 发现自己的天赋和擅长 | 拒绝内卷和躺平</summary><br>

<a href="https://www.youtube.com/watch?v=TSLAgFYFjaA" target="_blank">
    <img src="https://img.youtube.com/vi/TSLAgFYFjaA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人生】当代年轻人的地狱开局 | 形成如今局面的原因 | 如何破解就业困局 | 发现自己的天赋和擅长 | 拒绝内卷和躺平



---

</details>

<details>
<summary>108. 【AIGC】AI生成视频攻破“闪烁”难题 | 画面更一致生动 | 零样本视频翻译 | 南洋理工大学最新发表论文</summary><br>

<a href="https://www.youtube.com/watch?v=X8dy7uuD86Q" target="_blank">
    <img src="https://img.youtube.com/vi/X8dy7uuD86Q/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】AI生成视频攻破“闪烁”难题 | 画面更一致生动 | 零样本视频翻译 | 南洋理工大学最新发表论文



---

</details>

<details>
<summary>107. How to install and use Amazon AWS CodeWhisperer</summary><br>

<a href="https://www.youtube.com/watch?v=hsLnqmCT5E0" target="_blank">
    <img src="https://img.youtube.com/vi/hsLnqmCT5E0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# How to install and use Amazon AWS CodeWhisperer



---

</details>

<details>
<summary>106. 【编程开发】2023年最流行和最赚钱的编程语言是什么 |  StackOverflow超过9万名开发者调查报告 | MySQL数据库只能屈居第二 | 新增AI深入调查</summary><br>

<a href="https://www.youtube.com/watch?v=T96d8iNsDUQ" target="_blank">
    <img src="https://img.youtube.com/vi/T96d8iNsDUQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【编程开发】2023年最流行和最赚钱的编程语言是什么 |  StackOverflow超过9万名开发者调查报告 | MySQL数据库只能屈居第二 | 新增AI深入调查



---

</details>

<details>
<summary>105. 【商业】Stability AI创始人Emad Mostaque被曝丑闻 | 剽窃代码 | 学历造假 | 拖欠工资 | 夸大收入</summary><br>

<a href="https://www.youtube.com/watch?v=VOjlOrq1Oh4" target="_blank">
    <img src="https://img.youtube.com/vi/VOjlOrq1Oh4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】Stability AI创始人Emad Mostaque被曝丑闻 | 剽窃代码 | 学历造假 | 拖欠工资 | 夸大收入



---

</details>

<details>
<summary>104. 【OpenAI】ChatGPT的GPT-4、GPT-3.5系列模型重大更新 | 新增函数调用功能 | API价格大幅降低 | API弃用时间表 | LangChain岌岌可危？</summary><br>

<a href="https://www.youtube.com/watch?v=jgHhhjIE_3c" target="_blank">
    <img src="https://img.youtube.com/vi/jgHhhjIE_3c/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】ChatGPT的GPT-4、GPT-3.5系列模型重大更新 | 新增函数调用功能 | API价格大幅降低 | API弃用时间表 | LangChain岌岌可危？



---

</details>

<details>
<summary>103. 【人工智能】OmniMotion | 跟踪视频中的一切物体 | 即使遮挡也可跟踪 | quasi-3D规范体积视频表征 | 康奈尔大学、谷歌研究院和UC伯克利共同研究</summary><br>

<a href="https://www.youtube.com/watch?v=_Zj2jmsEoXA" target="_blank">
    <img src="https://img.youtube.com/vi/_Zj2jmsEoXA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OmniMotion | 跟踪视频中的一切物体 | 即使遮挡也可跟踪 | quasi-3D规范体积视频表征 | 康奈尔大学、谷歌研究院和UC伯克利共同研究



---

</details>

<details>
<summary>102. 【人工智能】Transformer论文《Attention Is All You Need》发表六周年回顾 | 八名作者如今都在干什么 | 多人创立独角兽公司</summary><br>

<a href="https://www.youtube.com/watch?v=a0T8SmHR9Ik" target="_blank">
    <img src="https://img.youtube.com/vi/a0T8SmHR9Ik/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Transformer论文《Attention Is All You Need》发表六周年回顾 | 八名作者如今都在干什么 | 多人创立独角兽公司



---

</details>

<details>
<summary>101. 【BAAI】对2023北京智源大会的一个总结</summary><br>

<a href="https://www.youtube.com/watch?v=ueGR7Dhqeqc" target="_blank">
    <img src="https://img.youtube.com/vi/ueGR7Dhqeqc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【BAAI】对2023北京智源大会的一个总结



---

</details>

