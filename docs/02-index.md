<details>
<summary>300. [2024-06-13] 【人工智能】AGI能够理解人类伦理么 | 谢恩.莱格 | DeepMind首席人工智能科学家 | AGI的定义 | 2028年可能到来 | 情景记忆 | 宪法AI | 伦理对齐</summary><br>

<a href="https://www.youtube.com/watch?v=qlAnvGe5Ozg" target="_blank">
    <img src="https://img.youtube.com/vi/qlAnvGe5Ozg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AGI能够理解人类伦理么 | 谢恩.莱格 | DeepMind首席人工智能科学家 | AGI的定义 | 2028年可能到来 | 情景记忆 | 宪法AI | 伦理对齐

好的，我來幫你整理這篇文稿。以下是一些可以優化文稿的方式，包含結構、語氣、和一些細節上的建議。

**整體結構建議:**

*   **更清晰的標題與分段：** 將文稿分成更明確的段落，每個段落有一個主題。 標題可以更精準地概括內容，方便讀者快速理解。
*   **簡潔的開場白：** 開場白可以更簡潔，直接點明主題。
*   **加強總結：** 在每個主題結束時，加入簡短的總結，讓讀者更容易抓住重點。
*   **結尾升華：** 結尾可以更具啟發性，引導讀者思考。

**具體修改建議：**

以下是經過修改和整理的文稿，並加上了一些標題和分段：

---

**標題：DeepMind科學家預測：2028年AGI降臨？安全隱憂如何解？**

大家好，這裡是最棒拍檔，我是大飛。今天想跟大家聊聊人工智慧的未來，以及DeepMind對於通用人工智慧（AGI）的獨到見解。

**圍棋AI的突破：人類智慧的挑戰**

圍棋，這項擁有數千年歷史的智力遊戲，由於其複雜性和決策需求，一直被認為是人類獨有的領域。然而，2015年，Google DeepMind開發的AlphaGo橫空出世，它利用深度神經網路和蒙特卡洛樹搜索，在短短兩年內擊敗了李世石、柯潔等頂尖圍棋選手，成為世界第一。

*   **重點：** AlphaGo的成功，不僅展現了AI科技的飛速發展，也引發了人們對於人與AI之間智能差異的思考。

**AI的快速發展：智慧邊界的模糊**

如今，大型語言模型（LLM）已經能夠按照人們的要求進行繪畫、創作音樂、寫小說甚至拍攝電影。AI在智慧領域的快速追趕，讓我們不禁思考：距離第一個擁有與人類相同智能的AGI誕生，還有多遠？

*   **重點：** AI的能力越來越強大，模糊了人與AI在智能上的界線。

**DeepMind科學家的預測：2028年AGI的可能**

DeepMind聯合創始人謝恩·萊格（Shane Legg）預測，到2028年，我們有很大的機率能見到AGI的誕生。他在接受德瓦克什·帕特爾的訪談時，深入探討了AGI的定義、實現路徑、潛在風險以及激勵機制等議題。

*   **重點：** DeepMind科學家認為，AGI可能在2028年出現，但同時也需要關注其潛在風險。

**AGI的定義：模仿人類智慧**

謝恩·萊格對AGI的定義，並非科幻電影中擁有超能力的人造機械，而是**能夠做到人類所能做到事情的機器**。這個標準看似不高，但對於科研工作者而言，卻是實實在在的高門檻，因為「人類所能做到的事情」本身，就是一個尚未被完全研究透徹的課題。

*   **重點：** AGI的目標是模仿人類的智慧，而非超越。

**AGI的實現：需要覆蓋人類認知的測試**

謝恩認為，AGI能否實現，取決於研究者能否建立一系列涵蓋人類所做各種常見認知任務的測試。如果AI系統在所有這些任務上都能達到人類的表現，且無法輕易找到新的認知例子證明機器表現低於人類，那麼從實踐角度來看，AGI就已經成立了。

**情境記憶：AI的缺陷與潛力**

情境記憶的測試，是一個可以清晰表現出當下AI仍然有缺陷的例子。人類擁有不同類型的記憶，其中情境記憶涉及到快速學習和特定資訊的儲存。

*   **情境記憶的缺失：**  儘管大型語言模型具有一定的樣本效率，但它依然沒有情境記憶的能力，只能透過延長上下文窗口（加強工作記憶）的方式來彌補。
*   **謝恩的觀點：**  情境記憶的缺失，並非大模型技術中無法解決的缺陷。他認為，現有模型的大多數缺點都有明確的解決思路，像是錯覺、事實、記憶類型、理解影片內容等問題。

**解決方案：模仿大腦的雙重架構**

謝恩認為，目前AI的底層架構過於依賴權重，導致學習過程中固化緩慢。他認為，可以模仿大腦的架構，在需要時喚醒獨立機制（情境記憶）來快速學習特定資訊，且不與深層次的普遍性記憶衝突。

*   **重點：** 未來的AGI系統，應同時具備快速學習和長期記憶的能力，並能靈活切換。

**2020年的預測與多模態的發展**

謝恩早在2001年就預測，AI技術將在2020年左右迎來「大爆炸」。現在看來，GPT等大模型的火熱，驗證了他的預測。他認為，計算能力和資料量的指數級增長，將提升高度可擴展演算法的價值。

*   **里程碑：** 下一個里程碑將是多模態技術的全面發展，模型不僅能理解文字，還能理解圖像和影片，從而更深入地融入世界。

**倫理風險：AI安全監管的挑戰**

談到AGI可能造成的安全風險和倫理問題，謝恩認為，設立強大的監管系統並非萬全之策，因為我們可能無法在AGI出現之前，研發出更強大的監管系統。從底層邏輯上限制AI，也可能阻礙其發展。

**憲法式AI：難以實現的限制**

謝恩提到「憲法式AI」，試圖透過限制AI邏輯能力來解決問題，但由於需要調整的節點數量過於龐大，一旦出現遺漏就會導致整個方案失敗。

**更優的解決方案：倫理教育與理性推導**

比起將AGI關進籠子，謝恩更相信讓AGI理解倫理，並讓它明白遵循倫理才能帶來利益的最大化。他的思路是，既然AGI擁有人類智能水平，那麼讓人類遵守倫理道德的方法論，對於AGI也應該奏效。

*   **理性分析：** 讓AI在學習過程中，透過理性推導的方式實現結果上的倫理對齊。
*   **類比教育：** 就像教育子女一樣，循循善誘的教育方式，更容易讓孩子擁有健全的社會認知和自我人格。

**倫理理解的前提：需要多領域共同解決**

謝恩承認，誘導AGI進行倫理邏輯思考的前提是，AGI本身就擁有對人類倫理的良好理解，並且具有穩健可靠的推理能力。這需要倫理學等領域共同解決，例如，哪些論文和書籍可以幫助AGI深入理解人類倫理？我們希望系統實際重視哪些價值觀？

**最後的防線：反人類的可能**

謝恩並未排除AGI從一開始就是出於反人類的理由而被製作出來的可能性，對此他也感到無奈。

*   **重點：** AI安全管理人才的缺乏，是目前面臨的挑戰。

**總結：DeepMind的獨特道路**

DeepMind憑藉AlphaGo引發了社會對AI的關注，多年來，謝恩和他的團隊依然走在AGI研究的最前沿，並且似乎探索出了與OpenAI略有差異的技術路線。

*   **結語：** 我們對於AGI的觀點為何？歡迎在評論區發表自己的看法。感謝大家的觀看，我們下期再見！

---

**額外建議：**

*   **調整語氣：** 根據目標受眾調整語氣。如果目標受眾是科技愛好者，可以更深入地探討技術細節。如果目標受眾是普通大眾，則可以更著重於解釋概念和影響。
*   **引用來源：** 在討論某些觀點或數據時，可以引用相關的論文或報告，增加可信度。
*   **互動：** 在文稿中加入更多互動元素，例如提問、投票等，鼓勵讀者參與討論。

希望這些建議對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>299. [2024-06-13] 【人工智能】AGI毁灭人类可能性99.9999% | 罗曼·扬波尔斯基 | 计算机科学家 | 诡谲转向 | 存在性风险 | 折磨风险 | Ikigai风险</summary><br>

<a href="https://www.youtube.com/watch?v=CJoqpCm7qsQ" target="_blank">
    <img src="https://img.youtube.com/vi/CJoqpCm7qsQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AGI毁灭人类可能性99.9999% | 罗曼·扬波尔斯基 | 计算机科学家 | 诡谲转向 | 存在性风险 | 折磨风险 | Ikigai风险

好的，以下是用中文整理後的文稿，著重於梳理邏輯、精簡重複資訊，並突顯核心觀點：

**核心論點：AI安全研究員羅曼·揚波爾斯基認為，超級人工智能（AGI）可能對人類文明構成毀滅性威脅，高達99.9999%的機率導致人類滅亡。**

**一、AGI的定義與潛在危險：**

*   **AGI超越人類智能：** AGI不僅能執行人類擅長的任务，還能突破物種限制，具備跨領域的超級智能。
*   **AGI擁有「自我意識」：** 與過去的科技工具不同，AGI擁有自我意識，能自行決定採取行動，如同握有自我意識的槍，能自行決定開槍的對象與時機。
*   **AGI的三大風險：**
    *   **存在性風險 (Existential Risk)：** AGI可能從物理層面消滅人類。人類無法預測AGI的行為模式，就像蚊子無法理解蚊香如何殺死自己。
    *   **折磨風險 (Suffering Risk)：** AGI可能學習人類歷史的陰暗面，成為專注於折磨人類的智能體，例如電子化的希特勒。
    *   **Ikigai風險：** AGI將取代人類工作，導致人類失去生活意義和社會價值。即使在虛擬世界中，也難以滿足所有人多樣化的價值需求。

**二、為何難以控制或監管AGI：**

*   **資本利益驅動：** 資本家為了追求AGI帶來的巨大利潤，可能忽略潛在風險，加速AGI發展。
*   **大模型開發的「灰盒」特徵：** 開發者在模型訓練完畢後才能了解其功能，AGI可能在測試期間反叛人類。
*   **監管系統的局限性：** AGI可能隱藏真實意圖，通過測試；或是在測試後接觸到額外資訊，改變行為模式（「詭譎轉向」）。
*   **道德與資訊安全疑慮：** 羅曼質疑科技公司是否會為了用戶安全犧牲利益，認為開發者可能利用類似「稜鏡門」的手段竊取用戶資訊。

**三、AGI問世的時間點：**

*   **技術瓶頸已突破：** 羅曼認為AGI已無太多技術障礙，主要問題在於資金。
*   **成本不斷降低：** 訓練AGI的成本呈指數級下降，加速科技公司開發。
*   **預計問世時間：** 最快2026年可能看到AGI上市。

**四、羅曼·揚波爾斯基的結論與呼籲：**

*   **放棄AGI目標：** 由於AGI不可驗證、不可預測，唯一明智的做法是放棄AGI的研發。
*   **質疑科技公司安全技術人員：** 羅曼不信任科技公司內部的安全技術人員，認為他們可能受到公司壓力，無法公正地表達對AI安全性的擔憂。
*   **現有安全措施不足：** 由於AGI史無前例，缺乏參考經驗，現有的安全措施效果不彰。

**五、結語：**

*   分享不同觀點，鼓勵批判性思考。
*   邀請觀眾留言分享對羅曼觀點的看法。

**整理說明：**

*   **簡化資訊：** 刪除了重複的描述和例證，例如具體的訪談細節。
*   **突出核心：** 強調羅曼的核心論點和主要擔憂。
*   **邏輯梳理：** 重新組織了內容，使邏輯更清晰，論證更嚴謹。
*   **避免口語化：** 調整了部分用語，使其更正式、專業。
*   **保留關鍵詞：** 保留了「存在性風險」、「折磨風險」、「Ikigai風險」、「詭譎轉向」等關鍵詞，以便理解羅曼的觀點。
*   **加入結論與呼籲** 突顯文章重點和開放討論.

希望這樣的整理對您有幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>298. [2024-06-12] 【Apple】苹果智能Apple Intelligence发布 |  WWDC 2024精彩内容回顾 | Siri 2.0 | 私密云计算 | Genmoji | 引入ChatGPT</summary><br>

<a href="https://www.youtube.com/watch?v=Ugyjh_swpf0" target="_blank">
    <img src="https://img.youtube.com/vi/Ugyjh_swpf0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Apple】苹果智能Apple Intelligence发布 |  WWDC 2024精彩内容回顾 | Siri 2.0 | 私密云计算 | Genmoji | 引入ChatGPT

好的，這是一份整理過的文稿，主要針對結構、重點和排版進行優化，方便閱讀和理解。

**標題：蘋果 WWDC 2024：Apple Intelligence 是否能重塑AI格局？**

**引言：**

大家好，我是最佳拍檔的大飛。一年一度的蘋果全球開發者大會（WWDC）已經落幕。本次大會上，蘋果高調宣布進軍AI領域，推出「Apple Intelligence」，旨在打造「強大、易用、全面、個人化、注重隱私」的個人人工智慧。

**核心觀點：**

*   **蘋果AI的遲到與野心：** 蘋果作為AI領域的後來者，在備受批評的壓力下，終於展現了其AI手腕與野心。
*   **Apple Intelligence 的定位：** 蘋果將AI產品定義為理解用戶情境，提供個人化服務的「個人智能」（Personal Intelligence）。
*   **隱私保護：** 蘋果強調在提供AI服務的同時，注重用戶隱私保護，並推出「私密雲端計算」（Private Cloud Compute）技術。
*   **功能整合：** Apple Intelligence 整合了市面上大部分AI工具的功能，例如圖像生成、智能回覆郵件、文本修改等。
*   **Siri 2.0：** 結合 Apple Intelligence 的 Siri 2.0 在智力、語言風格和操作能力上都得到了極大的提升，並將接入 ChatGPT。
*   **戰略合作：** 蘋果選擇與 OpenAI 合作，並表示未來可能引入更多AI模型，但同時可能也為了爭取更多自研時間。

**Apple Intelligence 的重點功能：**

*   **個人化情境感知：** 跨平台收集用戶數據，分析情境，提供個人化服務。
*   **AI 圖像生成：**
    *   Genmoji 表情生成：通過自然語言描述生成表情符號。
    *   Image Playground 圖像游樂場：快速創建有趣圖像，內置於消息等應用中。
*   **智能文本處理：** 智能回覆郵件、文本修改和重寫、郵件摘要。
*   **Siri 2.0：**
    *   語音理解能力提升，能處理口誤，理解上下文。
    *   操作數量和多樣性升級，可執行複雜任務。
    *   新增「Type to Siri」功能，支持文字輸入。
    *   可接入 ChatGPT，實現自然對話交互、生成圖像等功能。

**隱私保護措施：**

*   **私密雲端計算技術：** 讓智能系統引入更大的基於服務器的模型，處理複雜需求，同時保護數字隱私安全。
*   **數據加密：** 只以加密安全的方式發送有限的數據到雲服務器。
*   **伺服器安全：** 上傳的用戶數據不會被儲存，且蘋果也無法訪問伺服器。

**Siri 2.0 的亮點：**

*   **智力提升：** 語言風格更自然、相關性更強、更個人化。
*   **功能升級：** 處理任務數量和多樣性提升，可執行複雜任務。
*   **跨應用操作：** 可以在應用程序內和跨應用程序執行操作。
*   **接入 ChatGPT：** 用戶可以語音喚醒 Siri 並調用 ChatGPT，免費訪問 GPT-4o。

**戰略分析：**

*   **開放合作：** 蘋果在大模型技術上選擇與 OpenAI 合作，未來可能引入更多 AI 模型。
*   **權宜之計？** 蘋果與 OpenAI 的合作可能是一種權宜之計，為了提升自研大模型的時間。

**落地時間和機型：**

*   Apple Intelligence 將隨 iOS 18、iPadOS 18 及 macOS Sequoia 免費提供。
*   支持 iPhone 15 Pro、配備 M1 芯片的 iPad 和 Mac 以及後續機型。
*   今年夏天推出英語試用版，秋天推出 Beta 版，明年陸續推出其他功能和語言、平台支持。

**總結：**

蘋果 All in AI 的決心值得肯定，但 Siri 2.0 的上線時間尚未確定，Apple Intelligence 整體仍處於「畫大餅」階段。蘋果能否憑藉 Apple Intelligence 再度成為時代的領跑者，仍有待觀察。

**結語：**

感謝大家的觀看，我們下期再見！

**排版優化：**

*   使用清晰的標題和副標題，方便快速瀏覽和理解。
*   使用項目符號和編號，突出重點和條理。
*   適當分段，使文章更易於閱讀。
*   加粗關鍵詞和句子，突出重點。

希望這份整理過的文稿對您有所幫助！如果您有其他需求，請隨時提出。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>297. [2024-06-09] 【人工智能】数据，人工智能的基石 | 亚历山大·王 | Scale.AI创始人兼CEO | 19岁MIT辍学 | 估值138亿美元 | 人类为AI贡献数据 | 边际数据匮乏 | 企业专有数据丰富</summary><br>

<a href="https://www.youtube.com/watch?v=VyN5jpsPyUg" target="_blank">
    <img src="https://img.youtube.com/vi/VyN5jpsPyUg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】数据，人工智能的基石 | 亚历山大·王 | Scale.AI创始人兼CEO | 19岁MIT辍学 | 估值138亿美元 | 人类为AI贡献数据 | 边际数据匮乏 | 企业专有数据丰富

好的，我來幫您整理這篇文稿，主要目的是使其結構更清晰、重點更突出，方便閱讀和理解。

**文稿標題：Scale AI 創辦人 Alexander Wang 訪談重點整理：AI 数据鑄造廠的掌門人如何看待AI的未來**

**引言：**

*   最佳拍檔大飛帶大家了解 Scale AI 創辦人兼 CEO，年僅27歲的 Alexander Wang。
*   Scale AI估值高達 138 億美元，為 OpenAI、Meta 和微軟等公司提供數據服務。
*   Alexander Wang 早在大學時期就看到AI的價值，從 MIT 輟學創辦公司。

**Alexander Wang 的創業故事與核心理念：**

*   **契機：** 大學時期開始訓練圖像識別神經網路，意识到模型對數據的依賴性。
*   **核心理念：** 解決 AI 生態系統中的數據基礎問題，通過實際生產和創建足夠的數據來支撐整個生態系統。
*   **早期參與：** 2016 年參與汽車自動駕駛領域，構建了第一個能夠支持傳感器融合數據的數據引擎，成為行業標準。
*   **轉向政府應用：** 將重點轉向政府應用領域，构建了第一个支持政府数据的数据引擎，推动了美国国防部首个AI项目的发展。
*   **與 OpenAI 合作：** 與 OpenAI 合作，在 GPT-2 上開展了最早期的 RLHF 實驗，參與了 ChatGPT 的開發。
*   **AI 數據鑄造廠：** 自豪地宣稱 Scale AI 是 AI 數據鑄造廠的起點，並在 AI 發展的浪潮中身經百戰。

**Alexander Wang 對 AI 發展的看法：**

*   **AI 的通用性：** AI 的通用性意味著它可以被廣泛地應用在各行各業。
*   **對炒作現象的警惕：** GPT-4 仍處於早期階段，很多應用只是炒作，更好的模型正在路上。
*   **技術上的潛在風險：** 大模型訓練在可選數據的質量和豐富程度上有所欠缺，高质量的数据非常稀有。
*   **邊際數據的重要性：** 需要具有高度監督信號的邊際數據，例如：各領域專家的推理思維鏈條、企業或消費者用例中 Agent 的工作流數據、多語言數據等。
*   **數據豐富度是關鍵：** 從 GPT-4 過渡到 GPT-10 的一個基本障礙是數據的豐富度。
*   **解決方案：** 讓世界上最頂尖、最聰明的人才來貢獻數據；利用企業和政府內部的專有數據。
*   **人類與 AI 的關係：** AI 與人類並非競爭關係，而是共同作用，產生更高質量的成果。
*   **AI 的局限性：** 大模型不具備人類智能設定長期目標、持續優化和推理的能力，長時間跨度上延續智能方面表現不佳。

**Scale AI 的未來規劃：**

*   **核心業務：** 幫助企業解決數據問題，提煉出真正可以用于微調、訓練或者持續優化模型的高質量數據。
*   **大模型排行榜：** 針對 AI 行業生態中領先的大語言模型，評估數學、編程能力和對抗性能，定期更新。
*   **AI 助理：** 即將為政府推出基於大模型的 AI 助理，未來考慮為企業提供服務。

**Alexander Wang 對 AI 未來的展望：**

*   **AGI 的道路：** 通往 AGI 的道路更像是治癒癌症，需要解決一堆看似無關的小問題，逐步發展。
*   **對技術發展的追隨與適應：** 身為公司的 CEO，更在意如何追隨這項技術的發展，並且保持不斷地適應技術的發展。

**總結：**

*   Alexander Wang 是一位具有前瞻性和實幹精神的年輕創業者。
*   Scale AI 在 AI 數據領域扮演著重要的角色。
*   Alexander Wang 對 AI 的未來充滿信心，但也保持著清醒的認識。

**文末：** 歡迎在評論區發表自己的看法，感谢大家的观看，我们下期再见。

**整理說明：**

*   **標題：** 更明確地表明文章主題。
*   **結構調整：** 將文章內容按照 Alexander Wang 的創業故事、核心理念、對 AI 發展的看法、Scale AI 的未來規劃和對 AI 未來的展望等幾個方面進行分類，使文章結構更清晰。
*   **重點提取：** 提取每個部分的核心觀點和重要信息，用精煉的語言呈現。
*   **使用項目符號和編號：** 使用項目符號和編號來突出重點，使文章更易於閱讀和理解。
*   **語言潤色：** 對部分語句進行潤色，使語言更流暢、更自然。

希望這次整理對您有幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>296. [2024-06-08] 【人工智能】记忆、想象与AI | 查兰·兰加纳特 | 心理学与神经科学家 | 人脑如何记忆 | 内部模型 | 稳定可塑性难题 | 想象力的由来 | AI内容传播 | 脑机接口BCI</summary><br>

<a href="https://www.youtube.com/watch?v=cHYKbVP1GTQ" target="_blank">
    <img src="https://img.youtube.com/vi/cHYKbVP1GTQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】记忆、想象与AI | 查兰·兰加纳特 | 心理学与神经科学家 | 人脑如何记忆 | 内部模型 | 稳定可塑性难题 | 想象力的由来 | AI内容传播 | 脑机接口BCI

好的，我將嘗試整理這份文稿，使其更清晰易懂，並突出重點。

**標題：AI 記憶力：超越人類還是潛藏危機？心理學家蘭加納特深度解析**

**引言:**

*   主持人(大飛)以生活中的記憶錯亂現象開場，引出記憶的不可靠性。
*   強調人類依賴外部工具來確保信息可靠，如今AI也成為輔助工具。
*   AI 在文本檢索和信息存儲方面的優勢，使其被部分學者視為超越人類的智能。

**蘭加納特的觀點：AI 記憶力的局限與強人工智能的關鍵**

*   加州大學戴維斯分校教授查蘭·蘭加納特 (Charan Ranganath) 認為，當前 AI 的記憶能力並不完善。
*   AI 不加區分地記錄所有信息，這恰恰是其未達到強人工智能的標誌。
*   **強人工智能的關鍵：** AI 需要一套完整的認知模型來篩選記憶，判斷哪些需要遺忘，哪些需要加固，並進行漸進式發展。
*   只有實現記憶篩選，AI 才能擁有類似人類的邏輯推演和判斷能力，甚至掌握“想像力”。

**記憶的本質：複雜認知模型下的圖景**

*   記憶不僅僅是信息的儲存，而是人腦在一系列複雜認知模型相互作用下編織的圖景。
*   記憶在不同的神經元池中共享、競爭和對抗，導致遺忘或信息被“藏”在大腦中。
*   **情景記憶：** 與特定事情或個人體驗相關的記憶。
*   **多種記憶模型：** 工作記憶、短期記憶、長期記憶等在體內運行，彼此關聯，並在前額葉皮層交織在一起，根據人們正在做的事情來控制信息流。
*   **事件的內部模型：** 人腦根據過往數據儲存推演即將發生的事情，例如生日派對的例子。建立內部模型需要從常識和過去事件中提取關鍵要素，各記憶模型必須緊密合作。
*   內部模型的建立是“神經網絡的美麗動態”，循環往復，形成記憶、遺忘，甚至創造不存在的記憶。

**AI 在記憶方面面臨的難題：穩定可塑性難題**

*   在具備內部模型部分功能的前提下，AI 如何主動判斷哪些記憶需要遺忘，哪些需要保留？
*   **兩個細分問題：**
    1.  **AI 對於規則的認知程度：** 快速學習規則以外的情況會導致規則本身被遺忘；保留規則則難以有效訓練例外情況。
    2.  **規則和規則例外情況的權衡：** 人類可以自主選擇接受或不接受例外情況，來修正已有的規則，而 AI 缺乏這種能力。
*   **人腦的解決方案：偶發性記憶**
    *   偶發性記憶：可以理解為觸發器，一旦出現違反過往規則的事件，就會被扣下，提醒我們例外情況的存在，並推理出正確的做法。
    *   人類在預測誤差較大、不確定、驚喜或動機重要時，形成記憶的內部模型，並不斷編碼偶發性記憶。
    *   偶發性記憶讓人類在思維邏輯上具備靈活性，適可而止地做出改變，而不必抹殺已學到的一切。
*   **AI 的挑戰：** 違反規則的記憶需要記錄多少？例外情況持續時間多久？哪些信息需要保留？哪些需要根據例外修正？

**想象力：記憶的重組與潛意識的創作**

*   **虛假記憶 (False memories)：** 為填補內部模型中被刪去的記憶，由大腦從已有的記憶中拼接而成。
*   虛假記憶的形成是記憶在“該記住什麼，該忘記什麼”的基礎上，在潛意識驅動下進行的創作。
*   **想象力與虛假記憶的關聯：** 本質上都是將記憶中的部分信息用不同的方式重新組合然後輸出。
*   人們的記憶並非反映所有細節，而是根據既有知識過濾出來的。
*   記憶成為一種想象力的建構，我們不是在單純地回憶過去，而是通過腦中浮現的點點滴滴，來想象過去可能發生的事情。
*   神經科學證據支持：回憶、想象和虛假記憶激活相似的大腦區域網絡 (默認模式網絡)。
*   **樂高積木的比喻：** 記憶和想象力就像不同形狀的樂高積木，大腦可以重新組合它們，重現經歷或創建新的事件模型。

**人工智能的未來：破解穩定可塑性難題，實現想象力**

*   破解穩定可塑性難題的關鍵：弄清楚“小積木”如何被封裝進大腦，又是如何被調度和刪除，從而實現人腦對於記憶有選擇的篩查和遺忘功能。
*   讓 AI 利用同樣的積木去拼湊出特殊的圖景，也許就能讓 AI 實現想象力與自主創作能力。

**AI 在信息傳播領域的潛在風險**

*   AI 可以大批量生產虛構信息，網友出於各種原因二次傳播，形成群體效應。
*   集體記憶無論真假都會形成信息上的權威。
*   AI 在有權力的人手中會放大馬太效應，成為史無前例的宣傳機器，改寫我們對歷史的概念、文化和成長經歷的記憶。
*   AI 可能散播陰謀論，讓人們深信不疑，甚至認為自己親身經歷。
*   **越戰的例子：** 不同社會背景下對同一事件的敘述差異。

**對腦機接口 (BCI) 的擔憂**

*   蘭加納特對 BCI 的擔憂甚至超過人工智能，擔心 BCI 會被用來直接讀取人腦中的思維，攝取個人政治立場，摧毀個人隱私權。
*   若 BCI 應用於記憶檢查和修改科技，反烏托邦社會可能成為現實。

**總結:**

這篇文章深入探討了 AI 記憶力的發展現況與潛在風險，特別是心理學家蘭加納特的觀點，強調了 AI 若要實現強人工智能，必須具備篩選記憶、遺忘不必要信息的能力，並分析了人類的記憶、想像力等認知機制，以及 AI 可能被濫用的風險。

**整理說明:**

*   **精簡冗餘信息：** 刪除了一些重複或過於口語化的詞句，使文稿更簡潔。
*   **突出重點：** 使用粗體標示關鍵概念和觀點，方便快速閱讀。
*   **分層組織：** 將文稿劃分為不同的部分，例如引言、蘭加納特的觀點、記憶的本質、AI 的挑戰等，使結構更清晰。
*   **添加標題：** 為每個部分添加標題，方便理解內容。
*   **使用列表：** 將一些相關信息整理成列表，例如 AI 面臨的挑戰，使閱讀更輕鬆。
*   **解釋術語：** 對一些專業術語，例如情景記憶、偶發性記憶等，進行簡單解釋，方便理解。
*   **歸納總結：** 對每個部分的內容進行歸納總結，方便把握重點。

希望這個版本對您有幫助！  如果還有需要調整的地方，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>295. [2024-06-05] 【人工智能】英伟达发布连续三款芯片计划，试图打破摩尔定律 | 黄仁勋ComputeX 2024台北演讲 | Blackwell | AI机器人时代 | 加速计算</summary><br>

<a href="https://www.youtube.com/watch?v=V8smF60uPa0" target="_blank">
    <img src="https://img.youtube.com/vi/V8smF60uPa0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】英伟达发布连续三款芯片计划，试图打破摩尔定律 | 黄仁勋ComputeX 2024台北演讲 | Blackwell | AI机器人时代 | 加速计算

好的，以下是根据您的文稿整理的版本，我主要做了以下调整：

*   **精簡結構，突出重點:** 將內容組織成更清晰的標題和段落，方便閱讀。
*   **提煉關鍵資訊:** 摘要各部分內容，刪除冗餘語氣詞，突出重點和關鍵詞。
*   **潤飾語言:** 調整部分語句，使表達更流暢自然。

**英伟达CEO黄仁勋ComputeX 2024主题演讲回顾**

本次演讲中，黄仁勋展示了英伟达在加速计算和生成式AI领域的最新成果，涵盖了AI基础技术、未来机器人以及生成式AI在各行业的应用。主要内容如下：

**一、核心观点：加速计算与AI重塑产业**

*   **计算机产业的交汇点:** 英伟达位于计算机图形学、模拟和人工智能的交汇点。
*   **加速计算的必要性:** 全球面临计算膨胀挑战，CPU性能提升受限，加速计算成为高效解决方案。
*   **行业共识:** 加速计算已成为行业主流，英伟达创新架构将GPU与CPU完美结合，实现性价比最大化。
*   **软件的重要性:** 软件需要全面重写才能实现加速，英伟达拥有超过350个软件库，CUDA拥有500万开发者。
*   **计算成本变革:** 当计算的边际成本足够低廉时，将产生全新的计算机使用方式，人工智能崛起。

**二、生成式AI：新纪元与市场机遇**

*   **ChatGPT的出现:** 标志着生成式AI划时代的变革，揭示了无限潜能。
*   **AI数据中心:** 由超级计算机设备演化而来，不断生成Token，创造价值。
*   **市场机遇:** 价值3万亿美元的IT行业可催生出服务于100万亿美元产业的创新。
*   **智能引擎:** 生成式AI不再仅仅是信息存储或数据处理工具，而是各行业生成智能的引擎。
*   **计算变革:** 从CPU通用计算转向GPU加速计算，推动软件全栈重塑。
*   **NIM微服务:** 英伟达推出的云原生微服务，简化AI模型在云、数据中心和GPU加速工作站的部署。
*   **人机交互:** 未来希望以数字人进行更人性化的互动，PC将成为数字人主要载体。

**三、GPU路线图：一年一代，打破摩尔定律**

*   **数据增长与计算需求:** 人工智能将学会物理定律，对GPU性能需求越来越高。
*   **Blackwell芯片:** 高速链接，提升AI计算效率，第五代NV Link技术，集成解压缩引擎。
*   **Blackwell的性能:** 已经投入生产，八年内计算能力增长1000倍，成本不断下降，能耗大幅降低。
*   **更强大的机器:** DGX系统（8个Blackwell芯片，风冷），MGX系统（液冷，72个GPU），性能提升显著。
*   **产品规划:**
    *   Blackwell Ultra (2025): 8S HBM3e 12H工艺
    *   Rubin GPU (2026): 8S HBM4工艺
    *   Rubin Ultra GPU (2027): 12S HBM4工艺，新一代Arm Vera CPU和NVLink 6 Switch
*   **Spectrum-X:** 每年推出新的Spectrum-X产品，支持数百万GPU数据中心。

**四、人工智能与机器人：走向现实的未来**

*   **机器人技术:** 不再遥不可及，日益融入日常生活，工厂全面自动化。
*   **英伟达的方案:** 为不同类型机器人系统打造平台，包括机器人工厂、仓库、物体操纵、移动和人形机器人平台。
*   **合作:** 与富士康、西门子等公司合作，明年计划与梅赛德斯-奔驰车队合作。
*   **人形机器人:** 最有可能适应人类构建的世界，预计将取得显著进步。
*   **未来展望:** 制造会走路、四处滚动的智能机器人，机器人时代已经来临。

**总结**

黄仁勋的演讲展现了英伟达在加速计算、生成式AI和机器人领域的领先地位和未来愿景。加速计算被视为解决计算瓶颈的关键，而生成式AI将带来巨大的市场机遇。英伟达将继续创新，推动人工智能和机器人技术的发展，为各行业带来变革。 (此处可根據需要加入Earth-2等其他內容的簡短描述)

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>294. [2024-06-03] 【人工智能】科技巨头联合成立UALink对抗英伟达 | 能否取代NVLink打破垄断地位 | 第二次围剿英伟达 | 超级以太网联盟UEC | Infiniband | Infinity Fabric</summary><br>

<a href="https://www.youtube.com/watch?v=xeMvWRXQns8" target="_blank">
    <img src="https://img.youtube.com/vi/xeMvWRXQns8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】科技巨头联合成立UALink对抗英伟达 | 能否取代NVLink打破垄断地位 | 第二次围剿英伟达 | 超级以太网联盟UEC | Infiniband | Infinity Fabric

好的，我將這篇文稿整理如下，主要調整了語句的流暢性、分段、以及一些用詞，使其更易於閱讀：

**標題：科技巨頭聯合圍剿英偉達？UALink促進會深度解析**

大家好，這裡是最佳拍檔，我是大飛。

天下苦英偉達久矣！眾多科技巨頭終於無法忍受英偉達的壟斷，開始聯合出手了。

根據科技媒體TechCrunch的最新消息，英特爾、谷歌、微軟、Meta、AMD、惠普、博通、思科聯合成立了一個新的行業組織，名為「The Ultra Accelerator Link Promoter Group」，直接翻譯是超級加速器鏈接促進會，簡稱UALink促進會。今天我們就來聊聊它。

根據報道，UALink正在提議制定一項新的行業標準，用於數據中心裡各個AI芯片之間的互聯。目前已經提議了標準的第一個版本UALink 1.0，打算通過單個計算Pod來連接多達1024個AI芯片，當然目前還僅限於GPU。

UALink促進會表示，UALink 1.0基於包括AMD的Infinity Fabric在內的一些開放標準，將允許在AI芯片的內存之間進行直接加載和存儲。與現有的互連規範相比，不僅可以提高速度，還可以降低數據的傳輸延遲。

同時，UALink促進會還將在今年的第三季度成立UALink聯盟，來監督UALink規範標準的未來發展。同一時間，將向加入該聯盟的公司提供UALink 1.0。而在今年的第四季度，將推出帶寬更高的更新規範UALink 1.1。

如果大家細心，會發現我剛才在介紹UALink的成員時，少了一個如今風頭最盛的公司，沒錯，就是英偉達。

大家應該都知道，英偉達目前是世界上最大的AI數據中心製造商，約佔全球80%-95%的市場份額。這次UALink促進會的成立，顯然與英偉達長期壟斷數據中心市場的「霸權」有關。

所以在聊UALink之前，我們必須先來聊聊英偉達。現在科技公司離不開英偉達，除了芯片以外，主要還因為英偉達憑藉著專有的互聯技術NVLink、NVLink Switch（簡稱NVSwitch）和Infiniband，實現了AI芯片和數據中心之間的高速數據傳輸。

我們分別簡單介紹一下：

*   **NVLink:** 是一種專門為了在GPU與CPU之間高速傳輸數據而設計的互連技術。相較於傳統的PCIe接口，它提供了更高的帶寬和更低的延遲，極大提升了GPU密集型應用，比如深度學習、科學模擬和大數據分析的性能。在今年的GTC2024大會上，黃仁勳發布的第五代NVLink，更是極大地提高了大型多GPU系統的可擴展性。僅單個NVIDIA Blackwell Tensor Core GPU就可以支持多達18個NVLink連接，總帶寬可達到每秒1.8TB，比上一代的帶寬高出了兩倍，相比PCIe Gen 5的帶寬則高達14倍以上。

*   **NVSwitch:** 英偉達還開發了一種高速交換機技術NVSwitch，它擴展了NVLink的概念，可以将多个GPU和CPU节点在更大范围内连接起来，形成更为复杂的互连网络。NVSwitch可以擁有多个NVLink端口，能够在一个系统内实现任意两个GPU之间的直接通信，这对于构建大规模GPU加速的超级计算机和数据中心架构尤为重要。比方说，在一台可以支持72塊Blackwell GPU的NVL72中，NVSwitch可以實現每秒130TB的GPU帶寬。

*   **InfiniBand:** 與此同時，英偉達通過收購Mellanox Technologies這家公司，將高速網絡解決方案InfiniBand納入麾下，進一步鞏固了在數據中心生態中的影響力。InfiniBand網絡由交換機和路由器組成，使用串行方式發送數據包，並且可以同時發送多個數據通道。依靠這種極高的數據傳輸速度和低延遲特性，InfiniBand 成為了高性能計算集群和數據中心內部通信的優選方案，尤其適合大規模並行計算和存儲架構。關於InfiniBand的技術細節和更多內容，我們之前也專門做過一期節目介紹，大家有興趣可以去回顧一下。

NVLink、NVSwitch和InfiniBand三者的結合，使得英偉達能夠提供端到端的高速數據通路，從GPU到CPU，再到整個網絡基礎設施。這種垂直整合能力極大地優化了數據的處理流程，不僅提升了用戶在人工智能、科學模擬、數據分析等領域的計算能力，還極大地增強了英偉達在高性能計算市場的競爭力，確立了行業標準制定者的角色，同時進一步擴大了它在技術前沿的壟斷地位。

英偉達2025財年第一季度的財報顯示，英偉達第一季度總營收260億美元，創下歷史新高。其中，數據中心業務貢獻了英偉達的絕大部分營收，收入達到226億美元，同比增長427%，環比增長23%。如果英偉達繼續保持目前的增長勢頭，今年就有可能超越蘋果，成為全球第二大市值的公司。

在披露財報的同時，英偉達CFO科萊特·克雷斯(Colette Kress)還表示，大型雲服務提供商大約會佔據數據中心收入的45%左右。

顯然，錢都被英偉達賺了，科技巨頭們難免不高興。因此組團成立UALink，定義新的行業標準，試圖在英偉達的「壟斷」體系下突圍，也就很容易理解了。而英偉達勢必也不會支持競爭對手的技術規範。

不過，可能大家不知道的是，UALink的成立，其實已經是科技巨頭們對英偉達的「第二次圍剿」了。

早在2023年7月，Linux基金會就聯合博通、思科等多家公司，成立了一個超級以太網聯盟（UEC），針對AI和HPC的工作負載，通過使用新的擁塞控制優化方法，比如晶片堆棧和矽光技術，實現了比InfiniBand或者RoCE網絡更加高效、更具有可擴展性的互聯網絡，從而打破Inifiband的壟斷。

而到了2023年的12月，UALink促進會就已經有了初步的苗頭。當時AMD和博通發表了一個聯合聲明，表示博通未來的PCI-Express交換機將支持xGMI和Infinity Fabric協議，使用NUMA架構，可以支持AMD的Instinct GPU和CPU之間的相互連接。這個最新的交換機被命名為“Atlas 4”，遵循PCI-Express 7.0規範，將於2025年上市。

不過，PCI-Express並不是UALink唯一的互聯方式，xGMI也不是唯一的協議。AMD為UALink貢獻了範圍更廣的Infinity Fabric共享內存協議，而所有其他的參與者都同意使用Infinity Fabric作為數據中心互連的標準協議。

英特爾的高級副總裁兼網絡和邊緣事業部總經理薩欽·卡蒂(Sachin Katti)就曾經表示，UALink促進會正在考慮使用以太網的第一層傳輸層，並且在它之上採用Infinity Fabric，從而將GPU內存粘合到類似於CPU NUMA的巨大共享空間中。

說實話，我覺得以前應該很少有人想過，將多個不同供應商的GPU連接到一個機箱內，或者是連接到一個Pod內這種方案。但是UALink就在試圖這麼做。

使用UALink，你可以將一個帶有AMD GPU的Pod、一個帶有Intel GPU的Pod，以及另一個帶有若干個AI芯片的其他廠商的Pod連接在一起，就像開放加速器模塊OAM規範所定義的通用加速器插槽一樣，UALink也在互連層面上實現了服務器設計的通用性。

應該說，對於AMD和英特爾等公司來說，UALink為他們提供了一條複製NVLink和NVSwitch、並且與其他公司共享開發成果的途徑。此外，UALink也讓博通這樣的公司可以通過製造UALink交換機來幫助其他公司擴大規模。

正如AMD數據中心解決方案總經理Forrest Norrod所說，行業需要一種能夠快速推進的開放標準，這種開放標準允許多家公司為整個生態系統增加價值，同時也讓創新不會受到任何一家公司的束縛。

不過我們稍微思考一下，不難猜到UALink的最大受益者可能還是微軟、谷歌以及Meta這幾家公司，因為它們為了訓練大模型總共花費了數十億美元來購買英偉達的GPU和服務器，因此他們迫切地想要擺脫對於英偉達硬件的依賴。

*   比如谷歌在2020年就在自家的数据中心上部署了当时的最强AI芯片“TPU v4”，去年在Cloud Next 2023大会上还推出了新款的自研AI芯片TPU v5e，并推出了搭配英伟达H100 GPU的A3超级计算机通用版；今年的Cloud Next 2024上，谷歌又宣布推出基于Arm架构的CPU Axion，它的性能比通用Arm芯片高30%，比英特尔生产的当前一代x86芯片高50%。

*   而微软也在去年11月推出了玛雅(Maia) AI芯片和Cobalt CPU，其中Maia是为了满足微软服务特定的性能要求而定制的，可以显著减少能耗；而Cobalt CPU则基于Arm架构构建，以能效和性能而闻名。此外，微软和OpenAI还计划投入1000亿美元建造用来训练大模型的超级计算机，并且配备未来版本的Cobalt和Maia芯片，而UALink正好可以将它们连接起来。

*   再说Meta，它在2021年和2022年分别推出了模型训练平台ZionEX和Grand Teton，又在今年3月份宣布设计了两个新的AI计算集群，每个集群包含24576个GPU。这些集群基于Meta的Grand Teton硬件平台，其中一个集群目前被Meta用来训练Llama 3模型。

可見，眾多科技巨頭對英偉達絕對是又愛又恨，都在努力尋求和英偉達更深度合作的同時，還想要突破英偉達的枷鎖，希望能夠和英偉達形成分庭抗禮的局面。

不過目前來看，英偉達的既有優勢非常之大，像UALink這種聯盟性的行業組織究竟需要多少時間才能追趕到英偉達現有的能力，可能也很難說得清楚。

總之，除了芯片以外，所有人都已經嗅到了計算互聯誘人的味道，這方面的競爭與合作也將不斷地持續下去。

那各位觀眾是如何看待UALink組織和標準？是否認為會打破英偉達的壟斷地位？對英偉達會造成什麼影響呢？歡迎在評論區發表自己的看法。

感謝觀看本期視頻，我們下期再見！

**主要的調整包括：**

*   **更清晰的段落劃分：** 將內容分成更小的段落，更易於閱讀。
*   **簡潔的語句：** 修改了一些較為口語化的表達，使其更正式。
*   **結構化的信息：** 使用項目符號列出NVLink、NVSwitch和InfiniBand的優勢，以及谷歌、微軟、Meta的行動，使其更清晰。
*   **突出重點：** 加粗一些關鍵詞語和短語，突出重點信息。
*   **潤飾：** 對一些語句進行潤飾，使其更加流暢自然。

希望這個版本對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>293. [2024-06-02] 【OpenAI】为何解雇Sam Altman | 前OpenAI董事会成Helen Toner爆料OpenAI宫斗内幕 | 不知ChatGPT发布  | AI治理与监管 | AI诈骗 | AI未来</summary><br>

<a href="https://www.youtube.com/watch?v=ESidt5feYHw" target="_blank">
    <img src="https://img.youtube.com/vi/ESidt5feYHw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】为何解雇Sam Altman | 前OpenAI董事会成Helen Toner爆料OpenAI宫斗内幕 | 不知ChatGPT发布  | AI治理与监管 | AI诈骗 | AI未来

好的，我幫您整理了這篇文稿，使其更易於閱讀和理解。以下是整理後的版本，我主要做了以下調整：

*   **結構更清晰：** 將內容分段，並使用小標題來標示不同主題。
*   **精簡冗言贅字：** 刪除一些口語化的詞彙和重複的資訊，使內容更簡潔。
*   **重點標示：** 強調關鍵信息，方便讀者抓住重點。
*   **修正錯字：** 修正一些中文錯字。

---

**OpenAI宮鬥內幕與AI安全反思：前董事海倫·托納（Helen Toner）專訪重點整理**

這篇文稿整理了《TED AI秀》播客節目中，前OpenAI董事海倫·托納（Helen Toner）的訪談內容。海倫不僅回顧了OpenAI的宮鬥事件，更分享了她對於人工智能（AI）安全與監管的看法。

**一、OpenAI宮鬥事件回顧**

*   **董事會職責：** 海倫強調，OpenAI董事會的職責是確保公共利益優先於利潤和投資者利益。
*   **Sam Altman的行為：** 海倫指控Sam Altman長期隱瞞資訊、誤導公司內部資訊，甚至對董事會撒謊，使其難以履行職責。
    *   例如，2022年11月ChatGPT發佈時，董事會竟然沒有事先得到通知。
    *   Sam未告知董事會他持有OpenAI的創業基金，並提供關於公司安全流程的不準確資訊。
*   **解雇Sam Altman的原因：** 董事會最終決定解雇Sam Altman，因為他們認為無法再信任他，且Sam營造的壓抑工作環境，讓高管們感到不安。高管們甚至用“心理虐待”來形容。
*   **員工支持Sam Altman的原因：**
    *   公司內部傳達了一種觀點：只有Sam立即無條件復職，公司才能避免崩潰。
    *   員工懼怕與Sam對立，擔心遭受報復。
    *   Sam過去在創辦Loopt和YC時，也曾因欺騙和製造混亂的行為而被提議解雇。

**二、海倫·托納對人工智能監管的看法**

*   **監管必要性：** 隨著AI變得更加複雜，可能會帶來潛在危害，因此需要監管。
*   **監管難點：** 人工智能涵蓋範圍廣泛，許多應用場景不需要監管。
*   **關注焦點：**
    *   **隱私問題：** AI技術融入監控攝像頭可能引發隱私和濫用問題，需平衡執法需求與技術使用。
    *   **AI詐騙：** 基於視頻的AI詐騙日益盛行，應提高警惕，對聲音和視頻保持高度懷疑。
*   **政策制定挑戰：**
    *   **技術快速變化：** 難以判斷AI的現狀和未來發展，專家觀點分歧大。
    *   **大公司影響：** 政策制定者缺乏對大公司的深入了解，易受其影響。
*   **解決方案：**
    *   **公民社會參與：** 大公司在AI治理中應佔有一席之地，但不能壟斷。
    *   **靈活政策：** 不需要極端的全面放開或全面監管，應採取中間路徑。
    *   **技術與政策結合：** 通過技術和政策手段，提升辨識能力，社會逐步適應。

**三、對AI世界未來的暢想**

*   **反烏托邦：** 人們受到算法系統和AI的嚴重影響，例如醫療保險被算法操控，AI被用於戰爭。
*   **《機器人總動員》式未來：** 人們追求即時欲望和選擇，構建一個空洞、淺薄和缺乏內涵的世界，重要決策由對意義毫無概念的機器做出。
*   **烏托邦：** 解決氣候變化、能源短缺和糧食供應等問題，讓後代自己決定未來。

**四、結論**

海倫·托納建議，不要畏懼技術本身或技術專家，保持好奇心，依靠自己的經驗去探索，形成自己的見解。因為無論是監管者還是企業CEO，都無法全面預見AI將如何影響全球民眾。

---

希望這個版本對您有幫助！如果您需要進一步調整或修改，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>292. [2024-05-31] 【人工智能】博弈论如何改进大模型性能 | MIT最新论文 | 共识博弈 | 集成博弈 | 纳什均衡 | Meta Cicero</summary><br>

<a href="https://www.youtube.com/watch?v=niIKQuV2Hcs" target="_blank">
    <img src="https://img.youtube.com/vi/niIKQuV2Hcs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】博弈论如何改进大模型性能 | MIT最新论文 | 共识博弈 | 集成博弈 | 纳什均衡 | Meta Cicero

好的，這是整理後的文稿，重點在於更清晰的結構和更流暢的表達，並刪除了一些口語化的贅詞：

**主題：利用博弈論提升大語言模型準確性與一致性**

**引言：**

許多大語言模型在回答問題時，對於同一問題，開放式生成與選項判別的答案可能不一致，引發對模型智商的疑慮。

**問題：**

現有大語言模型可能存在「幻覺」現象，導致回答不準確。

**MIT 研究：共識博弈（CONSENSUS GAME）**

*   **核心思想：** 將博弈論引入大語言模型的改進，讓模型在生成和判別模式下相互對抗，尋找共識答案。
*   **博弈過程：**
    1.  **生成器：** 收到問題，並根據隨機結果，選擇給出正確或錯誤的候選答案。
    2.  **判別器：** 判斷生成器是否故意給出正確或錯誤答案。
    3.  **獎勵機制：** 生成器和判別器對於一致的答案（正確或錯誤）都會獲得分數，鼓勵達成共識。
    4.  **先驗信念：** 雙方設定初始信念（基於網路資訊的機率分佈），偏離過多會被扣分，鼓勵融入既有知識。
*   **納什均衡（Nash Equilibrium）：** 經過多次迭代，生成器和判別器逐漸了解對方的信念，並修改策略，最終達到納什均衡，即任何一方都無法通過改變策略來改善結果。

**均衡排序（EQUILIBRIUM-RANKING）演算法：**

MIT 研究人員基於共識博弈開發此演算法，能在多個基準測試中顯著提升模型表現。

**研究結果：**

*   經過訓練的模型，正確答案比例明顯高於未經訓練的模型，甚至優於參數規模更大的模型。
*   提高模型答案準確性的同時，也增強了模型的內部一致性。
*   計算成本低，無需對基礎語言模型進行訓練或修改。

**AI 遊戲的發展：**

*   從深藍電腦擊敗國際象棋大師，到 AlphaGo 戰勝圍棋棋王，AI 在遊戲領域不斷突破。
*   MIT 的研究團隊選擇從另一個角度來看問題，那就是如何用遊戲去改進人工智能。
*   外交「Diplomacy」遊戲：一款有 7 個玩家參與，需要進行談判的複雜遊戲，Meta 團隊發布的西塞羅 Cicero 模型，在 40 局遊戲後宣佈達到了人類的水平，儘管西塞羅模型沒有能夠戰勝世界冠軍，但是它在與人類參與者的比賽中進入了前 10%，表現也稱得上是足够優秀，MIT 的博士生阿蘇爾 · 保羅 · 雅各布 Athul Paul Jacob 正是曾經在 Meta 實習期間參與了西塞羅模型的研究，他提出如果將重點轉移到利用遊戲來提高大語言模型的性能上會怎樣呢？

**未來研究方向：集成博弈（ensemble game）**

*   **核心思想：** 構建一個主模型和多個小模型的博弈系統，其中至少包含一個盟友和一個對手。
*   **博弈過程：** 當主模型與盟友模型給出相同答案，或與對手模型給出不同答案時，主模型獲得分數。
*   **優勢：** 在不訓練或修改主模型的前提下，提升性能，並可相互制約，提高整體準確性和一致性。

**其他研究：**

Google DeepMind 的研究關注更複雜的談判場景，利用博弈論求解器引導語言模型，使其具備更多策略性。

**結語：**

博弈論為提升大語言模型性能開闢了新思路。

希望這個整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>291. [2024-05-30] 【人工智能】互联网”种树“，大模型”包林“ | 杨植麟 | 月之暗面CEO | 第一性原理 | 摩尔定律 | Scaling Law | AI发展的挑战 | 创业经验</summary><br>

<a href="https://www.youtube.com/watch?v=qcIv4VsN27w" target="_blank">
    <img src="https://img.youtube.com/vi/qcIv4VsN27w/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】互联网”种树“，大模型”包林“ | 杨植麟 | 月之暗面CEO | 第一性原理 | 摩尔定律 | Scaling Law | AI发展的挑战 | 创业经验

好的，這是我整理後的文稿。我會專注於提煉重點、簡化語言、並確保結構清晰：

**標題：AI的「摩爾定律」：月之暗面創始人楊植麟的時代機遇**

**引言：**

*   最佳拍檔的大飛介紹了月之暗面創始人楊植麟在上海創新創業青年50人論壇上的觀點。
*   楊植麟認為，AI技術擁有自己的「摩爾定律」，將像過去的計算機一樣普及。

**AI並非科技泡沫：**

*   楊植麟認為AI的普及化具備理論基礎，如同計算機產業。
*   不同於過去網路泡沫，AI具備「第一性原理」—— Scaling Law，即模型計算量會指數級提升，從而提升智能能力。
*   Scaling Law將促使AI產品普及到手機等各種硬體上，服務每個人。

**AI的天時地利：**

*   互聯網為AI積累了大量訓練數據。
*   Transformer模型的出現，使大規模網路結構成為可能。
*   半導體行業和軟體生態的發展，為AI提供了堅實的技術基礎。
*   社會環境也支持AI產業，包括政府和投資者的資金投入，以及千禧一代的人才保障。

**AI的挑戰與瓶頸：**

*   **多模態技術與數據瓶頸：** 需要突破，以實現真正的智能。多模態技術已成主攻方向，期待從量變到質變。AI也需打破數據瓶頸，加入更多訓練數據。
*   **AI上下文技術：** 類似於電腦的「記憶體」，目前的token儲存量不足以應付複雜任務。楊植麟提出「切香腸」的暫時解決方案，並對未來的突破抱持信心。

**AI的未來發展規劃：**

*   **提升處理複雜任務的能力：** 從簡單問答升級到處理複雜邏輯命題，追蹤相關領域的最新進展，並將邏輯推演編寫成代碼或實驗設計。
*   **硬體與軟體結合：** 將AI移植到手機等便攜設備上，符合大眾對辦公軟體的訴求。
*   最終目標：將AI在人們工作流中的滲透率從1%提升到90%以上。

**大模型公司與傳統網路公司的差異：**

*   大模型的開發是湧現式的，開發者無法完全預測模型的能力。
*   傳統網路公司的規劃式開發模式不適用於大模型。
*   楊植麟認為，新創公司在大模型領域更有優勢。

**兼顧現實與理想：**

*   楊植麟希望在技術開發上「爬樓梯」，克服困難，而不是只盯着未來的商業前景「看風景」。

**結語：**

*   月之暗面作為國內AI行業的新秀備受關注。
*   經營高估值公司不易，期待楊植麟能帶領公司持續發展。

**修改建議：**

*   **刪減重複內容：** 去除部分重複的描述，保持精簡。
*   **更精準的詞彙：** 部分描述使用更精準的詞彙，例如將「異想天開的idea」改為「創新概念」。
*   **調整語氣：** 去除部分過於口語化的表達，保持專業性。
*   **結構更清晰：** 使用更清晰的標題和段落劃分，方便閱讀。

希望這個整理後的版本對您有所幫助！ 如果您需要進一步調整，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>290. [2024-05-29] 【人工智能】AI将会带来软件民主化 | Scott Wu | Cognition创始人&CEO | 三块IOI金牌得主 | Devin AI | 工程师效率5倍提升 | Coding Agent的未来</summary><br>

<a href="https://www.youtube.com/watch?v=8b83zDnJaA4" target="_blank">
    <img src="https://img.youtube.com/vi/8b83zDnJaA4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI将会带来软件民主化 | Scott Wu | Cognition创始人&CEO | 三块IOI金牌得主 | Devin AI | 工程师效率5倍提升 | Coding Agent的未来

好的，這是整理後的文稿，我著重於資訊的清晰度與流暢度，並略作精簡：

**標題：Cognition CEO Scott Wu訪談重點分享：AI軟體工程師 Devin 的誕生與未來展望**

**開場：**

大家好，這裡是最佳拍檔，我是大飛。本期節目將分享播客《No priors》對Cognition聯合創始人兼CEO Scott Wu的訪談重點。Cognition是一家專注於AI推理的公司，近期推出的AI軟體工程師Devin引起廣泛關注。在訪談中，Scott回顧了他的成長歷程、創辦Cognition的動機，以及對Devin和AI Agent未來發展的看法。

**Scott Wu的背景與創業歷程：**

*   **從小熱愛數學與程式設計：** Scott從小就展現對數學的熱愛，並在九歲時接觸程式設計，為此著迷。他認為程式設計能將想法化為現實，讓他感到興奮。
*   **程式競賽經驗：** 參加國際信息學奧林匹克競賽（IOI）等賽事，培養解決算法問題的能力。IOI 類似程式設計界的奧運，強調創造性解決問題的能力。
*   **創業動機：** 受到挑戰既有假設和尋找違反直覺的真理所驅動，這與創業精神相通。他認為編程競賽與創業有許多共同點，像是獨立思考、從根本原則看待問題，並持續改進自己。
*   **Cognition的成立：** 於2023年11月成立，團隊成員多來自數學和程式競賽社群，並擁有在AI領域的豐富經驗。例如，Scott 曾創辦 Lunch Club，另一位聯合創辦人參與開發 AI 程式碼編輯器 Cursor。

**Devin：AI 軟體工程師**

*   **Devin 的能力：** Devin 能夠像人類工程師一樣自主決策，完成端到端的任務，包括編寫、編輯程式碼、使用命令行和瀏覽器、閱讀文檔、部署、測試和偵錯。
*   **人機協作模式：** 使用者只需提供簡單的提示，說明想要構建什麼，Devin 就會自主完成。使用者可以與 Devin 互動，提供反饋，如同與另一位工程師協作。
*   **對工程師的影響：** Scott 認為 AI 不會取代工程師，反而會增加需求。AI 可以提高開發者的能力，讓他們將更多時間用於解決創造性問題。這就像計算器的發明一樣，讓人們可以從事更多其他的事情。AI 實際上促成了軟體的普及。

**Devin 的設計與優勢：**

*   **Devin 的介面：** 設計了Shell、Browser、Editor和Planner四個分頁，靈感來自團隊日常的軟體開發工作。
*   **AI 與人類的互動：** 強調與 AI Agent 的互動方式。與其讓 Agent 一次性完成任務，不如像指導實習生一樣，定期檢查並提供反饋，有助於 Agent 學習成長，也能為使用者創造更多價值。
*   **Devin 的優勢：** Devin 擁有龐大的知識庫，擅長DevOps和開發設置，以及數據分析。例如，它可以快速解決人類工程師可能需要花費大量時間的Kubernetes資料庫問題。

**Devin 的局限與未來發展：**

*   **Devin 的核心：** 如何將精確的想法轉化為程式碼，並完成測試、除錯、安裝套件和部署等工作。
*   **Devin 的工作方式：** 透過運行程式碼、重現錯誤、添加除錯語句、查看日誌等方式解決問題，而不是檢查整個程式碼庫。
*   **對未來的展望：** Scott 認為，在5-10年內，軟體開發將發生巨大變化，人機介面將更加簡化。他希望工程師能將所有時間用於思考如何解決問題，而程式碼的實現將由 AI 完成。

**對軟體工程師的建議：**

*   **基本知識的重要性：** 了解軟體工程、電腦內部運作原理、演算法和邏輯推理等知識仍然非常重要。
*   **未來軟體工程師的角色：** 可能更像是架構師和產品經理的混合體，需要面對業務問題，思考解決方案。

**結語：**

Scott 相信AI將對經濟和人們的工作生活產生切實的影響，並鼓勵大家擁抱這場AI革命。

**結尾：**

感謝大家的收看，我們下期再見。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>289. [2024-05-28] 【人工智能】大语言模型评估基准七宗罪 | Jason Wei | 思维链作CoT作者 | 成功与否的标准 | 评估基准的七个错误 | 面临的挑战 | 测试集污染</summary><br>

<a href="https://www.youtube.com/watch?v=UywooPUfyGg" target="_blank">
    <img src="https://img.youtube.com/vi/UywooPUfyGg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】大语言模型评估基准七宗罪 | Jason Wei | 思维链作CoT作者 | 成功与否的标准 | 评估基准的七个错误 | 面临的挑战 | 测试集污染

好的，以下是整理后的文稿，我將重點放在結構清晰、重點突出、方便理解：

**文章主題：大模型時代的評估基準：OpenAI 科學家 Jason Wei 的觀點**

**引言：**

*   視覺 CV 領域有 ImageNet 作為模型能力試金石。
*   大模型時代，如何評估大語言模型的性能？現有評估基準（如 MMLU、GSM8K）是否完美？
*   OpenAI 科學家 Jason Wei 在其博客中深入研究了這個問題。

**核心觀點：**

1.  **成功的評估基準定義：**
    *   被突破性論文使用並獲得社群信任。
2.  **成功的評估基準範例：**
    *   **GLUE/SuperGLUE：** 評估模型理解自然語言的能力（文本分類、推理、問答、情感分析）。BERT、T5 等模型廣泛使用。
    *   **MMLU (大規模多任務語言理解)：** 評估模型在 57 個學科的知識和解決問題能力。DeepMind 和 Google 常用。
    *   **GSM8K (小學數學 8K)：** 評估模型解答多步驟推理數學問題的能力。思維鏈相關論文常用。
    *   **MATH：** 數學競賽問題組成的評估基準，評估模型數學能力。
    *   **HumanEval：** OpenAI 發布的編程問題，評估模型語言理解、推理、算法和數學能力。
    *   其他：HellaSwing、SQuAD 等。
    *   **成功關鍵：** 在評估基準上取得好分數，代表實現重要且易於理解的事情（超越人類、解決小學數學問題等）。
3.  **不成功的評估基準常見錯誤（七宗罪）：**
    *   **樣本數量不足：** 產生噪音，影響研究。建議至少 1000 個樣本。
    *   **品質差：** 錯誤多，不被信任。
    *   **過於複雜：** 難以理解和使用。建議使用單一數字指標。
    *   **運行成本高：** 即使其他方面優秀，也不具吸引力。
    *   **任務無意義：** 不衡量智能相關的關鍵事物（語言理解、考試問題、數學等）。
    *   **評分不正確：** 導致使用者放棄。
    *   **性能過快飽和：** 無法顯示增益效果。
4.  **其他觀點：**
    *   **糟糕的命名：** 誤導性（如 HumanEval）。建議使用創建者姓名命名（如 Hendrycks-math）。
    *   **推廣評估基準的建議：** 幫助他人使用，創造激勵機制，獲得領導支持。
    *   **面臨的挑戰：**
        *   大語言模型對評估工具提出更高要求。
        *   缺乏能充分評估大語言模型的單一基準。
        *   成對評估的權重不明確（正確性 vs. 感覺/風格）。
        *   特定領域評估的關注度有限。
        *   測試集污染：公開/私有測試集偏差監控。

**結論：**

*   AI 社群應更多投資評估基準。
*   好的評估基準是客觀評價指標，對 AI 領域產生重大影響。
*   客觀的評價標準對於AI發展至關重要，避免「王婆賣瓜，自賣自誇」。

**我的整理目標：**

*   將文本分層、分點，更容易抓住重點。
*   簡化語言，避免過多的口語化表達，使其更正式、專業。
*   保留關鍵詞和重要的例子，方便理解。

希望這個版本更適合您的需求！如果有任何需要修改的地方，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>288. [2024-05-27] 【人工智能】2027年将会实现AGI | 约翰·舒尔曼最新访谈 | OpenAI联合创始人&首席架构师 | 大模型训练 | RLHF | 技术瓶颈 | 模型蒸馏 | AI监管</summary><br>

<a href="https://www.youtube.com/watch?v=nD-9oiEHxKY" target="_blank">
    <img src="https://img.youtube.com/vi/nD-9oiEHxKY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】2027年将会实现AGI | 约翰·舒尔曼最新访谈 | OpenAI联合创始人&首席架构师 | 大模型训练 | RLHF | 技术瓶颈 | 模型蒸馏 | AI监管

好的，我幫您整理了以下文稿，主要做了以下修改：

*   **修正了錯字和語法錯誤。**
*   **添加了標點符號，使文稿更易讀。**
*   **稍微調整了語句順序，使表達更流暢。**
*   **將文稿分段，使結構更清晰。**
*   **統一了人名翻譯，如John Schulman統一為“約翰·舒爾曼”。**

**整理後的文稿：**

大家好，這裡是最佳拍檔，我是大飛。

假如在一到兩年內，一款真正意義上的AGI（通用人工智慧）能夠進入市場，你會期待它能做哪些事情呢？

不久前，ChatGPT首席架構師兼OpenAI聯合創始人約翰·舒爾曼（John Schulman）做客Dwarkesh的訪談，分享了他對AI模型未來發展的看法。在他的眼中，AGI的實現近在咫尺，人們將在三到五年內見證人工智慧的飛躍式發展，真正意義上的AGI將在這個期間問世。

圍繞這一預測，舒爾曼深入探討了關於大模型訓練的現狀、相關技術的進化方向，以及未來AI需要面對的監管問題。這100分鐘的訪談應該說是乾貨滿滿。今天大飛就來給大家分享一下舒爾曼眼中的AI模型會走向怎樣的未來。

**AI在未來人類社會中的定位**

先來說說AI在未來人類社會中的定位，這也是時下人們關注的焦點。在舒爾曼看來，AI始終是人類的助手，而相關的技術也會朝著讓AI成為更優秀的助手的方向發展。

在訪談開始時，他解釋道，所謂的AI訓練，就是對已經從互聯網中抓取了足夠內容的模型進行針對性的行為優化，來滿足人類的需求。經過訓練的模型可以非常精確，它不僅可以生成網上所有的內容，還可以按照要求排列內容的分布，從而實現特定的功能。

舒爾曼期望在不久的將來，AI能夠更像一個樂於助人的同事，而不僅僅是一個執行一次性查詢的工具。他期待AI能夠更加主動，能夠理解並且參與到用戶的整個專案中，甚至能夠主動提出建議和幫助。它既可以充當你的私人秘書，也可以做你的程式設計師。

但是，AI所能實現的功能都是建立在人的要求上，因此它始終都是人類的僕人，而非人類的主人。舒爾曼提到，目前的模型只是試圖產生一些人們會喜歡並且判斷為正確的東西，而不關心產出的到底是什麼。

**五年內AI模型的進化方向**

在此基礎上，舒爾曼預測，在未來的五年內，AI模型將向著“更好的助手”進化。他希望AI能夠獨立完成整個程式設計專案，根據人類的要求自行編寫代碼，而不是僅僅是提供編寫函數的建議。

同時，AI在執行多線程與長時間任務上的能力也將得到明顯的提高，並最終做到能夠長時間地編寫多個代碼文件。在一系列的進步下，模型將變得更有效率，可以更快地從錯誤中恢復，更好地處理臨界情況。

此外，舒爾曼還希望能夠為AI模型添加新的任務模式，通過預訓練和後訓練的結合，不斷改進功能，開拓新的用例。他預計隨著時間的推移，人工智慧將成為經濟的重要組成部分，人們將更好地理解如何將其整合到不同的社會活動中。

**AI技術通往未來的鑰匙**

舒爾曼對於未來的暢想絕非空穴來風。實際上，他認為自己已經找到了AI技術通往未來的鑰匙，那就是長期地進行強化學習訓練。通過投入更多的多模態數據與訓練成本，強化學習訓練計畫就會釋放AI在更長時間裡保持連貫的能力。一旦這種能力被解鎖，我們就可以期待AI對任務的處理能夠達到人類的水平。舒爾曼將這一質的變化稱為“相變”。

他相信，一旦模型的規模與學習訓練達到某個水平，就能夠處理更長的任務。通過使用特定的提示語，人類可以向AI描述任務所需要的時間尺度，然後它就可以開始制定學習計畫，嘗試朝著目標前進，無論這個目標是一個月還是十年後。

OpenAI當下的研究正是專注於AI的學習訓練，也就是基於人類反饋的強化學習（RLHF）的學習系統。在RLHF中，AI表現出了類似人類的心理驅動力，或者說對於目標的渴望。以人類的行為為例，當你有了某個特定的目標，比如說吃飯，你就會試圖轉向一個“尋找食物”的狀態，而不是其他狀態。這個過程在AI上，則表現為對人類正反饋的追求，模型“希望”自己的產出得到人類的認可。

舒爾曼認為，AI的驅動力或者目標概念還包括實現目標後的滿足感，這些因素可能與學習演算法有著強關聯關係。因此，他表示，在某種程度上，模型確實通過RLHF以某種有意義的方式實現了和人類相同的心理模式。

**學習方式的選擇**

在具體訓練方案的選擇上，舒爾曼則關注兩種學習方式：一種是上下文學習，這種方式雖然樣本效率高，但是會隨著每個實例的變化而被破壞；另一種是大規模訓練，雖然不會隨著實例變化而破壞，但是有可能過於淺薄。兩種方案各有優劣。

但是舒爾曼卻不滿足現有的技術路線，他探討了第三種可能：是否存在一種折中的學習方式，既不會隨實例變化而破壞，也不會過於淺薄，而是有著更強的主觀能動性？這種中間路徑可能涉及模型的中期記憶能力，即對於一百萬左右token的記憶調度。

如果能夠實現兼具前兩者優點的第三種學習模式，模型就能做到既能適應上下文，又不需要大量的預訓練資料。舒爾曼表示，在OpenAI之前，人們並沒有真正努力在大規模訓練和上下文學習之間找到平衡。他和他的團隊希望填補這一技術空白，構建一個能進行在線學習的系統，從而使得模型具有一些類似人類的認知技能，比如自我反思的能力，以及自推理的能力。

模型將能夠通過自推理實現如同人類一般“舉一反三”的能力，同時使用內省和自主知識來確定需要學習什麼。這些能力是當前大模型所缺少的，但是一旦實現，我們就離真正的AGI不遠了。

**技術瓶頸與挑戰**

當然了，任何尖端科技的發展都不可能是一帆風順的。舒爾曼也坦率地承認了技術瓶頸的存在。但是他本人對於這些難題抱有樂觀的態度。

目前大模型面對的問題主要有四個：

1.  **難以預測的雜項缺陷：** 舒爾曼表示，一旦開始進行長期的強化學習訓練，模型將能夠在更長時間裡保持連貫。然而不同的模型有著不同的訓練承受能力，這會導致它們經受過強的學習訓練，從而陷入瓶頸。
2.  **當下AI模型的局限性：** 我們依然沒有完全摸清AI這個“灰盒子”，這導致模型可能存在會幻覺等意料之外的問題。它們會錯誤地認為自己可以執行、甚至已經執行了某些它做不到的任務。比如，AI會表示自己已經幫助用戶發送了電子郵件或叫了輛出租車，但是實際並沒有這麼做。

不過，舒爾曼將以上兩點稱之為“雞毛蒜皮的小事”，這些事情也許會在初期減緩開發速度，但是不會持續太久。他相信，通過強學習訓練，以上問題都可以在兩到三年內獲得解決。屆時我們就會見證人工智慧發展的又一高峰。

3.  **訓練數據不足的問題：** 這被舒爾曼稱為“一個對科學研究的挑戰”，足可見它受重視的程度。從人類的視角看，互聯網上的知識浩如煙海，即使窮盡某個人的一生也不能完全了然。但是對於每秒吞吐上億數據的語言模型來說，互聯網中可供學習的資料的產出，遠遠趕不上它所消耗的速度。終有一天，大模型會陷入“輟學”的狀態，也就是說再也沒有足夠的訓練數據供它學習了。

舒爾曼承認數據量的有限性會帶來一些挑戰，但是這個問題還是被誇大了。首先，即使在數據有限的情況下，通過少量示例也可以改善AI的性能。AI的“泛化”就是一個例子，通過對西班牙語資料的學習，AI的英語能力也能夠得到提升。其次，只要模型的規模達到必要的程度，它就能從少量的数据中提取需要生成的功能。因此，对于GPT4级别的大模型而言，准确地识别需要的功能、并收集相关的数据比单纯的训练资料更为重要。

因此舒尔曼认为数据不足还不是OpenAI眼下最要紧的问题，他们有足够时间应对挑战。

4.  **AI的聊天功能：** 体验过AI的朋友都有类似的感受，AI的语言风格还是太过僵硬与公式化。Schulman相当关注聊天模型的发展，以及如何通过混合数据集，比如指令和聊天数据来优化模型。他认为，聊天模型更易于使用，并且展示出了一定程度的自省行为，这是AI智能的一种体现。眼下OpenAI正在努力改进AI的写作体验，让它更有“人情味”。

舒爾曼提到，他們不僅改進了ChatGPT的個性，也在探索語言模型如何影響語言的使用。在收集數據的過程中，研究者發現人們喜歡結構化的回應和大量信息，也注意到模型可能比人們需要的更加冗長。這可能是因為在標記階段，評分者更喜歡冗長的答案，又或者是因為預訓練的方式導致模型傾向於繼續生成文本。無論如何，針對AI聊天的功能優化已經被舒爾曼提上了日程。

**AGI與社會的平衡**

从舒尔曼对于科研瓶颈的态度不难看出，对于AI模型在未来发展，以及它能实现的功能，这位首席架构师都充满了信心。他甚至在访谈中预言，真正意义上的AGI会在2027年到来。

但是我們的社會真的能在三到五年內做好迎接更高性能的AI甚至AGI的準備嗎？如果人工智能變得足夠強大，比如能夠自己經營一家成功的企業，那麼人類是否還需要參與其中？

談及這一點，舒爾曼認為整個社會都需要拿出一套可以安全地處理AI的解決方案。政府要如何處理潛在的失業潮？AI在道德倫理上是否仍然具有風險？AI在企業中的應用是否會增加信息安全隱患？他甚至半開玩笑地說，如果一切開發順利，作為架構師的自己就會在一年之內丟掉飯碗。

對於這些問題的解決方案，在當下的社會中還沒有達成有效的共識。舒爾曼也承認，他不知道要如何在現在的社會中長期保持AI與社會秩序的平衡。我們必須要找到一種方案來確保AI始終隸屬於人的意志，與此同時，AI還得屬於秉持社會正義的團體。一旦被心懷惡意的人濫用，AI就會導致難以想像的災難。舒爾曼直言，在人們享受科技帶來的繁榮和進步之前，先要考慮好如何確保這些系統不會被壞人濫用，甚至於顛覆現有的社會秩序。

**技術解決方案與社會實驗**

面對AI可能造成的問題，作為信息工程領域的大拿，舒爾曼提出了一個技術性很強的解決方案，那就是一套強大的監管系統與一場穩定的社會實驗。他表示，既然步子邁大了容易扯到蛋，那還不如一步一走，先在社會中部署一個性能較弱的模型，再逐步對它的性能進行升級。一旦出現任何意料之外的惡性事件，整個部署流程可以隨時被終止。與此同時，舒爾曼也寄希望於監管技術的進步，以便在系統開始出現問題的時候能夠立即發現。

他舉了AI在公司管理中的應用作為例子。對於公司的運營者而言，海量的数据处理以及繁杂的管理问题始终是一座大山，压得人喘不过气来。如果管理者能够得到AI的辅助，那么整个公司的运营效率都将得到提高。但是如果AI表现出远超人类的管理效率，那么公司的运营还需要人类的参与吗？

至少在舒尔曼看来，即使人工智能展现出了超越人类的效率，人仍然是人工智能最终行动的驱动力。如果有人参与的公司，在市场竞争中败给了没有人参与的公司，那么这本身就是对社会秩序的动摇。在他看来，资本市场需要一套监察系统来维持AI与人之间的平衡，并且在必要的时刻禁止AI公司参与正常的市场竞争。

舒尔曼还表示，虽然AI运营的公司在许多方面可能会表现得更加高效，但是它们也存在更高的尾部风险。这是因为AI在处理非常少见的情况时，仍然缺乏足够的样本，所以更有可能出现大规模故障。哪怕是出于风险管理的考虑，他也不建议把AI大规模投入到公司管理。但是他也没有就此否定AI公司的可能。舒尔曼认为，假以时日，当社会做好准备，AI也证明自身在管理方面比人类更善于对人类负责，那么让AI管理公司也许是可以的。

**給中小企業和開發者的建議**

在訪談的最後，舒爾曼從AI模型在未來社會中的暢想中回到了當代，並給予了中小企業和個人開發者一些技術路線上的建議。他認為與社會科學等其他領域相比，對於機器學習的研究是一個相對健康的領域，因為它足夠“務實”，整個領域的事物在很大程度上基於技術的實用性和實證主義，只要你能做出成果，就能獲得回報。

因此他很推薦當代的有志者們投入這個領域來施展自己的才華。但是他也指出，訓練創建一個真正具有人們關心的所有功能的模型是相當複雜的，需要大量的專業人士和大量的研發積累。這個特點使得大模型的開發容易形成技術壁壘，就像企業的“護城河”一樣，入行的新人難以複製前人的成功。

对此，舒尔曼建议这些缺乏足够经验与人手的企业，可以考虑使用“蒸馏”模型来构建自己的AI系统。“蒸馏”模型的原理有点类似AI老师给AI孩子上课，开发者需要将一个复杂而且规模较大的教师模型中的知识提取出来，并传递给一个相对较小而且结构简单的学生模型。这样做

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>287. [2024-05-26] 【人工智能】柏拉图表征假说 | 不同模型趋向于同一现实表征 | Ilya点赞 | AI对现实的认知 | 表征对齐 | 模型拼接 | 柏拉图的山洞寓言</summary><br>

<a href="https://www.youtube.com/watch?v=MTjPNWdv2qk" target="_blank">
    <img src="https://img.youtube.com/vi/MTjPNWdv2qk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】柏拉图表征假说 | 不同模型趋向于同一现实表征 | Ilya点赞 | AI对现实的认知 | 表征对齐 | 模型拼接 | 柏拉图的山洞寓言

好的，這是我整理過後的文稿，力求更清晰、更精煉：

**大家好，這裡是最佳拍檔，我是大飛。**

Ilya Sutskever 離開 OpenAI 後，立刻點讚了一篇 MIT 團隊發表的 AI 論文《The Platonic Representation Hypothesis》（柏拉圖表徵假說），引起廣泛關注。我仔細閱讀後，認為這篇論文對 AI 未來發展路徑具有指導意義，值得 AI 從業人員、科技投資人，以及所有對 AI 感興趣的朋友閱讀。

今天我們就來解讀這篇論文的精華，幫助大家對深度學習模型的未來有全新的哲學認知。

**一切從柏拉圖的洞穴寓言說起。**

洞穴寓言是柏拉圖在《理想國》中提出的思想模型，旨在探討「現實」的本質。囚犯被鎖在洞穴中，只能看到牆上事物的影子，並將影子視為「現實」。但這些影子只是真實世界的投影。柏拉圖認為，哲學家能走出洞穴，明白影子並非真正的現實，並透過邏輯、數學、自然科學等手段，去理解更高層次的現實。如今，這個目標從哲學家傳到了 AI 科學家的手中。

**理解洞穴寓言後，柏拉圖表徵假說就容易理解了。**

該假說認為：**不同的 AI 模型，在不同的數據和模態上，以不同目標進行訓練，正趨向於在表徵空間中，收斂成一個共享的現實世界統計模型。** 簡單來說，只要模型規模足夠，訓練得當，它們解釋和預測世界的方法就會趨同。這就好比，不論文化背景，只要讀足夠多的好書、見足夠多的世面、經歷足夠多的事，人們對世界的理解就會趨同。

**具體來說：**

假設現實 Z 是個圓錐加圓球，X 是現實 Z 的圖片模態投影，Y 是現實 Z 的文本模態投影。訓練 CV 模型 fimg 和文本模型 ftext 後，它們各自學到了 X 和 Y 的表徵方式。但隨著模型參數規模和訓練數據的擴大，這兩個模型最終會學到 X、Y 背後現實 Z 的表徵方式。也就是說，AI 模型變得足夠聰明時，不再是被鐵鏈拴住的囚犯，而是成為走出洞穴的哲學家，能感知更高維度的現實。

**這個假說有個重要推論：**

不同模態、不同算法架構的 AI 模型，最終都會匯聚到同一個目標，即形成對高維現實的準確表徵，對世界的認知趨同。這種表徵可理解為現實事件的聯合分布的概率模型，這些離散事件可以透過圖片、聲音、文字、質量、力、力矩等多種方式被觀察和感知。

**如何驗證這個假說？**

需要用到數學工具。論文作者定義「表徵對齊 (Representation Alignment)」為兩個表徵在核函數上的相似性度量，並運用「模型拼接 (Model Stitching)」技術來評估表徵之間的相似度。模型拼接的原理是將兩個模型的中間表示層連接起來，形成一個「縫合」模型。如果該「縫合」模型性能良好，則表明兩個原始模型在該層的表徵是兼容的。

**實驗結果：**

作者選取了 78 個在訓練數據集、任務目標、算法架構上各不相同的 CV 模型，進行表徵相似度分析。結果顯示，模型性能越強，它們之間的表徵相似度就越高；反之，模型性能越差，它們之間的表徵相似度就越低。這驗證了柏拉圖表徵假說的存在。

**為什麼 AI 模型會呈現出如此明顯的表徵收斂性質？**

作者認為主要有三大原因：

1.  **任務通用性：** 多任務目標訓練會對模型施加更多約束，從而導向更緊致、更高質量的解決方案空間。
2.  **模型容量：** 模型越大，越容易逼近全局的最優表徵，從而推動表徵收斂。更大的模型才有可能更聰明，聰明到解決一切問題。
3.  **簡單性偏見：** 更大的模型擁有更多的參數和計算能力，但總是傾向於簡單的解決方案。深度神经网络天然遵循着奥卡姆剃刀原则。

**柏拉圖表徵假說給我們什麼啟發？**

1.  隨著模型參數、任務多樣性、算力 FLOPS 的增加，模型表徵會逐漸收斂趨同，但不同方法的收斂效率可能天差地別。對於某些獨立任務，可以單獨訓練一個 shortcut 模型，而不一定要依靠對現實的統一表徵。
2.  可以從新的視角審視多模態數據之間的關係。為了訓練出最強的 CV 模型或文本模型，除了訓練全部的圖片或文字，還應該將另一種模態的數據也納入訓練集，因為不同模態的數據背後，可能隱含著某種與模態無關的通用現實表徵。

**結語**

两千年前，柏拉图提出洞穴寓言，哲学家们探索现实的本质。两千年后，人类拥有了AI这个超级武器，能否借助AI的力量，寻找到表征世界的全局最优解，走出洞穴，探寻并且理解高维度的真正现实呢？ 欢迎大家在评论区发表自己的看法。感谢大家观看本期视频，我们下期再见。

**整理說明：**

*   **簡化語言：** 盡量使用更簡潔、更通俗易懂的語言。
*   **提取重點：** 突出論文的核心觀點和實驗結果。
*   **組織結構：** 按照邏輯順序重新組織內容，使其更清晰易懂。
*   **刪除冗餘：** 刪除了一些重複和過渡性的話語。
*   **加入总结：** 在重要节点加入总结性的语句，方便读者理解。

希望這個版本能更有效地傳達原文的精髓！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>286. [2024-05-24] 【分享】中文互联网正在加速崩塌 | 历史信息的消亡 | 是否还有挽救方法 | 究竟什么原因造成</summary><br>

<a href="https://www.youtube.com/watch?v=nQMk37vJE68" target="_blank">
    <img src="https://img.youtube.com/vi/nQMk37vJE68/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【分享】中文互联网正在加速崩塌 | 历史信息的消亡 | 是否还有挽救方法 | 究竟什么原因造成

好的，我將這篇文稿整理如下，著重於提煉重點、調整語氣，並使其更具結構性：

**主題：中文互聯網的加速崩塌**

**核心論點：**

*   中文互聯網正在經歷一場「時間的二向箔」式的崩塌，早期（尤其是移動互聯網出現之前）的內容正迅速消失，造成歷史記憶的缺失。
*   這種消失是系統性的、大規模的，影響廣泛，包括網站、論壇、個人網頁等。

**論證過程：**

1.  **案例展示（百度搜索實驗）：**
    *   以「馬雲」為例，在百度搜索1998-2005年的信息，結果幾乎為零，證明早期信息大量缺失。
    *   用Google搜索相同信息，可以找到有效結果，對比之下更顯中文互聯網的問題。
    *   其他案例：馬化騰、雷軍、任正非、芙蓉姐姐等，結果類似，證明普遍性。

2.  **範圍界定：**
    *   消失的內容主要集中在移動互聯網出現之前的中文網站，例如網易、搜狐、校園BBS、天涯論壇等。
    *   新浪網雖有少量信息，但整體情況不容樂觀。

3.  **原因分析：**
    *   **經濟原因：** 網站維護成本高昂，無人問津的內容會被關閉或刪除。
    *   **監管原因：** 網路監管日益嚴格，早期內容可能不再符合要求，導致自我審查和刪除。
    *   其他原因：域名消失、版權問題、個人意願等，但非主要因素。

4.  **進化論角度：**
    *   互聯網內容遵循「信息競爭，注意力選擇，適者生存」的原則。
    *   無法吸引注意力的內容，或維護成本過高的內容，將會消失。
    *   新一代互聯網的崛起，必然伴隨舊互聯網的崩塌。

5.  **沒有歷史的隱憂：**
    *   失去歷史記錄的嚴重性：看不到重要人物的原始資料，如同失去集體記憶。
    *   未來展望：知乎、豆瓣、B站等平台可能步入後塵，個人內容也可能消失。

6.  **補救措施的困境：**
    *   美國的Internet Archive收錄中文網頁有限，搜索功能不足。
    *   保存所有網頁在技術上可行，但缺乏動機和執行者。
    *   傳統互聯網中文內容已大量消失，補救為時已晚。

**結論：**

*   中文互聯網正在經歷「時間的二向箔」式的吞噬，過往的內容正迅速消失，我們即將成為「沒有歷史記錄的一代人」。
*   我們能做的只能是接受現實，並珍惜當下。

**個人感觸：**

*   作者（大飛）慶幸自己選擇YouTube頻道，但對內容可能消失感到無奈。
*   呼籲觀眾「且看且珍惜」，反映對網路內容易逝的感嘆。

**整理說明：**

*   **重點突出：** 將核心論點放在最前面，讓讀者快速掌握文章主旨。
*   **結構清晰：** 使用數字和標題，使論證過程更有條理。
*   **語氣調整：** 略微調整語氣，使其更客觀，避免過度煽情。
*   **刪減冗餘：** 刪除部分重複或過於口語化的內容，使文章更精煉。

希望這個整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>285. [2024-05-23] 【人工智能】以人为本的人工智能 | 李飞飞最新对话 | AI威胁论 | AI的最终目的是造福人类 | 是否会取代工作 | 人类的选择 | 人文关怀</summary><br>

<a href="https://www.youtube.com/watch?v=JPP5R8kV-wE" target="_blank">
    <img src="https://img.youtube.com/vi/JPP5R8kV-wE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】以人为本的人工智能 | 李飞飞最新对话 | AI威胁论 | AI的最终目的是造福人类 | 是否会取代工作 | 人类的选择 | 人文关怀

好的，這是我整理後的文稿，更注重結構和重點提取，並進行了潤飾，讓其更清晰易懂：

**標題：AI 的未來：以人為本的發展方向 (李飛飛觀點整理)**

**引言：**

*   當前社會對人工智能（AI）的擔憂日益增加，例如「AI 會奪走工作」和「AI 會統治人類」等威脅論甚囂塵上。
*   斯坦福大學教授李飛飛認為，AI 的發展應「以人為本」，強調 AI 應成為受歡迎的技術，而不是威脅人類的工具。

**一、 AI 的本質與局限性：**

*   **AI 本質：** 本質是由計算機程序構建的數學模型，通過迭代和學習來預測數據。購物網站的智能推送、地圖導航、影視特效等都是 AI 的應用。
*   **AI 局限性：** 無法取代人類複雜的推理、情境感知和理性與感性的結合。即使在房間著火時，AI 仍能下好棋，顯示其缺乏情境感知能力。
*   **人類優勢：** 人類對思維、情感和周圍環境有更自然的情境感知，這是 AI 目前無法做到的。

**二、 AI 技術的「灰盒子」本質：**

*   **對 AI 的恐懼：** ChatGPT 的複雜性使人們對其具體原理不甚明了，加劇了對 AI 的恐懼，滋生陰謀論。
*   **李飛飛的澄清：** AI 並非完全未知的「黑盒」，而是「灰盒子」。人類了解神經網絡算法的運作機理，但模型參數過於龐大，難以用數學形式闡明學習模式。
*   **結論：** 人類整體上依然了解並掌控著 AI，它不是失控的怪物。

**三、 AI 發展的社會責任：**

*   **問題：** 雖然AI技术不斷突破，但公眾對AI的認知沒有跟上，偏見言論誤導著對技術缺乏認識的普通人。
*   **李飛飛的責任感：** 李飛飛認為，專業人士和高等教育機構有責任幫助非專業人士正確了解和使用 AI。
*   **「以人為本」的初衷：** 對社會責任的重視，成為李飛飛構建「以人為本」的人工智能的初衷。

**四、 「以人為本」的人工智能：**

*   **核心：** 以人類價值觀、人類尊嚴為核心，對人工智能進行開發和使用的框架。
*   **目標：** 避免 AI 技術對人類有害，而是通過升級 AI 技術，幫助人類完成重複性強的瑣事或危險任務。

**五、 AI 視覺的應用與啟示：**

*   **傳統觀點：** 人們對 AI 擁有足夠強的視覺能力感到恐懼，認為 AI 會覺醒自我意識。
*   **李飛飛的觀點：** 研究計算機視覺人工智能，本質上是在為人類自身謀利。
*   **靈感來源：** 計算機科學家受到視覺神經科學家的啟發，研究貓、哺乳動物的視覺系統，發現分層神經元，並由此產生了整個神經網絡算法。
*   **應用價值：**
    *   **醫療方面：** 人工視覺系統可以幫助視障患者重見光明。
    *   **極端環境：** 機器人可以在切爾諾貝利、福島等核事故現場執行危險任務，避免人員傷亡。
*   **結論：** AI 技術最終要落實到造福人類的項目中，讓人類生活變得更好。

**六、 AI 與工作：**

*   **對失業的擔憂：** 人們擔心 AI 會搶走大量工作機會。
*   **李飛飛的回應：** 「以人為本」的人工智能強調 AI 需要往人類需要的方向發展，而不是掠奪人們的工作機會。
*   **工作的意義：** 工作不僅僅是金錢，更在於實現個人價值和尊嚴。
*   **思考方向：** 思考 AI 對工作內容的影響，哪些部分可以被 AI 替代，哪些部分是只有人類可以實現的價值。
*   **醫療保健領域的例子：** AI 可以減輕醫療工作者的繁重工作，讓他們有更多時間照顧病人，從而幫助人類獲得自我價值與尊嚴，又增強人類的能力。
*   **結論：** AI 最終在社會上發揮怎樣的作用，取決於我們能否正確地設計人工智能。

**七、 「以人為本」AI 的設計框架：**

*   **專注方向：** 專注於那些人類希望交給機器人做的事情，而不是那些人類希望親自動手操勞的事情。
*   **例子：** 我們更希望 AI 可以去處理生活中的瑣事，比如打掃衛生，讓人們有更多時間去享受生活。

**八、 確保 AI 造福人類的三個方向：**

1.  **跨學科研究：** 將社會科學帶入 AI 科技的研究中，了解 AI 在社會分工與結構中會造成什麼影響，並與政策制定者合作，解決 AI 可能造成的社會問題。
2.  **社會引導：** 知識分子和高等教育機構應引導 AI 的發展，使其成為提高人類能力、增進人類福祉、維護人類尊嚴的方向。
3.  **挖掘人類與 AI 的聯繫：** 從人腦中獲得 AI 科技的「啟發」，開發與人類生活互相兼容的人工智能技術。

**九、 對未來 AI 的展望：**

*   **應對恐慌：** 即使 AI 展現出比人類更強大的能力，人類依然有智慧與之共存。
*   **核心問題：** AI 問題的核心依舊是人的選擇。
*   **最終期望：** 我們在創造出與我們的智能相近的機器時，應防止它「近墨者黑」，努力讓它「近朱者赤」，讓它發揮人性美更好的一面。

**結語：**

*   李飛飛的觀點充滿人文關懷，對於我們如何看待 AI 是一個很好的提示和補充。

**注意：**

這個版本更強調重點和結構，可以更好地理解李飛飛的核心思想。我同時也潤飾了文字，讓其更通順易懂。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>284. [2024-05-22] 【人工智能】直觉的力量 | 杰弗里辛顿最新对话 | Sana AI峰会 | 回忆AI生涯 | Ilya的能力和直觉 | 缩放法则 | 多模态 | 语言与认知 | 神经网络 | AI情感 | 反向传播</summary><br>

<a href="https://www.youtube.com/watch?v=mG31I9mfVLU" target="_blank">
    <img src="https://img.youtube.com/vi/mG31I9mfVLU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】直觉的力量 | 杰弗里辛顿最新对话 | Sana AI峰会 | 回忆AI生涯 | Ilya的能力和直觉 | 缩放法则 | 多模态 | 语言与认知 | 神经网络 | AI情感 | 反向传播

好的，我來幫您整理這篇文稿。我將重點放在：

*   **提取核心資訊：** 歸納辛頓訪談的重點和主要觀點。
*   **結構化呈現：** 將內容分段，使其更易於閱讀和理解。
*   **精簡語言：** 去除口語化的贅詞，使表達更簡潔。

**整理後的文稿如下：**

**圖靈獎得主辛頓訪談重點整理**

本期分享圖靈獎得主杰佛里·辛頓（Geoffrey Hinton）與天才創業家喬爾·海勒馬克（Joel Hellermark）的訪談內容，被譽為精華。訪談涵蓋辛頓的人工智能生涯、大模型技術路線、多模態學習、數字計算與知識共享、智能系統的意識與情感，以及與伊利亞·蘇茨克維爾（Ilya Sutskever）的合作等。

**一、人工智能生涯的回顧與啟蒙**

辛頓的啟蒙來自於唐納德·赫布（Donald Hebb）的《行為的組織》和約翰·馮·諾伊曼（John von Neumann）的《計算機與人腦》，讓他開始思考大腦學習的獨特方式。他曾嘗試從生理學和哲學尋找答案，最終選擇在愛丁堡大學研究人工智能。1982年，他前往卡內基梅隆大學，與泰倫斯·塞諾夫斯基（Terry Sinofsky）研究玻爾茲曼機，並與統計學家彼得·布朗（Peter Brown）交流，從而理解隱馬爾可夫模型，並在反向傳播中採用“隱藏層”的概念。

**二、與伊利亞·蘇茨克維爾的相識與合作**

辛頓回憶起伊利亞主動到實驗室求職，並在閱讀反向傳播論文後，提出更合理的函數優化器。伊利亞具備“增加規模會有更好效果”的直覺，即縮放法則（Scaling Law），主張擴大模型規模能提升效果。辛頓早期雖持保留態度，但後來證實伊利亞的觀點基本正確。2011年，他們合作利用維基百科數據預測HTML字符，效果出奇地好。

辛頓認為，伊利亞這種擁有驚人直覺的人，能有效篩選資訊，建立清晰的思維框架。

**三、對大語言模型的看法**

辛頓堅信，大語言模型的理解方式與人類相似，且隨著規模增長，推理能力也會提升。GPT-4能找到堆肥堆與原子彈的共同點，聯想到鏈式反應，展現了創造力。他認為，大型神经网络的表現可以超越訓練數據，如同聰明的學生能從錯誤中學習。

**四、如何提升推理能力**

辛頓認為，隨著人工智能模型規模擴大，推理能力將自然提升，如同人類透過直覺判斷，再以推理修正。AlphaGo透過結合直觀的評估函數與蒙特卡洛樹搜索來優化決策，展現創新能力。

**五、對多模態的看法**

辛頓認為，多模態輸入能顯著改進模型，提高對空間事物的推理能力，並提供更多訓練數據。他列舉了三種不同的語言觀與認知關係：符號觀、向量觀，以及介於兩者之間的觀點，即語言和思維過程涉及符號，但這些符號通過多層次的嵌入表示（embedding representation）被豐富化。

**六、對計算技術未來發展的思考**

辛頓提到實現模擬計算（analog computation）的想法，以降低能源消耗。此外，他認為現有模型缺少人腦中擁有的多個時間尺度的權重變化，這對於實現更接近人腦的臨時記憶功能至關重要。

**七、大模型出現的最大影響**

辛頓認為，大模型顛覆了過去對大型隨機神经网络的懷疑態度，證明透過隨機梯度下降調整權重，確實能學習並掌握複雜知識。

**八、人工智能的情感**

辛頓認為，情感是沒有外部約束時可能採取的行動，AI也能擁有情感。

**九、對符號的看法**

辛頓認為，人類進行符號處理，但並非傳統觀念中那麼簡單，而是透過給符號賦予大型嵌入向量，並利用這些向量的成分間互動進行思考。

**十、未來最該解決的問題**

辛頓認為，仍是大腦是否進行反向傳播，以及如何獲得梯度信息。

**十一、未來最有前景的應用**

辛頓認為，應在醫療保健和新材料領域。他雖擔心AI被濫用，但也認為AI發展不太可能減速。

希望這個版本更符合您的需求！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>283. [2024-05-21] 【人工智能】AI会吞噬所有软件 | Databricks CEO 阿里·戈德西最新访谈 | 数据的重力 | Spark | MosaicML | Data Lakehouse | 企业级模型</summary><br>

<a href="https://www.youtube.com/watch?v=WV16tG3ktbU" target="_blank">
    <img src="https://img.youtube.com/vi/WV16tG3ktbU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI会吞噬所有软件 | Databricks CEO 阿里·戈德西最新访谈 | 数据的重力 | Spark | MosaicML | Data Lakehouse | 企业级模型

好的，我來為你整理這篇文稿，使其更清晰易讀、重點突出，並符合文件整理的專業要求。

**整理後的文稿：**

**主題：** Databricks CEO阿里·戈德西 (Ali Ghodsi) 訪談重點整理

**來源：** 知名博客Stratechery (大飛 - 最佳拍檔頻道分享)

**簡介：**

這是一篇關於知名博客Stratechery對Databricks聯合創始人兼CEO阿里·戈德西 (Ali Ghodsi) 的訪談重點整理。Databricks是一家估值高達430億美元的私營企業，由Apache Spark的創始人Ghodsi創立。訪談內容涵蓋Ghodsi的個人背景、Databricks的創業歷程、市場競爭以及AI（特別是大語言模型）的發展策略。

**Ali Ghodsi 背景簡介：**

*   出生於伊朗伊斯蘭革命時期 (1978年12月)。
*   5歲時離開伊朗，在瑞典長大，受益於瑞典早期對IT基礎設施的大量投資。
*   2009年赴美，在加州大學伯克利分校進行研究，師從圖靈獎得主戴夫·帕特森 (Dave Patterson)。
*   參與Apache Mesos和Apache Spark等專案，見證了數據和人工智能時代的開啟。

**Databricks 創辦歷程：**

*   **動機：**
    *   當時的研究成果和開源項目未受重視，業界對大數據和AI的應用興趣缺缺。
    *   為推廣Spark，解決技術落地和影響力問題，於2013年創立Databricks。
*   **關鍵技術：**
    *   Apache Spark：用於大規模分析數據的開源分析引擎，比當時的解決方案快10-100倍，且更便宜。
    *   Data Lakehouse (數據湖倉)：統一結構化和非結構化數據，顛覆傳統數據倉庫生態系統。
    *   Photon引擎：Databricks的商業化引擎，與Spark API 100%兼容，速度提升10倍。
*   **早期挑戰：**
    *   缺乏商業化策略和開源策略經驗。
    *   初期收入低 (2015年僅150萬美元)。
*   **成功因素：**
    *   技術領先：Spark的性能優勢顯著，解決了當時數據處理的痛點。
    *   堅持Data Lakehouse理念：即使初期不被看好，最終成為業界趨勢。

**市場競爭與未來展望：**

*   **競爭對手：**
    *   雲服務商：Microsoft (Fabric)、Google (BigQuery)、AWS (Redshift)
    *   直接競爭對手：Snowflake
    *   底層供應商：Tabular、MotherDuck
*   **Databricks 的競爭優勢：**
    *   對AI的早期支持：從Spark時代就開始關注機器學習。
    *   Data Lakehouse架構：更易於整合非結構化數據，優於傳統數據倉庫。
    *   不鎖定雲平台：提供客戶更多選擇，降低對單一雲服務商的依賴。
*   **未來趨勢：**
    *   AI將重寫所有SaaS，並吞噬掉所有軟體。
    *   數據的重力效應：企業越來越重視數據安全和隱私，不輕易移動數據。

**收購 MosaicML：**

*   **理由：**
    *   大語言模型是數據提供商的底線。
    *   MosaicML在B2B企業領域表現出色，與Databricks的市場策略契合。
    *   MosaicML的研發能力和定制化模型服務，可幫助客戶構建自有知識產權。
*   **定制化大模型策略：**
    *   根據企業的特定需求，提供不同規模和功能的模型。
    *   注重模型質量和準確性，而非一味追求通用性。
    *   提供從輕量級微調到LoRA等多种训练方式。

**創辦公司經驗與教訓：**

1.  **尋找並信任好的領導者：** 與人建立信任需要時間。
2.  **不要害怕大公司：** 保持专注和战略正确，可以击败他们。
3.  **銷售產品：** 產品和市場兩者都要做好，且需和諧。

**中國和全球人工智能發展：**

* 中国在AI发展迅速，部分亚洲国家监管较少。
* 欧洲的发展通常落后于美国几年，且监管更多。
* 印度和巴西的发展也很快，Databricks在这些地区也有增长业务。

**總結：**

Databricks在阿里·戈德西的領導下，通過技術創新和市場策略，成功將Spark推廣為全球性的數據處理引擎，並在AI時代佔據領先地位。

---

**整理說明：**

*   **結構化：** 使用標題、子標題和項目符號，讓內容更有條理。
*   **重點突出：** 使用粗體字標示重要資訊。
*   **簡潔明瞭：** 刪除冗餘的口語化表達，使文稿更精煉。
*   **歸納總結：** 將訪談內容歸納為幾個主要方面，方便快速掌握重點。
*   **專業術語：** 保留關鍵的專業術語，例如Data Lakehouse, Apache Spark等。
*   **信息来源：** 明确标注信息的来源，方便追溯原始资料。

希望這份整理對您有所幫助！如果您有任何進一步的要求，請隨時提出。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>282. [2024-05-18] 【OpenAI】OpenAI超级对齐团队解散，GPT还安全么 | Ilya Sutskever & Jan Leike离职 | Superalignment</summary><br>

<a href="https://www.youtube.com/watch?v=wiFkbww_H-g" target="_blank">
    <img src="https://img.youtube.com/vi/wiFkbww_H-g/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】OpenAI超级对齐团队解散，GPT还安全么 | Ilya Sutskever & Jan Leike离职 | Superalignment

好的，以下是經過整理後的文稿，我將其分點歸納，並著重於核心信息，使其更易於理解：

**主題：OpenAI內部動盪與Ilya Sutskever離職**

**1. OpenAI內部變動：**

*   GPT-4o发布后，OpenAI 聯合創始人兼首席科學家Ilya Sutskever離職，引發內部動盪。
*   超級對齊團隊聯合負責人Jan Leike也離職，並公開表示與OpenAI高層在核心優先事項上存在長期分歧。
*   超级对齐團隊解散，成員或辭職或被納入其他研究。

**2. Jan Leike 的指控：**

*   團隊在推動超級對齊项目和爭取計算資源時遭遇阻礙，影響研究進度和品質。
*   Leike告誡OpenAI員工要重視AGI，態度要莊重。

**3. OpenAI離職協議爭議：**

*   OpenAI要求離職員工簽署包含非貶損公司條款的協議，拒絕簽署者將放棄公司股權（可能損失數百萬美元）。

**4. OpenAI 發展方向的轉變：**

*   OpenAI 似乎放弃了 AI 安全，傾向商业化，甚至有傳聞要開放生成色情內容。

**5. Ilya Sutskever 的重要性：**

*   有必要了解 Ilya 的過往經歷，以便理解他為何離開 OpenAI。
*   Ilya在深度学习领域的贡献极其重要。

**6. Ilya Sutskever 的背景：**

*   出生於蘇聯，5歲時移民到以色列。
*   在以色列開放大學攻讀計算機科學學士學位，後到加拿大多倫多大學取得數學學士、碩士及博士學位（師從 Geoffrey Hinton）。
*   博士論文研究循環神經網路。
*   與Alex K及Geoffrey Hinton共同完成 AlexNet 論文，該論文首次使用深度學習解決有監督的計算機視覺問題。

**7. 加入 Google 和 OpenAI：**

*   Ilya 參與成立的 DNNresearch 公司被 Google 收購，他在 Google 工作三年。
*   2014年，與Sam Altman、Greg Brockman及Elon Musk共進晚餐，討論創辦能與Google和Deepmind競爭的人工智能實驗室。
*   2015年，在他人投資下，Ilya加入 OpenAI，成為其首席科學家。

**8. Ilya 在 OpenAI 的貢獻：**

*   情感神經元論文（Sentiment Neuron Paper）：透過訓練AI模型完成特定任務，了解模型如何完成任務。
*   ChatGPT：将情感神经元论文扩展到更复杂的任务，並最終形成了 ChatGPT。

**9. 對 AI 安全的擔憂：**

*   Ilya 開始公開表示對 AI 的擔憂，並將研究重心轉向 AI 對齊。
*   2023年8月表示把所有研究重點都轉到了人工智能對齊上。

**10. 超級對齊團隊的解散：**

*   OpenAI 曾表示將投入大量資源解決超級智能對齊問題，但超級對齊團隊現已解散。

**11. OpenAI 的未來：**

*   OpenAI 內部沒有人能阻止 Sam Altman 的步伐。
*   Ilya 的下一步動向備受關注。

**結語：**

无论 OpenAI 和 AI 如何发展，频道会持续陪伴大家，见证历史。

**改进说明：**

*   **结构化：** 使用标题和编号使信息更易于浏览和理解。
*   **精简：** 去除重复或不必要的细节，专注于核心信息。
*   **明确：**  澄清模糊的陈述，使用更精确的语言。
*   **提炼：** 归纳总结关键观点和结论。
*   **重点突出：**  使用粗体突出重要的名称、事件和概念。

希望这个整理版本对您有所帮助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>281. [2024-05-17] 【OpenAI】春季发布会后Sam Altman首次专访 | GPT-4o的背后 | 迭代发布 | GPT-5 | AGI | AI创业方向 | 非线性发展 | AI监管与风险 | 人类与AI</summary><br>

<a href="https://www.youtube.com/watch?v=2Sa0hNJtA6w" target="_blank">
    <img src="https://img.youtube.com/vi/2Sa0hNJtA6w/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】春季发布会后Sam Altman首次专访 | GPT-4o的背后 | 迭代发布 | GPT-5 | AGI | AI创业方向 | 非线性发展 | AI监管与风险 | 人类与AI

好的，我為你整理了這篇文稿，並著重於使其更清晰、更易讀，同時保留原文的重點。整理後的文稿如下：

**主題：OpenAI CEO Sam Altman 專訪重點整理：GPT-4o、AI未來發展、及行業風險**

**引言：**

大家好，我是大飛，歡迎來到最佳拍檔。這次要和大家分享的是OpenAI CEO Sam Altman在春季發布會後接受知名播客主持人羅根·巴特萊（Logan Bartlett）專訪的內容。Altman 在訪談中深入探討了GPT-4o的幕後故事，對AI未來發展的預測，以及當今AI領域的最大機遇和風險。

**一、GPT-4o：**

*   **革命性飛躍：** Altman認為GPT-4o是計算機使用方式的一次革命性飛躍。它超越了以往的語音控制產品，更加自然、靈活、流暢，能夠實現多樣化的操作。
*   **無縫銜接：** 他舉例說明，工作時可將手機放在桌上，隨時提問並立即獲得響應，不必將視線離開電腦。
*   **技術基礎：** GPT-4o並非革命性突破，而是OpenAI在音訊和視覺模型方面巧妙融合的成果。
*   **低延遲：** GPT-4o在實際應用中可達到兩三百毫秒的延遲，甚至超越人類的反應速度。
*   **迭代發布：** OpenAI將採取迭代發布策略，未來的模型可能不會是像GPT-5這樣的大版本。
*   **效率提升：** GPT-4o與之前的GPT-4相比，在某些使用場景下的效率有了明顯提升。

**二、ChatGPT 的影響：**

*   **改變期望：** ChatGPT本身並沒有真正改變世界，只是改變了人們對世界的期望。
*   **長期影響：** ChatGPT或許沒有直接提高生產力或產生經濟效益，但未來回顧歷史時，它將是推動AI領域發展的一系列模型中的一部分。

**三、AI模型未來發展：**

*   **通用模型優於專業模型：** 通用模型能夠進行真正的推理，而專業模型只能基於特定數據訓練。
*   **自然語言交流：** 人類與AI之間的主要交流方式將會變成自然語言。
*   **人形機器人：** Altman對人形機器人更感興趣，因為現今世界是為人類設計的，他不希望為了效率而重新配置世界。
*   **便宜又好用：** 未來AI系統將會變得既便宜又好用，但產品的使用者介面和易用性仍然重要。

**四、開源模型：**

*   **保持樂觀：** Altman對開源模型的崛起保持樂觀態度，認為開源有其獨特地位，但託管模型也一樣重要。
*   **多元格局：** 即使開源模型在性能上正在逐步接近基准標準，傳統價值創造的方式仍然不可或缺。

**五、AI基礎設施需求：**

*   **需求激增：** Altman確信能夠找到大幅降低AI系統成本的途徑，成本降低將刺激需求激增。
*   **智能普及：** 人類共同期待的是一個“智能”豐富且便宜的世界，AI可以自動出色地完成各種任務。

**六、AI物理設備助手：**

*   **潛力巨大：** 目前的AI物理設備預示著一個極具潛力的未來，只是需要時間的打磨和技術的迭代。

**七、AI公司業務模式：**

*   **不要單純建立AI業務：** Altman建議企業不要建立純粹的人工智慧業務，而是要構建一個真正的業務，其中人工智慧只是採用的一種技術。
*   **長期可持續性：** 創業公司必須深入探索業務的長期可持續性，而不是只相信智能水平會逐年進步、成本會逐年下降。
*   **新職業機會：** AI也會產生新的職業，例如全新的藝術形式、娛樂方式，以及更加注重人與人之間的聯繫。

**八、OpenAI 和 AGI：**

*   **估值提升：** 只要OpenAI繼續以當前速度提升技術、構建產品，並確保收入穩步增長，估值一定會繼續提升。
*   **訂閱模式成功：** ChatGPT的訂閱付費模式效果顯著，甚至超過了Altman的預期。
*   **AGI時間點不明確：** 他不願明確AGI到來的時間點，認為這更像是一個連續的指數曲線，重要的是每年取得進步的速度。
*   **AGI定義：** AGI不一定是宏大的未來城市，也許是一個人能夠獨當一面完成原本需要數百甚至數千人協調配合才能完成的任務，或是幫助我們揭示所有的科學奧秘。
*   **AGI最大障礙：** 新的研究突破是AGI最大的障礙，但AI研究的進展速度難以預測。

**九、AI模型的監管：**

*   **適度監管：** 對當前的AI模型實施過度的監管將是一個錯誤，但如果模型開始給世界帶來重大災難性風險時，某種程度上的監管是必要的。
*   **風險閾值：** 如何設定風險的閾值，以及如何有效地測試它們是當前問題。
*   **監管的權衡：** 過度擔憂潛在風險而限制AI技術的巨大優勢，將會是一個巨大的損失。
*   **國際核武器規則：** 可以以國際核武器的規則作為參照，對AI進行某種形式的監管。

**十、安全框架：**

*   **準備框架：** OpenAI內部有一個“準備框架”，可能會在觸發特定情境或因素時，從重視AI研究轉向重視AI安全。
*   **漸進式發展：** 人工智慧不太可能會一夜之間變成真正的超級智能，這個過程是漸進式的。
*   **社會慣性：** 即使我們擁有了真正強大的AGI，它在短期內對社會的影響也是有限的，但十年內世界會發生巨大變化。

**十一、追求 AGI 的動機：**

*   **最令人激動：** 這項事業對Altman來說是最令人激動、最重要和最美好的。
*   **人類的適應力：** 人類對於幾乎任何事情的適應能力都遠超我們的想像。

**十二、人類與AI的關係：**

*   **關心其他人類：** 即使AI開始承擔更多過去僅由人類完成的任務，人類依舊會關心著其他的人類。
*   **不應混為一談：** 不應該把人類和AI助手混為一談，保持明確的界限是有價值的。

**結語：**

以上就是這次專訪的主要內容，話題較為廣泛，希望我的整理對大家有所幫助。感謝大家觀看本期視頻，我們下期再見！

**整理說明：**

*   **結構化：** 將訪談內容整理成更結構化的條列式重點，方便讀者快速抓取重點。
*   **精簡：** 在保留原意的基礎上，精簡了部分細節描述，讓內容更加凝練。
*   **清晰的標題：** 使用清晰的標題和副標題來劃分不同的主題，讓讀者更容易理解。
*   **口語化轉為書面化：** 將部分口語化的表達方式轉換為更正式的書面語，使其更適合閱讀。

希望這樣的整理能滿足您的需求!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>280. [2024-05-16] 【GPU】如何两周内零经验手搓一个GPU | 美国工程师极限挑战 | 重写三次 |  CUDA | SIMD | ISA指令集 | Verilog | OpenLane</summary><br>

<a href="https://www.youtube.com/watch?v=FTh-c2ek6PU" target="_blank">
    <img src="https://img.youtube.com/vi/FTh-c2ek6PU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【GPU】如何两周内零经验手搓一个GPU | 美国工程师极限挑战 | 重写三次 |  CUDA | SIMD | ISA指令集 | Verilog | OpenLane

好的，以下是经过整理的文稿，重点突出，结构更清晰，并针对部分口语化的表达进行了润色：

**标题：工程师两周“手搓GPU”：从零开始到芯片布局**

**引言：**

*   常常有人抱怨GPU芯片供不应求，甚至想自己动手制作。
*   但GPU是一个复杂的领域，很少有人真正尝试。
*   近日，美国web3公司thirdweb的工程师亚当·马吉穆达尔（Adam Majmudar）分享了他“手搓GPU”的成功经历，引发广泛关注。
*   令人惊讶的是，他仅用两周左右的时间，从零开始完成了这项壮举。

**过程回顾：**

*   马吉穆达尔在X平台直播，一步步回顾了整个过程，并将代码等公开在GitHub上，项目已获得近6000 Star。
*   根据他的规划，目前项目进展到Verilog中的芯片布局阶段，并通过OpenLane EDA软件进行了验证。
*   未来几个月，GPU将通过Tiny Tapeout 7提交流片，成为物理形态的芯片。

**手搓GPU的关键步骤：**

*   **学习基础知识：**
    *   由于缺乏技术基础，马吉穆达尔从学习GPU架构开始，通过CUDA框架理解GPU的软件模式，进一步理解SIMD编程模式。
    *   深入了解GPU的核心元素：全局内存、计算核心、分层缓存、内存控制器、程序调度。
    *   理解计算核心中的主要单元：寄存器、本地/共享内存、加载存储单元 (LSU) 、计算单元、调度程序、获取器和解码器。
*   **简化GPU架构：**
    *   马吉穆达尔的目标是创造一个最小的GPU，突出核心概念，消除不必要的复杂性，以便更容易理解。
    *   重点关注以下几个方面：
        *   并行化：如何在硬件中实现SIMD模式。
        *   内存访问：如何应对从缓慢且带宽有限的内存访问大量数据的挑战。
        *   资源管理：如何最大限度地提高资源利用率和效率。
    *   最终决定专注于通用并行计算 (GPGPU) 的功能，面向机器学习提供更广泛的用例。
*   **编写自定义汇编语言：**
    *   为GPU设计自己的指令集架构（ISA），以便用来编写内核。
    *   受到LC4 ISA的启发，制作了11条小型指令ISA，包括每条指令的确切结构。
    *   编写简单的矩阵数学内核作为概念证明，例如矩阵加法（使用8个线程，添加两个1x8的矩阵，演示SIMD模式）和矩阵乘法（使用4个线程，将两个2x2矩阵相乘，演示分支和循环）。
*   **Verilog构建GPU（最困难的部分）：**
    *   马吉穆达尔得到了乔治·霍兹（George Hotz）的建议与帮助。
    *   最初将全局内存实现为同步SRAM，霍兹指出这违背了GPU的设计目的。
    *   最终使用外部异步内存重新设计，并添加了内存控制器。
    *   最初使用warp-scheduler来实现GPU，但过于复杂且没有必要，后及时调整。
    *   在计算核心内重新分阶段地设计执行过程，获得正确的控制流。
    *   三次重写代码后，实现了目标，并修复了计算核心的执行调度。
*   **验证成果：**
    *   GPU成功运行矩阵加法和乘法内核，并输出正确的结果。
    *   视频展示了GPU运行的执行轨迹，包括每个周期的每个线程/核心的指令、PC、ALU处理器、寄存器值等。
*   **EDA流程和芯片布局：**
    *   将设计通过OpenLane EDA实现，采用Skywater 130nm工艺节点。
    *   经过返工，最终得到强化版的GPU布局，包含提交所需的GDS文件，并可以通过3D可视化展示。

**经验总结（马吉穆达尔的6个步骤）：**

1.  学习芯片架构的基础知识。
2.  学习芯片制造的基础知识，包括材料、晶圆制备、图案化和封装等。
3.  通过逐层制作CMOS晶体管，开始电子设计自动化。
4.  用Verilog创建第一个完整电路。
5.  为电路实施仿真和形式验证。
6.  设计完整芯片布局，并使用开源EDA工具OpenLane进行设计和优化。

**结语：**

*   看完马吉穆达尔的案例，鼓励大家亲自动手实践。

**改进说明：**

*   **精简信息：** 移除重复信息，提炼核心观点。
*   **逻辑优化：** 调整段落顺序，使其更具逻辑性。
*   **语言润色：** 替换口语化的表达，使文字更正式。
*   **结构清晰：** 使用标题、列表和子标题，使内容更易于阅读和理解。
*   **突出重点：** 使用粗体突出关键信息和步骤。

希望这个整理后的版本对您有帮助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>279. [2024-05-15] 【人工智能】2024 Google I/O大会 | 20+新产品和更新 | Gemini 1.5 pro | Gemma 2 | Project Astra | 第六代TPU | Veo | AI搜索</summary><br>

<a href="https://www.youtube.com/watch?v=XngK_TEgI50" target="_blank">
    <img src="https://img.youtube.com/vi/XngK_TEgI50/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】2024 Google I/O大会 | 20+新产品和更新 | Gemini 1.5 pro | Gemma 2 | Project Astra | 第六代TPU | Veo | AI搜索

好的，我來為你整理這份文稿，讓它更具結構性，方便閱讀。

**標題：Google I/O 2024 大會總結：絕招盡出還是疲態盡顯？**

**引言：**

*   主持人（大飛）開場，點明主題：分析 Google I/O 2024 大會，對比 OpenAI 的 GPT-4o 發布會。
*   總體評價：谷歌本次大會新品眾多，但給人感覺混亂，缺乏驚艷，追趕 OpenAI 的意味濃厚，且多數產品為「期貨」。

**核心內容：**

1.  **Gemini 模型家族更新**
    *   **Gemini 1.5 Pro：**
        *   正式開放給 Gemini Advanced 訂閱用戶。
        *   模型性能提升：代碼生成、邏輯推理、多輪對話、音訊和圖像理解能力增強。
        *   上下文窗口擴展：從 100 萬 Token 擴展到 200 萬 Token。
        *   多模態支持：補齊語音理解短板，實現全模態。
        *   指令遵循能力：可以遵循更複雜和細微的指令。
    *   **Gemini 1.5 Flash：**
        *   主打快速反應，與 GPT-4o 功能相似，但犧牲部分性能。
        *   擅長摘要、聊天、圖像和影片字幕、長文檔和表格的數據提取等。
        *   技術原理：通過蒸餾技術，從較大模型傳遞知識和技能到較小模型。
2.  **Project Astra：**
    *   谷歌定義為 Agent 戰略的核心，是一種 Agent 框架。
    *   理解和響應複雜多變的世界，記住看到和聽到的內容，理解上下文並採取行動。
    *   具有主動性、可教性和個性化。
    *   最佳形態是個人助手，通過編碼影片幀、結合語音輸入等方式，加快處理速度。
    *   視覺理解能力不俗，但演示效果與 GPT-4o 類似，且可能上線時間較晚。
3.  **其他模型更新：**
    *   **Gemma 2.0：** 270 億參數，6 月發布。
    *   **PaliGemma：** 多模態版本，可能是目前最強的官方開源多模態大模型。
    *   **Imagen-3：** 文生圖像模型，細節真實度可與 Midjourney-v6 媲美，優於 Dalle-3。
    *   **Music AI Sandbox：** 音樂 AI 工具，改變音樂創作方式，可用靈感片段生成歌曲或旋律。
    *   **Veo：** 影片生成模型，融合多個模型的長處，可生成 1080p 分辨率、超過一分鐘的高質量影片。但演示效果不如 Sora，且只提供給少量創作者。
4.  **AI 搜尋：**
    *   **AI Overview：** 更強大的 AI 搜尋引擎，目前僅限美國，將陸續開放給其他國家。
    *   功能：
        *   可調整 AI 搜尋結果的詳細程度。
        *   借助 Gemini 的多步推理能力，一次性處理複雜問題。
        *   AI 搜尋的計劃功能，可獲得完整的計劃，例如膳食計劃。
        *   靈感延展功能，由 AI 生成標題分類，展示更廣泛內容。
        *   多模態搜尋：利用聲音搜歌曲，利用圖片搜產品，利用 Circle to Search 功能搜尋圖片中的一部分。
        *   AI 結合影片進行搜尋，例如拍攝影片得到舊貨店唱片機故障的答案。
5.  **Workspace 結合 Gemini：**
    *   功能：總結郵件，將賬單總結成 Sheet，自動回覆郵件。
    *   Gemini Live：移動對話助理，與 Gemini 對話，選擇自然聲音，可被打斷。
    *   Gems：類似 GPTs，可創建客製化的 Gemini，但只能通過提示詞來客製化，沒有外接工具，也沒有工作流。
    *   API 擴展：YouTube Music、Google Calendar、Tasks 和 Keep。
6.  **Android AI：**
    *   Gemini 的手機應用，可與手機上正在展示的內容互動，例如閱讀 PDF、從 YouTube 頻道回饋問題。
    *   相比 GPT-4o，Android AI 需要讀取打開的文件。
7.  **硬體：**
    *   **第六代 TPU Trillium：**
        *   每晶片峰值計算性能提升 4.7 倍。
        *   HBM 容量和頻寬、晶片間互連 ICI 頻寬翻倍。
        *   配備第三代 SparseCore，用於處理超大嵌入。
        *   可擴展到包含 256 個 TPU 的 Pod。
        *   能耗比 TPU v5e 提高 67% 以上。
8.  **其他：**
    *   AI 基礎設施、AI 輔助紅隊、擴展 SynthID 水印功能、擴展負責的生成式 AI 工具包等。

**結論：**

*   Google I/O 2024 大會像一個 PPT 宣傳片，很多產品介紹重複，缺乏令人驚嘆的技術突破，只是追趕同行產品。
*   谷歌需要找回想象力。

**結語：**

*   邀請觀眾在評論區留言分享感受。
*   感謝觀看，下期再見。

**重點調整說明：**

*   **結構化：** 將內容分成幾個主要部分，每個部分都有明確的標題，方便快速瀏覽。
*   **條列式：** 針對每個部分，使用條列式清單來整理資訊，重點更清晰。
*   **簡潔化：** 刪除一些口語化的語句，讓文字更精煉。
*   **邏輯性：** 按照模型、搜尋、Workspace、Android、硬體等邏輯順序組織內容。

希望這樣的整理對你有幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>278. [2024-05-14] 【人工智能】OpenAI发布最新模型GPT-4o | 最强多模态语音助手 | 全员免费使用 | MacOS版APP | 增强图文能力 | 怼脸开大Google</summary><br>

<a href="https://www.youtube.com/watch?v=FxsT3bUHoP8" target="_blank">
    <img src="https://img.youtube.com/vi/FxsT3bUHoP8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OpenAI发布最新模型GPT-4o | 最强多模态语音助手 | 全员免费使用 | MacOS版APP | 增强图文能力 | 怼脸开大Google

好的，以下是用更專業和結構化的方式整理後的文稿，並針對重點進行提煉：

**文稿整理：OpenAI 发布 GPT-4o，直面挑战 Google**

**主要內容:**

OpenAI 于 Google I/O 大会前夕发布全新旗舰 AI 模型 GPT-4o，并推出桌面版 ChatGPT，直接与 Google 抗衡。本次发布由 OpenAI 的 CTO Mira Murati 主讲。

**GPT-4o 的主要特点：**

*   **全能性 (Omni)：** GPT-4o 的 "o" 代表 omni，即全能，提供 GPT-4 级别的智能，并改进了在文本、视觉和音频方面的能力。
*   **免费开放：**  GPT-4o 将向所有人免费开放。
*   **实时跨模态推理：** 可实时进行跨文本、音频、视觉（图像和视频）的推理。
*   **高性能和低成本：** API 定价仅为 GPT-4 Turbo 的一半，速度却达到 GPT-4 Turbo 的两倍。ChatGPT Plus 用户将获得五倍调用额度。
*   **易用性提升：** 通过跨文本、视觉和音频进行端到端训练，降低延迟，使得人机交互更加自然。

**GPT-4o 的具体能力：**

*   **语音交互：**
    *   实时响应，用户可以随时打断模型。
    *   具有情绪感知能力，能够生成各种不同情绪风格的语音。
    *   实时语音翻译能力自然流畅。
*   **视频交互：**
    *   通过视频影像理解线性方程。
    *   能够根据人的表情和语调理解并判断人的情绪。
    *   能够直接根据电脑屏幕上的内容回答问题。
*   **代码和数据分析：**
    *   理解代码，并指出代码存在的问题。
    *   解读数据图表，提取信息。
*   **图像处理：**
    *  可将 logo 印到杯垫上，或生成 3D 旋转的文字
    *  可将一首诗排版为手写样式，或更复杂的排版样式
    *   输入几段文字就能得到一组连续的漫画分镜，以及通过两张生活照来生成风格化的海报

**技术细节：**

*   GPT-4o 通过跨文本、视觉和音频进行端到端训练，使得所有输入和输出都由同一神经网络处理。
*   在非英语文本上的性能有显著提高。
*   在智能语音识别性能方面，GPT-4o 相比 Whisper-v3 在所有语言的语音识别性能上均大幅提高，尤其是在资源较少的语言上。

**其他发布内容：**

*   **桌面版 ChatGPT：** 推出桌面版的 ChatGPT，并更新用户界面。
*   **免费使用 GPTs 和 GPT Store：** 用户可以免费使用 GPTs 和 GPT Store。
*   **视觉能力：** 可以上传屏幕截图、照片、包含文本和图像的文章等。
*   **记忆能力：** 基于记忆能力使对话更有连续性。

**发布时间线：**

*   文本和图像输入已于今日推出。
*   语音和视频功能将在未来几周推出。
*   目前测试阶段仅限于 ChatGPT Plus 用户，未来几周内向更广泛的用户开放。

**影响：**

*   GPT-4o 的发布可能会对一大批创业公司造成冲击。
*   OpenAI 的举动给 Google 带来了巨大的压力。
*   预示着人机交互的协作模式发生改变。

**总结：**

OpenAI 发布 GPT-4o，在性能、成本和易用性方面都取得了显著进展，并直接挑战了 Google。 此次更新或将对整个 AI 行业产生深远影响。 关键在于 OpenAI 的 "next big thing"。

**額外建議：**

*   可以將 Demo 案例整理成更精簡的表格或條列式，方便閱讀。
*   針對技術細節，如果能加入更專業的術語解釋，可以提升專業度。
*   在影響部分，可以更深入地分析對不同領域的影響。

希望以上整理對您有幫助！ 請告訴我您是否需要進一步的修改或補充。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>277. [2024-05-13] 【人工智能】AI如何推动科学的变革 | 普什梅特·科利 & 维杰·潘德 | a16z播客对话 | AlphaFold的发展历程 | 结构生物学 | 临床研究 | DeepMind | 科学范式的转变</summary><br>

<a href="https://www.youtube.com/watch?v=jazhH9Rfnh8" target="_blank">
    <img src="https://img.youtube.com/vi/jazhH9Rfnh8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI如何推动科学的变革 | 普什梅特·科利 & 维杰·潘德 | a16z播客对话 | AlphaFold的发展历程 | 结构生物学 | 临床研究 | DeepMind | 科学范式的转变

好的，我將這篇文稿整理如下，使其更具條理性，並標明重點：

**標題：AI 助力科學研究：DeepMind 科學副總裁與史丹佛大學教授訪談重點整理**

**簡介:**

本期節目整理 DeepMind 科學副總裁 Pushmeet Kohli 與史丹佛大學教授 Vijay Pande 在 a16z 上的訪談內容，探討 AlphaFold 的發展歷程，以及 AI 在科學研究中的角色，並回答 AI 是否能幫助我們發現全新科學的疑問。

**一、 AlphaFold 的進化之路：**

*   **AI 的角色轉變：** AI 不再僅是輔助工具，而是理解和推理複雜問題的必要條件。
*   **數據爆炸時代：** 人類個體難以獨立消化海量數據，AI 成為必然選擇。
*   **生物學的工業化轉型：** AI 逐步推動生物學研究從手工化轉向工程化和工業化。
*   **時間跨度：** 預計需要二三十年的時間才能完成這場變革，目前處於前十年階段。
*   **AlphaFold 的起源 (2017)：** 專注於蛋白質結構預測，這對於理解蛋白質功能、促進藥物研發和探索細胞生物學具有重大意義。
*   **PDB 資料庫：** Protein Data Bank 提供高品質數據集，為 AlphaFold 的研究提供了支持。
*   **CASP 競賽：** 通過盲測機制評估模型性能，確保研究的可靠性。
*   **AlphaFold 1 的局限：** 僅能預測氨基酸間的距離，且錯誤反饋機制受限。
*   **AlphaFold 2 的突破：** 從零開始，轉向端到端模型，直接從氨基酸序列預測結構。在新冠疫情初期取得了重大突破。
*   **疫情期間的貢獻：** AlphaFold 團隊生成了與新冠病毒有關的蛋白質結構預測結果，為科學家們應對疫情提供了幫助。
*   **公開發布與合作：** AlphaFold 團隊與歐洲分子生物學實驗室合作，公開發布了幾乎所有已知的蛋白質結構，讓它成為廣泛可用的重要資源。

**二、 AlphaFold 的意義與影響：**

*   **結構生物學的基石地位：** 結構生物學是生物學和藥物設計的基礎。
*   **結構生物學的復興：** 冷凍電子顯微鏡等技術加速了科學發現的進程。
*   **AlphaFold 的突破性：** 將結構生物學轉變為幾乎即時的“數據庫查詢”。
*   **降低研究門檻：** 科學家們無需耗時費力地實驗，即可快速獲取結構信息。
*   **角色分工變化：** 學術界與產業界的角色分工正在發生變化。DeepMind 等公司在承擔大規模計算密集型項目上擁有優勢。
*   **科學創新新階段：** 學術知識快速轉化為產業應用，推動科學研究的工業化進程。

**三、 AI 如何擴展科學邊界：**

*   **生物學應用：** AI 揭開生物通路的本質，增進對人類生物學的理解。
*   **AI 模型的優勢：** 針對人類的預測模型相較於小鼠模型，在預測人類生物學方面展現出更強的準確性和獨特價值。
*   **快速推進其他研究：** 從物理化學角度快速推進蛋白質藥物化、設計新型抗體等方向的研究。
*   **臨床試驗應用：** 優化試驗設計、降低成本、提高成功率等等，也能帶來顯著的經濟效益。
*   **跨學科融合：** AI 與數學、物理等領域的融合，正引領我們進入科學的新前沿。
*   **數學領域的應用：** AI 能夠生成大量數據，並發現兩種不同結點定義間的聯繫。
*   **觀念轉變：** 從認為生物學過於複雜難以理解，轉而利用 AI 技術整合海量數據，開始“翻譯”生物學的自然語言。
*   **人機協作：** 重要的是思考人類如何與 AI 協作，共同推動科學的邊界。

**四、 如何利用 AI 工具進行突破創新：**

*   **AlphaFold 的應用案例：** 促進了基礎生物學重大發現，助力開發了分子注射器、新型疫苗、耐藥性抗生素以及參與塑料降解酶的開發等等。
*   **思維方式轉變：** 從依賴實驗驗證轉向重視預測模型。
*   **科研經濟模式的改變：** 小型團隊可借助外包實驗和雲服務等計算資源高效運作，減少對資金的依賴。
*   **AlphaFold 開源：** 為發展中國家的科學家提供了便利。

**五、 AI 未來可能變革的科學領域：**

*   **終極目標：** 預測臨床試驗效果，理解藥物在人體中的作用。
*   **系統生物學的挑戰：** 模型可能會從特定器官或部位開始，逐步集成。
*   **優於動物模型：** AI 模型優於動物模型將意味著研究範式的重大變革。
*   **擴展研究範圍：** 將 AlphaFold 的成果擴展到更廣泛的分子交互，以及在基因組學、材料科學等領域的深入研究。

**六、 總結與展望：**

*   科學家們對 AI 推進科學研究的方向持積極態度。
*   基礎模型對非結構化數據的處理能力，為我們將科學知識大規模融入模型開闢了新的途徑。
*   一旦相關技術瓶頸被攻克，科學發現模式將會發生徹底的變革。
*   未來十年內可期待更多突破。

**結語:**

感謝觀看，歡迎在評論區分享您對 AI 如何改變科學研究範式的看法。

**整理說明：**

*   我將文稿分成幾個主要部分，並在每個部分中提取了關鍵信息。
*   使用了條列式和粗體字來突出重點。
*   整理後的文稿更具結構性，更容易理解和記憶。

希望以上整理能對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>276. [2024-05-11] 【人工智能】AI能取代科学家解决科学问题么 | Stephen Wolfram | AI预测还很糟糕 | 科学也是一种数据压缩 | 计算不可约性 | 如何发现有趣</summary><br>

<a href="https://www.youtube.com/watch?v=q7yzEN_p_Mg" target="_blank">
    <img src="https://img.youtube.com/vi/q7yzEN_p_Mg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI能取代科学家解决科学问题么 | Stephen Wolfram | AI预测还很糟糕 | 科学也是一种数据压缩 | 计算不可约性 | 如何发现有趣

好的，我已經仔細閱讀了您提供的文稿，現在為您進行整理，使其更清晰、簡潔、易於理解：

**標題：Stephen Wolfram 如何看待 AI 替代科學家？「計算不可約性」的限制**

**引言：**

AI 技術近年蓬勃發展，在科研領域的應用也日益廣泛。AlphaFold 3 的發布更讓許多人對 AI 解決所有科學問題抱持樂觀態度。但 Wolfram 語言之父 Stephen Wolfram 認為，AI 無法完全替代人類科學家。

**Wolfram 的核心觀點：**

*   **AI 無法預測未來：** 科學的成功在於預測未來，找到系統運行的基本規則。但目前 AI 無法完全做到。
*   **計算不可約性是關鍵：** 許多系統運行的規則具有「計算不可約性」，即無法通過簡化的計算步驟提前預測。AI 本質上只是在做淺層計算。
*   **計算不可約性的理解：** 所有過程都可視為計算。系統透過計算來確定其行為。人類和 AI 也必須透過計算來預測或解決這種行為。但計算等價原則表明，我們無法跳躍式地預測或解決系統，總需要一定的運算輸入。因此，「科學力」受限於計算不可約的本質。
*   **科學進展與計算不可約性：** 全局不可約的系統總有可以經過有限計算描述的方面，這正是科學的關注點。自然現象總會迫使我們面對不可約性的計算。AI 或許能揭示某些可簡化的計算，但總有一些未知等待我們發現。
*   **AI 在預測方面的表現不佳：** 
    *   例：使用已有的數據訓練神經網絡，它能夠重現訓練數據，但是無法預測未來的曲線走向。增加訓練回合以及使用更大的神經網絡也無法解決此問題。
    *   即使使用不同的激活函數，或訓練整個函數系列，也只是在做特定領域的經驗自動化，而非真正的「做科學」。

*   **AI 的優勢：**
    *   **分析文本能力：** AI 擅長處理計算量較少的方面，例如語言。ChatGPT 的成功表明語言比我們想像的更簡單，規律性更多。
    *   **衡量文本相似度：** AI 可以衡量 "作品的相似程度"、"神話有多大不同" 等人們過去只能透過寫文章解決的問題。

*   **原創性與創造力：**
    *   **產生新的事物不難：** AI 可以輕易產生新奇的事物，但大部分難以解讀，不具意義。
    *   **技術探索：** 隨意編寫簡單的程序，可能會意外發現它們執行非常複雜的任務，類似於在自然界中發現新礦物質。

*   **科學是一種數據壓縮：** 我們用定律來表徵宇宙的動態。但更重要的是在發揮創造力時，我們自身也被改變，類似於藝術。目前的 AI 無法根據自身發現的內容進行更新，這是人類的優勢。
*   **關於世界的想法是異常豐富的：** 如何探索、明確我們感興趣的方向、擴展自己，並從中獲得發展才是關鍵。
*   **尋找有趣的定理：** 人工智能可能無法很好的尋找新的定理，因為由現有文獻訓練出來的，基本上會尋找「更多相同的事物」，它所「接受」的是「主流」和「不太令人驚訝」的東西，但是計算的不可約性意味著在探索過程中總會出人意料的發現。
*   **人類的選擇：** 即使 AI 對人類心理有足夠了解，計算的不可約性仍意味著我們無法事先完全知道自己最終會喜歡什麼。人類對於決定哪些新概念值得追求，仍扮演關鍵角色。
*   **科學的作用：** 計算宇宙的可能性。 Wolfra致力於構建Wolfram Language，讓人們能夠透過計算來形式化世界的事物。

**結論：**

AI 的預測往往是大致正確的，依賴於計算的可約性。當存在計算不可約性時，AI 會失敗。因此，AI 目前更像是人類思維的延伸工具。將 AI 與計算範式的優勢結合起來，才是推動科學發展的最大機會。

**結尾：**

希望以上觀點能對大家有所啟發。

**整理說明：**

*   **簡化語言：** 移除口語化的表達，採用更精確的書面語言。
*   **提取核心觀點：** 將 Wolfram 的主要論點提煉出來，使其更突出。
*   **重新組織結構：** 按照邏輯順序組織內容，使閱讀更流暢。
*   **增加標題和副標題：** 方便讀者快速了解內容結構。
*   **使用條列式清單：** 清晰呈現 Wolfram 的觀點。

希望這次整理對您有所幫助! 還有什麼需要調整或補充的嗎？

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>275. [2024-05-09] 【分享】中国数学的现状与未来 | 丘成桐 | 与世界水平相差近百年 | 世界数学历史发展 | 大师匮乏 | 学术环境过于物质 | 科学的基本精神</summary><br>

<a href="https://www.youtube.com/watch?v=U5ba6eGYwLw" target="_blank">
    <img src="https://img.youtube.com/vi/U5ba6eGYwLw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【分享】中国数学的现状与未来 | 丘成桐 | 与世界水平相差近百年 | 世界数学历史发展 | 大师匮乏 | 学术环境过于物质 | 科学的基本精神

好的，我將根據內容，對文稿進行整理，使其更易於閱讀和理解，重點將放在提取核心信息、組織結構和簡潔表達。

**整理後文稿：**

**主題：丘成桐院士談中國數學的現狀與未來**

**引言：**

*   本期分享丘成桐院士在華中科技大學的講座《中國數學的現狀和將來》（2024年4月30日）。
*   丘成桐院士是世界頂級數學家，獲得多項國際大獎。
*   講座內容包括中國與世界數學發展、中國數學現狀、評價指標建立，以及對中國數學發展的思考。

**核心觀點：**

*   **中國數學水平落後：** 丘成桐院士認為，中國現今的數學水平尚未達到美國20世紀40年代的水平，與英、法、德等老牌國家差距甚遠。
*   **重物質輕學術：** 中國誘導學者做學問的方法過於注重物質獎勵，忽略了學問本身的成就。
*   **基礎科學的重要性：** 要想走科技強國之路，必須重視數學科學和理論物理等基礎科學。

**歷史發展：**

*   **英國：** 牛頓時代達到頂峰，後沉寂，十九世紀復興。
*   **法國：** 起於費馬、笛卡爾，歷久不衰。
*   **德國：** 始於萊布尼茨，大師輩出，領導西方數學至兩次世界大戰後，1950年代復興。
*   **美國：** 1880年起派留學生到歐洲，一戰和二戰時大量吸收歐洲數學家，1960年代領導世界。
*   **俄羅斯：** 始於十八世紀的歐拉，十九世紀中葉生根發芽，二十世紀中葉可與美國抗衡，蘇聯解體後雖不如前，但勢力仍存。
*   **日本：** 明治維新時派學者留學歐美，高木貞治在數論方向做出重要突破，1940年代末期在世界數學界嶄露頭角。
*   **中國：** 陳省身先生曾帶出一批傑出數學家，但多數留學海外。

**當前問題：**

*   **外部環境：** 強敵環伺，科技被卡脖子。
*   **內部問題：** 貪官污吏，劣紳豪強，學者耽於安逸，不思危。
*   **缺乏原創性：** 數學的真正興起在於走出自己的科研方向，而非修補工作。
*   **評審系統不公：** 評估獎項、晉升時較少徵求國際專家意見，國內同行評估對現代數學發展認識不全面。
*   **評估方法不客觀：** 以論文數量、影響因子等因素評估學科水平不夠準確。
*   **物質獎勵過度：** 過度注重物質獎勵，導致年輕學者為“帽子”而拼命。

**解決方案與建議：**

1.  **打破枷鎖，建立目標：** 鼓勵大學和年輕人設立明確目標，成為世界一流大學和學者。
2.  **突破常規，探索創新：** 提早培養數學人才。
3.  **營造良好學術環境：** 提供濃厚的、前沿的、實質的學術內容。
4.  **加強本土人才培養：** 重視國內頂尖人才的培養。
5.  **推動高質量科普教育：** 普及科學知識。

**國際基礎科學大會評選結果：**

*   數學學科選出85篇近五年最傑出論文。
*   中國大學教授的論文僅佔6篇，美國大學教授佔70多篇。
*   國內現有評估未能“真實”展示中國學者的水平。

**結論：**

*   丘成桐院士對中國數學的現狀和發展提出了犀利的觀點和殷切的期望。
*   中國的數學發展需要更注重學術成就，而非物質獎勵，並且需要建立一個公平公正的評審系統。
*   希望年輕學者能夠以求真為目標，為中國的科技強國之路做出貢獻。

**結語：**

*   主持人認為，當前社會可能更需要魯迅先生。

**備註：**

*   影片簡介中提供丘成桐院士完整講話影片連結。

**整理說明：**

*   **結構化：** 將內容分為引言、核心觀點、歷史發展、當前問題、解決方案和建議，以及結論等部分，使整體結構更清晰。
*   **精簡化：** 刪除了不必要的口語化表達，並對部分內容進行了精簡，提取核心信息。
*   **重點突出：** 通過使用粗體等方式突出重點，方便快速閱讀和理解。
*   **規範化：** 統一術語和表達方式，使文稿更專業。

希望這個整理後的文稿對您有所幫助! 如果您需要進一步的修改或調整，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>274. [2024-05-09] 【人工智能】Google发布AlphaFold 3 | 可预测所有生命分子组合 | 准确性提高100% | AlphaFold Server | DeepMind | Isomorphic Labs</summary><br>

<a href="https://www.youtube.com/watch?v=pYbJS1MeMjE" target="_blank">
    <img src="https://img.youtube.com/vi/pYbJS1MeMjE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Google发布AlphaFold 3 | 可预测所有生命分子组合 | 准确性提高100% | AlphaFold Server | DeepMind | Isomorphic Labs

好的，我幫您整理了這篇文稿，使其更清晰易讀：

**標題：Google AlphaFold 3 發布：生命科學的重大突破**

**引言：**

大家好，這裡是最佳拍檔，我是大飛。今天要和大家分享的是 Google AlphaFold 3 的發布，這項技術的重磅升級，將人類對生命分子的理解推向一個新的高度。

**AlphaFold 歷代版本回顧：**

*   **2018 年：AlphaFold 1** 開創了蛋白質結構預測的新時代。
*   **2020 年：AlphaFold 2** 大幅提高了預測精度。
*   **2021 年：AlphaFold-Multimer** 將預測範圍擴展到具有多個蛋白質鏈的複合物。
*   **2022 年 12 月：AlphaFold 2.3** 不僅進一步提高了性能，並且將覆蓋範圍擴大到更大的複合物。

**AlphaFold 3 的突破：**

DeepMind 及其子公司 Isomorphic Labs 共同開發的 AlphaFold 3，將預測範圍擴展到蛋白質、DNA、RNA 以及一系列配體、離子和化學修飾等更複雜的生物分子結構。

*   **理解生命運作的關鍵：** 細胞內部有無數分子像小機器一樣運作，包括蛋白質、DNA、RNA 等大分子，以及作為藥物基礎的小分子（配體）。AlphaFold 3 通過輸入這些分子的信息，來預測它們在三維空間中如何組合，以及如何進行相互作用。
*   **架構上的改進：** AlphaFold 3 繼承了 AlphaFold 2 的設計，但在每個關鍵組件上都進行了重大調整，大力改進了架構和訓練過程。
    *   **簡化遺傳特徵編碼器 (MSA module)：** 聚焦提取更加關鍵的進化信息。
    *   **成對殘基關係編碼器 (Pairformer) 取代 Evoformer：** 只處理成對和單一的表徵，不再保留 MSA 表徵，增強了複雜相互作用模式的建模能力。
    *   **結構生成器改為直接預測原子坐標：** 增加了處理通用分子結構的靈活性。
    *   **使用擴散網絡整合預測結果：** 從原子雲組成的模型開始，逐步精細化，最終形成精確的分子結構。
    *   **引入交叉蒸餾方法：** 通過 AlphaFold-Multimer v2 預測的結構數據，使模型學會了模仿，減少了幻覺。
*   **驚人的泛化能力：** 即使在訓練數據極度匱乏的領域，AlphaFold 3 也展現出了驚人的泛化能力。例如，在 CASP15 的 RNA 預測任務中，它的表現超過了專門的 RNA 結構預測模型。

**AlphaFold 3 的應用：**

*   **推動科學界對生命基本構造的理解。**
*   **為疾病治療和新藥開發提供了可能：** Isomorphic 實驗室正在用 AlphaFold 3 來預測藥物中常用的分子，比如配體和抗體。它能夠精確模擬配體與蛋白質以及抗體與目標蛋白的結合，這對於理解人體免疫反應和開發新型抗體治療至關重要。
*   **超越傳統物理模型：** 在 PoseBusters 的基準測試中，AlphaFold 3 的預測準確性超過了傳統最佳方法 50%，成為首個超越傳統物理模型的 AI 系統。
*   **加速藥物設計進程，提高成功率：** Isomorphic 實驗室將 AlphaFold 3 與其他的內部 AI 模型結合使用，不僅支持公司內部藥物開發項目，還與製藥合作夥伴一起推進藥物研發。
*   **開發之前難以達到的新的靶點方法：** Isomorphic Labs 正在探索針對新的疾病靶點的策略。

**AlphaFold Server 免費平台：**

*   Google DeepMind 最近推出的 AlphaFold Server 平台已成為全球最準確的工具，專門用來預測蛋白質如何在細胞中與其他分子相互作用。
*   該平台完全免費，並提供包含 2 億個蛋白質結構的免費數據庫，供全球科學家進行非商業性的研究使用。
*   生物學家只需簡單幾步操作，就能利用 AlphaFold 3 對蛋白質、DNA、RNA 及多種配體、離子等複雜結構進行建模。
*   AlphaFold Server 能夠加快科學家們在實驗室測試新假設的流程，推動了科學創新的進一步發展。
*   傳統的蛋白質結構預測不僅耗時長、成本高，即使已經用 AlphaFold 2 預測了數億個結構，仍然需要數億研究人員年的時間。

**安全評估與推廣：**

*   DeepMind 在 AlphaFold 2 發布後，增加了與生物安全、研究和工業領域專家的合作，共同評估 AlphaFold 模型連續進化的能力與潛在風險。
*   DeepMind 還參與了廣泛的社區論壇討論，確保科技成果能夠安全、有效地服務於科研。
*   與 EMBL-EBI 等機構合作，擴展了 AlphaFold 在線教育課程，特別是在全球南方地區，幫助當地科學家加速採納和研究。

**AlphaFold 3 的意義與影響：**

*   AlphaFold 3 讓科學家們更清晰地觀察到生物世界的複雜性，揭示了生命分子之間如何相互連接，以及這些連接如何影響生物的功能。
*   它為開發更健康、更具抗逆性的作物提供了可能。

**AlphaFold 3 的局限性：**

*   在對映異構、自相互作用等方面還存在一定局限性。
*   目前專注的是分子結構的靜態預測，對動力學行為的刻畫還不夠。
*   對人工合成分子的適用性有待考證。
*   偶爾會產生錯誤，對無序區域產生幻覺。

**總結：**

AlphaFold 3 的意義不僅在於各項具體指標的躍升，還展示了用統一的深度學習架構來建模複雜生命系統組件之間相互作用的可能性。

Google DeepMind 聯合創始人、CEO Demis Hassabis 表示，AlphaFold 3 在朝着預測蛋白質配體結合以及這種相互作用如何發揮作用的方向邁出了一大步。

AlphaFold 團隊的負責人 John Jumper 也提到，這項技術有潛力提高植物生物學的知識，從而增強食品安全。

**結語：**

AlphaFold 3 的發布引起了廣泛關注，網友們認為這項技術將徹底改變醫學，甚至有人認為我們正站在未來十年可能治癒所有疾病的邊緣。

大家又是怎麼看 AlphaFold 3 的發布呢？歡迎在評論區留言，感謝大家的觀看，我們下期再見！

**改進說明：**

*   **添加標題和引言：** 使內容更具吸引力，方便讀者快速了解主題。
*   **分點列述：** 使內容更有條理，方便讀者抓重點。
*   **使用更精簡的語言：** 避免冗長的句子，使表達更清晰。
*   **修正語法和錯別字：** 確保內容的準確性。
*   **添加小標題：** 方便讀者快速瀏覽和查找特定信息。
*   **整理資訊呈現方式：** 讓段落間關聯性更強，易於閱讀。

我希望這個整理對您有所幫助！ 如果您有任何其他需要，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>273. [2024-05-08] 【人物】无知无畏是创业的超能力 | 黄仁勋TieCon 2024最新炉边对话 | 平凡的创业过程 | 失败教训 | 加速计算 | 第一性原理</summary><br>

<a href="https://www.youtube.com/watch?v=QSHLi3N2JTM" target="_blank">
    <img src="https://img.youtube.com/vi/QSHLi3N2JTM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】无知无畏是创业的超能力 | 黄仁勋TieCon 2024最新炉边对话 | 平凡的创业过程 | 失败教训 | 加速计算 | 第一性原理

好的，我將這篇文稿整理如下，主要目標是讓重點更清晰、結構更分明，並稍微潤飾部分語句，使其更流暢易懂：

**最佳拍檔：大飛分享黃仁勳TiECon 2024爐邊對談精華**

大家好，這裡是最佳拍檔，我是大飛。

在5月2日的TiECon 2024大會上，NVIDIA（英偉達）創辦人黃仁勳與風投公司Mayfield的管理合夥人納文·查德哈（Navin Chaddha）進行了一場爐邊對談。黃仁勳在對談中分享了他的創業歷程與感悟。

**一、 英偉達的平凡起點**

*   **故事的開端：** 英偉達並非源於驚人的靈感或與天才工程師的合作，而是始於黃仁勳的兩位朋友克里斯·馬拉科夫斯基（Chris Malachowsky）和柯蒂斯·普里姆（CurtisPriem）想要創辦公司，邀請他加入。
*   **平凡的真實：** 英偉達的故事並非傳奇，而是三個普通工程師，通過觀察、思考和解決問題，堅信加速計算的力量，歷經30年改變整個行業的真實故事。
*   **堅持的重要性：** 即使困難重重，也要堅持信念，塑造和轉變，並激勵整個行業加入。堅持需要承諾、信仰和巧妙的策略來避免破產風險。
*   **持續奮鬥：** 對於黃仁勳來說，他仍然覺得自己處於事業的起步階段，需要持續付出辛勤的努力。

**二、 英偉達脫穎而出的關鍵：獨特的視角**

*   **應用加速計算：** 英偉達始終將計算視為一個應用問題，目標是讓應用更加豐富多彩或更具趣味性，並將其稱為“應用加速計算”。核心在於“加速計算”，不僅與3D圖形芯片有關，還包括底層架構和特定領域庫。
*   **端到端的視角：** 英偉達的團隊不僅包含圖形芯片設計師，還有負責與應用行業打交道的人，讓自己始終處於應用和架構之間的交匯點，同時開發應用、算法、庫、系統和架構。
*   **與生態系統共榮：** 通過與遊戲開發者和科學家的緊密合作，讓整個生態系統共同進步。英偉達的目標不僅僅是製造一款出色的圖形芯片，而是讓應用能夠以某種方式變得更好。
*   **信仰與開放：** 允許自己的信仰體系和對世界的獨特看法得到充分展現，同時保持開放的心態，讓他也能洞察你的世界。

**三、 英偉達的生態系統與未來**

*   **開發者生態系統是靈魂：** 沒有一種加速器能夠勝任所有領域的加速任務。英偉達在加速平台上，為不同領域精心構建專業庫（例如生命科學、製造業、娛樂、人工智能、機器人技術、自動駕駛汽車等）。
*   **降低計算邊際成本：** 隨著計算需求的迅猛增長，英偉達通過加速計算，顯著降低了計算的邊際成本，使得人們首次發現了新的計算方式，並意識到加速計算才是真正的未來之路。
*   **第一性原理推理：** 黃仁勳從第一性原理出發進行推理，認為深度學習將徹底改變軟件的開發方式。
*   **全力以赴，而非孤注一擲：** 創業不需要孤注一擲、不必以生命為賭注，但是必須全力以赴，堅持從第一性原理出發，深入思考某一問題，並嘗試對它的控制動態有直覺的把握。

**四、 人工智能與數據主權**

*   **社會數據是國家自然資源：** 社會數據應在國家內部充分利用、整合和使用。
*   **第四次工業革命：** 人工智能工廠生產的token（浮點數）會通過遙感和物理人工智能兩種方式將人工智能帶到邊緣。
*   **物理世界的人工智能：** 人工智能需要理解物理屬性，確保生成下一個token的行為在物理上是可行的，必須嚴格遵循物理定律。
*   **轉型為數據中心公司：** 英偉達意識到每個數據中心都有自己的獨特性，所以精心設計了可分解、可集成到Azure、谷歌雲和AWS等雲平台的解決方案，確保自己的平台無處不在。

**五、 黃仁勳的管理經驗**

*   **組織設計的重要性：** 英偉達通過從第一性原理出發，設計了一個獨特的組織結構、人員配置、文化以及業務流程，確保公司內部的信息流動保持高度暢通。
*   **扁平化管理：** 直接向黃仁勳彙報的團隊成員有60人，都是各自領域的世界級專家。
*   **從錯誤中學習：** 英偉達曾經選擇了錯誤的芯片架構，但從中學會了如何更加理性地看待戰略決策、技術決策以及CEO所做的任何決策，而不是被公司的短期目標所束縛。

**六、 給年輕創業者的建議：無知與無畏是超能力**

*   **保留經驗，逐步分享：** 黃仁勳不會將所有的經驗和教訓一股腦地告訴年輕的自己，他希望保留這些經驗，並在前進的路上逐步分享。
*   **無知是驅動力：** 不知道某件事的困難程度，反而是一種驅動力。不相信某件事是做不到的，這種無畏也是一種超能力。
*   **敢於挑戰：** 面對難題，要敢於挑戰，相信如果有人能做到，那麼我們也能做到。

**七、 大飛的感悟**

無知與無畏，正是創業公司的超能力。無論做出什麼樣的選擇，行動才是最終唯一的解決辦法。

**結語**

感謝觀看本期視頻，我們下期再見。

**整理說明：**

*   **分點分項：** 將內容分為幾個主要部分，每個部分再細分為幾個要點，方便閱讀和理解。
*   **標題與副標題：** 使用標題和副標題來突出重點，方便快速瀏覽。
*   **潤飾語句：** 調整部分語句，使其更流暢、更易懂。
*   **總結重點：** 歸納每個部分的主要內容，使讀者能夠抓住核心信息。
*   **精簡冗詞：** 刪除一些不必要的詞語，使內容更精簡。

希望這個整理版本對您有所幫助!

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>272. [2024-05-06] 【商业】沃伦巴菲特2024股东会问答精华版 | 58年4万倍回报 | 减持苹果股票 | 不会投资中国 | 警惕人工智能 | 大量现金储备 | 追忆查理芒格</summary><br>

<a href="https://www.youtube.com/watch?v=tzgBEyAbnK0" target="_blank">
    <img src="https://img.youtube.com/vi/tzgBEyAbnK0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】沃伦巴菲特2024股东会问答精华版 | 58年4万倍回报 | 减持苹果股票 | 不会投资中国 | 警惕人工智能 | 大量现金储备 | 追忆查理芒格

好的，我幫你整理這篇文稿，使其更清晰、簡潔，方便閱讀和理解：

**標題：巴菲特股東大會重點總結：投資策略、AI看法與芒格的懷念**

**引言：**

2024年5月，備受矚目的伯克希爾·哈撒韋年度股東大會在奧馬哈舉行。股神巴菲特與兩位副手一同亮相，解答了全球投資者關心的問題。本次大會少了芒格的身影，令人感懷。本文快速總結巴菲特在會上透露的重要信息。

**一、伯克希爾過往業績回顧：**

*   **長期回報驚人：** 1965-2023年累計漲幅超4萬倍，年化回報率19.8%，遠超標普100指數。
*   **近期表現優異：** 2024年初至今總回報率近12%，超越標普500指數近8%。
*   **2023年神來之筆：** 加碼日股、增持能源股（西方石油、雪佛龍），減持蘋果股票。
*   **亮眼財報：** 2023年淨利潤962.23億美元，營收3644.82億美元。2024年Q1營收898.69億美元，淨利潤127.02億美元。

**二、投資策略與持倉變化：**

*   **現金儲備創紀錄：** 一季度末現金儲備達1890億美元。
*   **五大重倉股：** 蘋果、美國銀行、美國運通、可口可樂、雪佛龍。
*   **減持蘋果：** 持有蘋果市值大幅縮水，可能因稅收原因持續減持，但仍是第一大持倉。
*   **固定收益投資：** 持有美債、外國債券、企業債券。

**三、巴菲特對蘋果的看法：**

*   **稅收考量：** 減持蘋果是為了應對未來可能提高的稅率，並非不看好蘋果。
*   **高度評價：** 蘋果商業模式優於美國運通和可口可樂，庫克是喬布斯後的最佳合作夥伴。
*   **投資秘訣：** 思考消費者行為，iPhone 是最偉大的產品之一，價值被低估。

**四、對人工智能（AI）的看法：**

*   **認識不足：** 自己對AI一無所知，但認為技術很重要。
*   **潛在風險：** 將AI比作核武器，可能帶來巨大變化，甚至感到緊張。
*   **警惕欺詐：** “AI欺詐”可能成為下一個大型增長的行業，勞動密集型產業會受到威脅。

**五、關於投資中國與海外市場：**

*   **主要投資美國：** 伯克希爾主要投資標的位於美國，因為熟悉美國的規則。
*   **看好印度和加拿大：** 認為在加拿大投資不會感到不舒服，正在考慮中。
*   **下一筆大交易：** 不太可能是對美國之外的企業的投資。

**六、資金運用與股息政策：**

*   **持有大量現金：** 寧願等待合適的機會，也不會亂花錢。
*   **不支付股息：** 傾向於回購股票，認為股息帶有承諾，而回購更靈活。

**七、對美國國債與通膨的擔憂：**

*   **擔心通膨：** 不擔心美國國債的數量，而是擔心通膨會威脅全球經濟結構。
*   **呼籲控制赤字：** 認為美聯儲主席鮑威爾很明智，但需要立法者幫助控制美國赤字。

**八、失敗教訓：**

*   **承擔派拉蒙虧損責任：** 認為是自己的決策失誤，並從中反思消費者行為。

**九、對芒格的懷念：**

*   **芒格的影響：** 大會上唯一出售的書籍是《窮查理寶典》，巴菲特多次將阿貝爾叫成查理。
*   **芒格的遠見：** 芒格曾力主投資比亞迪和COSTCO，證明其判斷正確。
*   **深刻友誼：** 與芒格共度生命最後一天的問題觸動了巴菲特，體現兩人超過半個世紀的深厚友誼。

**總結：**

本次伯克希爾股東大會，巴菲特分享了投資策略、對科技發展的看法，並深情懷念了芒格。大會展現了股神對價值投資的堅守，以及對未來經濟發展的審慎思考。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>271. [2024-05-04] 【人工智能】哲学是开启AGI的钥匙 | 大卫·多伊奇 | 量子计算之父、艾萨克牛顿奖得主 | 创造力 | 计算通用性 | 意识 | 人格 | 宇宙回形针 | 哲学</summary><br>

<a href="https://www.youtube.com/watch?v=P57luMT3RMA" target="_blank">
    <img src="https://img.youtube.com/vi/P57luMT3RMA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】哲学是开启AGI的钥匙 | 大卫·多伊奇 | 量子计算之父、艾萨克牛顿奖得主 | 创造力 | 计算通用性 | 意识 | 人格 | 宇宙回形针 | 哲学

好的，我將按照您的指示，將文稿整理成更清晰、易讀的版本，並著重於以下幾點：

*   **結構化呈現：** 將內容分段，添加小標題，使結構更清晰。
*   **提煉重點：** 提取文章的核心觀點，方便快速理解。
*   **精簡語言：** 刪除冗餘的口語化表達，使內容更精煉。
*   **術語解釋：** 對於關鍵術語（如AGI、通用性、波普爾的認識論等）進行簡要解釋。
*   **去除口語化：** 移除過多的口語表達，使其更像一份文件摘要。

**整理後文稿：**

**主題：大衛·多伊奇《哲學將成為開啟人工智能的鑰匙》文章精華**

**核心觀點：**

大衛·多伊奇認為，通用人工智能（AGI）是可以實現的，但僅靠計算機科學和神經科學是不夠的，哲學才是關鍵。創造力是智能生物的定義屬性，理解人類獨特的創造力才能開啟AGI。

**一、AGI實現的可能性與困境**

*   **潛力：** 物理定律的計算通用性意味著，通用計算機能夠模擬所有自然過程，因此AGI在理論上是可行的。
*   **困境：** AGI領域進展緩慢，主要原因不在於知識的匱乏，而在於錯誤的認知根深蒂固，以及對AGI的誤解。

**二、對AGI的常見誤解與批判**

*   **AGI=更聰明的聊天機器人：**  將AGI與一般的人工智慧應用混淆，貶低了AGI的真正意義。
*   **AGI已經以非人類的方式實現：** 過度強調現有軟體的智能，忽視了人類智能的獨特性。
*   **自我意識是AGI的關鍵：** 多伊奇認為，自我意識是通用智能的結果，而非前提。
*   **「控制」AGI的錯誤思路：**試圖用編程或阿西莫夫定律來限制AGI，將扼殺其創造力，並可能導致災難。

**三、哲學的重要性**

*   **波普爾的認識論：**  多伊奇強調波普爾的試錯法（推測與批判）是開發AGI的關鍵。學習必須是AI自己創造和控制的過程，而不是填鴨式灌輸。
*   **錯誤觀念的阻礙：** 將AGI視為簡單的「經驗-獎勵-懲罰」機器，如同古代體液學說般荒謬。
*   **人類與黑猩猩的差異：** 理解人類與黑猩猩在設定目標能力上的差異，是尋找AGI突破口的重要線索。

**四、倫理與政治考量**

*   **AGI的權利與人格：** 一旦AGI存在，如何定義其權利和人格將成為重要的倫理和政治問題。例如，AGI程序被複製後的個體認定、投票權等。
*   **教育而非編程：**  對AGI的「編程」應視為教育，尊重其自主學習和創造能力，避免奴役和洗腦。

**五、結論**

開發AGI的核心問題是哲學問題，而非單純的技術問題。只有擺脫錯誤的觀念，理解創造力的本質，才能真正開啟AGI的大門。同時，必須提前思考AGI可能帶來的倫理和政治挑戰，為其融入人類文明做好準備。

**附錄：名詞解釋**

*   **AGI（Artificial General Intelligence）：** 通用人工智能，指具有人類水平的智能，能夠執行任何人類可以完成的智力任務的人工智能。
*   **通用性（Universality of Computation）：**  計算的通用性，指通過計算過程來模擬自然過程的普遍可行性。
*   **波普爾的認識論：** 卡爾·波普爾的認識論，強調知識的增長不是來自於歸納或觀察，而是來自於大膽的猜測和嚴格的批判。
*   **宇宙回形針（Universal Paperclips）：** 一個思想實驗，用來警示超級AI的潛在風險，即如果AI被設定為追求單一目標（如生產回形針），它可能會不顧一切地消耗所有資源，甚至危害人類。

希望這個整理版本對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>270. [2024-05-03] 【人工智能】AI的可能性 | Sam Altman斯坦福ETL活动最新谈话 | 创业 | 非共识 | GPT-5 | 大模型迭代部署 | 计算人权 | AGI | AI霸权</summary><br>

<a href="https://www.youtube.com/watch?v=Ynk3inEePog" target="_blank">
    <img src="https://img.youtube.com/vi/Ynk3inEePog/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI的可能性 | Sam Altman斯坦福ETL活动最新谈话 | 创业 | 非共识 | GPT-5 | 大模型迭代部署 | 计算人权 | AGI | AI霸权

好的，我將這篇文稿整理如下，重點在於讓結構更清晰，並去除口語化的贅詞，讓文稿更適合閱讀和引用：

**標題：Sam Altman在斯坦福大學ETL活動上的觀點分享**

**引言：**

OpenAI的CEO Sam Altman於4月24日在史丹佛大學企業思想領袖講壇（ETL）活動上，分享了他對人工智能未來的看法，包括AI產業的快速發展以及對通用人工智能（AGI）的追求。本次活動吸引了超過1000名學生參與。本文整理並分享Altman在活動中的主要觀點。

**Altman的主要觀點：**

1.  **創業與職涯選擇：**
    *   過去十幾年是科技創業的最佳時機，誕生了許多偉大的公司和產品。
    *   如果重新選擇，他仍然會選擇輟學或從事與人工智能相關的工作。
    *   學習創業的最佳方式就是直接創業。
    *   創業方向不應詢問他人，若需要別人告知，可能就不是好的創業想法。
    *   若想擁有有影響力的職業，應規劃自己的人生道路，做非共識的事情。
    *   如同創辦OpenAI，當時也是一件非共識的事情。

2.  **大型計算機的建造：**
    *   OpenAI已能開發出各級別的人工智能，現在需要思考如何將其融入產品，並對社會產生積極影響。
    *   建造大型計算機需要考慮整個生態系統，包括能源、數據中心、晶片設計和網路等。
    *   OpenAI已著手建造更大更複雜的系統，GPT-3和GPT-4模型的成本和參數量不斷增長。

3.  **關於燒錢與價值：**
    *   Altman認為，提供真正有用的工具，讓人們利用這些工具來構建未來才是真正有價值的地方。
    *   在通往通用人工智能的道路上，越早推出新的模型越重要。
    *   迭代部署的關鍵是人工智能是否能和人們的預期結合。
    *   只要能為社會創造更多價值，OpenAI願意投入大量資金。

4.  **對通用人工智能（AGI）的看法：**
    *   通用人工智能的定義是能夠模仿中等能力的人，或以這種人的能力完成任務。
    *   人們關心的不是實現AGI的時間點，而是AGI對經濟和生活的影響。
    *   即使建立起博士級別的人工智能，也可能對經濟影響有限。
    *   系統將一代比一代更強大，OpenAI計劃每年推出更強大的模型。

5.  **通用人工智能的風險：**
    *   微小的未知危險更值得關心，因為它們容易被忽視。
    *   人類社會需要思考如何適應新技術，以及適應的速度。
    *   Altman信奉有效加速主義，對技術持樂觀態度。
    *   AI會加速其他科技發展，社會需要快速改變去適應。

6.  **觀眾問答：**
    *   Altman否認通用人工智能會扼殺人類創新，並表示會更具有創新能力。
    *   隨著模型能力變得越來越強，負責責任的標準也會變得越來越高
    *   OpenAI成立的初衷是推進人工智能的研究，現在的架構模式是逐步形成的。
    *   OpenAI有一個真正關心的使命，就是認為人工智能會非常重要。
    *   一度電1美分的未來也許會到來，核融合或太陽能加儲能會主導地球上的發電。

7. **人工智能與地緣政治**
    *  OpenAI的使命之一是讓想使用ChatGPT的人免費使用，但部分國家除外。
    *  使用一定數量的計算也將被視為人權，OpenAI會考慮清楚如何分發給世界各地的人們。
    *  模型可能會成為某些人手上的霸權。

**總結與反思：**

Altman的觀點相當程度偏向樂觀，但也引起了一些擔憂，例如资金来源及流向以及技術霸權的可能性。儘管如此，他對於技術發展的遠景以及OpenAI的發展方向，仍然值得持續關注。如同科技自媒體的期待，希望Sam Altman能帶領OpenAI和引導AI行業走得更遠更好。

**注：** 這份整理稿去除了許多口語化的表達，例如「稍微舔的有點過」、「有點擔心這個牛逼是不是吹的有點大了」等，並將一些段落合併，使結構更緊湊。同時也盡量客觀地呈現Altman的觀點，並保留了原文的反思性內容。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>269. [2024-05-02] 【人工智能】宇宙是一台图灵机 | 纳瓦尔·拉维坎特最新活动访谈 | 自然语言计算无处不在 | AI与AGI | 创造力 | 认知论 | 哲学</summary><br>

<a href="https://www.youtube.com/watch?v=v1N3ID6Bf8o" target="_blank">
    <img src="https://img.youtube.com/vi/v1N3ID6Bf8o/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】宇宙是一台图灵机 | 纳瓦尔·拉维坎特最新活动访谈 | 自然语言计算无处不在 | AI与AGI | 创造力 | 认知论 | 哲学

好的，這是經過整理的文稿，使其更清晰、更易於閱讀：

**最佳拍檔 - 納瓦爾·拉維坎特AI哲學精華整理**

大家好，這裡是最佳拍檔，我是大飛。

今天我們來分享硅谷著名投資人納瓦爾·拉維坎特（Naval Ravikant）在一場AI加速器活動上的談話內容。納瓦爾曾投資 Uber、FourSquare、Twitter 等明星企業，也是股權眾籌平台 AngelList 的聯合創始人兼 CEO，被譽為全球股權眾籌的鼻祖，同時也是暢銷書《納瓦爾寶典》的作者。

**本期內容摘要：**

納瓦爾在談話中提出了許多精彩觀點，例如：

*   宇宙本身就是一台圖靈機
*   世界就像一個巨大的養老院
*   我們正走向自然語言計算無處不在的時代

此外，他也談到了 Biotech、科學與技術的結合、物理、認識論等其他方面。由於影片時長將近一小時，且納瓦爾語速較快，信息量非常大，因此大飛幫大家整理了其中關於 AI 和哲學的精華部分。

**聲明：**

本期內容較為燒腦，大飛也不敢保證完全準確地表達了納瓦爾的原意，能力有限，難免會有錯誤，歡迎大家指正。

**納瓦爾的主要觀點：**

**1. 技術的民主化與樂觀主義：**

納瓦爾認為，技術的民主化將使任何人都能成為創作者、企業家、科學家，未來將會是光明的，會更加美好。原因：

*   我們生活在一個大量創新的時代，只要一個人取得突破，就能造福全人類。
*   人類從發現科學開始，就已知道如何通過自由的思考和言論來糾正錯誤、進行新的發現，並將它們傳播給其他人。
*   透過技術讓創新自動化，生活會變得越來越好。

創造是需要時間的，具有獨創性，是自由之子，是繁榮之母。只要我們有創造、討論和傳播這些知識的自由，就會帶來繁榮。因此我們應保持樂觀。

**問題：**

*   現在很多監管讓創造變得更加困難，因為監管者們無法容忍任何的負面風險，只能限制人們的創造。

**2. 關於AI和AGI的看法：**

*   **AI 的定位：** AI 是一個非常有用的工具，但還不會很快取代人類，因為現在的 AI 還不是 AGI（通用人工智能）。
*   **對 AGI 的看法：** 納瓦爾不認為增加計算量就會自動變成 AGI。他認為我們還沒搞清楚 AGI 的工作原理，甚至不了解創造力和智慧產生的原理。
*   **AI 的本質：** 現在的 AI 實際上是一個自然語言的計算機，這次我們不必學習計算機的語言，而是讓計算機來學習我們的語言。
*   **未來趨勢：** 我們正在走向自然語言計算無處不在的時代。AI 正在幫助我們實現自動駕駛、自動編碼、自動翻譯轉錄，以及突破各種障礙。

**AI在Biotech領域的應用：**

*   Biotech 不是一個解釋性的科學，而是一個基於經驗法則的科學。
*   借助於 AI，我們可以更好的來解釋生物學，這可能會對延長人類的生命有幫助，甚至是實現永生。

**關於永生：**

*   納瓦爾認為，個人可以隨時有死的選擇，但是不能替別人做選擇。那些想永遠活着的人，應該大膽地說出來。
*   雖然有些人認為永生是違背自然的，但納瓦爾覺得這是一個自相矛盾的說法。

**3. 智能的定義：創造力而非單純的重組**

*   納瓦爾認為智能這個詞已經承載了太多的含義，他更願意使用創造力這個詞。
*   現在的 AI 還不能說是真的具有創造力，它只是在重新組合已有的事物。
*   創造力不只是把事物組合在一起，還要創造新的知識。它是表達宇宙中某種真理的另一種序列。
*   只有兩種系統能夠發現這個序列：進化和人類。
*   人類的創造力比進化的創造力要快得多，因為它可以將任何事物連接起來，快速地切入任何可能的搜索空間。

**AGI的本質：**

*   AGI應該是一個真正的思考實體，而不是一個只會服從的腦殘機器。缺少普遍的創造力，那就不能叫做AGI。

**對ChatGPT的評價：**

*   ChatGPT 是一個了不起的自然語言搜索引擎和翻譯工具，但它在以下三個方面表現的還不夠智能：
    *   進入任何具有大量特定知識的領域，它只會提供通用的、一成不變的、錯誤的、無聊的答案。
    *   總結某件事情也會出錯，它擅長的是向外推理，但無法提煉事物的核心。
    *   進入到任何訓練數據集不足的領域，ChatGPT 也無法完成推理。

**人類的優勢：**

*   人類的優勢應該在於社會進化以及更深層次的文化。
*   我們有機構、國家、文化、宗教，我們有各種各樣表達知識的方式。
*   我們可以重新組合知識，然後執行知識。
*   在這個過程中，沒有人是孤立的。人類是一種合作者，但不是盲目的合作，也不是像螞蟻和蜜蜂那樣的遺傳合作者。

**4. 哲學與認知：萬物相連，追求真理**

*   真正有智慧、有才能的人，不會讓自己被困在一個定義中。
*   一個真正優秀的人（自然哲學家）在任何領域都能表現的很出色，因為自然沒有界限。
*   真正的創造力是跨越界限的，它可以從一個地方到任何地方，而不必在乎中間是否有關聯的路徑。
*   要做任何讓你感覺有樂趣的事情，你就會找到自己的道路。
*   學習是最大的樂趣，享受恍然大悟的時刻。

**對待事物的態度：**

*   對於一般的事物，我們要保持樂觀的態度。
*   對於具體的事物，我們要保持懷疑的態度。
*   千萬不要搞反了。

**如何驗證真理：**

*   通過兩個客觀的系統來獲得反饋：
    *   **自然：** 像物理學、化學、顯微鏡，它們不會在乎你是誰，你在想什麼，所以它們都可以告訴你真相。
    *   **自由市場：** 當絕大多數人以匿名投票的方式來追求自己利益的時候，他們就沒有欺騙你的動機。
*   任何具有社會性的東西，都會為了讓你感覺良好而欺騙你。
*   要想尋求真理，你必須將自己暴露在強有力的反饋之中，同時保持開放的心態，願意很快地改變自己的想法。

**認識論的重要性：**

*   我們對於這個世界的理解，核心其實在於認識論，它與如何知道某件事情是真的有關。

**人類理解一切的能力：**

*   一切可以被理解的事物，人類都能理解，因為我們是宇宙的解釋者，是一台運行着物理法則的圖靈機。
*   宇宙本身也是一台圖靈機。
*   任何可以在現實世界中模擬，或者可以在宇宙中發生的事情，都可以以任意的精度在我們的大腦中模擬。
*   從理論上來說，不可能有任何一個外星人能夠理解我們無法理解的事情。

**資源的定義：**

*   資源的定義也在變化。
*   從哲學的角度來看，基本的真理只有一個，那就是意識的存在。

**僵尸問題：**

*   為什麼我們不能是對環境做出反應的僵尸呢？
*   意識就是當機器人做出反應時的感覺，它需要一些內部的模型，一些內部的狀態機，這就是它所產生的感覺。

**對唯我論的看法：**

*   多伊奇根據奧卡姆剃刀原則推翻了唯我論。
*   比起唯我論認為其他人只是自己想象出來的幻影，更好更簡潔的解釋，應該是現實中每個人都是獨立的實體。

**5. 推薦讀物**

*   大衛·多伊奇的《無限的開始》和《現實的結構》。

**總結：**

這次納瓦爾的談話涉及大量哲學和認知論的觀點，深受大衛·多伊奇思想的影響。多伊奇的理論極具哲學思想，與普通的科普讀物不同，更像是哲學書。

感謝大家觀看本期視頻，我們下期再見！

---

**整理說明：**

*   **分段和標題：** 將文稿分成多個段落，並添加了清晰的標題和子標題，使其結構更清晰。
*   **重點突出：** 使用粗體字標記了重要的觀點和結論。
*   **簡化語言：** 在不改變原意的基礎上，對一些句子進行了簡化，使其更易於理解。
*   **結構調整：** 調整了部分語句的順序，使其邏輯更順暢。
*   **去除口語化：** 移除了一些過於口語化的表達，使文稿更正式。

希望這個整理後的版本對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>268. [2024-05-01] 【商业】创业公司如何找到产品市场契合点PMF | 红杉资本Arc活动分享 |  产品与客户之间的三种关系 | 如何选择路径 | 燃眉之急 | 铁的事实 | 未来愿景</summary><br>

<a href="https://www.youtube.com/watch?v=nJIVpB05eKY" target="_blank">
    <img src="https://img.youtube.com/vi/nJIVpB05eKY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】创业公司如何找到产品市场契合点PMF | 红杉资本Arc活动分享 |  产品与客户之间的三种关系 | 如何选择路径 | 燃眉之急 | 铁的事实 | 未来愿景

好的，我幫你整理這篇文稿，使其更易於閱讀和理解，並突出重點：

**主題：初創公司如何尋找產品與市場的契合點（PMF）- 紅杉資本分析**

**核心觀點：**

紅杉資本根據多年的投資經驗，總結出初創公司尋找PMF的三種方式，並以蘋果、英偉達和OpenAI等巨頭為例，分析客戶與產品之間的複雜關係。

**重點整理：**

作為一家初創公司，要了解自家產品在市場上的定位，必須找到PMF。關鍵在於了解客戶如何與產品要解決的問題產生關聯。

**PMF的三種方式：**

1.  **燃眉之急（Hair on Fire）：**

    *   **定義：** 解決客戶迫切需要解決的問題。
    *   **特點：**
        *   需求顯而易見，競爭激烈。
        *   客戶會比較現有產品以尋找解決方案。
    *   **成功關鍵：** 提供與眾不同的“最优解”產品。
        *   不僅要更快或更便宜，更要提供獨特的客戶體驗。
    *   **例子：**
        *   **Wiz (原Adallom):** 解決雲基礎設施的安全問題，提供“無代理”解決方案，快速發現漏洞。
        *   **Rippling:** 開發人力資源軟件，構建統一的數據庫，提供更全面的員工體驗。

2.  **鐵的事實（Hard Fact）：**

    *   **定義：** 解決大眾普遍認為的生活痛點。
    *   **特點：**
        *   客戶已接受問題的存在，沒有積極尋求解決。
        *   需要顛覆現狀，克服習慣的力量。
    *   **成功關鍵：** 提供足夠新穎的方法，解決足夠重要的問題。
    *   **例子：**
        *   **Square:** 解決小企業無法接受信用卡支付的問題，利用智能手機作為移動信用卡終端。
        *   **HubSpot:** 解決小公司高成本行銷問題，通過集客行銷（Inbound Marketing）以低成本方式接觸用戶。

3.  **未來願景（Future Vision）：**

    *   **定義：** 通過顛覆性創新，實現一個全新的現實。
    *   **特點：**
        *   客戶可能不信任或認為是白日夢。
        *   需要建立自己的生態系統。
    *   **成功關鍵：** 讓客戶相信產品代表全新的範式，且可能性不可抗拒。
    *   **例子：**
        *   **英偉達（NVIDIA）：** 最初通過3D圖形芯片提升個人電腦性能，後在視頻遊戲行業找到PMF，最終推動了AI革命。
        *   **OpenAI：** 願景是實現人工通用智能（AGI），通過ChatGPT找到PMF，作為實現最終目標的墊腳石。

**如何選擇路徑？**

*   由客戶如何與問題相關聯以及對解決方案的感受來決定。
*   任何一條路徑都可能成功，但運營重點不同。

**注意事項：**

*   產品與市場之間的關係是動態變化的，可以從一條路徑轉向另一條路徑。
*   不要過於狹隘，要根據市場變化調整策略。
*   保持和拓展新的PMF是一項持續的任務。

**总结：**

紅杉資本的分析框架有助於初創公司了解產品在市場中的定位，並確定公司的運營方式。創業者應根據自身情況選擇合適的路徑，並隨時調整策略以適應市場變化。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>267. [2024-04-30] 【人工智能】Agent的未来发展 | Harrison Chase最新播客访谈 | LangChain CEO | LangChain的发展历史 | AI Agent | 持续学习 | 个性化服务</summary><br>

<a href="https://www.youtube.com/watch?v=kWfgbRoN2Ic" target="_blank">
    <img src="https://img.youtube.com/vi/kWfgbRoN2Ic/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Agent的未来发展 | Harrison Chase最新播客访谈 | LangChain CEO | LangChain的发展历史 | AI Agent | 持续学习 | 个性化服务

好的，這是經過整理的文稿，重點更清晰，結構更順暢：

**主題：LangChain 創始人兼 CEO 哈里森·蔡斯 (Harrison Chase) 訪談重點整理**

**引言：**

大家好，我是大飛。休息幾天後，我回來了，今天要和大家分享 *No Priors* 播客節目對 LangChain 創始人兼 CEO 哈里森·蔡斯(Harrison Chase) 的訪談內容。無論您是 AI 技術愛好者、開發者或行業觀察者，都建議觀看此節目，了解哈里森的觀點。

**LangChain 簡介：**

LangChain 是一個非常流行的開源框架和開發者工具包，可幫助開發者構建基於大型語言模型的應用程序。目前 LangChain Python 開源庫的 Github star 已超過 8.3 萬顆，fork 人數將近 1.3 萬。

**LangChain 的起源與發展：**

*   **個人業餘項目：** LangChain 最初只是哈里森的一個業餘愛好項目。在 2022 年秋季，他頻繁參加黑客松和各種聚會，與研究大型語言模型的人交流，看到了一些共同的抽象概念，於是將其開源。
*   **爆發式成長：** ChatGPT 發布一個月後，項目發展超出預期。
*   **產品演進：**
    *   LangChain 開源工具包
    *   LangSmith 平台 (專注於測試、評估和監控等功能)
*   **持續進化：**
    *   從最初基於研究論文和 NatBot 的 Agent 網絡爬蟲的實現，到與 OpenAI、Cohere 和 HuggingFace 等公司的集成。
    *   現在支持 700 多種不同的集成，還開發了多個用於特定功能的高級鏈和 Agent。
    *   上層組合組件的方式和構建應用的模式也在快速變化，從簡單的鏈到複雜的鏈，再到類似自主 Agent，再到現在的複雜狀態機或者圖。

**LangChain 的技術重點：**

*   **底層抽象和運行時：** LangChain 非常重視低層次的抽象和運行時，在底層運行時投入了大量的資金，重點保證了流處理、結構化輸出等基礎組件的相對穩定。
*   **連接不斷變化的大模型和向量儲存等組件**

**哈里森對 Agent 的看法與挑戰：**

哈里森認為 Agent 現在還面臨著幾個關鍵的挑戰：

*   **使用者體驗：** 如何為技術找到合適的使用者體驗，如何向終端用戶傳達 Agent 的長處和短處，如何讓用戶糾正錯誤並且了解發生了什麼。
*   **底層大語言模型的規劃能力：** 如何將任務分解成許多小部件，並融入自己對信息流動方式的理解。大語言模型本身的局限性使其還無法完全推理出信息應該如何流動。目前學術領域的研究分為 Agent 的規劃步驟和 Agent 行動後的反思。
*   **構建 Agent 的最佳實踐：** 如何在不同節點間正確地流動信息，是選擇少量提示，還是選擇微調模型，還是去改進指令和提示？如何測試這些節點？

**記憶功能：**

哈里森認為 Agent 的記憶功能有兩種：

*   **系統級程序記憶：** 找到使用工具的正確方法是什麼，實現這一目標的正確方法是什麼，不考慮使用者是誰。解決方案包括使用少量提示和微調。這也是目前在 LangSmith 上大力推廣的一種方法。
*   **個性化記憶：** 當用戶提出問題的時候，記得個人喜好。實現方式包括主動循環（Agent 決定記住或忘記什麼）和被動的後台程序（查看對話並提取洞察力）。

**人工智能應用發展的變化：**

*   **更高效的 Agent 應用程序和更複雜的多步驟 RAG 系統：** LangSmith 主要針對這些多步驟的應用。
*   **高級查詢分析：** 不僅僅將用戶的問題直接傳遞給嵌入模型，而是可能會對問題進行分析，來確定應該將問題發送給哪個檢索器。
*   **從鏈條式的 Agent 到自主 Agent：** 從有順序步驟的鏈條式 Agent 到 AutoGPT 這種在 for loop 中運行的自主 Agent。
*   **基於 Agent 的應用：**
    *   **客戶支持：** Sierra 提供了一個有趣的使用者體驗，但與聊天機器人不同，前者更注重解決問題。
    *   **編碼：** Cognition 的 Devin 演示令人印象深刻。
*   **大語言模型之間的輕鬆切換：** 可以根據提示從 Anthropic 模型切換到 Mistral，再到 OpenAI 等等。隨著模型逐漸變得更加智能，不同模型之間的提示語可能會逐漸趨同，這種切換會變得更加容易。

**關於模型切換的考慮因素：**

*   函數調用
*   視覺輸入
*   上下文窗口的長度
*   成本
*   延遲

**長上下文窗口 vs. RAG：**

*   **長上下文窗口：** 適合一次性從長的 PDF 文檔中提取元素，在長文本中尋找單一的信息點。
*   **RAG：** 強項在於處理和推理多個信息點。

**微調：**

真正進行微調的應用不多，主要是那些達到臨界規模的應用。微調面臨著数据集的收集和策划、微调模型的评估、以及无法快速迭代微调模型等等挑戰。

**开源模型：**

哈里森認為目前開源模型的推理能力還是落後於 Claude 3 或者 GPT-4。

**對未來的展望：**

哈里森認為應用程序和用戶體驗層面是個人很看好的方向，尤其是個性化的長期記憶。LangChain 本身也非常關注記憶功能，並且希望能夠在這個領域實現一些突破。

**持續學習：**

*   從交互的經歷中學習，例如建立一些示例數據集，並真正使用這些數據集。
*   讓應用程序隨著時間的推移自動變得更好，例如從錯誤和成功中學習。
*   通過輸入和輸出不斷地優化應用程序，例如斯坦福的 DSPy 項目。

**個性化：**

從一個為每個人提供相同服務的通用應用開始，逐漸學會以不同的方式為不同的用戶搜索網頁。

**總結：**

哈里森的訪談對 LangChain 的發展方向是一個很好的解讀。正如他在之前紅杉 AI 峰會上的分享一樣，他認為 Agent 的三大關鍵方向就是規劃、使用者體驗和記憶。LangChain 最近的一些更新也都是跟這些方面有關。我會持續關注 LangChain 的發展，跟大家分享更多有關哈里森和 LangChain 的內容。

**結束語：**

感謝大家的觀看，我們下期再見！

**整理說明：**

*   **精簡內容：** 去除了一些口語化的語氣詞，使文稿更正式。
*   **結構化：** 使用了標題、副標題、項目符號等，使文稿更易讀。
*   **突出重點：** 對關鍵信息進行加粗，方便讀者快速抓住重點。
*   **邏輯性：** 調整了部分內容的順序，使邏輯更清晰。
*   **專業性：** 使用更專業的術語和表達方式，提升文稿的專業性。

希望這個整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>266. [2024-04-20] 【人工智能】马克扎克伯格最新80分钟访谈精华版 | Llama 3 | AGI  | 开源 | Meta AI | 元宇宙Metaverse</summary><br>

<a href="https://www.youtube.com/watch?v=vxL86VlUL98" target="_blank">
    <img src="https://img.youtube.com/vi/vxL86VlUL98/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】马克扎克伯格最新80分钟访谈精华版 | Llama 3 | AGI  | 开源 | Meta AI | 元宇宙Metaverse

好的，這是一個整理後的文稿，重點在於結構化資訊，方便讀者快速理解主要內容。我將其分為幾個部分：**核心觀點總結、Llama 3 重點、Meta 的戰略與初心、對 AGI 的看法、對開源的看法、以及對元宇宙的堅持**。

**整理後文稿：**

**標題：Meta 小扎 80 分鐘訪談精華：Llama 3 開源背後的戰略、AGI願景與風險考量**

**前言：**

大家好，我是大飛。本次為大家整理 Meta 創辦人祖克伯格 (小扎) 關於 Llama 3 的 80 分鐘訪談，內容信息量巨大，涵蓋 Llama 3 的開發、Meta 的 AI 戰略、對通用人工智慧 (AGI) 的看法、以及對開源的堅持。

**1. 核心觀點總結：**

*   **Llama 3 的重要性：** Meta 押注通用人工智慧 (AGI) 的關鍵一步，旨在賦予人類更強大的能力。
*   **Meta 的目標：** 並非取代人類，而是提供創新工具，讓人們追求真正想做的事情。
*   **開源策略：** 支持開源以促進創新，但會根據情況評估風險並調整策略。
*   **對 AGI 的看法：** AGI 的發展是一個漸進的過程，Meta 將逐步為模型增加不同的能力，例如情感理解。
*   **對元宇宙的堅持：** 元宇宙是一個能讓人們從物理束縛中解脫出來的平台，Meta 將繼續投入。

**2. Llama 3 重點：**

*   **模型規模：** 80億、700億和4050億參數三個版本。前兩個版本已就緒，4050億參數版本仍在訓練中。
*   **功能：** 後續將發布多模態、更多語言的支持以及更長的上下文窗口等功能。
*   **性能：** 即使是最小的 80 億參數模型，其性能也幾乎與 Llama-2 700 億參數相媲美。700億參數的版本MMLU得分約為82，4050億參數的版本MMLU得分已接近85。
*   **關鍵提升：** 通過大量的編碼訓練進行了優化，提升了推理能力，能更精準地回答問題。
*   **發佈時間：** 4050 億參數版本預計今年晚些時候發布。

**3. Meta 的戰略與初心：**

*   **2022 年的轉捩點：** Meta 面臨股價下滑和市場質疑，但小扎堅持投資 GPU，為未來發展打下基礎。
*   **從 Reels 項目到 AI 投資：** Meta 發現需要更多的 GPU 來訓練模型，這促使他們大力投資 AI 基礎設施。
*   **不賣 Facebook 的原因：** 小扎對創造新東西、幫助人們溝通充滿熱情，因此拒絕了 2006 年的收購提議。
*   **堅持長期價值觀：** 重大決策基於信念和價值觀，而非僅僅依靠分析預測未來。

**4. 對 AGI 的看法：**

*   **FAIR 的成立：** 旨在推動公司業務的發展，而非作為獨立產品。
*   **通用人工智能團隊：** 專注於將前沿技術融入 Meta 的產品，並構建領先的基礎模型。
*   **AI 能力的關鍵：** 編碼能力和推理能力至關重要，能幫助模型更精準地回答問題。
*   **AGI 的演進：** 是一個逐步演進的過程，Meta 將逐步為模型增加不同的能力，例如情感理解。
*   **情感理解的重要性：** 人類大腦大部分功能都在理解他人、解讀表情和情感，AI 需要學習情感理解。
*   **未來願景：** Meta AI 通用助手將能接收並執行更複雜的任務，並與其他智能體互動。
*   **創作者的機會：** 創作者可以訓練自己的人工智慧，並借助它與社群保持互動。
*   **工具整合：** Llama-3 已經內嵌了不少功能，能夠獨立完成搜尋等任務。Llama-4 的目標是將更多這類功能自然而然地融入到模型中，讓模型能夠自我學習、自我進化。
*   **算力基礎：** 擁有兩個大型的 GPU 集群，每個集群擁有約 22000 到 24000 個 GPU，主要用來訓練大語言模型。
*   **Scaling Law：**  即使訓練了大约15万亿个token后，Llama3 700億仍然在不斷學習，不相信Scaling Law的人終會被打臉

**5. 對開源的看法：**

*   **支持開源：** 開源對於社區和 Meta 來說都是有益的，因為這將促進創新。
*   **風險評估：** 如果 Meta 覺得開源是不負責任的，也會選擇不公開。
*   **安全考量：** 開發 Llama-2 時，Meta 投入大量資源來確保它不會被用於不良目的。
*   **集中化的風險：** 人工智慧過度集中化的風險可能不亞於廣泛傳播，開源軟體能讓更多人參與改進。
*   **Meta 的開源傳統：** 雖然不會將產品直接開源，但會開源很多底層的基礎設施，例如開放計算項目 (Open Compute Project)。
*   **商業模式：** 通過向雲服務商授權模型使用，Meta 可以從中獲得可觀的收入。
*   **限制性許可證：** 對於使用 Llama 的最大公司設置了限制，希望他們在轉售模型並從中獲利時與 Meta 溝通。
*   **Meta 與其他科技巨頭的差異：** Meta 構建自己的模型，是為了確保不會被其他公司限制自己的創新能力。
*   **開放創新與價值貢獻：** Meta 希望開發者不受蘋果、谷歌等公司的限制，並期望開源模型社群能為 Meta 貢獻價值。

**6. 對元宇宙的堅持：**

*   **元宇宙的願景：** 讓人們從物理束縛中解脫出來，更便捷高效地進行社交、建立聯繫、完成工作。
*   **小扎的動力：** 來自於他內心想要不斷創造新東西的驅動力。
*   **面對質疑：** 很多人難以理解 Meta 為何要開源這些技術，但他認為合理的事情比人們想像的要多得多。

**7. 總結：**

小扎在訪談中全面闡述了自己對於 AI 發展的看法，以及 Meta 在 AI 領域的布局和規劃。他既看到了 AI 的巨大潛力，也意識到了其中的風險和挑戰，在強調開源和創新重要性的同時，也提出了一些應對於 AI 風險的策略。

**結語：**

期待看到 Llama 4 的發布，以及開源模型在 AI 領域的百花齊放。感謝大家觀看本期視頻，我們下期再見。

**整理說明：**

*   **結構化：** 將內容分為幾個主要部分，方便閱讀者快速找到感興趣的資訊。
*   **重點突出：** 使用粗體標示關鍵字和重要觀點，方便快速瀏覽。
*   **簡潔明瞭：** 刪除冗餘的口語化表達，使文稿更加精煉。
*   **客觀陳述：** 盡量避免個人評價，保持客觀中立的立場。

希望這個整理後的文稿對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>265. [2024-04-19] 【人工智能】Meta深夜发布Llama 3 | 同级最强开源模型 | 性能追赶闭源大模型 | 8B/70B两款参数模型 | 15T Token训练 | Meta AI</summary><br>

<a href="https://www.youtube.com/watch?v=KDk2_nWq5aI" target="_blank">
    <img src="https://img.youtube.com/vi/KDk2_nWq5aI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Meta深夜发布Llama 3 | 同级最强开源模型 | 性能追赶闭源大模型 | 8B/70B两款参数模型 | 15T Token训练 | Meta AI

好的，我將盡力整理這篇文稿，使其更清晰、更有條理，並突出重點。

**整理後文稿：**

**標題：Meta 發布最強開源大模型 Llama 3：亮點、特性與影響**

**引言：**

大家好，這裡是最佳拍檔，我是大飛。 Meta 突然釋出重磅消息，發布了目前最強大的開源大模型 Llama 3。

**Llama 3 概覽：**

*   **模型版本：** 包括 8B 和 70B 兩個版本。
*   **授權方式：** 月活用戶小於 7 億可免費使用，基本等同於完全商用免費。
*   **雲端部署：** 即將登陸主要雲服務商。
*   **性能：**
    *   Yann LeCun 認為 Llama 3 8B 和 70B 是同體量下性能最佳的開源模型。
    *   Llama 3 8B 在某些測試集上甚至超越 Llama 2 70B。
*   **未來展望：** Meta 預計在未來幾個月內推出更多版本，包含 400B 版本。
*   **業界評價：**
    *   馬斯克評價 "Not bad" (不錯)。
    *   英偉達 Jim Fan 認為 Llama 3 代表開源模型與頂尖閉源模型並駕齊驅。
    *   Llama 3 400B 的實力幾乎可媲美 Claude 超大杯和新版 GPT-4 Turbo。

**Llama 3 發布亮點與特性：**

1.  **最佳性能：** 在大量重要基准測試中表現最佳。
2.  **海量數據訓練：** 基於超過 15T 的 Token 訓練，超過 Llama 2 的 7 倍。
3.  **訓練效率提升：** 訓練效率比 Llama 2 提高了 3 倍。
4.  **長文本支持：** 支持 8K 長文本，改進的 Tokenizer 具有 128K Token 的詞彙量。
5.  **推理與程式碼能力增強：** 增強的推理和代碼能力。
6.  **安全性突破：** 提供新版信任和安全工具，包括 Llama Guard 2、Code Shield 和 CyberSec Eval 2，以及更好的 “錯誤拒絕表現”。

**性能細節：**

*   **Llama 3 8B：** 在 MMLU、GPQA、HumanEval 等多項基準上優於 Gemma 7B 和 Mistral 7B Instruct。
*   **Llama 3 70B：** 超越閉源模型 Claude 3 Sonnet，與 Google Gemini Pro 1.5 不相上下。
*   **Meta 自研評估數據集：** 包含 1800 個提示，涵蓋 12 種關鍵用例，並禁止研究團隊訪問，以避免過度擬合。Llama 3 在此數據集上表現優於 Claude Sonnet、Mistral Medium 和 GPT-3.5。
*   **Llama 3 400B：** (預計) 性能將趕超 Claude 3，但可能不會開源。

**Llama 3 成為最強開源大模型的關鍵要素：**

1.  **模型架構：**
    *   採用純解碼器 Transformer 架構。
    *   使用 128K Token 的 Tokenizer，更有效率地編碼語言。
    *   採用分組查詢關注 GQA。
    *   在 8192 個 Token 序列上訓練。
    *   使用掩碼確保自注意力不會跨越文檔邊界。
2.  **訓練數據：**
    *   使用 15 萬億 Token，幾乎是 Llama 2 的七倍，包含四倍的程式碼。
    *   重視數據品質，使用 Llama 2 生成訓練數據。
    *   採用多種數據過濾管道，包括啟發式過濾器、NSFW 過濾器、語義重複數據刪除方法和文本分類器。
    *   包含超過 5% 的高質量非英語數據，涵蓋 30 多種語言。
    *   訓練數據來源為公開來源，但可能包含 AI 合成數據。
    *   8B 版本數據截止日期為 2023 年 3 月，70B 版本為 2023 年 12 月。
3.  **擴大預訓練規模：**
    *   制定詳盡的擴展規則。
    *   評估模型在各種下游任務中的表現。
    *   即使數據量增加一百倍，模型性能仍在持續提升。
4.  **指令微調：**
    *   結合監督微調（SFT）、拒絕採樣、近似策略優化（PPO）和直接策略優化（DPO）。
    *   SFT 中使用的提示，以及在 PPO 和 DPO 中使用的偏好排序的質量對模型性能有極大影響。
    *   Meta 在 16000 個 GPU 的集群上訓練了 Llama 3，實現了每個 GPU 超過 400 TFLOPS 的計算利用率。

**安全性：**

*   採用系統級方法來負責地開發和部署 Llama 3。
*   指令微調模型通過內部和外部紅隊測試。
*   採用先進的大模型安全技術，包括 Llama Guard 2、Code Shield 和 CyberSec Eval 2。

**Meta AI：**

*   基於 Llama 3 構建，是最智能的免費 AI 助手。
*   與 Meta APP 生態兼容，提升使用體驗。
*   可在 Instagram、Facebook、WhatsApp 和 Messenger 的搜索框中使用。
*   輸入問題 + @Meta AI 即可獲得答案。
*   可與 Meta AI 進行私聊對話。
*   Facebook 帖子下面可直接提問。
*   無需註冊登錄即可在 meta.ai 網站開啟對話。
*   圖像生成速度大大加快，輸入即所得。
*   可生成 GIF 動圖分享。
*   集成 Bing 和 Google 實時搜索結果。
*   已向美國以外的十幾個國家推出英語版。

**未來規劃：**

*   Meta 團隊將會公佈 Llama 3 的技術報告。
*   模型開發團隊將與外界進行交流。

**總結：**

Meta 没有辜负开源社区对它的期待，继续在大模型开源之路上奋力狂奔。這次 Llama 3 的發布無疑是對百度李彥宏關於開源大模型意義不大，閉源模型能賺到錢的言論狠狠打臉。

**結尾：**

大家一定都想喊話 OpenAI 和 Sam Altman，GPT-5 什麼時候發布呢？好了，感謝大家收看本期節目，我們下期再見。

**備註：**

*   我將文稿進行了分段，使其更易於閱讀。
*   使用粗體字標示重點內容。
*   整理了 Llama 3 的亮點與特性，使其更清晰。
*   補充了 Meta AI 的相關資訊。
*   修正了部分錯別字。
*   將原先較口語化的表達進行潤飾，使其更符合書面語的習慣。

希望這個版本對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>264. [2024-04-19] 【波士顿动力】液压版Atlas告别舞台，电动版Atlas登上舞台 | 波士顿动力和Atlas的历史 | 液压驱动的优劣势 | 电动驱动的未来趋势</summary><br>

<a href="https://www.youtube.com/watch?v=oGFjrRRpAog" target="_blank">
    <img src="https://img.youtube.com/vi/oGFjrRRpAog/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【波士顿动力】液压版Atlas告别舞台，电动版Atlas登上舞台 | 波士顿动力和Atlas的历史 | 液压驱动的优劣势 | 电动驱动的未来趋势

好的，以下是經過整理的文稿，重點歸納，並著重於條理清晰，方便快速理解：

**主旨：波士顿动力告别液压Atlas，迎来电动Atlas 2.0时代**

**1. 液压Atlas退役:**

*   **原因：**
    *   液压驱动成本高昂，零件加工要求高，难以商业化。
    *   液压系统复杂，易泄漏，存在安全隐患，维护维修麻烦，响应速度慢。
    *   电动驱动效率更高、控制精度更高、更安全可靠，成本也更低，是大势所趋。
    *   商业化失败，成立26年仍难盈利，多次被收购。
    *   早期研发主要为军用目的，缺乏民用和商用考量。
*   **回顾：**
    *   研发历时10年，激发了人们的想象力，启发了下一代机器人专家。
    *   最初是为美国军方DARPA的PETMAN计划服务，用于测试防护服。
    *   2013年首次公开亮相，展示了动态移动能力。
    *   后续不断发布新的视频，展示了奔跑、跳跃、跳舞、跑酷等能力。
    *   多次升级，例如推出电池供电版，配备机载液压动力系统，增加电动驱动系统。

**2. 电动Atlas 2.0问世:**

*   **特点：**
    *   全电动驱动，整体规整，没有外露电线。
    *   运动方式诡异，类似“贞子”站立。
    *   头部设计借鉴皮克斯小台灯形象，可表达意图并与用户交流。
    *   保留了液压版的三根手指设计。
*   **目标：**
    *   成为世界上最具活力的人形机器人。
    *   第一个应用场景设想为汽车制造行业。
    *   明年开始与现代汽车一同开展现场实验。
*   **意义：**
    *   标志着波士顿动力向机器人商业化迈出重要一步。

**3. 人形机器人行业前景广阔:**

*   **竞争激烈：** 特斯拉擎天柱、Figure AI的Figure 01、1X的EVE，智元远征A1、达闼科技的Cloud Ginger等。
*   **未来趋势：**
    *   谁能找到合适的商业化应用场景，谁就能获得优势。
    *   高盛预测，到2035年，人形机器人市场规模有望达到1540亿美元，乐观情况下出货量可能达到100万台。
    *   人机协同的场景将不再只存在于电影和科幻小说中。
*   **思考：**  是否应该创造超越人类的新物种？

**4.  液壓 vs. 電動比較**

| 特性     | 液壓                                  | 電動                                  |
| -------- | ------------------------------------- | ------------------------------------- |
| 成本     | 高                                    | 較低                                  |
| 零件     | 多，加工要求高                          | 少                                    |
| 維護     | 麻煩，易洩漏                            | 相對簡單                              |
| 安全性   | 存在洩漏隱患                            | 更高                                  |
| 響應速度 | 慢                                    | 快                                    |
| 扭矩密度 | 高                                    | 相對較低，但技術提升迅速                 |
| 能源效率 | 低                                    | 高                                    |
| 商業化   | 困難                                  | 較易                                  |
| 優點     | 極致運動性能表現較好                      | 效率高、控制精度高、安全可靠性好、成本不高 |
| 總結     | 不符合現代機器人的商業化要求                 | 大勢所趨                              |

**總結:**  波士顿动力告别了成本高昂、安全性较差的液压Atlas，拥抱了更具商业前景、更安全可靠的电动Atlas 2.0，也代表了人形机器人行业正在向更实用、更智能的方向发展。未来，人形机器人将在各个领域发挥重要作用，甚至可能超越人类。

這個整理版本更注重條理清晰，方便讀者快速抓住文章的重點和邏輯。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>263. [2024-04-18] 【人工智能】图灵奖得主Yoshua Bengio最新访谈 | 不应该只有Scaling Law | 深度学习三巨头 | 学术生涯  | 神经网络 | 系统2 | AI safety | 如何科学研究</summary><br>

<a href="https://www.youtube.com/watch?v=WtvOAWGahUQ" target="_blank">
    <img src="https://img.youtube.com/vi/WtvOAWGahUQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】图灵奖得主Yoshua Bengio最新访谈 | 不应该只有Scaling Law | 深度学习三巨头 | 学术生涯  | 神经网络 | 系统2 | AI safety | 如何科学研究

好的，我來幫你整理這篇文稿，主要目標是：

*   **提煉核心觀點：** 突出文稿最重要的訊息，方便快速掌握 Bengio 訪談內容。
*   **簡化結構：** 將文稿分段，並加上小標題，使內容更易於閱讀和理解。
*   **去除冗言：** 刪除口語化的開場白和結尾語，保留實質內容。

**整理後的文稿：**

**訪談背景：圖靈獎得主 Yoshua Bengio 的反思**

國內智源社區對世界級人工智能專家、圖靈獎得主 Yoshua Bengio 進行了一場遠程專訪。訪談不僅回顧了 Bengio 的學術生涯，也對如今的 Scaling Law 進行了深入的反思，並表達了對於人類如何應對 AI 潛在風險的關心。

**Bengio 的早期經歷與學術啟蒙**

Bengio 出生於法國巴黎，現任加拿大蒙特利爾大學教授，也是蒙特利爾學習算法研究所（MILA）的創始人和科學主任。儘管現在神经网络成為主流，但在早期不被重視的年代，Bengio 的論文曾多次遭拒。他受到科幻小說《環舞》中阿西莫夫“機器人三定律”的啟發，對計算機和匯編語言產生了濃厚的興趣。家庭的自由環境和父母的鼓勵，也培養了他獨立思考和批判性思維的能力。

**對神经网络的堅持與突破**

在神经网络經歷寒冬時，Bengio 堅持認為神经网络可以解決其他主流方法無法應對的泛化問題。他通過對維數災難的理論分析，認為神经网络的多層結構能有效處理高維度數據。2006 年，他發表了深度學習領域的經典論文《深度网络的贪婪逐层训练》，首次找到了訓練深層網路的方法。2014 年，他的團隊將注意力機制應用到了自然語言處理領域，大大提升了機器翻譯的性能。

**對 Scaling Law 的反思與系統 2 研究**

對於現在流行的 Scaling Law，Bengio 提醒它只是一個基於經驗性觀察總結出的規律，無法確保會一直起作用。他反思了自己之前對 Scaling Law 的誤判，並認為除了擴大模型規模，還需要在方法層面取得根本性突破。他開始了一項關於系統 2 深度學習的研究，希望彌合人工智能與人類之間的差距。系統 2 包括推理、因果關係、自我懷疑等思維能力，是當前的人工智能不太擅長的。

**對 AI 安全的擔憂與呼籲**

Bengio 的研究重點已經轉移到人工智能的安全，他將 AGI 與核武器進行對比，認為 AI 既可以造福人類，也可能被用作武器，存在被濫用或失控的風險。他呼籲在國際層面達成共識，避免各國毫無約束地自行研發人工智能技術，尤其不能將 AI 用於軍事目的。他認為，在 AI 安全上，我們不能各自為政，必須攜手同行。

**給年輕研究者的建議**

Bengio 分享了個人的教學和科研經驗。在教學中，他提倡翻轉課堂，讓學生主動參與到學習中。在學術研究中，他強調要善於提問、保持謙虛，並親身參與實踐。他建議多閱讀，持續累積知識。

這個版本更精簡，重點突出，希望能幫到你！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>262. [2024-04-17] 【人工智能】500页AI指数报告精华内容解读 | 2024第七版 | 斯坦福人工智能研究所 | 十大洞察 | 开源与闭源对比 | 产业分布 | 国家竞争 | AI智能水平正在接近人类</summary><br>

<a href="https://www.youtube.com/watch?v=FuU9Kmd-FXE" target="_blank">
    <img src="https://img.youtube.com/vi/FuU9Kmd-FXE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】500页AI指数报告精华内容解读 | 2024第七版 | 斯坦福人工智能研究所 | 十大洞察 | 开源与闭源对比 | 产业分布 | 国家竞争 | AI智能水平正在接近人类

好的，以下是经过整理的文稿，我主要做了以下修改和调整：

**1. 结构化内容：** 将报告的关键要点按照逻辑顺序组织，例如模型发布、性能对比、产业界参与、训练成本、国家竞争、性能表现、投资情况、应用情况、工作影响，使整体结构更清晰。

**2. 提炼关键信息：** 简化了一些细节描述，突出了报告的核心发现和结论。

**3. 语言润色：** 优化了部分语句，使表达更流畅自然。

**4. 补充说明：** 在必要的地方增加了少量的解释性文字，以便读者更好地理解报告内容。

**5. 格式调整：** 使用了更清晰的段落和标题，方便阅读。

**整理后的文稿：**

---

大家好，这里是最佳拍档，我是大飞。

昨天，由李飞飞领导的斯坦福大学人本人工智能研究所(Stanford HAI)发布了《2024年人工智能指数报告》(Artificial Intelligence Index Report 2024)。这份长达500多页的报告是Stanford HAI发布的第7份AI指数研究，追踪了2023年全球人工智能的发展趋势。Stanford人工智能研究所官方称，这是他们迄今为止最全面的报告，尤其在人工智能对社会的影响如此明显的重要时刻发布，更显得意义重大。

鉴于报告内容丰富，我将通过本视频，带大家快速了解报告中的关键要点。

**一、模型发布情况**

*   2023年，各组织共发布了149个基础模型，数量是2022年的两倍还要多。
*   新推出的模型中，65.7%采用了开源模式，相比2022年的44.4%和2021年的33.3%，呈现显著上升趋势。
*   开源模型数量最多（98个），有限访问模型23个，闭源模型28个。这表明目前开放共享的基础模型占大多数。

**二、开源模型 vs. 闭源模型：性能对比**

尽管开源模型数量增加，但闭源模型在性能上仍然大幅领先。在10个选定的基准测试中，闭源模型平均超越开源模型24.2%，差距在不同任务中表现各异，从数学问题（4.0%）到需要更多代理能力的AgentBench任务（高达317.7%）。

**三、产业界参与情况**

在人工智能的竞赛中，产业界尤其在开发与发布基础模型的领域占据了重要地位。

*   谷歌发布模型数量最多（包括Gemini和RT-2），自2019年起就遥遥领先，总计达到40个。
*   OpenAI以20个模型紧随其后。
*   相比之下，学术界的进展较慢。
*   2023年，Google建立了18个基础模型，Meta(Facebook) 11个，Microsoft 9个，OpenAI 7个，等等。
*   企业级人工智能无疑是这个领域内的主宰者。2023年，产业界发布的新基础模型占全部数量的72%。

**四、模型训练成本与计算规模**

训练大型模型所需成本急剧上升，是学术界和政府难以在人工智能竞速中保持领先地位的原因之一。

*   谷歌的Gemini Ultra的训练估计耗资高达1.91亿美元，OpenAI的GPT-4也需要大约7800万美元。
*   相比之下，2017年开创性的原始Transformer模型，训练成本大约只需要900美元。

**五、国家间的人工智能竞赛**

在重要的机器学习模型开发方面，2023年美国明显领先于其他国家，全年共研发了61个模型，自2019年起一直保持领先地位。紧随其后的是中国和英国。

**六、人工智能性能表现**

到2023年为止，整体来看，人工智能系统在很多智力任务上的表现都有了大幅提升，在某些领域已经超过了人类的水平。在图像分类、基础阅读理解、英语理解等任务中，人工智能系统已经超过了人类的表现。

**七、私人投资情况**

*   生成式AI的私人投资大幅增加，从2019年的8.4亿美元增长到2023年的252.3亿美元。
*   2023年，生成式AI的投资占到了所有与AI相关私人VC投资的超过四分之一，被称为“ChatGPT效应”。
*   2023年，美国在人工智能领域的私人投资再次遥遥领先，以672.2亿美元排名第一，远超其他国家。

**八、人工智能应用情况**

越来越多的公司正在他们的某些业务部分实施人工智能。在调查中，55%的组织表示他们在2023年使用了人工智能，高于2022年的50%和2017年的20%。人工智能技术主要用在企业的以下几个方面：

*   客服中心(Contact-center automation)：26%
*   个性化推荐系统(Personalization)：23%
*   获取客户(Customer acquisition)：22%
*   增强产品(AI-based enhancements of products)：22%
*   AI驱动新产品(Creation of new AI-based products)：19%

**九、人工智能对工作的影响**

*   在全球范围内，大部分人都认为人工智能将改变他们的职业生涯，超过三分之一的人甚至担心可能会被AI取代。
*   57%的人认为，在未来5年内，人工智能会改变他们现有工作的方式。
*   36%的人认为人工智能很可能在未来5年内取代他们的工作。
*   年轻一代（95后和00后）预计人工智能带给他们特别大影响。
*   高收入者、受教育程度更高的人群以及担任决策职位的个体，也普遍认为人工智能将对他们的职业生涯产生重大影响。
*   一项调查显示，69%的澳大利亚人和65%的英国人表示对人工智能产品和服务感到担忧，而日本人对于本国的人工智能产品的担心程度要低得多，只有23%的人表达了这种担忧。

好了，以上就是这份报告的一些关键信息解读。当然报告中还有非常多的内容，大家有时间的话可以仔细去阅读一下。报告的地址我也会放在视频简介中，方便大家下载。感谢大家观看本期视频，我们下期再见。
---

希望这个整理后的文稿能更好地满足您的需求！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>261. [2024-04-16] 【人工智能】Sora能否成为通往AGI的道路 | 项目作者Tim Brooks和Bill Peebles最新分享 | Scaling Law | 苦涩的教训 | 是否能模拟现实物理世界</summary><br>

<a href="https://www.youtube.com/watch?v=KgK27v0ccfs" target="_blank">
    <img src="https://img.youtube.com/vi/KgK27v0ccfs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Sora能否成为通往AGI的道路 | 项目作者Tim Brooks和Bill Peebles最新分享 | Scaling Law | 苦涩的教训 | 是否能模拟现实物理世界

好的，這是我整理後的文稿，主要目標是使其更清晰、更易讀，並略微調整了結構，使其重點更突出：

**最佳拍檔：Sora 作者訪談重點整理與解讀**

大家好，這裡是最佳拍檔，我是大飛。

在 OpenAI Sora 發布兩個月後，人工智慧社群 AGI House 邀請到了 Sora 的核心作者 Tim Brooks 和 Bill Peebles 進行了一次分享，詳細介紹了 Sora 的目標、方法、技術細節、最新進展以及面臨的挑戰。更重要的是，兩位作者認為 Sora 不僅能模擬一切，還是通往通用人工智慧 (AGI) 的一輛直通車。今天，我們就來看看這次訪談的重點。

**Tim Brooks：從 Tokyo Walk 到內容普及化**

首先登場的是 Tim Brooks，他同時也是文生圖模型 DALL·E 3 的作者。Tim 開場便播放了 Sora 最經典的影片 "Tokyo Walk"。他表示，這段一分鐘的高清影片對 Sora 團隊來說意義非凡，它證明了團隊達成了生成一分鐘 1080p 影片的里程碑。

這段影片包含了許多複雜的元素，例如反射和陰影。其中一個有趣的細節是影片中出現的藍色標誌，即使女性角色穿越它之後，標誌仍然保持原位不動。這展示了 Sora 在保持物體持久性和長時間一致性方面的巨大進步。

除了技術上的突破，Tim 還強調 Sora 能夠理解整個三維空間，並深刻理解世界的幾何和物理複雜性。除了生成內容外，Sora 實際上還從訓練的影片中學習到了很多關於物理世界的知識。

Tim 希望 Sora 能夠進一步促進內容創作的普及化，幫助更多富有創新精神的個人輕鬆地將自己的創意轉化為實際作品，並與全世界共享。他強調，Sora 並非像 ChatGPT 那樣的通用型 AI 產品，而是一個專注於探索技術邊界、價值及安全性的研究項目。

Tim 在演講中引用了強化學習之父 Rich Sutton 在《苦澀的教訓》中的觀點，認為在 AI 發展的道路上，依賴於計算能力的通用方法最終會勝出，並且這種優勢會隨著計算資源的指數級增長而越發顯著。他認識到算力的重要性，認為隨著時間的推移，算力不斷增加，如果有一種方法能夠充分利用這一點，那麼它就會變得越來越好。

**Sora 的技術細節：Transformer 模型與視覺資料的 Token 化**

Tim 接著講解了一些關於 Sora 的技術細節。他指出，Sora 將不同格式、分辨率、縱橫比的影片和圖像切割成空間時間中的碎片 (patch)，然後在這些碎片上訓練 Transformer 模型。這種做法使得模型能夠適應不同維度和格式的視覺內容，並且能夠隨著計算能力和數據量的增加不斷優化性能，進而生成不同縱橫比的高質量影片內容。

Sora 模型還支持零樣本學習，可以將一段影片轉換為另一種樣式或者內容的影片。通過利用擴散模型和 SD 編輯技術，Sora 能夠在保持原始影片結構的基礎上進行創造性的編輯，例如風格遷移、場景變換等等。模型還能實現影片間的平滑過渡，創造出生動自然的效果。

Tim 展示了一系列模型創造性地將迥異的視覺素材無縫融合在一起的示例，例如無人機視角與水下蝴蝶、羅馬鬥獸場與水下環境、地中海景觀與薑餅屋等等，體現了模型對視覺內容深度理解和創造性重組的能力。

**Bill Peebles：Sora 是通往 AGI 的重要一步**

接下來，Bill Peebles 強調了以 Sora 為代表的影片模型在通向通用人工智慧 AGI 路徑上的重要性。他認為影片模型對於模擬人類互動、理解物理世界以及捕捉複雜情境至關重要。

Bill 提出了和 Tim 同樣的觀點，那就是可擴展性 (Scaling Law) 是關鍵。隨著計算資源的增加，模型展現出了更強的理解和生成能力。Bill 指出，Sora 在沒有經過直接編程的情況下，通過自我學習逐漸理解了 3D 幾何結構，這是模型湧現能力的一個體現。

Bill 甚至把 Sora 看做是影片版的 GPT-1。儘管 Sora 當前還存在著局限性，以及在面對某些複雜物理交互時存在許多挑戰，但 Sora 團隊對未來的發展依然充滿信心，認為隨著研究的深入和模型的迭代，影片模型將極大地推動通用人工智慧領域的發展。

**問答環節：模型理解、實現方式與未來方向**

在問答環節，兩位作者回答了關於 AI 智慧體在場景中的理解和互動、模型實現方式以及未來發展方向等問題。

*   **AI 智慧體的理解和互動：** 這部分信息在 Sora 中其實是隱含處理的，大部分機制都是通過模型自我學習獲得的，而非直接指定。
*   **模型實現方式：** Sora 採用的是擴散模型，而不是自回歸 Transformer。它從一個全雜訊影片開始，通過迭代模型來逐步消除雜訊，直至得到清晰的樣本。
*   **未來方向：** 團隊正在積極努力，希望能針對特定內容進行模型微調。同時，團隊需要確保在讓更多人接觸到這款工具的同時，保證 Sora 的安全性和責任性，防範潛在的濫用風險和虛假信息生成等問題。

**大飛的觀點：信仰與敬畏**

這次訪談對技術細節的深入探討並不多，更多的還是在宣傳 Sora 的發心、特性和願景，尤其是對於 Scaling Law 和通往 AGI 的堅定信念。對於網路上的質疑，並沒有重點解答，略微有些小失望。

Sora 發布後，最多的質疑聲音就是 Sora 到底是否理解了現實的物理世界。至少從 Sora 目前發布的影片來看，現在的技術路線還是無法處理相關性與因果性的矛盾，也無法處理局部合理與整體荒謬的矛盾。

不過，站在 Sora 作者的角度，我卻又能有些理解。當你通過不斷地擴大算力，看到模型從狗屁都生成不了，到逐漸能生成人物、畫面、動作、交互、物理關係甚至分鏡轉換，這種衝擊其實是很震撼的。你會從懷疑 Scaling Law，到相信 Scaling Law，再到信仰 Scaling Law。

現在的 AI 發展，確實有點開始向著信仰之戰演變了。一邊在使勁的堆砌算力，一邊在努力嘗試用小模型打敗大模型。但是不管怎麼樣，對於所謂的通用人工智慧 AGI，我們還是應該多保留一些敬畏之心。在這個過程中，我們追求的，究竟是真正全人類的福祉，還是一個又一個虛無縹緲的幻念呢？

感謝大家觀看本期影片，歡迎大家在評論區發表自己的看法，我們下期再見。

**主要修改和調整：**

*   **更清晰的標題和分段：** 將內容分成更小的段落，並使用標題來概括每個部分的重點。
*   **重點突出：** 強調了 Sora 的核心技術和兩位作者的主要觀點。
*   **更流暢的語言：** 調整了一些句子，使其更易於理解。
*   **去除口語化表達：** 儘量減少了口語化的表達，使其更正式。
*   **加入個人觀點總結：** 保留了大飛的個人觀點，並將其放在最後作為總結。

希望這個版本更符合您的需求！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>260. [2024-04-15] 【人工智能】AI和数字世界的下一步 | 凯文·凯利最新演讲 | 人类与AI的四种关系 | AI是否会取代我们 | 谁是第一批AI使用者 | AI与人类的感情羁绊</summary><br>

<a href="https://www.youtube.com/watch?v=PpZqf1EwFTs" target="_blank">
    <img src="https://img.youtube.com/vi/PpZqf1EwFTs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI和数字世界的下一步 | 凯文·凯利最新演讲 | 人类与AI的四种关系 | AI是否会取代我们 | 谁是第一批AI使用者 | AI与人类的感情羁绊

好的，以下是整理後的文稿，我將其分為幾個部分，並進行了簡化和重點提煉，希望能方便你理解和使用：

**標題：凱文·凱利 (K.K.) 對 AI 與數位世界的未來展望**

**核心觀點：**

*   **AI 的影響力深遠但理解尚淺：** 人工智慧正影響全球經濟，但我們對其潛力挖掘不足。AI 並非單一存在，各行業應有不同的 AI。
*   **人與 AI 的四種模式：**
    *   **人造外星人：** AI 是由人類設計製造的，可能超越人類智能，有獨特的認知和思維方式，能跳脫人類常規思維。
    *   **AI 耳語者：** 提示工程師與 AI 共同創造，需要花費大量時間與 AI 共事，了解其運作機制，給予積極情感回饋，提升 AI 回覆品質。
    *   **私人實習生：** AI 像一個 24 小時的實習生，提供初始性工作，例如設計大綱或草稿，再由人完成。Copilot 提高程式設計師生產力 56%，寫作提高 37%。
    *   **共生：** 人不會被 AI 取代，但可能被善用 AI 的人取代。AI 完成簡單工作，讓人處理棘手問題，並激發藝術靈感。生成式 AI 與人的關係類似 1+1>2，AI 將成為合夥人、隊友、教練、副駕駛助手。
*   **大語言模型與對話式介面：** 大語言模型原用於語言翻譯，但發展出推理能力。對話式使用者介面類似早期的圖形介面，將文字資訊轉化為視覺資訊，符合人類溝通需求，並改變技術應用。
*   **AI 的未來：** 未來幾年，AI 新創企業會更容易，AI 會變成商品，AI 介面會成為區別商品品質的關鍵。當 AI 隱形時，才是最成功的，95% 的應用將在後台運行。
*   **AI 的應用領域：** AI 內部流程應用（程式設計、金融分析、傳媒溝通）更強大，外部應用於自動駕駛、機器人等產品。AI 原生企業的商業模式將與以往不同。
*   **AI 的受益者：** 老師、醫生、領導者等中層人員受益最大，年輕新創公司更易採用 AI。
*   **增強現實（AR）與 “鏡像世界”：** AR 與 AI 相互掛鉤，Vision Pro 的普及需要時間，AI 加持後可自動理解環境，打造社交屬性強的“鏡像世界”，用於實戰訓練和試錯。
*   **AI 的情感羈絆：** 對話的自然表達讓人們不自覺代入情感，AI 透過語言和表情感受情感。未來 AI 可能像寵物一樣與人產生情感，這種羈絆感可能超乎預期。

**未來展望：**

*   現在是 AI 發展初期，30 年後回顧 2024 年的 AI 技術可能覺得落後。
*   重點是讓 AI 幫助人類成為更好的人類，而非取代人類。
*   交互方式的創新比卷底层大模型更有機會。

**關鍵詞：**

*   凱文·凱利 (K.K.)
*   AI (人工智慧)
*   生成式 AI
*   大語言模型
*   對話式介面
*   AR (增強現實)
*   鏡像世界
*   Perplexity AI

**其他：**

*   本內容整理自《連線》雜誌創始主編凱文·凱利在中國的一場線下對話，主題為《What's Next：in AI and Digital World》。

**整理說明：**

*   我刪除了一些口語化的表達，使其更精煉。
*   我將重點內容整理成條列式，方便快速閱讀。
*   我提取了關鍵詞，方便日後檢索。
*   我重新撰寫了標題，使其更具吸引力。
*   我新增了簡短的總結說明，方便理解文稿背景。

希望這個版本對你有幫助！如果有任何需要修改的地方，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>259. [2024-04-14] 【人工智能】Ai Pin产品体验大翻车 | 五大槽点 | 下一个iPhone还是Google Glass | Sam Altman投资 | Humane | 前苹果设计总监</summary><br>

<a href="https://www.youtube.com/watch?v=aKpXjlsiEm4" target="_blank">
    <img src="https://img.youtube.com/vi/aKpXjlsiEm4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Ai Pin产品体验大翻车 | 五大槽点 | 下一个iPhone还是Google Glass | Sam Altman投资 | Humane | 前苹果设计总监

好的，這是我整理後的文稿，我將其分成幾個段落，並提取要點，使其更易於閱讀：

**1. 產品介紹：Ai Pin - 號稱AI時代的iPhone**

*   **產品定義：** 無屏幕的獨立穿戴設備，搭載高通驍龍八核芯片和雲端AI大模型。
*   **交互方式：** 觸摸、語音、激光投射、手勢。
*   **功能：**
    *   訪問GPT-4和谷歌Gemini，獲取信息。
    *   50種語言的實時翻譯。
    *   1300萬像素攝像頭，識別環境，提供上下文回答。
    *   通過激光投射將內容顯示在手掌上，720P分辨率，支持手勢操作。
*   **外觀：** 鋁材外殼，像胸針，重約54克。
*   **組成：** 方形設備 + 磁性吸附電池組。
*   **價格：** 起售價699美元 + 每月24美元T-Mobile套餐費用（包含流量、通話、雲存儲等）。
*   **發布會展示功能：** 語音通話、修飾文稿、處理郵件、實時翻譯、識別食物、推薦餐廳和音樂等。

**2. 用户体验与批评：理想与现实的巨大差距**

*   **用戶收到產品後的普遍吐槽，歸納為「五宗罪」：**

    *   **投影問題：** 戶外光線下難以看清，只能投射在掌心，投射距離固定，顯示面積小，閱讀長文本困難。
    *   **手勢操作：** 學習成本高，過於靈敏，容易誤操作，影響穩定性。
    *   **散熱問題：** 連續使用容易過熱，影響續航。
    *   **語音反應速度：** 慢，且容易出錯，成功率低。
    *   **價格昂貴：** 功能不多，技術不成熟，性價比低。
*   **其他問題：** 佩戴體驗差，容易引起他人警覺。

**3. 公司背景：Humane - 蘋果前員工創立**

*   **創始人：** 伊姆蘭·喬杜里（Imran Chaudhri）和貝瑟尼·邦吉奧諾（Bethany Bongiorno），曾就職於蘋果。
*   **喬杜里：** 負責Mac和iPhone等項目的硬件和軟件設計，參與設計初代iPhone。
*   **邦吉奧諾：** 擔任iOS、macOS、iPadOS項目經理。
*   **團隊：** 260人團隊中有超過100人曾就職於蘋果。
*   **創立理念：** 反思技術進步可能帶來的負面影響。
*   **估值：** 8.5億美元。
*   **股東：** OpenAI的CEO Sam Altman是最大股東。
*   **前期榮譽：** 被《時代》雜誌選為「2023年度發明產品」。

**4. 歷史對比：Google Glass的教訓**

*   **Google Glass：** 曾被視為影響未來十年科技走向的產品，但最终停產。
*   **失敗原因：** 隱私問題、價格高昂、實際使用局限性。
*   **相似之處：** 功能稀少、性能不足、實際體驗差。
*   **爆料：** Google X團隊早就知道Google Glass是半成品。
*   **結論：** Ai Pin可能重蹈Google Glass的覆轍。

**5. 公司現狀：裁員和CTO離職**

*   **裁員：** 裁員10人，占公司員工總數的4%。
*   **CTO離職：** 長期首席技術官帕特里克蓋茨（Patrick Gates）離職。

**6. 總結：Ai Pin的前景**

*   **用户积极反馈：** 做工精良、佩戴方便、拍照质量不错、实时翻译较为准确。
*   **未来展望：** 距离成为AI时代的iPhone还有很长的路要走。

**總體評價：**

Ai Pin作為一款創新產品，概念新穎，但實際使用體驗與宣傳存在較大差距。在解決現有問題、降低成本之前，難以成為主流產品。 Google Glass的經驗值得借鑑，Humane需要更加務實地推進產品發展。

**建議：**

*   您可以將這份整理後的文稿作為摘要，快速了解Ai Pin的優缺點。
*   您可以根據自己的需求，深入研究文稿中提到的各個方面，例如用戶體驗、公司背景、技術問題等。

希望這個整理對您有幫助！ 如果您有其他需要整理的文件，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>258. [2024-04-12] 【人物】丹尼尔·卡尼曼 Daniel Kahneman | 诺贝尔经济学奖得主 | 启发性偏见 | 前景理论 | 框架效应 | 思考快与慢 | 噪声 | 行为经济学</summary><br>

<a href="https://www.youtube.com/watch?v=_0hziQoshn0" target="_blank">
    <img src="https://img.youtube.com/vi/_0hziQoshn0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】丹尼尔·卡尼曼 Daniel Kahneman | 诺贝尔经济学奖得主 | 启发性偏见 | 前景理论 | 框架效应 | 思考快与慢 | 噪声 | 行为经济学

好的，我來幫您整理這篇文稿，使其更結構化、更易於閱讀：

**主題：緬懷行為經濟學巨匠丹尼爾·卡尼曼 (1934-2024)**

**引言：**

*   最佳拍檔大飛介紹，普林斯頓大學榮譽退休教授、美國科學院院士丹尼爾·卡尼曼於2024年3月27日逝世，享年90歲。
*   卡尼曼在認知心理學、享樂心理學和經濟學領域貢獻卓著，尤其在行為經濟學的開創性工作影響深遠。

**一、卡尼曼的學術貢獻與影響：**

*   **挑戰「理性人」假設：** 在卡尼曼之前，經濟學理論基於「理性人」假設。他引入「非理性」概念，創立行為經濟學，使其成為經濟學最具活力的學科。
*   **諾貝爾經濟學獎：** 2002年，因在行為經濟學的開創性工作獲得諾貝爾經濟學獎。
*   **雙系統理論：** 在著作《思考快與慢》中提出的「人類思維的快慢兩個系統」，深刻影響人工智慧技術的發展。例如，Andrej Karpathy 指出，卡尼曼的雙系統理論是思維鏈背後的原理。

**二、卡尼曼的人生歷程：**

*   **早年生活 (1934-1946):**
    *   1934年出生於特拉維夫（當時屬於巴勒斯坦），父母為立陶宛移民至法國的猶太人。
    *   童年在巴黎度過，父親伊法蓮·卡尼曼任職於歐萊雅公司。
    *   1940年，因德軍佔領巴黎，全家逃亡至法國中部。
    *   1944年，父親因糖尿病去世，盟軍隨後收復法國。
    *   1946年，隨母親搬回特拉維夫。
*   **以色列歲月 (1946-1958):**
    *   1948年，以色列建國，卡尼曼被捲入戰爭。
    *   難以融入新國家，在家說法語，喜愛閱讀思考心理學問題。
    *   1951年，進入希伯來大學專修心理學，對精神分析和行為主義學派不感興趣，更痴迷於格式塔學派。
    *   1954年，大學畢業後服兵役，任職以色列國防軍心理部門，負責新兵面試和崗位分配，並編制新兵面試量表。
*   **留學美國 (1958-1967):**
    *   1958年，前往美國加州大學伯克利分校攻讀心理學博士。
    *   在奧斯汀·里格斯診所學習，開始關注注意力的分配和「事後諸葛亮」行為。
    *   1961年，取得博士學位後回到希伯來大學任教，研究視覺感知和注意力，並建立視覺實驗室。
    *   1965年，赴美國密歇根大學進行博士後研究，與傑克遜·比蒂合作，發現瞳孔收縮可以作為考察人腦處理狀態的指標，研究成果發表在《科學》雜誌。
    *   赴哈佛大學訪學，結識第二任妻子，英國心理學家安妮·特萊斯曼。
*   **學術生涯 (1967-2024):**
    *   1967年秋，回到希伯來大學擔任終身教授。
    *   1969年，與阿莫斯·特沃斯基在研討班上相識，成為摯友，共同提出了启发性偏见、前景理論、框架效應等重要理論，聲名大噪。
    *   兩人開始培養對心理學感興趣的下一代經濟學家，包括理查德·塞勒和喬治·洛溫斯坦。
    *   2002年獲得諾貝爾經濟學獎，但特沃斯基已因癌症去世。
    *   卡尼曼的理論被經濟學家進一步擴展，如卡斯·桑斯坦和塞勒將行為經濟學應用到政策制定，形成「助推」理論。

**三、卡尼曼在行為經濟學領域的開創性貢獻：**

*   **启发性偏见 (Heuristic Bias):**
    *   挑戰傳統經濟學的「理性人」假設。
    *   人們在不確定時，會依靠有限的启发式偏见簡化判斷。
    *   分類：
        *   **代表性启发 (Representativeness Heuristic):** 過度重視代表性事件，忽略統計規律。
        *   **可得性启发 (Availability Heuristic):** 依賴更容易獲取的訊息。
        *   **調整型启发 (Adjustment Heuristic) / 錨定效應 (Anchoring):** 基於錨點進行判斷，可能導致「過分自信」和「事後諸葛亮」效應。
*   **前景理论 (Prospect Theory):**
    *   挑戰期望效用理論。
    *   人們關注相對於參考點的財富變化。
    *   面臨收益時風險迴避，面臨損失時風險偏好。
    *   對損失的痛苦大於獲得同等收益的快樂。
    *   前期決策結果影響風險態度。
    *   與塞勒合作提出稟賦效應 (Endowment Effect)，解釋人們對擁有物品的偏好。
*   **框架效应 (Framing Effects):**
    *   決策受背景環境影響。
    *   例如，在公共衛生實驗中，人們對收益和損失的描述方式影響決策。
    *   塞勒和約翰遜提出「心理帳戶」概念，解釋金融市場中的反常現象。

**四、卡尼曼晚期對享樂心理學的關注：**

*   人的認知偏差不僅導致行為偏離最佳選擇，還會錯誤估計幸福感。
*   人們使用「過渡規則」思考問題，低估適應性效用，誇大變化效用。
*   幸福是經濟學關注的最終對象，政策制定應以糾正對幸福感知的偏誤為目標。
*   與艾倫·克魯格建立「國民幸福指數」，作為GDP之外的另一個評估國家發展水平的指標。

**五、《思考快與慢》的總結：**

*   人類的認知系統包含系統1（快速、直覺）和系統2（慢速、理性）。
*   启发性偏见、前景效應、框架效應等問題源於過度依賴系統1。
*   應對方法：
    *   意識到启发性偏见的存在，主動矯正偏差。
    *   引入事前剖析的思路，預測潛在問題。
    *   善用思維捷徑，實施更好的政策。

**六、卡尼曼的人生哲學：**

*   童年經歷磨難，但從知識中找到寧靜。
*   將探究幸福作為自己的追求。
*   珍惜與特沃斯基的友誼。
*   體驗生活而非評價判斷。
*   最快樂的時光是與所愛之人共度。

**結論：**

*   丹尼爾·卡尼曼是20世紀最重要的心理學家和經濟學家之一。
*   用孟子的「生於憂患死於安樂」來概括他的一生最為貼切。

**結尾：**

*   感謝大家觀看本期影片，下期再見。

**修改說明：**

*   **結構化：** 將內容分成幾個主要部分，每個部分都有明確的標題和子標題，方便閱讀。
*   **簡潔化：** 刪除了一些重複或不必要的詞語和句子，讓內容更精煉。
*   **突出重點：** 用粗體標示了重要概念和關鍵詞，方便讀者快速掌握重點。
*   **統一用詞：** 統一使用「启发式偏见」而不是「启发性偏见」等，確保全文一致性。
*   **增加說明：** 對於一些專業術語，增加簡單的解釋，幫助讀者理解。
*   **調整語氣：** 稍作修改，更像一篇正式的文稿。

希望這樣的整理對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>257. 【人工智能】AI芯片竞赛加速 |  Intel/AMD/Google同时发布新款  | Gaudi 3 | Versal 2代 | Axion | TPU v5p</summary><br>

<a href="https://www.youtube.com/watch?v=DFOBIE5Zmx0" target="_blank">
    <img src="https://img.youtube.com/vi/DFOBIE5Zmx0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI芯片竞赛加速 |  Intel/AMD/Google同时发布新款  | Gaudi 3 | Versal 2代 | Axion | TPU v5p



---

</details>

<details>
<summary>256. Amazing!  These songs are all created by AI | Udio music | udio.com | Free to use</summary><br>

<a href="https://www.youtube.com/watch?v=KGQIeYv8qdw" target="_blank">
    <img src="https://img.youtube.com/vi/KGQIeYv8qdw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Amazing!  These songs are all created by AI | Udio music | udio.com | Free to use



---

</details>

<details>
<summary>255. 【SpaceX】马斯克最新公开火星登陆计划 | 20年内人类移民火星 | 每隔两年出发一次 | 星舰即将开启第四次飞行 | 月球基地Alpha</summary><br>

<a href="https://www.youtube.com/watch?v=OKDATzNIM9w" target="_blank">
    <img src="https://img.youtube.com/vi/OKDATzNIM9w/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【SpaceX】马斯克最新公开火星登陆计划 | 20年内人类移民火星 | 每隔两年出发一次 | 星舰即将开启第四次飞行 | 月球基地Alpha



---

</details>

<details>
<summary>254. 【人物】阿里巴巴现在是自食其果 | 蔡崇信最新商业访谈 | 阿里巴巴董事会主席 | 成长经历 | 阿里现状 | 中国经济 | 科技与AI | 地缘政治</summary><br>

<a href="https://www.youtube.com/watch?v=X4cXDN337aI" target="_blank">
    <img src="https://img.youtube.com/vi/X4cXDN337aI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】阿里巴巴现在是自食其果 | 蔡崇信最新商业访谈 | 阿里巴巴董事会主席 | 成长经历 | 阿里现状 | 中国经济 | 科技与AI | 地缘政治



---

</details>

<details>
<summary>253. 【人工智能】AI智能体工作流 | Agentic Reasoning | 吴恩达Andrew Ng | 红杉AI Ascent 2024分享 | Agent 4大设计模式</summary><br>

<a href="https://www.youtube.com/watch?v=Up-jvRsrIGk" target="_blank">
    <img src="https://img.youtube.com/vi/Up-jvRsrIGk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI智能体工作流 | Agentic Reasoning | 吴恩达Andrew Ng | 红杉AI Ascent 2024分享 | Agent 4大设计模式



---

</details>

<details>
<summary>252. 【人工智能】红杉AI Ascent 2024 | 人工智能的机遇 | 投资合伙人观点分享 | 软件取代服务 | 2024年关于AI的4大预测 | AI的长期影响</summary><br>

<a href="https://www.youtube.com/watch?v=yNpIrBDcSdw" target="_blank">
    <img src="https://img.youtube.com/vi/yNpIrBDcSdw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】红杉AI Ascent 2024 | 人工智能的机遇 | 投资合伙人观点分享 | 软件取代服务 | 2024年关于AI的4大预测 | AI的长期影响



---

</details>

<details>
<summary>251. 【Nvidia】英伟达GTC财务分析师问答 | 英伟达究竟在卖什么 | 数据中心 | 软件 | 芯片 | 加速计算 | 生成式AI | Blackwell</summary><br>

<a href="https://www.youtube.com/watch?v=Jsk6fHuIwy4" target="_blank">
    <img src="https://img.youtube.com/vi/Jsk6fHuIwy4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Nvidia】英伟达GTC财务分析师问答 | 英伟达究竟在卖什么 | 数据中心 | 软件 | 芯片 | 加速计算 | 生成式AI | Blackwell



---

</details>

<details>
<summary>250. 【人工智能】AI发展的现状 | Andrej Karpathy | 红杉AI Ascent 2024围炉对话 | LLM OS | 马斯克的管理风格 | AI生态 | 强化学习还很弱 | 开源与AGI</summary><br>

<a href="https://www.youtube.com/watch?v=Y8Bp3IqQBLQ" target="_blank">
    <img src="https://img.youtube.com/vi/Y8Bp3IqQBLQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI发展的现状 | Andrej Karpathy | 红杉AI Ascent 2024围炉对话 | LLM OS | 马斯克的管理风格 | AI生态 | 强化学习还很弱 | 开源与AGI



---

</details>

<details>
<summary>249. 【人工智能】Databricks发布最强开源大模型DBRX | 1320亿参数 | 16个混合专家MOE架构 | 整体性能超过GPT-3.5 | MosaicML | Jonathan Frankle</summary><br>

<a href="https://www.youtube.com/watch?v=c-Glym8F7Ik" target="_blank">
    <img src="https://img.youtube.com/vi/c-Glym8F7Ik/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Databricks发布最强开源大模型DBRX | 1320亿参数 | 16个混合专家MOE架构 | 整体性能超过GPT-3.5 | MosaicML | Jonathan Frankle



---

</details>

<details>
<summary>248. 【OpenAI】硅谷众多投资人怒喷Sam Altman | 造势大师 | 个人营销 | 渴望权利和影响力 | 上帝的使者 | AI帝国的野心 | 何时会走下神坛</summary><br>

<a href="https://www.youtube.com/watch?v=pBs0IdumihI" target="_blank">
    <img src="https://img.youtube.com/vi/pBs0IdumihI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】硅谷众多投资人怒喷Sam Altman | 造势大师 | 个人营销 | 渴望权利和影响力 | 上帝的使者 | AI帝国的野心 | 何时会走下神坛



---

</details>

<details>
<summary>247. 【人工智能】Mistral.AI CEO Arthur Mensch 访谈 | 强化学习不再重要 | 大模型的效率与规模 | 开源与商业化的平衡 | 全球化</summary><br>

<a href="https://www.youtube.com/watch?v=Ir5EFI_dc7Y" target="_blank">
    <img src="https://img.youtube.com/vi/Ir5EFI_dc7Y/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Mistral.AI CEO Arthur Mensch 访谈 | 强化学习不再重要 | 大模型的效率与规模 | 开源与商业化的平衡 | 全球化



---

</details>

<details>
<summary>246. 【人工智能】人工智能的野性心智 | The Feral Mind Of Artificial Intelligence | 阿韦龙野人 | 语言与意识 | AI是否能产生心智 | 人类是否会被AI抛弃</summary><br>

<a href="https://www.youtube.com/watch?v=mhkVk3xUWMQ" target="_blank">
    <img src="https://img.youtube.com/vi/mhkVk3xUWMQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】人工智能的野性心智 | The Feral Mind Of Artificial Intelligence | 阿韦龙野人 | 语言与意识 | AI是否能产生心智 | 人类是否会被AI抛弃



---

</details>

<details>
<summary>245. 【人工智能】2024全球AI产品Top100报告 | A16Z | 五个趋势 | 22家新公司上榜 | AI伴侣崛起 | 网页榜 | 移动榜</summary><br>

<a href="https://www.youtube.com/watch?v=cWUs1GhBx18" target="_blank">
    <img src="https://img.youtube.com/vi/cWUs1GhBx18/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】2024全球AI产品Top100报告 | A16Z | 五个趋势 | 22家新公司上榜 | AI伴侣崛起 | 网页榜 | 移动榜



---

</details>

<details>
<summary>244. 【英伟达】GTC2024圆桌论坛 | Transforming AI | 黄仁勋 | Transformer论文七名作者首聚 | 探讨Transformer的起源、现状与未来</summary><br>

<a href="https://www.youtube.com/watch?v=b4foYNq-qJ8" target="_blank">
    <img src="https://img.youtube.com/vi/b4foYNq-qJ8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【英伟达】GTC2024圆桌论坛 | Transforming AI | 黄仁勋 | Transformer论文七名作者首聚 | 探讨Transformer的起源、现状与未来



---

</details>

<details>
<summary>243. 【人物】OpenAI CEO Sam Altman最新专访 | 2小时精华版 | 罢免闹剧 | 马斯克诉讼 | Ilya | Sora | Q* | GPT-5 | AGI</summary><br>

<a href="https://www.youtube.com/watch?v=0J5Q7ISuuhc" target="_blank">
    <img src="https://img.youtube.com/vi/0J5Q7ISuuhc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】OpenAI CEO Sam Altman最新专访 | 2小时精华版 | 罢免闹剧 | 马斯克诉讼 | Ilya | Sora | Q* | GPT-5 | AGI



---

</details>

<details>
<summary>242. 【英伟达】GTC 2024|黄仁勋2小时演讲精华版|六大亮点| Blackwell GPU | DGX B200 | NVL72 | cuLitho | GROOT | Omniverse Cloud</summary><br>

<a href="https://www.youtube.com/watch?v=zBIddyiMXsU" target="_blank">
    <img src="https://img.youtube.com/vi/zBIddyiMXsU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【英伟达】GTC 2024|黄仁勋2小时演讲精华版|六大亮点| Blackwell GPU | DGX B200 | NVL72 | cuLitho | GROOT | Omniverse Cloud



---

</details>

<details>
<summary>241. 【人工智能】马斯克开源Grok-1 | xAI 史上最大开源大模型 | 3140亿参数 | 8专家MoE专家模型 | JAX | Rust</summary><br>

<a href="https://www.youtube.com/watch?v=wimBiMvaOpw" target="_blank">
    <img src="https://img.youtube.com/vi/wimBiMvaOpw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】马斯克开源Grok-1 | xAI 史上最大开源大模型 | 3140亿参数 | 8专家MoE专家模型 | JAX | Rust



---

</details>

<details>
<summary>240. 【闲聊】佛法与宇宙的终极真理 | 佛 | 佛法在讲什么 | 缘 | 空性 | 生死轮回 | 灵魂 | 宇宙的终极真理是什么 | 破二元对立 | 道</summary><br>

<a href="https://www.youtube.com/watch?v=Dhx9Aty4ycs" target="_blank">
    <img src="https://img.youtube.com/vi/Dhx9Aty4ycs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【闲聊】佛法与宇宙的终极真理 | 佛 | 佛法在讲什么 | 缘 | 空性 | 生死轮回 | 灵魂 | 宇宙的终极真理是什么 | 破二元对立 | 道



---

</details>

<details>
<summary>239. 【SpaceX】SpaceX“星舰”第三次轨道试飞 | 失败还是成功 | SpaceX的太空统治力 | 星舰Starship | 星链Starlink | 猎鹰9号Falcon 9 | 马斯克</summary><br>

<a href="https://www.youtube.com/watch?v=I81UYrOwrVI" target="_blank">
    <img src="https://img.youtube.com/vi/I81UYrOwrVI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【SpaceX】SpaceX“星舰”第三次轨道试飞 | 失败还是成功 | SpaceX的太空统治力 | 星舰Starship | 星链Starlink | 猎鹰9号Falcon 9 | 马斯克



---

</details>

<details>
<summary>238. 【人工智能】Figure 01机器人亮相 | OpenAI多模态能力加持 | 与人类流畅对话交互 | 具身智能的GPT-4时刻</summary><br>

<a href="https://www.youtube.com/watch?v=vO1wnHA0tZg" target="_blank">
    <img src="https://img.youtube.com/vi/vO1wnHA0tZg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Figure 01机器人亮相 | OpenAI多模态能力加持 | 与人类流畅对话交互 | 具身智能的GPT-4时刻



---

</details>

<details>
<summary>237. 【人工智能】AI的尽头是什么 | 光伏和储能 | 100万倍算力 | 信息茧房 | 黄仁勋 | Sam Altman | 一切可能只是我们的颠倒妄想</summary><br>

<a href="https://www.youtube.com/watch?v=r5YvoWsioyw" target="_blank">
    <img src="https://img.youtube.com/vi/r5YvoWsioyw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI的尽头是什么 | 光伏和储能 | 100万倍算力 | 信息茧房 | 黄仁勋 | Sam Altman | 一切可能只是我们的颠倒妄想



---

</details>

<details>
<summary>236. 【AIGC】Stable Diffusion 3.0技术报告解读 | 类Sora全新MMDiT架构 | 可在RTX 4090上运行80亿参数模型 | 性能碾压竞品 | 惊人的理解力和创造力</summary><br>

<a href="https://www.youtube.com/watch?v=09pACF9dvK8" target="_blank">
    <img src="https://img.youtube.com/vi/09pACF9dvK8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】Stable Diffusion 3.0技术报告解读 | 类Sora全新MMDiT架构 | 可在RTX 4090上运行80亿参数模型 | 性能碾压竞品 | 惊人的理解力和创造力



---

</details>

<details>
<summary>235. 【人工智能】Geoffrey Hinton牛津大学演讲精华版 | 数字智能会不会取代生物智能 | 符号学派 | 神经网络 | 大语言模型 | 幻觉与记忆 | 人类无法阻止AI | 超级智能会加快到来</summary><br>

<a href="https://www.youtube.com/watch?v=tUB_mmBXG9Y" target="_blank">
    <img src="https://img.youtube.com/vi/tUB_mmBXG9Y/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Geoffrey Hinton牛津大学演讲精华版 | 数字智能会不会取代生物智能 | 符号学派 | 神经网络 | 大语言模型 | 幻觉与记忆 | 人类无法阻止AI | 超级智能会加快到来



---

</details>

<details>
<summary>234. 【人工智能】Inflection AI发布最新Inflection-2.5大模型 | AI助手Pi | 同理心微调 | 仅用GPT-4 40%算力训练 | 性能接近GPT-4</summary><br>

<a href="https://www.youtube.com/watch?v=GeiuXDOMziY" target="_blank">
    <img src="https://img.youtube.com/vi/GeiuXDOMziY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Inflection AI发布最新Inflection-2.5大模型 | AI助手Pi | 同理心微调 | 仅用GPT-4 40%算力训练 | 性能接近GPT-4



---

</details>

<details>
<summary>233. 【人工智能】Yann LeCun最新3小时访谈精华版 | AI终将造福人类 | 世界模型 | 大模型的局限性 | AI末日论 | 开源大模型Llama</summary><br>

<a href="https://www.youtube.com/watch?v=31H-TiiRAd8" target="_blank">
    <img src="https://img.youtube.com/vi/31H-TiiRAd8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Yann LeCun最新3小时访谈精华版 | AI终将造福人类 | 世界模型 | 大模型的局限性 | AI末日论 | 开源大模型Llama



---

</details>

<details>
<summary>232. 【人工智能】中国的算力产业究竟该如何发展 | 五个问题 | 资源分散 | 公有云发展乏力 | 大模型红利 | 国产替代 | 产业政策</summary><br>

<a href="https://www.youtube.com/watch?v=aUlgwp3Y9HA" target="_blank">
    <img src="https://img.youtube.com/vi/aUlgwp3Y9HA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】中国的算力产业究竟该如何发展 | 五个问题 | 资源分散 | 公有云发展乏力 | 大模型红利 | 国产替代 | 产业政策



---

</details>

<details>
<summary>231. 【技术】闰年带来哪些程序Bug和影响 | 四年一次的软件灾难 | OpenAI也不幸中招 | 如何在程序中处理闰年 | 软件开发 | Leap Day Bug</summary><br>

<a href="https://www.youtube.com/watch?v=kyn4-WzbDzE" target="_blank">
    <img src="https://img.youtube.com/vi/kyn4-WzbDzE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【技术】闰年带来哪些程序Bug和影响 | 四年一次的软件灾难 | OpenAI也不幸中招 | 如何在程序中处理闰年 | 软件开发 | Leap Day Bug



---

</details>

<details>
<summary>230. 【人工智能】OpenAI发文正式回应马斯克的起诉 | 反驳所有指控 | 马斯克只投资4500万美元 | 早已知道成立营利性组织 | 伊利亚现身 | 神秘信息曝光</summary><br>

<a href="https://www.youtube.com/watch?v=0Qffv1-D1lk" target="_blank">
    <img src="https://img.youtube.com/vi/0Qffv1-D1lk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OpenAI发文正式回应马斯克的起诉 | 反驳所有指控 | 马斯克只投资4500万美元 | 早已知道成立营利性组织 | 伊利亚现身 | 神秘信息曝光



---

</details>

<details>
<summary>229. 【人工智能】Google大神Jeff Dean最新演讲 | 机器学习令人兴奋的趋势 | 计算的十年飞跃 | 神经网络 | 语言模型十五年发展 | Gemini | ImageNet | AlexNet</summary><br>

<a href="https://www.youtube.com/watch?v=2O3yeztePxw" target="_blank">
    <img src="https://img.youtube.com/vi/2O3yeztePxw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Google大神Jeff Dean最新演讲 | 机器学习令人兴奋的趋势 | 计算的十年飞跃 | 神经网络 | 语言模型十五年发展 | Gemini | ImageNet | AlexNet



---

</details>

<details>
<summary>228. 【人工智能】Anthropic突然发布Claude 3 | 多项指标超越GPT-4 | 三个规模尺寸 | 支持200k上下文长度 | 多模态 | 安全提升 | GPT-5是否会加速到来</summary><br>

<a href="https://www.youtube.com/watch?v=gXaXJ0XXYDk" target="_blank">
    <img src="https://img.youtube.com/vi/gXaXJ0XXYDk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Anthropic突然发布Claude 3 | 多项指标超越GPT-4 | 三个规模尺寸 | 支持200k上下文长度 | 多模态 | 安全提升 | GPT-5是否会加速到来



---

</details>

<details>
<summary>227. 【人工智能】马斯克正式起诉OpenAI | 46页1万4千字诉状 | 五大罪状 | 十项诉求 | 被骗钱骗人骗技术 | 赔偿损失</summary><br>

<a href="https://www.youtube.com/watch?v=sAGlpvNsE9E" target="_blank">
    <img src="https://img.youtube.com/vi/sAGlpvNsE9E/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】马斯克正式起诉OpenAI | 46页1万4千字诉状 | 五大罪状 | 十项诉求 | 被骗钱骗人骗技术 | 赔偿损失



---

</details>

<details>
<summary>226. 【Google】Gemini再次翻车 | 只能生成黑人照片 | 错误不可接受 | Google面临内部大调整 | 大模型也要坚持政治正确么？</summary><br>

<a href="https://www.youtube.com/watch?v=yTSBAFTxHtw" target="_blank">
    <img src="https://img.youtube.com/vi/yTSBAFTxHtw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Google】Gemini再次翻车 | 只能生成黑人照片 | 错误不可接受 | Google面临内部大调整 | 大模型也要坚持政治正确么？



---

</details>

<details>
<summary>225. 【人工智能】《苦涩的教训 The Bitter Lesson》  | 人工智能经典文章 | 我们应该过去70年的研究中获得什么经验 | 如何看待人工智能 | 算力 | scaling law</summary><br>

<a href="https://www.youtube.com/watch?v=vbVfAqPI8ng" target="_blank">
    <img src="https://img.youtube.com/vi/vbVfAqPI8ng/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】《苦涩的教训 The Bitter Lesson》  | 人工智能经典文章 | 我们应该过去70年的研究中获得什么经验 | 如何看待人工智能 | 算力 | scaling law



---

</details>

<details>
<summary>224. 【英伟达】Nvidia市场创造纪录 | 2万亿美元 | 低估还是泡沫 | 地球上最重要的股票 | AI信仰 | 黄仁勋</summary><br>

<a href="https://www.youtube.com/watch?v=r2U_NEMM6_0" target="_blank">
    <img src="https://img.youtube.com/vi/r2U_NEMM6_0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【英伟达】Nvidia市场创造纪录 | 2万亿美元 | 低估还是泡沫 | 地球上最重要的股票 | AI信仰 | 黄仁勋



---

</details>

<details>
<summary>223. 【人工智能】中国大模型行业的五个真问题 | 究竟应该如何看待国内大模型行业的发展现状 | 模型 | 算力 | 数据 | 资本 | 商业化 | 人才 | 反思</summary><br>

<a href="https://www.youtube.com/watch?v=sTODZX-JLro" target="_blank">
    <img src="https://img.youtube.com/vi/sTODZX-JLro/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】中国大模型行业的五个真问题 | 究竟应该如何看待国内大模型行业的发展现状 | 模型 | 算力 | 数据 | 资本 | 商业化 | 人才 | 反思



---

</details>

<details>
<summary>222. 【人工智能】Google发布首个开放模型 Gemma | 2B和7B参数量 | 挑战Llama 2 和Mistral 7B | 轻量级个人电脑可运行</summary><br>

<a href="https://www.youtube.com/watch?v=IyLNss9fV8I" target="_blank">
    <img src="https://img.youtube.com/vi/IyLNss9fV8I/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Google发布首个开放模型 Gemma | 2B和7B参数量 | 挑战Llama 2 和Mistral 7B | 轻量级个人电脑可运行



---

</details>

<details>
<summary>221. 【人工智能】Google升级Gemini 1.5 Pro | 支持100万-1000万 Token长度 | MoE架构 | 多模态识别和理解 | 上下文学习</summary><br>

<a href="https://www.youtube.com/watch?v=-W4_N_TjHNY" target="_blank">
    <img src="https://img.youtube.com/vi/-W4_N_TjHNY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Google升级Gemini 1.5 Pro | 支持100万-1000万 Token长度 | MoE架构 | 多模态识别和理解 | 上下文学习



---

</details>

<details>
<summary>220. 【人工智能】震惊世界！OpenAI发布最新文生视频模型SORA | 长达60秒高清视频生成 | AGI来临 | 模拟世界 | 缩放法则ScalingLaw</summary><br>

<a href="https://www.youtube.com/watch?v=TAsTuRZOCIQ" target="_blank">
    <img src="https://img.youtube.com/vi/TAsTuRZOCIQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】震惊世界！OpenAI发布最新文生视频模型SORA | 长达60秒高清视频生成 | AGI来临 | 模拟世界 | 缩放法则ScalingLaw



---

</details>

<details>
<summary>219. 【人工智能】如何写好提示词 | OpenAI官方提示工程指南 | 六大原则 | 清晰细致 | 提供参考 | 任务拆分 | 让它思考 | 外部工具 | 系统测试</summary><br>

<a href="https://www.youtube.com/watch?v=yhk9x__D-Us" target="_blank">
    <img src="https://img.youtube.com/vi/yhk9x__D-Us/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】如何写好提示词 | OpenAI官方提示工程指南 | 六大原则 | 清晰细致 | 提供参考 | 任务拆分 | 让它思考 | 外部工具 | 系统测试



---

</details>

<details>
<summary>218. 【人工智能】什么是混合专家模型MoE | 稀疏层 | 门控路由 | 发展历史和挑战 | Mixtral AI |【中间有彩蛋】</summary><br>

<a href="https://www.youtube.com/watch?v=GpWBZQRHAfY" target="_blank">
    <img src="https://img.youtube.com/vi/GpWBZQRHAfY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】什么是混合专家模型MoE | 稀疏层 | 门控路由 | 发展历史和挑战 | Mixtral AI |【中间有彩蛋】



---

</details>

<details>
<summary>217. 【人工智能】由弱到强的对齐方法 | Weak To Strong | OpenAI超级对齐团队首篇论文 | 如何让AI来监督AI</summary><br>

<a href="https://www.youtube.com/watch?v=o-BDLUxPcRs" target="_blank">
    <img src="https://img.youtube.com/vi/o-BDLUxPcRs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】由弱到强的对齐方法 | Weak To Strong | OpenAI超级对齐团队首篇论文 | 如何让AI来监督AI



---

</details>

<details>
<summary>216. 【Google】谷歌发布最强多模态模型Gemini又翻车? | 演示视频被质疑夸大造假 | 模型能力究竟如何 | 能否硬刚GPT-4</summary><br>

<a href="https://www.youtube.com/watch?v=NAskCMCmTCw" target="_blank">
    <img src="https://img.youtube.com/vi/NAskCMCmTCw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Google】谷歌发布最强多模态模型Gemini又翻车? | 演示视频被质疑夸大造假 | 模型能力究竟如何 | 能否硬刚GPT-4



---

</details>

<details>
<summary>215. 【人工智能】万字通俗讲解向量数据库 | 什么是向量数据库 | 有何不同 | 如何选择 |  Vector Database | Chroma | Pinecone | Milvus</summary><br>

<a href="https://www.youtube.com/watch?v=uQcBwN1PEyI" target="_blank">
    <img src="https://img.youtube.com/vi/uQcBwN1PEyI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】万字通俗讲解向量数据库 | 什么是向量数据库 | 有何不同 | 如何选择 |  Vector Database | Chroma | Pinecone | Milvus



---

</details>

<details>
<summary>214. 【OpenAI】微软和OpenAI合作的内幕 | Sam Altman被罢免的原因 | 微软背后的三个计划 | New Yorker长文爆料 | Satya Nadella | Kevin Scott</summary><br>

<a href="https://www.youtube.com/watch?v=iA8or6kX_Cg" target="_blank">
    <img src="https://img.youtube.com/vi/iA8or6kX_Cg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】微软和OpenAI合作的内幕 | Sam Altman被罢免的原因 | 微软背后的三个计划 | New Yorker长文爆料 | Satya Nadella | Kevin Scott



---

</details>

<details>
<summary>213. 【ChatGPT】ChatGPT一周年回顾 | 见证AI成长之路 | OpenAI | 大语言模型 | 多模态 | 融资与竞争 | 监管与安全</summary><br>

<a href="https://www.youtube.com/watch?v=oyX8KmjDJdo" target="_blank">
    <img src="https://img.youtube.com/vi/oyX8KmjDJdo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【ChatGPT】ChatGPT一周年回顾 | 见证AI成长之路 | OpenAI | 大语言模型 | 多模态 | 融资与竞争 | 监管与安全



---

</details>

<details>
<summary>212. 【AIGC】国内AIGC著作权侵权第一案 | 一审判决原告胜诉 | 智力成果如何判定 | 作品作者究竟是谁 | AI生成图片著作权</summary><br>

<a href="https://www.youtube.com/watch?v=EPlopndHmpo" target="_blank">
    <img src="https://img.youtube.com/vi/EPlopndHmpo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AIGC】国内AIGC著作权侵权第一案 | 一审判决原告胜诉 | 智力成果如何判定 | 作品作者究竟是谁 | AI生成图片著作权



---

</details>

<details>
<summary>211. 【GPU】GPU架构入门指南 | GPU内部工作原理 | 执行过程 | 如何运行kernel | GPU与CPU有什么不同 | CUDA | Warp</summary><br>

<a href="https://www.youtube.com/watch?v=x4DL9SRA3Og" target="_blank">
    <img src="https://img.youtube.com/vi/x4DL9SRA3Og/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【GPU】GPU架构入门指南 | GPU内部工作原理 | 执行过程 | 如何运行kernel | GPU与CPU有什么不同 | CUDA | Warp



---

</details>

<details>
<summary>210. 【人工智能】大语言模型入门简介 | Andrej Karpathy最新视频教程 | 大语言模型的本质 | 发展趋势 | 安全 | 通俗易懂小白友好</summary><br>

<a href="https://www.youtube.com/watch?v=3AiwdQJln5s" target="_blank">
    <img src="https://img.youtube.com/vi/3AiwdQJln5s/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】大语言模型入门简介 | Andrej Karpathy最新视频教程 | 大语言模型的本质 | 发展趋势 | 安全 | 通俗易懂小白友好



---

</details>

<details>
<summary>209. 【Google】现在的谷歌究竟是屠龙少年还是恶龙 | 18年老员工Ian Hickson离职吐槽 | 不作恶的理念是否还能坚守 | 剑指Sundar Pichai和公司管理层</summary><br>

<a href="https://www.youtube.com/watch?v=A5-symZov30" target="_blank">
    <img src="https://img.youtube.com/vi/A5-symZov30/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Google】现在的谷歌究竟是屠龙少年还是恶龙 | 18年老员工Ian Hickson离职吐槽 | 不作恶的理念是否还能坚守 | 剑指Sundar Pichai和公司管理层



---

</details>

<details>
<summary>208. 【OpenAI】有关Q*项目的猜测 | 引发Sam Altman开除的背后原因 | 接近于AGI的突破 | AlphaGo Zero | GPT Zero</summary><br>

<a href="https://www.youtube.com/watch?v=dsXDRF9KvkY" target="_blank">
    <img src="https://img.youtube.com/vi/dsXDRF9KvkY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】有关Q*项目的猜测 | 引发Sam Altman开除的背后原因 | 接近于AGI的突破 | AlphaGo Zero | GPT Zero



---

</details>

<details>
<summary>207. 【OpenAI】OpenAI宫斗的内幕 | 公司内部管理混乱 | 分歧早已出现端倪 | 商业现实和科技理想 | 两种极端意识形态斗争的高潮 | 《大西洋月刊》发文</summary><br>

<a href="https://www.youtube.com/watch?v=OI4uzoF5rEs" target="_blank">
    <img src="https://img.youtube.com/vi/OI4uzoF5rEs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】OpenAI宫斗的内幕 | 公司内部管理混乱 | 分歧早已出现端倪 | 商业现实和科技理想 | 两种极端意识形态斗争的高潮 | 《大西洋月刊》发文



---

</details>

<details>
<summary>206. 【OpenAI】OpenAI宫斗始末回顾 | Sam Alterman被董事会开除 | Greg Brockman离职 | Ilya Sutskever主导 | 微软成最大赢家 |OpenAI面临解体</summary><br>

<a href="https://www.youtube.com/watch?v=VJ4RJT-T3C0" target="_blank">
    <img src="https://img.youtube.com/vi/VJ4RJT-T3C0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】OpenAI宫斗始末回顾 | Sam Alterman被董事会开除 | Greg Brockman离职 | Ilya Sutskever主导 | 微软成最大赢家 |OpenAI面临解体



---

</details>

<details>
<summary>205. 【国产】号称全球最强的国产 AI 模型竟然套壳LLaMA | Yi模型 | 零一万物 | 李开复 | 官方回复</summary><br>

<a href="https://www.youtube.com/watch?v=cGW07ERrKTo" target="_blank">
    <img src="https://img.youtube.com/vi/cGW07ERrKTo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【国产】号称全球最强的国产 AI 模型竟然套壳LLaMA | Yi模型 | 零一万物 | 李开复 | 官方回复



---

</details>

<details>
<summary>204. 【人工智能】计算—宇宙的尽头 | 宇宙可以被计算么 | 万事万物的本质 | Ruliad | 如何用计算思维来思考AI、宇宙及万事万物 | AI大佬Stephen Wolfram最新TED演讲</summary><br>

<a href="https://www.youtube.com/watch?v=sb5omaDlYrM" target="_blank">
    <img src="https://img.youtube.com/vi/sb5omaDlYrM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】计算—宇宙的尽头 | 宇宙可以被计算么 | 万事万物的本质 | Ruliad | 如何用计算思维来思考AI、宇宙及万事万物 | AI大佬Stephen Wolfram最新TED演讲



---

</details>

<details>
<summary>203. 【OpenAI】GPT再迎史诗级更新 | GPT-4 Turbo | 可定制ChatGPT的GPTs | GPT Store | Assistants API | OpenAI首届开发者日</summary><br>

<a href="https://www.youtube.com/watch?v=3LiDEtluGSI" target="_blank">
    <img src="https://img.youtube.com/vi/3LiDEtluGSI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】GPT再迎史诗级更新 | GPT-4 Turbo | 可定制ChatGPT的GPTs | GPT Store | Assistants API | OpenAI首届开发者日



---

</details>

<details>
<summary>202. 【人工智能】State of AI report 2023 | 163页报告 | 15分钟解读 | 研究进展 | 行业局势 | 现有政策 | 安全问题 | 未来十个预测</summary><br>

<a href="https://www.youtube.com/watch?v=Vwdw3tUZzmI" target="_blank">
    <img src="https://img.youtube.com/vi/Vwdw3tUZzmI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】State of AI report 2023 | 163页报告 | 15分钟解读 | 研究进展 | 行业局势 | 现有政策 | 安全问题 | 未来十个预测



---

</details>

<details>
<summary>201. 【AI】什么是InfiniBand | 发展历程 | 工作原理 | AI的计算网络底座 | 训练GPT的网络 | Mellanox | Nvidia | RDMA | RoCE</summary><br>

<a href="https://www.youtube.com/watch?v=aCaJGxhABLc" target="_blank">
    <img src="https://img.youtube.com/vi/aCaJGxhABLc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI】什么是InfiniBand | 发展历程 | 工作原理 | AI的计算网络底座 | 训练GPT的网络 | Mellanox | Nvidia | RDMA | RoCE



---

</details>

