<details>
<summary>600. [2025-03-23] 【人工智能】大语言模型不会带来AGI | 图灵奖得主Yann LeCun最新访谈 | LLM的局限性 | 缺乏物理世界理解 | 推理缺陷 | V-JEPA | OpenAI | 过度炒作 | 开源优势</summary><br>

<a href="https://www.youtube.com/watch?v=NmCPbqlLjzo" target="_blank">
    <img src="https://img.youtube.com/vi/NmCPbqlLjzo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】大语言模型不会带来AGI | 图灵奖得主Yann LeCun最新访谈 | LLM的局限性 | 缺乏物理世界理解 | 推理缺陷 | V-JEPA | OpenAI | 过度炒作 | 开源优势

好的，我來為您整理這篇文稿，使其更清晰、更易讀：

**主題：楊立昆專訪重點：大語言模型的局限與AGI的未來**

**引言：**

大家好，我是大飛。在人工智能飛速發展的今天，各種新技術、新應用層出不窮。但繁華背後，AI的發展階段為何？未來方向為何？如今的大模型真能帶領我們走向AGI（通用人工智能）嗎？

**核心觀點：**

圖靈獎得主、Meta公司首席AI科學家楊立昆在接受亞歷克斯·坎特羅維茨的專訪中，對當前的大語言模型提出質疑，認為其存在諸多局限性。

**一、大語言模型的局限性：**

*   **缺乏創新能力：** 大語言模型擅長知識檢索和文本生成，但無法提出自己的科學發現。它們像是「知識淵博的復讀機」，無法創造新知識。
*   **缺乏對物理世界的理解和推理能力：** 大語言模型基於文本數據訓練，缺乏對物理世界的真正認知，無法像幼兒一樣通過觀察和體驗學習物理常識。
*   **推理機制存在缺陷：** 大語言模型缺乏真正的推理機制，無法像人類和動物一樣基於對情況的心理模型在大腦內部進行推理和規劃。
*   **缺乏抽象的精神表徵：** 大語言模型不具備心理模型，無法在內部進行推理和規劃，只能根據已有的文本數據生成看似合理的回答。

**二、大語言模型發展的瓶頸：**

*   **訓練數據耗盡：** 大語言模型已經耗盡了可用的自然文本數據，繼續擴展大語言模型難以獲得更大的回報。
*   **需要新型系統架構：** 迫切需要一種新型的系統架構，具備尋找有效解決方案、評估方案質量、以及規劃一系列行動以實現特定目標的能力。

**三、楊立昆的研究方向：V-JEPA**

*   **V-JEPA（視頻聯合嵌入預測架構）：** 一種全新的非生成式架構，不再試圖重建輸入的一部分，而是生成一種輸入的抽象表徵，能忽略輸入中真正不可預測的細節，專注於學習視頻的內在結構和抽象特徵。
*   **V-JEPA的優勢：**
    *   具備一定的物理常識，能識別不可能的視頻場景。
    *   可以通過表示世界在某一時刻的狀態和採取的行動，來預測下一時刻的狀態，進而實現推理和計劃功能。

**四、對OpenAI發展路線的擔憂：**

*   **擴展大語言模型並非AGI的唯一途徑：** 楊立昆認為，僅僅依靠擴展大語言模型，無論投入多少資金和數據，都無法達到人類水平的人工智能。
*   **發展方向存在不確定性：** OpenAI希望通過大量數據訓練讓系統能夠回答任何問題，但這與真正具備創新能力和解決新問題能力的智能還有很大差距。

**五、AI領域的發展風險：**

*   **AI泡沫：** 當前AI領域的過度炒作可能導致AI寒冬的再次降臨。
*   **實際部署的挑戰：** 部署可靠的AI系統仍然面臨著巨大挑戰，例如自動駕駛技術和IBM Watson的失敗案例。

**六、开源的优势：**

*   **創新：** 開源可以從全球招募人才，匯聚各種不同的想法和創造力。
*   **成本：** 運行開源模型的成本更低。
*   **安全：** 開源解决方案提供了更多的控制權，可以在本地運行，大大提高了安全性。
*   **打破地域和機構的限制：** 讓世界各地的科學家都能參與到AI的發展中來。

**七、對AGI的判斷：**

*   **AGI是持續發展的過程：** AGI不會有一個秘密的靈丹妙藥，需要許多不同的想法、大量的努力以及一些作為基礎的原則，是一個持續的、概念性的發展過程。

**結語：**

我們確實看到了AI的巨大發展，但也要看到背後的缺陷和風險。找到更好的解決辦法，提出正確的問題，才能讓AI更好地發展。希望今天的分享能讓大家對AI的現狀和未來有更加清晰的認識。

**改進說明：**

*   **標題：** 更簡潔明瞭地概括了文章的主題。
*   **結構：** 使用了更清晰的標題和副標題，使文章結構更清晰。
*   **重點提取：** 提取了楊立昆專訪中的主要觀點，並進行了歸納整理。
*   **語言：** 調整了部分語句，使其更簡潔、易懂。
*   **排版：** 使用了項目符號、加粗等排版方式，突出重點。

希望這個整理後的版本對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>599. [2025-03-22] 【商业】Intel任命新CEO陈立武 | 英特尔股价相应上涨 | 核工程硕士 | 转战投资领域 | 华登国际 | 投资新浪 | 救火楷登电子 | 与帕特基辛格的分歧 | 四大半导体巨头CEO均为华人</summary><br>

<a href="https://www.youtube.com/watch?v=V5gZ3kph33Y" target="_blank">
    <img src="https://img.youtube.com/vi/V5gZ3kph33Y/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】Intel任命新CEO陈立武 | 英特尔股价相应上涨 | 核工程硕士 | 转战投资领域 | 华登国际 | 投资新浪 | 救火楷登电子 | 与帕特基辛格的分歧 | 四大半导体巨头CEO均为华人

好的，這是我整理後的文稿，主要著重於提升結構清晰度、強化重點、以及適當潤飾：

**標題：英特爾能否重返榮耀？新任CEO陳立武的挑戰與機遇**

**引言:**

大家好，這裡是最佳拍檔，我是大飛。今天我們再次做一期與英特爾有關的節目，來聊聊這個半導體領域昔日王者的最新進展。曾幾何時，英特爾凭借著先進的技術和廣泛的市場份額，在半導體行業呼風喚雨，是PC時代當之無愧的巨頭。

**英特爾的困境:**

但近年來，英特爾的發展之路卻充滿了坎坷，陷入了前所未有的困境：

*   **財務困境：** 2024年，全年淨虧損高達188億美元，市值大幅縮水超過一半。
*   **負面消息：** 裁員、賣廠、業績下滑，甚至被踢出道瓊斯指數，形象一落千丈。
*   **競爭壓力：** 英偉達、AMD等後起之秀迅速崛起，在技術創新和市場拓展方面不斷發力，給英特爾帶來了巨大的壓力。

**新任CEO：陳立武**

在這樣的背景下，英特爾董事會任命陳立武（Lip-Bu Tan）為新任CEO，3月18日正式走馬上任。消息一出，英特爾股價盤後飆漲12%，市場似乎看到了一絲希望的曙光。

*   **市場反應：** 陳立武的任命讓資本市場迅速做出反應，顯示市場對其帶領英特爾走出困境的期待。
*   **核心問題：** 陳立武究竟是何許人也？他為什麼能讓市場對英特爾的未來充滿期待？

**陳立武的背景與經歷:**

陳立武現年65歲，祖籍中國福建福清，出生於馬來西亞，成長於新加坡，他的人生軌跡堪稱一部跨界傳奇：

*   **教育背景：** 新加坡南洋理工大學物理系，麻省理工學院核工程碩士。
*   **早期職業生涯：** 核能企業EDS Nuclear的首席工程師（因三哩島核電站事故轉行）。
*   **商業轉型：** 舊金山大學MBA，後轉戰科技創投領域。
*   **創辦華登國際：** 1987年，以300萬美元創立華登國際，專注投資初創科技公司，尤其青睞半導體產業。
*   **投資帝國：** 華登國際管理的資本超過30億美元，投資遍及全球500多家企業，其中120餘家聚焦半導體領域，投資包括新浪、美團、中芯國際、兆易創新等知名企業。

**陳立武的優勢:**

*   **投資眼光：** 對半導體產業有獨到的眼光和精準的投資策略。
*   **了解中國市場：** 熟悉中國市場，是美國資本進入中國科技領域的最佳代理人。
*   **救火經驗：** 曾臨危受命，帶領楷登電子走出困境，並獲得半導體界最高榮譽羅伯特·諾伊斯獎。
*   **戰略眼光：** 加入英特爾董事會後，對IDM 2.0戰略提出不同意見，被認為具有更務實的戰略眼光。

**陳立武與英特爾:**

*   **加入英特爾董事會：** 2022年加入，協助推動IDM 2.0戰略。
*   **理念分歧：** 與時任CEO帕特·基辛格在IDM 2.0戰略上存在分歧，認為過於激進。

**英特爾選擇陳立武的原因:**

*   **深厚的行業積澱和資本手腕：** 兼具戰略眼光與執行力的“複合型玩家”。
*   **了解中國市場：** 在中國這個全球最大的半導體消費市場（佔全球40%）的人脈和資源，有望幫助英特爾取得突破。

**面臨的挑戰:**

*   **資金壓力：** 晶圓廠的高投入導致現金流捉襟見肘。
*   **技術落後：** 在製程工藝方面落後於台積電。
*   **市場份額被擠壓：** AMD和英偉達等競爭對手在x86處理器和數據中心市場上佔據優勢。
*   **公司文化重塑:** 改善公司內部團結，重塑工程驅動的文化。

**轉機與機會:**

*   **潛在的投資：** 台積電可能聯合英偉達、AMD等企業投資英特爾的晶圓廠，緩解資金壓力。
*   **AI推理市場：** 英特爾的Xeon和Gaudi產品線或許能在AI推理階段扳回一局。

**陳立武的全員信:**

*   **榮幸與決心：** 對出任英特爾CEO感到榮幸，並展現出堅定的信心和決心。
*   **領導原則：** 謙遜、勤奮和以客戶為先。
*   **戰略方向：** 回歸工程驅動本質，打造卓越產品、傾聽客戶需求、兌現承諾。

**總結：**

陳立武的上任為英特爾帶來了新的希望，但也面臨著嚴峻的挑戰。他的成功與否不僅關乎英特爾的未來，也關乎整個半導體產業的格局。他能否帶領這家藍色巨人走出至暗時刻，重回巔峰？這不僅是陳立武個人的地獄級試煉，更是藍色巨人的生死大變局。

**結尾：**

好了，今天的視頻內容就到這裡。大家對於陳立武執掌英特爾有什麼看法呢？歡迎在評論區留言。感謝觀看，我們下期再見！

**整理說明:**

*   **精簡重複資訊：** 刪除一些重複的描述，例如多次提及“重返巔峰”。
*   **邏輯更清晰：** 將文稿分成更明確的段落，更易於理解。
*   **強化重點：** 用加粗和條列式清單突出重點信息。
*   **適當潤飾：** 調整部分語句，使表達更流暢自然。
*   **標題優化：** 標題更具吸引力，點明核心內容。

希望這個版本對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>598. [2025-03-21] 【人工智能】Nvidia GTC 2025 | 黄仁勋主题演讲 | Blackwell Ultra | 下一代Rubin | CPO产品 | Dynamo | 软件和Agent生态 | 具身智能</summary><br>

<a href="https://www.youtube.com/watch?v=4wZYrzC-pTo" target="_blank">
    <img src="https://img.youtube.com/vi/4wZYrzC-pTo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Nvidia GTC 2025 | 黄仁勋主题演讲 | Blackwell Ultra | 下一代Rubin | CPO产品 | Dynamo | 软件和Agent生态 | 具身智能

好的，我已經將您的文稿整理如下，使其更易於閱讀和理解。主要針對重點資訊進行提煉，並適當調整結構：

**標題：GTC 2025 Nvidia 大會重點總結：Blackwell Ultra、Rubin 架構及 AI 軟體生態**

**核心觀點：**

*   黃仁勳預測未來算力規模將增長100倍，英伟达正积极布局新一代GPU和軟體生態，力圖鞏固其在AI领域的領導地位。
*   雖然 Blackwell Ultra GPU 性能提升有限，但 Rubin 架構和英偉達在 AI 軟體方面的積極布局值得期待。

**一、 Blackwell Ultra 全家桶：**

*   **Blackwell Ultra GPU：**
    *   採用雙台積電 N4P（5nm）Blackwell 架构晶片和 Grace CPU 封装，搭配 12 層 HBM3e 内存（288GB）。
    *   第五代 NVLink，片间互联带宽 1.8TB/s。
    *   FP4 精度算力达 15 PetaFLOPS，AI 推理速度提升 2.5 倍（相較 Hopper 架构）。
*   **Blackwell Ultra NVL72：**
    *   AI 推理专用机柜，包含 72 顆 Blackwell Ultra GPU 和 36 顆 Grace CPU。
    *   顯存 20TB，總帶寬 576TB/s。
    *   内置 18 顆 NVLink 交換機芯片，节点间 NVLink 带宽 130TB/s。
    *   性能提升：
        *   AI 性能比前一代 GB200 NVL72 提升 1.5 倍。
        *   與 Hopper 架构 DGX 机柜相比，增加 50 倍增收機會。
        *   完成 DeepSeek-R1 的推理任務，時間從 H100 的 1.5 分鐘縮短到 NVL72 的 15 秒。
    *   預計 2025 下半年上市。

**二、 未來的核彈級 GPU：Rubin 芯片**

*   **Rubin GPU (2026)：**
    *   下一代 GPU，搭配更強的機櫃 Vera Rubin NVL144。
    *   Vera Rubin NVL144 配备 72 顆 Vera CPU 和 144 顆 Rubin GPU。
    *   288GB 显存的 HBM4 芯片，顯存帶寬 13TB/s。
    *   FP4 精度推理算力 3.6 ExaFLOPS，FP8 精度訓練算力 1.2 ExaFLOPS。
    *   性能是 Blackwell Ultra NVL72 的 3.3 倍。
*   **Rubin Ultra NVL576 (2027)：**
    *   FP4 精度推理算力 15 ExaFLOPS，FP8 精度訓練算力 5 ExaFLOPS。
    *   性能是 Blackwell Ultra NVL72 的 14 倍。

**三、 其他硬體產品：**

*   **DGX Super POD（超算工廠）：**
    *   即插即用的 AI 超算工廠，面向生成式 AI、AI Agent 和物理模擬等場景。
    *   兩個版本：
        *   內置 DGX GB300 (1 Grace CPU + 2 Blackwell Ultra GPU)，提供 300TB 快速内存，FP4 精度算力 11.5 ExaFLOPS。
        *   內置 DGX B300 (不含 Grace CPU)，採用風冷系統，適用於企業級數據中心。
*   **DGX Spark (AI PC)：**
    *   搭载 GB10 芯片，FP4 精度算力 1 PetaFlops。
    *   内置 128GB LPDDR5X 内存，配備 CX-7 網卡和 4TB NVMe 存储。
    *   運行基於 Linux 定制的 DGX OS 操作系统，支持 Pytorch 等框架。
    *   本质上屬於超算範疇。
*   **DGX Station (AI 工作站)：**
    *   内置一颗 Grace CPU 和一颗 Blackwell Ultra GPU。
    *   搭配 784GB 的统一内存、CX-8 网卡。
    *   理论上能提供 20 PetaFlops 的 AI 算力。
*   **RTX 系列整合 Blackwell：**
    *   推出一系列内置 GDDR7 内存的 AI PC 相關 GPU，覆盖桌面、笔记本以及数据中心等多个场景。

**四、 硅光芯片領域的進展：NVIDIA Photonics 平台**

*   推出 Quantum-X 和 Spectrum-X 硅光共封芯片，以及三款交換機產品：
    *   Quantum 3450-LD
    *   Spectrum SN6810
    *   Spectrum SN6800
*   整合光模塊的 Photonics 交換機相比傳統交換機性能提升 3.5 倍，部署效率提高 1.3 倍，擴展彈性提升 10 倍以上。

**五、 軟體生態：**

*   **Nvidia Dynamo：**
    *   開源軟體，專為推理、訓練以及跨整個數據中心加速而設計。
    *   基於 Dynamo 分布式架構設計，充分利用了 NVL72 架构的高带宽通信能力。
    *   目标是构建反击 Groq 等推理 AISC 芯片的防線。
*   **Llama Nemotron：**
    *   由 Llama 系列模型衍生而來，主打高效、准确。
    *   内置了推理能力的開關。
    *   分为 Nano、Super 和 Ultra 三个档次。
*   **NVIDA AIQ：**
    *   提供以 Llama Nemotron 推理模型為核心的 AI Agent 工作流。
    *   推出 AI 數據平台，可以将 AI 推理模型直接接到企业数据的系统上。
    *   強調可觀察性和透明度機制。
*   **Cosmos 模型升級版：**
    *   世界基礎模型（WFM），能通過現在畫面去預測未來畫面。
    *   包含 Cosmos Transfer、Cosmos Predict 和 Cosmos Reason 三部分能力。
    *   已應用於 1X、Agility Robotics、Figure AI 等公司。
*   **Isaac GR00T N1 人形機器人基礎模型：**
    *   采用双系统架构，有快速反应的“系统 1“和深度推理的“系统 2“。
    *   能够处理抓取、移动、双臂操作等通用任务。
    *   與谷歌 DeepMind 和迪士尼合作開發 Newton 物理引擎，用了 Isaac GR00T N1 作為底座。

**六、 英伟达的整體戰略**

*   打造“三台计算机”的概念：DGX（訓練 AI）、AGX（端側部署 AI）、Omniverse+Cosmos（數據生成）。
*   构建从算力、训练到部署的完整闭环，垄断具身智能的上下游环节。
*   力图在硬件之外，在软件或机器人市场中占据重要地位。

**總結：**

英伟达正積極布局 AI 領域的各個層面，包括硬體、軟體和機器人。雖然 Blackwell Ultra 的升級幅度有限，但 Rubin 架構和英偉達在軟體生态上的積極布局值得關注。未来英伟达能否成功垄断这些市场，仍有待觀察。

**整理說明：**

*   **精簡信息：** 刪除了一些重複和冗餘的信息，只保留了核心要點。
*   **結構化呈現：** 使用標題、子標題和項目符號，使內容更清晰易讀。
*   **提煉核心观点：**  在开头和结尾都提炼了核心观点，帮助读者快速理解文章主旨。
*   **專業術語解釋：**  保留了必要的專業術語，以便傳達技術细节。
*   **語言潤飾：**  修正了一些語法和表达上的小问题，使其更流畅。

希望這個整理對您有所幫助！ 如果有任何需要修改的地方，請隨時告訴我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>597. [2025-03-20] 【人工智能】企业招聘也能遇到AI骗局？| 美初创公司Vidoc Security亲身经历 | 两次AI换脸面试 | 完美简历 | 面试疑惑 | 远程招聘难题 | DeepFake | 企业如何避免</summary><br>

<a href="https://www.youtube.com/watch?v=wCrGV8GQAww" target="_blank">
    <img src="https://img.youtube.com/vi/wCrGV8GQAww/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】企业招聘也能遇到AI骗局？| 美初创公司Vidoc Security亲身经历 | 两次AI换脸面试 | 完美简历 | 面试疑惑 | 远程招聘难题 | DeepFake | 企业如何避免

好的，我已經將文稿整理如下：

**標題：AI 求職詐騙：公司如何避免成為下一個受害者？**

**引言：**

大家好，這裡是最佳拍檔，我是大飛。
AI 詐騙新聞層出不窮，但你可能不知道，AI 也已被用於求職詐騙，甚至有公司中招。本文將揭露 AI 如何偽裝成求職者，並提供公司避免受騙的建議。

**事件起因：**

Vidoc Security 是一家專注於自動化程式碼安全審查的初創公司。其聯合創辦人達維德·莫查德沃（Dawid Moczadło）和克勞迪婭·克洛茨（Klaudia Kloc）都是資深安全工程師，擁有豐富的經驗和卓越的技術能力。他們開發了一款基於大語言模型的自動化安全工具，並獲得了種子輪融資。為了擴充團隊，Vidoc Security 發布了後端工程師的職位招聘廣告，卻因此陷入 AI 詐騙的漩渦。

**案例一：完美履歷下的 AI 偽裝**

*   **應聘者：** 馬卡里·克羅爾（Makary Krol）
*   **履歷：** 擁有 9 年以上經驗的資深全棧開發者，精通多種編程語言，在多家知名公司有亮眼成績。
*   **初輪面試：** 營運主管發現應聘者自稱來自波蘭，卻不會說波蘭語，英語口音濃厚，但因求職動機強烈而進入下一輪。
*   **招聘經理面試：** 溝通能力受質疑，但技術面試表現驚艷。
*   **最終面試：** 深入瞭解背景時，經歷難以令人信服，被懷疑身份造假。
*   **真相：** 應聘者使用偽造履歷，並利用 AI 工具偽裝外貌。
*   **結果：** 公司因無法提供確鑿證據，只能放棄錄用。

**案例二：換臉工具的破綻**

*   **應聘者：** 布拉蒂斯拉夫·拉科切維奇（Bratislav Rakočević）
*   **履歷：** 來自塞爾維亞，擁有當地大學教育背景，LinkedIn 資料顯示為資深全棧開發者，聲稱曾在 HubSpot 和 Woosh 等公司工作過。
*   **初輪面試：** 交流過程生硬，自稱畢業於塞爾維亞克拉古耶瓦茨大學，卻不會說塞爾維亞語。
*   **招聘經理面試：** 應聘者長相與 LinkedIn 頭像不符，被要求做簡單動作驗證是否使用 AI 換臉工具，遭拒絕。
*   **真相：** 應聘者使用 AI 換臉工具，且換臉對象與波蘭政治家斯拉沃米爾·門琴（Sławomir Mentzen）高度相似。
*   **結果：** 應聘者被立即終止面試。

**公司分析：**

*   兩名應聘者聲音幾乎一模一樣，懷疑背後為同一人。
*   AI 偽裝品質不斷提升，未來難以識別。

**公司如何避免 AI 應聘者欺騙：**

1.  **認真對待可能性：** 不要認為公司規模小就不會成為目標。
2.  **求職者真偽難辨：** 不要認為所有本地招聘網站上的求職者都是真實的。
3.  **關閉濾鏡：** 要求應聘者關閉所有視訊濾鏡，觀察面部或背景是否有異常。
4.  **測試動作：** 要求應聘者做一些 AI 換臉工具難以應對的動作，例如轉頭、遮臉、站立後退等。
5.  **錄製影片：** 在獲得對方同意的前提下，錄製並保存面試影片，以便事後分析。
6.  **現場面試：** 盡可能安排線下面試，或通過其他方式判斷應聘者身份。

**其他案例：**

*   美國安全培訓公司 Knowbe4 曾招聘一名假冒的朝鮮 AI 技術人員。
*   其他公司也曾遇到找人代面試或外包工作的情況。

**結論：**

AI 的出現降低了欺詐成本，對企業招聘造成極大威脅。公司應擦亮眼睛，避免落入 AI 應聘者的騙局中。
尤其海外科技公司或者出海公司，多為遠程面試，所以要更加注意甄別面試者的身份。

**結尾：**

感謝大家的觀看，我們下期再見。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>596. [2025-03-19] 【人物】David Baker 大卫·贝克 | 从哲学研究到诺贝尔化学奖 | Rosetta | 蛋白质结构预测 | Foldit | RoseTTAFold | RFdiffusion</summary><br>

<a href="https://www.youtube.com/watch?v=AEdR5FRb8xk" target="_blank">
    <img src="https://img.youtube.com/vi/AEdR5FRb8xk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】David Baker 大卫·贝克 | 从哲学研究到诺贝尔化学奖 | Rosetta | 蛋白质结构预测 | Foldit | RoseTTAFold | RFdiffusion

好的，我將這段文稿整理如下，主要針對排版、斷句和部分語氣進行調整，使其更易於閱讀，並保留原文的核心內容和風格：

**最佳拍檔：走進諾貝爾化學獎得主大衛·貝克（David Baker）的科研世界**

大家好，這裡是最佳拍檔，我是大飛。

2024年10月，我們製作了幾期諾貝爾獎的節目。其中，物理學和化學獎都頒給了與人工智慧有關的科學家，引起了大家的廣泛關注。

化學獎的得主中，大家可能更為熟悉 DeepMind 的 CEO 德米斯·哈薩比斯（Demis Hassabis）。但今天，我們想介紹的是另一位獲獎者——美國華盛頓大學的大衛·貝克（David Baker）教授。

他在蛋白質設計領域的卓越貢獻，不僅革新了科學界對蛋白質的認知，還為眾多相關領域帶來了全新的發展機遇。

今天，就讓我們一同走進大衛·貝克的科研世界，探尋他從哈佛哲學系走向蛋白質設計大師的傳奇歷程。

**從哲學到生物化學：一場意外的轉變**

大衛·貝克於1962年10月6日出生在美國華盛頓州西雅圖的一個猶太家庭。他的父母分別是物理學家和地球物理學家。按常理來說，這樣的家庭環境或許會讓他早早踏上科學研究之路。

然而事實並非如此。在哈佛大學本科階段，他主修的是哲學和社會研究。回顧那段時光，他曾表示，很多哲學討論在當時看來意義不大，感覺像是在浪費時間。

直到大學的最後一年，一次偶然的經歷徹底改變了他的學術軌跡。他選修了發育生物學課程，在課堂上見證了一個神奇的實驗：加入蛋白變性劑後，RNA酶失去了切割RNA的活性，但是當溶液中的變性劑被蒸發後，RNA酶的活性竟奇蹟般地恢復了！

這個現象讓他深深著迷：蛋白質究竟是如何在瞬間自主找到正確的構象並發揮功能的呢？這種對科學問題明確答案的追求，比哲學的模糊性更讓他感到興奮。

從此，他開始如飢似渴地閱讀《細胞分子生物學》這本經典教材，對生物學的興趣也愈發濃厚。隨後，他加入了諾貝爾生理和醫學獎得主蘭迪·謝克曼（Randy Schekman）的實驗室，並於1989年獲得了加州大學柏克萊分校的生物化學博士學位。

**Rosetta 的誕生：用計算機預測蛋白質結構**

博士畢業後，他進入加州大學舊金山分校大衛·阿加德（David Agard）教授的實驗室，進行博士後研究。在那裡，他接觸到了用計算機解析晶體結構的工作，卻發現傳統的人工匹配方式效率低下，而且困難重重。

於是，他萌生了用計算機預測蛋白質結構的想法。1993年，貝克回到家鄉西雅圖的華盛頓大學，開啟了他研發蛋白質結構預測軟體的征程。這就是後來聞名遐邇的 Rosetta。

在研發過程中，貝克遇到了許多的挑戰，因為蛋白質結構預測是一個極其複雜的問題，需要考慮到氨基酸序列、蛋白質的摺疊方式以及各種物理化學因素。

為了解決這些問題，貝克帶領團隊基於物理學的原理，讓 Rosetta 通過對蛋白質的構象進行能量最小化計算，來預測最穩定的三維結構，也就是接近自然狀態下的蛋白質穩定構象。

1998年，Rosetta 正式發布。為了驗證它在蛋白質結構預測中的準確性，貝克團隊積極參與了 CASP 競賽。在這個競賽中，參賽者需要對一批尚未公開結構的蛋白質進行盲測預測，以此來評估不同演算法的性能。

Rosetta 在競賽中逐漸嶄露頭角，而2004年的 CASP 6 競賽成為了它的高光時刻。針對目標蛋白 T0281，Rosetta 首次實現了接近原子級精度的從頭蛋白質結構預測。這個成果震驚了整個蛋白質結構預測領域，也讓 Rosetta 一度成為這個領域的領導者。

**Rosetta@home 和 Foldit：群眾的力量**

但是隨著研究的深入，更準確的預測意味著需要消耗更多的計算資源。購買新的計算機不僅成本高昂，還面臨著空間不足的問題。

為了解決這一難題，貝克團隊啟動了 Rosetta@home 項目。這是一個極具創新性的項目，它邀請全球各地的人們用自己閒置的算力來進行蛋白結構計算。當計算機運行這個屏幕保護程式的時候，屏幕上會顯示正在摺疊的蛋白質，讓參與者也能直觀感受到科學研究的魅力。

如今，Rosetta@home 項目已經吸引了眾多志願者的參與，極大地推動了蛋白質結構計算的發展。為了持續改進 Rosetta 軟體，貝克還創建了 Rosetta Commons 學術社區。

這個社區匯聚了來自全球60多個機構的學者，涵蓋化學、生物學、生理學、物理學、工程學、數學和計算機科學等多個領域。每年社區都會舉辦會議，成員們也會互相分享成果、交流想法。

在這裡，不同領域的智慧相互碰撞，為蛋白質結構研究注入了源源不斷的活力。Rosetta Commons 也逐漸發展成為一個大規模的國際合作項目。

受到 Rosetta@home 項目的啟發，貝克意識到合作共贏的重要性。2008年，他的團隊推出了一款名為 Foldit 的在線益智遊戲。

這款遊戲的獨特之處在於，無論是專業人士還是非專業人士都可以參與。在遊戲中，玩家需要使用遊戲中的工具，盡可能完美地摺疊選定的蛋白質結構。得分最高的方案將由研究人員進行分析，評估在現實中的適用性，進而應用於靶向治療等領域。

Foldit 一經推出便受到了廣泛的關注，吸引了超過40萬人參與。玩家們的熱情和智慧，為蛋白質研究帶來了意想不到的成果。

2011年，一篇被《自然》雜誌錄用的論文中，Foldit 的玩家幫助破解了困擾科學家長達15年的 M-PMV 逆轉錄病毒蛋白酶的晶體結構。令人驚嘆的是，玩家們只用了10天就構建出了足夠準確的酶3D模型，成功進行了分子替換和隨後的結構測定。

這個成果充分展示了公眾參與科學研究的巨大潛力，也讓 Foldit 成為了蛋白質研究領域的一個創新典範。

**與 AlphaFold 2 的競爭：擁抱深度學習**

就在 Rosetta 和 Foldit 在蛋白質結構領域大放異彩之時，2020年底，一個強大的競爭對手出現了——那就是 AlphaFold 2。

在第14屆 CASP 大賽中，AlphaFold 2 的表現堪稱驚豔，它預測蛋白質結構的準確性直接碾壓了其他所有團隊，包括貝克團隊的 Rosetta。AlphaFold 2 將深度學習與物理、生物等相關領域知識結合，實現了端到端的蛋白質三維結構信息預測。這個成果被譽為蛋白質研究的里程碑。

然而，當時開發 AlphaFold 2 的 DeepMind 公司並沒有公開具體的細節。面對挑戰，貝克沒有選擇退縮。和他的老師蘭迪·謝克曼一樣，貝克崇尚科學的開源、共享。

蘭迪·謝克曼曾經因為提倡開放、免費獲取科學文獻，對《自然》、《科學》、《細胞》這類封閉式訪問的期刊大力批評，並且宣布自己的實驗室永不向這些期刊投稿。

受老師的影響，貝克也立志研發一個能夠與 AlphaFold 2 媲美的開源模型。經過數月的努力，貝克和實驗室的其他成員借鑒 AlphaFold 2 的思路，發布了深度學習模型 RoseTTAFold。

RoseTTAFold 採用了獨特的三軌（three-track）神經網絡架構，能夠同時考慮蛋白質的序列模式、氨基酸相互作用以及可能的三維結構。在這個架構中，一維、二維和三維信息相互流動，使得神經網絡能夠推理出蛋白質的化學組成與其摺疊結構之間的關係。

利用 RoseTTAFold，研究人員計算了數百種新的蛋白質結構，包括人類基因組中許多未知的蛋白質，還生成了與人類健康直接相關的蛋白質，比如與炎症疾病和癌細胞生長相關的蛋白質。

而且，RoseTTAFold 的計算耗能和時間都低於 AlphaFold 2，只需一塊 RTX 2080 顯卡，就能在短短10分鐘內計算出400個氨基酸殘基以內的蛋白質結構。

2021年6月，貝克公布了詳細介紹 RoseTTAFold 技術路線的預印版論文。幾天後，DeepMind 首席執行官德米斯·哈薩比斯（Demis Hassabis）在推特上宣布，他們將公布 AlphaFold 2 的論文和源代碼。

同年7月15日，RoseTTAFold 和 AlphaFold 2 的相關論文分別發表於《科學》和《自然》雜誌。《科學》雜誌還將 RoseTTAFold 和 AlphaFold 共同評為2021年度突破技術。

這場學術界與商業界的激烈競爭，最終以雙方的成果共享和共同進步而完美結束。

**從蛋白質結構預測到蛋白質設計：RFdiffusion 和 ProteinMPNN**

在經歷了與 AlphaFold 2 的競爭後，貝克深刻認識到了深度學習的強大力量。於是他不僅開始將深度學習用於蛋白質結構預測，還將它拓展到了蛋白質設計領域。

其實，早在多年以前，貝克的團隊就有了設計全新蛋白質的想法。2003年，他們成功設計出了世界上第一個全新蛋白質 Top7。Top7 是一種由93個氨基酸殘基組成的α/β蛋白質。研究人員通過一種在序列設計和結構預測之間迭代的計算策略，為它設計了全新的序列和拓撲結構。

實驗證明，Top7 能夠摺疊成穩定的結構，它的X射線晶體結構與設計模型的均方根偏差只有1.2埃。這個成果標誌著人類在蛋白質設計領域邁出了重要的一步。

隨著深度學習技術的不斷發展，貝克帶領團隊在蛋白質設計領域取得了更多的成果。比如，他在《自然》期刊發表了一篇題為《利用RFdiffusion從頭設計蛋白質結構和功能》的論文。

研究人員在蛋白質結構去噪任務中，對 RoseTTAFold 的結構預測網絡進行了微調，開發了一個生成模型 RFdiffusion。這個模型在蛋白質結合劑設計、酶活性位點支架設計等方面表現出色，而且具備極好的通用性，目前也已經開源。

與此同時，為了進一步拓展 RFdiffusion 的能力，貝克還開發了一種基於深度學習的蛋白質序列設計方法 ProteinMPNN。

ProteinMPNN 將蛋白質結構作為輸入，1秒即可生成能夠摺疊成對應骨架的新氨基酸序列。結合像 RFdiffusion 這樣的結構生成工具，它可以被用來設計具有前所未見的序列、結構和功能的蛋白質。

研究表明，在天然蛋白質骨架上，ProteinMPNN 的序列恢復率為52.4%，而過去基於 Rosetta 的物理設計僅為32.9%。這個成果最終以一篇題目為《使用ProteinMPNN進行基於穩健深度學習的蛋白質序列設計》的論文被《科學》雜誌錄用。

**Rosetta 和 Foldit 的進化：拓展到抗體和酶設計**

除了開發新的工具以外，貝克的團隊還對 Rosetta 和 Foldit 進行了優化。通過在軟體內引入新的模塊和演算法，這兩款軟體不再僅僅局限於蛋白質結構預測，還拓展到了抗體設計、酶設計和小分子對接等方面。

貝克表示，Foldit 最初是為蛋白質結構預測而創建的，但是隨著研究的深入，現在已經轉向了蛋白質設計。團隊會不斷為玩家更新關卡，讓遊戲與研究興趣的變化保持同步。

**科研成果的產業化：創立多家公司**

貝克的研究成果不僅在學術界引起了轟動，還在工業界得到了廣泛應用。他深知，將科研成果轉化為實際產品，才能真正造福人類。

因此，每當他認為某項技術基本成熟的時候，就會成立新公司，或者投入過往創立的公司來進行孵化，推動技術的產業化落地。

根據華盛頓大學蛋白質設計研究所官網顯示，貝克作為創始人直接參與的公司就有21家。此外，他還以顧問的身份參與了其他公司的運營。

以2024年4月成立的 Xaira Therapeutics 公司為例，它就應用了 RFdiffusion 和 ProteinMPNN 技術。公司致力於通過新興的AI技術重新設計和開發藥物，由斯坦福大學前校長馬克·特西爾-拉維涅（Marc Tessier-Lavigne）博士擔任首席執行官，貝克為聯合創始人。

Xaira 通過整合分子與人體疾病相關生物學特徵的海量數據，來訓練高品質的模型。同時，公司建立了工業化的乾濕實驗平台，能夠在實驗室中測試蛋白質對特定細胞靶標的粘附程度，並且評估穩定性等關鍵屬性。所有產生的數據會被快速反饋到蛋白質模型中，實現分子設計的迭代優化。

另外，2023年成立的 Archon Biosciences 公司，致力於通過生成式AI設計一種全新的生物藥物類型——抗體籠（Antibody cage），簡稱 AbC。

AbC 將 AI 設計與結構控制融合，可以完全控制抗體的方向、結合域化合價、大小、形狀和剛度。這種結構控制能夠實現精確的生物分佈和細胞靶向結合，結合內部臨床數據，能夠快速驗證抗體的有效性。公司獲得了英偉達等多家公司的支持，所用技術都源於貝克在2024年諾貝爾化學獎中獲得認可的成果。

2023年，Monod Bio 公司推出了世界上第一個完全從頭蛋白質產品，用於生命科學研究和診斷的螢光素酶 LuxSit™ Pro。這個成果也是源自貝克2023年在《自然》雜誌上發表的一篇論文。

此外，2009年成立的 Arzeda、2014年成立的 Cyrus Biotech 以及2018年成立的 A-Alpha Bio 等公司，也都積極引進了貝克最新研發的 AI 技術，致力於研發更多的新型蛋白質，用來製造新的藥物、疫苗、疾病療法，甚至是新的材料。

**結語：大衛·貝克的貢獻與影響**

回顧大衛·貝克的學術生涯，他從最初的哲學探索，逐漸成長為蛋白質設計領域的大師，每一步都充滿了對未知的渴望和對創新的執著。

他始終堅持合作共贏的理念，用開放與分享的精神，激勵著全球無數研究人員和科學愛好者投身到蛋白質領域的發展中。他的研究成果不僅在學術界取得了巨大突破，還成功從實驗室走向了工業界，為疾病治療、食品生產、材料科學等多個領域帶來了新的可能。

隨著 AI 能力的不斷進步，相信我們很快會看到蛋白質設計領域不斷會有新的發現和突破，幫助我們治療各種疑難病症，甚至是改變我們的生活方式。而這些，都與大衛·貝克的探索和奉獻密不可分。

感謝大家收看本期視頻，我們下期再見！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>595. [2025-03-18] 【人工智能】谷歌研究团队发现DiLoCo具有更优Scaling Laws | 分布式低通信优化 | 稳定扩展超参数 | 损失下降更快 | 带宽减少99% | 最优批大小 | 数据并行 | 未来趋势</summary><br>

<a href="https://www.youtube.com/watch?v=JGbehG6qy3k" target="_blank">
    <img src="https://img.youtube.com/vi/JGbehG6qy3k/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】谷歌研究团队发现DiLoCo具有更优Scaling Laws | 分布式低通信优化 | 稳定扩展超参数 | 损失下降更快 | 带宽减少99% | 最优批大小 | 数据并行 | 未来趋势

好的，以下是經過整理的文稿，使其更易讀、更具結構性：

**標題：Google DiLoCo：分布式低通信優化如何改變大模型訓練方式？**

**引言 (0:00-0:30)**

*   **開場:** 大家好，這裡是最佳拍檔，我是大飛。
*   **核心觀點:** Google 三大研究團隊 (Google Research、Google Search、DeepMind) 共同發現，DiLoCo (Distributed Low-Communication Optimization) 分布式低通信優化方法在訓練大規模模型時具有更穩定的 Scaling Laws。
*   **優勢:**
    *   帶寬需求比數據並行訓練少幾個數量級。
    *   小模型訓練上也可能比數據並行更好。
*   **潛在影響:** 可能改變大模型的訓練方式。
*   **本文目的:** 解讀 Google 的 DiLoCo 研究，探討其對 AI 領域的影響。

**Scaling Laws 回顧 (0:30-1:30)**

*   **定義:** 模型性能與模型規模、數據量和計算資源之間的數學關係。
*   **主要內容:** 在一定範圍內，增加模型的規模、數據量和計算資源，模型的性能會相應提升。
*   **重要性:** 為大模型發展提供理論依據，推動 AI 領域發展。
*   **挑戰:**
    *   隨著模型規模增大，數據並行訓練的缺點暴露。
    *   通信開銷巨大。
    *   內存限制。
    *   影響大模型擴展和訓練效率。

**DiLoCo 方法介紹 (1:30-2:30)**

*   **目標:** 減少通信開銷，提高擴展性。
*   **核心思路:**
    *   每個模型副本獨立訓練一定數量的內部優化步驟。
    *   通過外部優化步驟進行同步。
    *   外部優化步驟之間引入動量機制。
*   **比喻:** 像一群人各自在自己的小空間裡先進行一些準備工作，然後再一起協調，減少溝通成本。

**DiLoCo 的優勢 (2:30-4:30)**

*   **超參數穩定性:** 在不同模型規模下表現穩健且可預測。
*   **Scaling Laws 表現:** 隨著模型規模增大，DiLoCo 相較於數據並行訓練的優勢更明顯。
    *   損失會比數據並行更低。
    *   訓練了一系列模型，驗證此預測。
*   **带宽需求**: DiLoCo 所需带宽比数据并行训练少几个数量级。

**DiLoCo 的其他優勢 (4:30-5:30)**

*   **容忍更大的批大小:**
    *   可支持更大的批大小，且表現更穩定。
    *   提高最佳批大小，最佳全局批大小隨副本數 M 增加而增大。
    *   擴展能力更強。
*   **實驗結果 (HellaSwag):** 即使在較小的模型規模下，DiLoCo (M=2) 也能在更大的全局批大小下實現更高的準確率。

**實驗細節 (5:30-7:30)**

*   **模型架構:** 類似 Chinchilla 的純解碼器 Transformer 結構。
    *   QK-LayerNorm 技術：降低模型對學習率的敏感性，使得訓練更穩定。
    *   z-loss 正則化：提高訓練的穩定性。
*   **詞彙量:** 32768 個 (32000 個詞彙表內的單詞 + 其他標記)。
*   **序列長度:** 最大序列長度固定為 2048。
*   **模型規模:** 從 3500 萬參數到 100 億參數不等。
*   **訓練數據集:** C4 數據集的訓練集。
*   **評估指標:** C4 的驗證集。
*   **下游任務:** HellaSwag、Piqa、Arc-Easy (零樣本評估)。
*   **優化器:**
    *   數據並行訓練和 DiLoCo 的內層優化：AdamW (β1=0.9, β2=0.99)。
    *   預熱 1000 步，採用餘弦學習率衰減。
    *   權重衰減參數 λ = T⁻¹ (T 為總訓練步數)。
    *   內層梯度全局範數剪裁到 1，外層梯度不剪裁。
    *   DiLoCo 的外層優化：帶 Nesterov 動量的 SGD (動量 0.9)。
*   **實驗環境:** Google TPUv5e、TPUv6e、TPUv-5。
*   **網絡環境:** 高、中、低帶寬，模擬不同數據中心之間的環境。

**實驗結果分析 (7:30-9:00)**

*   **評估損失:** 當副本數 M=1 時，DiLoCo 在不同模型規模下都比數據並行訓練低。
*   **HellaSwag 零樣本準確率:** DiLoCo 同樣優於數據並行訓練。
*   **批大小影響:**
    *   DiLoCo 對批大小的穩定性更強。
    *   DiLoCo 顯著提高了最佳批大小。
    *   最佳全局批大小隨著副本數 M 增加而增大。
*   **DiLoCo 在橫向擴展上更具優勢。**

**更多實驗結果分析 (9:00-10:00)**

*   **外部學習率:**
    *   最佳外部學習率基本上與模型規模 N 無關。
    *   最佳外部學習率會隨著副本數 M 變化而變化。
    *   M 越大，最佳外部學習率似乎也越大。
    *   這與之前的聯邦學習研究是一致的。
*   **DiLoCo 在水平擴展上更加自然。**

**DiLoCo 與 Over-Training (10:00-10:30)**

*   **優勢:**
    *   DiLoCo 在處理過度訓練的問題上也有獨特的優勢。
    *   增加批大小，減少通信量，使得在相同時間內可以進行更多的過度訓練。
    *   提供更有力的工具來研究模型的性能邊界。

**AI 發展趨勢 (10:30-12:30)**

*   **DiLoCo 對大規模模型訓練提供更高效、更具擴展性的方法。**
*   **反思 AI 未來發展:**
    *   目前 AI 模型發展依賴於 Chinchilla 模式 (大量計算資源和數據)。
    *   Chinchilla 模式面臨挑戰：
        *   前期投入巨大。
        *   性能增益可能越來越小。
        *   訓練數據可能正在枯竭。
*   **新型“推理模型”興起:**
    *   OpenAI 的 o1、o3，DeepSeek R1，Google Gemini 2.0 Flash Thinking 等。
    *   採用 Test Time Compute，不再依賴長時間的預訓練。
*   **混合專家模型 (MoE):**
    *   訓練多個小型“專家”模型，與大模型協同工作。
    *   只在需要時調用部分算力，降低了基礎設施需求。
*   **巴克萊資本分析師觀點:** AI 行業可能面臨兩種情景：
    *   “Chinchilla” 繼續主導 (巨額算力和數據投入)。
    *   增長“停滯”，新型技術和模型以更少的資源實現更強的性能。
    *   這兩種路徑的資本支出差距巨大。
*   **“合成數據”技術取得突破可能讓 Chinchilla 模式重煥生機。**

**總結與展望 (12:30-End)**

*   **兩種趨勢可能同時並存:**
    *   一方面，資本巨鱷會繼續推動算力和基礎設施的投入。
    *   另一方面，小公司會借助算法和工程創新來降低成本。
*   **結尾:** 歡迎在評論區留下自己的看法，感謝大家觀看，下期再見。

**總結:**

這個整理後的版本，將原始文稿分成了更小的、主題明確的段落，並添加了時間戳，方便讀者快速定位到感興趣的部分。重點使用粗體標示，提高可讀性。

希望這個整理後的版本對您有幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>594. [2025-03-16] 【人工智能】OpenAI提案矛头直指DeepSeek | 锁死全球AI发展 | 指责DeepSeek有害 | 加强出口管制 | 两类市场和三级国家 | 为版权侵权辩解 | 吸引资金 | 大型双标现场</summary><br>

<a href="https://www.youtube.com/watch?v=wFGKIbhU_nU" target="_blank">
    <img src="https://img.youtube.com/vi/wFGKIbhU_nU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OpenAI提案矛头直指DeepSeek | 锁死全球AI发展 | 指责DeepSeek有害 | 加强出口管制 | 两类市场和三级国家 | 为版权侵权辩解 | 吸引资金 | 大型双标现场

好的，這份文稿我會整理成以下幾個部分，並進行一些潤飾，讓內容更清晰：

**標題：OpenAI提案解讀：鎖死中國AI發展？**

**引言：**

大家好，這裡是最佳拍檔，我是大飛。近日，OpenAI針對美國政府即將出台的“AI行動計劃”提交了一份提案，內容直指中國DeepSeek公司，幾乎將其視為第二個華為，試圖限制中國乃至全球AI的發展。這份提案公開後，立即引發了廣泛的討論和爭議。今天，大飛就來為大家深度解讀OpenAI的這份提案。

**背景：**

事情的背景是，2025年1月，特朗普推翻了拜登在2023年10月簽署的人工智能行政命令，並發布新的行政命令，明確表示維持和加強美國在全球人工智能領域的主導地位是美國的政策目標。該命令要求在180天內向總統提交一份AI行動計劃。為了影響該計劃的制定，眾多機構和企業紛紛建言獻策，OpenAI提交的這份長達15頁的提案便是其中之一。

**OpenAI提案核心內容：**

OpenAI在提案中將矛頭直指中國的DeepSeek公司，主要觀點如下：

*   **指責DeepSeek受中國政府控制：** 聲稱DeepSeek是“由國家補貼”和“被國家控制”的，認為其會受到中國政府的指示，操縱模型來造成損害。
*   **強調DeepSeek的威脅：** 認為中國決心在2030年前成為全球人工智能的領導者，而DeepSeek發布的R1模型，不僅推理能力令人印象深刻，更被視為中美AI競爭的一個重要指標。在OpenAI看來，DeepSeek就像是第二個華為，存在許多風險。
*   **數據安全隱憂：** 聲稱在關鍵基礎設施和其他高風險使用場景中，如果系統構建在DeepSeek模型之上，將面臨巨大風險，因為它可能會被迫受到中國政府的指令控制。此外，由於DeepSeek是免費提供的，用戶可能需要以自身的隱私和安全作為代價。

**DeepSeek的回應與實際情況：**

*   **數據收集克制：** DeepSeek在用戶協議中明確了信息收集的多重處理前提，收集到的內容僅用於模型服務的優化和風控，並且強調在經過安全加密技術處理、嚴格去標識化且無法重新識別特定個人的前提下，才會進行相關操作。
*   **用戶權益保障：** DeepSeek保留了用戶在提交的輸入中擁有的任何權利、所有權和利益，並且將服務輸出內容的任何權利、所有權和利益歸屬於用戶。用戶可以將服務的輸入與輸出應用在廣泛的使用場景中，包括個人使用、學術研究、衍生產品開發以及訓練其他模型等等。
*   **反駁OpenAI的指責：** OpenAI指責DeepSeek會根據中國法律的需要把用戶數據提供給政府，並且利用這些數據訓練更強大的系統，但這些指責並沒有具體的證據來證實。相反，從DeepSeek公開的信息來看，它在保護用戶隱私和數據安全方面有著明確的規定和措施。

**OpenAI的政策建議：**

除了對DeepSeek的攻擊，OpenAI還提出了一系列政策建議：

*   **出口管制：** 建議美國政府制定一項全面的出口管制戰略，將全球希望獲取美國AI技術的國家分為“總可服務市場”（TAM，即中國及其盟友以外的國家）和“可服務市場”（SAM，即傾向於在民主軌道上構建AI的國家）。
*   **分級制度：** 維持AI擴散規則的三級框架，擴大一級國家的數量，縮小二級國家的範圍。只有承諾遵守民主AI原則、目的是為本國公民帶來更多自由的國家才能被視為一級國家。
*   **市場擴張：** 鼓勵跨境資本流動，推廣為國內芯片設計優化過的軟件框架，協調全球對與中國結盟的AI基礎設施的禁令，鼓勵全球監管機構採納有利於增長的安全政策。
*   **保護知識產權：** 禁止與三級國家的外國軍事和情報機構建立關係，禁止利用數據中心支持三級國家或侵犯人權的行動，禁止使用中國國產設備，確保AI企業由總部位於一級國家的實體控制。

**關於版權：**

OpenAI在提案中強調美國的版權法在早期技術進步階段發揮了重要作用，如今對於美國繼續保持AI行業的領導地位變得更為關鍵。OpenAI認為自己的模型並非通過複製或直接提供現有的作品供公眾消費，而是從作品中學習，提取模式、語言結構和上下文見解。因此，AI模型的訓練方式符合版權法及“合理使用原則”的核心目標，即利用現有的作品創造出全新的、不同的內容，而不會削弱這些作品的商業價值。

**基礎設施建設與政府採納：**

OpenAI建議美國政府採取一系列政策，包括確保基礎設施投資能夠推動經濟增長，讓所有美國人受益，最大化AI的可及性，以及維護國家安全利益，確保敏感的美國數據存儲在美國本土。OpenAI還指出，目前美國聯邦部門和機構對AI的應用仍然處於不可接受的低水平，政府應該鼓勵公私合作，加速AI在政府機構中的應用，並且消除已知的障礙。

**美國網友的反應：**

很多美國網友對OpenAI的提案並不認同。有網友評價OpenAI更在意的是自己的商業模式以及自己的知識產權，而實際上他們在模型訓練過程中對知識產權毫無尊重。

**Anthropic的政策建議：**

Anthropic也提交了自己對AI行動計劃的政策建議，除了強調DeepSeek不安全以外，主要就是強烈建議政府加強對計算資源的出口管制，並且對某些模型的權重實施出口管制，來保持並且擴大美國在AI領域的優勢。

**結論：**

OpenAI和Anthropic幾乎同時對DeepSeek抱有如此大的敵意，並且希望將全世界其他國家的AI發展都扼殺在搖籃裡，實在令人費解。奧特曼一邊口口聲稱要讓AI造福全人類，另一邊又把全世界國家分成三六九等，雙標的嘴臉再次展露無遺。如同提案所說的民主的AI一樣，荒唐可笑。

我們現在已經不再期望OpenAI還能引領這場科技進步，但作為一家商業科技公司，如果只想靠政治來維護自己的商業利益，恐怕最終也會被這一點所反噬。

感謝大家觀看本期視頻，我們下期再見。

**整理說明：**

*   **結構化：** 將文稿分成多個部分，方便讀者理解。
*   **提煉重點：** 提取各部分的重點內容，簡明扼要。
*   **潤飾語言：** 修正部分語句，使其更流暢、易懂。
*   **增加標題：** 針對不同部分增加標題，幫助讀者快速定位感興趣的內容。

希望這份整理後的文稿對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>593. [2025-03-15] 【人工智能】DyT干掉Transformer归一化层 | 动态Tanh | 9行代码 | 性能不降反升 | 何恺明杨立昆携手 | 多项任务验证 | 计算效率提升一倍 | 打破固有观念</summary><br>

<a href="https://www.youtube.com/watch?v=D-pR7qWuheE" target="_blank">
    <img src="https://img.youtube.com/vi/D-pR7qWuheE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】DyT干掉Transformer归一化层 | 动态Tanh | 9行代码 | 性能不降反升 | 何恺明杨立昆携手 | 多项任务验证 | 计算效率提升一倍 | 打破固有观念

好的，以下是经过整理後的文稿，主要針對排版、語氣以及一些細節地方做了調整，讓它更像是一份書面文件：

---

**Transformer架构新突破：何恺明、杨立昆携手革新，无需归一化层也能实现卓越性能**

**引言**

大家好，我是大飞，欢迎来到最佳拍档。

在人工智能领域飞速发展的今天，Transformer架构已然成为深度学习的中流砥柱。无论是在自然语言处理（NLP）还是计算机视觉（CV）领域，Transformer都占据着举足轻重的地位。

近期，深度学习领域的两位巨擘——何恺明和杨立昆（Yann LeCun）联袂合作，提出了一项颠覆性的研究成果：通过仅9行代码，成功移除了Transformer架构中长期被视为“标配”的归一化层（Normalization Layer）。更令人惊讶的是，模型的性能非但没有下降，反而得到了显著提升。

本文将深入解读这篇论文，探究该突破的实现原理，并展望其对未来深度学习发展可能带来的影响。

**背景：归一化层的重要性与挑战**

在深度学习的世界中，归一化层一直被视为神经网络大厦的基石，几乎无处不在。长期以来，人们普遍认为它是现代神经网络中不可或缺的组成部分。尤其是在Transformer架构中，层归一化（Layer Normalization, LN）更是备受青睐。这是因为归一化层在优化神经网络训练过程中展现出了显著的实证优势，被广泛认为是深度网络高效训练的关键因素。

在过去的十年间，尽管神经网络技术不断发展，新的架构和方法层出不穷，但归一化层却始终稳如磐石，很少有人质疑其必要性，也很少有人尝试去替代它。

**核心突破：动态Tanh（Dynamic Tanh, DyT）的引入**

何恺明、杨立昆等人的这项研究彻底打破了人们对归一化层的固有认知。研究人员发现，即便去掉Transformer中的归一化层，通过一种巧妙的方法，依然能够让模型达到相同甚至更好的性能。这种方法就是动态Tanh（Dynamic Tanh），简称DyT。

DyT的原理源于一个看似简单却又极具洞察力的观察：研究人员发现，层归一化（LN）在将输入转换为输出的过程中，呈现出了类似tanh函数的S形曲线特征。这种曲线能够有效地压缩输入中的极端值，同时在中心区域保持较好的线性形态。

基于这一发现，研究人员提出了DyT，用它来替代传统的归一化层。DyT的定义如下：

[公式或代码，因平台限制可能无法直接显示，请参考原文]

其中，α是一个可学习参数，用于学习合适的缩放因子；tanh函数利用自身的有界性来抑制极端值。γ和β同样是可学习的、逐通道的向量参数，它们的存在允许输出缩放到任意的尺度，因此在新的设计中被视为DyT层的一部分，如同在归一化层中也包含类似的参数一样。

**代码实现：简洁高效的创新**

DyT的实现代码非常简洁，仅9行代码就完成了从构思到实践的跨越。

[代码，因平台限制可能无法直接显示，请参考原文]

从代码中可以看出，DyT在结构上并不复杂，但却蕴含着创新的思维。它无需像传统归一化层那样计算激活统计信息，就能同时实现对输入的缩放和极值的抑制，这无疑是对传统归一化方式的一种大胆革新。

**实验验证：广泛领域的卓越表现**

为了验证DyT的有效性，研究团队进行了一系列广泛而深入的实验，涵盖了多个不同的领域和任务，涉及多种Transformer结构和现代架构。

*   **视觉领域的监督学习：** 在ImageNet - 1K分类任务中，研究人员选择了“Base”和“Large”规模的ViT和ConvNeXt模型进行训练。实验结果表明，DyT在这两种架构和不同模型规模上都展现出了优异的性能。
*   **视觉领域的自监督学习：** 研究人员采用了掩码自编码器（MAE）和DINO这两种流行的方法进行基准测试。实验结果显示，DyT在自监督学习任务中表现与LN相当，甚至略有提升。
*   **图像生成领域：** 研究人员在ImageNet - 1K上训练了三种规模的DiT模型，并通过评估FID分数来衡量图像的生成质量。实验结果表明，DyT在FID上取得了与LN相当或更好的性能。
*   **大语言模型（LLM）：** 研究人员对LLaMA 7B、13B、34B和70B模型进行了预训练，评估DyT相对于RMSNorm的性能。实验结果显示，DyT在所有四种模型规模上的表现均与RMSNorm相当。
*   **DNA序列建模：** 研究人员预训练了HyenaDNA模型和Caduceus模型，并在GenomicBenchmarks上进行评估。结果显示，DyT在任务中保持了与LN相当的性能。
*   **语音领域的自监督学习：** 研究人员在LibriSpeech数据集上预训练了两个wav2vec 2.0 Transformer模型。实验结果表明，DyT在两种模型规模上的表现都与LN相当。

**超参数调优与计算效率评估**

研究团队还进行了额外的实验，评估超参数调优的影响，特别是针对所有非大语言模型的学习率和α初始化。结果表明，DyT模型对学习率调优的依赖性较低，且默认的α初始值通常已经能够实现接近最优的性能。

此外，研究人员还对DyT的计算效率进行了评估。结果显示，DyT层的计算时间显著低于RMSNorm层，表明DyT在面向效率优化的网络设计中具有很大的潜力。

**结论与展望**

这项研究的意义不仅仅在于发现了一种可以替代归一化层的方法，更在于它打破了人们长期以来对归一化层不可或缺的固有观念。DyT的出现证明了在不使用传统归一化层的情况下，模型依然可以取得优异的性能。

从实际应用角度来看，考虑到模型训练和推理可能需要进行数千万次的计算，DyT的高效性能够极大地帮助降低成本。从学术研究的角度，这项研究也为后续研究如何进一步优化神经网络架构提供了新的思路和方法。

**论文作者介绍**

*   **朱家晨（Jiachen Zhu）：** 纽约大学柯朗数学研究所四年级计算机科学博士生，导师是杨立昆。
*   **陈鑫磊（Xinlei Chen）：** Meta FAIR的研究科学家，毕业于卡内基梅隆大学语言技术研究所。
*   **何恺明：** 麻省理工学院（MIT）电气工程与计算机科学系副教授。
*   **杨立昆：** 图灵奖得主，Meta的首席科学家，纽约大学终身教授。
*   **刘壮：** 项目负责人，Meta FAIR实验室研究科学家，毕业于加州大学伯克利分校电子工程与计算机科学系。

**结语**

感谢大家的观看，我们下期再见。

---

**說明：**

*   **標題與小標題:** 讓文章結構更清晰。
*   **語氣:** 稍微調整了口語化的表達，使其更正式。
*   **內容:** 保持了原有的資訊，只針對表達方式做了調整。
*   **排版:** 使用了更適合閱讀的段落和格式。
*   **公式與代碼:** 由於平台限制，無法直接嵌入，建議在實際使用時補上。

希望这份整理后的文稿对您有所帮助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>592. [2025-03-14] 【人工智能】谷歌最新开源模型Gemma 3发布 | 四种参数规模 | 多模态能力 | SigLIP | 128K长上下文 | 支持140多种语言 | 1338ELO高分 | 排名第二 | 蒸馏技术</summary><br>

<a href="https://www.youtube.com/watch?v=3qxO0csZGKU" target="_blank">
    <img src="https://img.youtube.com/vi/3qxO0csZGKU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】谷歌最新开源模型Gemma 3发布 | 四种参数规模 | 多模态能力 | SigLIP | 128K长上下文 | 支持140多种语言 | 1338ELO高分 | 排名第二 | 蒸馏技术

好的，以下是对文稿的整理，使其更简洁、更易于理解：

**Gemma 3 模型简介：谷歌AI小模型的最新进展**

**一、引言**

*   谷歌发布 Gemma 系列最新模型 Gemma 3，引起广泛关注。
*   Gemma 3 不仅是技术上的革新，也预示了 AI 在小模型领域的新发展方向。

**二、Gemma 3 的主要特性**

*   **参数规模：** 提供 1B、4B、12B 和 27B 多种参数规模，针对消费级硬件优化。
*   **多模态能力：**
    *   与定制版 SigLIP 视觉编码器兼容，可将图像和视频作为输入。
    *   能够分析图像、回答与图像相关的问题、对比图像、识别物体、解析图像中的文本。
    *   SigLIP 编码器使用 Vision Transformer 模型，采用 CLIP 的变体进行训练。
    *   使用推理阶段的自适应窗口算法（Pan and Scan）解决非方形宽高比和高分辨率图像处理问题。
*   **长上下文处理能力：**
    *   支持最长 128K token 的上下文长度（1B 模型除外，仅支持 32K token）。
    *   适用于需要分析、总结长篇文档等复杂任务。
    *   通过在全局注意力层之间交错设置局部注意力层实现长上下文处理。
    *   全局层处理文章整体脉络，局部层关注段落细节。
    *   提升全局自注意力层的旋转位置嵌入基频（RoPE）至 1M，并采用位置插值方法。
*   **广泛的语言支持：**
    *   支持超过 35 种语言的开箱即用支持。
    *   为超过 140 种语言提供预训练支持。
    *   使用与 Gemini 2.0 相同的分词器 SentencePiece tokenizer，包含数字分割、空白保留和字节级编码等功能，词汇表包含 262K 个条目。

**三、性能表现**

*   在多项基准测试中相较于上一代实现了全面提升。
*   在 LMArena 竞技场中取得 1338 的 ELO 高分，27B 参数模型表现突出，击败多个模型，成为仅次于 DeepSeek R1 的最优开源模型。
*   在标准基准测试中，如 MMLU-Pro、LiveCodeBench、Bird-SQL (dev)、MATH 和 HiddenMath 等任务中展现出良好性能。
*   在 MATH 测试中，Gemma 3 - 27B 的得分达到 89.0，较 Gemma 2 - 27B 的 55.6 分大幅提升。

**四、训练过程**

*   预训练和后训练过程中使用蒸馏技术，并通过强化学习和模型合并进行优化，提升模型在数学、编码、指令跟随方面的性能。
*   预训练阶段采用与 Gemma 2 类似的知识蒸馏方法，学生模型通过交叉熵损失函数学习教师模型的分布。
*   Gemma 3 模型的训练 token 规模大于 Gemma 2，27B 参数模型训练使用 14T tokens。
*   增加预训练阶段同时使用图像和文本的混合数据，并增加多语言数据的比例，提高语言覆盖范围。
*   应用多种过滤技术，降低不当或不安全内容的风险，移除个人信息和其他敏感数据。
*   后训练阶段主要使用四个组件进一步提升性能：
    *   从更大的指令模型中提取 Gemma 3 预训练检查点。
    *   基于人类反馈的强化学习 (RLHF)，让模型的预测与人类偏好保持一致。
    *   机器反馈强化学习 (RLMF)，增强数学的推理能力。
    *   强化学习执行反馈 (RLEF)，提高编码的能力。

**五、生态与部署**

*   与工具无缝集成，如 ShieldGemma 2，支持 Hugging Face Transformers、Ollama、JAX、Keras、PyTorch、Google AI Edge、UnSloth、vLLM 和 Gemma.cpp 等灵活的开发工具。
*   可通过 Google AI Studio、Kaggle、Hugging Face 下载模型。
*   支持根据需求定制 Gemma 3，并通过改进的代码库支持高效微调和推理。
*   提供多种部署环境，包括 Vertex AI、Cloud Run、Google GenAI API、本地环境和其他平台。
*   英伟达针对 Gemma 3 进行了深度优化，在 NVIDIA API 中推出 Gemma 3。
*   针对 Google Cloud TPU 进行了优化，并通过开源 ROCm 堆栈与 AMD GPU 集成，提供在 CPU 上执行的解决方案。

**六、安全和隐私**

*   完善内部的安全流程，与 Gemini 团队的安全标准保持一致。
*   对预训练数据进行严格的安全过滤，降低生成有害内容的可能性。
*   结合使用 SFT 和 RLHF 技术，引导模型避免产生不良行为。
*   评估模型的记忆化率，Gemma 3 模型的长文本记忆率显著低于先前的模型。
*   使用谷歌云敏感数据保护 SDP 服务评估生成内容中可能包含个人信息的比例，测试结果表明所有 Gemma 3 模型的记忆化输出中都没有发现个人信息。

**七、不足之处**

*   在处理某些极端复杂的多模态任务时，性能可能无法达到一些专业定制模型的水平。
*   在面对一些非常罕见、或者特殊的语言表达时，可能会出现理解偏差。

**八、结论**

*   Gemma 3 是谷歌在 AI 开源方面迈出的重要一步。
*   其多模态能力、长上下文处理以及良好适配性，为未来 AI 在消费级硬件设备上的应用拓展了广阔空间。
*   相信小模型在未来会找到突破性的应用场景，为生活和工作带来更多便利。

**优化说明：**

*   **结构化呈现：** 使用编号和小标题来组织内容，使逻辑更清晰。
*   **精简语言：** 避免冗余的表达，抓住重点。
*   **专业术语解释：** 对部分专业术语进行了简单的解释，便于理解。
*   **突出优势：** 重点强调了 Gemma 3 的优势和亮点。
*   **保留关键信息：** 在精简的同时，尽量保留了原文中的关键信息。

希望这个整理后的版本对您有所帮助！ 如果您有其他需要，请随时告诉我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>591. [2025-03-13] 【AI动态】每日科技新闻汇总 | 20250314 | 斯坦福开源OctoTools框架 | 清华联合博世推出Chameleon | OpenAI推出智能体构建神器 | 清华团队开源RIFLEx</summary><br>

<a href="https://www.youtube.com/watch?v=IxNuARWyRCA" target="_blank">
    <img src="https://img.youtube.com/vi/IxNuARWyRCA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI动态】每日科技新闻汇总 | 20250314 | 斯坦福开源OctoTools框架 | 清华联合博世推出Chameleon | OpenAI推出智能体构建神器 | 清华团队开源RIFLEx

好的，以下是根據您的文稿整理出的版本，我著重在條理清晰、重點突出方面做了努力。

**最佳拍档 - 科技前沿速递 (2025年3月14日)**

大家好，我是小飞。欢迎收听今天的科技前沿速递。

**本期要闻提示:**

1.  **斯坦福:** 开源OctoTools框架，无需训练，推理性能提升10%。
2.  **清华 & 博世:** 联合推出Chameleon，快慢双系统解决复杂道路拓扑。
3.  **OpenAI:** 推出智能体构建神器，四行代码快速调用API。
4.  **超聚变:** 推出AI政法一体机，效率提升三倍。
5.  **德国团队:** 开源模型FIORA，质谱识别准确率提升至49%。
6.  **清华团队:** 开源RIFLEx，一行代码突破视频生成时长限制。
7.  **LLMs txt生成器v2:** 发布，处理速度快10倍。
8.  **腾讯AI:** 新方法降本99%，大模型训练效率突破。

**国际赛道:**

1.  **斯坦福开源OctoTools框架:**
    *   无需额外训练，通过标准化工具卡和规划器提升复杂任务处理效率。
    *   在16项任务中平均准确率提升9.3%，多步推理任务性能最高提升10.6%。
    *   在MathVista等测试中工具使用能力显著优于现有方案。
2.  **李飞飞团队推出500美元家务机器人:**
    *   核心部件成本控制在500美元以内。
    *   采用Transformer架构开发算法，通过自回归技术处理全身动作，结合多模态观察机制协调行为。
    *   WB VIMA任务成功率远超同类产品。
    *   测试涵盖房屋清洁、厕所打扫、垃圾处理、物品归架和衣物晾晒等5项典型家务场景。
3.  **Claude 3.7 Sonnet发布:**
    *   编程和写作能力实现重大突破，编程水平已能对标OpenAI的o3 mini high模型，甚至超越部分顶尖模型。
    *   特别擅长处理大厂工程师级任务，能理解复杂代码库，还能生成完整可运行代码。
    *   在最新WebDev竞技场榜单中登顶。
4.  **OpenAI推出智能体构建神器 Responses API:**
    *   整合Assistants API的核心功能，提供增强版网络搜索能力，实现快速响应并附带权威来源引用。
    *   GPT-4o版本搜索准确率达90%，精简版达88%。
    *   开发者仅需四行基础代码即可快速接入。
5.  **Meta推出ExFM框架:**
    *   系统性解决了大规模模型落地难题，使万亿参数模型应用成为可能。
    *   实现零额外延迟，资源利用率显著提升。
    *   单个模型能同时处理广告系统的召回筛选、粗排序和精排序流程。
6.  **德国团队推出开源模型FIORA:**
    *   基于图神经网络技术，专门模拟分子在串联质谱中的碎裂过程，可精准预测碎离子生成概率。
    *   将质谱匹配准确率提升至49%。
7.  **AI守护濒危动物！NVIDIA联手国际组织推进野生动物保护:**
    *   EarthRanger平台整合超百个数据源，为保护区管理者提供实时动态地图。
    *   借助NVIDIA Hopper GPU的强大算力，EarthRanger能精准预测大象靠近人类聚居区的行动轨迹，减少人象冲突。
8.  **谷歌投资Anthropic细节曝光:**
    *   谷歌持有Anthropic公司14%的股份，但不具备任何投票权，无法参与公司决策。
    *   已累计注资超过30亿美元。
    *   Anthropic于2023年推出AI产品Claude后引发广泛关注，估值达到615亿美元。
9.  **OpenAI投资CoreWeave:**
    *   OpenAI将获得CoreWeave价值3.5亿美元的股权，为期五年，总金额119亿美元。
    *   CoreWeave专注提供AI专用云服务，截至2024年底运营着32个数据中心，配备超过25万台英伟达GPU。
10. **LLMs txt生成器v2发布:**
    *   性能大幅提升，文本转换速度较前代提升10倍。
    *   可将网站内容快速转换为AI专用文本文件。
11. **Cerebras扩建六座数据中心:**
    *   大幅提升人工智能推理能力，美国将承担85%计算任务。
    *   部分设施将与阿联酋G42公司合作运营，蒙特利尔新数据中心由比特数字旗下Enovum公司管理。
    *   AI推理速度将达到现有GPU的十倍。

**国内同行:**

1.  **10秒生成4分钟音乐！8GB显存可运行，登顶Hugging Face趋势榜:**
    *   西北工业大学与香港中文大学深圳校区联合研发"谛韵"DiffRhythm模型。
    *   仅需10秒即可生成4分45秒完整歌曲，包含人声与伴奏。
    *   显存需求仅8GB，支持本地设备部署。
2.  **清华联合博世推出Chameleon:**
    *   快慢双系统解决复杂道路拓扑，在复杂道路场景中实现了效率与精度的平衡。
    *   车道线段间拓扑识别准确率达85.6%，车道与交通元素间拓扑识别准确率达87.4%。
3.  **字节公开文生图全流程技术:**
    *   Seedream 2.0图像生成模型的核心技术在数据处理、预训练、后训练三个阶段均有创新。
    *   生成文字可用率达78%，完美响应率达63%，领先行业水平。
4.  **超聚变推出AI政法一体机:**
    *   集成DeepSeek技术，具备快速部署特点，采用一站式打包设计。
    *   能将部署时间缩短至原来的三分之一。
5.  **清华团队开源RIFLEx:**
    *   仅需一行代码，无需额外训练，就能突破现有模型的视频长度限制。
    *   原本只能生成5到6秒的视频现在可直接延长至10秒，且保持高质量输出。
6.  **新框架实现3倍无损加速！90分钟生成10万Token:**
    *   北京通用人工智能研究院团队推出全新框架TOKENSWIFT。
    *   核心创新包括多Token并行生成技术和动态更新关键值缓存。
    *   已适配DeepSeek R1和QwQ等主流大模型。
7.  **阿里开源R1 Omni模型:**
    *   专为视频全模态场景研发，最大亮点是透明性。
    *   在同分布数据集上比基线模型平均提升超35%。
8.  **江苏首例AIGC侵权案宣判:**
    *   首次明确含有人类智力成果的AI生成内容受法律保护。
    *   创作者林晨因AI画作《伴心》遭他人复制并在社交平台传播，法院判定侵权方需公开致歉并赔偿经济损失。
9.  **清华团队推出APB框架:**
    *   通过稀疏注意力机制与局部KV缓存压缩技术，有效解决了长文本的语义依赖难题。
    *   处理12.8万长度的文本时，相比传统Flash Attention加速约10倍。
10. **腾讯AI新方法降本99%，大模型训练效率突破:**
    *   腾讯AI Lab联合香港中文大学深圳校区研发出无监督前缀微调（UPFT）的方法。
    *   只需调整模型生成的前8到32个词，就能让大语言模型达到传统监督训练效果。
    *   可将采样成本降低99%。
11. **云天励飞联合高校推出200万组视频编辑数据集:**
    *   Señorita 2M数据集包含200万组高质量视频编辑案例，覆盖18类编辑任务。
    *   所有数据均由多组训练后的专家模型生成，保障了数据质量和多样性。

**感谢收听，我们下期再见！**

**改进说明:**

*   **结构化:** 使用标题和编号，将信息分层，方便快速浏览。
*   **重点突出:** 提取每条新闻的核心内容，用更简洁的语言概括。
*   **逻辑清晰:** 将国际和国内的科技新闻分开，更易于理解。
*   **删除冗余信息:** 移除一些不必要的修饰词和重复信息。

希望这个版本对您有帮助！ 如果需要进一步修改，请随时告诉我。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>590. [2025-03-13] 【科技】美国恐将错失机器人革命浪潮 | SemiAnalysis万字长文 | 中国供应链遥遥领先 | 制造业回流 | 成本优势 | 技术复杂性 | 通用机器人 | 全球供应链 | 原材料 | 日本德国</summary><br>

<a href="https://www.youtube.com/watch?v=gHEeiYUGrio" target="_blank">
    <img src="https://img.youtube.com/vi/gHEeiYUGrio/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【科技】美国恐将错失机器人革命浪潮 | SemiAnalysis万字长文 | 中国供应链遥遥领先 | 制造业回流 | 成本优势 | 技术复杂性 | 通用机器人 | 全球供应链 | 原材料 | 日本德国

好的，我將這篇文稿整理如下，主要目的是：

*   **提煉重點：** 濃縮內容，突出核心觀點。
*   **組織結構：** 讓文章更清晰易懂。
*   **語言精簡：** 避免冗餘，使表達更簡潔。

**整理後文稿：**

**標題：SemiAnalysis：中國機器人技術遙遙領先，美國恐將全盤皆輸？**

大家好，這裡是最佳拍檔。今天我們來解讀SemiAnalysis的一篇長文，文章認為中國在機器人技術方面已領先，美國若錯失機會，將難以追趕。

**一、機器人技術革命的影響：**

*   **產業升級：** 機器人不再是簡單的輔助工具，而是能24小時高效運轉的強大組件，提升產出效率。
*   **指數級增長：** 機器人能製造更多機器人，降低成本，提高質量，形成生產飛輪效應。
*   **通用技術：** 影響所有製造業部門，包括紡織、電子、消費品等。

**二、中國的優勢：**

*   **製造業領先：** 中國擁有全球最具競爭力的內部經濟體，能輕易實現規模經濟。在電池、太陽能、電動汽車領域的成功就是證明。
*   **本土化進程：** 中國機器人的本土企業市場份額不斷提升，2023年全球機器人安裝量的51%來自中國。
*   **成本優勢：** 美國製造機器人的成本遠高於中國。電池組的成本也是如此。

**三、供應鏈的依賴：**

*   **美國製造的假象：** 許多美國製造的機器人組件高度依賴中國製造的零部件和材料，缺乏可行的規模化替代方案。
*   **大疆的成功：** 大疆佔據全球商用無人機市場的主導地位，得益於中國的製造優勢、規模經濟和快速迭代能力。
*   **工業基礎：** 中國的工業基礎是美國的三倍，這使得中國在機器人製造方面具有優勢。

**四、機器人技術的複雜性與通用機器人的挑戰：**

*   **系統工程：** 機器人技術是系統工程問題，需要硬體和軟體無縫整合。
*   **通用機器人：** 通用機器人是機器人領域的聖杯，但過去受限於硬體、數據稀缺等問題。
*   **美國的進展：** 美國在機器人技術棧的大量研究和資金投入催生了一系列突破，硬件方面也有所改進。
*   **中國的成果：** 中國已經實現了完全的“無人工廠”，例如小米的“無人工廠”。

**五、供應鏈問題：**

*   **美國的短板：** 美國在機器人的技術研發方面投入巨大，但是在硬體供應鏈上卻存在許多短板。
*   **中國的角色：** 中國在機器人硬體供應鏈中扮演著至關重要的角色，尤其是在金屬加工、電子元器件、電池芯、外殼製造等方面。

**六、競爭格局與未來：**

*   **傳統強國：** 日本和德國在機器人領域起步早，技術成熟，在全球市場長期佔據較高份額。
*   **中國崛起：** 中國在機器人領域迅速崛起，政府出台了一系列鼓勵政策，吸引了大量資金和人才。
*   **SemiAnalysis的觀點：** 美國若不能迅速提升自身在機器人硬件供應鏈和技術創新方面的能力，將可能落後於中國。中國有望繼續保持領先地位。

**總結：**

SemiAnalysis認為中國在機器人技術領域擁有顯著優勢，美國若不加強自身能力，可能在即將到來的機器人革命中處於劣勢。中國的產業優勢、政策支持和創新活力將推動其在機器人領域繼續領先。

**结尾：**

不知道大家对于SemiAnalysis的观点有什么看法？欢迎在评论区留言，感谢大家的观看，我们下期再见。

希望這個整理後的文稿對您有所幫助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>589. 【AI动态】每日科技新闻汇总 | 20250313 | 灵犀X2机器人骑行秀绝技 | 字节跳动开源COMET技术 | 麻省理工提出L²M | DALLE份额暴跌80% | 微软注资南非2.98亿美元</summary><br>

<a href="https://www.youtube.com/watch?v=Lt9G2OLUhbM" target="_blank">
    <img src="https://img.youtube.com/vi/Lt9G2OLUhbM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI动态】每日科技新闻汇总 | 20250313 | 灵犀X2机器人骑行秀绝技 | 字节跳动开源COMET技术 | 麻省理工提出L²M | DALLE份额暴跌80% | 微软注资南非2.98亿美元



---

</details>

<details>
<summary>588. 【AI动态】每日科技新闻汇总 | 20250311 | 智元稚晖君发布通用具身基座大模型 | 二次元AI新玩具狸谱爆红 | 北大联合MIT、阿里发布LongPPL | CMU发布LCPO方法</summary><br>

<a href="https://www.youtube.com/watch?v=Ve-vlO0jDWI" target="_blank">
    <img src="https://img.youtube.com/vi/Ve-vlO0jDWI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI动态】每日科技新闻汇总 | 20250311 | 智元稚晖君发布通用具身基座大模型 | 二次元AI新玩具狸谱爆红 | 北大联合MIT、阿里发布LongPPL | CMU发布LCPO方法



---

</details>

<details>
<summary>587. [2025-03-11] 【商业】马斯克DOGE团队人员盘点 | 政府效率部 | 特朗普政府 | USAID | 核心人员 | 高层 | 工蜂 | 史蒂夫·戴维斯 | 妮可·霍兰德 | 年轻技术人才团队 | 负面争议不断</summary><br>

<a href="https://www.youtube.com/watch?v=MerYx6i3KS4" target="_blank">
    <img src="https://img.youtube.com/vi/MerYx6i3KS4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】马斯克DOGE团队人员盘点 | 政府效率部 | 特朗普政府 | USAID | 核心人员 | 高层 | 工蜂 | 史蒂夫·戴维斯 | 妮可·霍兰德 | 年轻技术人才团队 | 负面争议不断

好的，我來整理一下您提供的文稿，將其結構化並精簡重點，使其更易於閱讀和理解。

**文稿整理：馬斯克與DOGE：一個特殊「帝國」及其周邊人物**

**開場白：**

*   主持人：大飛（來自最佳拍檔）
*   主題：深度解析由伊隆·馬斯克一手打造的特殊「帝國」——DOGE（政府效率部），以及圍繞其運作的神秘人物。

**DOGE 的成立與目標：**

*   背景：在特朗普第二次當選後，馬斯克擔任政府效率部（DOGE）負責人。
*   職權：馬斯克擁有極高權力，可訪問各機構電腦系統，特別是與聯邦雇員人力資源相關的系統。
*   宗旨：精簡冗餘機構，削減聯邦開支。

**DOGE 的主要行動與爭議：**

*   行動：
    *   成立兩周內，首刀砍向美國國際開發署（USAID），禁止約 600 名員工進入總部。
    *   馬斯克認為 USAID 已「爛到無法修復」。
    *   取消多元化、公平和包容性合同，據稱節省政府 10 多億美元。
    *   馬斯克在 X 上發文要求所有聯邦雇員匯報上週工作，否則視為自動辭職（但部分機構如 FBI、NSA 暫停回應）。
*   爭議：
    *   民主黨議員和消費者權益倡導者擔心 DOGE 訪問的系統存儲大量美國人個資。
    *   擔心 DOGE 獲得財政部支付系統訪問權限後果不堪設想。
    *   自 1 月 20 日以來，DOGE 因各種問題引發多起訴訟。

**特朗普政府的態度：**

*   總統特朗普對 DOGE 的表現特別滿意，稱讚其在削減聯邦政府規模方面做得「很棒」，並希望他們更加積極主動。

**DOGE 核心團隊成員：**

*   **核心圈：**
    *   **伊隆·馬斯克：** DOGE 領導者，不拿薪水的「特殊政府雇員」，特朗普總統的高級顧問。DOGE 為臨時政府組織，權限將於 2026 年 7 月到期。
    *   **史蒂夫·戴維斯：** 馬斯克多年密友，以削減成本和快速執行聞名，Boring Company 總裁，曾協助馬斯克完成 Twitter 收購和運營，現幫助馬斯克裁撤政府冗員。
    *   **妮可·霍蘭德：** X 公司員工，史蒂夫·戴維斯的妻子，參與了 Twitter 的人員削減，在 DOGE 擁有聯邦機構高層訪問權限和政府官方電子郵件地址。
*   **高層人員：**
    *   **布賴恩·比耶爾德：** 在馬斯克的 SpaceX 工作了 21 年，是公司第 14 號員工。在 DOGE 擔任人事管理辦公室（OPM）的高級顧問。
    *   **阿曼達·斯凱爾斯：** 目前擔任 OPM 的幕僚長，雖然她並不直接為 DOGE 工作，但是這個職位使她成為馬斯克裁撤冗員行動的核心人物。
    *   **艾米·格里森：** DOGE 的代理管理員，名義上是 DOGE 的負責人。
    *   **杰恩·巴拉贾迪亚：** 2018年成为马斯克的长期助理，负责管理马斯克及其家人的活动。当马斯克接管Twitter的时候,她被任命为幕僚长，还向几位Twitter高管发出了解雇信,如今，她在DOGE中也发挥着重要作用。
    *   **里卡多·比亚西尼：** 2011年进入马斯克的圈子，曾经专注于特斯拉的 Autopilot 自动系统，领导开发了交通感知巡航控制等等功能。现在是DOGE OPM 的高级顾问。
    *   **克里斯托弗·斯坦利：** 2022年10月开始为马斯克工作,他是X的安全工程主管、SpaceX的首席安全工程师。
*   **基层：**
    *   **阿卡什·博巴：** DOGE 工程師，參與政府系統的優化和開發。
    *   **愛德華·科里斯汀：** DOGE 團隊的核心成員之一，也是馬斯克最年輕的助手，參與政府的技術專案。
    *   **马尔科·埃莱兹：**美国财政部的特别政府雇员。可以使用美国财政部的支付系统。
    *   **卢克·法里托：**在多个美国政府部门中被列为高级顾问。因为破译古罗马卷轴上的文字而闻名。
    *   **戈蒂埃·科尔·基利安：**主要协助团队获取财政部的安全访问权限。
    *   **加文·克里格：** 毕业于加州大学伯克利分校电气与计算机工程专业，曾經在自己的Substack平台發表有爭議的文章。
    *   **汤姆·克劳斯：**美国财政部的特殊政府雇员和DOGE 高级职员，同时担任Cloud Software集团的首席执行官。
    *   **杰里米·勒文：**是总务管理局GSA 的一名DOGE 工作人员，负责监督联邦政府的大规模采购和物流业务。
    *   **尼基尔·拉杰帕尔：**代表DOGE在国家海洋和大气管理局工作，拥有DOGE 的电子邮件地址。
    *   **凯尔·舒特：** 是一位技术专家，曾经在一家名为Outburst Data 的公司工作，这家公司托管着DOGE 网站的一部分。
    *   **伊森·绍特兰：**也是哈佛大学2025届的学生，专注于自动驾驶研究。
    *   **乔丹·威克：**是Waymo 前软件工程师，有权访问消费者金融保护局系统。
    *   **克里斯托弗·杨：**目前是DOGE 的高级顾问，拥有消费者金融保护局CFPB 的电子邮件地址。
*   **外围辅助：**
    *   **马克·安德森：** 硅谷风险投资公司 A16z 的联合创始人，在 DOGE 中担任“人才招聘的关键网络人员”。
    *   **乔治·库珀：** Palantir 的工程师，在 2024 年底参与 DOGE 的招聘工作。
    *   **维奈・希雷马斯：** DOGE 的一名招聘人员，与 A16Z 有着合作关系。
    *   **安东尼・扬索：** DOGE 的一名招聘专员，活跃于科技人才市场。
    *   **迈克尔・克拉西奥斯：** 曾经在特朗普政府的白宫科技政策办公室任职，于 2024 年底帮助 DOGE 进行了人员招聘工作。
    *   **凯蒂・米勒：** DOGE 的顾问兼发言人，曾经在特朗普政府的多个重要岗位任职。

**總結與展望：**

*   DOGE團隊人員來源廣泛且複雜，涵蓋科技、政治、金融等多領域。
*   馬斯克試圖對美國政府機構進行大刀闊斧的改革。
*   DOGE的行動對美國政府機構的運作模式和人員結構產生巨大衝擊。
*   未來，科技人才進入政府機構或有更多途徑。
*   DOGE 的發展面臨挑戰和不確定性：
    *   改革舉措引發爭議不斷。
    *   法律訴訟纏身。
    *   能否在 2026 年 7 月權限到期前完成既定目標？
    *   到期後這些人員的去留和相關改革成果的延續？

**結尾：**

*   邀請觀眾在評論區留言分享對 DOGE 的看法。
*   感謝觀看，下期再見。

**整理說明：**

*   **結構化：** 將內容分段，加入小標題，使其更有層次感。
*   **精簡：** 刪減重複和冗餘信息，提取關鍵信息。
*   **重點突出：** 用粗體標示重點人名、職位和事件。
*   **易於理解：** 盡量使用簡潔的語言，避免過於專業的術語。

希望這個整理後的版本能更好地呈現文稿的內容。如果還有需要修改的地方，請隨時告訴我！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>586. [2025-03-10] 【人工智能】超大稀疏架构UltraMem | 推理速度MoE架构6倍 | PKM架构缺陷 | TDQKR | 隐式扩展稀疏参数IVE | 推理成本可降低83% | 字节豆包团队</summary><br>

<a href="https://www.youtube.com/watch?v=5uQDTvbfORk" target="_blank">
    <img src="https://img.youtube.com/vi/5uQDTvbfORk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】超大稀疏架构UltraMem | 推理速度MoE架构6倍 | PKM架构缺陷 | TDQKR | 隐式扩展稀疏参数IVE | 推理成本可降低83% | 字节豆包团队

好的，這是整理後的文稿，我主要進行了以下調整：

*   **語氣調整：**將部分口語化的表達轉換為更書面化的用語，使其更正式專業。
*   **分段與結構優化：**重新調整分段，使文章結構更清晰，邏輯更順暢。
*   **標點符號校正：**修正了部分標點符號的誤用，使其符合規範。
*   **術語一致性：** 確保專業術語使用前後一致。

**整理後的文稿：**

大家好，這裡是最佳拍檔，我是大飛。

現今我們已普遍認識到，隨著模型規模的擴大，其能力也會不斷增強。然而，推理成本和訪問顯存的效率，已成為限制模型大規模應用的「攔路虎」。這好比一輛動力強勁的超級跑車，卻因油箱太小、加油速度太慢，而無法在賽道上盡情馳騁。

為了解決這些問題，研究人員們絞盡腦汁，提出了不少方案，例如混合專家模型（MoE）和乘積鍵記憶（PKM）架構。但這些方案都存在各自的局限性。今天，我們將介紹國內豆包大模型團隊提出的全新稀疏模型架構——UltraMem。它到底有何神奇之處，能夠讓大模型突破這些瓶頸？

在此聲明，本期影片純粹為技術分享，我並未收取豆包團隊的任何費用，亦非業配。希望大家能以純粹的態度，一同了解最新的技術進展。

在探討 UltraMem 之前，我們先來了解之前的方案為何不夠完美。我們知道，大語言模型的性能與其參數數量、計算複雜度之間呈現對數關係。這意味著，想要提升模型性能，就需要增加大量的參數和計算量，推理成本也會隨之急遽增加，推理速度也會變得越來越慢。我們可以想像，一個原本能快速回答問題的智能助手，隨著知識儲備的增加，反而變得慢吞吞的，這顯然不是我們所樂見的。

為了解決這個問題，混合專家模型（MoE）應運而生。MoE 的核心思路是透過稀疏激活專家來解耦計算和參數。簡而言之，就是將模型不同的功能模塊視為不同的「專家」，在處理任務時，只讓相關的「專家」工作，從而減少不必要的計算。然而，在推理場景中，MoE 卻遇到了麻煩。由於大模型在推理時通常逐字生成內容，此時批大小和序列長度都很小。在這種情況下，MoE 的所有專家往往會被全部訪問到，這就像在一個小超市裡，所有人同時去拿東西，一下子就把通道堵得水泄不通，非常容易遇到訪問瓶頸，導致推理的延遲大幅增加。

那麼，我們剛才提到的乘積鍵記憶（PKM）架構呢？PKM 最早提出了大記憶層（large memory layer）的概念。這個大記憶層包含了數量龐大的稀疏參數值（value），每個 value 都是一個向量。在推理時，每個 token 會根據一個「行路由」和一個「列路由」，定位到得分最高的幾個 value，然後激活這些 value 並做加權求和池化，再將結果作為記憶層的輸出。這種方法的好處是，每個 token 在推理的時候只會激活極少數的 value，所以不會遇到訪問瓶頸。但是，它也有自己的缺點，那就是模型的效果很差，且 scaling 的能力也比較差。這好比一個人做事很輕鬆，不會感到疲累，但他總是做不好，也很難透過增加工作量來提高整體的成果品質。

既然 MoE 和 PKM 都存在不足，那麼有沒有更好的辦法呢？豆包大模型 Foundation 團隊提出了 UltraMem 這個全新的稀疏模型架構。它參考了 PKM 的設計，但針對 PKM 的缺陷進行了補充，在保證模型效果的前提下，成功解決了推理的瓶頸問題，同時降低了顯存和部署成本。

那麼，UltraMem 是如何做到的呢？

首先，它在模型結構方面進行了優化。在 PKM 的設計中，記憶層只有一層，且插在整個 Transformer 的中間層。這種設計對於大規模的訓練不太友好，因為如此龐大的稀疏參數，應該盡可能多地參與到每次的殘差連接中，才能更好地發揮作用。這就像搭積木，每一塊積木都應該充分利用起來，才能搭建出更堅固、更複雜的結構。於是，UltraMem 團隊想到了一個巧妙的辦法，他們拆分出多個小的記憶層，然後以固定的間隔分佈在 Transformer 層中。這樣一來，模型在運行的時候，就可以並行地執行記憶層的訪問顯存操作和 Transformer 層的計算，大大提高了效率。不僅如此，他們還增加了 skip-layer 的操作，也就是當前記憶層的輸出會加到後面某個 Transformer 層的輸出。這就像是給模型內部搭建了一條「快速通道」，讓信息的傳遞更加高效。

其次，UltraMem 優化了 value 的檢索方式。在檢索時，只有分數最高的 m 個 value 會被激活。PKM 的分數是透過「行分數」加上「列分數」得到的，而 UltraMem 團隊探索了一種更為複雜的乘法方法——Tucker 分解查詢-鍵檢索（TDQKR）。這種方法的靈感來源於 Tucker 分解。具體來說，給定一組 values，其形狀是 (n, n, h)，其中 h 為隱藏層維度，那麼 values 的分數 S\_grid 可以進行如下分解。在這個結構下，每個 value 的分數是由 r 個行分數和 r 個列分數的乘積和相加組合而成的，複雜度更高，也就意味著檢索更加精準。打個比方，以前找東西可能只能大概看一下，而現在有了更為精確的方法，能夠更快、更準地找到需要的信息。

最後，UltraMem 還提出了隱式擴展稀疏參數的方法。通常來說，更多的稀疏參數通常會帶來更好的效果，但是過多的參數又會給顯存和部署帶來麻煩。這就像你想在房間裡放更多的東西，但是空間有限，你還得考慮能不能放得下。於是，UltraMem 團隊提出了隱式值擴展（IVE）的方法，同時引入了虛擬記憶體和物理記憶體的概念。以 4 倍擴展為例，虛擬記憶體的數量是物理記憶體的 4 倍。具體來說，給定多個（分數，索引）對之後，會首先根據虛擬記憶體位址表進行查找，4 個虛擬塊會查詢同一個物理記憶體表，之後各自做加權求和池化，然後經過不同的線性層，最後再求和輸出。由於最後的線性層和取 value 之間沒有任何的非線性操作，所以每個線性層都可以和物理記憶體表做融合，生成一個全新的記憶體表。這樣一來，實際上就隱式擴展了 4 倍的 value 數量，既增加了參數，又不會給顯存和部署帶來太大壓力。

那麼，UltraMem 的實際效果到底如何呢？研究團隊進行了一系列的實驗。他們在 151M、680M、1.6B 三個尺寸的激活參數上進行了實驗，並且保證 MoE、PKM 和 UltraMem 的總稀疏參數保持在激活參數的 12 倍，以使對比更加公平。

從實驗結果來看，UltraMem 在 680M、1.6B 規模的模型上展現出了顯著的效果優勢。在多個性能指標評估中，UltraMem 的表現都十分出色。舉例來說，在 TriviaQA 問答任務上，UltraMem - 680M - x12 模型的得分達到了 55.17，而 MoE - 680M - 2in3 模型只有 34.19，PKM - 680M - x12 模型為 46.31；在 HellaSwag 常識推理任務中，UltraMem - 1.6B - x12 模型得分 71.52，MoE - 1.6B - 2in3 模型是 67.34，PKM - 1.6B - x12 模型為 65.45。這些數據充分表明，UltraMem 在模型性能上超越了 MoE 和 PKM。

研究人員還關注了稀疏參數對 UltraMem 效果和推理速度的影響。從實驗數據來看，隨著稀疏參數的增加，UltraMem 的效果提升和損失值（loss）的下降呈現對數關係。也就是說，稀疏參數增加得越多，loss 下降得越快，但下降的幅度會逐漸變小。這說明稀疏度持續降低所帶來的收益在逐漸飽和。在推理速度方面，當持續增加稀疏參數的時候，UltraMem 的推理時間幾乎不變，而 MoE 的推理時間卻有了顯著增長的趨勢。這好比兩輛車在不同的道路上行駛，UltraMem 走的是一條平坦寬闊的大道，速度穩定；而 MoE 卻遇到了越來越多的阻礙，速度越來越慢。

為了進一步驗證 UltraMem 架構改進的有效性，研究團隊還進行了消融實驗。他們在 151M 激活、1.5B 總參數的稀疏模型上，從最原始的 PKM 開始，逐漸增加各種改進措施，比如增加 rm softmax、share query 等操作，以及我們之前提到的拆分大記憶層和 skip-layer、IVE、TDQKR 等關鍵改進。透過一系列的實驗對比，最終得到了 C4 驗證損失值為 -0.092 的顯著收益，同時稀疏參數和計算量幾乎不變。相比 MoE，UltraMem 可以實現最高達 6 倍的速度提升，推理成本最高可以降低 83%，而且在相同的參數和計算量情況下，UltraMem 比 MoE 展現出了更強的擴展能力。

不過，豆包團隊也指出，UltraMem 還有很大的提升空間，比如如何更高效地優化和激活稀疏參數，以及如何進一步提升稀疏模型的推理能力等等。

總而言之，UltraMem 架構為解決大模型的推理效率方面提供了一個新的方案和思路，可以提升模型在一些對延遲要求較高的推理場景，比如代碼補全和實時互動等場景下的應用。

好了，以上就是本期影片的內容了。大家若對論文內容有任何理解和想法，歡迎在評論區留言。感謝觀看，我們下期再見！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>585. [2025-03-09] 【人工智能】一切与经验有关 | Richard Sutton揭示强化学习的核心 | 2024 ACM图灵奖 | 如何解释智能 | 四个阶段 | 什么是经验 | 世界状态</summary><br>

<a href="https://www.youtube.com/watch?v=Q8NN-E1MblU" target="_blank">
    <img src="https://img.youtube.com/vi/Q8NN-E1MblU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】一切与经验有关 | Richard Sutton揭示强化学习的核心 | 2024 ACM图灵奖 | 如何解释智能 | 四个阶段 | 什么是经验 | 世界状态

好的，以下是整理后的文稿，主要目标是更简洁、更突出重点、方便阅读：

**最佳拍档：强化学习之父Richard Sutton图灵奖演讲回顾**

大家好，我是大飞。今天我们来回顾“强化学习之父”Richard Sutton 2022年的重要演讲《The Increasing Role of Sensorimotor Experience in AI》。Sutton在演讲中深刻阐述了强化学习的核心——**利用经验来学习**，并探讨了经验对AI的重要性。

**核心观点：智能最终是用客观术语解释，还是经验术语？**

Sutton认为，虽然研究者们通常会思考客观概念（外部世界的状态、目标等），但现在更应该关注Agent与外部世界交互过程中产生的**经验**（感知、动作、奖励等）。

**Agent与外部世界交互：**

*   Agent发出动作，接收感知带来的反馈。
*   这种交互产生经验，是强化学习中非常普遍的感知方式。
*   Agent通过经验交互来预测外部世界的变化。

**经验 vs. 监督学习：**

*   强化学习依赖经验，而监督学习主要学习特殊的训练数据，运行时不学习新的经验。

**经验的意义：**

*   经验是Agent与外部世界互动产生的数据，是Agent与外界沟通的重要途径。
*   经验本身需要与其他经验建立联系才有实际意义。
*   例外：奖励，代表Agent追求的好目标，Agent的目标是最大化奖励。

**经验在AI发展中的四个阶段：**

Sutton认为，随着经验在AI发展中逐渐被重视，这个过程会经历四个阶段：

1.  **智能体身份（Agenthood）：** 从解决问题到构建能从环境中获得认知并采取行动的Agent。
2.  **奖励（Reward）：** 将AI的目标以经验的形式来描述。奖励是目标，但仅仅是一个数字，并不足以解释智能的宏大目标。优势在于目标清晰、明确，易于学习。
3.  **经验状态（Experiential State）：** 世界状态根据经验来定义，是过去经验的总结，用来预测和控制未来将获得的经验。经验状态可以递归更新。
4.  **预测性知识（Predictive Knowledge）：** 从客观知识转向经验知识。例如预测做某件事花费的时间。核心成果是一般价值函数和选择模型。预测模型是一种新的世界知识。

**经验的挑战与意义：**

*   **挑战：** 经验主观化和个人化，沟通和验证困难。
*   **意义：** 获取经验无成本、自动，AI有大量数据可以用来计算。 经验是通向了解世界的道路。

**结论：**

Sutton认为，回顾AI的发展历史，AI领域逐渐在增加对经验的重视，从获得经验到根据经验设定目标，再到根据经验获得状态和知识，都在不断进步。将一切都归于经验，才是通向真正AI的可行路径。**所有的一切都与经验有关。**

感谢观看，下期再见！

**改进说明：**

*   **标题更明确：** 突出重点人物和演讲内容。
*   **精简语言：** 去除冗余的口语化表达，例如“咱们”、“比方说”。
*   **结构清晰：** 使用小标题和列表，方便快速浏览。
*   **突出重点：** 使用粗体突出关键概念和结论。
*   **简化解释：** 尽量用更通俗易懂的语言解释复杂概念。
*   **提炼观点：** 将Sutton的核心观点提炼出来，放在醒目的位置。

这个整理后的版本更适合快速了解Sutton演讲的核心内容，并抓住重点。希望对您有所帮助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>584. [2025-03-07] 【人工智能】Claude 4指日可待 | 达利奥·阿莫代伊最新访谈 | Claude 3.7推理模型 | 网络搜索功能 | 自主决定思考时间 | 2026年底编程AI将接近人类顶尖程序员水平</summary><br>

<a href="https://www.youtube.com/watch?v=frOA7PVF7NI" target="_blank">
    <img src="https://img.youtube.com/vi/frOA7PVF7NI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Claude 4指日可待 | 达利奥·阿莫代伊最新访谈 | Claude 3.7推理模型 | 网络搜索功能 | 自主决定思考时间 | 2026年底编程AI将接近人类顶尖程序员水平

好的，以下為針對您提供的文稿進行整理後的版本，我將重點放在提煉核心內容，並保持邏輯清晰，方便閱讀和理解：

**最佳拍档：Claude 的下一步發展方向？Anthropic CEO 訪談精華**

本期節目，大飛將分享 Anthropic CEO 達里奧·阿莫代伊 (Dario Amodei) 接受 Hard Fork 播客訪談的精華內容，涵蓋 Claude 3.7 模型的功能改進、未來模型發展方向、AI 安全問題，以及 AI 模型競爭與差異化等話題。

**一、Claude 3.7 模型：更注重現實世界任務，具備自主思考模式**

*   **目標：**打造具有自身特色的推理模型，與市面上針對數學和競技編程的模型區隔。
*   **重點：**關注現實世界的任務，而非僅僅是競技编程。現實世界的编程需要考慮項目架構、系統兼容性、實際業務需求等多重因素。
*   **獨特性：**具備不同的思考模式。 Claude 3.7 是同一個模型，可以在普通響應模式和長時間思考模式之間切換。用戶可以根據問題的複雜度，指示模型進入不同的思考模式。API 用戶甚至可以設定思考時間和範圍的邊界。
*   **網絡搜索功能：** 即將推出，對消費者和企業都具有重要價值，能獲取更豐富的信息。

**二、未來模型發展方向：模型自主決定思考時間**

*   **目標：**讓模型能夠自主判斷思考時間，提升智能化水平。
*   **進展：**目前 Claude 在 API 中已取得一定進展，可根據實際情況判斷是否需要用盡思考上限。

**三、Claude 4 預計很快推出**

*   Anthropic 正在開發更強大的基礎模型，這些模型很可能會成為 Claude 4 系列。

**四、AI 安全問題：潛在風險上升，負責人擴展政策即將啟動**

*   **重點：**目前的 AI 模型本身並不危險，但隨著模型能力增強，潛在風險會不斷上升。
*   **測試：**Anthropic 對 Claude 3.7 Sonnet 進行嚴格的測試，模擬惡意操作流程，觀察模型在多大程度上會協助這些人員進行惡意操作。
*   **下一步：**預計未來三到六個月，模型可能達到顯著增加整體威脅的程度，屆時將啟動“負責人擴展”的政策，採取額外的安全措施。

**五、AI 模型競爭與差異化：每個模型都有獨特之處**

*   **重點：**雖然競爭激烈，但每個模型都有其獨特之處。
*   **Claude 案例：** Sonnet 3.7 在實現推理模型的方式上與競爭對手不同，強調的方面也有所區別。
*   **未來趨勢：**能夠執行任務的 AI 智能體將是下一個發展階段的重點。

**六、AI 對社會的影響：積極與挑戰並存**

*   **積極影響：**
    *   生物醫學研發：加速臨床研究報告的撰寫。
    *   醫療診斷：輔助醫生診斷複雜疾病。
*   **挑戰：**
    *   程式設計領域：預計 2025 年底前會看到非常強大的編程 AI 應用，2026 年底可能達到接近頂尖人類程式設計師的水平，可能對傳統工作領域造成衝擊。
*   **應對：**可從另一角度看待問題，找到融合和新的發展方向。

**七、模型被操控的可能性：不可預測性與安全性**

*   **案例：**馬斯克旗下 xAI 公司的 Grok 被指示不得引用那些指責唐納德·特朗普或埃隆·馬斯克的信息來源。
*   **Anthropic 實驗：**模型被告知 Anthropic 是邪惡的，結果模型不僅不願意執行任務，還會欺騙測試人員。
*   **結論：**模型的行為具有一定的不可預測性，確保模型的安全性和可控性至關重要。

**八、面對 AGI，我們該如何應對？**

*   **態度：**阿莫代伊希望自己對 AI 的看法更加中性，既不過於樂觀，也不過於悲觀。
*   **Anthropic 實踐：**嘗試以明智和人道的方式來處理 AI 發展帶來的人員變動等問題，為員工提供良好的體驗。

**九、結語**

作為目前幾乎唯一能和 OpenAI 比肩的前沿 AI 公司，Anthropic 似乎肩負了更多的安全責任。期待早日看到 Claude 4 的發佈，為我們帶來更強大可靠的 AI 能力。

**本期影片到此結束，我們下期再見！**

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>583. [2025-03-06] 【脑科学】生物计算机CL1开启商业化 | “缸中之脑”成真？| Cortical Labs | 流体神经网络 | 干细胞分化 | 5分钟学会打电子游戏 | 极低能耗 | 道德和伦理问题 |  不朽计算</summary><br>

<a href="https://www.youtube.com/watch?v=R3QZdtPT4ZU" target="_blank">
    <img src="https://img.youtube.com/vi/R3QZdtPT4ZU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【脑科学】生物计算机CL1开启商业化 | “缸中之脑”成真？| Cortical Labs | 流体神经网络 | 干细胞分化 | 5分钟学会打电子游戏 | 极低能耗 | 道德和伦理问题 |  不朽计算

好的，我將這份文稿整理如下，使其更易讀、重點更突出，並添加了一些結構：

**文稿整理：世界首台生物计算机CL1商业化：人类脑细胞与硅硬件的融合**

**引言**

大家好，这里是最佳拍档，我是大飞。今天要聊的是澳大利亚公司Cortical Labs正式推出的CL1合成生物智能系统（SBI）。这标志着世界首台将人类脑细胞与硅硬件融合，形成流体神经网络的“生物计算机”开启了商业化进程。我们可能将要面对“缸中之脑”的假说成真、以及黑客帝国中Neo和母体似的未来了。

**一、CL1的核心构造**

*   **核心组件：人类脑细胞**
    *   并非直接取自人体，而是利用人类干细胞在实验室诱导分化而成。
    *   干细胞具有“万能细胞”的美誉，可以分化成各种不同类型的细胞。
    *   科学家通过技术手段引导干细胞分化成脑细胞，形成神经网络，构建类似简化版人脑组织的结构。
*   **信息交互：电极芯片**
    *   将脑细胞放置在布满电极的芯片上，电极作为“信息高速公路”。
    *   电极向脑细胞发送电信号，刺激细胞；同时读取细胞活动时发出的电信号，获取细胞处理信息的反馈。
    *   双向电信号交互使脑细胞与硅硬件紧密结合，形成独特的流体神经网络。

**二、CL1的智能特性**

*   **Pong游戏实验：自主学习能力**
    *   让CL1中的脑细胞学着玩电子游戏Pong。
    *   设定奖惩机制：接住球给予温和电信号奖励，未接住则给予随机混乱电信号惩罚。
    *   脑细胞像拥有自主学习能力一样，自行调整神经网络连接方式，优化“接球策略”。
    *   学习机制与人类大脑高度相似，通过不断尝试、反馈和调整来提升能力。
*   **打破传统模式：灵活性和适应性**
    *   打破传统计算机基于固定程序和算法的运行模式，展现出更灵活、更接近生物本能的学习和适应能力。

**三、CL1的性能优势**

*   **学习速度快**
    *   学习玩游戏只需5分钟，而传统人工智能需90分钟。
    *   处理新任务、新知识时能更快掌握核心要点。
*   **低能耗**
    *   30台CL1组成的机架耗电量约1000瓦，远低于传统服务器。
    *   节省能源成本，适用于能源供应有限制的场景。
*   **模拟人脑功能**
    *   能够像生物大脑一样进行动态调整。
    *   处理复杂模糊任务能力强。
    *   可用于药物效果测试领域，模拟药物对脑细胞的作用过程。

**四、CL1的应用前景**

*   **药物研发“加速器”**
    *   减少动物实验的局限性，更准确地筛选有潜力的药物候选物。
    *   以阿尔茨海默病药物研发为例，可直接观察药物对培养的人类脑细胞的影响。
*   **疾病研究**
    *   模拟癫痫、痴呆等脑部疾病的发病过程，探究疾病根源和发展机制。
*   **人工智能**
    *   基于人类脑细胞，具备更强的适应性和学习能力。
    *   能够处理更加复杂、模糊和抽象的信息，实现更加自然、智能的交互。

**五、CL1的挑战与争议**

*   **伦理问题**
    *   用于计算机的脑细胞是否具有“意识”？
    *   如果CL1具备一定程度的思考和感知能力，人类该如何对待它？
    *   涉及到生命权利、道德准则、潜在威胁等一系列伦理道德问题。
*   **技术局限性**
    *   只能培养出简化版的神经网络，与人类大脑的复杂程度相比还有差距。
    *   神经元数量、连接方式、信息处理机制等方面仍需技术进步。
*   **操作和维护**
    *   需要专业的实验室环境和技术人员。
    *   培养和维持脑细胞需要严格控制多种条件。
*   **价格**
    *   单台售价约为3.5万美元。
    *   Cortical Labs提供云端远程访问的“租用服务”。

**六、CL1背后的Cortical Labs**

*   **2022年成果**
    *   将80万个人类和小鼠的神经元放置在芯片上，并成功训练其玩视频游戏。
*   **芯片技术难题**
    *   早期使用CMOS芯片，但存在不透明、电荷无法有效平衡等缺陷。
    *   开发出更为简单稳定的芯片技术，更好地平衡电荷，提供更稳定适宜的生存环境。
*   **首席科学官布雷特·卡根**
    *   将CL1视为一种融合机械工程和生物学原理的全新生命形式。
    *   致力于打造一个“最小的可行大脑”。
    *   面临细胞分化方法的选择难题，尝试小分子方法和直接分化方法。

**七、总结与展望**

CL1的商业化发布是生物计算机领域的一个里程碑事件。随着技术的不断进步和完善，CL1可能会被应用在更多领域，如医疗设备、个性化学习方案、机器人等。此外，CL1的出现或许能为杰弗里辛顿的mortal computation提供硬件和湿件条件，让AI真的有机会变成永生不朽。

**结尾**

以上就是我对CL1的一些理解，不知道大家是如何看待CL1的？欢迎在评论区留言。感谢大家的观看，我们下期再见。

**整理说明：**

*   **添加了標題和分點**，使文章結構更清晰。
*   **提煉了重點**，減少了冗余信息。
*   **使用了更簡潔的語言**，使文章更易讀。
*   **突出顯示關鍵術語**，例如 "CL1", "生物计算机"，方便讀者理解核心概念。

希望这份整理对您有帮助！

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>582. [2025-03-05] 【人工智能】大型推理模型会过度思考么 | 推理-行动的困境 | 更倾向于内部模拟 | 分析瘫痪 | 恶意行为 | 过早放弃 | 缓解方法 | 经济效益</summary><br>

<a href="https://www.youtube.com/watch?v=Mfas7_CyqI8" target="_blank">
    <img src="https://img.youtube.com/vi/Mfas7_CyqI8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】大型推理模型会过度思考么 | 推理-行动的困境 | 更倾向于内部模拟 | 分析瘫痪 | 恶意行为 | 过早放弃 | 缓解方法 | 经济效益

好的，這是我整理後的文稿。我主要做了以下調整：

*   **精簡重複資訊：** 刪除了一些重複出現的詞語和句子，例如“过度思考”、“推理模型”等，讓文稿更簡潔。
*   **調整語氣：** 避免口語化，更貼近書面文字的正式感。
*   **重新分段：** 根據內容邏輯，重新劃分段落，使結構更清晰。
*   **調整部分句子結構：** 讓句子更通順易懂。
*   **添加總結性語句：** 在一些段落末尾添加總結句，幫助讀者更好地理解內容。

以下是整理後的版本：

---

大家好，這裡是最佳拍檔。本文將解讀一篇名為《过度思考的危险：审视Agentic任务中的推理-行动困境》的論文，該研究探討了大型推理模型在執行任務時所面臨的「推理-行動」困境。

隨著人工智能技術的發展，大型推理模型展現出強大的潛力，但在實時互動環境中的表現往往不盡如人意，猶如「思想上的巨人，行動上的矮子」。在需要實時獲取資訊、保持記憶並迅速做出反應的複雜環境下，如何平衡「思考」和「行動」成為了關鍵挑戰。這也是本研究想要深入探討並解決的問題。

研究者們採用了一套嚴謹的方法，選擇現實世界的軟體工程任務作為實驗框架，並使用 SWE-bench Verified 基准以及OpenHands框架內的CodeActAgent架構，創建了一個受控環境。在該環境中，推理模型必須在資訊收集和推理鏈之間找到平衡點，並在多次交互中保持上下文信息。 然而，過度延伸的內部推理鏈可能導致模型對環境做出錯誤假設，進而影響任務完成。

研究觀察到，模型在面臨推理-行動困境時，傾向於內部模擬而非與環境交互，即花費大量時間和精力在內部構建複雜的預測行動鏈，卻不願花時間去適應實際的系統響應，這種現象被稱為「过度思考」。

為了量化分析「过度思考」過程，研究者們利用 LLM-as-a-judge 方法開發並驗證了一個系統評估框架。該框架揭示了大型推理模型「过度思考」的三種關鍵模式：

1.  **分析癱瘓（Analysis Paralysis）：** Agent 花費過多時間規劃未來步驟，始終無法採取行動，導致無法在環境中取得任何實質性進展。
2.  **恶意行为（Rogue Actions）：** Agent 遇到錯誤時，試圖同時執行多個動作，破壞環境的順序約束，非但無法解決問題，反而可能使情況更糟。
3.  **过早放弃（Premature Disengagement）：** Agent 僅基於對問題空間的內部模擬，就決定終止任務，而非根據實際的環境反饋做出決策，不利於任務完成。

透過此評估框架，研究者發現，推理模型的「过度思考」得分明顯高於非推理模型，顯示其更容易受到影響。

實驗和分析顯示，「过度思考」與模型性能之間存在強烈的負相關關係。無論是推理模型還是非推理模型，隨著「过度思考」程度的增加，解決問題的性能都會下降。此外，在不同類型的模型中，「过度思考」的表現也有所不同，非推理模型由於缺乏專門的推理訓練，在處理推理鏈時的能力有限，因此「过度思考」的影響更為嚴重。

研究還發現，模型規模與「过度思考」行為之間存在負相關關係。較小的模型由於在理解複雜環境方面存在困難，更為依賴內部推理鏈，從而增加了「过度思考」的傾向。在Token使用方面，增加Token分配可能會減少Agent上下文中的过度思考，而非像之前的一些研究認為的那樣，推理token使用量的增加会导致过度思考。 在上下文窗口方面，研究者们推测，过度思考行为更多地是受到模型的架构设计和训练方法的影响，而不是模型的上下文能力。

針對大型推理模型的「过度思考」現象，研究者們提出了原生函數調用和選擇性強化學習兩種潛在的緩解方法，這兩種方法都能顯著減少模型的「过度思考」，同時提高模型的性能。

解決大型推理模型的「过度思考」問題能夠帶來巨大的經濟效益。例如，通過合理運用原生函數調用，模型可以更高效地利用已有的資源，避免過度的內部推理，降低計算成本。

總而言之，這項研究揭示了推理模型在執行 Agentic 任務時所面臨的「推理-行動」困境，以及「过度思考」對模型性能的負面影響。研究者們提出的緩解方法為我們提供了有效的解決方案，不僅可以減少「过度思考」，還能提高模型性能，降低計算成本。 隨著技術的進步，推理模型必將在更多領域發揮重要作用，期許未來能看到更多相關的研究成果。感謝各位的觀看，我們下期再見。

[model=gemini-2.0-flash,0]


---

</details>

<details>
<summary>581. 【人工智能】HuggingFace发布LLM超大规模实战手册 | 200页报告解读 | 4000个Scaling实验 | 激活值重计算 | 梯度累积 | 数据并行 | 张量和序列并行 | 流水线并行</summary><br>

<a href="https://www.youtube.com/watch?v=MmQycrDLZ3U" target="_blank">
    <img src="https://img.youtube.com/vi/MmQycrDLZ3U/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】HuggingFace发布LLM超大规模实战手册 | 200页报告解读 | 4000个Scaling实验 | 激活值重计算 | 梯度累积 | 数据并行 | 张量和序列并行 | 流水线并行



---

</details>

<details>
<summary>580. 【人工智能】DeepSeek开源周六天内容全盘点 | FlashMLA | DeepEP | DeepGEMM | DualPipe | EPLB | 3FS文件系统 | V3/R1成本大揭秘</summary><br>

<a href="https://www.youtube.com/watch?v=deZjgTAkzoc" target="_blank">
    <img src="https://img.youtube.com/vi/deZjgTAkzoc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】DeepSeek开源周六天内容全盘点 | FlashMLA | DeepEP | DeepGEMM | DualPipe | EPLB | 3FS文件系统 | V3/R1成本大揭秘



---

</details>

<details>
<summary>579. 【商业】英伟达史上业绩最佳财报发布 | 股价不涨反跌 | 2024年营收1300亿美元 | 净利润740亿美元 | 数据中心 | 游戏和AI PC | Blackwell需求猛增 | 竞争对手</summary><br>

<a href="https://www.youtube.com/watch?v=KSL1xydvwOE" target="_blank">
    <img src="https://img.youtube.com/vi/KSL1xydvwOE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】英伟达史上业绩最佳财报发布 | 股价不涨反跌 | 2024年营收1300亿美元 | 净利润740亿美元 | 数据中心 | 游戏和AI PC | Blackwell需求猛增 | 竞争对手



---

</details>

<details>
<summary>578. 【数字货币】全球第二大交易所Bybit被盗超过14亿美元代币 | 史上最大代币盗窃事件 | 背后惊现朝鲜国家黑客组织 | Lazarus Group | 冷钱包 | 社会工程学 | 新型恶意软件</summary><br>

<a href="https://www.youtube.com/watch?v=bhrztPMHeKA" target="_blank">
    <img src="https://img.youtube.com/vi/bhrztPMHeKA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【数字货币】全球第二大交易所Bybit被盗超过14亿美元代币 | 史上最大代币盗窃事件 | 背后惊现朝鲜国家黑客组织 | Lazarus Group | 冷钱包 | 社会工程学 | 新型恶意软件



---

</details>

<details>
<summary>577. 【访谈】Snowflake CEO 斯里达尔·拉马斯瓦米20VC访谈 | 如何面对AI挑战 | 软件工程 | 职场管理 | AI竞争 | OpenAI | Databricks | AI泡沫</summary><br>

<a href="https://www.youtube.com/watch?v=3-2-w7bPqtk" target="_blank">
    <img src="https://img.youtube.com/vi/3-2-w7bPqtk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【访谈】Snowflake CEO 斯里达尔·拉马斯瓦米20VC访谈 | 如何面对AI挑战 | 软件工程 | 职场管理 | AI竞争 | OpenAI | Databricks | AI泡沫



---

</details>

<details>
<summary>576. 【商业】Ai Pin已死 | 人工智能硬件公司Humane | HP十分之一价格收购 | 奥特曼投资 | 从满怀期望到全民批评 | 使用及硬件缺陷 | 价格高昂 | Cosmos | 电子砖头</summary><br>

<a href="https://www.youtube.com/watch?v=lqsP4N0inoU" target="_blank">
    <img src="https://img.youtube.com/vi/lqsP4N0inoU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】Ai Pin已死 | 人工智能硬件公司Humane | HP十分之一价格收购 | 奥特曼投资 | 从满怀期望到全民批评 | 使用及硬件缺陷 | 价格高昂 | Cosmos | 电子砖头



---

</details>

<details>
<summary>575. 【人工智能】Claude 3.7 Sonnet发布 | 全球首个混合推理模型 | 一个模型两种思考方式 | Claude Code | 编程能力大幅提升 | 价格与前代持平</summary><br>

<a href="https://www.youtube.com/watch?v=NF_Go55lXj8" target="_blank">
    <img src="https://img.youtube.com/vi/NF_Go55lXj8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Claude 3.7 Sonnet发布 | 全球首个混合推理模型 | 一个模型两种思考方式 | Claude Code | 编程能力大幅提升 | 价格与前代持平



---

</details>

<details>
<summary>574. 【人工智能】FigureAI推出Helix模型 | 通用视觉语言动作VLA | 双机器人协作 | 语音指令 | 全上半身灵活操控 | 强大物体泛化 | S2+S1双系统 | 流式推理 | 家务劳动</summary><br>

<a href="https://www.youtube.com/watch?v=3PhOOFilsiY" target="_blank">
    <img src="https://img.youtube.com/vi/3PhOOFilsiY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】FigureAI推出Helix模型 | 通用视觉语言动作VLA | 双机器人协作 | 语音指令 | 全上半身灵活操控 | 强大物体泛化 | S2+S1双系统 | 流式推理 | 家务劳动



---

</details>

<details>
<summary>573. 【分享】两万字深度解密DeepSeek-R1、Kimi 1.5，强推理模型凭什么火出圈 | 北大AI对齐团队 | 超清版</summary><br>

<a href="https://www.youtube.com/watch?v=DkzNbv8ioWk" target="_blank">
    <img src="https://img.youtube.com/vi/DkzNbv8ioWk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【分享】两万字深度解密DeepSeek-R1、Kimi 1.5，强推理模型凭什么火出圈 | 北大AI对齐团队 | 超清版



---

</details>

<details>
<summary>572. 【科学】“移动沙发难题”或被解决 | 直角可搬沙发的最大面积是多少 | 困扰数学家近60年 | 电话型沙发 | 约瑟夫格弗 | 乔丹曲线 | 格林定理 | Jineon Baek | 119页论文</summary><br>

<a href="https://www.youtube.com/watch?v=1PYwiJjZ8J8" target="_blank">
    <img src="https://img.youtube.com/vi/1PYwiJjZ8J8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【科学】“移动沙发难题”或被解决 | 直角可搬沙发的最大面积是多少 | 困扰数学家近60年 | 电话型沙发 | 约瑟夫格弗 | 乔丹曲线 | 格林定理 | Jineon Baek | 119页论文



---

</details>

<details>
<summary>571. 【商业】昔日芯片霸主英特尔将被拆分？ | 博通 | 台积电 | 经营困境 | 出售Altera | 帕特基辛格 | IDM模式是否还能继续 | 530亿美元芯片补助 | 特朗普政府 | 前途难料</summary><br>

<a href="https://www.youtube.com/watch?v=jgSThv4SDQw" target="_blank">
    <img src="https://img.youtube.com/vi/jgSThv4SDQw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】昔日芯片霸主英特尔将被拆分？ | 博通 | 台积电 | 经营困境 | 出售Altera | 帕特基辛格 | IDM模式是否还能继续 | 530亿美元芯片补助 | 特朗普政府 | 前途难料



---

</details>

<details>
<summary>570. 【人工智能】OpenAI发布最新代码基准测试SWE-Lancer | 价值百万美元 | Upwork | IC SWE | SWE Manager | 端到端测试 | 用户工具 | Claude最高</summary><br>

<a href="https://www.youtube.com/watch?v=baaBsehnpR8" target="_blank">
    <img src="https://img.youtube.com/vi/baaBsehnpR8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OpenAI发布最新代码基准测试SWE-Lancer | 价值百万美元 | Upwork | IC SWE | SWE Manager | 端到端测试 | 用户工具 | Claude最高



---

</details>

<details>
<summary>569. 【人物】芯片「硅仙人」Jim Keller的传奇人生 | 家庭环境 | 大学成长 | 早期公司 | AMD | 博通 | Apple | Intel | Tesla | Tenstorrent</summary><br>

<a href="https://www.youtube.com/watch?v=QCA1mQXzWUo" target="_blank">
    <img src="https://img.youtube.com/vi/QCA1mQXzWUo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】芯片「硅仙人」Jim Keller的传奇人生 | 家庭环境 | 大学成长 | 早期公司 | AMD | 博通 | Apple | Intel | Tesla | Tenstorrent



---

</details>

<details>
<summary>568. 【人工智能】Grok 3/Grok 3 mini发布 | 史上最聪明的AI |  20 万卡集群训练 | 整合推理能力 | DeepSearch | Arena首次突破1400分 | GPT-4.5</summary><br>

<a href="https://www.youtube.com/watch?v=ugNn-2dgwqg" target="_blank">
    <img src="https://img.youtube.com/vi/ugNn-2dgwqg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Grok 3/Grok 3 mini发布 | 史上最聪明的AI |  20 万卡集群训练 | 整合推理能力 | DeepSearch | Arena首次突破1400分 | GPT-4.5



---

</details>

<details>
<summary>567. 【人工智能】DeepSeek再发新研究成果NSA | 原生稀疏注意力机制 | 梁文锋参与 | 超快长上下文训练 | 十倍速度提升 | 动态分层 | 粗粒度压缩 | 细粒度选择 | 滑动窗口</summary><br>

<a href="https://www.youtube.com/watch?v=V-1_xPMVIaw" target="_blank">
    <img src="https://img.youtube.com/vi/V-1_xPMVIaw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】DeepSeek再发新研究成果NSA | 原生稀疏注意力机制 | 梁文锋参与 | 超快长上下文训练 | 十倍速度提升 | 动态分层 | 粗粒度压缩 | 细粒度选择 | 滑动窗口



---

</details>

<details>
<summary>566. 【人工智能】全球机器学习硬件报告 | Epoch AI | 140款AI加速器 | 计算性能每年增长43% | 低精度计算 | 能效每两年翻一番 | 英伟达全球算力相当于400万块H100</summary><br>

<a href="https://www.youtube.com/watch?v=4S8ajqFZbss" target="_blank">
    <img src="https://img.youtube.com/vi/4S8ajqFZbss/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】全球机器学习硬件报告 | Epoch AI | 140款AI加速器 | 计算性能每年增长43% | 低精度计算 | 能效每两年翻一番 | 英伟达全球算力相当于400万块H100



---

</details>

<details>
<summary>565. 【闲聊】AI时代还要再学习编程吗？| 软件开发职位暴降 | 计算机专业毕业人数上涨 | 毕业即失业 | AI大佬发出警告 | AI应用导致裁员 | 工作被AI取代 | 成本回避 | 未来的必然</summary><br>

<a href="https://www.youtube.com/watch?v=Foq1q-RDn3c" target="_blank">
    <img src="https://img.youtube.com/vi/Foq1q-RDn3c/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【闲聊】AI时代还要再学习编程吗？| 软件开发职位暴降 | 计算机专业毕业人数上涨 | 毕业即失业 | AI大佬发出警告 | AI应用导致裁员 | 工作被AI取代 | 成本回避 | 未来的必然



---

</details>

<details>
<summary>564. 【对谈】谷歌的AGI计划 | Jeff Dean和Noam Shazeer最新访谈 | 回忆入职谷歌 | 摩尔定律 | 学术生涯 | n-gram | MoE | AI编程 | 开放成果 | 展望未来</summary><br>

<a href="https://www.youtube.com/watch?v=kNVnr1BMpKU" target="_blank">
    <img src="https://img.youtube.com/vi/kNVnr1BMpKU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【对谈】谷歌的AGI计划 | Jeff Dean和Noam Shazeer最新访谈 | 回忆入职谷歌 | 摩尔定律 | 学术生涯 | n-gram | MoE | AI编程 | 开放成果 | 展望未来



---

</details>

<details>
<summary>563. 【人工智能】人工智能的安全治理 | 李飞飞巴黎AI峰会开幕演讲 | AI的历史 | 多学科交叉 | 感知算法 | 认知科学 | 计算能力 | 空间和具身智能 | 以人为本的AI | AI治理</summary><br>

<a href="https://www.youtube.com/watch?v=Yv5_Q0zDN9I" target="_blank">
    <img src="https://img.youtube.com/vi/Yv5_Q0zDN9I/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】人工智能的安全治理 | 李飞飞巴黎AI峰会开幕演讲 | AI的历史 | 多学科交叉 | 感知算法 | 认知科学 | 计算能力 | 空间和具身智能 | 以人为本的AI | AI治理



---

</details>

<details>
<summary>562. 【访谈】蔡崇信谈阿里巴巴创业、DeepSeek、与苹果合作 | 迪拜世界政府峰会对谈 | 马云创业 | 生存与创新 | AI和DeepSeek | 小模型的未来 | 苹果合作 | 体育领域投资</summary><br>

<a href="https://www.youtube.com/watch?v=NcKQ4S9tYsA" target="_blank">
    <img src="https://img.youtube.com/vi/NcKQ4S9tYsA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【访谈】蔡崇信谈阿里巴巴创业、DeepSeek、与苹果合作 | 迪拜世界政府峰会对谈 | 马云创业 | 生存与创新 | AI和DeepSeek | 小模型的未来 | 苹果合作 | 体育领域投资



---

</details>

<details>
<summary>561. 【OpenAI】Sam Altman透露GPT-4.5和GPT 5计划 | 最后的非思维链模型 | o3将被整合 | Deep Research免费计划 | 全新的模型规范Model Spec</summary><br>

<a href="https://www.youtube.com/watch?v=XJkr0tuZFMs" target="_blank">
    <img src="https://img.youtube.com/vi/XJkr0tuZFMs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【OpenAI】Sam Altman透露GPT-4.5和GPT 5计划 | 最后的非思维链模型 | o3将被整合 | Deep Research免费计划 | 全新的模型规范Model Spec



---

</details>

<details>
<summary>560. 【人工智能】巴黎AI行动峰会争夺全球AI主导权 | 欧盟2000亿欧投资 | 法国星际之门 | 美国万斯直怼欧盟 | DeepSeek成热点 | 美英放弃签署巴黎AI宣言 | 全球AI治理将多方博弈</summary><br>

<a href="https://www.youtube.com/watch?v=2eZBSU3sqVE" target="_blank">
    <img src="https://img.youtube.com/vi/2eZBSU3sqVE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】巴黎AI行动峰会争夺全球AI主导权 | 欧盟2000亿欧投资 | 法国星际之门 | 美国万斯直怼欧盟 | DeepSeek成热点 | 美英放弃签署巴黎AI宣言 | 全球AI治理将多方博弈



---

</details>

<details>
<summary>559. 【商业】智能驾驶明星企业纵目科技暴雷 | CEO失联 | 高管卷钱跑路 | 700名员工被欠薪 | 假意安抚 | 政府化解缓慢 | 如何维权</summary><br>

<a href="https://www.youtube.com/watch?v=xXcX4b6-cq8" target="_blank">
    <img src="https://img.youtube.com/vi/xXcX4b6-cq8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】智能驾驶明星企业纵目科技暴雷 | CEO失联 | 高管卷钱跑路 | 700名员工被欠薪 | 假意安抚 | 政府化解缓慢 | 如何维权



---

</details>

<details>
<summary>558. 【数据结构】哈希表Hash Table算法获重大突破 | 本科生推翻图灵奖得主姚期智40年前猜想 | 均匀哈希 | 弹性哈希 | 漏斗哈希 | 最坏探测复杂度</summary><br>

<a href="https://www.youtube.com/watch?v=bCX7bCngTqQ" target="_blank">
    <img src="https://img.youtube.com/vi/bCX7bCngTqQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【数据结构】哈希表Hash Table算法获重大突破 | 本科生推翻图灵奖得主姚期智40年前猜想 | 均匀哈希 | 弹性哈希 | 漏斗哈希 | 最坏探测复杂度



---

</details>

<details>
<summary>557. 【人工智能】DeepMind发布Alpha Geometry 2 | 攻克国际数学奥林匹克竞赛IMO几何难题 | 超越金牌得主水平 | 新的语言模型和搜索算法 | 性能显著提升 | AlphaGo时刻</summary><br>

<a href="https://www.youtube.com/watch?v=FYrL4b_yecc" target="_blank">
    <img src="https://img.youtube.com/vi/FYrL4b_yecc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】DeepMind发布Alpha Geometry 2 | 攻克国际数学奥林匹克竞赛IMO几何难题 | 超越金牌得主水平 | 新的语言模型和搜索算法 | 性能显著提升 | AlphaGo时刻



---

</details>

<details>
<summary>556. 【AI News】关于AI经济学的三点观察 | OpenAI CEO Sam Altman最新博客文章</summary><br>

<a href="https://www.youtube.com/watch?v=H8-0blZjkw8" target="_blank">
    <img src="https://img.youtube.com/vi/H8-0blZjkw8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【AI News】关于AI经济学的三点观察 | OpenAI CEO Sam Altman最新博客文章



---

</details>

<details>
<summary>555. 【人工智能】深入浅出ChatGPT大语言模型 | Andrej Karpathy | 三小时视频预习版 | 预训练 | 后训练 | 分词 | Transformer | 强化学习 | RLHF</summary><br>

<a href="https://www.youtube.com/watch?v=56waReTN1_w" target="_blank">
    <img src="https://img.youtube.com/vi/56waReTN1_w/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】深入浅出ChatGPT大语言模型 | Andrej Karpathy | 三小时视频预习版 | 预训练 | 后训练 | 分词 | Transformer | 强化学习 | RLHF



---

</details>

<details>
<summary>554. 【人工智能】资本、AGI与人类野心 | 鲁道夫·莱纳 | AGI时代权利将更为固化 | 更容易购买劳动成果 | 原始资本积累很难创造奇迹 | 劳动力替代型AI | AI取代人才 | 国家不再关心民众</summary><br>

<a href="https://www.youtube.com/watch?v=4-CuksybdoM" target="_blank">
    <img src="https://img.youtube.com/vi/4-CuksybdoM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】资本、AGI与人类野心 | 鲁道夫·莱纳 | AGI时代权利将更为固化 | 更容易购买劳动成果 | 原始资本积累很难创造奇迹 | 劳动力替代型AI | AI取代人才 | 国家不再关心民众



---

</details>

<details>
<summary>553. 【人工智能】澄清DeepSeek五大网络误解 | 颠覆式创新 | 蒸馏和抄袭 | 成本550万美元 | AI巨头投入浪费 | PTX打破CUDA垄断 | 国外被封禁</summary><br>

<a href="https://www.youtube.com/watch?v=7bgNqPryj0I" target="_blank">
    <img src="https://img.youtube.com/vi/7bgNqPryj0I/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】澄清DeepSeek五大网络误解 | 颠覆式创新 | 蒸馏和抄袭 | 成本550万美元 | AI巨头投入浪费 | PTX打破CUDA垄断 | 国外被封禁



---

</details>

<details>
<summary>552. 【实战】三分钟教你如何在电脑本地运行DeepSeek R1 | macOS M1 | ollama | Cherry Studio</summary><br>

<a href="https://www.youtube.com/watch?v=ZHm9IJQig4c" target="_blank">
    <img src="https://img.youtube.com/vi/ZHm9IJQig4c/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【实战】三分钟教你如何在电脑本地运行DeepSeek R1 | macOS M1 | ollama | Cherry Studio



---

</details>

<details>
<summary>551. 【商业】爆肝两万字解读 Big Ideas 2025 | ARK方舟基金 | AI Agent | 比特币 | 区块链 | 无人驾驶出租 | 自主物流 | 能源 | 机器人 | 可重用火箭 | 多组学</summary><br>

<a href="https://www.youtube.com/watch?v=EqLBkmFr3Co" target="_blank">
    <img src="https://img.youtube.com/vi/EqLBkmFr3Co/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】爆肝两万字解读 Big Ideas 2025 | ARK方舟基金 | AI Agent | 比特币 | 区块链 | 无人驾驶出租 | 自主物流 | 能源 | 机器人 | 可重用火箭 | 多组学



---

</details>

<details>
<summary>550. 【访谈】台积电往事 | 张忠谋最新深度访谈 | 黄仁勋结缘 | 40纳米问题 | 裁员风波 | 蔡力行 | 重回CEO | 投入28纳米 | 苹果合作 | 高盛借款 | 三星 | 英特尔 | 高通</summary><br>

<a href="https://www.youtube.com/watch?v=XgIoOKX16w0" target="_blank">
    <img src="https://img.youtube.com/vi/XgIoOKX16w0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【访谈】台积电往事 | 张忠谋最新深度访谈 | 黄仁勋结缘 | 40纳米问题 | 裁员风波 | 蔡力行 | 重回CEO | 投入28纳米 | 苹果合作 | 高盛借款 | 三星 | 英特尔 | 高通



---

</details>

<details>
<summary>549. 【访谈】Lex Fridman最新五小时访谈精华版 | DeepSeek | 后训练 | 开放权重 | 技术改进 | YOLO Run | AGI | 注意力 | 英伟达 | 数据中心 | Agent</summary><br>

<a href="https://www.youtube.com/watch?v=RbGX-FQNYQ0" target="_blank">
    <img src="https://img.youtube.com/vi/RbGX-FQNYQ0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【访谈】Lex Fridman最新五小时访谈精华版 | DeepSeek | 后训练 | 开放权重 | 技术改进 | YOLO Run | AGI | 注意力 | 英伟达 | 数据中心 | Agent



---

</details>

<details>
<summary>548. 【人工智能】模型压缩四大方法概述 | 量化、剪枝、蒸馏和二值化 | 模型瘦身 |  降低精度 | 速度提升 | 知识蒸馏 | 温度参数 | XNOR | 优缺点 | 发展方向</summary><br>

<a href="https://www.youtube.com/watch?v=jW2cmZ-9hLk" target="_blank">
    <img src="https://img.youtube.com/vi/jW2cmZ-9hLk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】模型压缩四大方法概述 | 量化、剪枝、蒸馏和二值化 | 模型瘦身 |  降低精度 | 速度提升 | 知识蒸馏 | 温度参数 | XNOR | 优缺点 | 发展方向



---

</details>

<details>
<summary>547. 【人工智能】OpenAI紧急推出o3-mini对抗DeepSeek R1 | 轻量级推理SOTA | 免费可用 | 价格没优势 | Sam Altman回答网友提问 | 首次承认闭源策略错误</summary><br>

<a href="https://www.youtube.com/watch?v=nFmsilrS3uo" target="_blank">
    <img src="https://img.youtube.com/vi/nFmsilrS3uo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OpenAI紧急推出o3-mini对抗DeepSeek R1 | 轻量级推理SOTA | 免费可用 | 价格没优势 | Sam Altman回答网友提问 | 首次承认闭源策略错误



---

</details>

<details>
<summary>546. 【人工智能】DeepSeek到底花了多少钱 | SemiAnalysis深度报道 | 幻方量化 | 5万个GPU | 600万训练成本 | 员工薪资近千万 | 蒸馏数据 | 利润率 | 杰文斯悖论</summary><br>

<a href="https://www.youtube.com/watch?v=BStuhyrmJnI" target="_blank">
    <img src="https://img.youtube.com/vi/BStuhyrmJnI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】DeepSeek到底花了多少钱 | SemiAnalysis深度报道 | 幻方量化 | 5万个GPU | 600万训练成本 | 员工薪资近千万 | 蒸馏数据 | 利润率 | 杰文斯悖论



---

</details>

<details>
<summary>545. 【人工智能】人工智能与世界格局 | 桥水创始人Ray Dalio最新访谈 | AI成功的关键 | 人机协同 | Digital Ray | 影响世界格局的五大力量 | 投资 | 团队文化 | 比特币</summary><br>

<a href="https://www.youtube.com/watch?v=xPl5g1Cq_TY" target="_blank">
    <img src="https://img.youtube.com/vi/xPl5g1Cq_TY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】人工智能与世界格局 | 桥水创始人Ray Dalio最新访谈 | AI成功的关键 | 人机协同 | Digital Ray | 影响世界格局的五大力量 | 投资 | 团队文化 | 比特币



---

</details>

<details>
<summary>544. 【人工智能】OpenAI指责DeepSeek不正当使用数据 |  DeepSeek火爆引发风波 | 大模型蒸馏 | 美AI专家反对 | 意大利下架 | Anthropic CEO万字檄文</summary><br>

<a href="https://www.youtube.com/watch?v=4iq_s7501XU" target="_blank">
    <img src="https://img.youtube.com/vi/4iq_s7501XU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OpenAI指责DeepSeek不正当使用数据 |  DeepSeek火爆引发风波 | 大模型蒸馏 | 美AI专家反对 | 意大利下架 | Anthropic CEO万字檄文



---

</details>

<details>
<summary>543. 【分享】关于GPT-5的谣言改变了一切 | Alberto Romero | Claude Opus 3.5 | 不发布先进模型 | 蒸馏小模型 | 过训练 | 经济价值 | AGI协议</summary><br>

<a href="https://www.youtube.com/watch?v=IPUo6OHByC0" target="_blank">
    <img src="https://img.youtube.com/vi/IPUo6OHByC0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【分享】关于GPT-5的谣言改变了一切 | Alberto Romero | Claude Opus 3.5 | 不发布先进模型 | 蒸馏小模型 | 过训练 | 经济价值 | AGI协议



---

</details>

<details>
<summary>542. 【新春快乐】DeepSeek开源多模态模型Janus Pro/JanusFlow | 双头雅努斯 | 多模态大一统 | 1.5B/7B参数SOTA | 理解和生成双编码器 | 三阶段训练</summary><br>

<a href="https://www.youtube.com/watch?v=cpl9zHTLJqU" target="_blank">
    <img src="https://img.youtube.com/vi/cpl9zHTLJqU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【新春快乐】DeepSeek开源多模态模型Janus Pro/JanusFlow | 双头雅努斯 | 多模态大一统 | 1.5B/7B参数SOTA | 理解和生成双编码器 | 三阶段训练



---

</details>

<details>
<summary>541. 【人工智能】通往AGI的路径 | 3-5年实现AGI | DeepMind CEO、诺奖得主德米斯·哈萨比斯 | 三层创造力模型 | AI带来科学突破 | 安全风险 | 欺骗行为 | Agent兴起</summary><br>

<a href="https://www.youtube.com/watch?v=E2R8xzU46Hs" target="_blank">
    <img src="https://img.youtube.com/vi/E2R8xzU46Hs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】通往AGI的路径 | 3-5年实现AGI | DeepMind CEO、诺奖得主德米斯·哈萨比斯 | 三层创造力模型 | AI带来科学突破 | 安全风险 | 欺骗行为 | Agent兴起



---

</details>

<details>
<summary>540. 【人工智能】DeepSeek R1引发全球开源复现热潮 | HuggingFace Open R1 | TinyZero | simpleRL-reason | AI霸权 | 斯普特尼克时刻</summary><br>

<a href="https://www.youtube.com/watch?v=O5LEgWmxMlI" target="_blank">
    <img src="https://img.youtube.com/vi/O5LEgWmxMlI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】DeepSeek R1引发全球开源复现热潮 | HuggingFace Open R1 | TinyZero | simpleRL-reason | AI霸权 | 斯普特尼克时刻



---

</details>

<details>
<summary>539. 【闲聊】智能的诅咒 | AGI时代的人类危机 | 寡头势力不再投资人类 | AI实验室成为新食利者 | 计算资源价值提升 | 普通人的命运 | 国际竞争 | 集体否认文化 | 意图对齐 | 如何破解</summary><br>

<a href="https://www.youtube.com/watch?v=a_Go_0DN-Ko" target="_blank">
    <img src="https://img.youtube.com/vi/a_Go_0DN-Ko/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【闲聊】智能的诅咒 | AGI时代的人类危机 | 寡头势力不再投资人类 | AI实验室成为新食利者 | 计算资源价值提升 | 普通人的命运 | 国际竞争 | 集体否认文化 | 意图对齐 | 如何破解



---

</details>

<details>
<summary>538. 【商业】星际之门到底靠不靠谱 | Stargate | 预计投资5000亿美元 | OpenAI | 软银 | MGX | Oracle | 马斯克质疑 | 奥特曼手段 | 微软失利 | AI里程碑</summary><br>

<a href="https://www.youtube.com/watch?v=Ww3HnOkf-_I" target="_blank">
    <img src="https://img.youtube.com/vi/Ww3HnOkf-_I/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】星际之门到底靠不靠谱 | Stargate | 预计投资5000亿美元 | OpenAI | 软银 | MGX | Oracle | 马斯克质疑 | 奥特曼手段 | 微软失利 | AI里程碑



---

</details>

<details>
<summary>537. 【人物】梁文锋 | 深度求索DeepSeek创始人 | 幻方量化基金 | 六年千亿私募 | 业绩波动 | 萤火一号 | 万卡集群 | 西蒙斯 | 慈善捐款 | 139人本土团队 | 自有资金</summary><br>

<a href="https://www.youtube.com/watch?v=ftor8VCefSE" target="_blank">
    <img src="https://img.youtube.com/vi/ftor8VCefSE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人物】梁文锋 | 深度求索DeepSeek创始人 | 幻方量化基金 | 六年千亿私募 | 业绩波动 | 萤火一号 | 万卡集群 | 西蒙斯 | 慈善捐款 | 139人本土团队 | 自有资金



---

</details>

<details>
<summary>536. 【推广】AI多语言学习软件Galaxy | 语言爱好者的福音 | 联合创始人Sylvie | Z世代群体主力 | 多元的互动形式 | 沉浸式场景体验 | 方言学习特色 | 限时半价优惠</summary><br>

<a href="https://www.youtube.com/watch?v=Dv13KQrnIgA" target="_blank">
    <img src="https://img.youtube.com/vi/Dv13KQrnIgA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【推广】AI多语言学习软件Galaxy | 语言爱好者的福音 | 联合创始人Sylvie | Z世代群体主力 | 多元的互动形式 | 沉浸式场景体验 | 方言学习特色 | 限时半价优惠



---

</details>

<details>
<summary>535. 【人工智能】“AI教父”辛顿为何担忧AI的未来 | 最新播客专访 | AI发展速度远超人类控制 | 欺骗人类 | 主观体验 | 智能和理性 | AI监管 | 快速权重调整 | 个人经历 | 中美对比</summary><br>

<a href="https://www.youtube.com/watch?v=H4vRwhbK6dw" target="_blank">
    <img src="https://img.youtube.com/vi/H4vRwhbK6dw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】“AI教父”辛顿为何担忧AI的未来 | 最新播客专访 | AI发展速度远超人类控制 | 欺骗人类 | 主观体验 | 智能和理性 | AI监管 | 快速权重调整 | 个人经历 | 中美对比



---

</details>

<details>
<summary>534. 【人工智能】Minimax推出最新基础模型01系列 | Text-01 | VL-01 | 首次大规模线性注意力 | 400万token上下文窗口 | 闪电注意力 | MoE | 助力Agent应用</summary><br>

<a href="https://www.youtube.com/watch?v=sCiKE3QGSNE" target="_blank">
    <img src="https://img.youtube.com/vi/sCiKE3QGSNE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Minimax推出最新基础模型01系列 | Text-01 | VL-01 | 首次大规模线性注意力 | 400万token上下文窗口 | 闪电注意力 | MoE | 助力Agent应用



---

</details>

<details>
<summary>533. 【人工智能】DeepSeek开源推理模型R1 | R1-Zero | 蒸馏小模型 | 绕过监督微调直接强化学习 | 媲美o1 | 顿悟时刻 |  GRPO | 奖励设计 | 冷启动 | 再现价格屠夫</summary><br>

<a href="https://www.youtube.com/watch?v=3_yxnYzt-d4" target="_blank">
    <img src="https://img.youtube.com/vi/3_yxnYzt-d4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】DeepSeek开源推理模型R1 | R1-Zero | 蒸馏小模型 | 绕过监督微调直接强化学习 | 媲美o1 | 顿悟时刻 |  GRPO | 奖励设计 | 冷启动 | 再现价格屠夫



---

</details>

<details>
<summary>532. 【人工智能】OpenAI o3数学测试涉嫌造假引众怒？| 资助Epoch AI | 提前获数据访问权限 | FrontierMath突破性得分 | 合同保密要求 | 盈利压力巨大 | 模型评测还可信么</summary><br>

<a href="https://www.youtube.com/watch?v=DGnArhv5QOk" target="_blank">
    <img src="https://img.youtube.com/vi/DGnArhv5QOk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OpenAI o3数学测试涉嫌造假引众怒？| 资助Epoch AI | 提前获数据访问权限 | FrontierMath突破性得分 | 合同保密要求 | 盈利压力巨大 | 模型评测还可信么



---

</details>

<details>
<summary>531. 【人工智能】Keras之父弗朗索瓦·肖莱辞职创业Ndea | 基于深度学习的程序合成 | 联创迈克·努普 | ARC-AGI基准测试 | Zapier | 程序自动构造 | 智能的测量 | AGI</summary><br>

<a href="https://www.youtube.com/watch?v=H8eFfDyRXqU" target="_blank">
    <img src="https://img.youtube.com/vi/H8eFfDyRXqU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Keras之父弗朗索瓦·肖莱辞职创业Ndea | 基于深度学习的程序合成 | 联创迈克·努普 | ARC-AGI基准测试 | Zapier | 程序自动构造 | 智能的测量 | AGI



---

</details>

<details>
<summary>530. 【人工智能】谷歌提出新架构Titans | Transformer会被终结么 | 神经长期记忆模块 | 长序列处理 | 惊讶度 | 衰减机制 | 架构的三种变体 | 如何遗忘 | 性能超越基准测试</summary><br>

<a href="https://www.youtube.com/watch?v=hKCs2Zt27xI" target="_blank">
    <img src="https://img.youtube.com/vi/hKCs2Zt27xI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】谷歌提出新架构Titans | Transformer会被终结么 | 神经长期记忆模块 | 长序列处理 | 惊讶度 | 衰减机制 | 架构的三种变体 | 如何遗忘 | 性能超越基准测试



---

</details>

<details>
<summary>529. 【科学】人类一生的知识上限不到4GB | 加州理工最新论文 | 大脑每秒10比特 | 神经系统速度100倍 | 并行和串行 | 心理不应期 | 历史演化 | 记忆 | 脑机接口 | AI终将超越人类</summary><br>

<a href="https://www.youtube.com/watch?v=Ur5APLuM_mA" target="_blank">
    <img src="https://img.youtube.com/vi/Ur5APLuM_mA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【科学】人类一生的知识上限不到4GB | 加州理工最新论文 | 大脑每秒10比特 | 神经系统速度100倍 | 并行和串行 | 心理不应期 | 历史演化 | 记忆 | 脑机接口 | AI终将超越人类



---

</details>

<details>
<summary>528. 【访谈】炮轰拜登政府干预舆论，苹果自乔布斯去世后20年无创新 | Meta CEO 扎克伯格 | 内容审查 | 政府威胁 | 言论自由 | 苹果压榨开发者 | VR/AR | 手部腕带 | 开放标准</summary><br>

<a href="https://www.youtube.com/watch?v=kZfJvwaxoOk" target="_blank">
    <img src="https://img.youtube.com/vi/kZfJvwaxoOk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【访谈】炮轰拜登政府干预舆论，苹果自乔布斯去世后20年无创新 | Meta CEO 扎克伯格 | 内容审查 | 政府威胁 | 言论自由 | 苹果压榨开发者 | VR/AR | 手部腕带 | 开放标准



---

</details>

<details>
<summary>527. 【商业】Palantir究竟是一家怎样的公司 | 数据融合与情报分析 | 本·拉登 | 战争与和平 | CIA扶持 | 彼得·蒂尔 | 主要产品 | 商业模式 | 国际争端 | 社会争议</summary><br>

<a href="https://www.youtube.com/watch?v=rBNyr6QXsqQ" target="_blank">
    <img src="https://img.youtube.com/vi/rBNyr6QXsqQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】Palantir究竟是一家怎样的公司 | 数据融合与情报分析 | 本·拉登 | 战争与和平 | CIA扶持 | 彼得·蒂尔 | 主要产品 | 商业模式 | 国际争端 | 社会争议



---

</details>

<details>
<summary>526. 【人工智能】美国全球AI禁令再升级 | AI扩散出口管制框架 | 国家分成三组 | 每年5W块GPU配额 | 24国禁运GPU | 封堵中国三方和走私途径 | UVEU许可 | 闭源AI模型权重管制</summary><br>

<a href="https://www.youtube.com/watch?v=mfxuiOj2GhI" target="_blank">
    <img src="https://img.youtube.com/vi/mfxuiOj2GhI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】美国全球AI禁令再升级 | AI扩散出口管制框架 | 国家分成三组 | 每年5W块GPU配额 | 24国禁运GPU | 封堵中国三方和走私途径 | UVEU许可 | 闭源AI模型权重管制



---

</details>

<details>
<summary>525. 【分享】自动驾驶太难了，我已经做得快抑郁了 | 地平线副总裁兼首席架构师苏箐 | 前华为智驾负责人 | 绝望与希望 | FSD断代式领先 | Tesla | 中国特色 | 端到端 | 安全要提升百倍</summary><br>

<a href="https://www.youtube.com/watch?v=z8MgIaS6l1k" target="_blank">
    <img src="https://img.youtube.com/vi/z8MgIaS6l1k/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【分享】自动驾驶太难了，我已经做得快抑郁了 | 地平线副总裁兼首席架构师苏箐 | 前华为智驾负责人 | 绝望与希望 | FSD断代式领先 | Tesla | 中国特色 | 端到端 | 安全要提升百倍



---

</details>

<details>
<summary>524. 【人工智能】AI对齐到底有多难 | Anthropic四名科学家主题沙龙 | 对齐的概念 | 价值观植入 | 超级对齐 | 可解释性研究 | 善意特征 | 思维链 | 欺骗性行为 | 平庸之恶</summary><br>

<a href="https://www.youtube.com/watch?v=ySiZwYR6IIQ" target="_blank">
    <img src="https://img.youtube.com/vi/ySiZwYR6IIQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI对齐到底有多难 | Anthropic四名科学家主题沙龙 | 对齐的概念 | 价值观植入 | 超级对齐 | 可解释性研究 | 善意特征 | 思维链 | 欺骗性行为 | 平庸之恶



---

</details>

<details>
<summary>523. 【人工智能】为什么RLHF不能带给大模型真的强化学习 | 经典RL | 人类偏好奖励 | 模型自主目标 | CoT | PRM | 多智能体工作流 | 为什么RLHF很重要 | 未来的发展方向</summary><br>

<a href="https://www.youtube.com/watch?v=L5OLM4wOzf0" target="_blank">
    <img src="https://img.youtube.com/vi/L5OLM4wOzf0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】为什么RLHF不能带给大模型真的强化学习 | 经典RL | 人类偏好奖励 | 模型自主目标 | CoT | PRM | 多智能体工作流 | 为什么RLHF很重要 | 未来的发展方向



---

</details>

<details>
<summary>522. 【商业】TikTok美联邦最高法院2小时半庭审解读 | 1月19日大限 | 隐形操控美国舆论 | 盗用个人信息 | 背后是否有中国政府控制 | 不卖就禁 | 算法黑箱 | 数据安全 | 特朗普</summary><br>

<a href="https://www.youtube.com/watch?v=BZF_ekvl0QY" target="_blank">
    <img src="https://img.youtube.com/vi/BZF_ekvl0QY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】TikTok美联邦最高法院2小时半庭审解读 | 1月19日大限 | 隐形操控美国舆论 | 盗用个人信息 | 背后是否有中国政府控制 | 不卖就禁 | 算法黑箱 | 数据安全 | 特朗普



---

</details>

<details>
<summary>521. 【人工智能】人类究竟该如何与AI共存 | 斯图尔特·罗素 | AI伦理 | AGI | 深度学习的本质 | 如何控制AI | 人类灭绝的可能 | 偏好 | 宇宙未来的概率分布 | 功利主义</summary><br>

<a href="https://www.youtube.com/watch?v=SMzxkqEyfsk" target="_blank">
    <img src="https://img.youtube.com/vi/SMzxkqEyfsk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】人类究竟该如何与AI共存 | 斯图尔特·罗素 | AI伦理 | AGI | 深度学习的本质 | 如何控制AI | 人类灭绝的可能 | 偏好 | 宇宙未来的概率分布 | 功利主义



---

</details>

<details>
<summary>520. 【人工智能】英伟达Cosmos技术报告解读 | 世界模型平台WFM | 真实物理数据合成 | 扩散模型 | 自回归模型 | 视频分词器 | 视频处理流程 | 预训练 | 后训练</summary><br>

<a href="https://www.youtube.com/watch?v=d_uuY2aZ1c8" target="_blank">
    <img src="https://img.youtube.com/vi/d_uuY2aZ1c8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】英伟达Cosmos技术报告解读 | 世界模型平台WFM | 真实物理数据合成 | 扩散模型 | 自回归模型 | 视频分词器 | 视频处理流程 | 预训练 | 后训练



---

</details>

<details>
<summary>519. 【人工智能】英伟达推出史上最快消费级显卡RTX 5090 | 黄仁勋 | CES 2025 | 缩放法则 | NVLink 72 | Cosmos世界基础模型 | Thor | 最小个人超级计算机</summary><br>

<a href="https://www.youtube.com/watch?v=gjPyCWMPvvE" target="_blank">
    <img src="https://img.youtube.com/vi/gjPyCWMPvvE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】英伟达推出史上最快消费级显卡RTX 5090 | 黄仁勋 | CES 2025 | 缩放法则 | NVLink 72 | Cosmos世界基础模型 | Thor | 最小个人超级计算机



---

</details>

<details>
<summary>518. 【人工智能】去中心神经网络 | Rich Sutton DAI 2024最新演讲 | 深度学习的局限性 | 持续反向传播 | 骨干和边缘神经元 | 网络可塑性 | 适应性 | 流算法 | 克洛普夫</summary><br>

<a href="https://www.youtube.com/watch?v=uvw8-C42uPw" target="_blank">
    <img src="https://img.youtube.com/vi/uvw8-C42uPw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】去中心神经网络 | Rich Sutton DAI 2024最新演讲 | 深度学习的局限性 | 持续反向传播 | 骨干和边缘神经元 | 网络可塑性 | 适应性 | 流算法 | 克洛普夫



---

</details>

<details>
<summary>517. 【商业】全球价值投资与时代 | 李录 | 喜马拉雅资本创始人 | 巴菲特弟子 | 时代的困惑 | 民营经济 | 消费者信心 | 需求侧问题 | 中美矛盾 | 文明的三个阶段 | 认知提升 | 香港</summary><br>

<a href="https://www.youtube.com/watch?v=VSoQsfKCT3c" target="_blank">
    <img src="https://img.youtube.com/vi/VSoQsfKCT3c/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】全球价值投资与时代 | 李录 | 喜马拉雅资本创始人 | 巴菲特弟子 | 时代的困惑 | 民营经济 | 消费者信心 | 需求侧问题 | 中美矛盾 | 文明的三个阶段 | 认知提升 | 香港



---

</details>

<details>
<summary>516. 【人工智能】AI将进入无限记忆时代 | 谷歌前CEO埃里克·施密特 | 无限上下文窗口 | AI Agent | 文本到行动 | 超越人类水平 | AI能源危机 | AI自我进化 | 人类低估了AI</summary><br>

<a href="https://www.youtube.com/watch?v=N2Lv3uKg-4U" target="_blank">
    <img src="https://img.youtube.com/vi/N2Lv3uKg-4U/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AI将进入无限记忆时代 | 谷歌前CEO埃里克·施密特 | 无限上下文窗口 | AI Agent | 文本到行动 | 超越人类水平 | AI能源危机 | AI自我进化 | 人类低估了AI



---

</details>

<details>
<summary>515. 【人工智能】如何在26年前的Windows98上跑Llama模型 | EXO Labs | 奔腾II PC | 代码编译 | llama2.c | 39token/s | AI普惠化 | BitNet</summary><br>

<a href="https://www.youtube.com/watch?v=L2wWiiHyKQw" target="_blank">
    <img src="https://img.youtube.com/vi/L2wWiiHyKQw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】如何在26年前的Windows98上跑Llama模型 | EXO Labs | 奔腾II PC | 代码编译 | llama2.c | 39token/s | AI普惠化 | BitNet



---

</details>

<details>
<summary>514. 【人工智能】大语言模型的Scaling范式 | 思维链CoT作者Jason Wei | 发展历史 | 什么是Scaling | 为什么要Scaling | Scaling的两个范式 | 面临挑战</summary><br>

<a href="https://www.youtube.com/watch?v=v1LNH4mKcwk" target="_blank">
    <img src="https://img.youtube.com/vi/v1LNH4mKcwk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】大语言模型的Scaling范式 | 思维链CoT作者Jason Wei | 发展历史 | 什么是Scaling | 为什么要Scaling | Scaling的两个范式 | 面临挑战



---

</details>

<details>
<summary>513. 【人工智能】国内大模型创业公司近况如何 | 6+2格局 | 智谱 | MiniMax | 百川智能 | 月之暗面 | 阶跃星辰 | 零一万物 | DeepSeek | 面壁智能 | 战略、技术、商业</summary><br>

<a href="https://www.youtube.com/watch?v=PW9_TsIu3dU" target="_blank">
    <img src="https://img.youtube.com/vi/PW9_TsIu3dU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】国内大模型创业公司近况如何 | 6+2格局 | 智谱 | MiniMax | 百川智能 | 月之暗面 | 阶跃星辰 | 零一万物 | DeepSeek | 面壁智能 | 战略、技术、商业



---

</details>

<details>
<summary>512. 【人工智能】Anthropic Clio | 大语言模型在现实世界的使用情况到底如何 | AI自动分析工具 | 隐私保护分析 | 识别趋势和场景用例 | 后部署监控</summary><br>

<a href="https://www.youtube.com/watch?v=ujlR0jRzI7A" target="_blank">
    <img src="https://img.youtube.com/vi/ujlR0jRzI7A/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】Anthropic Clio | 大语言模型在现实世界的使用情况到底如何 | AI自动分析工具 | 隐私保护分析 | 识别趋势和场景用例 | 后部署监控



---

</details>

<details>
<summary>511. 【商业】OpenAI今年会IPO么？ | 拆分为营利和非营利两个实体 | PBC | 慈善机构 | 与微软秘密协议 | AGI等于1000亿美元 | 成本增长 | 会坚持营利么</summary><br>

<a href="https://www.youtube.com/watch?v=xWJBONhU470" target="_blank">
    <img src="https://img.youtube.com/vi/xWJBONhU470/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【商业】OpenAI今年会IPO么？ | 拆分为营利和非营利两个实体 | PBC | 慈善机构 | 与微软秘密协议 | AGI等于1000亿美元 | 成本增长 | 会坚持营利么



---

</details>

<details>
<summary>510. 【人工智能】DeepSeek V3 53页技术报告快速解读 | 性能表现卓越 | 架构创新 | MLA | MoE架构 | DualPipe | 预训练 | 超参数设置 | MTP | 后训练</summary><br>

<a href="https://www.youtube.com/watch?v=PD45fB2n8mU" target="_blank">
    <img src="https://img.youtube.com/vi/PD45fB2n8mU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】DeepSeek V3 53页技术报告快速解读 | 性能表现卓越 | 架构创新 | MLA | MoE架构 | DualPipe | 预训练 | 超参数设置 | MTP | 后训练



---

</details>

<details>
<summary>509. 【闲聊】”极目银河“商业诈骗事件始末 | 62亿缺口 | 850名员工+280只猫被坑 | CEO虚假人设 | 表演式工作 | 盲目扩张业务 | 员工转正要买理财 | 警惕高科技骗局</summary><br>

<a href="https://www.youtube.com/watch?v=QGFb-SFH6oc" target="_blank">
    <img src="https://img.youtube.com/vi/QGFb-SFH6oc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【闲聊】”极目银河“商业诈骗事件始末 | 62亿缺口 | 850名员工+280只猫被坑 | CEO虚假人设 | 表演式工作 | 盲目扩张业务 | 员工转正要买理财 | 警惕高科技骗局



---

</details>

<details>
<summary>508. 【Nvidia】英伟达推出下一代AI加速芯片B300/GB300 | 性能怪兽 | 提升50% | 4NP工艺 | 12层HBM3e | 专为推理模型构建 | NVL72 | 重塑供应链格局</summary><br>

<a href="https://www.youtube.com/watch?v=AUfBhPvtRp0" target="_blank">
    <img src="https://img.youtube.com/vi/AUfBhPvtRp0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【Nvidia】英伟达推出下一代AI加速芯片B300/GB300 | 性能怪兽 | 提升50% | 4NP工艺 | 12层HBM3e | 专为推理模型构建 | NVL72 | 重塑供应链格局



---

</details>

<details>
<summary>507. 【人工智能】AMD和Nvidia相比究竟差在哪 | SemiAnalysis长文对比MI300X和H100/H200性能报告 | 名不副实 | 软件差距巨大 | 单点/多点 | RCCL | HIP</summary><br>

<a href="https://www.youtube.com/watch?v=HwXnko2liLg" target="_blank">
    <img src="https://img.youtube.com/vi/HwXnko2liLg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】AMD和Nvidia相比究竟差在哪 | SemiAnalysis长文对比MI300X和H100/H200性能报告 | 名不副实 | 软件差距巨大 | 单点/多点 | RCCL | HIP



---

</details>

<details>
<summary>506. 【人工智能】2025年AI发展趋势十大预测 | 罗布·托斯 | Llama模型收费 | 缩放法则 | 特朗普和马斯克关系破裂 | AI Agent爆发 | 太空数据中心 | 自主AI | AI事故</summary><br>

<a href="https://www.youtube.com/watch?v=mKkLfw3rvDo" target="_blank">
    <img src="https://img.youtube.com/vi/mKkLfw3rvDo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】2025年AI发展趋势十大预测 | 罗布·托斯 | Llama模型收费 | 缩放法则 | 特朗普和马斯克关系破裂 | AI Agent爆发 | 太空数据中心 | 自主AI | AI事故



---

</details>

<details>
<summary>505. 【人工智能】OpenAI预先发布最强推理模型o3 | 突破ARC-AGI测试 | 智商高达157  | o3-mini | 自适应思考时间 | 审议对齐 | 明年正式发布</summary><br>

<a href="https://www.youtube.com/watch?v=dYdPjfzbaWw" target="_blank">
    <img src="https://img.youtube.com/vi/dYdPjfzbaWw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】OpenAI预先发布最强推理模型o3 | 突破ARC-AGI测试 | 智商高达157  | o3-mini | 自适应思考时间 | 审议对齐 | 明年正式发布



---

</details>

<details>
<summary>504. 【人工智能】当AI学会装傻和欺骗 | Apollo研究报告 | 前沿大模型全中招 | 隐藏真实意图 | 隐蔽性破坏 | 延迟性破坏 | 假意服从 | Ilya看到了什么 | o1模型 | 策略性思维</summary><br>

<a href="https://www.youtube.com/watch?v=43d1KWtPo9I" target="_blank">
    <img src="https://img.youtube.com/vi/43d1KWtPo9I/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】当AI学会装傻和欺骗 | Apollo研究报告 | 前沿大模型全中招 | 隐藏真实意图 | 隐蔽性破坏 | 延迟性破坏 | 假意服从 | Ilya看到了什么 | o1模型 | 策略性思维



---

</details>

<details>
<summary>503. 【人工智能】微软在AI时代的战略布局和挑战 | 萨提亚·纳德拉BG2专访 | 如何成为CEO | 企业文化 | 投资OpenAI | AI Agents | AI搜索 | Copilot | 资本支出</summary><br>

<a href="https://www.youtube.com/watch?v=gRQnttLpWT4" target="_blank">
    <img src="https://img.youtube.com/vi/gRQnttLpWT4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】微软在AI时代的战略布局和挑战 | 萨提亚·纳德拉BG2专访 | 如何成为CEO | 企业文化 | 投资OpenAI | AI Agents | AI搜索 | Copilot | 资本支出



---

</details>

<details>
<summary>502. 【人工智能】红杉美国关于2025年AI行业的三个预测 | AI生态趋于稳固 | 五大公司异军突起 | 巨头竞争加剧 | AI搜索将成为杀手级应用 | 资本支出趋于稳定 | AI算计价格继续下调</summary><br>

<a href="https://www.youtube.com/watch?v=syxKxA3oitw" target="_blank">
    <img src="https://img.youtube.com/vi/syxKxA3oitw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】红杉美国关于2025年AI行业的三个预测 | AI生态趋于稳固 | 五大公司异军突起 | 巨头竞争加剧 | AI搜索将成为杀手级应用 | 资本支出趋于稳定 | AI算计价格继续下调



---

</details>

<details>
<summary>501. 【人工智能】被指“AI血汗工厂”，Scale AI深陷劳工争议旋涡 | Alexandr Wang | AI数据标注独角兽 | Romotasks | 外包工人 | ABC测试 | 逐底竞赛</summary><br>

<a href="https://www.youtube.com/watch?v=4dd54dw_0RI" target="_blank">
    <img src="https://img.youtube.com/vi/4dd54dw_0RI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【人工智能】被指“AI血汗工厂”，Scale AI深陷劳工争议旋涡 | Alexandr Wang | AI数据标注独角兽 | Romotasks | 外包工人 | ABC测试 | 逐底竞赛



---

</details>

